2022-10-08 04:12:31,919 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 04:12:31,920 [trainer.py] => prefix: cil
2022-10-08 04:12:31,920 [trainer.py] => dataset: CFEE
2022-10-08 04:12:31,920 [trainer.py] => memory_size: 2000
2022-10-08 04:12:31,920 [trainer.py] => memory_per_class: 20
2022-10-08 04:12:31,920 [trainer.py] => fixed_memory: True
2022-10-08 04:12:31,920 [trainer.py] => shuffle: True
2022-10-08 04:12:31,920 [trainer.py] => init_cls: 7
2022-10-08 04:12:31,920 [trainer.py] => increment: 5
2022-10-08 04:12:31,920 [trainer.py] => model_name: foster
2022-10-08 04:12:31,920 [trainer.py] => convnet_type: resnet18
2022-10-08 04:12:31,920 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 04:12:31,920 [trainer.py] => seed: 1993
2022-10-08 04:12:31,920 [trainer.py] => beta1: 0.96
2022-10-08 04:12:31,920 [trainer.py] => beta2: 0.97
2022-10-08 04:12:31,920 [trainer.py] => oofc: ft
2022-10-08 04:12:31,920 [trainer.py] => is_teacher_wa: False
2022-10-08 04:12:31,920 [trainer.py] => is_student_wa: False
2022-10-08 04:12:31,920 [trainer.py] => lambda_okd: 1
2022-10-08 04:12:31,920 [trainer.py] => wa_value: 1
2022-10-08 04:12:31,920 [trainer.py] => init_epochs: 40
2022-10-08 04:12:31,920 [trainer.py] => init_lr: 0.01
2022-10-08 04:12:31,920 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 04:12:31,920 [trainer.py] => boosting_epochs: 34
2022-10-08 04:12:31,920 [trainer.py] => compression_epochs: 26
2022-10-08 04:12:31,920 [trainer.py] => lr: 0.001
2022-10-08 04:12:31,920 [trainer.py] => batch_size: 32
2022-10-08 04:12:31,920 [trainer.py] => weight_decay: 0.0005
2022-10-08 04:12:31,920 [trainer.py] => num_workers: 8
2022-10-08 04:12:31,920 [trainer.py] => T: 2
2022-10-08 04:12:31,920 [trainer.py] => nb_runs: 3
2022-10-08 04:12:31,920 [trainer.py] => fold: 10
2022-10-08 04:12:31,921 [data.py] => ========== Fold:0 ==========
2022-10-08 04:12:31,926 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 13, 17, 15, 9, 11, 20, 18, 12, 14, 7, 10, 19, 21, 16, 8]
2022-10-08 04:12:35,244 [foster.py] => Learning on 0-7
2022-10-08 04:12:35,244 [foster.py] => All params: 11183694
2022-10-08 04:12:35,244 [foster.py] => Trainable params: 11183694
2022-10-08 04:12:38,432 [foster.py] => Task 0, Epoch 1/40 => Loss 1.354, Train_accy 51.61
2022-10-08 04:12:41,623 [foster.py] => Task 0, Epoch 2/40 => Loss 0.555, Train_accy 81.19, Test_accy 87.57
2022-10-08 04:12:44,650 [foster.py] => Task 0, Epoch 3/40 => Loss 0.363, Train_accy 86.78, Test_accy 85.31
2022-10-08 04:12:47,812 [foster.py] => Task 0, Epoch 4/40 => Loss 0.290, Train_accy 89.37, Test_accy 86.44
2022-10-08 04:12:50,976 [foster.py] => Task 0, Epoch 5/40 => Loss 0.232, Train_accy 91.40, Test_accy 89.27
2022-10-08 04:12:53,429 [foster.py] => Task 0, Epoch 6/40 => Loss 0.183, Train_accy 94.76
2022-10-08 04:12:56,639 [foster.py] => Task 0, Epoch 7/40 => Loss 0.143, Train_accy 95.94, Test_accy 89.27
2022-10-08 04:12:59,870 [foster.py] => Task 0, Epoch 8/40 => Loss 0.153, Train_accy 94.97, Test_accy 88.14
2022-10-08 04:13:03,124 [foster.py] => Task 0, Epoch 9/40 => Loss 0.120, Train_accy 96.78, Test_accy 89.83
2022-10-08 04:13:06,195 [foster.py] => Task 0, Epoch 10/40 => Loss 0.084, Train_accy 97.69, Test_accy 88.70
2022-10-08 04:13:08,856 [foster.py] => Task 0, Epoch 11/40 => Loss 0.087, Train_accy 96.99
2022-10-08 04:13:12,144 [foster.py] => Task 0, Epoch 12/40 => Loss 0.073, Train_accy 97.69, Test_accy 89.83
2022-10-08 04:13:15,499 [foster.py] => Task 0, Epoch 13/40 => Loss 0.068, Train_accy 97.90, Test_accy 88.70
2022-10-08 04:13:18,810 [foster.py] => Task 0, Epoch 14/40 => Loss 0.052, Train_accy 98.67, Test_accy 90.40
2022-10-08 04:13:22,204 [foster.py] => Task 0, Epoch 15/40 => Loss 0.057, Train_accy 98.53, Test_accy 90.40
2022-10-08 04:13:24,985 [foster.py] => Task 0, Epoch 16/40 => Loss 0.049, Train_accy 98.60
2022-10-08 04:13:28,783 [foster.py] => Task 0, Epoch 17/40 => Loss 0.035, Train_accy 99.30, Test_accy 90.40
2022-10-08 04:13:32,165 [foster.py] => Task 0, Epoch 18/40 => Loss 0.035, Train_accy 99.16, Test_accy 91.53
2022-10-08 04:13:35,638 [foster.py] => Task 0, Epoch 19/40 => Loss 0.024, Train_accy 99.58, Test_accy 90.40
2022-10-08 04:13:39,181 [foster.py] => Task 0, Epoch 20/40 => Loss 0.034, Train_accy 99.44, Test_accy 90.96
2022-10-08 04:13:41,883 [foster.py] => Task 0, Epoch 21/40 => Loss 0.026, Train_accy 99.30
2022-10-08 04:13:45,453 [foster.py] => Task 0, Epoch 22/40 => Loss 0.019, Train_accy 99.86, Test_accy 90.40
2022-10-08 04:13:48,981 [foster.py] => Task 0, Epoch 23/40 => Loss 0.017, Train_accy 99.86, Test_accy 92.09
2022-10-08 04:13:52,595 [foster.py] => Task 0, Epoch 24/40 => Loss 0.018, Train_accy 99.79, Test_accy 90.96
2022-10-08 04:13:56,551 [foster.py] => Task 0, Epoch 25/40 => Loss 0.016, Train_accy 99.93, Test_accy 91.53
2022-10-08 04:13:59,464 [foster.py] => Task 0, Epoch 26/40 => Loss 0.015, Train_accy 99.93
2022-10-08 04:14:03,093 [foster.py] => Task 0, Epoch 27/40 => Loss 0.020, Train_accy 99.65, Test_accy 91.53
2022-10-08 04:14:06,519 [foster.py] => Task 0, Epoch 28/40 => Loss 0.016, Train_accy 99.65, Test_accy 91.53
2022-10-08 04:14:09,953 [foster.py] => Task 0, Epoch 29/40 => Loss 0.015, Train_accy 99.72, Test_accy 91.53
2022-10-08 04:14:13,854 [foster.py] => Task 0, Epoch 30/40 => Loss 0.017, Train_accy 99.58, Test_accy 91.53
2022-10-08 04:14:16,560 [foster.py] => Task 0, Epoch 31/40 => Loss 0.014, Train_accy 99.93
2022-10-08 04:14:20,017 [foster.py] => Task 0, Epoch 32/40 => Loss 0.018, Train_accy 99.72, Test_accy 91.53
2022-10-08 04:14:23,309 [foster.py] => Task 0, Epoch 33/40 => Loss 0.012, Train_accy 99.93, Test_accy 91.53
2022-10-08 04:14:26,962 [foster.py] => Task 0, Epoch 34/40 => Loss 0.012, Train_accy 99.86, Test_accy 91.53
2022-10-08 04:14:30,935 [foster.py] => Task 0, Epoch 35/40 => Loss 0.016, Train_accy 99.86, Test_accy 90.96
2022-10-08 04:14:33,848 [foster.py] => Task 0, Epoch 36/40 => Loss 0.016, Train_accy 99.65
2022-10-08 04:14:37,468 [foster.py] => Task 0, Epoch 37/40 => Loss 0.015, Train_accy 99.79, Test_accy 91.53
2022-10-08 04:14:40,992 [foster.py] => Task 0, Epoch 38/40 => Loss 0.017, Train_accy 99.72, Test_accy 90.96
2022-10-08 04:14:44,437 [foster.py] => Task 0, Epoch 39/40 => Loss 0.013, Train_accy 99.86, Test_accy 91.53
2022-10-08 04:14:53,838 [foster.py] => Task 0, Epoch 40/40 => Loss 0.012, Train_accy 100.00, Test_accy 91.53
2022-10-08 04:14:53,839 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 04:15:01,189 [foster.py] => Exemplar size: 140
2022-10-08 04:15:01,189 [trainer.py] => CNN: {'total': 91.53, 'old': 91.53, 'new': 0, 'base': 91.53, 'compound': 0}
2022-10-08 04:15:01,189 [trainer.py] => CNN top1 curve: [91.53]
2022-10-08 04:15:01,189 [trainer.py] => CNN base curve: [91.53]
2022-10-08 04:15:01,189 [trainer.py] => CNN old curve: [91.53]
2022-10-08 04:15:01,189 [trainer.py] => CNN new curve: [0]
2022-10-08 04:15:01,189 [trainer.py] => CNN compound curve: [0]
2022-10-08 04:15:01,189 [trainer.py] => NME: {'total': 90.96, 'old': 90.96, 'new': 0, 'base': 90.96, 'compound': 0}
2022-10-08 04:15:01,189 [trainer.py] => NME top1 curve: [90.96]
2022-10-08 04:15:01,189 [trainer.py] => NME base curve: [90.96]
2022-10-08 04:15:01,189 [trainer.py] => NME old curve: [90.96]
2022-10-08 04:15:01,189 [trainer.py] => NME new curve: [0]
2022-10-08 04:15:01,189 [trainer.py] => NME compound curve: [0]
2022-10-08 04:15:01,434 [foster.py] => Learning on 7-12
2022-10-08 04:15:01,434 [foster.py] => All params: 22375071
2022-10-08 04:15:01,435 [foster.py] => Trainable params: 11194968
2022-10-08 04:15:01,445 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 04:15:04,867 [foster.py] => Task 1, Epoch 1/34 => Loss 4.731, Loss_clf 2.208, Loss_fe 1.868, Loss_kd 0.382, Train_accy 37.14, Test_accy 67.93
2022-10-08 04:15:07,399 [foster.py] => Task 1, Epoch 2/34 => Loss 2.619, Loss_clf 0.742, Loss_fe 1.239, Loss_kd 0.372, Train_accy 63.37
2022-10-08 04:15:09,950 [foster.py] => Task 1, Epoch 3/34 => Loss 2.232, Loss_clf 0.586, Loss_fe 1.008, Loss_kd 0.372, Train_accy 46.59
2022-10-08 04:15:12,482 [foster.py] => Task 1, Epoch 4/34 => Loss 2.079, Loss_clf 0.562, Loss_fe 0.894, Loss_kd 0.363, Train_accy 46.68
2022-10-08 04:15:15,003 [foster.py] => Task 1, Epoch 5/34 => Loss 1.953, Loss_clf 0.508, Loss_fe 0.815, Loss_kd 0.368, Train_accy 48.81
2022-10-08 04:15:18,638 [foster.py] => Task 1, Epoch 6/34 => Loss 1.891, Loss_clf 0.505, Loss_fe 0.761, Loss_kd 0.365, Train_accy 46.51, Test_accy 68.62
2022-10-08 04:15:21,454 [foster.py] => Task 1, Epoch 7/34 => Loss 1.799, Loss_clf 0.476, Loss_fe 0.699, Loss_kd 0.364, Train_accy 47.79
2022-10-08 04:15:24,214 [foster.py] => Task 1, Epoch 8/34 => Loss 1.755, Loss_clf 0.469, Loss_fe 0.661, Loss_kd 0.364, Train_accy 47.10
2022-10-08 04:15:27,005 [foster.py] => Task 1, Epoch 9/34 => Loss 1.722, Loss_clf 0.459, Loss_fe 0.645, Loss_kd 0.360, Train_accy 47.70
2022-10-08 04:15:30,009 [foster.py] => Task 1, Epoch 10/34 => Loss 1.681, Loss_clf 0.434, Loss_fe 0.622, Loss_kd 0.365, Train_accy 47.87
2022-10-08 04:15:33,875 [foster.py] => Task 1, Epoch 11/34 => Loss 1.633, Loss_clf 0.425, Loss_fe 0.582, Loss_kd 0.365, Train_accy 48.98, Test_accy 67.93
2022-10-08 04:15:36,756 [foster.py] => Task 1, Epoch 12/34 => Loss 1.601, Loss_clf 0.418, Loss_fe 0.563, Loss_kd 0.361, Train_accy 48.89
2022-10-08 04:15:39,789 [foster.py] => Task 1, Epoch 13/34 => Loss 1.585, Loss_clf 0.416, Loss_fe 0.550, Loss_kd 0.361, Train_accy 48.30
2022-10-08 04:15:42,935 [foster.py] => Task 1, Epoch 14/34 => Loss 1.560, Loss_clf 0.406, Loss_fe 0.539, Loss_kd 0.359, Train_accy 49.83
2022-10-08 04:15:45,934 [foster.py] => Task 1, Epoch 15/34 => Loss 1.537, Loss_clf 0.395, Loss_fe 0.524, Loss_kd 0.361, Train_accy 50.09
2022-10-08 04:15:49,865 [foster.py] => Task 1, Epoch 16/34 => Loss 1.529, Loss_clf 0.395, Loss_fe 0.516, Loss_kd 0.360, Train_accy 47.44, Test_accy 68.28
2022-10-08 04:15:52,962 [foster.py] => Task 1, Epoch 17/34 => Loss 1.497, Loss_clf 0.381, Loss_fe 0.491, Loss_kd 0.365, Train_accy 51.62
2022-10-08 04:15:55,994 [foster.py] => Task 1, Epoch 18/34 => Loss 1.478, Loss_clf 0.371, Loss_fe 0.483, Loss_kd 0.364, Train_accy 49.32
2022-10-08 04:15:59,061 [foster.py] => Task 1, Epoch 19/34 => Loss 1.468, Loss_clf 0.372, Loss_fe 0.482, Loss_kd 0.358, Train_accy 47.79
2022-10-08 04:16:02,022 [foster.py] => Task 1, Epoch 20/34 => Loss 1.448, Loss_clf 0.355, Loss_fe 0.469, Loss_kd 0.364, Train_accy 50.34
2022-10-08 04:16:05,884 [foster.py] => Task 1, Epoch 21/34 => Loss 1.483, Loss_clf 0.377, Loss_fe 0.492, Loss_kd 0.358, Train_accy 48.98, Test_accy 68.28
2022-10-08 04:16:08,695 [foster.py] => Task 1, Epoch 22/34 => Loss 1.431, Loss_clf 0.358, Loss_fe 0.460, Loss_kd 0.357, Train_accy 49.74
2022-10-08 04:16:11,953 [foster.py] => Task 1, Epoch 23/34 => Loss 1.422, Loss_clf 0.347, Loss_fe 0.453, Loss_kd 0.363, Train_accy 51.02
2022-10-08 04:16:15,208 [foster.py] => Task 1, Epoch 24/34 => Loss 1.431, Loss_clf 0.356, Loss_fe 0.461, Loss_kd 0.358, Train_accy 49.83
2022-10-08 04:16:18,390 [foster.py] => Task 1, Epoch 25/34 => Loss 1.410, Loss_clf 0.349, Loss_fe 0.447, Loss_kd 0.359, Train_accy 49.91
2022-10-08 04:16:22,543 [foster.py] => Task 1, Epoch 26/34 => Loss 1.400, Loss_clf 0.341, Loss_fe 0.444, Loss_kd 0.358, Train_accy 50.00, Test_accy 68.97
2022-10-08 04:16:25,723 [foster.py] => Task 1, Epoch 27/34 => Loss 1.401, Loss_clf 0.338, Loss_fe 0.445, Loss_kd 0.361, Train_accy 50.17
2022-10-08 04:16:28,925 [foster.py] => Task 1, Epoch 28/34 => Loss 1.436, Loss_clf 0.358, Loss_fe 0.457, Loss_kd 0.362, Train_accy 50.94
2022-10-08 04:16:31,928 [foster.py] => Task 1, Epoch 29/34 => Loss 1.404, Loss_clf 0.343, Loss_fe 0.441, Loss_kd 0.362, Train_accy 51.19
2022-10-08 04:16:34,906 [foster.py] => Task 1, Epoch 30/34 => Loss 1.419, Loss_clf 0.351, Loss_fe 0.450, Loss_kd 0.360, Train_accy 49.74
2022-10-08 04:16:38,768 [foster.py] => Task 1, Epoch 31/34 => Loss 1.410, Loss_clf 0.341, Loss_fe 0.448, Loss_kd 0.363, Train_accy 51.02, Test_accy 69.66
2022-10-08 04:16:41,588 [foster.py] => Task 1, Epoch 32/34 => Loss 1.411, Loss_clf 0.347, Loss_fe 0.443, Loss_kd 0.362, Train_accy 50.85
2022-10-08 04:16:44,717 [foster.py] => Task 1, Epoch 33/34 => Loss 1.394, Loss_clf 0.339, Loss_fe 0.433, Loss_kd 0.363, Train_accy 51.45
2022-10-08 04:16:47,777 [foster.py] => Task 1, Epoch 34/34 => Loss 1.387, Loss_clf 0.333, Loss_fe 0.433, Loss_kd 0.362, Train_accy 50.60
2022-10-08 04:16:47,778 [foster.py] => do not weight align teacher!
2022-10-08 04:16:47,778 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 04:16:52,528 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.670,  Train_accy 11.67, Test_accy 54.14
2022-10-08 04:16:55,986 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.552,  Train_accy 12.10
2022-10-08 04:16:59,458 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.478,  Train_accy 14.40
2022-10-08 04:17:03,407 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.451,  Train_accy 15.33
2022-10-08 04:17:07,077 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.441,  Train_accy 17.80
2022-10-08 04:17:11,435 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.407,  Train_accy 21.29, Test_accy 58.62
2022-10-08 04:17:14,675 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.397,  Train_accy 21.38
2022-10-08 04:17:18,070 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.399,  Train_accy 20.95
2022-10-08 04:17:21,705 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.373,  Train_accy 21.81
2022-10-08 04:17:25,143 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.374,  Train_accy 22.23
2022-10-08 04:17:29,580 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.373,  Train_accy 23.34, Test_accy 60.34
2022-10-08 04:17:33,912 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.359,  Train_accy 23.42
2022-10-08 04:17:37,980 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.353,  Train_accy 24.36
2022-10-08 04:17:41,960 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.352,  Train_accy 24.36
2022-10-08 04:17:45,669 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.357,  Train_accy 24.62
2022-10-08 04:17:49,867 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.345,  Train_accy 24.53, Test_accy 61.03
2022-10-08 04:17:53,244 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.348,  Train_accy 26.24
2022-10-08 04:17:56,733 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.347,  Train_accy 24.79
2022-10-08 04:18:00,205 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.335,  Train_accy 26.15
2022-10-08 04:18:03,776 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.343,  Train_accy 25.72
2022-10-08 04:18:09,175 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.340,  Train_accy 24.87, Test_accy 61.38
2022-10-08 04:18:12,648 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.342,  Train_accy 25.47
2022-10-08 04:18:15,875 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.336,  Train_accy 26.49
2022-10-08 04:18:19,456 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.341,  Train_accy 25.55
2022-10-08 04:18:23,474 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.335,  Train_accy 26.06
2022-10-08 04:18:28,324 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.326,  Train_accy 26.15, Test_accy 60.69
2022-10-08 04:18:28,325 [foster.py] => do not weight align student!
2022-10-08 04:18:29,098 [foster.py] => darknet eval: 
2022-10-08 04:18:29,098 [foster.py] => CNN top1 curve: 60.69
2022-10-08 04:18:29,098 [foster.py] => CNN top5 curve: 98.97
2022-10-08 04:18:29,098 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 04:18:37,968 [foster.py] => Exemplar size: 240
2022-10-08 04:18:37,968 [trainer.py] => CNN: {'total': 68.62, 'old': 83.62, 'new': 45.13, 'base': 83.62, 'compound': 45.13}
2022-10-08 04:18:37,968 [trainer.py] => CNN top1 curve: [91.53, 68.62]
2022-10-08 04:18:37,968 [trainer.py] => CNN base curve: [91.53, 83.62]
2022-10-08 04:18:37,968 [trainer.py] => CNN old curve: [91.53, 83.62]
2022-10-08 04:18:37,968 [trainer.py] => CNN new curve: [0, 45.13]
2022-10-08 04:18:37,968 [trainer.py] => CNN compound curve: [0, 45.13]
2022-10-08 04:18:37,968 [trainer.py] => NME: {'total': 75.86, 'old': 77.97, 'new': 72.57, 'base': 77.97, 'compound': 72.57}
2022-10-08 04:18:37,968 [trainer.py] => NME top1 curve: [90.96, 75.86]
2022-10-08 04:18:37,968 [trainer.py] => NME base curve: [90.96, 77.97]
2022-10-08 04:18:37,968 [trainer.py] => NME old curve: [90.96, 77.97]
2022-10-08 04:18:37,968 [trainer.py] => NME new curve: [0, 72.57]
2022-10-08 04:18:37,968 [trainer.py] => NME compound curve: [0, 72.57]
2022-10-08 04:18:38,217 [foster.py] => Learning on 12-17
2022-10-08 04:18:38,218 [foster.py] => All params: 22385326
2022-10-08 04:18:38,218 [foster.py] => Trainable params: 11202658
2022-10-08 04:18:38,228 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 04:18:41,997 [foster.py] => Task 2, Epoch 1/34 => Loss 5.820, Loss_clf 2.072, Loss_fe 2.299, Loss_kd 1.023, Train_accy 38.40, Test_accy 47.84
2022-10-08 04:18:44,772 [foster.py] => Task 2, Epoch 2/34 => Loss 3.916, Loss_clf 1.012, Loss_fe 1.517, Loss_kd 0.979, Train_accy 43.69
2022-10-08 04:18:47,552 [foster.py] => Task 2, Epoch 3/34 => Loss 3.636, Loss_clf 0.897, Loss_fe 1.360, Loss_kd 0.974, Train_accy 42.06
2022-10-08 04:18:50,934 [foster.py] => Task 2, Epoch 4/34 => Loss 3.380, Loss_clf 0.823, Loss_fe 1.174, Loss_kd 0.977, Train_accy 41.74
2022-10-08 04:18:54,082 [foster.py] => Task 2, Epoch 5/34 => Loss 3.308, Loss_clf 0.785, Loss_fe 1.130, Loss_kd 0.983, Train_accy 43.38
2022-10-08 04:18:58,062 [foster.py] => Task 2, Epoch 6/34 => Loss 3.254, Loss_clf 0.781, Loss_fe 1.096, Loss_kd 0.972, Train_accy 42.21, Test_accy 52.67
2022-10-08 04:19:00,920 [foster.py] => Task 2, Epoch 7/34 => Loss 3.112, Loss_clf 0.746, Loss_fe 1.000, Loss_kd 0.964, Train_accy 41.36
2022-10-08 04:19:07,761 [foster.py] => Task 2, Epoch 8/34 => Loss 3.088, Loss_clf 0.730, Loss_fe 0.974, Loss_kd 0.976, Train_accy 46.03
2022-10-08 04:19:11,447 [foster.py] => Task 2, Epoch 9/34 => Loss 3.022, Loss_clf 0.713, Loss_fe 0.931, Loss_kd 0.973, Train_accy 45.17
2022-10-08 04:19:14,500 [foster.py] => Task 2, Epoch 10/34 => Loss 2.983, Loss_clf 0.700, Loss_fe 0.900, Loss_kd 0.976, Train_accy 42.60
2022-10-08 04:19:18,328 [foster.py] => Task 2, Epoch 11/34 => Loss 2.937, Loss_clf 0.690, Loss_fe 0.860, Loss_kd 0.979, Train_accy 45.64, Test_accy 54.45
2022-10-08 04:19:21,227 [foster.py] => Task 2, Epoch 12/34 => Loss 2.849, Loss_clf 0.661, Loss_fe 0.809, Loss_kd 0.973, Train_accy 46.26
2022-10-08 04:19:24,085 [foster.py] => Task 2, Epoch 13/34 => Loss 2.838, Loss_clf 0.649, Loss_fe 0.811, Loss_kd 0.973, Train_accy 45.56
2022-10-08 04:19:26,985 [foster.py] => Task 2, Epoch 14/34 => Loss 2.850, Loss_clf 0.643, Loss_fe 0.805, Loss_kd 0.989, Train_accy 45.79
2022-10-08 04:19:30,161 [foster.py] => Task 2, Epoch 15/34 => Loss 2.792, Loss_clf 0.629, Loss_fe 0.777, Loss_kd 0.978, Train_accy 47.43
2022-10-08 04:19:34,609 [foster.py] => Task 2, Epoch 16/34 => Loss 2.785, Loss_clf 0.635, Loss_fe 0.759, Loss_kd 0.982, Train_accy 45.40, Test_accy 55.22
2022-10-08 04:19:37,747 [foster.py] => Task 2, Epoch 17/34 => Loss 2.772, Loss_clf 0.627, Loss_fe 0.746, Loss_kd 0.987, Train_accy 46.26
2022-10-08 04:19:40,892 [foster.py] => Task 2, Epoch 18/34 => Loss 2.723, Loss_clf 0.610, Loss_fe 0.729, Loss_kd 0.977, Train_accy 45.64
2022-10-08 04:19:44,034 [foster.py] => Task 2, Epoch 19/34 => Loss 2.667, Loss_clf 0.578, Loss_fe 0.701, Loss_kd 0.979, Train_accy 48.75
2022-10-08 04:19:47,568 [foster.py] => Task 2, Epoch 20/34 => Loss 2.696, Loss_clf 0.586, Loss_fe 0.714, Loss_kd 0.985, Train_accy 48.91
2022-10-08 04:19:52,003 [foster.py] => Task 2, Epoch 21/34 => Loss 2.636, Loss_clf 0.578, Loss_fe 0.681, Loss_kd 0.972, Train_accy 46.34, Test_accy 54.71
2022-10-08 04:19:55,278 [foster.py] => Task 2, Epoch 22/34 => Loss 2.665, Loss_clf 0.570, Loss_fe 0.698, Loss_kd 0.986, Train_accy 49.53
2022-10-08 04:19:58,564 [foster.py] => Task 2, Epoch 23/34 => Loss 2.635, Loss_clf 0.574, Loss_fe 0.686, Loss_kd 0.970, Train_accy 48.83
2022-10-08 04:20:01,836 [foster.py] => Task 2, Epoch 24/34 => Loss 2.632, Loss_clf 0.561, Loss_fe 0.671, Loss_kd 0.988, Train_accy 49.61
2022-10-08 04:20:04,926 [foster.py] => Task 2, Epoch 25/34 => Loss 2.659, Loss_clf 0.577, Loss_fe 0.691, Loss_kd 0.982, Train_accy 48.60
2022-10-08 04:20:09,105 [foster.py] => Task 2, Epoch 26/34 => Loss 2.614, Loss_clf 0.553, Loss_fe 0.679, Loss_kd 0.975, Train_accy 50.78, Test_accy 54.96
2022-10-08 04:20:12,193 [foster.py] => Task 2, Epoch 27/34 => Loss 2.593, Loss_clf 0.546, Loss_fe 0.657, Loss_kd 0.981, Train_accy 49.14
2022-10-08 04:20:15,449 [foster.py] => Task 2, Epoch 28/34 => Loss 2.639, Loss_clf 0.570, Loss_fe 0.672, Loss_kd 0.986, Train_accy 47.90
2022-10-08 04:20:18,631 [foster.py] => Task 2, Epoch 29/34 => Loss 2.584, Loss_clf 0.552, Loss_fe 0.653, Loss_kd 0.973, Train_accy 48.44
2022-10-08 04:20:21,831 [foster.py] => Task 2, Epoch 30/34 => Loss 2.571, Loss_clf 0.542, Loss_fe 0.648, Loss_kd 0.974, Train_accy 50.23
2022-10-08 04:20:25,970 [foster.py] => Task 2, Epoch 31/34 => Loss 2.570, Loss_clf 0.539, Loss_fe 0.641, Loss_kd 0.981, Train_accy 48.99, Test_accy 55.22
2022-10-08 04:20:29,367 [foster.py] => Task 2, Epoch 32/34 => Loss 2.590, Loss_clf 0.539, Loss_fe 0.674, Loss_kd 0.972, Train_accy 48.83
2022-10-08 04:20:32,610 [foster.py] => Task 2, Epoch 33/34 => Loss 2.627, Loss_clf 0.570, Loss_fe 0.668, Loss_kd 0.980, Train_accy 48.44
2022-10-08 04:20:35,889 [foster.py] => Task 2, Epoch 34/34 => Loss 2.571, Loss_clf 0.544, Loss_fe 0.649, Loss_kd 0.973, Train_accy 48.05
2022-10-08 04:20:35,889 [foster.py] => do not weight align teacher!
2022-10-08 04:20:35,890 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 04:20:40,752 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.094,  Train_accy 11.99, Test_accy 44.02
2022-10-08 04:20:44,496 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 2.017,  Train_accy 12.31
2022-10-08 04:20:48,416 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.995,  Train_accy 12.38
2022-10-08 04:20:52,273 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.990,  Train_accy 12.46
2022-10-08 04:20:56,813 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.971,  Train_accy 12.62
2022-10-08 04:21:02,140 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.958,  Train_accy 13.01, Test_accy 44.27
2022-10-08 04:21:06,040 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.951,  Train_accy 13.40
2022-10-08 04:21:09,907 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.940,  Train_accy 13.24
2022-10-08 04:21:14,288 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.936,  Train_accy 13.63
2022-10-08 04:21:18,606 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.928,  Train_accy 13.71
2022-10-08 04:21:23,818 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.933,  Train_accy 14.41, Test_accy 45.29
2022-10-08 04:21:27,530 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.914,  Train_accy 14.41
2022-10-08 04:21:31,728 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.919,  Train_accy 13.63
2022-10-08 04:21:35,856 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.906,  Train_accy 14.33
2022-10-08 04:21:39,903 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.923,  Train_accy 15.34
2022-10-08 04:21:44,924 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.899,  Train_accy 14.72, Test_accy 46.82
2022-10-08 04:21:48,798 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.904,  Train_accy 14.33
2022-10-08 04:21:52,702 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.903,  Train_accy 14.72
2022-10-08 04:21:56,427 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.908,  Train_accy 14.72
2022-10-08 04:22:01,774 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.913,  Train_accy 14.80
2022-10-08 04:22:07,921 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.900,  Train_accy 15.11, Test_accy 46.06
2022-10-08 04:22:12,261 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.908,  Train_accy 15.65
2022-10-08 04:22:16,654 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.903,  Train_accy 15.89
2022-10-08 04:22:20,632 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.898,  Train_accy 15.50
2022-10-08 04:22:24,620 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.890,  Train_accy 14.72
2022-10-08 04:22:29,493 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.900,  Train_accy 15.11, Test_accy 46.56
2022-10-08 04:22:29,494 [foster.py] => do not weight align student!
2022-10-08 04:22:30,410 [foster.py] => darknet eval: 
2022-10-08 04:22:30,410 [foster.py] => CNN top1 curve: 46.56
2022-10-08 04:22:30,410 [foster.py] => CNN top5 curve: 94.15
2022-10-08 04:22:30,411 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 04:22:41,240 [foster.py] => Exemplar size: 340
2022-10-08 04:22:41,240 [trainer.py] => CNN: {'total': 55.47, 'old': 62.07, 'new': 36.89, 'base': 80.79, 'compound': 34.72}
2022-10-08 04:22:41,240 [trainer.py] => CNN top1 curve: [91.53, 68.62, 55.47]
2022-10-08 04:22:41,240 [trainer.py] => CNN base curve: [91.53, 83.62, 80.79]
2022-10-08 04:22:41,240 [trainer.py] => CNN old curve: [91.53, 83.62, 62.07]
2022-10-08 04:22:41,240 [trainer.py] => CNN new curve: [0, 45.13, 36.89]
2022-10-08 04:22:41,240 [trainer.py] => CNN compound curve: [0, 45.13, 34.72]
2022-10-08 04:22:41,240 [trainer.py] => NME: {'total': 67.18, 'old': 67.24, 'new': 66.99, 'base': 71.75, 'compound': 63.43}
2022-10-08 04:22:41,240 [trainer.py] => NME top1 curve: [90.96, 75.86, 67.18]
2022-10-08 04:22:41,240 [trainer.py] => NME base curve: [90.96, 77.97, 71.75]
2022-10-08 04:22:41,240 [trainer.py] => NME old curve: [90.96, 77.97, 67.24]
2022-10-08 04:22:41,240 [trainer.py] => NME new curve: [0, 72.57, 66.99]
2022-10-08 04:22:41,240 [trainer.py] => NME compound curve: [0, 72.57, 63.43]
2022-10-08 04:22:41,511 [foster.py] => Learning on 17-22
2022-10-08 04:22:41,512 [foster.py] => All params: 22395581
2022-10-08 04:22:41,512 [foster.py] => Trainable params: 11210348
2022-10-08 04:22:41,522 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 04:22:45,535 [foster.py] => Task 3, Epoch 1/34 => Loss 6.506, Loss_clf 2.075, Loss_fe 2.431, Loss_kd 1.546, Train_accy 30.81, Test_accy 44.95
2022-10-08 04:22:48,473 [foster.py] => Task 3, Epoch 2/34 => Loss 4.999, Loss_clf 1.217, Loss_fe 1.812, Loss_kd 1.522, Train_accy 32.12
2022-10-08 04:22:51,624 [foster.py] => Task 3, Epoch 3/34 => Loss 4.693, Loss_clf 1.117, Loss_fe 1.612, Loss_kd 1.517, Train_accy 35.11
2022-10-08 04:22:54,754 [foster.py] => Task 3, Epoch 4/34 => Loss 4.558, Loss_clf 1.083, Loss_fe 1.511, Loss_kd 1.518, Train_accy 33.87
2022-10-08 04:22:58,207 [foster.py] => Task 3, Epoch 5/34 => Loss 4.427, Loss_clf 1.047, Loss_fe 1.418, Loss_kd 1.515, Train_accy 35.98
2022-10-08 04:23:02,887 [foster.py] => Task 3, Epoch 6/34 => Loss 4.275, Loss_clf 1.003, Loss_fe 1.320, Loss_kd 1.509, Train_accy 35.11, Test_accy 46.53
2022-10-08 04:23:06,212 [foster.py] => Task 3, Epoch 7/34 => Loss 4.224, Loss_clf 0.991, Loss_fe 1.276, Loss_kd 1.512, Train_accy 35.62
2022-10-08 04:23:10,440 [foster.py] => Task 3, Epoch 8/34 => Loss 4.149, Loss_clf 0.962, Loss_fe 1.225, Loss_kd 1.516, Train_accy 36.34
2022-10-08 04:23:14,685 [foster.py] => Task 3, Epoch 9/34 => Loss 4.102, Loss_clf 0.957, Loss_fe 1.186, Loss_kd 1.514, Train_accy 37.51
2022-10-08 04:23:18,874 [foster.py] => Task 3, Epoch 10/34 => Loss 4.019, Loss_clf 0.926, Loss_fe 1.132, Loss_kd 1.516, Train_accy 38.38
2022-10-08 04:23:24,272 [foster.py] => Task 3, Epoch 11/34 => Loss 4.004, Loss_clf 0.923, Loss_fe 1.114, Loss_kd 1.520, Train_accy 37.87, Test_accy 49.11
2022-10-08 04:23:27,773 [foster.py] => Task 3, Epoch 12/34 => Loss 3.931, Loss_clf 0.889, Loss_fe 1.076, Loss_kd 1.520, Train_accy 38.67
2022-10-08 04:23:31,306 [foster.py] => Task 3, Epoch 13/34 => Loss 3.892, Loss_clf 0.879, Loss_fe 1.050, Loss_kd 1.517, Train_accy 38.97
2022-10-08 04:23:34,856 [foster.py] => Task 3, Epoch 14/34 => Loss 3.823, Loss_clf 0.855, Loss_fe 1.009, Loss_kd 1.513, Train_accy 41.73
2022-10-08 04:23:38,373 [foster.py] => Task 3, Epoch 15/34 => Loss 3.815, Loss_clf 0.847, Loss_fe 0.996, Loss_kd 1.524, Train_accy 39.11
2022-10-08 04:23:48,961 [foster.py] => Task 3, Epoch 16/34 => Loss 3.789, Loss_clf 0.841, Loss_fe 0.981, Loss_kd 1.520, Train_accy 40.71, Test_accy 48.71
2022-10-08 04:23:52,174 [foster.py] => Task 3, Epoch 17/34 => Loss 3.742, Loss_clf 0.828, Loss_fe 0.952, Loss_kd 1.516, Train_accy 39.55
2022-10-08 04:23:55,266 [foster.py] => Task 3, Epoch 18/34 => Loss 3.721, Loss_clf 0.811, Loss_fe 0.942, Loss_kd 1.520, Train_accy 41.59
2022-10-08 04:23:58,543 [foster.py] => Task 3, Epoch 19/34 => Loss 3.680, Loss_clf 0.798, Loss_fe 0.917, Loss_kd 1.518, Train_accy 41.51
2022-10-08 04:24:02,146 [foster.py] => Task 3, Epoch 20/34 => Loss 3.653, Loss_clf 0.783, Loss_fe 0.906, Loss_kd 1.518, Train_accy 41.44
2022-10-08 04:24:06,998 [foster.py] => Task 3, Epoch 21/34 => Loss 3.631, Loss_clf 0.781, Loss_fe 0.892, Loss_kd 1.513, Train_accy 40.57, Test_accy 49.90
2022-10-08 04:24:10,770 [foster.py] => Task 3, Epoch 22/34 => Loss 3.621, Loss_clf 0.765, Loss_fe 0.883, Loss_kd 1.525, Train_accy 42.17
2022-10-08 04:24:14,383 [foster.py] => Task 3, Epoch 23/34 => Loss 3.607, Loss_clf 0.762, Loss_fe 0.876, Loss_kd 1.522, Train_accy 42.32
2022-10-08 04:24:18,057 [foster.py] => Task 3, Epoch 24/34 => Loss 3.593, Loss_clf 0.755, Loss_fe 0.867, Loss_kd 1.523, Train_accy 43.19
2022-10-08 04:24:21,421 [foster.py] => Task 3, Epoch 25/34 => Loss 3.605, Loss_clf 0.760, Loss_fe 0.875, Loss_kd 1.523, Train_accy 43.55
2022-10-08 04:24:26,084 [foster.py] => Task 3, Epoch 26/34 => Loss 3.616, Loss_clf 0.767, Loss_fe 0.884, Loss_kd 1.519, Train_accy 41.73, Test_accy 50.10
2022-10-08 04:24:29,301 [foster.py] => Task 3, Epoch 27/34 => Loss 3.578, Loss_clf 0.755, Loss_fe 0.853, Loss_kd 1.522, Train_accy 43.85
2022-10-08 04:24:37,432 [foster.py] => Task 3, Epoch 28/34 => Loss 3.572, Loss_clf 0.751, Loss_fe 0.861, Loss_kd 1.515, Train_accy 43.55
2022-10-08 04:24:42,003 [foster.py] => Task 3, Epoch 29/34 => Loss 3.560, Loss_clf 0.740, Loss_fe 0.851, Loss_kd 1.521, Train_accy 43.48
2022-10-08 04:24:45,742 [foster.py] => Task 3, Epoch 30/34 => Loss 3.545, Loss_clf 0.742, Loss_fe 0.843, Loss_kd 1.515, Train_accy 43.34
2022-10-08 04:24:50,283 [foster.py] => Task 3, Epoch 31/34 => Loss 3.565, Loss_clf 0.743, Loss_fe 0.853, Loss_kd 1.522, Train_accy 43.34, Test_accy 49.90
2022-10-08 04:24:53,354 [foster.py] => Task 3, Epoch 32/34 => Loss 3.546, Loss_clf 0.737, Loss_fe 0.848, Loss_kd 1.516, Train_accy 42.83
2022-10-08 04:24:56,663 [foster.py] => Task 3, Epoch 33/34 => Loss 3.545, Loss_clf 0.726, Loss_fe 0.842, Loss_kd 1.528, Train_accy 44.79
2022-10-08 04:25:00,027 [foster.py] => Task 3, Epoch 34/34 => Loss 3.532, Loss_clf 0.728, Loss_fe 0.839, Loss_kd 1.518, Train_accy 42.75
2022-10-08 04:25:00,027 [foster.py] => do not weight align teacher!
2022-10-08 04:25:00,028 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 04:25:04,830 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.448,  Train_accy 12.75, Test_accy 36.83
2022-10-08 04:25:08,724 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.398,  Train_accy 12.96
2022-10-08 04:25:12,921 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.376,  Train_accy 13.62
2022-10-08 04:25:16,998 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.367,  Train_accy 13.69
2022-10-08 04:25:21,110 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.365,  Train_accy 13.98
2022-10-08 04:25:26,050 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.345,  Train_accy 13.55, Test_accy 39.60
2022-10-08 04:25:30,154 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.341,  Train_accy 14.06
2022-10-08 04:25:35,276 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.338,  Train_accy 13.84
2022-10-08 04:25:40,399 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.333,  Train_accy 13.84
2022-10-08 04:25:45,366 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.335,  Train_accy 14.64
2022-10-08 04:25:50,617 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.332,  Train_accy 13.91, Test_accy 40.59
2022-10-08 04:25:54,500 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.323,  Train_accy 14.64
2022-10-08 04:25:58,385 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.328,  Train_accy 13.77
2022-10-08 04:26:02,408 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.334,  Train_accy 14.06
2022-10-08 04:26:06,564 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.331,  Train_accy 14.28
2022-10-08 04:26:11,583 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.322,  Train_accy 13.69, Test_accy 40.59
2022-10-08 04:26:15,550 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.332,  Train_accy 14.20
2022-10-08 04:26:19,869 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.324,  Train_accy 14.28
2022-10-08 04:26:24,310 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.316,  Train_accy 14.64
2022-10-08 04:26:28,691 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.325,  Train_accy 13.98
2022-10-08 04:26:34,078 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.307,  Train_accy 13.91, Test_accy 41.19
2022-10-08 04:26:38,068 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.309,  Train_accy 13.84
2022-10-08 04:26:42,074 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.321,  Train_accy 14.64
2022-10-08 04:26:53,508 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.315,  Train_accy 14.79
2022-10-08 04:26:58,134 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.319,  Train_accy 13.98
2022-10-08 04:27:03,064 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.313,  Train_accy 13.98, Test_accy 40.59
2022-10-08 04:27:03,065 [foster.py] => do not weight align student!
2022-10-08 04:27:03,996 [foster.py] => darknet eval: 
2022-10-08 04:27:03,996 [foster.py] => CNN top1 curve: 40.59
2022-10-08 04:27:03,996 [foster.py] => CNN top5 curve: 83.56
2022-10-08 04:27:03,996 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 04:27:16,414 [foster.py] => Exemplar size: 440
2022-10-08 04:27:16,415 [trainer.py] => CNN: {'total': 50.3, 'old': 54.2, 'new': 36.61, 'base': 79.66, 'compound': 34.45}
2022-10-08 04:27:16,415 [trainer.py] => CNN top1 curve: [91.53, 68.62, 55.47, 50.3]
2022-10-08 04:27:16,415 [trainer.py] => CNN base curve: [91.53, 83.62, 80.79, 79.66]
2022-10-08 04:27:16,415 [trainer.py] => CNN old curve: [91.53, 83.62, 62.07, 54.2]
2022-10-08 04:27:16,415 [trainer.py] => CNN new curve: [0, 45.13, 36.89, 36.61]
2022-10-08 04:27:16,415 [trainer.py] => CNN compound curve: [0, 45.13, 34.72, 34.45]
2022-10-08 04:27:16,415 [trainer.py] => NME: {'total': 60.0, 'old': 62.09, 'new': 52.68, 'base': 72.88, 'compound': 53.05}
2022-10-08 04:27:16,415 [trainer.py] => NME top1 curve: [90.96, 75.86, 67.18, 60.0]
2022-10-08 04:27:16,415 [trainer.py] => NME base curve: [90.96, 77.97, 71.75, 72.88]
2022-10-08 04:27:16,415 [trainer.py] => NME old curve: [90.96, 77.97, 67.24, 62.09]
2022-10-08 04:27:16,415 [trainer.py] => NME new curve: [0, 72.57, 66.99, 52.68]
2022-10-08 04:27:16,415 [trainer.py] => NME compound curve: [0, 72.57, 63.43, 53.05]
2022-10-08 04:27:16,416 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 04:27:16,416 [trainer.py] => prefix: cil
2022-10-08 04:27:16,416 [trainer.py] => dataset: CFEE
2022-10-08 04:27:16,416 [trainer.py] => memory_size: 2000
2022-10-08 04:27:16,416 [trainer.py] => memory_per_class: 20
2022-10-08 04:27:16,416 [trainer.py] => fixed_memory: True
2022-10-08 04:27:16,416 [trainer.py] => shuffle: True
2022-10-08 04:27:16,416 [trainer.py] => init_cls: 7
2022-10-08 04:27:16,417 [trainer.py] => increment: 5
2022-10-08 04:27:16,417 [trainer.py] => model_name: foster
2022-10-08 04:27:16,417 [trainer.py] => convnet_type: resnet18
2022-10-08 04:27:16,417 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 04:27:16,417 [trainer.py] => seed: 1993
2022-10-08 04:27:16,417 [trainer.py] => beta1: 0.96
2022-10-08 04:27:16,417 [trainer.py] => beta2: 0.97
2022-10-08 04:27:16,417 [trainer.py] => oofc: ft
2022-10-08 04:27:16,417 [trainer.py] => is_teacher_wa: False
2022-10-08 04:27:16,417 [trainer.py] => is_student_wa: False
2022-10-08 04:27:16,417 [trainer.py] => lambda_okd: 1
2022-10-08 04:27:16,417 [trainer.py] => wa_value: 1
2022-10-08 04:27:16,417 [trainer.py] => init_epochs: 40
2022-10-08 04:27:16,417 [trainer.py] => init_lr: 0.01
2022-10-08 04:27:16,417 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 04:27:16,417 [trainer.py] => boosting_epochs: 34
2022-10-08 04:27:16,417 [trainer.py] => compression_epochs: 26
2022-10-08 04:27:16,417 [trainer.py] => lr: 0.001
2022-10-08 04:27:16,417 [trainer.py] => batch_size: 32
2022-10-08 04:27:16,417 [trainer.py] => weight_decay: 0.0005
2022-10-08 04:27:16,417 [trainer.py] => num_workers: 8
2022-10-08 04:27:16,417 [trainer.py] => T: 2
2022-10-08 04:27:16,417 [trainer.py] => nb_runs: 3
2022-10-08 04:27:16,417 [trainer.py] => fold: 10
2022-10-08 04:27:16,417 [data.py] => ========== Fold:1 ==========
2022-10-08 04:27:16,423 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 13, 17, 15, 9, 11, 20, 18, 12, 14, 7, 10, 19, 21, 16, 8]
2022-10-08 04:27:16,651 [foster.py] => Learning on 0-7
2022-10-08 04:27:16,651 [foster.py] => All params: 11183694
2022-10-08 04:27:16,651 [foster.py] => Trainable params: 11183694
2022-10-08 04:27:19,130 [foster.py] => Task 0, Epoch 1/40 => Loss 1.358, Train_accy 49.49
2022-10-08 04:27:22,258 [foster.py] => Task 0, Epoch 2/40 => Loss 0.552, Train_accy 80.53, Test_accy 85.14
2022-10-08 04:27:25,359 [foster.py] => Task 0, Epoch 3/40 => Loss 0.391, Train_accy 86.15, Test_accy 89.86
2022-10-08 04:27:28,548 [foster.py] => Task 0, Epoch 4/40 => Loss 0.285, Train_accy 90.47, Test_accy 89.86
2022-10-08 04:27:31,738 [foster.py] => Task 0, Epoch 5/40 => Loss 0.249, Train_accy 91.78, Test_accy 83.78
2022-10-08 04:27:34,280 [foster.py] => Task 0, Epoch 6/40 => Loss 0.211, Train_accy 93.42
2022-10-08 04:27:37,499 [foster.py] => Task 0, Epoch 7/40 => Loss 0.159, Train_accy 95.00, Test_accy 87.84
2022-10-08 04:27:40,695 [foster.py] => Task 0, Epoch 8/40 => Loss 0.142, Train_accy 95.48, Test_accy 89.19
2022-10-08 04:27:43,751 [foster.py] => Task 0, Epoch 9/40 => Loss 0.115, Train_accy 95.89, Test_accy 91.89
2022-10-08 04:27:46,913 [foster.py] => Task 0, Epoch 10/40 => Loss 0.092, Train_accy 97.40, Test_accy 89.19
2022-10-08 04:27:49,465 [foster.py] => Task 0, Epoch 11/40 => Loss 0.087, Train_accy 97.33
2022-10-08 04:27:52,631 [foster.py] => Task 0, Epoch 12/40 => Loss 0.063, Train_accy 98.49, Test_accy 88.51
2022-10-08 04:27:58,774 [foster.py] => Task 0, Epoch 13/40 => Loss 0.050, Train_accy 98.97, Test_accy 87.84
2022-10-08 04:28:02,192 [foster.py] => Task 0, Epoch 14/40 => Loss 0.054, Train_accy 98.29, Test_accy 87.84
2022-10-08 04:28:05,291 [foster.py] => Task 0, Epoch 15/40 => Loss 0.049, Train_accy 98.77, Test_accy 88.51
2022-10-08 04:28:07,884 [foster.py] => Task 0, Epoch 16/40 => Loss 0.053, Train_accy 98.22
2022-10-08 04:28:11,010 [foster.py] => Task 0, Epoch 17/40 => Loss 0.045, Train_accy 98.83, Test_accy 87.84
2022-10-08 04:28:14,131 [foster.py] => Task 0, Epoch 18/40 => Loss 0.032, Train_accy 99.18, Test_accy 87.16
2022-10-08 04:28:17,441 [foster.py] => Task 0, Epoch 19/40 => Loss 0.031, Train_accy 99.31, Test_accy 87.16
2022-10-08 04:28:22,143 [foster.py] => Task 0, Epoch 20/40 => Loss 0.025, Train_accy 99.52, Test_accy 87.84
2022-10-08 04:28:24,762 [foster.py] => Task 0, Epoch 21/40 => Loss 0.029, Train_accy 99.18
2022-10-08 04:28:28,080 [foster.py] => Task 0, Epoch 22/40 => Loss 0.031, Train_accy 99.25, Test_accy 87.16
2022-10-08 04:28:31,147 [foster.py] => Task 0, Epoch 23/40 => Loss 0.023, Train_accy 99.59, Test_accy 87.84
2022-10-08 04:28:34,386 [foster.py] => Task 0, Epoch 24/40 => Loss 0.018, Train_accy 99.86, Test_accy 88.51
2022-10-08 04:28:37,630 [foster.py] => Task 0, Epoch 25/40 => Loss 0.020, Train_accy 99.59, Test_accy 88.51
2022-10-08 04:28:41,725 [foster.py] => Task 0, Epoch 26/40 => Loss 0.017, Train_accy 99.73
2022-10-08 04:28:45,445 [foster.py] => Task 0, Epoch 27/40 => Loss 0.015, Train_accy 99.79, Test_accy 88.51
2022-10-08 04:28:48,634 [foster.py] => Task 0, Epoch 28/40 => Loss 0.017, Train_accy 99.73, Test_accy 88.51
2022-10-08 04:28:51,816 [foster.py] => Task 0, Epoch 29/40 => Loss 0.013, Train_accy 99.86, Test_accy 88.51
2022-10-08 04:28:55,003 [foster.py] => Task 0, Epoch 30/40 => Loss 0.016, Train_accy 99.66, Test_accy 88.51
2022-10-08 04:28:57,659 [foster.py] => Task 0, Epoch 31/40 => Loss 0.016, Train_accy 99.79
2022-10-08 04:29:00,882 [foster.py] => Task 0, Epoch 32/40 => Loss 0.013, Train_accy 99.86, Test_accy 88.51
2022-10-08 04:29:04,121 [foster.py] => Task 0, Epoch 33/40 => Loss 0.013, Train_accy 99.79, Test_accy 88.51
2022-10-08 04:29:07,427 [foster.py] => Task 0, Epoch 34/40 => Loss 0.016, Train_accy 99.59, Test_accy 88.51
2022-10-08 04:29:12,131 [foster.py] => Task 0, Epoch 35/40 => Loss 0.012, Train_accy 99.93, Test_accy 88.51
2022-10-08 04:29:15,427 [foster.py] => Task 0, Epoch 36/40 => Loss 0.014, Train_accy 99.86
2022-10-08 04:29:19,255 [foster.py] => Task 0, Epoch 37/40 => Loss 0.012, Train_accy 99.86, Test_accy 88.51
2022-10-08 04:29:22,495 [foster.py] => Task 0, Epoch 38/40 => Loss 0.015, Train_accy 99.66, Test_accy 89.19
2022-10-08 04:29:25,749 [foster.py] => Task 0, Epoch 39/40 => Loss 0.013, Train_accy 99.79, Test_accy 89.19
2022-10-08 04:29:29,582 [foster.py] => Task 0, Epoch 40/40 => Loss 0.012, Train_accy 99.79, Test_accy 88.51
2022-10-08 04:29:29,583 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 04:29:36,598 [foster.py] => Exemplar size: 140
2022-10-08 04:29:36,598 [trainer.py] => CNN: {'total': 88.51, 'old': 88.51, 'new': 0, 'base': 88.51, 'compound': 0}
2022-10-08 04:29:36,598 [trainer.py] => CNN top1 curve: [88.51]
2022-10-08 04:29:36,598 [trainer.py] => CNN base curve: [88.51]
2022-10-08 04:29:36,598 [trainer.py] => CNN old curve: [88.51]
2022-10-08 04:29:36,598 [trainer.py] => CNN new curve: [0]
2022-10-08 04:29:36,598 [trainer.py] => CNN compound curve: [0]
2022-10-08 04:29:36,599 [trainer.py] => NME: {'total': 88.51, 'old': 88.51, 'new': 0, 'base': 88.51, 'compound': 0}
2022-10-08 04:29:36,599 [trainer.py] => NME top1 curve: [88.51]
2022-10-08 04:29:36,599 [trainer.py] => NME base curve: [88.51]
2022-10-08 04:29:36,599 [trainer.py] => NME old curve: [88.51]
2022-10-08 04:29:36,599 [trainer.py] => NME new curve: [0]
2022-10-08 04:29:36,599 [trainer.py] => NME compound curve: [0]
2022-10-08 04:29:36,832 [foster.py] => Learning on 7-12
2022-10-08 04:29:36,833 [foster.py] => All params: 22375071
2022-10-08 04:29:36,833 [foster.py] => Trainable params: 11194968
2022-10-08 04:29:36,842 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 04:29:40,312 [foster.py] => Task 1, Epoch 1/34 => Loss 4.756, Loss_clf 2.157, Loss_fe 1.959, Loss_kd 0.374, Train_accy 37.29, Test_accy 57.79
2022-10-08 04:29:42,846 [foster.py] => Task 1, Epoch 2/34 => Loss 2.489, Loss_clf 0.708, Loss_fe 1.145, Loss_kd 0.371, Train_accy 63.65
2022-10-08 04:29:45,426 [foster.py] => Task 1, Epoch 3/34 => Loss 2.140, Loss_clf 0.575, Loss_fe 0.942, Loss_kd 0.363, Train_accy 48.89
2022-10-08 04:29:48,260 [foster.py] => Task 1, Epoch 4/34 => Loss 2.010, Loss_clf 0.554, Loss_fe 0.839, Loss_kd 0.360, Train_accy 49.66
2022-10-08 04:29:51,746 [foster.py] => Task 1, Epoch 5/34 => Loss 1.893, Loss_clf 0.511, Loss_fe 0.760, Loss_kd 0.363, Train_accy 48.89
2022-10-08 04:29:56,051 [foster.py] => Task 1, Epoch 6/34 => Loss 1.810, Loss_clf 0.486, Loss_fe 0.706, Loss_kd 0.360, Train_accy 47.61, Test_accy 62.36
2022-10-08 04:29:58,948 [foster.py] => Task 1, Epoch 7/34 => Loss 1.771, Loss_clf 0.479, Loss_fe 0.668, Loss_kd 0.364, Train_accy 48.72
2022-10-08 04:30:01,758 [foster.py] => Task 1, Epoch 8/34 => Loss 1.704, Loss_clf 0.455, Loss_fe 0.633, Loss_kd 0.359, Train_accy 47.78
2022-10-08 04:30:04,659 [foster.py] => Task 1, Epoch 9/34 => Loss 1.659, Loss_clf 0.436, Loss_fe 0.601, Loss_kd 0.363, Train_accy 46.84
2022-10-08 04:30:07,547 [foster.py] => Task 1, Epoch 10/34 => Loss 1.650, Loss_clf 0.437, Loss_fe 0.589, Loss_kd 0.364, Train_accy 50.17
2022-10-08 04:30:11,249 [foster.py] => Task 1, Epoch 11/34 => Loss 1.590, Loss_clf 0.414, Loss_fe 0.557, Loss_kd 0.361, Train_accy 49.57, Test_accy 62.74
2022-10-08 04:30:14,084 [foster.py] => Task 1, Epoch 12/34 => Loss 1.535, Loss_clf 0.399, Loss_fe 0.520, Loss_kd 0.359, Train_accy 50.60
2022-10-08 04:30:16,982 [foster.py] => Task 1, Epoch 13/34 => Loss 1.553, Loss_clf 0.411, Loss_fe 0.520, Loss_kd 0.362, Train_accy 50.34
2022-10-08 04:30:20,126 [foster.py] => Task 1, Epoch 14/34 => Loss 1.516, Loss_clf 0.388, Loss_fe 0.506, Loss_kd 0.363, Train_accy 48.89
2022-10-08 04:30:23,224 [foster.py] => Task 1, Epoch 15/34 => Loss 1.483, Loss_clf 0.379, Loss_fe 0.495, Loss_kd 0.355, Train_accy 48.46
2022-10-08 04:30:27,348 [foster.py] => Task 1, Epoch 16/34 => Loss 1.491, Loss_clf 0.379, Loss_fe 0.486, Loss_kd 0.365, Train_accy 50.51, Test_accy 62.74
2022-10-08 04:30:30,590 [foster.py] => Task 1, Epoch 17/34 => Loss 1.457, Loss_clf 0.361, Loss_fe 0.475, Loss_kd 0.362, Train_accy 51.62
2022-10-08 04:30:33,823 [foster.py] => Task 1, Epoch 18/34 => Loss 1.446, Loss_clf 0.363, Loss_fe 0.468, Loss_kd 0.358, Train_accy 49.66
2022-10-08 04:30:36,961 [foster.py] => Task 1, Epoch 19/34 => Loss 1.424, Loss_clf 0.347, Loss_fe 0.458, Loss_kd 0.361, Train_accy 48.04
2022-10-08 04:30:40,175 [foster.py] => Task 1, Epoch 20/34 => Loss 1.441, Loss_clf 0.360, Loss_fe 0.461, Loss_kd 0.362, Train_accy 50.00
2022-10-08 04:30:44,155 [foster.py] => Task 1, Epoch 21/34 => Loss 1.412, Loss_clf 0.345, Loss_fe 0.448, Loss_kd 0.361, Train_accy 52.39, Test_accy 63.50
2022-10-08 04:30:47,345 [foster.py] => Task 1, Epoch 22/34 => Loss 1.402, Loss_clf 0.336, Loss_fe 0.442, Loss_kd 0.364, Train_accy 51.54
2022-10-08 04:30:50,653 [foster.py] => Task 1, Epoch 23/34 => Loss 1.381, Loss_clf 0.337, Loss_fe 0.428, Loss_kd 0.359, Train_accy 50.26
2022-10-08 04:30:53,792 [foster.py] => Task 1, Epoch 24/34 => Loss 1.381, Loss_clf 0.330, Loss_fe 0.427, Loss_kd 0.364, Train_accy 50.68
2022-10-08 04:30:57,089 [foster.py] => Task 1, Epoch 25/34 => Loss 1.372, Loss_clf 0.330, Loss_fe 0.422, Loss_kd 0.361, Train_accy 52.30
2022-10-08 04:31:01,186 [foster.py] => Task 1, Epoch 26/34 => Loss 1.380, Loss_clf 0.333, Loss_fe 0.425, Loss_kd 0.363, Train_accy 51.37, Test_accy 65.40
2022-10-08 04:31:04,314 [foster.py] => Task 1, Epoch 27/34 => Loss 1.378, Loss_clf 0.339, Loss_fe 0.429, Loss_kd 0.356, Train_accy 50.77
2022-10-08 04:31:07,812 [foster.py] => Task 1, Epoch 28/34 => Loss 1.353, Loss_clf 0.321, Loss_fe 0.412, Loss_kd 0.361, Train_accy 51.96
2022-10-08 04:31:11,319 [foster.py] => Task 1, Epoch 29/34 => Loss 1.362, Loss_clf 0.322, Loss_fe 0.418, Loss_kd 0.363, Train_accy 52.47
2022-10-08 04:31:14,870 [foster.py] => Task 1, Epoch 30/34 => Loss 1.366, Loss_clf 0.325, Loss_fe 0.416, Loss_kd 0.365, Train_accy 52.22
2022-10-08 04:31:19,143 [foster.py] => Task 1, Epoch 31/34 => Loss 1.356, Loss_clf 0.325, Loss_fe 0.413, Loss_kd 0.361, Train_accy 50.68, Test_accy 65.02
2022-10-08 04:31:22,429 [foster.py] => Task 1, Epoch 32/34 => Loss 1.365, Loss_clf 0.323, Loss_fe 0.420, Loss_kd 0.363, Train_accy 51.45
2022-10-08 04:31:25,611 [foster.py] => Task 1, Epoch 33/34 => Loss 1.362, Loss_clf 0.320, Loss_fe 0.422, Loss_kd 0.362, Train_accy 52.99
2022-10-08 04:31:28,890 [foster.py] => Task 1, Epoch 34/34 => Loss 1.371, Loss_clf 0.329, Loss_fe 0.428, Loss_kd 0.358, Train_accy 50.77
2022-10-08 04:31:28,891 [foster.py] => do not weight align teacher!
2022-10-08 04:31:28,891 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 04:31:33,558 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.683,  Train_accy 11.52, Test_accy 47.15
2022-10-08 04:31:37,208 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.540,  Train_accy 12.20
2022-10-08 04:31:40,919 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.467,  Train_accy 13.91
2022-10-08 04:31:44,758 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.439,  Train_accy 16.04
2022-10-08 04:31:48,567 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.429,  Train_accy 18.26
2022-10-08 04:31:54,442 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.397,  Train_accy 20.31, Test_accy 50.57
2022-10-08 04:31:58,979 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.375,  Train_accy 19.45
2022-10-08 04:32:03,480 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.383,  Train_accy 22.95
2022-10-08 04:32:07,929 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.365,  Train_accy 22.10
2022-10-08 04:32:12,320 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.352,  Train_accy 23.46
2022-10-08 04:32:17,494 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.342,  Train_accy 24.23, Test_accy 53.23
2022-10-08 04:32:21,567 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.350,  Train_accy 24.66
2022-10-08 04:32:25,525 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.320,  Train_accy 24.83
2022-10-08 04:32:29,639 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.330,  Train_accy 25.85
2022-10-08 04:32:33,750 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.326,  Train_accy 25.34
2022-10-08 04:32:38,549 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.325,  Train_accy 26.79, Test_accy 53.61
2022-10-08 04:32:42,559 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.321,  Train_accy 25.34
2022-10-08 04:32:46,586 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.319,  Train_accy 25.77
2022-10-08 04:32:50,727 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.322,  Train_accy 26.28
2022-10-08 04:32:54,782 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.318,  Train_accy 27.13
2022-10-08 04:32:59,485 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.311,  Train_accy 28.07, Test_accy 53.99
2022-10-08 04:33:03,564 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.303,  Train_accy 27.13
2022-10-08 04:33:07,674 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.314,  Train_accy 27.30
2022-10-08 04:33:11,699 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.326,  Train_accy 27.39
2022-10-08 04:33:15,763 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.320,  Train_accy 26.88
2022-10-08 04:33:20,528 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.317,  Train_accy 26.96, Test_accy 53.61
2022-10-08 04:33:20,528 [foster.py] => do not weight align student!
2022-10-08 04:33:21,304 [foster.py] => darknet eval: 
2022-10-08 04:33:21,304 [foster.py] => CNN top1 curve: 53.61
2022-10-08 04:33:21,304 [foster.py] => CNN top5 curve: 97.72
2022-10-08 04:33:21,304 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 04:33:29,717 [foster.py] => Exemplar size: 240
2022-10-08 04:33:29,717 [trainer.py] => CNN: {'total': 64.64, 'old': 86.49, 'new': 36.52, 'base': 86.49, 'compound': 36.52}
2022-10-08 04:33:29,717 [trainer.py] => CNN top1 curve: [88.51, 64.64]
2022-10-08 04:33:29,717 [trainer.py] => CNN base curve: [88.51, 86.49]
2022-10-08 04:33:29,717 [trainer.py] => CNN old curve: [88.51, 86.49]
2022-10-08 04:33:29,717 [trainer.py] => CNN new curve: [0, 36.52]
2022-10-08 04:33:29,717 [trainer.py] => CNN compound curve: [0, 36.52]
2022-10-08 04:33:29,717 [trainer.py] => NME: {'total': 67.68, 'old': 72.3, 'new': 61.74, 'base': 72.3, 'compound': 61.74}
2022-10-08 04:33:29,717 [trainer.py] => NME top1 curve: [88.51, 67.68]
2022-10-08 04:33:29,717 [trainer.py] => NME base curve: [88.51, 72.3]
2022-10-08 04:33:29,717 [trainer.py] => NME old curve: [88.51, 72.3]
2022-10-08 04:33:29,717 [trainer.py] => NME new curve: [0, 61.74]
2022-10-08 04:33:29,717 [trainer.py] => NME compound curve: [0, 61.74]
2022-10-08 04:33:29,963 [foster.py] => Learning on 12-17
2022-10-08 04:33:29,963 [foster.py] => All params: 22385326
2022-10-08 04:33:29,964 [foster.py] => Trainable params: 11202658
2022-10-08 04:33:29,973 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 04:33:33,917 [foster.py] => Task 2, Epoch 1/34 => Loss 5.760, Loss_clf 2.008, Loss_fe 2.329, Loss_kd 1.005, Train_accy 37.53, Test_accy 45.74
2022-10-08 04:33:37,164 [foster.py] => Task 2, Epoch 2/34 => Loss 3.873, Loss_clf 0.982, Loss_fe 1.538, Loss_kd 0.955, Train_accy 39.83
2022-10-08 04:33:40,305 [foster.py] => Task 2, Epoch 3/34 => Loss 3.527, Loss_clf 0.854, Loss_fe 1.314, Loss_kd 0.959, Train_accy 40.38
2022-10-08 04:33:43,593 [foster.py] => Task 2, Epoch 4/34 => Loss 3.385, Loss_clf 0.819, Loss_fe 1.203, Loss_kd 0.961, Train_accy 40.14
2022-10-08 04:33:46,850 [foster.py] => Task 2, Epoch 5/34 => Loss 3.215, Loss_clf 0.764, Loss_fe 1.098, Loss_kd 0.955, Train_accy 40.46
2022-10-08 04:33:58,745 [foster.py] => Task 2, Epoch 6/34 => Loss 3.175, Loss_clf 0.754, Loss_fe 1.055, Loss_kd 0.964, Train_accy 40.38, Test_accy 48.06
2022-10-08 04:34:01,802 [foster.py] => Task 2, Epoch 7/34 => Loss 3.103, Loss_clf 0.746, Loss_fe 0.994, Loss_kd 0.963, Train_accy 42.91
2022-10-08 04:34:04,924 [foster.py] => Task 2, Epoch 8/34 => Loss 3.023, Loss_clf 0.712, Loss_fe 0.942, Loss_kd 0.966, Train_accy 42.83
2022-10-08 04:34:08,068 [foster.py] => Task 2, Epoch 9/34 => Loss 2.983, Loss_clf 0.705, Loss_fe 0.917, Loss_kd 0.960, Train_accy 40.22
2022-10-08 04:34:11,193 [foster.py] => Task 2, Epoch 10/34 => Loss 2.920, Loss_clf 0.685, Loss_fe 0.874, Loss_kd 0.961, Train_accy 44.97
2022-10-08 04:34:15,607 [foster.py] => Task 2, Epoch 11/34 => Loss 2.896, Loss_clf 0.671, Loss_fe 0.857, Loss_kd 0.965, Train_accy 43.63, Test_accy 48.58
2022-10-08 04:34:19,032 [foster.py] => Task 2, Epoch 12/34 => Loss 2.859, Loss_clf 0.664, Loss_fe 0.833, Loss_kd 0.961, Train_accy 39.98
2022-10-08 04:34:22,363 [foster.py] => Task 2, Epoch 13/34 => Loss 2.811, Loss_clf 0.649, Loss_fe 0.800, Loss_kd 0.961, Train_accy 42.60
2022-10-08 04:34:25,784 [foster.py] => Task 2, Epoch 14/34 => Loss 2.760, Loss_clf 0.617, Loss_fe 0.772, Loss_kd 0.967, Train_accy 45.53
2022-10-08 04:34:29,281 [foster.py] => Task 2, Epoch 15/34 => Loss 2.722, Loss_clf 0.607, Loss_fe 0.747, Loss_kd 0.966, Train_accy 45.05
2022-10-08 04:34:34,069 [foster.py] => Task 2, Epoch 16/34 => Loss 2.740, Loss_clf 0.619, Loss_fe 0.750, Loss_kd 0.968, Train_accy 45.13, Test_accy 48.84
2022-10-08 04:34:37,648 [foster.py] => Task 2, Epoch 17/34 => Loss 2.671, Loss_clf 0.585, Loss_fe 0.714, Loss_kd 0.968, Train_accy 45.92
2022-10-08 04:34:41,251 [foster.py] => Task 2, Epoch 18/34 => Loss 2.665, Loss_clf 0.589, Loss_fe 0.708, Loss_kd 0.966, Train_accy 45.84
2022-10-08 04:34:46,042 [foster.py] => Task 2, Epoch 19/34 => Loss 2.647, Loss_clf 0.590, Loss_fe 0.693, Loss_kd 0.963, Train_accy 46.32
2022-10-08 04:34:50,731 [foster.py] => Task 2, Epoch 20/34 => Loss 2.604, Loss_clf 0.562, Loss_fe 0.679, Loss_kd 0.962, Train_accy 46.95
2022-10-08 04:34:56,511 [foster.py] => Task 2, Epoch 21/34 => Loss 2.603, Loss_clf 0.554, Loss_fe 0.680, Loss_kd 0.967, Train_accy 46.87, Test_accy 49.61
2022-10-08 04:35:00,211 [foster.py] => Task 2, Epoch 22/34 => Loss 2.603, Loss_clf 0.560, Loss_fe 0.666, Loss_kd 0.972, Train_accy 48.77
2022-10-08 04:35:03,925 [foster.py] => Task 2, Epoch 23/34 => Loss 2.589, Loss_clf 0.558, Loss_fe 0.656, Loss_kd 0.971, Train_accy 49.01
2022-10-08 04:35:07,686 [foster.py] => Task 2, Epoch 24/34 => Loss 2.576, Loss_clf 0.552, Loss_fe 0.654, Loss_kd 0.967, Train_accy 47.27
2022-10-08 04:35:11,467 [foster.py] => Task 2, Epoch 25/34 => Loss 2.560, Loss_clf 0.543, Loss_fe 0.649, Loss_kd 0.966, Train_accy 47.51
2022-10-08 04:35:16,141 [foster.py] => Task 2, Epoch 26/34 => Loss 2.545, Loss_clf 0.540, Loss_fe 0.638, Loss_kd 0.965, Train_accy 49.09, Test_accy 50.39
2022-10-08 04:35:19,805 [foster.py] => Task 2, Epoch 27/34 => Loss 2.571, Loss_clf 0.549, Loss_fe 0.650, Loss_kd 0.968, Train_accy 49.80
2022-10-08 04:35:23,502 [foster.py] => Task 2, Epoch 28/34 => Loss 2.546, Loss_clf 0.535, Loss_fe 0.647, Loss_kd 0.963, Train_accy 47.43
2022-10-08 04:35:27,260 [foster.py] => Task 2, Epoch 29/34 => Loss 2.572, Loss_clf 0.551, Loss_fe 0.656, Loss_kd 0.963, Train_accy 49.49
2022-10-08 04:35:30,890 [foster.py] => Task 2, Epoch 30/34 => Loss 2.539, Loss_clf 0.536, Loss_fe 0.634, Loss_kd 0.967, Train_accy 48.06
2022-10-08 04:35:35,553 [foster.py] => Task 2, Epoch 31/34 => Loss 2.532, Loss_clf 0.529, Loss_fe 0.637, Loss_kd 0.964, Train_accy 47.90, Test_accy 50.13
2022-10-08 04:35:39,319 [foster.py] => Task 2, Epoch 32/34 => Loss 2.544, Loss_clf 0.537, Loss_fe 0.642, Loss_kd 0.964, Train_accy 48.22
2022-10-08 04:35:43,050 [foster.py] => Task 2, Epoch 33/34 => Loss 2.543, Loss_clf 0.540, Loss_fe 0.640, Loss_kd 0.962, Train_accy 47.51
2022-10-08 04:35:46,696 [foster.py] => Task 2, Epoch 34/34 => Loss 2.543, Loss_clf 0.536, Loss_fe 0.635, Loss_kd 0.968, Train_accy 49.01
2022-10-08 04:35:46,696 [foster.py] => do not weight align teacher!
2022-10-08 04:35:46,697 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 04:35:52,097 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.102,  Train_accy 13.06, Test_accy 36.43
2022-10-08 04:35:56,534 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 2.024,  Train_accy 12.83
2022-10-08 04:36:00,949 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.994,  Train_accy 13.22
2022-10-08 04:36:05,641 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.954,  Train_accy 12.83
2022-10-08 04:36:11,126 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.943,  Train_accy 13.38
2022-10-08 04:36:17,409 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.927,  Train_accy 13.30, Test_accy 36.69
2022-10-08 04:36:22,833 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.918,  Train_accy 13.78
2022-10-08 04:36:28,190 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.913,  Train_accy 13.78
2022-10-08 04:36:32,960 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.907,  Train_accy 13.94
2022-10-08 04:36:37,678 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.900,  Train_accy 14.81
2022-10-08 04:36:43,237 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.898,  Train_accy 15.20, Test_accy 37.47
2022-10-08 04:36:47,944 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.888,  Train_accy 14.96
2022-10-08 04:36:52,693 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.887,  Train_accy 15.12
2022-10-08 04:36:57,429 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.893,  Train_accy 14.96
2022-10-08 04:37:02,162 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.886,  Train_accy 15.68
2022-10-08 04:37:07,780 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.875,  Train_accy 15.84, Test_accy 38.24
2022-10-08 04:37:12,478 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.881,  Train_accy 16.39
2022-10-08 04:37:17,204 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.879,  Train_accy 15.76
2022-10-08 04:37:21,896 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.881,  Train_accy 15.76
2022-10-08 04:37:26,690 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.872,  Train_accy 16.63
2022-10-08 04:37:32,243 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.868,  Train_accy 17.18, Test_accy 38.76
2022-10-08 04:37:36,937 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.874,  Train_accy 16.94
2022-10-08 04:37:41,596 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.868,  Train_accy 15.91
2022-10-08 04:37:46,303 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.869,  Train_accy 16.31
2022-10-08 04:37:51,056 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.878,  Train_accy 16.23
2022-10-08 04:37:56,587 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.870,  Train_accy 15.99, Test_accy 39.02
2022-10-08 04:37:56,587 [foster.py] => do not weight align student!
2022-10-08 04:37:57,423 [foster.py] => darknet eval: 
2022-10-08 04:37:57,423 [foster.py] => CNN top1 curve: 39.02
2022-10-08 04:37:57,423 [foster.py] => CNN top5 curve: 91.99
2022-10-08 04:37:57,423 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 04:38:07,634 [foster.py] => Exemplar size: 340
2022-10-08 04:38:07,634 [trainer.py] => CNN: {'total': 50.13, 'old': 58.94, 'new': 31.45, 'base': 82.43, 'compound': 30.13}
2022-10-08 04:38:07,634 [trainer.py] => CNN top1 curve: [88.51, 64.64, 50.13]
2022-10-08 04:38:07,634 [trainer.py] => CNN base curve: [88.51, 86.49, 82.43]
2022-10-08 04:38:07,634 [trainer.py] => CNN old curve: [88.51, 86.49, 58.94]
2022-10-08 04:38:07,634 [trainer.py] => CNN new curve: [0, 36.52, 31.45]
2022-10-08 04:38:07,634 [trainer.py] => CNN compound curve: [0, 36.52, 30.13]
2022-10-08 04:38:07,634 [trainer.py] => NME: {'total': 57.88, 'old': 58.56, 'new': 56.45, 'base': 67.57, 'compound': 51.88}
2022-10-08 04:38:07,634 [trainer.py] => NME top1 curve: [88.51, 67.68, 57.88]
2022-10-08 04:38:07,634 [trainer.py] => NME base curve: [88.51, 72.3, 67.57]
2022-10-08 04:38:07,634 [trainer.py] => NME old curve: [88.51, 72.3, 58.56]
2022-10-08 04:38:07,634 [trainer.py] => NME new curve: [0, 61.74, 56.45]
2022-10-08 04:38:07,634 [trainer.py] => NME compound curve: [0, 61.74, 51.88]
2022-10-08 04:38:07,902 [foster.py] => Learning on 17-22
2022-10-08 04:38:07,902 [foster.py] => All params: 22395581
2022-10-08 04:38:07,902 [foster.py] => Trainable params: 11210348
2022-10-08 04:38:07,911 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 04:38:12,183 [foster.py] => Task 3, Epoch 1/34 => Loss 6.513, Loss_clf 2.042, Loss_fe 2.513, Loss_kd 1.513, Train_accy 32.26, Test_accy 37.43
2022-10-08 04:38:15,874 [foster.py] => Task 3, Epoch 2/34 => Loss 4.955, Loss_clf 1.221, Loss_fe 1.809, Loss_kd 1.488, Train_accy 31.89
2022-10-08 04:38:19,225 [foster.py] => Task 3, Epoch 3/34 => Loss 4.697, Loss_clf 1.147, Loss_fe 1.622, Loss_kd 1.490, Train_accy 33.43
2022-10-08 04:38:22,869 [foster.py] => Task 3, Epoch 4/34 => Loss 4.500, Loss_clf 1.093, Loss_fe 1.489, Loss_kd 1.482, Train_accy 34.16
2022-10-08 04:38:26,599 [foster.py] => Task 3, Epoch 5/34 => Loss 4.345, Loss_clf 1.039, Loss_fe 1.385, Loss_kd 1.484, Train_accy 32.92
2022-10-08 04:38:31,481 [foster.py] => Task 3, Epoch 6/34 => Loss 4.262, Loss_clf 1.028, Loss_fe 1.312, Loss_kd 1.486, Train_accy 34.89, Test_accy 38.81
2022-10-08 04:38:35,291 [foster.py] => Task 3, Epoch 7/34 => Loss 4.150, Loss_clf 0.979, Loss_fe 1.246, Loss_kd 1.487, Train_accy 35.19
2022-10-08 04:38:39,207 [foster.py] => Task 3, Epoch 8/34 => Loss 4.117, Loss_clf 0.975, Loss_fe 1.216, Loss_kd 1.488, Train_accy 36.72
2022-10-08 04:38:43,020 [foster.py] => Task 3, Epoch 9/34 => Loss 4.063, Loss_clf 0.960, Loss_fe 1.179, Loss_kd 1.486, Train_accy 36.94
2022-10-08 04:38:47,042 [foster.py] => Task 3, Epoch 10/34 => Loss 3.963, Loss_clf 0.929, Loss_fe 1.117, Loss_kd 1.481, Train_accy 36.50
2022-10-08 04:38:54,098 [foster.py] => Task 3, Epoch 11/34 => Loss 3.901, Loss_clf 0.903, Loss_fe 1.084, Loss_kd 1.480, Train_accy 36.80, Test_accy 40.40
2022-10-08 04:38:59,732 [foster.py] => Task 3, Epoch 12/34 => Loss 3.920, Loss_clf 0.920, Loss_fe 1.072, Loss_kd 1.490, Train_accy 38.04
2022-10-08 04:39:05,329 [foster.py] => Task 3, Epoch 13/34 => Loss 3.837, Loss_clf 0.884, Loss_fe 1.024, Loss_kd 1.491, Train_accy 37.97
2022-10-08 04:39:10,125 [foster.py] => Task 3, Epoch 14/34 => Loss 3.837, Loss_clf 0.894, Loss_fe 1.019, Loss_kd 1.487, Train_accy 39.28
2022-10-08 04:39:14,822 [foster.py] => Task 3, Epoch 15/34 => Loss 3.777, Loss_clf 0.860, Loss_fe 0.991, Loss_kd 1.488, Train_accy 38.70
2022-10-08 04:39:20,270 [foster.py] => Task 3, Epoch 16/34 => Loss 3.747, Loss_clf 0.839, Loss_fe 0.975, Loss_kd 1.494, Train_accy 39.58, Test_accy 41.98
2022-10-08 04:39:24,472 [foster.py] => Task 3, Epoch 17/34 => Loss 3.684, Loss_clf 0.821, Loss_fe 0.938, Loss_kd 1.487, Train_accy 38.55
2022-10-08 04:39:28,641 [foster.py] => Task 3, Epoch 18/34 => Loss 3.710, Loss_clf 0.835, Loss_fe 0.948, Loss_kd 1.489, Train_accy 39.36
2022-10-08 04:39:32,856 [foster.py] => Task 3, Epoch 19/34 => Loss 3.664, Loss_clf 0.811, Loss_fe 0.923, Loss_kd 1.491, Train_accy 40.53
2022-10-08 04:39:36,991 [foster.py] => Task 3, Epoch 20/34 => Loss 3.632, Loss_clf 0.803, Loss_fe 0.905, Loss_kd 1.487, Train_accy 40.45
2022-10-08 04:39:42,269 [foster.py] => Task 3, Epoch 21/34 => Loss 3.651, Loss_clf 0.809, Loss_fe 0.920, Loss_kd 1.485, Train_accy 42.87, Test_accy 41.98
2022-10-08 04:39:46,462 [foster.py] => Task 3, Epoch 22/34 => Loss 3.625, Loss_clf 0.803, Loss_fe 0.901, Loss_kd 1.485, Train_accy 39.36
2022-10-08 04:39:50,620 [foster.py] => Task 3, Epoch 23/34 => Loss 3.600, Loss_clf 0.789, Loss_fe 0.881, Loss_kd 1.492, Train_accy 41.26
2022-10-08 04:39:54,854 [foster.py] => Task 3, Epoch 24/34 => Loss 3.578, Loss_clf 0.776, Loss_fe 0.874, Loss_kd 1.490, Train_accy 42.14
2022-10-08 04:39:59,161 [foster.py] => Task 3, Epoch 25/34 => Loss 3.609, Loss_clf 0.794, Loss_fe 0.883, Loss_kd 1.493, Train_accy 41.99
2022-10-08 04:40:04,679 [foster.py] => Task 3, Epoch 26/34 => Loss 3.568, Loss_clf 0.774, Loss_fe 0.860, Loss_kd 1.495, Train_accy 41.55, Test_accy 42.57
2022-10-08 04:40:08,993 [foster.py] => Task 3, Epoch 27/34 => Loss 3.577, Loss_clf 0.784, Loss_fe 0.866, Loss_kd 1.489, Train_accy 41.55
2022-10-08 04:40:13,183 [foster.py] => Task 3, Epoch 28/34 => Loss 3.549, Loss_clf 0.767, Loss_fe 0.860, Loss_kd 1.485, Train_accy 42.87
2022-10-08 04:40:17,471 [foster.py] => Task 3, Epoch 29/34 => Loss 3.517, Loss_clf 0.752, Loss_fe 0.844, Loss_kd 1.485, Train_accy 41.99
2022-10-08 04:40:21,663 [foster.py] => Task 3, Epoch 30/34 => Loss 3.550, Loss_clf 0.763, Loss_fe 0.853, Loss_kd 1.495, Train_accy 42.21
2022-10-08 04:40:27,158 [foster.py] => Task 3, Epoch 31/34 => Loss 3.565, Loss_clf 0.770, Loss_fe 0.866, Loss_kd 1.491, Train_accy 41.70, Test_accy 41.98
2022-10-08 04:40:31,351 [foster.py] => Task 3, Epoch 32/34 => Loss 3.523, Loss_clf 0.757, Loss_fe 0.838, Loss_kd 1.490, Train_accy 42.50
2022-10-08 04:40:35,554 [foster.py] => Task 3, Epoch 33/34 => Loss 3.538, Loss_clf 0.767, Loss_fe 0.852, Loss_kd 1.483, Train_accy 42.50
2022-10-08 04:40:39,721 [foster.py] => Task 3, Epoch 34/34 => Loss 3.542, Loss_clf 0.760, Loss_fe 0.846, Loss_kd 1.496, Train_accy 43.89
2022-10-08 04:40:39,722 [foster.py] => do not weight align teacher!
2022-10-08 04:40:39,722 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 04:40:45,980 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.448,  Train_accy 12.44, Test_accy 31.49
2022-10-08 04:40:51,073 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.383,  Train_accy 13.17
2022-10-08 04:40:56,146 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.364,  Train_accy 13.17
2022-10-08 04:41:01,271 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.354,  Train_accy 13.68
2022-10-08 04:41:06,323 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.348,  Train_accy 13.83
2022-10-08 04:41:12,347 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.332,  Train_accy 13.90, Test_accy 33.07
2022-10-08 04:41:17,356 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.324,  Train_accy 13.31
2022-10-08 04:41:22,351 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.322,  Train_accy 14.19
2022-10-08 04:41:27,435 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.308,  Train_accy 14.26
2022-10-08 04:41:32,479 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.311,  Train_accy 15.00
2022-10-08 04:41:38,565 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.312,  Train_accy 14.63, Test_accy 33.47
2022-10-08 04:41:43,785 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.310,  Train_accy 14.78
2022-10-08 04:41:48,895 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.303,  Train_accy 14.34
2022-10-08 04:41:53,998 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.302,  Train_accy 14.70
2022-10-08 04:41:59,107 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.300,  Train_accy 14.19
2022-10-08 04:42:05,054 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.298,  Train_accy 14.26, Test_accy 33.47
2022-10-08 04:42:09,854 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.296,  Train_accy 15.07
2022-10-08 04:42:14,536 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.295,  Train_accy 14.56
2022-10-08 04:42:19,219 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.284,  Train_accy 14.70
2022-10-08 04:42:23,797 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.285,  Train_accy 14.19
2022-10-08 04:42:29,846 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.297,  Train_accy 14.34, Test_accy 33.86
2022-10-08 04:42:34,642 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.288,  Train_accy 14.26
2022-10-08 04:42:40,174 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.292,  Train_accy 14.34
2022-10-08 04:42:46,942 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.288,  Train_accy 14.78
2022-10-08 04:42:53,473 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.290,  Train_accy 15.07
2022-10-08 04:43:01,127 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.292,  Train_accy 14.34, Test_accy 34.06
2022-10-08 04:43:01,127 [foster.py] => do not weight align student!
2022-10-08 04:43:02,028 [foster.py] => darknet eval: 
2022-10-08 04:43:02,028 [foster.py] => CNN top1 curve: 34.06
2022-10-08 04:43:02,028 [foster.py] => CNN top5 curve: 79.21
2022-10-08 04:43:02,028 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 04:43:14,274 [foster.py] => Exemplar size: 440
2022-10-08 04:43:14,274 [trainer.py] => CNN: {'total': 42.18, 'old': 47.29, 'new': 25.42, 'base': 78.38, 'compound': 27.17}
2022-10-08 04:43:14,274 [trainer.py] => CNN top1 curve: [88.51, 64.64, 50.13, 42.18]
2022-10-08 04:43:14,274 [trainer.py] => CNN base curve: [88.51, 86.49, 82.43, 78.38]
2022-10-08 04:43:14,274 [trainer.py] => CNN old curve: [88.51, 86.49, 58.94, 47.29]
2022-10-08 04:43:14,274 [trainer.py] => CNN new curve: [0, 36.52, 31.45, 25.42]
2022-10-08 04:43:14,274 [trainer.py] => CNN compound curve: [0, 36.52, 30.13, 27.17]
2022-10-08 04:43:14,274 [trainer.py] => NME: {'total': 49.9, 'old': 52.45, 'new': 41.53, 'base': 65.54, 'compound': 43.42}
2022-10-08 04:43:14,274 [trainer.py] => NME top1 curve: [88.51, 67.68, 57.88, 49.9]
2022-10-08 04:43:14,274 [trainer.py] => NME base curve: [88.51, 72.3, 67.57, 65.54]
2022-10-08 04:43:14,274 [trainer.py] => NME old curve: [88.51, 72.3, 58.56, 52.45]
2022-10-08 04:43:14,274 [trainer.py] => NME new curve: [0, 61.74, 56.45, 41.53]
2022-10-08 04:43:14,274 [trainer.py] => NME compound curve: [0, 61.74, 51.88, 43.42]
2022-10-08 04:43:14,275 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 04:43:14,275 [trainer.py] => prefix: cil
2022-10-08 04:43:14,275 [trainer.py] => dataset: CFEE
2022-10-08 04:43:14,275 [trainer.py] => memory_size: 2000
2022-10-08 04:43:14,275 [trainer.py] => memory_per_class: 20
2022-10-08 04:43:14,276 [trainer.py] => fixed_memory: True
2022-10-08 04:43:14,276 [trainer.py] => shuffle: True
2022-10-08 04:43:14,276 [trainer.py] => init_cls: 7
2022-10-08 04:43:14,276 [trainer.py] => increment: 5
2022-10-08 04:43:14,276 [trainer.py] => model_name: foster
2022-10-08 04:43:14,276 [trainer.py] => convnet_type: resnet18
2022-10-08 04:43:14,276 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 04:43:14,276 [trainer.py] => seed: 1993
2022-10-08 04:43:14,276 [trainer.py] => beta1: 0.96
2022-10-08 04:43:14,276 [trainer.py] => beta2: 0.97
2022-10-08 04:43:14,276 [trainer.py] => oofc: ft
2022-10-08 04:43:14,276 [trainer.py] => is_teacher_wa: False
2022-10-08 04:43:14,276 [trainer.py] => is_student_wa: False
2022-10-08 04:43:14,276 [trainer.py] => lambda_okd: 1
2022-10-08 04:43:14,276 [trainer.py] => wa_value: 1
2022-10-08 04:43:14,276 [trainer.py] => init_epochs: 40
2022-10-08 04:43:14,276 [trainer.py] => init_lr: 0.01
2022-10-08 04:43:14,276 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 04:43:14,276 [trainer.py] => boosting_epochs: 34
2022-10-08 04:43:14,276 [trainer.py] => compression_epochs: 26
2022-10-08 04:43:14,276 [trainer.py] => lr: 0.001
2022-10-08 04:43:14,276 [trainer.py] => batch_size: 32
2022-10-08 04:43:14,276 [trainer.py] => weight_decay: 0.0005
2022-10-08 04:43:14,276 [trainer.py] => num_workers: 8
2022-10-08 04:43:14,276 [trainer.py] => T: 2
2022-10-08 04:43:14,276 [trainer.py] => nb_runs: 3
2022-10-08 04:43:14,276 [trainer.py] => fold: 10
2022-10-08 04:43:14,276 [data.py] => ========== Fold:2 ==========
2022-10-08 04:43:14,281 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 13, 17, 15, 9, 11, 20, 18, 12, 14, 7, 10, 19, 21, 16, 8]
2022-10-08 04:43:14,519 [foster.py] => Learning on 0-7
2022-10-08 04:43:14,519 [foster.py] => All params: 11183694
2022-10-08 04:43:14,519 [foster.py] => Trainable params: 11183694
2022-10-08 04:43:17,471 [foster.py] => Task 0, Epoch 1/40 => Loss 1.357, Train_accy 49.14
2022-10-08 04:43:21,051 [foster.py] => Task 0, Epoch 2/40 => Loss 0.566, Train_accy 80.33, Test_accy 80.38
2022-10-08 04:43:24,611 [foster.py] => Task 0, Epoch 3/40 => Loss 0.381, Train_accy 86.96, Test_accy 81.65
2022-10-08 04:43:28,690 [foster.py] => Task 0, Epoch 4/40 => Loss 0.284, Train_accy 90.82, Test_accy 82.91
2022-10-08 04:43:32,385 [foster.py] => Task 0, Epoch 5/40 => Loss 0.239, Train_accy 91.10, Test_accy 79.75
2022-10-08 04:43:35,450 [foster.py] => Task 0, Epoch 6/40 => Loss 0.200, Train_accy 93.24
2022-10-08 04:43:39,331 [foster.py] => Task 0, Epoch 7/40 => Loss 0.154, Train_accy 94.76, Test_accy 81.01
2022-10-08 04:43:42,915 [foster.py] => Task 0, Epoch 8/40 => Loss 0.150, Train_accy 94.82, Test_accy 82.91
2022-10-08 04:43:46,716 [foster.py] => Task 0, Epoch 9/40 => Loss 0.110, Train_accy 96.34, Test_accy 82.91
2022-10-08 04:43:50,608 [foster.py] => Task 0, Epoch 10/40 => Loss 0.109, Train_accy 96.62, Test_accy 82.91
2022-10-08 04:43:53,916 [foster.py] => Task 0, Epoch 11/40 => Loss 0.096, Train_accy 96.55
2022-10-08 04:43:57,794 [foster.py] => Task 0, Epoch 12/40 => Loss 0.072, Train_accy 97.65, Test_accy 79.75
2022-10-08 04:44:01,645 [foster.py] => Task 0, Epoch 13/40 => Loss 0.063, Train_accy 98.27, Test_accy 82.91
2022-10-08 04:44:05,421 [foster.py] => Task 0, Epoch 14/40 => Loss 0.064, Train_accy 97.93, Test_accy 83.54
2022-10-08 04:44:09,409 [foster.py] => Task 0, Epoch 15/40 => Loss 0.059, Train_accy 98.62, Test_accy 82.91
2022-10-08 04:44:12,620 [foster.py] => Task 0, Epoch 16/40 => Loss 0.040, Train_accy 99.38
2022-10-08 04:44:16,570 [foster.py] => Task 0, Epoch 17/40 => Loss 0.040, Train_accy 99.31, Test_accy 84.81
2022-10-08 04:44:20,480 [foster.py] => Task 0, Epoch 18/40 => Loss 0.042, Train_accy 99.10, Test_accy 82.28
2022-10-08 04:44:26,227 [foster.py] => Task 0, Epoch 19/40 => Loss 0.031, Train_accy 99.17, Test_accy 84.18
2022-10-08 04:44:31,056 [foster.py] => Task 0, Epoch 20/40 => Loss 0.029, Train_accy 99.03, Test_accy 82.91
2022-10-08 04:44:34,428 [foster.py] => Task 0, Epoch 21/40 => Loss 0.026, Train_accy 99.52
2022-10-08 04:44:38,369 [foster.py] => Task 0, Epoch 22/40 => Loss 0.028, Train_accy 99.38, Test_accy 85.44
2022-10-08 04:44:42,202 [foster.py] => Task 0, Epoch 23/40 => Loss 0.026, Train_accy 99.45, Test_accy 85.44
2022-10-08 04:44:46,077 [foster.py] => Task 0, Epoch 24/40 => Loss 0.021, Train_accy 99.65, Test_accy 86.71
2022-10-08 04:44:50,039 [foster.py] => Task 0, Epoch 25/40 => Loss 0.024, Train_accy 99.65, Test_accy 84.81
2022-10-08 04:44:52,991 [foster.py] => Task 0, Epoch 26/40 => Loss 0.015, Train_accy 99.79
2022-10-08 04:44:56,874 [foster.py] => Task 0, Epoch 27/40 => Loss 0.019, Train_accy 99.59, Test_accy 86.71
2022-10-08 04:45:00,537 [foster.py] => Task 0, Epoch 28/40 => Loss 0.023, Train_accy 99.52, Test_accy 84.81
2022-10-08 04:45:04,953 [foster.py] => Task 0, Epoch 29/40 => Loss 0.017, Train_accy 99.79, Test_accy 86.71
2022-10-08 04:45:09,286 [foster.py] => Task 0, Epoch 30/40 => Loss 0.019, Train_accy 99.59, Test_accy 86.08
2022-10-08 04:45:12,919 [foster.py] => Task 0, Epoch 31/40 => Loss 0.016, Train_accy 99.93
2022-10-08 04:45:17,334 [foster.py] => Task 0, Epoch 32/40 => Loss 0.013, Train_accy 99.86, Test_accy 86.71
2022-10-08 04:45:21,706 [foster.py] => Task 0, Epoch 33/40 => Loss 0.016, Train_accy 99.86, Test_accy 85.44
2022-10-08 04:45:25,587 [foster.py] => Task 0, Epoch 34/40 => Loss 0.018, Train_accy 99.59, Test_accy 86.08
2022-10-08 04:45:29,435 [foster.py] => Task 0, Epoch 35/40 => Loss 0.015, Train_accy 99.72, Test_accy 85.44
2022-10-08 04:45:32,507 [foster.py] => Task 0, Epoch 36/40 => Loss 0.014, Train_accy 99.86
2022-10-08 04:45:36,522 [foster.py] => Task 0, Epoch 37/40 => Loss 0.014, Train_accy 99.86, Test_accy 86.08
2022-10-08 04:45:40,361 [foster.py] => Task 0, Epoch 38/40 => Loss 0.017, Train_accy 99.79, Test_accy 86.08
2022-10-08 04:45:44,259 [foster.py] => Task 0, Epoch 39/40 => Loss 0.012, Train_accy 99.86, Test_accy 85.44
2022-10-08 04:45:48,213 [foster.py] => Task 0, Epoch 40/40 => Loss 0.013, Train_accy 100.00, Test_accy 86.08
2022-10-08 04:45:48,213 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 04:45:55,521 [foster.py] => Exemplar size: 140
2022-10-08 04:45:55,521 [trainer.py] => CNN: {'total': 86.08, 'old': 86.08, 'new': 0, 'base': 86.08, 'compound': 0}
2022-10-08 04:45:55,521 [trainer.py] => CNN top1 curve: [86.08]
2022-10-08 04:45:55,521 [trainer.py] => CNN base curve: [86.08]
2022-10-08 04:45:55,521 [trainer.py] => CNN old curve: [86.08]
2022-10-08 04:45:55,521 [trainer.py] => CNN new curve: [0]
2022-10-08 04:45:55,521 [trainer.py] => CNN compound curve: [0]
2022-10-08 04:45:55,521 [trainer.py] => NME: {'total': 85.44, 'old': 85.44, 'new': 0, 'base': 85.44, 'compound': 0}
2022-10-08 04:45:55,521 [trainer.py] => NME top1 curve: [85.44]
2022-10-08 04:45:55,521 [trainer.py] => NME base curve: [85.44]
2022-10-08 04:45:55,521 [trainer.py] => NME old curve: [85.44]
2022-10-08 04:45:55,521 [trainer.py] => NME new curve: [0]
2022-10-08 04:45:55,521 [trainer.py] => NME compound curve: [0]
2022-10-08 04:45:55,780 [foster.py] => Learning on 7-12
2022-10-08 04:45:55,780 [foster.py] => All params: 22375071
2022-10-08 04:45:55,781 [foster.py] => Trainable params: 11194968
2022-10-08 04:45:55,791 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 04:45:59,520 [foster.py] => Task 1, Epoch 1/34 => Loss 4.772, Loss_clf 2.183, Loss_fe 1.957, Loss_kd 0.369, Train_accy 36.54, Test_accy 63.47
2022-10-08 04:46:02,774 [foster.py] => Task 1, Epoch 2/34 => Loss 2.565, Loss_clf 0.713, Loss_fe 1.222, Loss_kd 0.367, Train_accy 61.24
2022-10-08 04:46:06,043 [foster.py] => Task 1, Epoch 3/34 => Loss 2.194, Loss_clf 0.583, Loss_fe 0.994, Loss_kd 0.360, Train_accy 46.85
2022-10-08 04:46:09,393 [foster.py] => Task 1, Epoch 4/34 => Loss 2.004, Loss_clf 0.523, Loss_fe 0.867, Loss_kd 0.358, Train_accy 45.83
2022-10-08 04:46:12,668 [foster.py] => Task 1, Epoch 5/34 => Loss 1.902, Loss_clf 0.494, Loss_fe 0.791, Loss_kd 0.360, Train_accy 46.51
2022-10-08 04:46:16,915 [foster.py] => Task 1, Epoch 6/34 => Loss 1.832, Loss_clf 0.492, Loss_fe 0.732, Loss_kd 0.355, Train_accy 46.68, Test_accy 60.52
2022-10-08 04:46:20,313 [foster.py] => Task 1, Epoch 7/34 => Loss 1.775, Loss_clf 0.472, Loss_fe 0.701, Loss_kd 0.351, Train_accy 44.55
2022-10-08 04:46:23,916 [foster.py] => Task 1, Epoch 8/34 => Loss 1.704, Loss_clf 0.445, Loss_fe 0.649, Loss_kd 0.355, Train_accy 46.17
2022-10-08 04:46:27,263 [foster.py] => Task 1, Epoch 9/34 => Loss 1.691, Loss_clf 0.443, Loss_fe 0.632, Loss_kd 0.359, Train_accy 44.80
2022-10-08 04:46:30,509 [foster.py] => Task 1, Epoch 10/34 => Loss 1.653, Loss_clf 0.435, Loss_fe 0.608, Loss_kd 0.356, Train_accy 46.25
2022-10-08 04:46:34,717 [foster.py] => Task 1, Epoch 11/34 => Loss 1.635, Loss_clf 0.436, Loss_fe 0.589, Loss_kd 0.356, Train_accy 48.72, Test_accy 60.52
2022-10-08 04:46:38,207 [foster.py] => Task 1, Epoch 12/34 => Loss 1.597, Loss_clf 0.416, Loss_fe 0.573, Loss_kd 0.355, Train_accy 45.74
2022-10-08 04:46:41,805 [foster.py] => Task 1, Epoch 13/34 => Loss 1.551, Loss_clf 0.398, Loss_fe 0.548, Loss_kd 0.353, Train_accy 47.02
2022-10-08 04:46:46,935 [foster.py] => Task 1, Epoch 14/34 => Loss 1.543, Loss_clf 0.396, Loss_fe 0.534, Loss_kd 0.357, Train_accy 49.74
2022-10-08 04:46:52,086 [foster.py] => Task 1, Epoch 15/34 => Loss 1.500, Loss_clf 0.383, Loss_fe 0.510, Loss_kd 0.354, Train_accy 47.02
2022-10-08 04:46:58,156 [foster.py] => Task 1, Epoch 16/34 => Loss 1.450, Loss_clf 0.363, Loss_fe 0.486, Loss_kd 0.351, Train_accy 49.74, Test_accy 60.89
2022-10-08 04:47:02,059 [foster.py] => Task 1, Epoch 17/34 => Loss 1.455, Loss_clf 0.368, Loss_fe 0.478, Loss_kd 0.355, Train_accy 48.64
2022-10-08 04:47:05,952 [foster.py] => Task 1, Epoch 18/34 => Loss 1.425, Loss_clf 0.349, Loss_fe 0.466, Loss_kd 0.356, Train_accy 49.23
2022-10-08 04:47:09,767 [foster.py] => Task 1, Epoch 19/34 => Loss 1.424, Loss_clf 0.353, Loss_fe 0.463, Loss_kd 0.355, Train_accy 48.89
2022-10-08 04:47:13,562 [foster.py] => Task 1, Epoch 20/34 => Loss 1.429, Loss_clf 0.353, Loss_fe 0.471, Loss_kd 0.353, Train_accy 48.64
2022-10-08 04:47:17,955 [foster.py] => Task 1, Epoch 21/34 => Loss 1.409, Loss_clf 0.344, Loss_fe 0.456, Loss_kd 0.355, Train_accy 51.19, Test_accy 60.89
2022-10-08 04:47:21,366 [foster.py] => Task 1, Epoch 22/34 => Loss 1.370, Loss_clf 0.329, Loss_fe 0.438, Loss_kd 0.352, Train_accy 50.94
2022-10-08 04:47:24,859 [foster.py] => Task 1, Epoch 23/34 => Loss 1.395, Loss_clf 0.340, Loss_fe 0.444, Loss_kd 0.356, Train_accy 50.60
2022-10-08 04:47:28,423 [foster.py] => Task 1, Epoch 24/34 => Loss 1.380, Loss_clf 0.334, Loss_fe 0.440, Loss_kd 0.353, Train_accy 49.83
2022-10-08 04:47:31,962 [foster.py] => Task 1, Epoch 25/34 => Loss 1.374, Loss_clf 0.337, Loss_fe 0.434, Loss_kd 0.352, Train_accy 50.77
2022-10-08 04:47:36,335 [foster.py] => Task 1, Epoch 26/34 => Loss 1.351, Loss_clf 0.320, Loss_fe 0.418, Loss_kd 0.358, Train_accy 50.34, Test_accy 61.25
2022-10-08 04:47:39,894 [foster.py] => Task 1, Epoch 27/34 => Loss 1.351, Loss_clf 0.314, Loss_fe 0.427, Loss_kd 0.356, Train_accy 50.17
2022-10-08 04:47:43,240 [foster.py] => Task 1, Epoch 28/34 => Loss 1.329, Loss_clf 0.304, Loss_fe 0.414, Loss_kd 0.356, Train_accy 50.09
2022-10-08 04:47:46,885 [foster.py] => Task 1, Epoch 29/34 => Loss 1.344, Loss_clf 0.314, Loss_fe 0.423, Loss_kd 0.354, Train_accy 50.34
2022-10-08 04:47:50,545 [foster.py] => Task 1, Epoch 30/34 => Loss 1.340, Loss_clf 0.315, Loss_fe 0.420, Loss_kd 0.353, Train_accy 51.28
2022-10-08 04:47:55,164 [foster.py] => Task 1, Epoch 31/34 => Loss 1.385, Loss_clf 0.328, Loss_fe 0.445, Loss_kd 0.357, Train_accy 49.57, Test_accy 61.25
2022-10-08 04:47:58,792 [foster.py] => Task 1, Epoch 32/34 => Loss 1.359, Loss_clf 0.324, Loss_fe 0.422, Loss_kd 0.358, Train_accy 52.30
2022-10-08 04:48:02,392 [foster.py] => Task 1, Epoch 33/34 => Loss 1.318, Loss_clf 0.300, Loss_fe 0.412, Loss_kd 0.354, Train_accy 50.51
2022-10-08 04:48:06,000 [foster.py] => Task 1, Epoch 34/34 => Loss 1.367, Loss_clf 0.321, Loss_fe 0.433, Loss_kd 0.358, Train_accy 50.00
2022-10-08 04:48:06,001 [foster.py] => do not weight align teacher!
2022-10-08 04:48:06,001 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 04:48:11,199 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.700,  Train_accy 11.75, Test_accy 48.34
2022-10-08 04:48:15,491 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.551,  Train_accy 12.01
2022-10-08 04:48:19,744 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.476,  Train_accy 12.44
2022-10-08 04:48:24,208 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.421,  Train_accy 15.08
2022-10-08 04:48:28,470 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.408,  Train_accy 16.61
2022-10-08 04:48:33,657 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.385,  Train_accy 17.97, Test_accy 53.51
2022-10-08 04:48:38,016 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.364,  Train_accy 20.19
2022-10-08 04:48:42,328 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.366,  Train_accy 20.61
2022-10-08 04:48:46,972 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.349,  Train_accy 22.49
2022-10-08 04:48:51,290 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.348,  Train_accy 22.57
2022-10-08 04:48:56,294 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.346,  Train_accy 23.42, Test_accy 55.35
2022-10-08 04:49:00,691 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.336,  Train_accy 24.79
2022-10-08 04:49:04,971 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.336,  Train_accy 24.28
2022-10-08 04:49:09,310 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.338,  Train_accy 25.47
2022-10-08 04:49:13,598 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.330,  Train_accy 24.19
2022-10-08 04:49:18,802 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.320,  Train_accy 25.72, Test_accy 56.09
2022-10-08 04:49:23,009 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.317,  Train_accy 25.64
2022-10-08 04:49:27,577 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.314,  Train_accy 25.89
2022-10-08 04:49:32,510 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.321,  Train_accy 24.28
2022-10-08 04:49:37,441 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.311,  Train_accy 26.06
2022-10-08 04:49:43,285 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.324,  Train_accy 26.41, Test_accy 56.46
2022-10-08 04:49:48,300 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.318,  Train_accy 25.21
2022-10-08 04:49:53,136 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.304,  Train_accy 26.66
2022-10-08 04:49:57,996 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.307,  Train_accy 26.49
2022-10-08 04:50:02,917 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.316,  Train_accy 26.24
2022-10-08 04:50:08,517 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.307,  Train_accy 27.00, Test_accy 56.46
2022-10-08 04:50:08,517 [foster.py] => do not weight align student!
2022-10-08 04:50:09,334 [foster.py] => darknet eval: 
2022-10-08 04:50:09,334 [foster.py] => CNN top1 curve: 56.46
2022-10-08 04:50:09,334 [foster.py] => CNN top5 curve: 97.79
2022-10-08 04:50:09,334 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 04:50:18,042 [foster.py] => Exemplar size: 240
2022-10-08 04:50:18,042 [trainer.py] => CNN: {'total': 60.89, 'old': 76.58, 'new': 38.94, 'base': 76.58, 'compound': 38.94}
2022-10-08 04:50:18,042 [trainer.py] => CNN top1 curve: [86.08, 60.89]
2022-10-08 04:50:18,042 [trainer.py] => CNN base curve: [86.08, 76.58]
2022-10-08 04:50:18,042 [trainer.py] => CNN old curve: [86.08, 76.58]
2022-10-08 04:50:18,042 [trainer.py] => CNN new curve: [0, 38.94]
2022-10-08 04:50:18,042 [trainer.py] => CNN compound curve: [0, 38.94]
2022-10-08 04:50:18,042 [trainer.py] => NME: {'total': 68.27, 'old': 74.68, 'new': 59.29, 'base': 74.68, 'compound': 59.29}
2022-10-08 04:50:18,042 [trainer.py] => NME top1 curve: [85.44, 68.27]
2022-10-08 04:50:18,042 [trainer.py] => NME base curve: [85.44, 74.68]
2022-10-08 04:50:18,042 [trainer.py] => NME old curve: [85.44, 74.68]
2022-10-08 04:50:18,042 [trainer.py] => NME new curve: [0, 59.29]
2022-10-08 04:50:18,042 [trainer.py] => NME compound curve: [0, 59.29]
2022-10-08 04:50:18,288 [foster.py] => Learning on 12-17
2022-10-08 04:50:18,289 [foster.py] => All params: 22385326
2022-10-08 04:50:18,289 [foster.py] => Trainable params: 11202658
2022-10-08 04:50:18,299 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 04:50:22,425 [foster.py] => Task 2, Epoch 1/34 => Loss 5.587, Loss_clf 2.023, Loss_fe 2.163, Loss_kd 0.989, Train_accy 35.29, Test_accy 45.00
2022-10-08 04:50:25,731 [foster.py] => Task 2, Epoch 2/34 => Loss 3.822, Loss_clf 0.986, Loss_fe 1.498, Loss_kd 0.944, Train_accy 41.81
2022-10-08 04:50:29,209 [foster.py] => Task 2, Epoch 3/34 => Loss 3.558, Loss_clf 0.880, Loss_fe 1.335, Loss_kd 0.948, Train_accy 38.47
2022-10-08 04:50:32,682 [foster.py] => Task 2, Epoch 4/34 => Loss 3.377, Loss_clf 0.821, Loss_fe 1.212, Loss_kd 0.949, Train_accy 38.71
2022-10-08 04:50:36,082 [foster.py] => Task 2, Epoch 5/34 => Loss 3.229, Loss_clf 0.774, Loss_fe 1.108, Loss_kd 0.951, Train_accy 38.08
2022-10-08 04:50:41,059 [foster.py] => Task 2, Epoch 6/34 => Loss 3.149, Loss_clf 0.750, Loss_fe 1.045, Loss_kd 0.956, Train_accy 41.34, Test_accy 46.25
2022-10-08 04:50:44,659 [foster.py] => Task 2, Epoch 7/34 => Loss 3.074, Loss_clf 0.726, Loss_fe 0.992, Loss_kd 0.957, Train_accy 39.59
2022-10-08 04:50:48,129 [foster.py] => Task 2, Epoch 8/34 => Loss 2.991, Loss_clf 0.698, Loss_fe 0.944, Loss_kd 0.952, Train_accy 39.90
2022-10-08 04:50:52,264 [foster.py] => Task 2, Epoch 9/34 => Loss 2.976, Loss_clf 0.701, Loss_fe 0.912, Loss_kd 0.963, Train_accy 41.10
2022-10-08 04:50:55,946 [foster.py] => Task 2, Epoch 10/34 => Loss 2.916, Loss_clf 0.677, Loss_fe 0.877, Loss_kd 0.962, Train_accy 41.81
2022-10-08 04:51:01,170 [foster.py] => Task 2, Epoch 11/34 => Loss 2.848, Loss_clf 0.651, Loss_fe 0.847, Loss_kd 0.953, Train_accy 38.95, Test_accy 47.25
2022-10-08 04:51:05,135 [foster.py] => Task 2, Epoch 12/34 => Loss 2.827, Loss_clf 0.649, Loss_fe 0.827, Loss_kd 0.954, Train_accy 40.46
2022-10-08 04:51:09,033 [foster.py] => Task 2, Epoch 13/34 => Loss 2.824, Loss_clf 0.653, Loss_fe 0.820, Loss_kd 0.954, Train_accy 42.21
2022-10-08 04:51:12,946 [foster.py] => Task 2, Epoch 14/34 => Loss 2.756, Loss_clf 0.625, Loss_fe 0.772, Loss_kd 0.959, Train_accy 41.65
2022-10-08 04:51:16,580 [foster.py] => Task 2, Epoch 15/34 => Loss 2.766, Loss_clf 0.627, Loss_fe 0.779, Loss_kd 0.960, Train_accy 42.61
2022-10-08 04:51:21,624 [foster.py] => Task 2, Epoch 16/34 => Loss 2.722, Loss_clf 0.618, Loss_fe 0.752, Loss_kd 0.954, Train_accy 43.72, Test_accy 47.50
2022-10-08 04:51:25,265 [foster.py] => Task 2, Epoch 17/34 => Loss 2.645, Loss_clf 0.584, Loss_fe 0.708, Loss_kd 0.955, Train_accy 45.47
2022-10-08 04:51:29,268 [foster.py] => Task 2, Epoch 18/34 => Loss 2.709, Loss_clf 0.619, Loss_fe 0.740, Loss_kd 0.953, Train_accy 42.45
2022-10-08 04:51:33,001 [foster.py] => Task 2, Epoch 19/34 => Loss 2.674, Loss_clf 0.597, Loss_fe 0.717, Loss_kd 0.960, Train_accy 43.24
2022-10-08 04:51:37,159 [foster.py] => Task 2, Epoch 20/34 => Loss 2.626, Loss_clf 0.570, Loss_fe 0.696, Loss_kd 0.960, Train_accy 44.59
2022-10-08 04:51:43,185 [foster.py] => Task 2, Epoch 21/34 => Loss 2.623, Loss_clf 0.576, Loss_fe 0.685, Loss_kd 0.962, Train_accy 45.07, Test_accy 47.75
2022-10-08 04:51:47,832 [foster.py] => Task 2, Epoch 22/34 => Loss 2.584, Loss_clf 0.565, Loss_fe 0.677, Loss_kd 0.947, Train_accy 44.59
2022-10-08 04:51:52,368 [foster.py] => Task 2, Epoch 23/34 => Loss 2.548, Loss_clf 0.538, Loss_fe 0.655, Loss_kd 0.957, Train_accy 46.18
2022-10-08 04:51:56,889 [foster.py] => Task 2, Epoch 24/34 => Loss 2.589, Loss_clf 0.559, Loss_fe 0.672, Loss_kd 0.959, Train_accy 43.40
2022-10-08 04:52:01,506 [foster.py] => Task 2, Epoch 25/34 => Loss 2.572, Loss_clf 0.550, Loss_fe 0.668, Loss_kd 0.956, Train_accy 45.47
2022-10-08 04:52:07,157 [foster.py] => Task 2, Epoch 26/34 => Loss 2.563, Loss_clf 0.553, Loss_fe 0.660, Loss_kd 0.954, Train_accy 46.26, Test_accy 47.75
2022-10-08 04:52:11,683 [foster.py] => Task 2, Epoch 27/34 => Loss 2.568, Loss_clf 0.551, Loss_fe 0.658, Loss_kd 0.959, Train_accy 45.31
2022-10-08 04:52:16,294 [foster.py] => Task 2, Epoch 28/34 => Loss 2.536, Loss_clf 0.536, Loss_fe 0.650, Loss_kd 0.953, Train_accy 45.47
2022-10-08 04:52:20,946 [foster.py] => Task 2, Epoch 29/34 => Loss 2.543, Loss_clf 0.537, Loss_fe 0.646, Loss_kd 0.960, Train_accy 44.67
2022-10-08 04:52:24,950 [foster.py] => Task 2, Epoch 30/34 => Loss 2.543, Loss_clf 0.544, Loss_fe 0.640, Loss_kd 0.960, Train_accy 45.71
2022-10-08 04:52:30,070 [foster.py] => Task 2, Epoch 31/34 => Loss 2.551, Loss_clf 0.544, Loss_fe 0.651, Loss_kd 0.957, Train_accy 43.96, Test_accy 47.50
2022-10-08 04:52:34,149 [foster.py] => Task 2, Epoch 32/34 => Loss 2.503, Loss_clf 0.525, Loss_fe 0.626, Loss_kd 0.955, Train_accy 46.34
2022-10-08 04:52:38,102 [foster.py] => Task 2, Epoch 33/34 => Loss 2.557, Loss_clf 0.545, Loss_fe 0.657, Loss_kd 0.957, Train_accy 45.23
2022-10-08 04:52:42,065 [foster.py] => Task 2, Epoch 34/34 => Loss 2.527, Loss_clf 0.529, Loss_fe 0.643, Loss_kd 0.956, Train_accy 45.15
2022-10-08 04:52:42,065 [foster.py] => do not weight align teacher!
2022-10-08 04:52:42,066 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 04:52:47,999 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.083,  Train_accy 12.00, Test_accy 38.50
2022-10-08 04:52:52,777 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 2.004,  Train_accy 12.48
2022-10-08 04:52:57,490 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.964,  Train_accy 12.88
2022-10-08 04:53:02,257 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.941,  Train_accy 12.80
2022-10-08 04:53:07,014 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.923,  Train_accy 13.20
2022-10-08 04:53:12,626 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.919,  Train_accy 12.96, Test_accy 38.25
2022-10-08 04:53:16,971 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.909,  Train_accy 13.20
2022-10-08 04:53:21,305 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.909,  Train_accy 13.51
2022-10-08 04:53:25,723 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.881,  Train_accy 13.28
2022-10-08 04:53:30,061 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.894,  Train_accy 13.35
2022-10-08 04:53:35,322 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.877,  Train_accy 13.28, Test_accy 39.00
2022-10-08 04:53:39,544 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.868,  Train_accy 13.51
2022-10-08 04:53:43,787 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.872,  Train_accy 14.23
2022-10-08 04:53:47,909 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.865,  Train_accy 14.47
2022-10-08 04:53:52,301 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.887,  Train_accy 14.23
2022-10-08 04:53:57,648 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.867,  Train_accy 14.71, Test_accy 39.25
2022-10-08 04:54:02,083 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.862,  Train_accy 13.91
2022-10-08 04:54:06,697 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.868,  Train_accy 14.71
2022-10-08 04:54:11,253 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.865,  Train_accy 15.34
2022-10-08 04:54:15,938 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.852,  Train_accy 14.39
2022-10-08 04:54:23,563 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.859,  Train_accy 14.55, Test_accy 38.75
2022-10-08 04:54:29,271 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.859,  Train_accy 14.79
2022-10-08 04:54:34,157 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.864,  Train_accy 14.47
2022-10-08 04:54:39,138 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.876,  Train_accy 14.86
2022-10-08 04:54:44,129 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.872,  Train_accy 15.10
2022-10-08 04:54:49,917 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.866,  Train_accy 14.79, Test_accy 39.50
2022-10-08 04:54:49,917 [foster.py] => do not weight align student!
2022-10-08 04:54:50,812 [foster.py] => darknet eval: 
2022-10-08 04:54:50,812 [foster.py] => CNN top1 curve: 39.5
2022-10-08 04:54:50,812 [foster.py] => CNN top5 curve: 92.5
2022-10-08 04:54:50,813 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 04:55:01,698 [foster.py] => Exemplar size: 340
2022-10-08 04:55:01,698 [trainer.py] => CNN: {'total': 47.75, 'old': 57.93, 'new': 26.36, 'base': 76.58, 'compound': 28.93}
2022-10-08 04:55:01,698 [trainer.py] => CNN top1 curve: [86.08, 60.89, 47.75]
2022-10-08 04:55:01,698 [trainer.py] => CNN base curve: [86.08, 76.58, 76.58]
2022-10-08 04:55:01,698 [trainer.py] => CNN old curve: [86.08, 76.58, 57.93]
2022-10-08 04:55:01,698 [trainer.py] => CNN new curve: [0, 38.94, 26.36]
2022-10-08 04:55:01,698 [trainer.py] => CNN compound curve: [0, 38.94, 28.93]
2022-10-08 04:55:01,698 [trainer.py] => NME: {'total': 60.5, 'old': 62.73, 'new': 55.81, 'base': 70.25, 'compound': 54.13}
2022-10-08 04:55:01,698 [trainer.py] => NME top1 curve: [85.44, 68.27, 60.5]
2022-10-08 04:55:01,698 [trainer.py] => NME base curve: [85.44, 74.68, 70.25]
2022-10-08 04:55:01,698 [trainer.py] => NME old curve: [85.44, 74.68, 62.73]
2022-10-08 04:55:01,698 [trainer.py] => NME new curve: [0, 59.29, 55.81]
2022-10-08 04:55:01,698 [trainer.py] => NME compound curve: [0, 59.29, 54.13]
2022-10-08 04:55:01,939 [foster.py] => Learning on 17-22
2022-10-08 04:55:01,939 [foster.py] => All params: 22395581
2022-10-08 04:55:01,940 [foster.py] => Trainable params: 11210348
2022-10-08 04:55:01,950 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 04:55:06,953 [foster.py] => Task 3, Epoch 1/34 => Loss 6.434, Loss_clf 2.114, Loss_fe 2.370, Loss_kd 1.507, Train_accy 30.87, Test_accy 36.63
2022-10-08 04:55:10,546 [foster.py] => Task 3, Epoch 2/34 => Loss 4.935, Loss_clf 1.240, Loss_fe 1.789, Loss_kd 1.473, Train_accy 29.93
2022-10-08 04:55:14,201 [foster.py] => Task 3, Epoch 3/34 => Loss 4.629, Loss_clf 1.135, Loss_fe 1.581, Loss_kd 1.478, Train_accy 31.81
2022-10-08 04:55:18,001 [foster.py] => Task 3, Epoch 4/34 => Loss 4.452, Loss_clf 1.072, Loss_fe 1.473, Loss_kd 1.474, Train_accy 34.20
2022-10-08 04:55:22,002 [foster.py] => Task 3, Epoch 5/34 => Loss 4.320, Loss_clf 1.043, Loss_fe 1.371, Loss_kd 1.472, Train_accy 32.10
2022-10-08 04:55:26,990 [foster.py] => Task 3, Epoch 6/34 => Loss 4.287, Loss_clf 1.041, Loss_fe 1.348, Loss_kd 1.467, Train_accy 34.13, Test_accy 37.43
2022-10-08 04:55:31,079 [foster.py] => Task 3, Epoch 7/34 => Loss 4.211, Loss_clf 1.021, Loss_fe 1.278, Loss_kd 1.477, Train_accy 32.83
2022-10-08 04:55:35,055 [foster.py] => Task 3, Epoch 8/34 => Loss 4.059, Loss_clf 0.963, Loss_fe 1.188, Loss_kd 1.474, Train_accy 35.58
2022-10-08 04:55:39,034 [foster.py] => Task 3, Epoch 9/34 => Loss 3.990, Loss_clf 0.941, Loss_fe 1.145, Loss_kd 1.471, Train_accy 36.01
2022-10-08 04:55:43,168 [foster.py] => Task 3, Epoch 10/34 => Loss 3.975, Loss_clf 0.934, Loss_fe 1.138, Loss_kd 1.470, Train_accy 35.58
2022-10-08 04:55:48,282 [foster.py] => Task 3, Epoch 11/34 => Loss 3.942, Loss_clf 0.936, Loss_fe 1.094, Loss_kd 1.478, Train_accy 35.43, Test_accy 39.60
2022-10-08 04:55:52,103 [foster.py] => Task 3, Epoch 12/34 => Loss 3.824, Loss_clf 0.880, Loss_fe 1.040, Loss_kd 1.472, Train_accy 37.32
2022-10-08 04:55:56,175 [foster.py] => Task 3, Epoch 13/34 => Loss 3.792, Loss_clf 0.881, Loss_fe 1.018, Loss_kd 1.463, Train_accy 37.75
2022-10-08 04:56:00,264 [foster.py] => Task 3, Epoch 14/34 => Loss 3.799, Loss_clf 0.872, Loss_fe 1.017, Loss_kd 1.475, Train_accy 35.65
2022-10-08 04:56:04,165 [foster.py] => Task 3, Epoch 15/34 => Loss 3.761, Loss_clf 0.869, Loss_fe 0.988, Loss_kd 1.471, Train_accy 37.90
2022-10-08 04:56:09,509 [foster.py] => Task 3, Epoch 16/34 => Loss 3.711, Loss_clf 0.838, Loss_fe 0.963, Loss_kd 1.476, Train_accy 37.68, Test_accy 40.40
2022-10-08 04:56:13,617 [foster.py] => Task 3, Epoch 17/34 => Loss 3.714, Loss_clf 0.843, Loss_fe 0.963, Loss_kd 1.475, Train_accy 38.41
2022-10-08 04:56:18,166 [foster.py] => Task 3, Epoch 18/34 => Loss 3.649, Loss_clf 0.814, Loss_fe 0.919, Loss_kd 1.480, Train_accy 38.91
2022-10-08 04:56:22,421 [foster.py] => Task 3, Epoch 19/34 => Loss 3.649, Loss_clf 0.825, Loss_fe 0.919, Loss_kd 1.472, Train_accy 38.41
2022-10-08 04:56:26,601 [foster.py] => Task 3, Epoch 20/34 => Loss 3.657, Loss_clf 0.826, Loss_fe 0.922, Loss_kd 1.475, Train_accy 38.99
2022-10-08 04:56:32,331 [foster.py] => Task 3, Epoch 21/34 => Loss 3.621, Loss_clf 0.805, Loss_fe 0.909, Loss_kd 1.474, Train_accy 39.28, Test_accy 41.98
2022-10-08 04:56:36,798 [foster.py] => Task 3, Epoch 22/34 => Loss 3.658, Loss_clf 0.818, Loss_fe 0.929, Loss_kd 1.476, Train_accy 38.48
2022-10-08 04:56:41,425 [foster.py] => Task 3, Epoch 23/34 => Loss 3.552, Loss_clf 0.769, Loss_fe 0.868, Loss_kd 1.480, Train_accy 40.14
2022-10-08 04:56:45,912 [foster.py] => Task 3, Epoch 24/34 => Loss 3.560, Loss_clf 0.774, Loss_fe 0.866, Loss_kd 1.484, Train_accy 41.16
2022-10-08 04:56:50,354 [foster.py] => Task 3, Epoch 25/34 => Loss 3.639, Loss_clf 0.825, Loss_fe 0.914, Loss_kd 1.468, Train_accy 39.06
2022-10-08 04:56:56,014 [foster.py] => Task 3, Epoch 26/34 => Loss 3.525, Loss_clf 0.766, Loss_fe 0.856, Loss_kd 1.470, Train_accy 40.51, Test_accy 42.38
2022-10-08 04:57:00,375 [foster.py] => Task 3, Epoch 27/34 => Loss 3.504, Loss_clf 0.748, Loss_fe 0.836, Loss_kd 1.483, Train_accy 39.64
2022-10-08 04:57:04,764 [foster.py] => Task 3, Epoch 28/34 => Loss 3.521, Loss_clf 0.768, Loss_fe 0.855, Loss_kd 1.467, Train_accy 39.86
2022-10-08 04:57:09,267 [foster.py] => Task 3, Epoch 29/34 => Loss 3.525, Loss_clf 0.768, Loss_fe 0.849, Loss_kd 1.475, Train_accy 39.86
2022-10-08 04:57:13,723 [foster.py] => Task 3, Epoch 30/34 => Loss 3.556, Loss_clf 0.776, Loss_fe 0.869, Loss_kd 1.476, Train_accy 40.72
2022-10-08 04:57:19,343 [foster.py] => Task 3, Epoch 31/34 => Loss 3.570, Loss_clf 0.794, Loss_fe 0.864, Loss_kd 1.478, Train_accy 39.64, Test_accy 41.58
2022-10-08 04:57:23,338 [foster.py] => Task 3, Epoch 32/34 => Loss 3.512, Loss_clf 0.760, Loss_fe 0.850, Loss_kd 1.469, Train_accy 39.06
2022-10-08 04:57:27,574 [foster.py] => Task 3, Epoch 33/34 => Loss 3.512, Loss_clf 0.762, Loss_fe 0.842, Loss_kd 1.474, Train_accy 39.64
2022-10-08 04:57:31,789 [foster.py] => Task 3, Epoch 34/34 => Loss 3.513, Loss_clf 0.754, Loss_fe 0.857, Loss_kd 1.470, Train_accy 38.84
2022-10-08 04:57:31,789 [foster.py] => do not weight align teacher!
2022-10-08 04:57:31,790 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 04:57:38,066 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.430,  Train_accy 12.46, Test_accy 31.88
2022-10-08 04:57:43,115 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.371,  Train_accy 13.04
2022-10-08 04:57:48,262 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.341,  Train_accy 13.41
2022-10-08 04:57:53,265 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.337,  Train_accy 13.41
2022-10-08 04:57:58,338 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.336,  Train_accy 13.41
2022-10-08 04:58:04,462 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.318,  Train_accy 13.33, Test_accy 33.07
2022-10-08 04:58:08,989 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.319,  Train_accy 13.91
2022-10-08 04:58:14,023 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.311,  Train_accy 13.55
2022-10-08 04:58:19,080 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.300,  Train_accy 13.91
2022-10-08 04:58:24,160 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.291,  Train_accy 13.70
2022-10-08 04:58:30,125 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.304,  Train_accy 13.84, Test_accy 34.06
2022-10-08 04:58:35,254 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.280,  Train_accy 14.42
2022-10-08 04:58:40,351 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.287,  Train_accy 13.77
2022-10-08 04:58:45,330 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.293,  Train_accy 14.49
2022-10-08 04:58:50,477 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.282,  Train_accy 13.99
2022-10-08 04:58:56,427 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.279,  Train_accy 14.57, Test_accy 34.26
2022-10-08 04:59:01,556 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.274,  Train_accy 14.42
2022-10-08 04:59:06,593 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.283,  Train_accy 14.13
2022-10-08 04:59:11,640 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.287,  Train_accy 14.64
2022-10-08 04:59:16,807 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.280,  Train_accy 14.13
2022-10-08 04:59:22,967 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.280,  Train_accy 14.42, Test_accy 34.46
2022-10-08 04:59:28,083 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.268,  Train_accy 14.49
2022-10-08 04:59:33,130 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.279,  Train_accy 14.28
2022-10-08 04:59:38,161 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.290,  Train_accy 14.57
2022-10-08 04:59:43,223 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.268,  Train_accy 14.42
2022-10-08 04:59:49,292 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.279,  Train_accy 14.78, Test_accy 33.86
2022-10-08 04:59:49,293 [foster.py] => do not weight align student!
2022-10-08 04:59:50,300 [foster.py] => darknet eval: 
2022-10-08 04:59:50,301 [foster.py] => CNN top1 curve: 33.86
2022-10-08 04:59:50,301 [foster.py] => CNN top5 curve: 83.56
2022-10-08 04:59:50,301 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 05:00:02,806 [foster.py] => Exemplar size: 440
2022-10-08 05:00:02,806 [trainer.py] => CNN: {'total': 42.57, 'old': 47.0, 'new': 25.71, 'base': 74.68, 'compound': 27.95}
2022-10-08 05:00:02,806 [trainer.py] => CNN top1 curve: [86.08, 60.89, 47.75, 42.57]
2022-10-08 05:00:02,806 [trainer.py] => CNN base curve: [86.08, 76.58, 76.58, 74.68]
2022-10-08 05:00:02,806 [trainer.py] => CNN old curve: [86.08, 76.58, 57.93, 47.0]
2022-10-08 05:00:02,806 [trainer.py] => CNN new curve: [0, 38.94, 26.36, 25.71]
2022-10-08 05:00:02,807 [trainer.py] => CNN compound curve: [0, 38.94, 28.93, 27.95]
2022-10-08 05:00:02,807 [trainer.py] => NME: {'total': 53.47, 'old': 55.25, 'new': 46.67, 'base': 67.72, 'compound': 46.97}
2022-10-08 05:00:02,807 [trainer.py] => NME top1 curve: [85.44, 68.27, 60.5, 53.47]
2022-10-08 05:00:02,807 [trainer.py] => NME base curve: [85.44, 74.68, 70.25, 67.72]
2022-10-08 05:00:02,807 [trainer.py] => NME old curve: [85.44, 74.68, 62.73, 55.25]
2022-10-08 05:00:02,807 [trainer.py] => NME new curve: [0, 59.29, 55.81, 46.67]
2022-10-08 05:00:02,807 [trainer.py] => NME compound curve: [0, 59.29, 54.13, 46.97]
2022-10-08 05:00:02,808 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 05:00:02,808 [trainer.py] => prefix: cil
2022-10-08 05:00:02,808 [trainer.py] => dataset: CFEE
2022-10-08 05:00:02,808 [trainer.py] => memory_size: 2000
2022-10-08 05:00:02,808 [trainer.py] => memory_per_class: 20
2022-10-08 05:00:02,808 [trainer.py] => fixed_memory: True
2022-10-08 05:00:02,808 [trainer.py] => shuffle: True
2022-10-08 05:00:02,808 [trainer.py] => init_cls: 7
2022-10-08 05:00:02,808 [trainer.py] => increment: 5
2022-10-08 05:00:02,808 [trainer.py] => model_name: foster
2022-10-08 05:00:02,809 [trainer.py] => convnet_type: resnet18
2022-10-08 05:00:02,809 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 05:00:02,809 [trainer.py] => seed: 1993
2022-10-08 05:00:02,809 [trainer.py] => beta1: 0.96
2022-10-08 05:00:02,809 [trainer.py] => beta2: 0.97
2022-10-08 05:00:02,809 [trainer.py] => oofc: ft
2022-10-08 05:00:02,809 [trainer.py] => is_teacher_wa: False
2022-10-08 05:00:02,809 [trainer.py] => is_student_wa: False
2022-10-08 05:00:02,809 [trainer.py] => lambda_okd: 1
2022-10-08 05:00:02,809 [trainer.py] => wa_value: 1
2022-10-08 05:00:02,809 [trainer.py] => init_epochs: 40
2022-10-08 05:00:02,809 [trainer.py] => init_lr: 0.01
2022-10-08 05:00:02,809 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 05:00:02,809 [trainer.py] => boosting_epochs: 34
2022-10-08 05:00:02,809 [trainer.py] => compression_epochs: 26
2022-10-08 05:00:02,809 [trainer.py] => lr: 0.001
2022-10-08 05:00:02,809 [trainer.py] => batch_size: 32
2022-10-08 05:00:02,809 [trainer.py] => weight_decay: 0.0005
2022-10-08 05:00:02,809 [trainer.py] => num_workers: 8
2022-10-08 05:00:02,809 [trainer.py] => T: 2
2022-10-08 05:00:02,809 [trainer.py] => nb_runs: 3
2022-10-08 05:00:02,809 [trainer.py] => fold: 10
2022-10-08 05:00:02,809 [data.py] => ========== Fold:3 ==========
2022-10-08 05:00:02,815 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 13, 17, 15, 9, 11, 20, 18, 12, 14, 7, 10, 19, 21, 16, 8]
2022-10-08 05:00:03,067 [foster.py] => Learning on 0-7
2022-10-08 05:00:03,068 [foster.py] => All params: 11183694
2022-10-08 05:00:03,068 [foster.py] => Trainable params: 11183694
2022-10-08 05:00:05,977 [foster.py] => Task 0, Epoch 1/40 => Loss 1.359, Train_accy 51.40
2022-10-08 05:00:09,906 [foster.py] => Task 0, Epoch 2/40 => Loss 0.533, Train_accy 80.95, Test_accy 83.24
2022-10-08 05:00:13,590 [foster.py] => Task 0, Epoch 3/40 => Loss 0.374, Train_accy 87.04, Test_accy 82.68
2022-10-08 05:00:17,242 [foster.py] => Task 0, Epoch 4/40 => Loss 0.266, Train_accy 90.83, Test_accy 84.92
2022-10-08 05:00:21,039 [foster.py] => Task 0, Epoch 5/40 => Loss 0.214, Train_accy 92.93, Test_accy 87.71
2022-10-08 05:00:24,105 [foster.py] => Task 0, Epoch 6/40 => Loss 0.203, Train_accy 92.93
2022-10-08 05:00:28,020 [foster.py] => Task 0, Epoch 7/40 => Loss 0.144, Train_accy 95.52, Test_accy 86.59
2022-10-08 05:00:31,733 [foster.py] => Task 0, Epoch 8/40 => Loss 0.120, Train_accy 95.87, Test_accy 86.59
2022-10-08 05:00:35,694 [foster.py] => Task 0, Epoch 9/40 => Loss 0.103, Train_accy 96.64, Test_accy 87.15
2022-10-08 05:00:39,574 [foster.py] => Task 0, Epoch 10/40 => Loss 0.088, Train_accy 96.92, Test_accy 84.36
2022-10-08 05:00:42,705 [foster.py] => Task 0, Epoch 11/40 => Loss 0.090, Train_accy 97.48
2022-10-08 05:00:46,981 [foster.py] => Task 0, Epoch 12/40 => Loss 0.060, Train_accy 98.53, Test_accy 84.36
2022-10-08 05:00:50,913 [foster.py] => Task 0, Epoch 13/40 => Loss 0.059, Train_accy 98.74, Test_accy 85.47
2022-10-08 05:00:54,616 [foster.py] => Task 0, Epoch 14/40 => Loss 0.055, Train_accy 98.53, Test_accy 84.92
2022-10-08 05:00:58,295 [foster.py] => Task 0, Epoch 15/40 => Loss 0.043, Train_accy 98.74, Test_accy 86.59
2022-10-08 05:01:01,544 [foster.py] => Task 0, Epoch 16/40 => Loss 0.047, Train_accy 98.74
2022-10-08 05:01:05,348 [foster.py] => Task 0, Epoch 17/40 => Loss 0.040, Train_accy 99.02, Test_accy 86.03
2022-10-08 05:01:09,341 [foster.py] => Task 0, Epoch 18/40 => Loss 0.037, Train_accy 99.16, Test_accy 87.71
2022-10-08 05:01:13,226 [foster.py] => Task 0, Epoch 19/40 => Loss 0.033, Train_accy 99.44, Test_accy 87.71
2022-10-08 05:01:17,107 [foster.py] => Task 0, Epoch 20/40 => Loss 0.030, Train_accy 99.37, Test_accy 88.83
2022-10-08 05:01:20,120 [foster.py] => Task 0, Epoch 21/40 => Loss 0.020, Train_accy 99.72
2022-10-08 05:01:24,104 [foster.py] => Task 0, Epoch 22/40 => Loss 0.026, Train_accy 99.30, Test_accy 87.15
2022-10-08 05:01:28,098 [foster.py] => Task 0, Epoch 23/40 => Loss 0.018, Train_accy 99.79, Test_accy 86.59
2022-10-08 05:01:31,978 [foster.py] => Task 0, Epoch 24/40 => Loss 0.021, Train_accy 99.65, Test_accy 87.15
2022-10-08 05:01:35,855 [foster.py] => Task 0, Epoch 25/40 => Loss 0.018, Train_accy 99.58, Test_accy 86.59
2022-10-08 05:01:39,124 [foster.py] => Task 0, Epoch 26/40 => Loss 0.020, Train_accy 99.58
2022-10-08 05:01:43,064 [foster.py] => Task 0, Epoch 27/40 => Loss 0.019, Train_accy 99.65, Test_accy 87.15
2022-10-08 05:01:46,926 [foster.py] => Task 0, Epoch 28/40 => Loss 0.018, Train_accy 99.51, Test_accy 87.15
2022-10-08 05:01:50,885 [foster.py] => Task 0, Epoch 29/40 => Loss 0.015, Train_accy 99.86, Test_accy 86.59
2022-10-08 05:01:54,775 [foster.py] => Task 0, Epoch 30/40 => Loss 0.016, Train_accy 99.72, Test_accy 87.71
2022-10-08 05:01:57,742 [foster.py] => Task 0, Epoch 31/40 => Loss 0.013, Train_accy 99.86
2022-10-08 05:02:01,561 [foster.py] => Task 0, Epoch 32/40 => Loss 0.016, Train_accy 99.72, Test_accy 87.71
2022-10-08 05:02:05,396 [foster.py] => Task 0, Epoch 33/40 => Loss 0.018, Train_accy 99.51, Test_accy 87.71
2022-10-08 05:02:09,226 [foster.py] => Task 0, Epoch 34/40 => Loss 0.016, Train_accy 99.65, Test_accy 88.27
2022-10-08 05:02:13,251 [foster.py] => Task 0, Epoch 35/40 => Loss 0.010, Train_accy 100.00, Test_accy 87.15
2022-10-08 05:02:16,417 [foster.py] => Task 0, Epoch 36/40 => Loss 0.011, Train_accy 100.00
2022-10-08 05:02:20,502 [foster.py] => Task 0, Epoch 37/40 => Loss 0.013, Train_accy 99.93, Test_accy 87.71
2022-10-08 05:02:24,604 [foster.py] => Task 0, Epoch 38/40 => Loss 0.012, Train_accy 99.93, Test_accy 87.71
2022-10-08 05:02:28,331 [foster.py] => Task 0, Epoch 39/40 => Loss 0.014, Train_accy 99.86, Test_accy 87.71
2022-10-08 05:02:32,119 [foster.py] => Task 0, Epoch 40/40 => Loss 0.014, Train_accy 99.86, Test_accy 87.15
2022-10-08 05:02:32,119 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 05:02:39,512 [foster.py] => Exemplar size: 140
2022-10-08 05:02:39,512 [trainer.py] => CNN: {'total': 87.15, 'old': 87.15, 'new': 0, 'base': 87.15, 'compound': 0}
2022-10-08 05:02:39,512 [trainer.py] => CNN top1 curve: [87.15]
2022-10-08 05:02:39,512 [trainer.py] => CNN base curve: [87.15]
2022-10-08 05:02:39,512 [trainer.py] => CNN old curve: [87.15]
2022-10-08 05:02:39,512 [trainer.py] => CNN new curve: [0]
2022-10-08 05:02:39,512 [trainer.py] => CNN compound curve: [0]
2022-10-08 05:02:39,512 [trainer.py] => NME: {'total': 87.15, 'old': 87.15, 'new': 0, 'base': 87.15, 'compound': 0}
2022-10-08 05:02:39,512 [trainer.py] => NME top1 curve: [87.15]
2022-10-08 05:02:39,512 [trainer.py] => NME base curve: [87.15]
2022-10-08 05:02:39,512 [trainer.py] => NME old curve: [87.15]
2022-10-08 05:02:39,512 [trainer.py] => NME new curve: [0]
2022-10-08 05:02:39,512 [trainer.py] => NME compound curve: [0]
2022-10-08 05:02:39,759 [foster.py] => Learning on 7-12
2022-10-08 05:02:39,760 [foster.py] => All params: 22375071
2022-10-08 05:02:39,760 [foster.py] => Trainable params: 11194968
2022-10-08 05:02:39,773 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 05:02:43,461 [foster.py] => Task 1, Epoch 1/34 => Loss 4.982, Loss_clf 2.339, Loss_fe 2.015, Loss_kd 0.366, Train_accy 34.27, Test_accy 63.76
2022-10-08 05:02:46,631 [foster.py] => Task 1, Epoch 2/34 => Loss 2.574, Loss_clf 0.748, Loss_fe 1.199, Loss_kd 0.365, Train_accy 60.81
2022-10-08 05:02:50,183 [foster.py] => Task 1, Epoch 3/34 => Loss 2.174, Loss_clf 0.598, Loss_fe 0.967, Loss_kd 0.355, Train_accy 47.58
2022-10-08 05:02:53,570 [foster.py] => Task 1, Epoch 4/34 => Loss 1.997, Loss_clf 0.542, Loss_fe 0.841, Loss_kd 0.358, Train_accy 47.84
2022-10-08 05:02:56,797 [foster.py] => Task 1, Epoch 5/34 => Loss 1.925, Loss_clf 0.530, Loss_fe 0.778, Loss_kd 0.360, Train_accy 47.16
2022-10-08 05:03:01,245 [foster.py] => Task 1, Epoch 6/34 => Loss 1.801, Loss_clf 0.486, Loss_fe 0.706, Loss_kd 0.355, Train_accy 48.35, Test_accy 63.41
2022-10-08 05:03:04,844 [foster.py] => Task 1, Epoch 7/34 => Loss 1.750, Loss_clf 0.478, Loss_fe 0.667, Loss_kd 0.352, Train_accy 48.09
2022-10-08 05:03:08,415 [foster.py] => Task 1, Epoch 8/34 => Loss 1.752, Loss_clf 0.480, Loss_fe 0.662, Loss_kd 0.356, Train_accy 48.18
2022-10-08 05:03:11,979 [foster.py] => Task 1, Epoch 9/34 => Loss 1.637, Loss_clf 0.439, Loss_fe 0.601, Loss_kd 0.349, Train_accy 47.75
2022-10-08 05:03:15,442 [foster.py] => Task 1, Epoch 10/34 => Loss 1.642, Loss_clf 0.447, Loss_fe 0.587, Loss_kd 0.355, Train_accy 50.64
2022-10-08 05:03:19,969 [foster.py] => Task 1, Epoch 11/34 => Loss 1.586, Loss_clf 0.423, Loss_fe 0.557, Loss_kd 0.354, Train_accy 49.02, Test_accy 64.46
2022-10-08 05:03:23,461 [foster.py] => Task 1, Epoch 12/34 => Loss 1.582, Loss_clf 0.427, Loss_fe 0.550, Loss_kd 0.353, Train_accy 49.11
2022-10-08 05:03:26,953 [foster.py] => Task 1, Epoch 13/34 => Loss 1.553, Loss_clf 0.412, Loss_fe 0.536, Loss_kd 0.353, Train_accy 48.18
2022-10-08 05:03:30,431 [foster.py] => Task 1, Epoch 14/34 => Loss 1.518, Loss_clf 0.398, Loss_fe 0.513, Loss_kd 0.354, Train_accy 48.94
2022-10-08 05:03:33,941 [foster.py] => Task 1, Epoch 15/34 => Loss 1.507, Loss_clf 0.398, Loss_fe 0.499, Loss_kd 0.356, Train_accy 50.72
2022-10-08 05:03:38,561 [foster.py] => Task 1, Epoch 16/34 => Loss 1.472, Loss_clf 0.382, Loss_fe 0.480, Loss_kd 0.356, Train_accy 51.06, Test_accy 65.16
2022-10-08 05:03:41,977 [foster.py] => Task 1, Epoch 17/34 => Loss 1.458, Loss_clf 0.377, Loss_fe 0.472, Loss_kd 0.355, Train_accy 51.74
2022-10-08 05:03:45,779 [foster.py] => Task 1, Epoch 18/34 => Loss 1.445, Loss_clf 0.363, Loss_fe 0.473, Loss_kd 0.355, Train_accy 49.87
2022-10-08 05:03:49,335 [foster.py] => Task 1, Epoch 19/34 => Loss 1.444, Loss_clf 0.367, Loss_fe 0.470, Loss_kd 0.354, Train_accy 50.72
2022-10-08 05:03:53,067 [foster.py] => Task 1, Epoch 20/34 => Loss 1.386, Loss_clf 0.350, Loss_fe 0.434, Loss_kd 0.351, Train_accy 51.23
2022-10-08 05:03:57,878 [foster.py] => Task 1, Epoch 21/34 => Loss 1.426, Loss_clf 0.364, Loss_fe 0.456, Loss_kd 0.353, Train_accy 50.81, Test_accy 65.51
2022-10-08 05:04:01,348 [foster.py] => Task 1, Epoch 22/34 => Loss 1.390, Loss_clf 0.350, Loss_fe 0.443, Loss_kd 0.349, Train_accy 51.06
2022-10-08 05:04:04,986 [foster.py] => Task 1, Epoch 23/34 => Loss 1.369, Loss_clf 0.335, Loss_fe 0.425, Loss_kd 0.355, Train_accy 51.91
2022-10-08 05:04:08,683 [foster.py] => Task 1, Epoch 24/34 => Loss 1.404, Loss_clf 0.356, Loss_fe 0.436, Loss_kd 0.357, Train_accy 50.38
2022-10-08 05:04:12,428 [foster.py] => Task 1, Epoch 25/34 => Loss 1.379, Loss_clf 0.341, Loss_fe 0.431, Loss_kd 0.354, Train_accy 51.99
2022-10-08 05:04:17,697 [foster.py] => Task 1, Epoch 26/34 => Loss 1.376, Loss_clf 0.342, Loss_fe 0.421, Loss_kd 0.357, Train_accy 52.42, Test_accy 64.81
2022-10-08 05:04:26,585 [foster.py] => Task 1, Epoch 27/34 => Loss 1.354, Loss_clf 0.331, Loss_fe 0.417, Loss_kd 0.353, Train_accy 51.15
2022-10-08 05:04:33,119 [foster.py] => Task 1, Epoch 28/34 => Loss 1.343, Loss_clf 0.324, Loss_fe 0.414, Loss_kd 0.353, Train_accy 51.74
2022-10-08 05:04:38,293 [foster.py] => Task 1, Epoch 29/34 => Loss 1.357, Loss_clf 0.327, Loss_fe 0.418, Loss_kd 0.357, Train_accy 52.25
2022-10-08 05:04:42,715 [foster.py] => Task 1, Epoch 30/34 => Loss 1.361, Loss_clf 0.334, Loss_fe 0.419, Loss_kd 0.355, Train_accy 52.08
2022-10-08 05:04:47,634 [foster.py] => Task 1, Epoch 31/34 => Loss 1.365, Loss_clf 0.338, Loss_fe 0.421, Loss_kd 0.353, Train_accy 51.23, Test_accy 64.11
2022-10-08 05:04:51,070 [foster.py] => Task 1, Epoch 32/34 => Loss 1.347, Loss_clf 0.326, Loss_fe 0.414, Loss_kd 0.354, Train_accy 51.74
2022-10-08 05:04:54,428 [foster.py] => Task 1, Epoch 33/34 => Loss 1.346, Loss_clf 0.328, Loss_fe 0.410, Loss_kd 0.355, Train_accy 51.82
2022-10-08 05:04:57,498 [foster.py] => Task 1, Epoch 34/34 => Loss 1.320, Loss_clf 0.315, Loss_fe 0.397, Loss_kd 0.355, Train_accy 52.93
2022-10-08 05:04:57,499 [foster.py] => do not weight align teacher!
2022-10-08 05:04:57,499 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 05:05:02,237 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.653,  Train_accy 11.79, Test_accy 51.57
2022-10-08 05:05:06,662 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.527,  Train_accy 12.04
2022-10-08 05:05:10,686 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.474,  Train_accy 12.98
2022-10-08 05:05:14,651 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.450,  Train_accy 14.93
2022-10-08 05:05:19,191 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.419,  Train_accy 16.12
2022-10-08 05:05:24,541 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.390,  Train_accy 17.56, Test_accy 57.49
2022-10-08 05:05:28,534 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.390,  Train_accy 19.17
2022-10-08 05:05:32,679 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.382,  Train_accy 18.49
2022-10-08 05:05:36,744 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.357,  Train_accy 20.87
2022-10-08 05:05:41,379 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.358,  Train_accy 22.14
2022-10-08 05:05:46,811 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.348,  Train_accy 21.97, Test_accy 58.19
2022-10-08 05:05:51,301 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.337,  Train_accy 21.20
2022-10-08 05:05:55,847 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.345,  Train_accy 23.49
2022-10-08 05:06:00,383 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.337,  Train_accy 22.65
2022-10-08 05:06:04,896 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.332,  Train_accy 24.77
2022-10-08 05:06:10,165 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.333,  Train_accy 25.28, Test_accy 58.89
2022-10-08 05:06:14,667 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.331,  Train_accy 24.77
2022-10-08 05:06:19,154 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.315,  Train_accy 24.51
2022-10-08 05:06:23,770 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.322,  Train_accy 23.83
2022-10-08 05:06:28,335 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.316,  Train_accy 25.61
2022-10-08 05:06:33,724 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.312,  Train_accy 24.60, Test_accy 59.58
2022-10-08 05:06:38,329 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.322,  Train_accy 26.12
2022-10-08 05:06:42,870 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.323,  Train_accy 25.02
2022-10-08 05:06:47,406 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.311,  Train_accy 25.36
2022-10-08 05:06:52,035 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.334,  Train_accy 25.36
2022-10-08 05:06:57,405 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.313,  Train_accy 24.94, Test_accy 59.93
2022-10-08 05:06:57,405 [foster.py] => do not weight align student!
2022-10-08 05:06:58,188 [foster.py] => darknet eval: 
2022-10-08 05:06:58,188 [foster.py] => CNN top1 curve: 59.93
2022-10-08 05:06:58,189 [foster.py] => CNN top5 curve: 96.86
2022-10-08 05:06:58,189 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 05:07:06,880 [foster.py] => Exemplar size: 240
2022-10-08 05:07:06,880 [trainer.py] => CNN: {'total': 64.81, 'old': 79.89, 'new': 39.81, 'base': 79.89, 'compound': 39.81}
2022-10-08 05:07:06,880 [trainer.py] => CNN top1 curve: [87.15, 64.81]
2022-10-08 05:07:06,880 [trainer.py] => CNN base curve: [87.15, 79.89]
2022-10-08 05:07:06,880 [trainer.py] => CNN old curve: [87.15, 79.89]
2022-10-08 05:07:06,880 [trainer.py] => CNN new curve: [0, 39.81]
2022-10-08 05:07:06,880 [trainer.py] => CNN compound curve: [0, 39.81]
2022-10-08 05:07:06,880 [trainer.py] => NME: {'total': 66.9, 'old': 69.83, 'new': 62.04, 'base': 69.83, 'compound': 62.04}
2022-10-08 05:07:06,880 [trainer.py] => NME top1 curve: [87.15, 66.9]
2022-10-08 05:07:06,880 [trainer.py] => NME base curve: [87.15, 69.83]
2022-10-08 05:07:06,880 [trainer.py] => NME old curve: [87.15, 69.83]
2022-10-08 05:07:06,880 [trainer.py] => NME new curve: [0, 62.04]
2022-10-08 05:07:06,880 [trainer.py] => NME compound curve: [0, 62.04]
2022-10-08 05:07:07,128 [foster.py] => Learning on 12-17
2022-10-08 05:07:07,129 [foster.py] => All params: 22385326
2022-10-08 05:07:07,129 [foster.py] => Trainable params: 11202658
2022-10-08 05:07:07,138 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 05:07:11,324 [foster.py] => Task 2, Epoch 1/34 => Loss 5.802, Loss_clf 2.098, Loss_fe 2.291, Loss_kd 0.997, Train_accy 37.14, Test_accy 47.85
2022-10-08 05:07:14,714 [foster.py] => Task 2, Epoch 2/34 => Loss 3.911, Loss_clf 1.019, Loss_fe 1.550, Loss_kd 0.948, Train_accy 40.97
2022-10-08 05:07:18,099 [foster.py] => Task 2, Epoch 3/34 => Loss 3.552, Loss_clf 0.878, Loss_fe 1.319, Loss_kd 0.956, Train_accy 38.39
2022-10-08 05:07:21,842 [foster.py] => Task 2, Epoch 4/34 => Loss 3.366, Loss_clf 0.830, Loss_fe 1.191, Loss_kd 0.949, Train_accy 38.47
2022-10-08 05:07:25,081 [foster.py] => Task 2, Epoch 5/34 => Loss 3.245, Loss_clf 0.780, Loss_fe 1.106, Loss_kd 0.960, Train_accy 41.28
2022-10-08 05:07:29,739 [foster.py] => Task 2, Epoch 6/34 => Loss 3.135, Loss_clf 0.758, Loss_fe 1.030, Loss_kd 0.951, Train_accy 39.72, Test_accy 53.42
2022-10-08 05:07:33,444 [foster.py] => Task 2, Epoch 7/34 => Loss 3.084, Loss_clf 0.746, Loss_fe 0.982, Loss_kd 0.957, Train_accy 40.89
2022-10-08 05:07:37,270 [foster.py] => Task 2, Epoch 8/34 => Loss 3.027, Loss_clf 0.723, Loss_fe 0.952, Loss_kd 0.954, Train_accy 39.41
2022-10-08 05:07:40,880 [foster.py] => Task 2, Epoch 9/34 => Loss 2.974, Loss_clf 0.717, Loss_fe 0.901, Loss_kd 0.957, Train_accy 42.38
2022-10-08 05:07:44,443 [foster.py] => Task 2, Epoch 10/34 => Loss 2.881, Loss_clf 0.679, Loss_fe 0.853, Loss_kd 0.952, Train_accy 41.20
2022-10-08 05:07:49,157 [foster.py] => Task 2, Epoch 11/34 => Loss 2.872, Loss_clf 0.675, Loss_fe 0.841, Loss_kd 0.957, Train_accy 44.88, Test_accy 53.42
2022-10-08 05:07:52,703 [foster.py] => Task 2, Epoch 12/34 => Loss 2.839, Loss_clf 0.668, Loss_fe 0.820, Loss_kd 0.953, Train_accy 40.42
2022-10-08 05:07:56,814 [foster.py] => Task 2, Epoch 13/34 => Loss 2.789, Loss_clf 0.650, Loss_fe 0.787, Loss_kd 0.954, Train_accy 43.71
2022-10-08 05:08:00,874 [foster.py] => Task 2, Epoch 14/34 => Loss 2.756, Loss_clf 0.635, Loss_fe 0.767, Loss_kd 0.956, Train_accy 42.61
2022-10-08 05:08:04,957 [foster.py] => Task 2, Epoch 15/34 => Loss 2.690, Loss_clf 0.606, Loss_fe 0.738, Loss_kd 0.950, Train_accy 44.49
2022-10-08 05:08:10,302 [foster.py] => Task 2, Epoch 16/34 => Loss 2.706, Loss_clf 0.614, Loss_fe 0.731, Loss_kd 0.961, Train_accy 45.19, Test_accy 54.43
2022-10-08 05:08:14,491 [foster.py] => Task 2, Epoch 17/34 => Loss 2.663, Loss_clf 0.603, Loss_fe 0.712, Loss_kd 0.951, Train_accy 45.04
2022-10-08 05:08:18,577 [foster.py] => Task 2, Epoch 18/34 => Loss 2.649, Loss_clf 0.586, Loss_fe 0.702, Loss_kd 0.960, Train_accy 44.80
2022-10-08 05:08:22,670 [foster.py] => Task 2, Epoch 19/34 => Loss 2.660, Loss_clf 0.594, Loss_fe 0.709, Loss_kd 0.958, Train_accy 45.90
2022-10-08 05:08:26,764 [foster.py] => Task 2, Epoch 20/34 => Loss 2.605, Loss_clf 0.575, Loss_fe 0.677, Loss_kd 0.955, Train_accy 47.30
2022-10-08 05:08:32,017 [foster.py] => Task 2, Epoch 21/34 => Loss 2.608, Loss_clf 0.569, Loss_fe 0.678, Loss_kd 0.961, Train_accy 47.22, Test_accy 55.70
2022-10-08 05:08:36,048 [foster.py] => Task 2, Epoch 22/34 => Loss 2.582, Loss_clf 0.563, Loss_fe 0.662, Loss_kd 0.958, Train_accy 45.74
2022-10-08 05:08:40,108 [foster.py] => Task 2, Epoch 23/34 => Loss 2.569, Loss_clf 0.560, Loss_fe 0.655, Loss_kd 0.956, Train_accy 47.38
2022-10-08 05:08:44,229 [foster.py] => Task 2, Epoch 24/34 => Loss 2.571, Loss_clf 0.557, Loss_fe 0.655, Loss_kd 0.959, Train_accy 46.05
2022-10-08 05:08:48,303 [foster.py] => Task 2, Epoch 25/34 => Loss 2.519, Loss_clf 0.530, Loss_fe 0.624, Loss_kd 0.963, Train_accy 47.15
2022-10-08 05:08:53,565 [foster.py] => Task 2, Epoch 26/34 => Loss 2.551, Loss_clf 0.557, Loss_fe 0.641, Loss_kd 0.955, Train_accy 46.83, Test_accy 54.94
2022-10-08 05:08:57,598 [foster.py] => Task 2, Epoch 27/34 => Loss 2.548, Loss_clf 0.557, Loss_fe 0.639, Loss_kd 0.954, Train_accy 46.05
2022-10-08 05:09:01,558 [foster.py] => Task 2, Epoch 28/34 => Loss 2.531, Loss_clf 0.538, Loss_fe 0.636, Loss_kd 0.957, Train_accy 46.83
2022-10-08 05:09:05,710 [foster.py] => Task 2, Epoch 29/34 => Loss 2.531, Loss_clf 0.533, Loss_fe 0.641, Loss_kd 0.958, Train_accy 47.30
2022-10-08 05:09:09,690 [foster.py] => Task 2, Epoch 30/34 => Loss 2.500, Loss_clf 0.526, Loss_fe 0.624, Loss_kd 0.953, Train_accy 46.68
2022-10-08 05:09:14,872 [foster.py] => Task 2, Epoch 31/34 => Loss 2.524, Loss_clf 0.536, Loss_fe 0.631, Loss_kd 0.958, Train_accy 47.54, Test_accy 55.44
2022-10-08 05:09:18,898 [foster.py] => Task 2, Epoch 32/34 => Loss 2.535, Loss_clf 0.545, Loss_fe 0.627, Loss_kd 0.962, Train_accy 46.76
2022-10-08 05:09:22,975 [foster.py] => Task 2, Epoch 33/34 => Loss 2.542, Loss_clf 0.554, Loss_fe 0.633, Loss_kd 0.956, Train_accy 46.21
2022-10-08 05:09:27,096 [foster.py] => Task 2, Epoch 34/34 => Loss 2.490, Loss_clf 0.525, Loss_fe 0.616, Loss_kd 0.952, Train_accy 46.44
2022-10-08 05:09:27,097 [foster.py] => do not weight align teacher!
2022-10-08 05:09:27,098 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 05:09:32,968 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.072,  Train_accy 11.96, Test_accy 43.54
2022-10-08 05:09:37,226 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.995,  Train_accy 12.04
2022-10-08 05:09:41,526 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.964,  Train_accy 12.35
2022-10-08 05:09:45,942 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.937,  Train_accy 12.59
2022-10-08 05:09:50,438 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.936,  Train_accy 12.67
2022-10-08 05:09:55,954 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.919,  Train_accy 12.59, Test_accy 45.32
2022-10-08 05:10:01,841 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.916,  Train_accy 13.06
2022-10-08 05:10:07,528 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.910,  Train_accy 13.37
2022-10-08 05:10:13,363 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.890,  Train_accy 13.45
2022-10-08 05:10:19,127 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.895,  Train_accy 12.98
2022-10-08 05:10:25,896 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.890,  Train_accy 12.82, Test_accy 44.81
2022-10-08 05:10:31,567 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.884,  Train_accy 13.84
2022-10-08 05:10:37,304 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.878,  Train_accy 13.92
2022-10-08 05:10:42,971 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.885,  Train_accy 13.37
2022-10-08 05:10:48,027 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.878,  Train_accy 14.31
2022-10-08 05:10:53,876 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.872,  Train_accy 14.07, Test_accy 46.33
2022-10-08 05:10:58,035 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.860,  Train_accy 14.00
2022-10-08 05:11:02,121 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.870,  Train_accy 14.62
2022-10-08 05:11:06,323 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.870,  Train_accy 14.62
2022-10-08 05:11:10,788 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.858,  Train_accy 14.46
2022-10-08 05:11:16,417 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.861,  Train_accy 14.54, Test_accy 46.33
2022-10-08 05:11:21,101 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.857,  Train_accy 13.60
2022-10-08 05:11:25,869 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.861,  Train_accy 14.07
2022-10-08 05:11:30,590 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.860,  Train_accy 14.00
2022-10-08 05:11:35,307 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.868,  Train_accy 13.92
2022-10-08 05:11:40,855 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.862,  Train_accy 15.09, Test_accy 46.08
2022-10-08 05:11:40,856 [foster.py] => do not weight align student!
2022-10-08 05:11:41,684 [foster.py] => darknet eval: 
2022-10-08 05:11:41,684 [foster.py] => CNN top1 curve: 46.08
2022-10-08 05:11:41,684 [foster.py] => CNN top5 curve: 94.18
2022-10-08 05:11:41,685 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 05:11:52,238 [foster.py] => Exemplar size: 340
2022-10-08 05:11:52,239 [trainer.py] => CNN: {'total': 55.44, 'old': 59.58, 'new': 44.44, 'base': 79.89, 'compound': 35.19}
2022-10-08 05:11:52,239 [trainer.py] => CNN top1 curve: [87.15, 64.81, 55.44]
2022-10-08 05:11:52,239 [trainer.py] => CNN base curve: [87.15, 79.89, 79.89]
2022-10-08 05:11:52,239 [trainer.py] => CNN old curve: [87.15, 79.89, 59.58]
2022-10-08 05:11:52,239 [trainer.py] => CNN new curve: [0, 39.81, 44.44]
2022-10-08 05:11:52,239 [trainer.py] => CNN compound curve: [0, 39.81, 35.19]
2022-10-08 05:11:52,239 [trainer.py] => NME: {'total': 60.51, 'old': 58.89, 'new': 64.81, 'base': 63.69, 'compound': 57.87}
2022-10-08 05:11:52,239 [trainer.py] => NME top1 curve: [87.15, 66.9, 60.51]
2022-10-08 05:11:52,239 [trainer.py] => NME base curve: [87.15, 69.83, 63.69]
2022-10-08 05:11:52,239 [trainer.py] => NME old curve: [87.15, 69.83, 58.89]
2022-10-08 05:11:52,239 [trainer.py] => NME new curve: [0, 62.04, 64.81]
2022-10-08 05:11:52,239 [trainer.py] => NME compound curve: [0, 62.04, 57.87]
2022-10-08 05:11:52,505 [foster.py] => Learning on 17-22
2022-10-08 05:11:52,506 [foster.py] => All params: 22395581
2022-10-08 05:11:52,507 [foster.py] => Trainable params: 11210348
2022-10-08 05:11:52,523 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 05:11:57,271 [foster.py] => Task 3, Epoch 1/34 => Loss 6.614, Loss_clf 2.139, Loss_fe 2.486, Loss_kd 1.538, Train_accy 32.95, Test_accy 39.80
2022-10-08 05:12:00,859 [foster.py] => Task 3, Epoch 2/34 => Loss 4.999, Loss_clf 1.262, Loss_fe 1.791, Loss_kd 1.504, Train_accy 31.42
2022-10-08 05:12:04,572 [foster.py] => Task 3, Epoch 3/34 => Loss 4.683, Loss_clf 1.138, Loss_fe 1.593, Loss_kd 1.509, Train_accy 34.47
2022-10-08 05:12:08,299 [foster.py] => Task 3, Epoch 4/34 => Loss 4.519, Loss_clf 1.088, Loss_fe 1.480, Loss_kd 1.508, Train_accy 35.85
2022-10-08 05:12:12,009 [foster.py] => Task 3, Epoch 5/34 => Loss 4.372, Loss_clf 1.046, Loss_fe 1.374, Loss_kd 1.508, Train_accy 35.49
2022-10-08 05:12:17,074 [foster.py] => Task 3, Epoch 6/34 => Loss 4.273, Loss_clf 1.021, Loss_fe 1.312, Loss_kd 1.499, Train_accy 35.71, Test_accy 44.95
2022-10-08 05:12:21,050 [foster.py] => Task 3, Epoch 7/34 => Loss 4.200, Loss_clf 1.002, Loss_fe 1.252, Loss_kd 1.503, Train_accy 37.09
2022-10-08 05:12:25,025 [foster.py] => Task 3, Epoch 8/34 => Loss 4.126, Loss_clf 0.972, Loss_fe 1.199, Loss_kd 1.511, Train_accy 38.47
2022-10-08 05:12:29,025 [foster.py] => Task 3, Epoch 9/34 => Loss 4.052, Loss_clf 0.942, Loss_fe 1.150, Loss_kd 1.514, Train_accy 37.09
2022-10-08 05:12:33,099 [foster.py] => Task 3, Epoch 10/34 => Loss 4.039, Loss_clf 0.954, Loss_fe 1.132, Loss_kd 1.509, Train_accy 38.84
2022-10-08 05:12:38,164 [foster.py] => Task 3, Epoch 11/34 => Loss 3.958, Loss_clf 0.922, Loss_fe 1.079, Loss_kd 1.512, Train_accy 39.56, Test_accy 47.33
2022-10-08 05:12:42,071 [foster.py] => Task 3, Epoch 12/34 => Loss 3.938, Loss_clf 0.919, Loss_fe 1.065, Loss_kd 1.509, Train_accy 39.42
2022-10-08 05:12:46,061 [foster.py] => Task 3, Epoch 13/34 => Loss 3.860, Loss_clf 0.875, Loss_fe 1.031, Loss_kd 1.510, Train_accy 41.16
2022-10-08 05:12:49,913 [foster.py] => Task 3, Epoch 14/34 => Loss 3.849, Loss_clf 0.875, Loss_fe 1.025, Loss_kd 1.506, Train_accy 39.35
2022-10-08 05:12:54,418 [foster.py] => Task 3, Epoch 15/34 => Loss 3.820, Loss_clf 0.867, Loss_fe 1.001, Loss_kd 1.508, Train_accy 39.71
2022-10-08 05:13:01,257 [foster.py] => Task 3, Epoch 16/34 => Loss 3.773, Loss_clf 0.853, Loss_fe 0.970, Loss_kd 1.507, Train_accy 41.45, Test_accy 46.34
2022-10-08 05:13:06,642 [foster.py] => Task 3, Epoch 17/34 => Loss 3.731, Loss_clf 0.841, Loss_fe 0.941, Loss_kd 1.506, Train_accy 40.73
2022-10-08 05:13:11,982 [foster.py] => Task 3, Epoch 18/34 => Loss 3.734, Loss_clf 0.840, Loss_fe 0.939, Loss_kd 1.511, Train_accy 42.04
2022-10-08 05:13:16,542 [foster.py] => Task 3, Epoch 19/34 => Loss 3.677, Loss_clf 0.807, Loss_fe 0.914, Loss_kd 1.512, Train_accy 42.98
2022-10-08 05:13:21,188 [foster.py] => Task 3, Epoch 20/34 => Loss 3.682, Loss_clf 0.824, Loss_fe 0.914, Loss_kd 1.502, Train_accy 43.27
2022-10-08 05:13:27,254 [foster.py] => Task 3, Epoch 21/34 => Loss 3.671, Loss_clf 0.806, Loss_fe 0.910, Loss_kd 1.511, Train_accy 41.60, Test_accy 47.13
2022-10-08 05:13:31,346 [foster.py] => Task 3, Epoch 22/34 => Loss 3.597, Loss_clf 0.775, Loss_fe 0.872, Loss_kd 1.507, Train_accy 43.20
2022-10-08 05:13:35,443 [foster.py] => Task 3, Epoch 23/34 => Loss 3.633, Loss_clf 0.789, Loss_fe 0.883, Loss_kd 1.515, Train_accy 41.96
2022-10-08 05:13:39,583 [foster.py] => Task 3, Epoch 24/34 => Loss 3.624, Loss_clf 0.783, Loss_fe 0.876, Loss_kd 1.518, Train_accy 43.20
2022-10-08 05:13:43,748 [foster.py] => Task 3, Epoch 25/34 => Loss 3.613, Loss_clf 0.785, Loss_fe 0.880, Loss_kd 1.506, Train_accy 42.25
2022-10-08 05:13:49,263 [foster.py] => Task 3, Epoch 26/34 => Loss 3.582, Loss_clf 0.774, Loss_fe 0.855, Loss_kd 1.509, Train_accy 43.49, Test_accy 47.52
2022-10-08 05:13:53,363 [foster.py] => Task 3, Epoch 27/34 => Loss 3.562, Loss_clf 0.770, Loss_fe 0.844, Loss_kd 1.506, Train_accy 44.22
2022-10-08 05:13:57,549 [foster.py] => Task 3, Epoch 28/34 => Loss 3.572, Loss_clf 0.763, Loss_fe 0.853, Loss_kd 1.512, Train_accy 43.49
2022-10-08 05:14:01,203 [foster.py] => Task 3, Epoch 29/34 => Loss 3.583, Loss_clf 0.770, Loss_fe 0.851, Loss_kd 1.516, Train_accy 43.93
2022-10-08 05:14:05,437 [foster.py] => Task 3, Epoch 30/34 => Loss 3.547, Loss_clf 0.756, Loss_fe 0.835, Loss_kd 1.512, Train_accy 42.25
2022-10-08 05:14:10,657 [foster.py] => Task 3, Epoch 31/34 => Loss 3.571, Loss_clf 0.762, Loss_fe 0.853, Loss_kd 1.511, Train_accy 42.25, Test_accy 47.33
2022-10-08 05:14:14,687 [foster.py] => Task 3, Epoch 32/34 => Loss 3.545, Loss_clf 0.750, Loss_fe 0.830, Loss_kd 1.518, Train_accy 44.00
2022-10-08 05:14:19,149 [foster.py] => Task 3, Epoch 33/34 => Loss 3.565, Loss_clf 0.761, Loss_fe 0.846, Loss_kd 1.513, Train_accy 43.93
2022-10-08 05:14:23,555 [foster.py] => Task 3, Epoch 34/34 => Loss 3.555, Loss_clf 0.760, Loss_fe 0.843, Loss_kd 1.508, Train_accy 43.13
2022-10-08 05:14:23,556 [foster.py] => do not weight align teacher!
2022-10-08 05:14:23,556 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 05:14:29,874 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.456,  Train_accy 12.15, Test_accy 36.83
2022-10-08 05:14:34,612 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.394,  Train_accy 13.24
2022-10-08 05:14:39,271 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.381,  Train_accy 12.87
2022-10-08 05:14:44,311 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.359,  Train_accy 13.38
2022-10-08 05:14:49,428 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.349,  Train_accy 13.53
2022-10-08 05:14:57,010 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.342,  Train_accy 13.67, Test_accy 38.81
2022-10-08 05:15:03,754 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.337,  Train_accy 13.75
2022-10-08 05:15:09,523 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.333,  Train_accy 13.60
2022-10-08 05:15:14,619 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.327,  Train_accy 13.16
2022-10-08 05:15:19,595 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.324,  Train_accy 13.75
2022-10-08 05:15:25,640 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.334,  Train_accy 13.53, Test_accy 39.60
2022-10-08 05:15:30,616 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.326,  Train_accy 13.24
2022-10-08 05:15:35,562 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.321,  Train_accy 13.96
2022-10-08 05:15:40,755 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.314,  Train_accy 13.45
2022-10-08 05:15:45,852 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.320,  Train_accy 13.89
2022-10-08 05:15:51,854 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.310,  Train_accy 13.24, Test_accy 39.80
2022-10-08 05:15:56,934 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.311,  Train_accy 13.67
2022-10-08 05:16:02,065 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.314,  Train_accy 13.60
2022-10-08 05:16:07,146 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.303,  Train_accy 13.53
2022-10-08 05:16:12,132 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.311,  Train_accy 13.09
2022-10-08 05:16:18,214 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.314,  Train_accy 13.75, Test_accy 40.40
2022-10-08 05:16:23,235 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.313,  Train_accy 14.40
2022-10-08 05:16:28,262 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.307,  Train_accy 14.47
2022-10-08 05:16:33,339 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.305,  Train_accy 13.89
2022-10-08 05:16:38,399 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.317,  Train_accy 14.11
2022-10-08 05:16:44,343 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.317,  Train_accy 14.18, Test_accy 40.40
2022-10-08 05:16:44,343 [foster.py] => do not weight align student!
2022-10-08 05:16:45,408 [foster.py] => darknet eval: 
2022-10-08 05:16:45,408 [foster.py] => CNN top1 curve: 40.4
2022-10-08 05:16:45,408 [foster.py] => CNN top5 curve: 83.17
2022-10-08 05:16:45,409 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 05:16:57,601 [foster.py] => Exemplar size: 440
2022-10-08 05:16:57,601 [trainer.py] => CNN: {'total': 47.33, 'old': 52.91, 'new': 27.27, 'base': 76.54, 'compound': 31.29}
2022-10-08 05:16:57,601 [trainer.py] => CNN top1 curve: [87.15, 64.81, 55.44, 47.33]
2022-10-08 05:16:57,601 [trainer.py] => CNN base curve: [87.15, 79.89, 79.89, 76.54]
2022-10-08 05:16:57,601 [trainer.py] => CNN old curve: [87.15, 79.89, 59.58, 52.91]
2022-10-08 05:16:57,601 [trainer.py] => CNN new curve: [0, 39.81, 44.44, 27.27]
2022-10-08 05:16:57,601 [trainer.py] => CNN compound curve: [0, 39.81, 35.19, 31.29]
2022-10-08 05:16:57,601 [trainer.py] => NME: {'total': 53.27, 'old': 56.2, 'new': 42.73, 'base': 62.57, 'compound': 48.16}
2022-10-08 05:16:57,601 [trainer.py] => NME top1 curve: [87.15, 66.9, 60.51, 53.27]
2022-10-08 05:16:57,601 [trainer.py] => NME base curve: [87.15, 69.83, 63.69, 62.57]
2022-10-08 05:16:57,601 [trainer.py] => NME old curve: [87.15, 69.83, 58.89, 56.2]
2022-10-08 05:16:57,601 [trainer.py] => NME new curve: [0, 62.04, 64.81, 42.73]
2022-10-08 05:16:57,601 [trainer.py] => NME compound curve: [0, 62.04, 57.87, 48.16]
2022-10-08 05:16:57,603 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 05:16:57,603 [trainer.py] => prefix: cil
2022-10-08 05:16:57,603 [trainer.py] => dataset: CFEE
2022-10-08 05:16:57,603 [trainer.py] => memory_size: 2000
2022-10-08 05:16:57,603 [trainer.py] => memory_per_class: 20
2022-10-08 05:16:57,603 [trainer.py] => fixed_memory: True
2022-10-08 05:16:57,603 [trainer.py] => shuffle: True
2022-10-08 05:16:57,604 [trainer.py] => init_cls: 7
2022-10-08 05:16:57,604 [trainer.py] => increment: 5
2022-10-08 05:16:57,604 [trainer.py] => model_name: foster
2022-10-08 05:16:57,604 [trainer.py] => convnet_type: resnet18
2022-10-08 05:16:57,604 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 05:16:57,604 [trainer.py] => seed: 1993
2022-10-08 05:16:57,604 [trainer.py] => beta1: 0.96
2022-10-08 05:16:57,604 [trainer.py] => beta2: 0.97
2022-10-08 05:16:57,604 [trainer.py] => oofc: ft
2022-10-08 05:16:57,604 [trainer.py] => is_teacher_wa: False
2022-10-08 05:16:57,604 [trainer.py] => is_student_wa: False
2022-10-08 05:16:57,604 [trainer.py] => lambda_okd: 1
2022-10-08 05:16:57,604 [trainer.py] => wa_value: 1
2022-10-08 05:16:57,604 [trainer.py] => init_epochs: 40
2022-10-08 05:16:57,604 [trainer.py] => init_lr: 0.01
2022-10-08 05:16:57,604 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 05:16:57,604 [trainer.py] => boosting_epochs: 34
2022-10-08 05:16:57,604 [trainer.py] => compression_epochs: 26
2022-10-08 05:16:57,604 [trainer.py] => lr: 0.001
2022-10-08 05:16:57,604 [trainer.py] => batch_size: 32
2022-10-08 05:16:57,604 [trainer.py] => weight_decay: 0.0005
2022-10-08 05:16:57,604 [trainer.py] => num_workers: 8
2022-10-08 05:16:57,604 [trainer.py] => T: 2
2022-10-08 05:16:57,604 [trainer.py] => nb_runs: 3
2022-10-08 05:16:57,604 [trainer.py] => fold: 10
2022-10-08 05:16:57,605 [data.py] => ========== Fold:4 ==========
2022-10-08 05:16:57,613 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 13, 17, 15, 9, 11, 20, 18, 12, 14, 7, 10, 19, 21, 16, 8]
2022-10-08 05:16:57,850 [foster.py] => Learning on 0-7
2022-10-08 05:16:57,850 [foster.py] => All params: 11183694
2022-10-08 05:16:57,850 [foster.py] => Trainable params: 11183694
2022-10-08 05:17:00,822 [foster.py] => Task 0, Epoch 1/40 => Loss 1.329, Train_accy 48.74
2022-10-08 05:17:04,456 [foster.py] => Task 0, Epoch 2/40 => Loss 0.532, Train_accy 82.64, Test_accy 79.86
2022-10-08 05:17:08,041 [foster.py] => Task 0, Epoch 3/40 => Loss 0.371, Train_accy 87.90, Test_accy 84.72
2022-10-08 05:17:11,810 [foster.py] => Task 0, Epoch 4/40 => Loss 0.281, Train_accy 90.29, Test_accy 86.11
2022-10-08 05:17:15,590 [foster.py] => Task 0, Epoch 5/40 => Loss 0.200, Train_accy 93.03, Test_accy 84.72
2022-10-08 05:17:18,581 [foster.py] => Task 0, Epoch 6/40 => Loss 0.187, Train_accy 93.44
2022-10-08 05:17:22,625 [foster.py] => Task 0, Epoch 7/40 => Loss 0.168, Train_accy 94.53, Test_accy 85.42
2022-10-08 05:17:26,718 [foster.py] => Task 0, Epoch 8/40 => Loss 0.132, Train_accy 95.69, Test_accy 88.19
2022-10-08 05:17:30,578 [foster.py] => Task 0, Epoch 9/40 => Loss 0.100, Train_accy 97.20, Test_accy 87.50
2022-10-08 05:17:34,756 [foster.py] => Task 0, Epoch 10/40 => Loss 0.082, Train_accy 97.61, Test_accy 88.19
2022-10-08 05:17:37,972 [foster.py] => Task 0, Epoch 11/40 => Loss 0.083, Train_accy 97.61
2022-10-08 05:17:41,922 [foster.py] => Task 0, Epoch 12/40 => Loss 0.068, Train_accy 98.29, Test_accy 86.11
2022-10-08 05:17:45,903 [foster.py] => Task 0, Epoch 13/40 => Loss 0.058, Train_accy 98.43, Test_accy 85.42
2022-10-08 05:17:49,772 [foster.py] => Task 0, Epoch 14/40 => Loss 0.046, Train_accy 99.18, Test_accy 86.81
2022-10-08 05:17:53,522 [foster.py] => Task 0, Epoch 15/40 => Loss 0.046, Train_accy 98.77, Test_accy 88.19
2022-10-08 05:17:57,081 [foster.py] => Task 0, Epoch 16/40 => Loss 0.028, Train_accy 99.52
2022-10-08 05:18:00,980 [foster.py] => Task 0, Epoch 17/40 => Loss 0.028, Train_accy 99.38, Test_accy 90.28
2022-10-08 05:18:04,916 [foster.py] => Task 0, Epoch 18/40 => Loss 0.029, Train_accy 99.38, Test_accy 87.50
2022-10-08 05:18:09,186 [foster.py] => Task 0, Epoch 19/40 => Loss 0.030, Train_accy 99.59, Test_accy 88.89
2022-10-08 05:18:13,061 [foster.py] => Task 0, Epoch 20/40 => Loss 0.023, Train_accy 99.79, Test_accy 89.58
2022-10-08 05:18:16,171 [foster.py] => Task 0, Epoch 21/40 => Loss 0.017, Train_accy 99.79
2022-10-08 05:18:20,190 [foster.py] => Task 0, Epoch 22/40 => Loss 0.017, Train_accy 99.86, Test_accy 88.89
2022-10-08 05:18:24,261 [foster.py] => Task 0, Epoch 23/40 => Loss 0.015, Train_accy 99.79, Test_accy 88.19
2022-10-08 05:18:28,064 [foster.py] => Task 0, Epoch 24/40 => Loss 0.019, Train_accy 99.52, Test_accy 88.19
2022-10-08 05:18:31,953 [foster.py] => Task 0, Epoch 25/40 => Loss 0.014, Train_accy 99.93, Test_accy 88.89
2022-10-08 05:18:42,458 [foster.py] => Task 0, Epoch 26/40 => Loss 0.015, Train_accy 99.73
2022-10-08 05:18:49,440 [foster.py] => Task 0, Epoch 27/40 => Loss 0.016, Train_accy 99.79, Test_accy 88.89
2022-10-08 05:18:53,089 [foster.py] => Task 0, Epoch 28/40 => Loss 0.015, Train_accy 99.73, Test_accy 88.89
2022-10-08 05:18:56,562 [foster.py] => Task 0, Epoch 29/40 => Loss 0.016, Train_accy 99.66, Test_accy 88.89
2022-10-08 05:18:59,970 [foster.py] => Task 0, Epoch 30/40 => Loss 0.013, Train_accy 99.86, Test_accy 88.89
2022-10-08 05:19:02,826 [foster.py] => Task 0, Epoch 31/40 => Loss 0.011, Train_accy 99.93
2022-10-08 05:19:06,599 [foster.py] => Task 0, Epoch 32/40 => Loss 0.017, Train_accy 99.59, Test_accy 88.19
2022-10-08 05:19:10,338 [foster.py] => Task 0, Epoch 33/40 => Loss 0.017, Train_accy 99.66, Test_accy 88.19
2022-10-08 05:19:13,965 [foster.py] => Task 0, Epoch 34/40 => Loss 0.013, Train_accy 99.86, Test_accy 88.89
2022-10-08 05:19:17,988 [foster.py] => Task 0, Epoch 35/40 => Loss 0.012, Train_accy 99.93, Test_accy 88.19
2022-10-08 05:19:21,289 [foster.py] => Task 0, Epoch 36/40 => Loss 0.015, Train_accy 99.66
2022-10-08 05:19:25,311 [foster.py] => Task 0, Epoch 37/40 => Loss 0.011, Train_accy 99.93, Test_accy 88.89
2022-10-08 05:19:29,063 [foster.py] => Task 0, Epoch 38/40 => Loss 0.009, Train_accy 100.00, Test_accy 88.89
2022-10-08 05:19:32,939 [foster.py] => Task 0, Epoch 39/40 => Loss 0.013, Train_accy 99.66, Test_accy 88.89
2022-10-08 05:19:36,933 [foster.py] => Task 0, Epoch 40/40 => Loss 0.014, Train_accy 99.73, Test_accy 88.19
2022-10-08 05:19:36,934 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 05:19:44,293 [foster.py] => Exemplar size: 140
2022-10-08 05:19:44,293 [trainer.py] => CNN: {'total': 88.19, 'old': 88.19, 'new': 0, 'base': 88.19, 'compound': 0}
2022-10-08 05:19:44,293 [trainer.py] => CNN top1 curve: [88.19]
2022-10-08 05:19:44,293 [trainer.py] => CNN base curve: [88.19]
2022-10-08 05:19:44,293 [trainer.py] => CNN old curve: [88.19]
2022-10-08 05:19:44,293 [trainer.py] => CNN new curve: [0]
2022-10-08 05:19:44,293 [trainer.py] => CNN compound curve: [0]
2022-10-08 05:19:44,294 [trainer.py] => NME: {'total': 87.5, 'old': 87.5, 'new': 0, 'base': 87.5, 'compound': 0}
2022-10-08 05:19:44,294 [trainer.py] => NME top1 curve: [87.5]
2022-10-08 05:19:44,294 [trainer.py] => NME base curve: [87.5]
2022-10-08 05:19:44,294 [trainer.py] => NME old curve: [87.5]
2022-10-08 05:19:44,294 [trainer.py] => NME new curve: [0]
2022-10-08 05:19:44,294 [trainer.py] => NME compound curve: [0]
2022-10-08 05:19:44,550 [foster.py] => Learning on 7-12
2022-10-08 05:19:44,550 [foster.py] => All params: 22375071
2022-10-08 05:19:44,551 [foster.py] => Trainable params: 11194968
2022-10-08 05:19:44,561 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 05:19:48,433 [foster.py] => Task 1, Epoch 1/34 => Loss 4.967, Loss_clf 2.259, Loss_fe 2.098, Loss_kd 0.356, Train_accy 37.03, Test_accy 62.15
2022-10-08 05:19:51,646 [foster.py] => Task 1, Epoch 2/34 => Loss 2.528, Loss_clf 0.748, Loss_fe 1.180, Loss_kd 0.350, Train_accy 62.88
2022-10-08 05:19:54,809 [foster.py] => Task 1, Epoch 3/34 => Loss 2.136, Loss_clf 0.588, Loss_fe 0.955, Loss_kd 0.346, Train_accy 49.41
2022-10-08 05:19:58,007 [foster.py] => Task 1, Epoch 4/34 => Loss 1.977, Loss_clf 0.540, Loss_fe 0.847, Loss_kd 0.344, Train_accy 49.15
2022-10-08 05:20:01,258 [foster.py] => Task 1, Epoch 5/34 => Loss 1.885, Loss_clf 0.527, Loss_fe 0.767, Loss_kd 0.344, Train_accy 49.92
2022-10-08 05:20:05,547 [foster.py] => Task 1, Epoch 6/34 => Loss 1.796, Loss_clf 0.494, Loss_fe 0.720, Loss_kd 0.340, Train_accy 46.95, Test_accy 65.34
2022-10-08 05:20:08,551 [foster.py] => Task 1, Epoch 7/34 => Loss 1.733, Loss_clf 0.472, Loss_fe 0.680, Loss_kd 0.339, Train_accy 49.58
2022-10-08 05:20:12,255 [foster.py] => Task 1, Epoch 8/34 => Loss 1.713, Loss_clf 0.474, Loss_fe 0.652, Loss_kd 0.342, Train_accy 50.85
2022-10-08 05:20:15,911 [foster.py] => Task 1, Epoch 9/34 => Loss 1.662, Loss_clf 0.453, Loss_fe 0.620, Loss_kd 0.344, Train_accy 50.00
2022-10-08 05:20:19,600 [foster.py] => Task 1, Epoch 10/34 => Loss 1.608, Loss_clf 0.437, Loss_fe 0.590, Loss_kd 0.339, Train_accy 48.73
2022-10-08 05:20:24,110 [foster.py] => Task 1, Epoch 11/34 => Loss 1.573, Loss_clf 0.424, Loss_fe 0.568, Loss_kd 0.339, Train_accy 51.19, Test_accy 64.54
2022-10-08 05:20:27,473 [foster.py] => Task 1, Epoch 12/34 => Loss 1.591, Loss_clf 0.439, Loss_fe 0.564, Loss_kd 0.343, Train_accy 50.08
2022-10-08 05:20:30,948 [foster.py] => Task 1, Epoch 13/34 => Loss 1.519, Loss_clf 0.406, Loss_fe 0.525, Loss_kd 0.343, Train_accy 51.69
2022-10-08 05:20:34,483 [foster.py] => Task 1, Epoch 14/34 => Loss 1.477, Loss_clf 0.386, Loss_fe 0.507, Loss_kd 0.340, Train_accy 48.81
2022-10-08 05:20:38,160 [foster.py] => Task 1, Epoch 15/34 => Loss 1.521, Loss_clf 0.408, Loss_fe 0.529, Loss_kd 0.340, Train_accy 50.08
2022-10-08 05:20:42,662 [foster.py] => Task 1, Epoch 16/34 => Loss 1.482, Loss_clf 0.390, Loss_fe 0.500, Loss_kd 0.346, Train_accy 51.36, Test_accy 64.94
2022-10-08 05:20:46,257 [foster.py] => Task 1, Epoch 17/34 => Loss 1.481, Loss_clf 0.393, Loss_fe 0.498, Loss_kd 0.344, Train_accy 50.17
2022-10-08 05:20:49,942 [foster.py] => Task 1, Epoch 18/34 => Loss 1.426, Loss_clf 0.370, Loss_fe 0.469, Loss_kd 0.342, Train_accy 51.02
2022-10-08 05:20:53,640 [foster.py] => Task 1, Epoch 19/34 => Loss 1.400, Loss_clf 0.361, Loss_fe 0.457, Loss_kd 0.340, Train_accy 51.78
2022-10-08 05:20:57,287 [foster.py] => Task 1, Epoch 20/34 => Loss 1.368, Loss_clf 0.348, Loss_fe 0.435, Loss_kd 0.341, Train_accy 52.20
2022-10-08 05:21:01,873 [foster.py] => Task 1, Epoch 21/34 => Loss 1.404, Loss_clf 0.363, Loss_fe 0.460, Loss_kd 0.339, Train_accy 50.25, Test_accy 63.75
2022-10-08 05:21:05,616 [foster.py] => Task 1, Epoch 22/34 => Loss 1.395, Loss_clf 0.353, Loss_fe 0.453, Loss_kd 0.343, Train_accy 52.29
2022-10-08 05:21:09,285 [foster.py] => Task 1, Epoch 23/34 => Loss 1.371, Loss_clf 0.340, Loss_fe 0.437, Loss_kd 0.346, Train_accy 52.71
2022-10-08 05:21:12,950 [foster.py] => Task 1, Epoch 24/34 => Loss 1.347, Loss_clf 0.338, Loss_fe 0.435, Loss_kd 0.335, Train_accy 50.42
2022-10-08 05:21:16,568 [foster.py] => Task 1, Epoch 25/34 => Loss 1.356, Loss_clf 0.341, Loss_fe 0.434, Loss_kd 0.339, Train_accy 51.53
2022-10-08 05:21:21,024 [foster.py] => Task 1, Epoch 26/34 => Loss 1.337, Loss_clf 0.328, Loss_fe 0.424, Loss_kd 0.341, Train_accy 52.97, Test_accy 64.14
2022-10-08 05:21:24,596 [foster.py] => Task 1, Epoch 27/34 => Loss 1.330, Loss_clf 0.330, Loss_fe 0.418, Loss_kd 0.339, Train_accy 51.78
2022-10-08 05:21:28,171 [foster.py] => Task 1, Epoch 28/34 => Loss 1.365, Loss_clf 0.344, Loss_fe 0.434, Loss_kd 0.342, Train_accy 51.10
2022-10-08 05:21:31,776 [foster.py] => Task 1, Epoch 29/34 => Loss 1.319, Loss_clf 0.325, Loss_fe 0.415, Loss_kd 0.338, Train_accy 51.36
2022-10-08 05:21:35,454 [foster.py] => Task 1, Epoch 30/34 => Loss 1.349, Loss_clf 0.334, Loss_fe 0.429, Loss_kd 0.342, Train_accy 53.31
2022-10-08 05:21:39,938 [foster.py] => Task 1, Epoch 31/34 => Loss 1.352, Loss_clf 0.343, Loss_fe 0.427, Loss_kd 0.340, Train_accy 50.76, Test_accy 64.94
2022-10-08 05:21:43,618 [foster.py] => Task 1, Epoch 32/34 => Loss 1.332, Loss_clf 0.332, Loss_fe 0.420, Loss_kd 0.339, Train_accy 51.02
2022-10-08 05:21:47,230 [foster.py] => Task 1, Epoch 33/34 => Loss 1.337, Loss_clf 0.327, Loss_fe 0.422, Loss_kd 0.343, Train_accy 52.63
2022-10-08 05:21:50,833 [foster.py] => Task 1, Epoch 34/34 => Loss 1.351, Loss_clf 0.335, Loss_fe 0.426, Loss_kd 0.344, Train_accy 52.63
2022-10-08 05:21:50,833 [foster.py] => do not weight align teacher!
2022-10-08 05:21:50,834 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 05:21:55,995 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.691,  Train_accy 11.61, Test_accy 49.40
2022-10-08 05:22:00,277 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.535,  Train_accy 12.37
2022-10-08 05:22:04,283 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.467,  Train_accy 15.25
2022-10-08 05:22:08,433 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.424,  Train_accy 17.71
2022-10-08 05:22:13,114 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.401,  Train_accy 19.66
2022-10-08 05:22:18,104 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.388,  Train_accy 21.19, Test_accy 54.58
2022-10-08 05:22:22,302 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.380,  Train_accy 22.20
2022-10-08 05:22:26,634 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.355,  Train_accy 23.05
2022-10-08 05:22:31,291 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.356,  Train_accy 24.32
2022-10-08 05:22:35,505 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.338,  Train_accy 25.08
2022-10-08 05:22:40,712 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.332,  Train_accy 25.42, Test_accy 54.98
2022-10-08 05:22:45,308 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.330,  Train_accy 25.76
2022-10-08 05:22:49,983 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.327,  Train_accy 25.42
2022-10-08 05:22:54,494 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.325,  Train_accy 27.03
2022-10-08 05:22:59,060 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.313,  Train_accy 26.69
2022-10-08 05:23:04,412 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.317,  Train_accy 28.05, Test_accy 56.18
2022-10-08 05:23:08,992 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.310,  Train_accy 28.39
2022-10-08 05:23:13,542 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.312,  Train_accy 26.69
2022-10-08 05:23:18,091 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.321,  Train_accy 27.29
2022-10-08 05:23:22,749 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.312,  Train_accy 27.80
2022-10-08 05:23:28,010 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.305,  Train_accy 28.39, Test_accy 56.18
2022-10-08 05:23:32,601 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.304,  Train_accy 28.56
2022-10-08 05:23:37,162 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.310,  Train_accy 26.27
2022-10-08 05:23:41,769 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.304,  Train_accy 28.14
2022-10-08 05:23:46,355 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.308,  Train_accy 28.47
2022-10-08 05:23:51,705 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.307,  Train_accy 27.71, Test_accy 56.97
2022-10-08 05:23:51,705 [foster.py] => do not weight align student!
2022-10-08 05:23:52,428 [foster.py] => darknet eval: 
2022-10-08 05:23:52,428 [foster.py] => CNN top1 curve: 56.97
2022-10-08 05:23:52,428 [foster.py] => CNN top5 curve: 97.21
2022-10-08 05:23:52,429 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 05:24:01,203 [foster.py] => Exemplar size: 240
2022-10-08 05:24:01,203 [trainer.py] => CNN: {'total': 64.54, 'old': 81.25, 'new': 42.06, 'base': 81.25, 'compound': 42.06}
2022-10-08 05:24:01,203 [trainer.py] => CNN top1 curve: [88.19, 64.54]
2022-10-08 05:24:01,203 [trainer.py] => CNN base curve: [88.19, 81.25]
2022-10-08 05:24:01,203 [trainer.py] => CNN old curve: [88.19, 81.25]
2022-10-08 05:24:01,203 [trainer.py] => CNN new curve: [0, 42.06]
2022-10-08 05:24:01,203 [trainer.py] => CNN compound curve: [0, 42.06]
2022-10-08 05:24:01,203 [trainer.py] => NME: {'total': 74.5, 'old': 79.17, 'new': 68.22, 'base': 79.17, 'compound': 68.22}
2022-10-08 05:24:01,204 [trainer.py] => NME top1 curve: [87.5, 74.5]
2022-10-08 05:24:01,204 [trainer.py] => NME base curve: [87.5, 79.17]
2022-10-08 05:24:01,204 [trainer.py] => NME old curve: [87.5, 79.17]
2022-10-08 05:24:01,204 [trainer.py] => NME new curve: [0, 68.22]
2022-10-08 05:24:01,204 [trainer.py] => NME compound curve: [0, 68.22]
2022-10-08 05:24:01,453 [foster.py] => Learning on 12-17
2022-10-08 05:24:01,453 [foster.py] => All params: 22385326
2022-10-08 05:24:01,454 [foster.py] => Trainable params: 11202658
2022-10-08 05:24:01,464 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 05:24:05,941 [foster.py] => Task 2, Epoch 1/34 => Loss 5.694, Loss_clf 2.156, Loss_fe 2.157, Loss_kd 0.975, Train_accy 37.56, Test_accy 46.54
2022-10-08 05:24:09,530 [foster.py] => Task 2, Epoch 2/34 => Loss 3.836, Loss_clf 0.979, Loss_fe 1.527, Loss_kd 0.938, Train_accy 43.11
2022-10-08 05:24:13,105 [foster.py] => Task 2, Epoch 3/34 => Loss 3.527, Loss_clf 0.867, Loss_fe 1.328, Loss_kd 0.940, Train_accy 39.54
2022-10-08 05:24:16,812 [foster.py] => Task 2, Epoch 4/34 => Loss 3.324, Loss_clf 0.796, Loss_fe 1.189, Loss_kd 0.945, Train_accy 42.23
2022-10-08 05:24:20,302 [foster.py] => Task 2, Epoch 5/34 => Loss 3.193, Loss_clf 0.760, Loss_fe 1.101, Loss_kd 0.940, Train_accy 42.23
2022-10-08 05:24:24,938 [foster.py] => Task 2, Epoch 6/34 => Loss 3.097, Loss_clf 0.740, Loss_fe 1.026, Loss_kd 0.939, Train_accy 43.19, Test_accy 48.94
2022-10-08 05:24:28,462 [foster.py] => Task 2, Epoch 7/34 => Loss 3.030, Loss_clf 0.703, Loss_fe 0.976, Loss_kd 0.953, Train_accy 43.19
2022-10-08 05:24:32,143 [foster.py] => Task 2, Epoch 8/34 => Loss 3.009, Loss_clf 0.716, Loss_fe 0.953, Loss_kd 0.946, Train_accy 41.68
2022-10-08 05:24:35,990 [foster.py] => Task 2, Epoch 9/34 => Loss 2.918, Loss_clf 0.689, Loss_fe 0.892, Loss_kd 0.944, Train_accy 44.37
2022-10-08 05:24:39,984 [foster.py] => Task 2, Epoch 10/34 => Loss 2.894, Loss_clf 0.676, Loss_fe 0.874, Loss_kd 0.949, Train_accy 43.34
2022-10-08 05:24:45,087 [foster.py] => Task 2, Epoch 11/34 => Loss 2.830, Loss_clf 0.660, Loss_fe 0.838, Loss_kd 0.941, Train_accy 41.13, Test_accy 49.73
2022-10-08 05:24:49,259 [foster.py] => Task 2, Epoch 12/34 => Loss 2.764, Loss_clf 0.635, Loss_fe 0.797, Loss_kd 0.941, Train_accy 43.42
2022-10-08 05:24:53,250 [foster.py] => Task 2, Epoch 13/34 => Loss 2.739, Loss_clf 0.625, Loss_fe 0.780, Loss_kd 0.941, Train_accy 45.48
2022-10-08 05:24:57,406 [foster.py] => Task 2, Epoch 14/34 => Loss 2.714, Loss_clf 0.621, Loss_fe 0.763, Loss_kd 0.938, Train_accy 43.42
2022-10-08 05:25:01,451 [foster.py] => Task 2, Epoch 15/34 => Loss 2.687, Loss_clf 0.605, Loss_fe 0.748, Loss_kd 0.942, Train_accy 43.11
2022-10-08 05:25:06,692 [foster.py] => Task 2, Epoch 16/34 => Loss 2.648, Loss_clf 0.588, Loss_fe 0.720, Loss_kd 0.946, Train_accy 47.31, Test_accy 51.33
2022-10-08 05:25:10,722 [foster.py] => Task 2, Epoch 17/34 => Loss 2.626, Loss_clf 0.590, Loss_fe 0.712, Loss_kd 0.935, Train_accy 45.40
2022-10-08 05:25:14,827 [foster.py] => Task 2, Epoch 18/34 => Loss 2.616, Loss_clf 0.576, Loss_fe 0.701, Loss_kd 0.945, Train_accy 47.07
2022-10-08 05:25:18,967 [foster.py] => Task 2, Epoch 19/34 => Loss 2.564, Loss_clf 0.558, Loss_fe 0.669, Loss_kd 0.944, Train_accy 48.26
2022-10-08 05:25:23,152 [foster.py] => Task 2, Epoch 20/34 => Loss 2.548, Loss_clf 0.554, Loss_fe 0.664, Loss_kd 0.938, Train_accy 47.86
2022-10-08 05:25:28,339 [foster.py] => Task 2, Epoch 21/34 => Loss 2.564, Loss_clf 0.555, Loss_fe 0.658, Loss_kd 0.954, Train_accy 48.02, Test_accy 51.06
2022-10-08 05:25:31,973 [foster.py] => Task 2, Epoch 22/34 => Loss 2.507, Loss_clf 0.530, Loss_fe 0.636, Loss_kd 0.946, Train_accy 47.62
2022-10-08 05:25:35,565 [foster.py] => Task 2, Epoch 23/34 => Loss 2.521, Loss_clf 0.542, Loss_fe 0.643, Loss_kd 0.943, Train_accy 48.34
2022-10-08 05:25:39,122 [foster.py] => Task 2, Epoch 24/34 => Loss 2.563, Loss_clf 0.562, Loss_fe 0.661, Loss_kd 0.946, Train_accy 48.81
2022-10-08 05:25:42,735 [foster.py] => Task 2, Epoch 25/34 => Loss 2.504, Loss_clf 0.527, Loss_fe 0.634, Loss_kd 0.948, Train_accy 46.75
2022-10-08 05:25:47,434 [foster.py] => Task 2, Epoch 26/34 => Loss 2.499, Loss_clf 0.532, Loss_fe 0.630, Loss_kd 0.944, Train_accy 49.37, Test_accy 51.60
2022-10-08 05:25:51,023 [foster.py] => Task 2, Epoch 27/34 => Loss 2.533, Loss_clf 0.544, Loss_fe 0.649, Loss_kd 0.946, Train_accy 47.54
2022-10-08 05:26:02,386 [foster.py] => Task 2, Epoch 28/34 => Loss 2.507, Loss_clf 0.535, Loss_fe 0.627, Loss_kd 0.949, Train_accy 48.49
2022-10-08 05:26:11,678 [foster.py] => Task 2, Epoch 29/34 => Loss 2.498, Loss_clf 0.529, Loss_fe 0.625, Loss_kd 0.949, Train_accy 49.45
2022-10-08 05:26:15,715 [foster.py] => Task 2, Epoch 30/34 => Loss 2.485, Loss_clf 0.529, Loss_fe 0.616, Loss_kd 0.945, Train_accy 48.34
2022-10-08 05:26:20,698 [foster.py] => Task 2, Epoch 31/34 => Loss 2.482, Loss_clf 0.525, Loss_fe 0.616, Loss_kd 0.946, Train_accy 49.60, Test_accy 52.66
2022-10-08 05:26:24,007 [foster.py] => Task 2, Epoch 32/34 => Loss 2.484, Loss_clf 0.524, Loss_fe 0.613, Loss_kd 0.951, Train_accy 47.62
2022-10-08 05:26:27,349 [foster.py] => Task 2, Epoch 33/34 => Loss 2.468, Loss_clf 0.511, Loss_fe 0.617, Loss_kd 0.946, Train_accy 47.46
2022-10-08 05:26:30,680 [foster.py] => Task 2, Epoch 34/34 => Loss 2.480, Loss_clf 0.519, Loss_fe 0.615, Loss_kd 0.949, Train_accy 48.57
2022-10-08 05:26:30,680 [foster.py] => do not weight align teacher!
2022-10-08 05:26:30,681 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 05:26:35,758 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.072,  Train_accy 12.44, Test_accy 37.50
2022-10-08 05:26:40,102 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.994,  Train_accy 12.84
2022-10-08 05:26:44,245 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.955,  Train_accy 13.07
2022-10-08 05:26:48,496 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.931,  Train_accy 13.23
2022-10-08 05:26:52,958 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.897,  Train_accy 13.23
2022-10-08 05:26:58,366 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.900,  Train_accy 13.79, Test_accy 39.89
2022-10-08 05:27:02,504 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.887,  Train_accy 13.63
2022-10-08 05:27:06,661 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.883,  Train_accy 13.87
2022-10-08 05:27:11,416 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.871,  Train_accy 13.87
2022-10-08 05:27:16,065 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.871,  Train_accy 14.10
2022-10-08 05:27:21,802 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.855,  Train_accy 14.34, Test_accy 40.69
2022-10-08 05:27:27,638 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.854,  Train_accy 14.18
2022-10-08 05:27:33,509 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.857,  Train_accy 14.50
2022-10-08 05:27:39,319 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.847,  Train_accy 14.66
2022-10-08 05:27:45,147 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.853,  Train_accy 15.37
2022-10-08 05:27:51,788 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.845,  Train_accy 15.53, Test_accy 42.02
2022-10-08 05:27:57,552 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.843,  Train_accy 16.09
2022-10-08 05:28:03,345 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.838,  Train_accy 16.16
2022-10-08 05:28:09,144 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.835,  Train_accy 15.77
2022-10-08 05:28:14,223 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.836,  Train_accy 16.32
2022-10-08 05:28:19,486 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.839,  Train_accy 16.09, Test_accy 42.55
2022-10-08 05:28:23,567 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.834,  Train_accy 15.77
2022-10-08 05:28:27,532 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.847,  Train_accy 15.45
2022-10-08 05:28:32,107 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.831,  Train_accy 15.77
2022-10-08 05:28:36,825 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.832,  Train_accy 14.98
2022-10-08 05:28:42,439 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.848,  Train_accy 15.69, Test_accy 42.02
2022-10-08 05:28:42,440 [foster.py] => do not weight align student!
2022-10-08 05:28:43,230 [foster.py] => darknet eval: 
2022-10-08 05:28:43,230 [foster.py] => CNN top1 curve: 42.02
2022-10-08 05:28:43,230 [foster.py] => CNN top5 curve: 93.09
2022-10-08 05:28:43,230 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 05:28:53,982 [foster.py] => Exemplar size: 340
2022-10-08 05:28:53,982 [trainer.py] => CNN: {'total': 52.66, 'old': 63.35, 'new': 31.2, 'base': 80.56, 'compound': 35.34}
2022-10-08 05:28:53,982 [trainer.py] => CNN top1 curve: [88.19, 64.54, 52.66]
2022-10-08 05:28:53,982 [trainer.py] => CNN base curve: [88.19, 81.25, 80.56]
2022-10-08 05:28:53,982 [trainer.py] => CNN old curve: [88.19, 81.25, 63.35]
2022-10-08 05:28:53,982 [trainer.py] => CNN new curve: [0, 42.06, 31.2]
2022-10-08 05:28:53,982 [trainer.py] => CNN compound curve: [0, 42.06, 35.34]
2022-10-08 05:28:53,982 [trainer.py] => NME: {'total': 64.63, 'old': 66.93, 'new': 60.0, 'base': 75.0, 'compound': 58.19}
2022-10-08 05:28:53,982 [trainer.py] => NME top1 curve: [87.5, 74.5, 64.63]
2022-10-08 05:28:53,983 [trainer.py] => NME base curve: [87.5, 79.17, 75.0]
2022-10-08 05:28:53,983 [trainer.py] => NME old curve: [87.5, 79.17, 66.93]
2022-10-08 05:28:53,983 [trainer.py] => NME new curve: [0, 68.22, 60.0]
2022-10-08 05:28:53,983 [trainer.py] => NME compound curve: [0, 68.22, 58.19]
2022-10-08 05:28:54,228 [foster.py] => Learning on 17-22
2022-10-08 05:28:54,228 [foster.py] => All params: 22395581
2022-10-08 05:28:54,229 [foster.py] => Trainable params: 11210348
2022-10-08 05:28:54,239 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 05:28:58,945 [foster.py] => Task 3, Epoch 1/34 => Loss 6.618, Loss_clf 2.130, Loss_fe 2.526, Loss_kd 1.515, Train_accy 34.22, Test_accy 38.61
2022-10-08 05:29:02,797 [foster.py] => Task 3, Epoch 2/34 => Loss 4.922, Loss_clf 1.204, Loss_fe 1.803, Loss_kd 1.480, Train_accy 34.66
2022-10-08 05:29:06,237 [foster.py] => Task 3, Epoch 3/34 => Loss 4.596, Loss_clf 1.068, Loss_fe 1.593, Loss_kd 1.495, Train_accy 38.13
2022-10-08 05:29:10,072 [foster.py] => Task 3, Epoch 4/34 => Loss 4.450, Loss_clf 1.052, Loss_fe 1.478, Loss_kd 1.483, Train_accy 36.36
2022-10-08 05:29:13,768 [foster.py] => Task 3, Epoch 5/34 => Loss 4.324, Loss_clf 1.028, Loss_fe 1.390, Loss_kd 1.473, Train_accy 37.17
2022-10-08 05:29:18,531 [foster.py] => Task 3, Epoch 6/34 => Loss 4.212, Loss_clf 0.995, Loss_fe 1.309, Loss_kd 1.475, Train_accy 38.64, Test_accy 42.57
2022-10-08 05:29:22,298 [foster.py] => Task 3, Epoch 7/34 => Loss 4.121, Loss_clf 0.971, Loss_fe 1.236, Loss_kd 1.479, Train_accy 37.46
2022-10-08 05:29:26,024 [foster.py] => Task 3, Epoch 8/34 => Loss 4.020, Loss_clf 0.933, Loss_fe 1.175, Loss_kd 1.477, Train_accy 38.50
2022-10-08 05:29:30,074 [foster.py] => Task 3, Epoch 9/34 => Loss 3.996, Loss_clf 0.935, Loss_fe 1.144, Loss_kd 1.482, Train_accy 38.42
2022-10-08 05:29:33,997 [foster.py] => Task 3, Epoch 10/34 => Loss 3.950, Loss_clf 0.914, Loss_fe 1.118, Loss_kd 1.482, Train_accy 39.53
2022-10-08 05:29:39,771 [foster.py] => Task 3, Epoch 11/34 => Loss 3.903, Loss_clf 0.909, Loss_fe 1.074, Loss_kd 1.484, Train_accy 41.37, Test_accy 42.57
2022-10-08 05:29:43,737 [foster.py] => Task 3, Epoch 12/34 => Loss 3.904, Loss_clf 0.916, Loss_fe 1.066, Loss_kd 1.485, Train_accy 39.75
2022-10-08 05:29:47,785 [foster.py] => Task 3, Epoch 13/34 => Loss 3.817, Loss_clf 0.880, Loss_fe 1.024, Loss_kd 1.479, Train_accy 39.16
2022-10-08 05:29:51,730 [foster.py] => Task 3, Epoch 14/34 => Loss 3.756, Loss_clf 0.855, Loss_fe 0.985, Loss_kd 1.480, Train_accy 40.34
2022-10-08 05:29:55,792 [foster.py] => Task 3, Epoch 15/34 => Loss 3.764, Loss_clf 0.859, Loss_fe 0.986, Loss_kd 1.484, Train_accy 39.45
2022-10-08 05:30:01,200 [foster.py] => Task 3, Epoch 16/34 => Loss 3.755, Loss_clf 0.856, Loss_fe 0.968, Loss_kd 1.492, Train_accy 40.19, Test_accy 42.97
2022-10-08 05:30:06,511 [foster.py] => Task 3, Epoch 17/34 => Loss 3.727, Loss_clf 0.847, Loss_fe 0.964, Loss_kd 1.481, Train_accy 40.34
2022-10-08 05:30:11,927 [foster.py] => Task 3, Epoch 18/34 => Loss 3.704, Loss_clf 0.835, Loss_fe 0.945, Loss_kd 1.487, Train_accy 43.58
2022-10-08 05:30:17,157 [foster.py] => Task 3, Epoch 19/34 => Loss 3.646, Loss_clf 0.807, Loss_fe 0.918, Loss_kd 1.484, Train_accy 42.63
2022-10-08 05:30:22,456 [foster.py] => Task 3, Epoch 20/34 => Loss 3.672, Loss_clf 0.832, Loss_fe 0.924, Loss_kd 1.481, Train_accy 41.00
2022-10-08 05:30:29,198 [foster.py] => Task 3, Epoch 21/34 => Loss 3.627, Loss_clf 0.811, Loss_fe 0.900, Loss_kd 1.480, Train_accy 43.07, Test_accy 42.77
2022-10-08 05:30:33,231 [foster.py] => Task 3, Epoch 22/34 => Loss 3.596, Loss_clf 0.782, Loss_fe 0.877, Loss_kd 1.497, Train_accy 43.51
2022-10-08 05:30:37,300 [foster.py] => Task 3, Epoch 23/34 => Loss 3.558, Loss_clf 0.768, Loss_fe 0.861, Loss_kd 1.490, Train_accy 43.07
2022-10-08 05:30:41,368 [foster.py] => Task 3, Epoch 24/34 => Loss 3.574, Loss_clf 0.782, Loss_fe 0.874, Loss_kd 1.483, Train_accy 42.04
2022-10-08 05:30:45,393 [foster.py] => Task 3, Epoch 25/34 => Loss 3.545, Loss_clf 0.777, Loss_fe 0.850, Loss_kd 1.482, Train_accy 42.33
2022-10-08 05:30:50,706 [foster.py] => Task 3, Epoch 26/34 => Loss 3.571, Loss_clf 0.784, Loss_fe 0.873, Loss_kd 1.479, Train_accy 42.18, Test_accy 43.56
2022-10-08 05:30:54,673 [foster.py] => Task 3, Epoch 27/34 => Loss 3.508, Loss_clf 0.751, Loss_fe 0.839, Loss_kd 1.483, Train_accy 42.18
2022-10-08 05:30:58,663 [foster.py] => Task 3, Epoch 28/34 => Loss 3.531, Loss_clf 0.768, Loss_fe 0.845, Loss_kd 1.483, Train_accy 42.70
2022-10-08 05:31:02,765 [foster.py] => Task 3, Epoch 29/34 => Loss 3.536, Loss_clf 0.762, Loss_fe 0.852, Loss_kd 1.485, Train_accy 44.47
2022-10-08 05:31:06,859 [foster.py] => Task 3, Epoch 30/34 => Loss 3.516, Loss_clf 0.753, Loss_fe 0.839, Loss_kd 1.487, Train_accy 43.51
2022-10-08 05:31:12,051 [foster.py] => Task 3, Epoch 31/34 => Loss 3.547, Loss_clf 0.762, Loss_fe 0.853, Loss_kd 1.493, Train_accy 43.44, Test_accy 43.17
2022-10-08 05:31:16,166 [foster.py] => Task 3, Epoch 32/34 => Loss 3.514, Loss_clf 0.755, Loss_fe 0.842, Loss_kd 1.481, Train_accy 44.25
2022-10-08 05:31:20,346 [foster.py] => Task 3, Epoch 33/34 => Loss 3.492, Loss_clf 0.746, Loss_fe 0.824, Loss_kd 1.485, Train_accy 44.25
2022-10-08 05:31:24,560 [foster.py] => Task 3, Epoch 34/34 => Loss 3.515, Loss_clf 0.751, Loss_fe 0.836, Loss_kd 1.490, Train_accy 42.26
2022-10-08 05:31:24,560 [foster.py] => do not weight align teacher!
2022-10-08 05:31:24,561 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 05:31:30,941 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.417,  Train_accy 13.50, Test_accy 33.66
2022-10-08 05:31:35,768 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.370,  Train_accy 14.01
2022-10-08 05:31:40,666 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.345,  Train_accy 14.38
2022-10-08 05:31:45,631 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.329,  Train_accy 13.72
2022-10-08 05:31:50,867 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.313,  Train_accy 14.45
2022-10-08 05:31:56,881 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.310,  Train_accy 14.23, Test_accy 34.85
2022-10-08 05:32:01,737 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.308,  Train_accy 13.86
2022-10-08 05:32:06,682 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.305,  Train_accy 14.90
2022-10-08 05:32:11,753 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.301,  Train_accy 14.60
2022-10-08 05:32:16,680 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.291,  Train_accy 14.82
2022-10-08 05:32:22,757 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.288,  Train_accy 14.60, Test_accy 35.05
2022-10-08 05:32:27,620 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.283,  Train_accy 14.31
2022-10-08 05:32:32,676 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.291,  Train_accy 14.38
2022-10-08 05:32:37,891 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.289,  Train_accy 15.34
2022-10-08 05:32:43,926 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.280,  Train_accy 15.12
2022-10-08 05:32:52,526 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.276,  Train_accy 14.82, Test_accy 35.25
2022-10-08 05:32:58,647 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.285,  Train_accy 15.04
2022-10-08 05:33:04,826 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.284,  Train_accy 14.68
2022-10-08 05:33:10,887 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.274,  Train_accy 16.08
2022-10-08 05:33:16,214 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.279,  Train_accy 14.82
2022-10-08 05:33:22,517 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.277,  Train_accy 15.63, Test_accy 35.05
2022-10-08 05:33:27,289 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.268,  Train_accy 15.49
2022-10-08 05:33:32,025 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.287,  Train_accy 15.34
2022-10-08 05:33:36,855 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.276,  Train_accy 15.12
2022-10-08 05:33:41,623 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.266,  Train_accy 16.00
2022-10-08 05:33:47,303 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.266,  Train_accy 15.78, Test_accy 35.64
2022-10-08 05:33:47,303 [foster.py] => do not weight align student!
2022-10-08 05:33:48,249 [foster.py] => darknet eval: 
2022-10-08 05:33:48,249 [foster.py] => CNN top1 curve: 35.64
2022-10-08 05:33:48,249 [foster.py] => CNN top5 curve: 81.78
2022-10-08 05:33:48,249 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 05:34:00,660 [foster.py] => Exemplar size: 440
2022-10-08 05:34:00,660 [trainer.py] => CNN: {'total': 43.17, 'old': 49.47, 'new': 24.81, 'base': 77.08, 'compound': 29.64}
2022-10-08 05:34:00,660 [trainer.py] => CNN top1 curve: [88.19, 64.54, 52.66, 43.17]
2022-10-08 05:34:00,660 [trainer.py] => CNN base curve: [88.19, 81.25, 80.56, 77.08]
2022-10-08 05:34:00,660 [trainer.py] => CNN old curve: [88.19, 81.25, 63.35, 49.47]
2022-10-08 05:34:00,660 [trainer.py] => CNN new curve: [0, 42.06, 31.2, 24.81]
2022-10-08 05:34:00,660 [trainer.py] => CNN compound curve: [0, 42.06, 35.34, 29.64]
2022-10-08 05:34:00,660 [trainer.py] => NME: {'total': 54.46, 'old': 59.31, 'new': 40.31, 'base': 72.22, 'compound': 47.37}
2022-10-08 05:34:00,660 [trainer.py] => NME top1 curve: [87.5, 74.5, 64.63, 54.46]
2022-10-08 05:34:00,660 [trainer.py] => NME base curve: [87.5, 79.17, 75.0, 72.22]
2022-10-08 05:34:00,660 [trainer.py] => NME old curve: [87.5, 79.17, 66.93, 59.31]
2022-10-08 05:34:00,660 [trainer.py] => NME new curve: [0, 68.22, 60.0, 40.31]
2022-10-08 05:34:00,661 [trainer.py] => NME compound curve: [0, 68.22, 58.19, 47.37]
2022-10-08 05:34:00,662 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 05:34:00,662 [trainer.py] => prefix: cil
2022-10-08 05:34:00,662 [trainer.py] => dataset: CFEE
2022-10-08 05:34:00,662 [trainer.py] => memory_size: 2000
2022-10-08 05:34:00,662 [trainer.py] => memory_per_class: 20
2022-10-08 05:34:00,662 [trainer.py] => fixed_memory: True
2022-10-08 05:34:00,662 [trainer.py] => shuffle: True
2022-10-08 05:34:00,662 [trainer.py] => init_cls: 7
2022-10-08 05:34:00,662 [trainer.py] => increment: 5
2022-10-08 05:34:00,662 [trainer.py] => model_name: foster
2022-10-08 05:34:00,662 [trainer.py] => convnet_type: resnet18
2022-10-08 05:34:00,662 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 05:34:00,662 [trainer.py] => seed: 1993
2022-10-08 05:34:00,663 [trainer.py] => beta1: 0.96
2022-10-08 05:34:00,663 [trainer.py] => beta2: 0.97
2022-10-08 05:34:00,663 [trainer.py] => oofc: ft
2022-10-08 05:34:00,663 [trainer.py] => is_teacher_wa: False
2022-10-08 05:34:00,663 [trainer.py] => is_student_wa: False
2022-10-08 05:34:00,663 [trainer.py] => lambda_okd: 1
2022-10-08 05:34:00,663 [trainer.py] => wa_value: 1
2022-10-08 05:34:00,663 [trainer.py] => init_epochs: 40
2022-10-08 05:34:00,663 [trainer.py] => init_lr: 0.01
2022-10-08 05:34:00,663 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 05:34:00,663 [trainer.py] => boosting_epochs: 34
2022-10-08 05:34:00,663 [trainer.py] => compression_epochs: 26
2022-10-08 05:34:00,663 [trainer.py] => lr: 0.001
2022-10-08 05:34:00,663 [trainer.py] => batch_size: 32
2022-10-08 05:34:00,663 [trainer.py] => weight_decay: 0.0005
2022-10-08 05:34:00,663 [trainer.py] => num_workers: 8
2022-10-08 05:34:00,663 [trainer.py] => T: 2
2022-10-08 05:34:00,663 [trainer.py] => nb_runs: 3
2022-10-08 05:34:00,663 [trainer.py] => fold: 10
2022-10-08 05:34:00,663 [data.py] => ========== Fold:5 ==========
2022-10-08 05:34:00,669 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 13, 17, 15, 9, 11, 20, 18, 12, 14, 7, 10, 19, 21, 16, 8]
2022-10-08 05:34:00,905 [foster.py] => Learning on 0-7
2022-10-08 05:34:00,905 [foster.py] => All params: 11183694
2022-10-08 05:34:00,906 [foster.py] => Trainable params: 11183694
2022-10-08 05:34:03,904 [foster.py] => Task 0, Epoch 1/40 => Loss 1.338, Train_accy 50.42
2022-10-08 05:34:07,375 [foster.py] => Task 0, Epoch 2/40 => Loss 0.542, Train_accy 81.15, Test_accy 84.02
2022-10-08 05:34:10,861 [foster.py] => Task 0, Epoch 3/40 => Loss 0.378, Train_accy 86.79, Test_accy 88.17
2022-10-08 05:34:14,336 [foster.py] => Task 0, Epoch 4/40 => Loss 0.273, Train_accy 89.64, Test_accy 86.39
2022-10-08 05:34:17,966 [foster.py] => Task 0, Epoch 5/40 => Loss 0.226, Train_accy 92.42, Test_accy 87.57
2022-10-08 05:34:20,956 [foster.py] => Task 0, Epoch 6/40 => Loss 0.194, Train_accy 93.53
2022-10-08 05:34:24,553 [foster.py] => Task 0, Epoch 7/40 => Loss 0.165, Train_accy 93.74, Test_accy 88.76
2022-10-08 05:34:27,947 [foster.py] => Task 0, Epoch 8/40 => Loss 0.119, Train_accy 96.80, Test_accy 85.80
2022-10-08 05:34:32,102 [foster.py] => Task 0, Epoch 9/40 => Loss 0.107, Train_accy 96.87, Test_accy 89.35
2022-10-08 05:34:36,290 [foster.py] => Task 0, Epoch 10/40 => Loss 0.085, Train_accy 97.98, Test_accy 89.35
2022-10-08 05:34:39,733 [foster.py] => Task 0, Epoch 11/40 => Loss 0.074, Train_accy 97.57
2022-10-08 05:34:43,835 [foster.py] => Task 0, Epoch 12/40 => Loss 0.063, Train_accy 98.19, Test_accy 88.76
2022-10-08 05:34:47,511 [foster.py] => Task 0, Epoch 13/40 => Loss 0.055, Train_accy 98.26, Test_accy 88.17
2022-10-08 05:34:51,233 [foster.py] => Task 0, Epoch 14/40 => Loss 0.055, Train_accy 98.26, Test_accy 89.35
2022-10-08 05:34:54,748 [foster.py] => Task 0, Epoch 15/40 => Loss 0.052, Train_accy 98.82, Test_accy 89.35
2022-10-08 05:34:57,713 [foster.py] => Task 0, Epoch 16/40 => Loss 0.036, Train_accy 99.17
2022-10-08 05:35:01,560 [foster.py] => Task 0, Epoch 17/40 => Loss 0.037, Train_accy 98.89, Test_accy 89.94
2022-10-08 05:35:05,418 [foster.py] => Task 0, Epoch 18/40 => Loss 0.033, Train_accy 99.24, Test_accy 87.57
2022-10-08 05:35:09,152 [foster.py] => Task 0, Epoch 19/40 => Loss 0.034, Train_accy 98.89, Test_accy 90.53
2022-10-08 05:35:12,936 [foster.py] => Task 0, Epoch 20/40 => Loss 0.029, Train_accy 99.24, Test_accy 88.17
2022-10-08 05:35:16,065 [foster.py] => Task 0, Epoch 21/40 => Loss 0.029, Train_accy 99.17
2022-10-08 05:35:20,108 [foster.py] => Task 0, Epoch 22/40 => Loss 0.024, Train_accy 99.51, Test_accy 89.94
2022-10-08 05:35:24,123 [foster.py] => Task 0, Epoch 23/40 => Loss 0.021, Train_accy 99.51, Test_accy 88.76
2022-10-08 05:35:28,175 [foster.py] => Task 0, Epoch 24/40 => Loss 0.018, Train_accy 99.65, Test_accy 89.35
2022-10-08 05:35:31,845 [foster.py] => Task 0, Epoch 25/40 => Loss 0.019, Train_accy 99.58, Test_accy 88.17
2022-10-08 05:35:35,024 [foster.py] => Task 0, Epoch 26/40 => Loss 0.023, Train_accy 99.37
2022-10-08 05:35:38,971 [foster.py] => Task 0, Epoch 27/40 => Loss 0.020, Train_accy 99.65, Test_accy 89.94
2022-10-08 05:35:42,838 [foster.py] => Task 0, Epoch 28/40 => Loss 0.015, Train_accy 99.79, Test_accy 88.76
2022-10-08 05:35:47,006 [foster.py] => Task 0, Epoch 29/40 => Loss 0.017, Train_accy 99.65, Test_accy 88.17
2022-10-08 05:35:50,935 [foster.py] => Task 0, Epoch 30/40 => Loss 0.013, Train_accy 99.93, Test_accy 87.57
2022-10-08 05:35:54,044 [foster.py] => Task 0, Epoch 31/40 => Loss 0.015, Train_accy 99.72
2022-10-08 05:35:58,384 [foster.py] => Task 0, Epoch 32/40 => Loss 0.011, Train_accy 100.00, Test_accy 88.76
2022-10-08 05:36:02,315 [foster.py] => Task 0, Epoch 33/40 => Loss 0.013, Train_accy 99.86, Test_accy 88.76
2022-10-08 05:36:05,998 [foster.py] => Task 0, Epoch 34/40 => Loss 0.014, Train_accy 99.79, Test_accy 89.35
2022-10-08 05:36:10,113 [foster.py] => Task 0, Epoch 35/40 => Loss 0.014, Train_accy 99.72, Test_accy 88.76
2022-10-08 05:36:13,728 [foster.py] => Task 0, Epoch 36/40 => Loss 0.017, Train_accy 99.65
2022-10-08 05:36:17,918 [foster.py] => Task 0, Epoch 37/40 => Loss 0.014, Train_accy 99.79, Test_accy 88.76
2022-10-08 05:36:22,152 [foster.py] => Task 0, Epoch 38/40 => Loss 0.014, Train_accy 99.86, Test_accy 88.17
2022-10-08 05:36:26,166 [foster.py] => Task 0, Epoch 39/40 => Loss 0.013, Train_accy 99.86, Test_accy 88.76
2022-10-08 05:36:30,379 [foster.py] => Task 0, Epoch 40/40 => Loss 0.013, Train_accy 99.93, Test_accy 89.35
2022-10-08 05:36:30,380 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 05:36:37,671 [foster.py] => Exemplar size: 140
2022-10-08 05:36:37,671 [trainer.py] => CNN: {'total': 89.35, 'old': 89.35, 'new': 0, 'base': 89.35, 'compound': 0}
2022-10-08 05:36:37,671 [trainer.py] => CNN top1 curve: [89.35]
2022-10-08 05:36:37,671 [trainer.py] => CNN base curve: [89.35]
2022-10-08 05:36:37,671 [trainer.py] => CNN old curve: [89.35]
2022-10-08 05:36:37,671 [trainer.py] => CNN new curve: [0]
2022-10-08 05:36:37,671 [trainer.py] => CNN compound curve: [0]
2022-10-08 05:36:37,671 [trainer.py] => NME: {'total': 87.57, 'old': 87.57, 'new': 0, 'base': 87.57, 'compound': 0}
2022-10-08 05:36:37,671 [trainer.py] => NME top1 curve: [87.57]
2022-10-08 05:36:37,671 [trainer.py] => NME base curve: [87.57]
2022-10-08 05:36:37,671 [trainer.py] => NME old curve: [87.57]
2022-10-08 05:36:37,671 [trainer.py] => NME new curve: [0]
2022-10-08 05:36:37,672 [trainer.py] => NME compound curve: [0]
2022-10-08 05:36:37,912 [foster.py] => Learning on 7-12
2022-10-08 05:36:37,912 [foster.py] => All params: 22375071
2022-10-08 05:36:37,912 [foster.py] => Trainable params: 11194968
2022-10-08 05:36:37,921 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 05:36:41,657 [foster.py] => Task 1, Epoch 1/34 => Loss 4.899, Loss_clf 2.350, Loss_fe 1.916, Loss_kd 0.369, Train_accy 32.71, Test_accy 65.59
2022-10-08 05:36:44,893 [foster.py] => Task 1, Epoch 2/34 => Loss 2.560, Loss_clf 0.721, Loss_fe 1.212, Loss_kd 0.366, Train_accy 60.15
2022-10-08 05:36:47,989 [foster.py] => Task 1, Epoch 3/34 => Loss 2.207, Loss_clf 0.593, Loss_fe 1.008, Loss_kd 0.353, Train_accy 43.59
2022-10-08 05:36:51,019 [foster.py] => Task 1, Epoch 4/34 => Loss 2.058, Loss_clf 0.563, Loss_fe 0.894, Loss_kd 0.350, Train_accy 46.30
2022-10-08 05:36:54,418 [foster.py] => Task 1, Epoch 5/34 => Loss 1.934, Loss_clf 0.515, Loss_fe 0.812, Loss_kd 0.354, Train_accy 45.62
2022-10-08 05:36:58,720 [foster.py] => Task 1, Epoch 6/34 => Loss 1.841, Loss_clf 0.495, Loss_fe 0.745, Loss_kd 0.351, Train_accy 45.20, Test_accy 64.52
2022-10-08 05:37:02,419 [foster.py] => Task 1, Epoch 7/34 => Loss 1.775, Loss_clf 0.477, Loss_fe 0.696, Loss_kd 0.352, Train_accy 46.13
2022-10-08 05:37:05,700 [foster.py] => Task 1, Epoch 8/34 => Loss 1.721, Loss_clf 0.473, Loss_fe 0.651, Loss_kd 0.348, Train_accy 45.96
2022-10-08 05:37:08,934 [foster.py] => Task 1, Epoch 9/34 => Loss 1.718, Loss_clf 0.471, Loss_fe 0.644, Loss_kd 0.352, Train_accy 45.54
2022-10-08 05:37:12,479 [foster.py] => Task 1, Epoch 10/34 => Loss 1.655, Loss_clf 0.443, Loss_fe 0.612, Loss_kd 0.350, Train_accy 47.15
2022-10-08 05:37:16,938 [foster.py] => Task 1, Epoch 11/34 => Loss 1.594, Loss_clf 0.417, Loss_fe 0.582, Loss_kd 0.347, Train_accy 47.32, Test_accy 64.87
2022-10-08 05:37:20,514 [foster.py] => Task 1, Epoch 12/34 => Loss 1.591, Loss_clf 0.424, Loss_fe 0.569, Loss_kd 0.348, Train_accy 46.81
2022-10-08 05:37:24,131 [foster.py] => Task 1, Epoch 13/34 => Loss 1.571, Loss_clf 0.419, Loss_fe 0.550, Loss_kd 0.351, Train_accy 48.34
2022-10-08 05:37:27,687 [foster.py] => Task 1, Epoch 14/34 => Loss 1.530, Loss_clf 0.403, Loss_fe 0.529, Loss_kd 0.349, Train_accy 47.58
2022-10-08 05:37:31,308 [foster.py] => Task 1, Epoch 15/34 => Loss 1.499, Loss_clf 0.391, Loss_fe 0.508, Loss_kd 0.350, Train_accy 46.30
2022-10-08 05:37:35,780 [foster.py] => Task 1, Epoch 16/34 => Loss 1.475, Loss_clf 0.383, Loss_fe 0.497, Loss_kd 0.347, Train_accy 45.88, Test_accy 64.87
2022-10-08 05:37:39,305 [foster.py] => Task 1, Epoch 17/34 => Loss 1.462, Loss_clf 0.372, Loss_fe 0.490, Loss_kd 0.350, Train_accy 49.45
2022-10-08 05:37:42,861 [foster.py] => Task 1, Epoch 18/34 => Loss 1.440, Loss_clf 0.363, Loss_fe 0.477, Loss_kd 0.350, Train_accy 49.02
2022-10-08 05:37:46,554 [foster.py] => Task 1, Epoch 19/34 => Loss 1.447, Loss_clf 0.369, Loss_fe 0.480, Loss_kd 0.349, Train_accy 48.51
2022-10-08 05:37:50,138 [foster.py] => Task 1, Epoch 20/34 => Loss 1.418, Loss_clf 0.357, Loss_fe 0.470, Loss_kd 0.345, Train_accy 48.68
2022-10-08 05:37:54,752 [foster.py] => Task 1, Epoch 21/34 => Loss 1.388, Loss_clf 0.344, Loss_fe 0.451, Loss_kd 0.346, Train_accy 49.79, Test_accy 64.52
2022-10-08 05:37:58,344 [foster.py] => Task 1, Epoch 22/34 => Loss 1.395, Loss_clf 0.346, Loss_fe 0.449, Loss_kd 0.350, Train_accy 49.28
2022-10-08 05:38:01,870 [foster.py] => Task 1, Epoch 23/34 => Loss 1.409, Loss_clf 0.356, Loss_fe 0.456, Loss_kd 0.348, Train_accy 47.15
2022-10-08 05:38:05,391 [foster.py] => Task 1, Epoch 24/34 => Loss 1.377, Loss_clf 0.337, Loss_fe 0.442, Loss_kd 0.349, Train_accy 48.94
2022-10-08 05:38:08,935 [foster.py] => Task 1, Epoch 25/34 => Loss 1.366, Loss_clf 0.330, Loss_fe 0.437, Loss_kd 0.349, Train_accy 48.94
2022-10-08 05:38:13,388 [foster.py] => Task 1, Epoch 26/34 => Loss 1.371, Loss_clf 0.330, Loss_fe 0.437, Loss_kd 0.352, Train_accy 50.30, Test_accy 64.87
2022-10-08 05:38:16,965 [foster.py] => Task 1, Epoch 27/34 => Loss 1.370, Loss_clf 0.335, Loss_fe 0.437, Loss_kd 0.349, Train_accy 50.81
2022-10-08 05:38:20,572 [foster.py] => Task 1, Epoch 28/34 => Loss 1.382, Loss_clf 0.339, Loss_fe 0.445, Loss_kd 0.349, Train_accy 48.17
2022-10-08 05:38:24,232 [foster.py] => Task 1, Epoch 29/34 => Loss 1.348, Loss_clf 0.323, Loss_fe 0.422, Loss_kd 0.352, Train_accy 50.38
2022-10-08 05:38:27,836 [foster.py] => Task 1, Epoch 30/34 => Loss 1.362, Loss_clf 0.329, Loss_fe 0.432, Loss_kd 0.350, Train_accy 49.36
2022-10-08 05:38:32,268 [foster.py] => Task 1, Epoch 31/34 => Loss 1.342, Loss_clf 0.322, Loss_fe 0.424, Loss_kd 0.347, Train_accy 50.47, Test_accy 65.23
2022-10-08 05:38:35,881 [foster.py] => Task 1, Epoch 32/34 => Loss 1.369, Loss_clf 0.336, Loss_fe 0.441, Loss_kd 0.345, Train_accy 48.94
2022-10-08 05:38:39,381 [foster.py] => Task 1, Epoch 33/34 => Loss 1.360, Loss_clf 0.332, Loss_fe 0.433, Loss_kd 0.347, Train_accy 49.02
2022-10-08 05:38:42,961 [foster.py] => Task 1, Epoch 34/34 => Loss 1.362, Loss_clf 0.334, Loss_fe 0.428, Loss_kd 0.350, Train_accy 49.11
2022-10-08 05:38:42,961 [foster.py] => do not weight align teacher!
2022-10-08 05:38:42,962 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 05:38:49,287 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.693,  Train_accy 11.81, Test_accy 53.05
2022-10-08 05:38:53,811 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.551,  Train_accy 11.98
2022-10-08 05:38:58,325 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.477,  Train_accy 12.91
2022-10-08 05:39:02,891 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.451,  Train_accy 15.38
2022-10-08 05:39:07,421 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.412,  Train_accy 17.08
2022-10-08 05:39:12,841 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.391,  Train_accy 18.52, Test_accy 56.63
2022-10-08 05:39:16,923 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.383,  Train_accy 18.86
2022-10-08 05:39:21,036 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.377,  Train_accy 19.88
2022-10-08 05:39:25,122 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.364,  Train_accy 20.22
2022-10-08 05:39:29,297 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.354,  Train_accy 22.01
2022-10-08 05:39:35,715 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.351,  Train_accy 21.67, Test_accy 59.86
2022-10-08 05:39:40,581 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.338,  Train_accy 22.85
2022-10-08 05:39:45,424 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.335,  Train_accy 23.53
2022-10-08 05:39:50,339 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.330,  Train_accy 23.70
2022-10-08 05:39:55,062 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.325,  Train_accy 23.36
2022-10-08 05:40:00,572 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.326,  Train_accy 24.21, Test_accy 59.86
2022-10-08 05:40:05,297 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.322,  Train_accy 25.06
2022-10-08 05:40:10,116 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.323,  Train_accy 24.30
2022-10-08 05:40:14,900 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.311,  Train_accy 23.62
2022-10-08 05:40:19,726 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.323,  Train_accy 24.13
2022-10-08 05:40:25,295 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.314,  Train_accy 23.70, Test_accy 59.86
2022-10-08 05:40:29,511 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.319,  Train_accy 24.21
2022-10-08 05:40:33,768 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.317,  Train_accy 23.96
2022-10-08 05:40:37,998 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.324,  Train_accy 24.81
2022-10-08 05:40:42,265 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.318,  Train_accy 23.70
2022-10-08 05:40:47,417 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.314,  Train_accy 23.87, Test_accy 60.57
2022-10-08 05:40:47,418 [foster.py] => do not weight align student!
2022-10-08 05:40:48,139 [foster.py] => darknet eval: 
2022-10-08 05:40:48,139 [foster.py] => CNN top1 curve: 60.57
2022-10-08 05:40:48,139 [foster.py] => CNN top5 curve: 97.13
2022-10-08 05:40:48,140 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 05:40:56,899 [foster.py] => Exemplar size: 240
2022-10-08 05:40:56,899 [trainer.py] => CNN: {'total': 64.87, 'old': 84.62, 'new': 34.55, 'base': 84.62, 'compound': 34.55}
2022-10-08 05:40:56,899 [trainer.py] => CNN top1 curve: [89.35, 64.87]
2022-10-08 05:40:56,899 [trainer.py] => CNN base curve: [89.35, 84.62]
2022-10-08 05:40:56,899 [trainer.py] => CNN old curve: [89.35, 84.62]
2022-10-08 05:40:56,899 [trainer.py] => CNN new curve: [0, 34.55]
2022-10-08 05:40:56,899 [trainer.py] => CNN compound curve: [0, 34.55]
2022-10-08 05:40:56,899 [trainer.py] => NME: {'total': 72.4, 'old': 78.7, 'new': 62.73, 'base': 78.7, 'compound': 62.73}
2022-10-08 05:40:56,899 [trainer.py] => NME top1 curve: [87.57, 72.4]
2022-10-08 05:40:56,899 [trainer.py] => NME base curve: [87.57, 78.7]
2022-10-08 05:40:56,899 [trainer.py] => NME old curve: [87.57, 78.7]
2022-10-08 05:40:56,899 [trainer.py] => NME new curve: [0, 62.73]
2022-10-08 05:40:56,900 [trainer.py] => NME compound curve: [0, 62.73]
2022-10-08 05:40:57,156 [foster.py] => Learning on 12-17
2022-10-08 05:40:57,156 [foster.py] => All params: 22385326
2022-10-08 05:40:57,156 [foster.py] => Trainable params: 11202658
2022-10-08 05:40:57,166 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 05:41:01,590 [foster.py] => Task 2, Epoch 1/34 => Loss 5.692, Loss_clf 2.063, Loss_fe 2.189, Loss_kd 1.016, Train_accy 37.85, Test_accy 48.49
2022-10-08 05:41:05,121 [foster.py] => Task 2, Epoch 2/34 => Loss 3.835, Loss_clf 0.979, Loss_fe 1.490, Loss_kd 0.964, Train_accy 41.72
2022-10-08 05:41:08,375 [foster.py] => Task 2, Epoch 3/34 => Loss 3.521, Loss_clf 0.856, Loss_fe 1.287, Loss_kd 0.973, Train_accy 39.35
2022-10-08 05:41:11,814 [foster.py] => Task 2, Epoch 4/34 => Loss 3.387, Loss_clf 0.814, Loss_fe 1.190, Loss_kd 0.977, Train_accy 40.69
2022-10-08 05:41:15,679 [foster.py] => Task 2, Epoch 5/34 => Loss 3.271, Loss_clf 0.788, Loss_fe 1.105, Loss_kd 0.972, Train_accy 37.78
2022-10-08 05:41:22,241 [foster.py] => Task 2, Epoch 6/34 => Loss 3.197, Loss_clf 0.773, Loss_fe 1.058, Loss_kd 0.964, Train_accy 39.43, Test_accy 49.25
2022-10-08 05:41:26,225 [foster.py] => Task 2, Epoch 7/34 => Loss 3.086, Loss_clf 0.725, Loss_fe 0.988, Loss_kd 0.969, Train_accy 39.59
2022-10-08 05:41:30,218 [foster.py] => Task 2, Epoch 8/34 => Loss 3.022, Loss_clf 0.711, Loss_fe 0.940, Loss_kd 0.968, Train_accy 40.22
2022-10-08 05:41:34,143 [foster.py] => Task 2, Epoch 9/34 => Loss 2.966, Loss_clf 0.691, Loss_fe 0.897, Loss_kd 0.973, Train_accy 41.72
2022-10-08 05:41:38,153 [foster.py] => Task 2, Epoch 10/34 => Loss 2.912, Loss_clf 0.662, Loss_fe 0.863, Loss_kd 0.979, Train_accy 41.88
2022-10-08 05:41:43,216 [foster.py] => Task 2, Epoch 11/34 => Loss 2.908, Loss_clf 0.670, Loss_fe 0.852, Loss_kd 0.978, Train_accy 39.27, Test_accy 50.50
2022-10-08 05:41:47,191 [foster.py] => Task 2, Epoch 12/34 => Loss 2.873, Loss_clf 0.670, Loss_fe 0.831, Loss_kd 0.969, Train_accy 41.80
2022-10-08 05:41:51,199 [foster.py] => Task 2, Epoch 13/34 => Loss 2.798, Loss_clf 0.635, Loss_fe 0.787, Loss_kd 0.971, Train_accy 41.32
2022-10-08 05:41:55,205 [foster.py] => Task 2, Epoch 14/34 => Loss 2.802, Loss_clf 0.639, Loss_fe 0.787, Loss_kd 0.972, Train_accy 41.56
2022-10-08 05:41:59,332 [foster.py] => Task 2, Epoch 15/34 => Loss 2.754, Loss_clf 0.617, Loss_fe 0.758, Loss_kd 0.973, Train_accy 42.11
2022-10-08 05:42:04,550 [foster.py] => Task 2, Epoch 16/34 => Loss 2.749, Loss_clf 0.619, Loss_fe 0.748, Loss_kd 0.976, Train_accy 43.53, Test_accy 50.00
2022-10-08 05:42:08,182 [foster.py] => Task 2, Epoch 17/34 => Loss 2.709, Loss_clf 0.599, Loss_fe 0.728, Loss_kd 0.975, Train_accy 42.67
2022-10-08 05:42:11,827 [foster.py] => Task 2, Epoch 18/34 => Loss 2.685, Loss_clf 0.595, Loss_fe 0.717, Loss_kd 0.969, Train_accy 43.77
2022-10-08 05:42:15,437 [foster.py] => Task 2, Epoch 19/34 => Loss 2.641, Loss_clf 0.574, Loss_fe 0.689, Loss_kd 0.973, Train_accy 44.16
2022-10-08 05:42:19,085 [foster.py] => Task 2, Epoch 20/34 => Loss 2.653, Loss_clf 0.586, Loss_fe 0.692, Loss_kd 0.970, Train_accy 43.77
2022-10-08 05:42:23,969 [foster.py] => Task 2, Epoch 21/34 => Loss 2.643, Loss_clf 0.580, Loss_fe 0.686, Loss_kd 0.971, Train_accy 42.90, Test_accy 52.51
2022-10-08 05:42:27,581 [foster.py] => Task 2, Epoch 22/34 => Loss 2.640, Loss_clf 0.575, Loss_fe 0.687, Loss_kd 0.973, Train_accy 44.72
2022-10-08 05:42:31,292 [foster.py] => Task 2, Epoch 23/34 => Loss 2.598, Loss_clf 0.566, Loss_fe 0.664, Loss_kd 0.966, Train_accy 44.09
2022-10-08 05:42:34,805 [foster.py] => Task 2, Epoch 24/34 => Loss 2.607, Loss_clf 0.561, Loss_fe 0.672, Loss_kd 0.970, Train_accy 44.56
2022-10-08 05:42:38,487 [foster.py] => Task 2, Epoch 25/34 => Loss 2.586, Loss_clf 0.551, Loss_fe 0.657, Loss_kd 0.973, Train_accy 45.11
2022-10-08 05:42:43,356 [foster.py] => Task 2, Epoch 26/34 => Loss 2.555, Loss_clf 0.541, Loss_fe 0.640, Loss_kd 0.971, Train_accy 45.35, Test_accy 52.26
2022-10-08 05:42:46,943 [foster.py] => Task 2, Epoch 27/34 => Loss 2.567, Loss_clf 0.538, Loss_fe 0.644, Loss_kd 0.978, Train_accy 46.06
2022-10-08 05:42:50,987 [foster.py] => Task 2, Epoch 28/34 => Loss 2.570, Loss_clf 0.543, Loss_fe 0.646, Loss_kd 0.974, Train_accy 44.95
2022-10-08 05:42:55,748 [foster.py] => Task 2, Epoch 29/34 => Loss 2.560, Loss_clf 0.539, Loss_fe 0.644, Loss_kd 0.973, Train_accy 44.79
2022-10-08 05:43:00,402 [foster.py] => Task 2, Epoch 30/34 => Loss 2.562, Loss_clf 0.536, Loss_fe 0.646, Loss_kd 0.974, Train_accy 45.90
2022-10-08 05:43:06,235 [foster.py] => Task 2, Epoch 31/34 => Loss 2.554, Loss_clf 0.534, Loss_fe 0.645, Loss_kd 0.971, Train_accy 45.35, Test_accy 52.26
2022-10-08 05:43:10,925 [foster.py] => Task 2, Epoch 32/34 => Loss 2.566, Loss_clf 0.535, Loss_fe 0.643, Loss_kd 0.980, Train_accy 46.61
2022-10-08 05:43:15,660 [foster.py] => Task 2, Epoch 33/34 => Loss 2.551, Loss_clf 0.538, Loss_fe 0.642, Loss_kd 0.968, Train_accy 44.64
2022-10-08 05:43:20,350 [foster.py] => Task 2, Epoch 34/34 => Loss 2.551, Loss_clf 0.536, Loss_fe 0.638, Loss_kd 0.972, Train_accy 45.19
2022-10-08 05:43:20,351 [foster.py] => do not weight align teacher!
2022-10-08 05:43:20,351 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 05:43:25,938 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.103,  Train_accy 11.83, Test_accy 42.46
2022-10-08 05:43:30,122 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 2.026,  Train_accy 12.07
2022-10-08 05:43:34,372 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.995,  Train_accy 12.54
2022-10-08 05:43:39,223 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.969,  Train_accy 12.62
2022-10-08 05:43:43,911 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.951,  Train_accy 12.70
2022-10-08 05:43:49,603 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.938,  Train_accy 12.46, Test_accy 42.96
2022-10-08 05:43:53,891 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.937,  Train_accy 12.93
2022-10-08 05:43:58,135 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.922,  Train_accy 13.09
2022-10-08 05:44:02,710 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.919,  Train_accy 12.78
2022-10-08 05:44:07,122 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.910,  Train_accy 13.25
2022-10-08 05:44:12,772 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.903,  Train_accy 13.41, Test_accy 43.22
2022-10-08 05:44:17,701 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.905,  Train_accy 13.25
2022-10-08 05:44:22,654 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.895,  Train_accy 13.17
2022-10-08 05:44:27,661 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.893,  Train_accy 13.01
2022-10-08 05:44:32,551 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.880,  Train_accy 13.72
2022-10-08 05:44:38,460 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.895,  Train_accy 13.64, Test_accy 42.96
2022-10-08 05:44:43,271 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.891,  Train_accy 13.56
2022-10-08 05:44:48,265 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.895,  Train_accy 14.20
2022-10-08 05:44:53,393 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.878,  Train_accy 14.35
2022-10-08 05:44:58,465 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.887,  Train_accy 14.12
2022-10-08 05:45:04,500 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.884,  Train_accy 14.43, Test_accy 42.96
2022-10-08 05:45:09,038 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.878,  Train_accy 14.04
2022-10-08 05:45:13,582 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.880,  Train_accy 13.88
2022-10-08 05:45:18,124 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.876,  Train_accy 14.35
2022-10-08 05:45:23,189 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.884,  Train_accy 13.64
2022-10-08 05:45:29,290 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.876,  Train_accy 14.04, Test_accy 43.22
2022-10-08 05:45:29,291 [foster.py] => do not weight align student!
2022-10-08 05:45:30,278 [foster.py] => darknet eval: 
2022-10-08 05:45:30,278 [foster.py] => CNN top1 curve: 43.22
2022-10-08 05:45:30,278 [foster.py] => CNN top5 curve: 90.95
2022-10-08 05:45:30,278 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 05:45:43,126 [foster.py] => Exemplar size: 340
2022-10-08 05:45:43,126 [trainer.py] => CNN: {'total': 52.76, 'old': 60.57, 'new': 34.45, 'base': 82.25, 'compound': 31.0}
2022-10-08 05:45:43,126 [trainer.py] => CNN top1 curve: [89.35, 64.87, 52.76]
2022-10-08 05:45:43,127 [trainer.py] => CNN base curve: [89.35, 84.62, 82.25]
2022-10-08 05:45:43,127 [trainer.py] => CNN old curve: [89.35, 84.62, 60.57]
2022-10-08 05:45:43,127 [trainer.py] => CNN new curve: [0, 34.55, 34.45]
2022-10-08 05:45:43,127 [trainer.py] => CNN compound curve: [0, 34.55, 31.0]
2022-10-08 05:45:43,127 [trainer.py] => NME: {'total': 61.06, 'old': 63.44, 'new': 55.46, 'base': 72.19, 'compound': 52.84}
2022-10-08 05:45:43,127 [trainer.py] => NME top1 curve: [87.57, 72.4, 61.06]
2022-10-08 05:45:43,127 [trainer.py] => NME base curve: [87.57, 78.7, 72.19]
2022-10-08 05:45:43,127 [trainer.py] => NME old curve: [87.57, 78.7, 63.44]
2022-10-08 05:45:43,127 [trainer.py] => NME new curve: [0, 62.73, 55.46]
2022-10-08 05:45:43,127 [trainer.py] => NME compound curve: [0, 62.73, 52.84]
2022-10-08 05:45:43,362 [foster.py] => Learning on 17-22
2022-10-08 05:45:43,363 [foster.py] => All params: 22395581
2022-10-08 05:45:43,363 [foster.py] => Trainable params: 11210348
2022-10-08 05:45:43,374 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 05:45:49,054 [foster.py] => Task 3, Epoch 1/34 => Loss 6.597, Loss_clf 2.106, Loss_fe 2.533, Loss_kd 1.513, Train_accy 29.25, Test_accy 36.63
2022-10-08 05:45:52,462 [foster.py] => Task 3, Epoch 2/34 => Loss 4.959, Loss_clf 1.223, Loss_fe 1.780, Loss_kd 1.511, Train_accy 32.22
2022-10-08 05:45:56,208 [foster.py] => Task 3, Epoch 3/34 => Loss 4.636, Loss_clf 1.121, Loss_fe 1.575, Loss_kd 1.499, Train_accy 32.73
2022-10-08 05:45:59,804 [foster.py] => Task 3, Epoch 4/34 => Loss 4.551, Loss_clf 1.116, Loss_fe 1.502, Loss_kd 1.494, Train_accy 35.12
2022-10-08 05:46:03,544 [foster.py] => Task 3, Epoch 5/34 => Loss 4.417, Loss_clf 1.085, Loss_fe 1.401, Loss_kd 1.492, Train_accy 34.47
2022-10-08 05:46:08,411 [foster.py] => Task 3, Epoch 6/34 => Loss 4.348, Loss_clf 1.062, Loss_fe 1.335, Loss_kd 1.507, Train_accy 36.50, Test_accy 43.37
2022-10-08 05:46:12,364 [foster.py] => Task 3, Epoch 7/34 => Loss 4.220, Loss_clf 1.010, Loss_fe 1.262, Loss_kd 1.506, Train_accy 36.07
2022-10-08 05:46:16,267 [foster.py] => Task 3, Epoch 8/34 => Loss 4.105, Loss_clf 0.969, Loss_fe 1.193, Loss_kd 1.502, Train_accy 36.65
2022-10-08 05:46:20,121 [foster.py] => Task 3, Epoch 9/34 => Loss 4.078, Loss_clf 0.970, Loss_fe 1.166, Loss_kd 1.501, Train_accy 36.65
2022-10-08 05:46:24,009 [foster.py] => Task 3, Epoch 10/34 => Loss 4.081, Loss_clf 0.961, Loss_fe 1.170, Loss_kd 1.507, Train_accy 39.84
2022-10-08 05:46:29,274 [foster.py] => Task 3, Epoch 11/34 => Loss 3.920, Loss_clf 0.902, Loss_fe 1.072, Loss_kd 1.504, Train_accy 37.74, Test_accy 44.55
2022-10-08 05:46:33,205 [foster.py] => Task 3, Epoch 12/34 => Loss 3.927, Loss_clf 0.889, Loss_fe 1.109, Loss_kd 1.491, Train_accy 39.26
2022-10-08 05:46:37,173 [foster.py] => Task 3, Epoch 13/34 => Loss 3.900, Loss_clf 0.898, Loss_fe 1.069, Loss_kd 1.494, Train_accy 39.99
2022-10-08 05:46:41,251 [foster.py] => Task 3, Epoch 14/34 => Loss 3.860, Loss_clf 0.893, Loss_fe 1.037, Loss_kd 1.492, Train_accy 41.65
2022-10-08 05:46:45,582 [foster.py] => Task 3, Epoch 15/34 => Loss 3.862, Loss_clf 0.906, Loss_fe 1.017, Loss_kd 1.498, Train_accy 37.59
2022-10-08 05:46:51,152 [foster.py] => Task 3, Epoch 16/34 => Loss 3.815, Loss_clf 0.888, Loss_fe 0.989, Loss_kd 1.497, Train_accy 42.24, Test_accy 45.54
2022-10-08 05:46:55,356 [foster.py] => Task 3, Epoch 17/34 => Loss 3.746, Loss_clf 0.834, Loss_fe 0.966, Loss_kd 1.504, Train_accy 42.16
2022-10-08 05:46:59,687 [foster.py] => Task 3, Epoch 18/34 => Loss 3.673, Loss_clf 0.804, Loss_fe 0.916, Loss_kd 1.509, Train_accy 40.78
2022-10-08 05:47:03,927 [foster.py] => Task 3, Epoch 19/34 => Loss 3.777, Loss_clf 0.836, Loss_fe 1.000, Loss_kd 1.501, Train_accy 40.28
2022-10-08 05:47:08,279 [foster.py] => Task 3, Epoch 20/34 => Loss 3.702, Loss_clf 0.818, Loss_fe 0.933, Loss_kd 1.507, Train_accy 41.29
2022-10-08 05:47:13,811 [foster.py] => Task 3, Epoch 21/34 => Loss 3.627, Loss_clf 0.790, Loss_fe 0.892, Loss_kd 1.503, Train_accy 41.44, Test_accy 46.34
2022-10-08 05:47:18,169 [foster.py] => Task 3, Epoch 22/34 => Loss 3.625, Loss_clf 0.787, Loss_fe 0.886, Loss_kd 1.508, Train_accy 42.67
2022-10-08 05:47:22,503 [foster.py] => Task 3, Epoch 23/34 => Loss 3.659, Loss_clf 0.807, Loss_fe 0.912, Loss_kd 1.499, Train_accy 42.53
2022-10-08 05:47:26,763 [foster.py] => Task 3, Epoch 24/34 => Loss 3.651, Loss_clf 0.800, Loss_fe 0.912, Loss_kd 1.498, Train_accy 43.69
2022-10-08 05:47:31,015 [foster.py] => Task 3, Epoch 25/34 => Loss 3.597, Loss_clf 0.774, Loss_fe 0.882, Loss_kd 1.500, Train_accy 44.70
2022-10-08 05:47:36,454 [foster.py] => Task 3, Epoch 26/34 => Loss 3.634, Loss_clf 0.794, Loss_fe 0.890, Loss_kd 1.507, Train_accy 43.83, Test_accy 46.93
2022-10-08 05:47:40,641 [foster.py] => Task 3, Epoch 27/34 => Loss 3.592, Loss_clf 0.776, Loss_fe 0.870, Loss_kd 1.503, Train_accy 43.69
2022-10-08 05:47:44,830 [foster.py] => Task 3, Epoch 28/34 => Loss 3.549, Loss_clf 0.756, Loss_fe 0.849, Loss_kd 1.502, Train_accy 42.74
2022-10-08 05:47:49,105 [foster.py] => Task 3, Epoch 29/34 => Loss 3.591, Loss_clf 0.759, Loss_fe 0.879, Loss_kd 1.509, Train_accy 44.41
2022-10-08 05:47:53,265 [foster.py] => Task 3, Epoch 30/34 => Loss 3.535, Loss_clf 0.741, Loss_fe 0.842, Loss_kd 1.508, Train_accy 44.78
2022-10-08 05:47:58,785 [foster.py] => Task 3, Epoch 31/34 => Loss 3.566, Loss_clf 0.747, Loss_fe 0.861, Loss_kd 1.513, Train_accy 44.70, Test_accy 47.33
2022-10-08 05:48:03,096 [foster.py] => Task 3, Epoch 32/34 => Loss 3.640, Loss_clf 0.797, Loss_fe 0.899, Loss_kd 1.502, Train_accy 44.34
2022-10-08 05:48:07,371 [foster.py] => Task 3, Epoch 33/34 => Loss 3.557, Loss_clf 0.752, Loss_fe 0.863, Loss_kd 1.501, Train_accy 44.56
2022-10-08 05:48:11,535 [foster.py] => Task 3, Epoch 34/34 => Loss 3.573, Loss_clf 0.749, Loss_fe 0.869, Loss_kd 1.511, Train_accy 44.56
2022-10-08 05:48:11,535 [foster.py] => do not weight align teacher!
2022-10-08 05:48:11,536 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 05:48:17,865 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.476,  Train_accy 12.48, Test_accy 36.24
2022-10-08 05:48:23,000 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.416,  Train_accy 13.06
2022-10-08 05:48:28,084 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.387,  Train_accy 13.13
2022-10-08 05:48:33,175 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.374,  Train_accy 13.79
2022-10-08 05:48:38,233 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.374,  Train_accy 13.50
2022-10-08 05:48:44,418 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.368,  Train_accy 13.13, Test_accy 36.04
2022-10-08 05:48:49,616 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.371,  Train_accy 13.57
2022-10-08 05:48:54,799 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.346,  Train_accy 13.86
2022-10-08 05:48:59,875 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.334,  Train_accy 13.93
2022-10-08 05:49:04,948 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.355,  Train_accy 13.79
2022-10-08 05:49:11,032 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.334,  Train_accy 13.79, Test_accy 36.24
2022-10-08 05:49:16,115 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.342,  Train_accy 13.43
2022-10-08 05:49:21,138 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.332,  Train_accy 13.64
2022-10-08 05:49:26,308 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.329,  Train_accy 14.30
2022-10-08 05:49:31,307 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.325,  Train_accy 14.08
2022-10-08 05:49:37,372 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.326,  Train_accy 13.64, Test_accy 37.23
2022-10-08 05:49:42,524 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.325,  Train_accy 13.86
2022-10-08 05:49:47,628 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.315,  Train_accy 14.15
2022-10-08 05:49:52,785 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.325,  Train_accy 14.88
2022-10-08 05:49:57,802 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.321,  Train_accy 14.37
2022-10-08 05:50:03,800 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.326,  Train_accy 14.30, Test_accy 37.62
2022-10-08 05:50:08,859 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.310,  Train_accy 14.30
2022-10-08 05:50:13,999 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.318,  Train_accy 14.15
2022-10-08 05:50:19,142 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.316,  Train_accy 14.80
2022-10-08 05:50:24,296 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.318,  Train_accy 14.15
2022-10-08 05:50:30,382 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.323,  Train_accy 14.22, Test_accy 37.62
2022-10-08 05:50:30,383 [foster.py] => do not weight align student!
2022-10-08 05:50:31,440 [foster.py] => darknet eval: 
2022-10-08 05:50:31,441 [foster.py] => CNN top1 curve: 37.62
2022-10-08 05:50:31,441 [foster.py] => CNN top5 curve: 83.37
2022-10-08 05:50:31,441 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 05:50:44,254 [foster.py] => Exemplar size: 440
2022-10-08 05:50:44,254 [trainer.py] => CNN: {'total': 46.73, 'old': 50.5, 'new': 32.71, 'base': 81.66, 'compound': 29.17}
2022-10-08 05:50:44,254 [trainer.py] => CNN top1 curve: [89.35, 64.87, 52.76, 46.73]
2022-10-08 05:50:44,254 [trainer.py] => CNN base curve: [89.35, 84.62, 82.25, 81.66]
2022-10-08 05:50:44,254 [trainer.py] => CNN old curve: [89.35, 84.62, 60.57, 50.5]
2022-10-08 05:50:44,254 [trainer.py] => CNN new curve: [0, 34.55, 34.45, 32.71]
2022-10-08 05:50:44,254 [trainer.py] => CNN compound curve: [0, 34.55, 31.0, 29.17]
2022-10-08 05:50:44,254 [trainer.py] => NME: {'total': 54.65, 'old': 57.04, 'new': 45.79, 'base': 72.19, 'compound': 45.83}
2022-10-08 05:50:44,254 [trainer.py] => NME top1 curve: [87.57, 72.4, 61.06, 54.65]
2022-10-08 05:50:44,254 [trainer.py] => NME base curve: [87.57, 78.7, 72.19, 72.19]
2022-10-08 05:50:44,254 [trainer.py] => NME old curve: [87.57, 78.7, 63.44, 57.04]
2022-10-08 05:50:44,254 [trainer.py] => NME new curve: [0, 62.73, 55.46, 45.79]
2022-10-08 05:50:44,254 [trainer.py] => NME compound curve: [0, 62.73, 52.84, 45.83]
2022-10-08 05:50:44,256 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 05:50:44,256 [trainer.py] => prefix: cil
2022-10-08 05:50:44,256 [trainer.py] => dataset: CFEE
2022-10-08 05:50:44,256 [trainer.py] => memory_size: 2000
2022-10-08 05:50:44,256 [trainer.py] => memory_per_class: 20
2022-10-08 05:50:44,256 [trainer.py] => fixed_memory: True
2022-10-08 05:50:44,256 [trainer.py] => shuffle: True
2022-10-08 05:50:44,256 [trainer.py] => init_cls: 7
2022-10-08 05:50:44,256 [trainer.py] => increment: 5
2022-10-08 05:50:44,256 [trainer.py] => model_name: foster
2022-10-08 05:50:44,256 [trainer.py] => convnet_type: resnet18
2022-10-08 05:50:44,256 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 05:50:44,256 [trainer.py] => seed: 1993
2022-10-08 05:50:44,256 [trainer.py] => beta1: 0.96
2022-10-08 05:50:44,256 [trainer.py] => beta2: 0.97
2022-10-08 05:50:44,256 [trainer.py] => oofc: ft
2022-10-08 05:50:44,256 [trainer.py] => is_teacher_wa: False
2022-10-08 05:50:44,256 [trainer.py] => is_student_wa: False
2022-10-08 05:50:44,256 [trainer.py] => lambda_okd: 1
2022-10-08 05:50:44,256 [trainer.py] => wa_value: 1
2022-10-08 05:50:44,256 [trainer.py] => init_epochs: 40
2022-10-08 05:50:44,256 [trainer.py] => init_lr: 0.01
2022-10-08 05:50:44,257 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 05:50:44,257 [trainer.py] => boosting_epochs: 34
2022-10-08 05:50:44,257 [trainer.py] => compression_epochs: 26
2022-10-08 05:50:44,257 [trainer.py] => lr: 0.001
2022-10-08 05:50:44,257 [trainer.py] => batch_size: 32
2022-10-08 05:50:44,257 [trainer.py] => weight_decay: 0.0005
2022-10-08 05:50:44,257 [trainer.py] => num_workers: 8
2022-10-08 05:50:44,257 [trainer.py] => T: 2
2022-10-08 05:50:44,257 [trainer.py] => nb_runs: 3
2022-10-08 05:50:44,257 [trainer.py] => fold: 10
2022-10-08 05:50:44,257 [data.py] => ========== Fold:6 ==========
2022-10-08 05:50:44,263 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 13, 17, 15, 9, 11, 20, 18, 12, 14, 7, 10, 19, 21, 16, 8]
2022-10-08 05:50:44,500 [foster.py] => Learning on 0-7
2022-10-08 05:50:44,500 [foster.py] => All params: 11183694
2022-10-08 05:50:44,500 [foster.py] => Trainable params: 11183694
2022-10-08 05:50:47,607 [foster.py] => Task 0, Epoch 1/40 => Loss 1.349, Train_accy 50.83
2022-10-08 05:50:51,369 [foster.py] => Task 0, Epoch 2/40 => Loss 0.549, Train_accy 81.40, Test_accy 83.23
2022-10-08 05:50:55,087 [foster.py] => Task 0, Epoch 3/40 => Loss 0.382, Train_accy 86.24, Test_accy 84.47
2022-10-08 05:50:58,844 [foster.py] => Task 0, Epoch 4/40 => Loss 0.294, Train_accy 89.42, Test_accy 88.20
2022-10-08 05:51:02,571 [foster.py] => Task 0, Epoch 5/40 => Loss 0.248, Train_accy 90.73, Test_accy 88.82
2022-10-08 05:51:05,515 [foster.py] => Task 0, Epoch 6/40 => Loss 0.188, Train_accy 93.71
2022-10-08 05:51:09,513 [foster.py] => Task 0, Epoch 7/40 => Loss 0.189, Train_accy 94.19, Test_accy 86.96
2022-10-08 05:51:13,850 [foster.py] => Task 0, Epoch 8/40 => Loss 0.168, Train_accy 94.33, Test_accy 88.82
2022-10-08 05:51:17,584 [foster.py] => Task 0, Epoch 9/40 => Loss 0.129, Train_accy 96.27, Test_accy 83.23
2022-10-08 05:51:21,385 [foster.py] => Task 0, Epoch 10/40 => Loss 0.110, Train_accy 96.54, Test_accy 85.09
2022-10-08 05:51:24,334 [foster.py] => Task 0, Epoch 11/40 => Loss 0.080, Train_accy 97.37
2022-10-08 05:51:28,621 [foster.py] => Task 0, Epoch 12/40 => Loss 0.104, Train_accy 96.68, Test_accy 85.71
2022-10-08 05:51:32,914 [foster.py] => Task 0, Epoch 13/40 => Loss 0.067, Train_accy 97.44, Test_accy 85.09
2022-10-08 05:51:36,900 [foster.py] => Task 0, Epoch 14/40 => Loss 0.052, Train_accy 98.89, Test_accy 85.71
2022-10-08 05:51:40,596 [foster.py] => Task 0, Epoch 15/40 => Loss 0.037, Train_accy 99.17, Test_accy 89.44
2022-10-08 05:51:43,634 [foster.py] => Task 0, Epoch 16/40 => Loss 0.052, Train_accy 98.62
2022-10-08 05:51:47,557 [foster.py] => Task 0, Epoch 17/40 => Loss 0.039, Train_accy 98.89, Test_accy 86.34
2022-10-08 05:51:51,500 [foster.py] => Task 0, Epoch 18/40 => Loss 0.037, Train_accy 98.96, Test_accy 85.09
2022-10-08 05:51:55,491 [foster.py] => Task 0, Epoch 19/40 => Loss 0.029, Train_accy 99.45, Test_accy 85.09
2022-10-08 05:51:59,497 [foster.py] => Task 0, Epoch 20/40 => Loss 0.032, Train_accy 99.45, Test_accy 88.20
2022-10-08 05:52:02,520 [foster.py] => Task 0, Epoch 21/40 => Loss 0.035, Train_accy 99.24
2022-10-08 05:52:07,089 [foster.py] => Task 0, Epoch 22/40 => Loss 0.031, Train_accy 99.17, Test_accy 89.44
2022-10-08 05:52:11,613 [foster.py] => Task 0, Epoch 23/40 => Loss 0.028, Train_accy 99.59, Test_accy 87.58
2022-10-08 05:52:15,748 [foster.py] => Task 0, Epoch 24/40 => Loss 0.030, Train_accy 99.24, Test_accy 87.58
2022-10-08 05:52:19,641 [foster.py] => Task 0, Epoch 25/40 => Loss 0.020, Train_accy 99.45, Test_accy 88.20
2022-10-08 05:52:22,885 [foster.py] => Task 0, Epoch 26/40 => Loss 0.032, Train_accy 98.82
2022-10-08 05:52:26,686 [foster.py] => Task 0, Epoch 27/40 => Loss 0.022, Train_accy 99.59, Test_accy 86.96
2022-10-08 05:52:30,433 [foster.py] => Task 0, Epoch 28/40 => Loss 0.030, Train_accy 99.72, Test_accy 85.09
2022-10-08 05:52:34,331 [foster.py] => Task 0, Epoch 29/40 => Loss 0.021, Train_accy 99.45, Test_accy 85.71
2022-10-08 05:52:38,215 [foster.py] => Task 0, Epoch 30/40 => Loss 0.029, Train_accy 99.59, Test_accy 86.96
2022-10-08 05:52:41,654 [foster.py] => Task 0, Epoch 31/40 => Loss 0.015, Train_accy 100.00
2022-10-08 05:52:45,540 [foster.py] => Task 0, Epoch 32/40 => Loss 0.019, Train_accy 99.65, Test_accy 87.58
2022-10-08 05:52:49,477 [foster.py] => Task 0, Epoch 33/40 => Loss 0.020, Train_accy 99.65, Test_accy 85.71
2022-10-08 05:52:53,375 [foster.py] => Task 0, Epoch 34/40 => Loss 0.018, Train_accy 99.72, Test_accy 86.34
2022-10-08 05:52:57,197 [foster.py] => Task 0, Epoch 35/40 => Loss 0.015, Train_accy 100.00, Test_accy 88.20
2022-10-08 05:53:00,225 [foster.py] => Task 0, Epoch 36/40 => Loss 0.011, Train_accy 99.93
2022-10-08 05:53:04,224 [foster.py] => Task 0, Epoch 37/40 => Loss 0.017, Train_accy 99.86, Test_accy 88.82
2022-10-08 05:53:08,445 [foster.py] => Task 0, Epoch 38/40 => Loss 0.014, Train_accy 99.79, Test_accy 86.34
2022-10-08 05:53:12,224 [foster.py] => Task 0, Epoch 39/40 => Loss 0.016, Train_accy 99.86, Test_accy 87.58
2022-10-08 05:53:16,226 [foster.py] => Task 0, Epoch 40/40 => Loss 0.022, Train_accy 99.59, Test_accy 86.96
2022-10-08 05:53:16,226 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 05:53:23,513 [foster.py] => Exemplar size: 140
2022-10-08 05:53:23,513 [trainer.py] => CNN: {'total': 86.96, 'old': 86.96, 'new': 0, 'base': 86.96, 'compound': 0}
2022-10-08 05:53:23,513 [trainer.py] => CNN top1 curve: [86.96]
2022-10-08 05:53:23,513 [trainer.py] => CNN base curve: [86.96]
2022-10-08 05:53:23,513 [trainer.py] => CNN old curve: [86.96]
2022-10-08 05:53:23,513 [trainer.py] => CNN new curve: [0]
2022-10-08 05:53:23,514 [trainer.py] => CNN compound curve: [0]
2022-10-08 05:53:23,514 [trainer.py] => NME: {'total': 88.82, 'old': 88.82, 'new': 0, 'base': 88.82, 'compound': 0}
2022-10-08 05:53:23,514 [trainer.py] => NME top1 curve: [88.82]
2022-10-08 05:53:23,514 [trainer.py] => NME base curve: [88.82]
2022-10-08 05:53:23,514 [trainer.py] => NME old curve: [88.82]
2022-10-08 05:53:23,514 [trainer.py] => NME new curve: [0]
2022-10-08 05:53:23,514 [trainer.py] => NME compound curve: [0]
2022-10-08 05:53:23,762 [foster.py] => Learning on 7-12
2022-10-08 05:53:23,763 [foster.py] => All params: 22375071
2022-10-08 05:53:23,763 [foster.py] => Trainable params: 11194968
2022-10-08 05:53:23,773 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 05:53:27,729 [foster.py] => Task 1, Epoch 1/34 => Loss 4.868, Loss_clf 2.237, Loss_fe 1.981, Loss_kd 0.379, Train_accy 34.39, Test_accy 63.51
2022-10-08 05:53:30,948 [foster.py] => Task 1, Epoch 2/34 => Loss 2.594, Loss_clf 0.738, Loss_fe 1.217, Loss_kd 0.373, Train_accy 60.19
2022-10-08 05:53:34,293 [foster.py] => Task 1, Epoch 3/34 => Loss 2.190, Loss_clf 0.583, Loss_fe 0.976, Loss_kd 0.368, Train_accy 46.26
2022-10-08 05:53:37,511 [foster.py] => Task 1, Epoch 4/34 => Loss 2.007, Loss_clf 0.539, Loss_fe 0.853, Loss_kd 0.359, Train_accy 45.49
2022-10-08 05:53:40,857 [foster.py] => Task 1, Epoch 5/34 => Loss 1.919, Loss_clf 0.515, Loss_fe 0.786, Loss_kd 0.361, Train_accy 45.74
2022-10-08 05:53:45,468 [foster.py] => Task 1, Epoch 6/34 => Loss 1.859, Loss_clf 0.506, Loss_fe 0.735, Loss_kd 0.360, Train_accy 44.45, Test_accy 66.67
2022-10-08 05:53:48,670 [foster.py] => Task 1, Epoch 7/34 => Loss 1.818, Loss_clf 0.490, Loss_fe 0.701, Loss_kd 0.365, Train_accy 46.17
2022-10-08 05:53:51,937 [foster.py] => Task 1, Epoch 8/34 => Loss 1.742, Loss_clf 0.471, Loss_fe 0.652, Loss_kd 0.362, Train_accy 44.88
2022-10-08 05:53:55,415 [foster.py] => Task 1, Epoch 9/34 => Loss 1.679, Loss_clf 0.446, Loss_fe 0.619, Loss_kd 0.358, Train_accy 46.00
2022-10-08 05:53:59,114 [foster.py] => Task 1, Epoch 10/34 => Loss 1.661, Loss_clf 0.449, Loss_fe 0.601, Loss_kd 0.357, Train_accy 46.09
2022-10-08 05:54:03,665 [foster.py] => Task 1, Epoch 11/34 => Loss 1.659, Loss_clf 0.450, Loss_fe 0.596, Loss_kd 0.358, Train_accy 44.97, Test_accy 67.37
2022-10-08 05:54:07,324 [foster.py] => Task 1, Epoch 12/34 => Loss 1.605, Loss_clf 0.424, Loss_fe 0.563, Loss_kd 0.360, Train_accy 46.35
2022-10-08 05:54:10,987 [foster.py] => Task 1, Epoch 13/34 => Loss 1.576, Loss_clf 0.407, Loss_fe 0.546, Loss_kd 0.363, Train_accy 46.78
2022-10-08 05:54:14,740 [foster.py] => Task 1, Epoch 14/34 => Loss 1.567, Loss_clf 0.418, Loss_fe 0.537, Loss_kd 0.356, Train_accy 47.29
2022-10-08 05:54:18,423 [foster.py] => Task 1, Epoch 15/34 => Loss 1.525, Loss_clf 0.391, Loss_fe 0.520, Loss_kd 0.358, Train_accy 47.46
2022-10-08 05:54:23,174 [foster.py] => Task 1, Epoch 16/34 => Loss 1.523, Loss_clf 0.397, Loss_fe 0.515, Loss_kd 0.356, Train_accy 46.43, Test_accy 68.42
2022-10-08 05:54:26,804 [foster.py] => Task 1, Epoch 17/34 => Loss 1.465, Loss_clf 0.370, Loss_fe 0.485, Loss_kd 0.356, Train_accy 45.74
2022-10-08 05:54:30,532 [foster.py] => Task 1, Epoch 18/34 => Loss 1.476, Loss_clf 0.373, Loss_fe 0.490, Loss_kd 0.358, Train_accy 47.98
2022-10-08 05:54:34,333 [foster.py] => Task 1, Epoch 19/34 => Loss 1.470, Loss_clf 0.378, Loss_fe 0.481, Loss_kd 0.357, Train_accy 46.60
2022-10-08 05:54:38,078 [foster.py] => Task 1, Epoch 20/34 => Loss 1.459, Loss_clf 0.363, Loss_fe 0.481, Loss_kd 0.359, Train_accy 47.72
2022-10-08 05:54:42,747 [foster.py] => Task 1, Epoch 21/34 => Loss 1.419, Loss_clf 0.349, Loss_fe 0.454, Loss_kd 0.360, Train_accy 47.72, Test_accy 68.07
2022-10-08 05:54:46,489 [foster.py] => Task 1, Epoch 22/34 => Loss 1.440, Loss_clf 0.356, Loss_fe 0.473, Loss_kd 0.356, Train_accy 48.67
2022-10-08 05:54:50,209 [foster.py] => Task 1, Epoch 23/34 => Loss 1.417, Loss_clf 0.347, Loss_fe 0.454, Loss_kd 0.359, Train_accy 47.55
2022-10-08 05:54:53,936 [foster.py] => Task 1, Epoch 24/34 => Loss 1.417, Loss_clf 0.358, Loss_fe 0.445, Loss_kd 0.359, Train_accy 47.64
2022-10-08 05:54:57,686 [foster.py] => Task 1, Epoch 25/34 => Loss 1.442, Loss_clf 0.363, Loss_fe 0.465, Loss_kd 0.358, Train_accy 48.50
2022-10-08 05:55:02,373 [foster.py] => Task 1, Epoch 26/34 => Loss 1.393, Loss_clf 0.342, Loss_fe 0.441, Loss_kd 0.355, Train_accy 49.44, Test_accy 69.47
2022-10-08 05:55:06,025 [foster.py] => Task 1, Epoch 27/34 => Loss 1.390, Loss_clf 0.340, Loss_fe 0.441, Loss_kd 0.355, Train_accy 49.27
2022-10-08 05:55:09,881 [foster.py] => Task 1, Epoch 28/34 => Loss 1.407, Loss_clf 0.338, Loss_fe 0.449, Loss_kd 0.361, Train_accy 49.53
2022-10-08 05:55:13,611 [foster.py] => Task 1, Epoch 29/34 => Loss 1.413, Loss_clf 0.349, Loss_fe 0.451, Loss_kd 0.358, Train_accy 48.58
2022-10-08 05:55:17,322 [foster.py] => Task 1, Epoch 30/34 => Loss 1.375, Loss_clf 0.335, Loss_fe 0.439, Loss_kd 0.351, Train_accy 48.07
2022-10-08 05:55:21,902 [foster.py] => Task 1, Epoch 31/34 => Loss 1.381, Loss_clf 0.330, Loss_fe 0.436, Loss_kd 0.358, Train_accy 49.27, Test_accy 69.47
2022-10-08 05:55:25,246 [foster.py] => Task 1, Epoch 32/34 => Loss 1.398, Loss_clf 0.341, Loss_fe 0.440, Loss_kd 0.360, Train_accy 49.53
2022-10-08 05:55:28,626 [foster.py] => Task 1, Epoch 33/34 => Loss 1.379, Loss_clf 0.332, Loss_fe 0.433, Loss_kd 0.359, Train_accy 49.01
2022-10-08 05:55:32,267 [foster.py] => Task 1, Epoch 34/34 => Loss 1.387, Loss_clf 0.336, Loss_fe 0.440, Loss_kd 0.356, Train_accy 46.86
2022-10-08 05:55:32,267 [foster.py] => do not weight align teacher!
2022-10-08 05:55:32,268 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 05:55:37,324 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.620,  Train_accy 11.87, Test_accy 47.72
2022-10-08 05:55:42,584 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.511,  Train_accy 11.95
2022-10-08 05:55:47,934 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.471,  Train_accy 12.81
2022-10-08 05:55:53,184 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.446,  Train_accy 14.02
2022-10-08 05:55:58,368 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.422,  Train_accy 16.94
2022-10-08 05:56:04,308 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.400,  Train_accy 16.94, Test_accy 52.98
2022-10-08 05:56:08,931 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.387,  Train_accy 17.20
2022-10-08 05:56:13,403 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.380,  Train_accy 18.14
2022-10-08 05:56:17,874 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.356,  Train_accy 18.40
2022-10-08 05:56:22,546 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.359,  Train_accy 19.60
2022-10-08 05:56:27,887 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.356,  Train_accy 19.95, Test_accy 54.39
2022-10-08 05:56:31,929 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.343,  Train_accy 20.29
2022-10-08 05:56:36,003 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.342,  Train_accy 21.84
2022-10-08 05:56:40,085 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.333,  Train_accy 21.67
2022-10-08 05:56:44,094 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.325,  Train_accy 21.07
2022-10-08 05:56:48,828 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.343,  Train_accy 22.79, Test_accy 56.49
2022-10-08 05:56:52,964 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.320,  Train_accy 22.36
2022-10-08 05:56:57,056 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.332,  Train_accy 23.39
2022-10-08 05:57:01,170 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.322,  Train_accy 23.22
2022-10-08 05:57:05,324 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.319,  Train_accy 23.82
2022-10-08 05:57:10,071 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.320,  Train_accy 23.04, Test_accy 56.14
2022-10-08 05:57:14,214 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.333,  Train_accy 23.13
2022-10-08 05:57:18,269 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.321,  Train_accy 23.65
2022-10-08 05:57:22,480 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.323,  Train_accy 24.16
2022-10-08 05:57:26,666 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.324,  Train_accy 22.44
2022-10-08 05:57:40,108 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.325,  Train_accy 23.90, Test_accy 56.49
2022-10-08 05:57:40,108 [foster.py] => do not weight align student!
2022-10-08 05:57:40,933 [foster.py] => darknet eval: 
2022-10-08 05:57:40,933 [foster.py] => CNN top1 curve: 56.49
2022-10-08 05:57:40,933 [foster.py] => CNN top5 curve: 97.19
2022-10-08 05:57:40,934 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 05:57:49,585 [foster.py] => Exemplar size: 240
2022-10-08 05:57:49,585 [trainer.py] => CNN: {'total': 69.12, 'old': 81.99, 'new': 52.42, 'base': 81.99, 'compound': 52.42}
2022-10-08 05:57:49,585 [trainer.py] => CNN top1 curve: [86.96, 69.12]
2022-10-08 05:57:49,585 [trainer.py] => CNN base curve: [86.96, 81.99]
2022-10-08 05:57:49,585 [trainer.py] => CNN old curve: [86.96, 81.99]
2022-10-08 05:57:49,585 [trainer.py] => CNN new curve: [0, 52.42]
2022-10-08 05:57:49,585 [trainer.py] => CNN compound curve: [0, 52.42]
2022-10-08 05:57:49,585 [trainer.py] => NME: {'total': 73.68, 'old': 77.64, 'new': 68.55, 'base': 77.64, 'compound': 68.55}
2022-10-08 05:57:49,586 [trainer.py] => NME top1 curve: [88.82, 73.68]
2022-10-08 05:57:49,586 [trainer.py] => NME base curve: [88.82, 77.64]
2022-10-08 05:57:49,586 [trainer.py] => NME old curve: [88.82, 77.64]
2022-10-08 05:57:49,586 [trainer.py] => NME new curve: [0, 68.55]
2022-10-08 05:57:49,586 [trainer.py] => NME compound curve: [0, 68.55]
2022-10-08 05:57:49,832 [foster.py] => Learning on 12-17
2022-10-08 05:57:49,832 [foster.py] => All params: 22385326
2022-10-08 05:57:49,833 [foster.py] => Trainable params: 11202658
2022-10-08 05:57:49,843 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 05:57:53,775 [foster.py] => Task 2, Epoch 1/34 => Loss 5.733, Loss_clf 2.147, Loss_fe 2.139, Loss_kd 1.021, Train_accy 36.03, Test_accy 47.29
2022-10-08 05:57:56,988 [foster.py] => Task 2, Epoch 2/34 => Loss 3.923, Loss_clf 1.015, Loss_fe 1.534, Loss_kd 0.969, Train_accy 42.41
2022-10-08 05:58:00,354 [foster.py] => Task 2, Epoch 3/34 => Loss 3.591, Loss_clf 0.873, Loss_fe 1.328, Loss_kd 0.981, Train_accy 42.26
2022-10-08 05:58:03,525 [foster.py] => Task 2, Epoch 4/34 => Loss 3.413, Loss_clf 0.818, Loss_fe 1.192, Loss_kd 0.990, Train_accy 44.36
2022-10-08 05:58:06,709 [foster.py] => Task 2, Epoch 5/34 => Loss 3.280, Loss_clf 0.794, Loss_fe 1.104, Loss_kd 0.976, Train_accy 41.25
2022-10-08 05:58:11,040 [foster.py] => Task 2, Epoch 6/34 => Loss 3.185, Loss_clf 0.765, Loss_fe 1.037, Loss_kd 0.976, Train_accy 43.27, Test_accy 53.23
2022-10-08 05:58:14,580 [foster.py] => Task 2, Epoch 7/34 => Loss 3.103, Loss_clf 0.739, Loss_fe 0.984, Loss_kd 0.974, Train_accy 42.96
2022-10-08 05:58:17,915 [foster.py] => Task 2, Epoch 8/34 => Loss 3.047, Loss_clf 0.724, Loss_fe 0.939, Loss_kd 0.977, Train_accy 44.98
2022-10-08 05:58:21,620 [foster.py] => Task 2, Epoch 9/34 => Loss 3.013, Loss_clf 0.725, Loss_fe 0.909, Loss_kd 0.974, Train_accy 43.81
2022-10-08 05:58:25,308 [foster.py] => Task 2, Epoch 10/34 => Loss 2.957, Loss_clf 0.693, Loss_fe 0.879, Loss_kd 0.978, Train_accy 43.27
2022-10-08 05:58:30,178 [foster.py] => Task 2, Epoch 11/34 => Loss 2.912, Loss_clf 0.689, Loss_fe 0.849, Loss_kd 0.970, Train_accy 45.53, Test_accy 55.04
2022-10-08 05:58:33,895 [foster.py] => Task 2, Epoch 12/34 => Loss 2.892, Loss_clf 0.672, Loss_fe 0.827, Loss_kd 0.983, Train_accy 43.81
2022-10-08 05:58:37,532 [foster.py] => Task 2, Epoch 13/34 => Loss 2.885, Loss_clf 0.677, Loss_fe 0.813, Loss_kd 0.984, Train_accy 45.14
2022-10-08 05:58:41,223 [foster.py] => Task 2, Epoch 14/34 => Loss 2.818, Loss_clf 0.646, Loss_fe 0.778, Loss_kd 0.983, Train_accy 45.14
2022-10-08 05:58:45,074 [foster.py] => Task 2, Epoch 15/34 => Loss 2.786, Loss_clf 0.640, Loss_fe 0.755, Loss_kd 0.981, Train_accy 45.91
2022-10-08 05:58:49,803 [foster.py] => Task 2, Epoch 16/34 => Loss 2.718, Loss_clf 0.618, Loss_fe 0.718, Loss_kd 0.976, Train_accy 45.99, Test_accy 56.07
2022-10-08 05:58:53,606 [foster.py] => Task 2, Epoch 17/34 => Loss 2.754, Loss_clf 0.633, Loss_fe 0.736, Loss_kd 0.978, Train_accy 45.76
2022-10-08 05:58:57,370 [foster.py] => Task 2, Epoch 18/34 => Loss 2.723, Loss_clf 0.619, Loss_fe 0.721, Loss_kd 0.976, Train_accy 47.55
2022-10-08 05:59:01,024 [foster.py] => Task 2, Epoch 19/34 => Loss 2.695, Loss_clf 0.604, Loss_fe 0.705, Loss_kd 0.978, Train_accy 49.88
2022-10-08 05:59:04,811 [foster.py] => Task 2, Epoch 20/34 => Loss 2.693, Loss_clf 0.606, Loss_fe 0.700, Loss_kd 0.979, Train_accy 47.00
2022-10-08 05:59:09,629 [foster.py] => Task 2, Epoch 21/34 => Loss 2.665, Loss_clf 0.591, Loss_fe 0.680, Loss_kd 0.984, Train_accy 47.86, Test_accy 56.59
2022-10-08 05:59:13,435 [foster.py] => Task 2, Epoch 22/34 => Loss 2.619, Loss_clf 0.573, Loss_fe 0.667, Loss_kd 0.973, Train_accy 48.64
2022-10-08 05:59:18,458 [foster.py] => Task 2, Epoch 23/34 => Loss 2.679, Loss_clf 0.596, Loss_fe 0.686, Loss_kd 0.986, Train_accy 48.72
2022-10-08 05:59:23,318 [foster.py] => Task 2, Epoch 24/34 => Loss 2.638, Loss_clf 0.579, Loss_fe 0.669, Loss_kd 0.981, Train_accy 48.25
2022-10-08 05:59:28,334 [foster.py] => Task 2, Epoch 25/34 => Loss 2.642, Loss_clf 0.578, Loss_fe 0.670, Loss_kd 0.983, Train_accy 48.25
2022-10-08 05:59:34,393 [foster.py] => Task 2, Epoch 26/34 => Loss 2.624, Loss_clf 0.571, Loss_fe 0.672, Loss_kd 0.975, Train_accy 48.40, Test_accy 55.81
2022-10-08 05:59:38,650 [foster.py] => Task 2, Epoch 27/34 => Loss 2.649, Loss_clf 0.583, Loss_fe 0.677, Loss_kd 0.980, Train_accy 48.09
2022-10-08 05:59:42,499 [foster.py] => Task 2, Epoch 28/34 => Loss 2.641, Loss_clf 0.583, Loss_fe 0.664, Loss_kd 0.984, Train_accy 48.72
2022-10-08 05:59:46,222 [foster.py] => Task 2, Epoch 29/34 => Loss 2.630, Loss_clf 0.569, Loss_fe 0.669, Loss_kd 0.982, Train_accy 46.85
2022-10-08 05:59:50,104 [foster.py] => Task 2, Epoch 30/34 => Loss 2.619, Loss_clf 0.571, Loss_fe 0.660, Loss_kd 0.979, Train_accy 48.17
2022-10-08 05:59:54,992 [foster.py] => Task 2, Epoch 31/34 => Loss 2.598, Loss_clf 0.567, Loss_fe 0.650, Loss_kd 0.975, Train_accy 46.85, Test_accy 56.59
2022-10-08 05:59:58,863 [foster.py] => Task 2, Epoch 32/34 => Loss 2.639, Loss_clf 0.588, Loss_fe 0.660, Loss_kd 0.982, Train_accy 48.25
2022-10-08 06:00:02,671 [foster.py] => Task 2, Epoch 33/34 => Loss 2.626, Loss_clf 0.570, Loss_fe 0.662, Loss_kd 0.984, Train_accy 47.16
2022-10-08 06:00:06,447 [foster.py] => Task 2, Epoch 34/34 => Loss 2.615, Loss_clf 0.570, Loss_fe 0.659, Loss_kd 0.978, Train_accy 47.94
2022-10-08 06:00:06,448 [foster.py] => do not weight align teacher!
2022-10-08 06:00:06,449 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 06:00:12,158 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.131,  Train_accy 11.67, Test_accy 41.60
2022-10-08 06:00:16,683 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 2.050,  Train_accy 11.91
2022-10-08 06:00:21,191 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 2.020,  Train_accy 12.37
2022-10-08 06:00:25,808 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.989,  Train_accy 12.61
2022-10-08 06:00:30,342 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.972,  Train_accy 12.92
2022-10-08 06:00:35,723 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.943,  Train_accy 12.76, Test_accy 45.74
2022-10-08 06:00:40,167 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.965,  Train_accy 13.00
2022-10-08 06:00:44,785 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.936,  Train_accy 13.62
2022-10-08 06:00:49,226 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.927,  Train_accy 13.46
2022-10-08 06:00:53,845 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.927,  Train_accy 13.77
2022-10-08 06:00:59,683 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.928,  Train_accy 14.40, Test_accy 46.25
2022-10-08 06:01:04,654 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.918,  Train_accy 14.79
2022-10-08 06:01:09,729 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.914,  Train_accy 14.55
2022-10-08 06:01:14,778 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.909,  Train_accy 15.33
2022-10-08 06:01:19,843 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.909,  Train_accy 14.86
2022-10-08 06:01:25,675 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.922,  Train_accy 15.95, Test_accy 47.55
2022-10-08 06:01:30,789 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.906,  Train_accy 15.72
2022-10-08 06:01:35,837 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.914,  Train_accy 16.03
2022-10-08 06:01:40,883 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.910,  Train_accy 15.95
2022-10-08 06:01:45,927 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.904,  Train_accy 15.49
2022-10-08 06:01:51,680 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.895,  Train_accy 15.80, Test_accy 47.55
2022-10-08 06:01:56,243 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.915,  Train_accy 16.03
2022-10-08 06:02:00,614 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.907,  Train_accy 15.80
2022-10-08 06:02:05,116 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.908,  Train_accy 16.19
2022-10-08 06:02:09,605 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.895,  Train_accy 15.41
2022-10-08 06:02:14,837 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.900,  Train_accy 15.10, Test_accy 48.84
2022-10-08 06:02:14,838 [foster.py] => do not weight align student!
2022-10-08 06:02:15,633 [foster.py] => darknet eval: 
2022-10-08 06:02:15,633 [foster.py] => CNN top1 curve: 48.84
2022-10-08 06:02:15,634 [foster.py] => CNN top5 curve: 95.61
2022-10-08 06:02:15,634 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 06:02:26,182 [foster.py] => Exemplar size: 340
2022-10-08 06:02:26,182 [trainer.py] => CNN: {'total': 56.33, 'old': 64.21, 'new': 34.31, 'base': 80.75, 'compound': 38.94}
2022-10-08 06:02:26,182 [trainer.py] => CNN top1 curve: [86.96, 69.12, 56.33]
2022-10-08 06:02:26,182 [trainer.py] => CNN base curve: [86.96, 81.99, 80.75]
2022-10-08 06:02:26,182 [trainer.py] => CNN old curve: [86.96, 81.99, 64.21]
2022-10-08 06:02:26,182 [trainer.py] => CNN new curve: [0, 52.42, 34.31]
2022-10-08 06:02:26,182 [trainer.py] => CNN compound curve: [0, 52.42, 38.94]
2022-10-08 06:02:26,182 [trainer.py] => NME: {'total': 63.82, 'old': 65.61, 'new': 58.82, 'base': 70.81, 'compound': 58.85}
2022-10-08 06:02:26,182 [trainer.py] => NME top1 curve: [88.82, 73.68, 63.82]
2022-10-08 06:02:26,182 [trainer.py] => NME base curve: [88.82, 77.64, 70.81]
2022-10-08 06:02:26,182 [trainer.py] => NME old curve: [88.82, 77.64, 65.61]
2022-10-08 06:02:26,182 [trainer.py] => NME new curve: [0, 68.55, 58.82]
2022-10-08 06:02:26,182 [trainer.py] => NME compound curve: [0, 68.55, 58.85]
2022-10-08 06:02:26,455 [foster.py] => Learning on 17-22
2022-10-08 06:02:26,455 [foster.py] => All params: 22395581
2022-10-08 06:02:26,456 [foster.py] => Trainable params: 11210348
2022-10-08 06:02:26,469 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 06:02:31,222 [foster.py] => Task 3, Epoch 1/34 => Loss 6.560, Loss_clf 2.035, Loss_fe 2.562, Loss_kd 1.517, Train_accy 30.41, Test_accy 39.48
2022-10-08 06:02:34,729 [foster.py] => Task 3, Epoch 2/34 => Loss 4.961, Loss_clf 1.210, Loss_fe 1.828, Loss_kd 1.486, Train_accy 30.41
2022-10-08 06:02:38,145 [foster.py] => Task 3, Epoch 3/34 => Loss 4.645, Loss_clf 1.105, Loss_fe 1.615, Loss_kd 1.488, Train_accy 33.85
2022-10-08 06:02:41,713 [foster.py] => Task 3, Epoch 4/34 => Loss 4.479, Loss_clf 1.063, Loss_fe 1.489, Loss_kd 1.489, Train_accy 32.24
2022-10-08 06:02:46,156 [foster.py] => Task 3, Epoch 5/34 => Loss 4.334, Loss_clf 1.022, Loss_fe 1.391, Loss_kd 1.485, Train_accy 34.14
2022-10-08 06:02:51,899 [foster.py] => Task 3, Epoch 6/34 => Loss 4.254, Loss_clf 1.004, Loss_fe 1.328, Loss_kd 1.486, Train_accy 33.41, Test_accy 45.83
2022-10-08 06:02:55,790 [foster.py] => Task 3, Epoch 7/34 => Loss 4.185, Loss_clf 0.988, Loss_fe 1.262, Loss_kd 1.496, Train_accy 35.82
2022-10-08 06:02:59,731 [foster.py] => Task 3, Epoch 8/34 => Loss 4.108, Loss_clf 0.968, Loss_fe 1.208, Loss_kd 1.492, Train_accy 36.48
2022-10-08 06:03:04,549 [foster.py] => Task 3, Epoch 9/34 => Loss 4.078, Loss_clf 0.969, Loss_fe 1.181, Loss_kd 1.490, Train_accy 33.99
2022-10-08 06:03:09,497 [foster.py] => Task 3, Epoch 10/34 => Loss 4.018, Loss_clf 0.934, Loss_fe 1.148, Loss_kd 1.496, Train_accy 38.23
2022-10-08 06:03:15,663 [foster.py] => Task 3, Epoch 11/34 => Loss 3.936, Loss_clf 0.905, Loss_fe 1.092, Loss_kd 1.498, Train_accy 36.84, Test_accy 47.62
2022-10-08 06:03:20,443 [foster.py] => Task 3, Epoch 12/34 => Loss 3.895, Loss_clf 0.900, Loss_fe 1.075, Loss_kd 1.484, Train_accy 35.45
2022-10-08 06:03:24,664 [foster.py] => Task 3, Epoch 13/34 => Loss 3.824, Loss_clf 0.862, Loss_fe 1.024, Loss_kd 1.497, Train_accy 39.11
2022-10-08 06:03:28,915 [foster.py] => Task 3, Epoch 14/34 => Loss 3.834, Loss_clf 0.871, Loss_fe 1.022, Loss_kd 1.500, Train_accy 39.40
2022-10-08 06:03:33,210 [foster.py] => Task 3, Epoch 15/34 => Loss 3.788, Loss_clf 0.859, Loss_fe 0.999, Loss_kd 1.491, Train_accy 37.65
2022-10-08 06:03:38,684 [foster.py] => Task 3, Epoch 16/34 => Loss 3.719, Loss_clf 0.820, Loss_fe 0.967, Loss_kd 1.493, Train_accy 40.42, Test_accy 47.22
2022-10-08 06:03:42,958 [foster.py] => Task 3, Epoch 17/34 => Loss 3.744, Loss_clf 0.841, Loss_fe 0.969, Loss_kd 1.495, Train_accy 40.35
2022-10-08 06:03:47,229 [foster.py] => Task 3, Epoch 18/34 => Loss 3.711, Loss_clf 0.824, Loss_fe 0.952, Loss_kd 1.494, Train_accy 40.28
2022-10-08 06:03:51,471 [foster.py] => Task 3, Epoch 19/34 => Loss 3.688, Loss_clf 0.820, Loss_fe 0.935, Loss_kd 1.494, Train_accy 38.89
2022-10-08 06:03:55,773 [foster.py] => Task 3, Epoch 20/34 => Loss 3.653, Loss_clf 0.804, Loss_fe 0.921, Loss_kd 1.490, Train_accy 40.86
2022-10-08 06:04:01,250 [foster.py] => Task 3, Epoch 21/34 => Loss 3.619, Loss_clf 0.782, Loss_fe 0.896, Loss_kd 1.500, Train_accy 41.01, Test_accy 48.41
2022-10-08 06:04:05,548 [foster.py] => Task 3, Epoch 22/34 => Loss 3.599, Loss_clf 0.780, Loss_fe 0.885, Loss_kd 1.494, Train_accy 40.06
2022-10-08 06:04:09,750 [foster.py] => Task 3, Epoch 23/34 => Loss 3.588, Loss_clf 0.776, Loss_fe 0.880, Loss_kd 1.493, Train_accy 40.86
2022-10-08 06:04:14,012 [foster.py] => Task 3, Epoch 24/34 => Loss 3.561, Loss_clf 0.766, Loss_fe 0.861, Loss_kd 1.495, Train_accy 41.74
2022-10-08 06:04:18,318 [foster.py] => Task 3, Epoch 25/34 => Loss 3.593, Loss_clf 0.778, Loss_fe 0.880, Loss_kd 1.495, Train_accy 39.99
2022-10-08 06:04:23,866 [foster.py] => Task 3, Epoch 26/34 => Loss 3.570, Loss_clf 0.770, Loss_fe 0.864, Loss_kd 1.496, Train_accy 41.30, Test_accy 48.61
2022-10-08 06:04:27,756 [foster.py] => Task 3, Epoch 27/34 => Loss 3.572, Loss_clf 0.767, Loss_fe 0.870, Loss_kd 1.495, Train_accy 42.62
2022-10-08 06:04:31,794 [foster.py] => Task 3, Epoch 28/34 => Loss 3.550, Loss_clf 0.755, Loss_fe 0.855, Loss_kd 1.499, Train_accy 42.47
2022-10-08 06:04:36,571 [foster.py] => Task 3, Epoch 29/34 => Loss 3.550, Loss_clf 0.766, Loss_fe 0.852, Loss_kd 1.493, Train_accy 42.54
2022-10-08 06:04:41,166 [foster.py] => Task 3, Epoch 30/34 => Loss 3.517, Loss_clf 0.741, Loss_fe 0.844, Loss_kd 1.493, Train_accy 42.91
2022-10-08 06:04:47,059 [foster.py] => Task 3, Epoch 31/34 => Loss 3.547, Loss_clf 0.747, Loss_fe 0.856, Loss_kd 1.502, Train_accy 43.20, Test_accy 48.41
2022-10-08 06:04:51,151 [foster.py] => Task 3, Epoch 32/34 => Loss 3.524, Loss_clf 0.743, Loss_fe 0.846, Loss_kd 1.495, Train_accy 42.18
2022-10-08 06:04:55,275 [foster.py] => Task 3, Epoch 33/34 => Loss 3.511, Loss_clf 0.744, Loss_fe 0.837, Loss_kd 1.492, Train_accy 42.84
2022-10-08 06:04:59,328 [foster.py] => Task 3, Epoch 34/34 => Loss 3.538, Loss_clf 0.753, Loss_fe 0.847, Loss_kd 1.497, Train_accy 41.45
2022-10-08 06:04:59,329 [foster.py] => do not weight align teacher!
2022-10-08 06:04:59,329 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 06:05:05,400 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.449,  Train_accy 12.43, Test_accy 38.10
2022-10-08 06:05:10,173 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.375,  Train_accy 13.52
2022-10-08 06:05:14,994 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.356,  Train_accy 13.52
2022-10-08 06:05:19,786 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.347,  Train_accy 13.74
2022-10-08 06:05:24,683 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.332,  Train_accy 13.96
2022-10-08 06:05:30,514 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.320,  Train_accy 14.25, Test_accy 39.68
2022-10-08 06:05:35,446 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.319,  Train_accy 13.89
2022-10-08 06:05:40,363 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.320,  Train_accy 14.04
2022-10-08 06:05:45,231 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.306,  Train_accy 14.04
2022-10-08 06:05:50,219 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.302,  Train_accy 13.89
2022-10-08 06:05:56,002 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.305,  Train_accy 13.82, Test_accy 39.88
2022-10-08 06:06:00,886 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.300,  Train_accy 13.96
2022-10-08 06:06:05,934 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.304,  Train_accy 14.55
2022-10-08 06:06:10,808 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.301,  Train_accy 14.77
2022-10-08 06:06:15,640 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.289,  Train_accy 13.96
2022-10-08 06:06:21,475 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.290,  Train_accy 14.55, Test_accy 40.48
2022-10-08 06:06:26,294 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.293,  Train_accy 14.33
2022-10-08 06:06:31,189 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.293,  Train_accy 15.06
2022-10-08 06:06:36,194 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.288,  Train_accy 14.40
2022-10-08 06:06:41,070 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.289,  Train_accy 14.18
2022-10-08 06:06:46,992 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.294,  Train_accy 14.25, Test_accy 40.87
2022-10-08 06:06:51,868 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.295,  Train_accy 14.84
2022-10-08 06:06:56,763 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.293,  Train_accy 14.62
2022-10-08 06:07:01,623 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.293,  Train_accy 14.33
2022-10-08 06:07:06,599 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.288,  Train_accy 14.33
2022-10-08 06:07:12,461 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.289,  Train_accy 14.18, Test_accy 40.28
2022-10-08 06:07:12,461 [foster.py] => do not weight align student!
2022-10-08 06:07:13,401 [foster.py] => darknet eval: 
2022-10-08 06:07:13,401 [foster.py] => CNN top1 curve: 40.28
2022-10-08 06:07:13,401 [foster.py] => CNN top5 curve: 81.35
2022-10-08 06:07:13,402 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 06:07:26,058 [foster.py] => Exemplar size: 440
2022-10-08 06:07:26,058 [trainer.py] => CNN: {'total': 48.61, 'old': 54.52, 'new': 29.06, 'base': 77.02, 'compound': 35.28}
2022-10-08 06:07:26,059 [trainer.py] => CNN top1 curve: [86.96, 69.12, 56.33, 48.61]
2022-10-08 06:07:26,059 [trainer.py] => CNN base curve: [86.96, 81.99, 80.75, 77.02]
2022-10-08 06:07:26,059 [trainer.py] => CNN old curve: [86.96, 81.99, 64.21, 54.52]
2022-10-08 06:07:26,059 [trainer.py] => CNN new curve: [0, 52.42, 34.31, 29.06]
2022-10-08 06:07:26,059 [trainer.py] => CNN compound curve: [0, 52.42, 38.94, 35.28]
2022-10-08 06:07:26,059 [trainer.py] => NME: {'total': 57.14, 'old': 59.43, 'new': 49.57, 'base': 68.32, 'compound': 51.9}
2022-10-08 06:07:26,059 [trainer.py] => NME top1 curve: [88.82, 73.68, 63.82, 57.14]
2022-10-08 06:07:26,059 [trainer.py] => NME base curve: [88.82, 77.64, 70.81, 68.32]
2022-10-08 06:07:26,059 [trainer.py] => NME old curve: [88.82, 77.64, 65.61, 59.43]
2022-10-08 06:07:26,059 [trainer.py] => NME new curve: [0, 68.55, 58.82, 49.57]
2022-10-08 06:07:26,059 [trainer.py] => NME compound curve: [0, 68.55, 58.85, 51.9]
2022-10-08 06:07:26,060 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 06:07:26,060 [trainer.py] => prefix: cil
2022-10-08 06:07:26,060 [trainer.py] => dataset: CFEE
2022-10-08 06:07:26,060 [trainer.py] => memory_size: 2000
2022-10-08 06:07:26,060 [trainer.py] => memory_per_class: 20
2022-10-08 06:07:26,060 [trainer.py] => fixed_memory: True
2022-10-08 06:07:26,060 [trainer.py] => shuffle: True
2022-10-08 06:07:26,060 [trainer.py] => init_cls: 7
2022-10-08 06:07:26,060 [trainer.py] => increment: 5
2022-10-08 06:07:26,060 [trainer.py] => model_name: foster
2022-10-08 06:07:26,061 [trainer.py] => convnet_type: resnet18
2022-10-08 06:07:26,061 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 06:07:26,061 [trainer.py] => seed: 1993
2022-10-08 06:07:26,061 [trainer.py] => beta1: 0.96
2022-10-08 06:07:26,061 [trainer.py] => beta2: 0.97
2022-10-08 06:07:26,061 [trainer.py] => oofc: ft
2022-10-08 06:07:26,061 [trainer.py] => is_teacher_wa: False
2022-10-08 06:07:26,061 [trainer.py] => is_student_wa: False
2022-10-08 06:07:26,061 [trainer.py] => lambda_okd: 1
2022-10-08 06:07:26,061 [trainer.py] => wa_value: 1
2022-10-08 06:07:26,061 [trainer.py] => init_epochs: 40
2022-10-08 06:07:26,061 [trainer.py] => init_lr: 0.01
2022-10-08 06:07:26,061 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 06:07:26,061 [trainer.py] => boosting_epochs: 34
2022-10-08 06:07:26,061 [trainer.py] => compression_epochs: 26
2022-10-08 06:07:26,061 [trainer.py] => lr: 0.001
2022-10-08 06:07:26,061 [trainer.py] => batch_size: 32
2022-10-08 06:07:26,061 [trainer.py] => weight_decay: 0.0005
2022-10-08 06:07:26,061 [trainer.py] => num_workers: 8
2022-10-08 06:07:26,061 [trainer.py] => T: 2
2022-10-08 06:07:26,061 [trainer.py] => nb_runs: 3
2022-10-08 06:07:26,061 [trainer.py] => fold: 10
2022-10-08 06:07:26,061 [data.py] => ========== Fold:7 ==========
2022-10-08 06:07:26,067 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 13, 17, 15, 9, 11, 20, 18, 12, 14, 7, 10, 19, 21, 16, 8]
2022-10-08 06:07:26,303 [foster.py] => Learning on 0-7
2022-10-08 06:07:26,303 [foster.py] => All params: 11183694
2022-10-08 06:07:26,303 [foster.py] => Trainable params: 11183694
2022-10-08 06:07:29,089 [foster.py] => Task 0, Epoch 1/40 => Loss 1.354, Train_accy 49.73
2022-10-08 06:07:32,675 [foster.py] => Task 0, Epoch 2/40 => Loss 0.569, Train_accy 79.56, Test_accy 86.58
2022-10-08 06:07:36,155 [foster.py] => Task 0, Epoch 3/40 => Loss 0.366, Train_accy 87.31, Test_accy 85.23
2022-10-08 06:07:39,941 [foster.py] => Task 0, Epoch 4/40 => Loss 0.274, Train_accy 90.19, Test_accy 90.60
2022-10-08 06:07:43,660 [foster.py] => Task 0, Epoch 5/40 => Loss 0.215, Train_accy 93.07, Test_accy 88.59
2022-10-08 06:07:46,811 [foster.py] => Task 0, Epoch 6/40 => Loss 0.183, Train_accy 93.48
2022-10-08 06:07:50,793 [foster.py] => Task 0, Epoch 7/40 => Loss 0.169, Train_accy 93.62, Test_accy 88.59
2022-10-08 06:07:54,447 [foster.py] => Task 0, Epoch 8/40 => Loss 0.130, Train_accy 95.47, Test_accy 87.92
2022-10-08 06:07:58,321 [foster.py] => Task 0, Epoch 9/40 => Loss 0.089, Train_accy 97.67, Test_accy 85.91
2022-10-08 06:08:02,265 [foster.py] => Task 0, Epoch 10/40 => Loss 0.077, Train_accy 97.81, Test_accy 88.59
2022-10-08 06:08:05,601 [foster.py] => Task 0, Epoch 11/40 => Loss 0.091, Train_accy 97.33
2022-10-08 06:08:09,402 [foster.py] => Task 0, Epoch 12/40 => Loss 0.082, Train_accy 97.81, Test_accy 89.26
2022-10-08 06:08:13,738 [foster.py] => Task 0, Epoch 13/40 => Loss 0.053, Train_accy 98.29, Test_accy 85.23
2022-10-08 06:08:17,548 [foster.py] => Task 0, Epoch 14/40 => Loss 0.051, Train_accy 98.77, Test_accy 85.23
2022-10-08 06:08:21,583 [foster.py] => Task 0, Epoch 15/40 => Loss 0.043, Train_accy 98.90, Test_accy 89.93
2022-10-08 06:08:25,031 [foster.py] => Task 0, Epoch 16/40 => Loss 0.042, Train_accy 98.97
2022-10-08 06:08:28,905 [foster.py] => Task 0, Epoch 17/40 => Loss 0.035, Train_accy 99.31, Test_accy 85.91
2022-10-08 06:08:33,777 [foster.py] => Task 0, Epoch 18/40 => Loss 0.031, Train_accy 99.38, Test_accy 85.91
2022-10-08 06:08:38,528 [foster.py] => Task 0, Epoch 19/40 => Loss 0.027, Train_accy 99.66, Test_accy 87.92
2022-10-08 06:08:42,768 [foster.py] => Task 0, Epoch 20/40 => Loss 0.026, Train_accy 99.52, Test_accy 87.92
2022-10-08 06:08:46,053 [foster.py] => Task 0, Epoch 21/40 => Loss 0.024, Train_accy 99.66
2022-10-08 06:08:49,714 [foster.py] => Task 0, Epoch 22/40 => Loss 0.024, Train_accy 99.59, Test_accy 86.58
2022-10-08 06:08:53,991 [foster.py] => Task 0, Epoch 23/40 => Loss 0.025, Train_accy 99.59, Test_accy 86.58
2022-10-08 06:08:57,770 [foster.py] => Task 0, Epoch 24/40 => Loss 0.024, Train_accy 99.52, Test_accy 86.58
2022-10-08 06:09:01,454 [foster.py] => Task 0, Epoch 25/40 => Loss 0.022, Train_accy 99.45, Test_accy 87.25
2022-10-08 06:09:04,571 [foster.py] => Task 0, Epoch 26/40 => Loss 0.016, Train_accy 99.86
2022-10-08 06:09:08,191 [foster.py] => Task 0, Epoch 27/40 => Loss 0.014, Train_accy 99.86, Test_accy 86.58
2022-10-08 06:09:12,061 [foster.py] => Task 0, Epoch 28/40 => Loss 0.016, Train_accy 99.73, Test_accy 87.25
2022-10-08 06:09:16,145 [foster.py] => Task 0, Epoch 29/40 => Loss 0.020, Train_accy 99.59, Test_accy 85.91
2022-10-08 06:09:20,035 [foster.py] => Task 0, Epoch 30/40 => Loss 0.013, Train_accy 100.00, Test_accy 87.25
2022-10-08 06:09:23,490 [foster.py] => Task 0, Epoch 31/40 => Loss 0.019, Train_accy 99.66
2022-10-08 06:09:27,558 [foster.py] => Task 0, Epoch 32/40 => Loss 0.011, Train_accy 99.79, Test_accy 86.58
2022-10-08 06:09:31,592 [foster.py] => Task 0, Epoch 33/40 => Loss 0.015, Train_accy 99.59, Test_accy 87.92
2022-10-08 06:09:35,357 [foster.py] => Task 0, Epoch 34/40 => Loss 0.012, Train_accy 99.86, Test_accy 87.92
2022-10-08 06:09:39,325 [foster.py] => Task 0, Epoch 35/40 => Loss 0.015, Train_accy 99.86, Test_accy 87.92
2022-10-08 06:09:42,426 [foster.py] => Task 0, Epoch 36/40 => Loss 0.014, Train_accy 99.86
2022-10-08 06:09:46,167 [foster.py] => Task 0, Epoch 37/40 => Loss 0.012, Train_accy 99.86, Test_accy 85.91
2022-10-08 06:09:50,114 [foster.py] => Task 0, Epoch 38/40 => Loss 0.011, Train_accy 99.93, Test_accy 86.58
2022-10-08 06:09:53,804 [foster.py] => Task 0, Epoch 39/40 => Loss 0.011, Train_accy 99.86, Test_accy 85.91
2022-10-08 06:09:57,655 [foster.py] => Task 0, Epoch 40/40 => Loss 0.013, Train_accy 99.86, Test_accy 87.25
2022-10-08 06:09:57,656 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 06:10:04,981 [foster.py] => Exemplar size: 140
2022-10-08 06:10:04,981 [trainer.py] => CNN: {'total': 87.25, 'old': 87.25, 'new': 0, 'base': 87.25, 'compound': 0}
2022-10-08 06:10:04,981 [trainer.py] => CNN top1 curve: [87.25]
2022-10-08 06:10:04,981 [trainer.py] => CNN base curve: [87.25]
2022-10-08 06:10:04,981 [trainer.py] => CNN old curve: [87.25]
2022-10-08 06:10:04,981 [trainer.py] => CNN new curve: [0]
2022-10-08 06:10:04,981 [trainer.py] => CNN compound curve: [0]
2022-10-08 06:10:04,981 [trainer.py] => NME: {'total': 89.26, 'old': 89.26, 'new': 0, 'base': 89.26, 'compound': 0}
2022-10-08 06:10:04,981 [trainer.py] => NME top1 curve: [89.26]
2022-10-08 06:10:04,981 [trainer.py] => NME base curve: [89.26]
2022-10-08 06:10:04,981 [trainer.py] => NME old curve: [89.26]
2022-10-08 06:10:04,981 [trainer.py] => NME new curve: [0]
2022-10-08 06:10:04,981 [trainer.py] => NME compound curve: [0]
2022-10-08 06:10:05,231 [foster.py] => Learning on 7-12
2022-10-08 06:10:05,232 [foster.py] => All params: 22375071
2022-10-08 06:10:05,232 [foster.py] => Trainable params: 11194968
2022-10-08 06:10:05,243 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 06:10:09,118 [foster.py] => Task 1, Epoch 1/34 => Loss 4.619, Loss_clf 2.117, Loss_fe 1.855, Loss_kd 0.378, Train_accy 35.55, Test_accy 65.34
2022-10-08 06:10:12,182 [foster.py] => Task 1, Epoch 2/34 => Loss 2.480, Loss_clf 0.715, Loss_fe 1.121, Loss_kd 0.375, Train_accy 61.17
2022-10-08 06:10:15,282 [foster.py] => Task 1, Epoch 3/34 => Loss 2.160, Loss_clf 0.581, Loss_fe 0.943, Loss_kd 0.371, Train_accy 45.13
2022-10-08 06:10:18,853 [foster.py] => Task 1, Epoch 4/34 => Loss 1.962, Loss_clf 0.522, Loss_fe 0.822, Loss_kd 0.361, Train_accy 46.51
2022-10-08 06:10:22,394 [foster.py] => Task 1, Epoch 5/34 => Loss 1.961, Loss_clf 0.538, Loss_fe 0.803, Loss_kd 0.362, Train_accy 44.09
2022-10-08 06:10:26,819 [foster.py] => Task 1, Epoch 6/34 => Loss 1.843, Loss_clf 0.492, Loss_fe 0.729, Loss_kd 0.363, Train_accy 45.30, Test_accy 59.57
2022-10-08 06:10:30,335 [foster.py] => Task 1, Epoch 7/34 => Loss 1.771, Loss_clf 0.474, Loss_fe 0.677, Loss_kd 0.362, Train_accy 46.07
2022-10-08 06:10:33,867 [foster.py] => Task 1, Epoch 8/34 => Loss 1.739, Loss_clf 0.465, Loss_fe 0.653, Loss_kd 0.362, Train_accy 48.49
2022-10-08 06:10:37,387 [foster.py] => Task 1, Epoch 9/34 => Loss 1.693, Loss_clf 0.448, Loss_fe 0.620, Loss_kd 0.365, Train_accy 45.73
2022-10-08 06:10:40,813 [foster.py] => Task 1, Epoch 10/34 => Loss 1.688, Loss_clf 0.448, Loss_fe 0.619, Loss_kd 0.362, Train_accy 46.85
2022-10-08 06:10:45,243 [foster.py] => Task 1, Epoch 11/34 => Loss 1.628, Loss_clf 0.439, Loss_fe 0.574, Loss_kd 0.359, Train_accy 48.66, Test_accy 59.93
2022-10-08 06:10:48,349 [foster.py] => Task 1, Epoch 12/34 => Loss 1.599, Loss_clf 0.427, Loss_fe 0.556, Loss_kd 0.359, Train_accy 47.20
2022-10-08 06:10:51,691 [foster.py] => Task 1, Epoch 13/34 => Loss 1.562, Loss_clf 0.413, Loss_fe 0.545, Loss_kd 0.353, Train_accy 48.32
2022-10-08 06:10:55,014 [foster.py] => Task 1, Epoch 14/34 => Loss 1.576, Loss_clf 0.414, Loss_fe 0.542, Loss_kd 0.362, Train_accy 47.54
2022-10-08 06:10:58,435 [foster.py] => Task 1, Epoch 15/34 => Loss 1.518, Loss_clf 0.388, Loss_fe 0.506, Loss_kd 0.364, Train_accy 47.80
2022-10-08 06:11:02,810 [foster.py] => Task 1, Epoch 16/34 => Loss 1.482, Loss_clf 0.372, Loss_fe 0.494, Loss_kd 0.359, Train_accy 48.32, Test_accy 61.01
2022-10-08 06:11:06,216 [foster.py] => Task 1, Epoch 17/34 => Loss 1.473, Loss_clf 0.366, Loss_fe 0.484, Loss_kd 0.363, Train_accy 50.30
2022-10-08 06:11:09,590 [foster.py] => Task 1, Epoch 18/34 => Loss 1.466, Loss_clf 0.373, Loss_fe 0.477, Loss_kd 0.359, Train_accy 49.09
2022-10-08 06:11:13,050 [foster.py] => Task 1, Epoch 19/34 => Loss 1.468, Loss_clf 0.380, Loss_fe 0.473, Loss_kd 0.358, Train_accy 48.06
2022-10-08 06:11:16,567 [foster.py] => Task 1, Epoch 20/34 => Loss 1.444, Loss_clf 0.363, Loss_fe 0.462, Loss_kd 0.361, Train_accy 48.14
2022-10-08 06:11:20,982 [foster.py] => Task 1, Epoch 21/34 => Loss 1.422, Loss_clf 0.345, Loss_fe 0.456, Loss_kd 0.362, Train_accy 49.87, Test_accy 61.01
2022-10-08 06:11:24,542 [foster.py] => Task 1, Epoch 22/34 => Loss 1.501, Loss_clf 0.386, Loss_fe 0.503, Loss_kd 0.357, Train_accy 48.92
2022-10-08 06:11:28,073 [foster.py] => Task 1, Epoch 23/34 => Loss 1.403, Loss_clf 0.347, Loss_fe 0.445, Loss_kd 0.357, Train_accy 50.04
2022-10-08 06:11:31,600 [foster.py] => Task 1, Epoch 24/34 => Loss 1.386, Loss_clf 0.337, Loss_fe 0.435, Loss_kd 0.358, Train_accy 49.78
2022-10-08 06:11:35,134 [foster.py] => Task 1, Epoch 25/34 => Loss 1.407, Loss_clf 0.342, Loss_fe 0.452, Loss_kd 0.358, Train_accy 47.80
2022-10-08 06:11:39,650 [foster.py] => Task 1, Epoch 26/34 => Loss 1.436, Loss_clf 0.353, Loss_fe 0.463, Loss_kd 0.362, Train_accy 50.13, Test_accy 61.37
2022-10-08 06:11:43,120 [foster.py] => Task 1, Epoch 27/34 => Loss 1.374, Loss_clf 0.330, Loss_fe 0.431, Loss_kd 0.358, Train_accy 49.96
2022-10-08 06:11:46,667 [foster.py] => Task 1, Epoch 28/34 => Loss 1.388, Loss_clf 0.332, Loss_fe 0.439, Loss_kd 0.360, Train_accy 49.78
2022-10-08 06:11:50,176 [foster.py] => Task 1, Epoch 29/34 => Loss 1.408, Loss_clf 0.343, Loss_fe 0.448, Loss_kd 0.360, Train_accy 49.35
2022-10-08 06:11:53,903 [foster.py] => Task 1, Epoch 30/34 => Loss 1.368, Loss_clf 0.323, Loss_fe 0.427, Loss_kd 0.361, Train_accy 50.65
2022-10-08 06:11:58,370 [foster.py] => Task 1, Epoch 31/34 => Loss 1.393, Loss_clf 0.338, Loss_fe 0.432, Loss_kd 0.363, Train_accy 49.44, Test_accy 61.73
2022-10-08 06:12:01,914 [foster.py] => Task 1, Epoch 32/34 => Loss 1.386, Loss_clf 0.336, Loss_fe 0.433, Loss_kd 0.360, Train_accy 49.78
2022-10-08 06:12:05,464 [foster.py] => Task 1, Epoch 33/34 => Loss 1.365, Loss_clf 0.322, Loss_fe 0.421, Loss_kd 0.363, Train_accy 50.56
2022-10-08 06:12:09,088 [foster.py] => Task 1, Epoch 34/34 => Loss 1.389, Loss_clf 0.333, Loss_fe 0.440, Loss_kd 0.359, Train_accy 50.82
2022-10-08 06:12:09,089 [foster.py] => do not weight align teacher!
2022-10-08 06:12:09,090 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 06:12:14,302 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.679,  Train_accy 11.82, Test_accy 46.21
2022-10-08 06:12:18,454 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.539,  Train_accy 12.17
2022-10-08 06:12:22,700 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.477,  Train_accy 14.50
2022-10-08 06:12:26,914 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.435,  Train_accy 15.70
2022-10-08 06:12:31,100 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.417,  Train_accy 18.12
2022-10-08 06:12:36,166 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.399,  Train_accy 20.10, Test_accy 52.35
2022-10-08 06:12:40,299 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.371,  Train_accy 21.31
2022-10-08 06:12:44,252 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.374,  Train_accy 22.61
2022-10-08 06:12:48,323 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.350,  Train_accy 23.55
2022-10-08 06:12:52,434 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.350,  Train_accy 23.64
2022-10-08 06:12:57,520 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.351,  Train_accy 25.37, Test_accy 54.51
2022-10-08 06:13:01,794 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.342,  Train_accy 25.45
2022-10-08 06:13:06,114 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.339,  Train_accy 25.71
2022-10-08 06:13:10,478 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.322,  Train_accy 26.57
2022-10-08 06:13:14,755 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.314,  Train_accy 27.18
2022-10-08 06:13:19,727 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.336,  Train_accy 26.92, Test_accy 55.60
2022-10-08 06:13:23,956 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.333,  Train_accy 26.06
2022-10-08 06:13:28,131 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.320,  Train_accy 27.18
2022-10-08 06:13:32,360 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.317,  Train_accy 26.57
2022-10-08 06:13:36,576 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.319,  Train_accy 27.09
2022-10-08 06:13:41,576 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.307,  Train_accy 26.75, Test_accy 55.60
2022-10-08 06:13:45,842 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.306,  Train_accy 27.35
2022-10-08 06:13:50,082 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.314,  Train_accy 27.18
2022-10-08 06:13:54,245 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.311,  Train_accy 26.14
2022-10-08 06:13:58,466 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.297,  Train_accy 26.66
2022-10-08 06:14:03,518 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.316,  Train_accy 27.18, Test_accy 55.23
2022-10-08 06:14:03,519 [foster.py] => do not weight align student!
2022-10-08 06:14:04,199 [foster.py] => darknet eval: 
2022-10-08 06:14:04,199 [foster.py] => CNN top1 curve: 55.23
2022-10-08 06:14:04,199 [foster.py] => CNN top5 curve: 98.19
2022-10-08 06:14:04,199 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 06:14:13,088 [foster.py] => Exemplar size: 240
2022-10-08 06:14:13,089 [trainer.py] => CNN: {'total': 61.73, 'old': 79.19, 'new': 41.41, 'base': 79.19, 'compound': 41.41}
2022-10-08 06:14:13,089 [trainer.py] => CNN top1 curve: [87.25, 61.73]
2022-10-08 06:14:13,089 [trainer.py] => CNN base curve: [87.25, 79.19]
2022-10-08 06:14:13,089 [trainer.py] => CNN old curve: [87.25, 79.19]
2022-10-08 06:14:13,089 [trainer.py] => CNN new curve: [0, 41.41]
2022-10-08 06:14:13,089 [trainer.py] => CNN compound curve: [0, 41.41]
2022-10-08 06:14:13,089 [trainer.py] => NME: {'total': 68.23, 'old': 73.15, 'new': 62.5, 'base': 73.15, 'compound': 62.5}
2022-10-08 06:14:13,089 [trainer.py] => NME top1 curve: [89.26, 68.23]
2022-10-08 06:14:13,089 [trainer.py] => NME base curve: [89.26, 73.15]
2022-10-08 06:14:13,089 [trainer.py] => NME old curve: [89.26, 73.15]
2022-10-08 06:14:13,089 [trainer.py] => NME new curve: [0, 62.5]
2022-10-08 06:14:13,089 [trainer.py] => NME compound curve: [0, 62.5]
2022-10-08 06:14:13,324 [foster.py] => Learning on 12-17
2022-10-08 06:14:13,324 [foster.py] => All params: 22385326
2022-10-08 06:14:13,325 [foster.py] => Trainable params: 11202658
2022-10-08 06:14:13,335 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 06:14:17,663 [foster.py] => Task 2, Epoch 1/34 => Loss 5.779, Loss_clf 2.083, Loss_fe 2.237, Loss_kd 1.030, Train_accy 36.28, Test_accy 44.39
2022-10-08 06:14:21,202 [foster.py] => Task 2, Epoch 2/34 => Loss 3.831, Loss_clf 0.961, Loss_fe 1.462, Loss_kd 0.994, Train_accy 40.47
2022-10-08 06:14:24,880 [foster.py] => Task 2, Epoch 3/34 => Loss 3.529, Loss_clf 0.857, Loss_fe 1.268, Loss_kd 0.992, Train_accy 40.85
2022-10-08 06:14:29,405 [foster.py] => Task 2, Epoch 4/34 => Loss 3.382, Loss_clf 0.798, Loss_fe 1.169, Loss_kd 0.999, Train_accy 42.09
2022-10-08 06:14:33,913 [foster.py] => Task 2, Epoch 5/34 => Loss 3.261, Loss_clf 0.774, Loss_fe 1.081, Loss_kd 0.992, Train_accy 39.69
2022-10-08 06:14:39,510 [foster.py] => Task 2, Epoch 6/34 => Loss 3.159, Loss_clf 0.746, Loss_fe 1.010, Loss_kd 0.990, Train_accy 41.63, Test_accy 48.66
2022-10-08 06:14:43,146 [foster.py] => Task 2, Epoch 7/34 => Loss 3.084, Loss_clf 0.717, Loss_fe 0.961, Loss_kd 0.993, Train_accy 43.02
2022-10-08 06:14:46,858 [foster.py] => Task 2, Epoch 8/34 => Loss 3.000, Loss_clf 0.695, Loss_fe 0.908, Loss_kd 0.986, Train_accy 43.02
2022-10-08 06:14:50,477 [foster.py] => Task 2, Epoch 9/34 => Loss 2.987, Loss_clf 0.697, Loss_fe 0.878, Loss_kd 0.997, Train_accy 44.65
2022-10-08 06:14:54,547 [foster.py] => Task 2, Epoch 10/34 => Loss 2.916, Loss_clf 0.671, Loss_fe 0.841, Loss_kd 0.991, Train_accy 44.26
2022-10-08 06:14:59,653 [foster.py] => Task 2, Epoch 11/34 => Loss 2.862, Loss_clf 0.642, Loss_fe 0.799, Loss_kd 1.002, Train_accy 46.82, Test_accy 49.20
2022-10-08 06:15:03,724 [foster.py] => Task 2, Epoch 12/34 => Loss 2.834, Loss_clf 0.634, Loss_fe 0.793, Loss_kd 0.993, Train_accy 45.43
2022-10-08 06:15:07,758 [foster.py] => Task 2, Epoch 13/34 => Loss 2.809, Loss_clf 0.639, Loss_fe 0.760, Loss_kd 0.996, Train_accy 46.36
2022-10-08 06:15:11,771 [foster.py] => Task 2, Epoch 14/34 => Loss 2.752, Loss_clf 0.603, Loss_fe 0.738, Loss_kd 0.996, Train_accy 46.59
2022-10-08 06:15:15,937 [foster.py] => Task 2, Epoch 15/34 => Loss 2.736, Loss_clf 0.600, Loss_fe 0.728, Loss_kd 0.994, Train_accy 47.91
2022-10-08 06:15:21,084 [foster.py] => Task 2, Epoch 16/34 => Loss 2.715, Loss_clf 0.592, Loss_fe 0.708, Loss_kd 0.999, Train_accy 46.59, Test_accy 49.73
2022-10-08 06:15:25,250 [foster.py] => Task 2, Epoch 17/34 => Loss 2.703, Loss_clf 0.592, Loss_fe 0.704, Loss_kd 0.994, Train_accy 47.98
2022-10-08 06:15:29,281 [foster.py] => Task 2, Epoch 18/34 => Loss 2.662, Loss_clf 0.567, Loss_fe 0.675, Loss_kd 1.002, Train_accy 48.91
2022-10-08 06:15:33,401 [foster.py] => Task 2, Epoch 19/34 => Loss 2.640, Loss_clf 0.566, Loss_fe 0.666, Loss_kd 0.994, Train_accy 48.53
2022-10-08 06:15:37,398 [foster.py] => Task 2, Epoch 20/34 => Loss 2.655, Loss_clf 0.559, Loss_fe 0.671, Loss_kd 1.006, Train_accy 48.99
2022-10-08 06:15:42,474 [foster.py] => Task 2, Epoch 21/34 => Loss 2.616, Loss_clf 0.556, Loss_fe 0.647, Loss_kd 0.997, Train_accy 48.45, Test_accy 48.93
2022-10-08 06:15:46,584 [foster.py] => Task 2, Epoch 22/34 => Loss 2.635, Loss_clf 0.554, Loss_fe 0.663, Loss_kd 1.001, Train_accy 46.59
2022-10-08 06:15:50,743 [foster.py] => Task 2, Epoch 23/34 => Loss 2.584, Loss_clf 0.540, Loss_fe 0.638, Loss_kd 0.993, Train_accy 48.60
2022-10-08 06:15:54,797 [foster.py] => Task 2, Epoch 24/34 => Loss 2.613, Loss_clf 0.558, Loss_fe 0.652, Loss_kd 0.991, Train_accy 49.22
2022-10-08 06:15:58,831 [foster.py] => Task 2, Epoch 25/34 => Loss 2.558, Loss_clf 0.532, Loss_fe 0.622, Loss_kd 0.991, Train_accy 48.99
2022-10-08 06:16:03,893 [foster.py] => Task 2, Epoch 26/34 => Loss 2.605, Loss_clf 0.545, Loss_fe 0.640, Loss_kd 1.002, Train_accy 48.84, Test_accy 50.80
2022-10-08 06:16:07,976 [foster.py] => Task 2, Epoch 27/34 => Loss 2.582, Loss_clf 0.539, Loss_fe 0.635, Loss_kd 0.994, Train_accy 47.83
2022-10-08 06:16:12,028 [foster.py] => Task 2, Epoch 28/34 => Loss 2.540, Loss_clf 0.522, Loss_fe 0.614, Loss_kd 0.991, Train_accy 48.53
2022-10-08 06:16:16,029 [foster.py] => Task 2, Epoch 29/34 => Loss 2.568, Loss_clf 0.538, Loss_fe 0.624, Loss_kd 0.993, Train_accy 50.39
2022-10-08 06:16:20,063 [foster.py] => Task 2, Epoch 30/34 => Loss 2.523, Loss_clf 0.514, Loss_fe 0.598, Loss_kd 0.996, Train_accy 50.47
2022-10-08 06:16:25,104 [foster.py] => Task 2, Epoch 31/34 => Loss 2.540, Loss_clf 0.514, Loss_fe 0.611, Loss_kd 0.999, Train_accy 49.69, Test_accy 50.27
2022-10-08 06:16:29,108 [foster.py] => Task 2, Epoch 32/34 => Loss 2.574, Loss_clf 0.534, Loss_fe 0.622, Loss_kd 1.001, Train_accy 49.61
2022-10-08 06:16:33,160 [foster.py] => Task 2, Epoch 33/34 => Loss 2.556, Loss_clf 0.531, Loss_fe 0.619, Loss_kd 0.993, Train_accy 48.68
2022-10-08 06:16:37,185 [foster.py] => Task 2, Epoch 34/34 => Loss 2.569, Loss_clf 0.534, Loss_fe 0.628, Loss_kd 0.994, Train_accy 48.53
2022-10-08 06:16:37,186 [foster.py] => do not weight align teacher!
2022-10-08 06:16:37,186 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 06:16:42,544 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.112,  Train_accy 12.25, Test_accy 40.64
2022-10-08 06:16:46,627 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 2.037,  Train_accy 12.17
2022-10-08 06:16:50,806 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.997,  Train_accy 12.17
2022-10-08 06:16:55,211 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.977,  Train_accy 12.33
2022-10-08 06:16:59,980 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.952,  Train_accy 12.33
2022-10-08 06:17:05,568 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.953,  Train_accy 12.71, Test_accy 42.25
2022-10-08 06:17:10,269 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.935,  Train_accy 12.56
2022-10-08 06:17:14,999 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.930,  Train_accy 12.95
2022-10-08 06:17:19,773 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.926,  Train_accy 12.56
2022-10-08 06:17:24,538 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.929,  Train_accy 13.88
2022-10-08 06:17:30,145 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.912,  Train_accy 13.10, Test_accy 43.32
2022-10-08 06:17:34,911 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.908,  Train_accy 13.57
2022-10-08 06:17:39,664 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.908,  Train_accy 13.64
2022-10-08 06:17:44,369 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.905,  Train_accy 13.80
2022-10-08 06:17:49,056 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.901,  Train_accy 13.80
2022-10-08 06:17:54,682 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.900,  Train_accy 14.34, Test_accy 43.32
2022-10-08 06:17:59,304 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.899,  Train_accy 14.34
2022-10-08 06:18:04,146 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.898,  Train_accy 14.50
2022-10-08 06:18:08,786 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.901,  Train_accy 14.42
2022-10-08 06:18:13,430 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.896,  Train_accy 14.03
2022-10-08 06:18:19,092 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.890,  Train_accy 14.03, Test_accy 44.92
2022-10-08 06:18:23,929 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.891,  Train_accy 14.42
2022-10-08 06:18:28,775 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.888,  Train_accy 14.34
2022-10-08 06:18:33,495 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.889,  Train_accy 14.42
2022-10-08 06:18:38,280 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.887,  Train_accy 14.42
2022-10-08 06:18:43,887 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.899,  Train_accy 14.42, Test_accy 43.05
2022-10-08 06:18:43,887 [foster.py] => do not weight align student!
2022-10-08 06:18:44,709 [foster.py] => darknet eval: 
2022-10-08 06:18:44,709 [foster.py] => CNN top1 curve: 43.05
2022-10-08 06:18:44,709 [foster.py] => CNN top5 curve: 95.19
2022-10-08 06:18:44,709 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 06:18:55,515 [foster.py] => Exemplar size: 340
2022-10-08 06:18:55,516 [trainer.py] => CNN: {'total': 50.53, 'old': 58.12, 'new': 28.87, 'base': 78.52, 'compound': 32.0}
2022-10-08 06:18:55,516 [trainer.py] => CNN top1 curve: [87.25, 61.73, 50.53]
2022-10-08 06:18:55,516 [trainer.py] => CNN base curve: [87.25, 79.19, 78.52]
2022-10-08 06:18:55,516 [trainer.py] => CNN old curve: [87.25, 79.19, 58.12]
2022-10-08 06:18:55,516 [trainer.py] => CNN new curve: [0, 41.41, 28.87]
2022-10-08 06:18:55,516 [trainer.py] => CNN compound curve: [0, 41.41, 32.0]
2022-10-08 06:18:55,516 [trainer.py] => NME: {'total': 59.36, 'old': 62.09, 'new': 51.55, 'base': 68.46, 'compound': 53.33}
2022-10-08 06:18:55,516 [trainer.py] => NME top1 curve: [89.26, 68.23, 59.36]
2022-10-08 06:18:55,516 [trainer.py] => NME base curve: [89.26, 73.15, 68.46]
2022-10-08 06:18:55,516 [trainer.py] => NME old curve: [89.26, 73.15, 62.09]
2022-10-08 06:18:55,516 [trainer.py] => NME new curve: [0, 62.5, 51.55]
2022-10-08 06:18:55,516 [trainer.py] => NME compound curve: [0, 62.5, 53.33]
2022-10-08 06:18:55,763 [foster.py] => Learning on 17-22
2022-10-08 06:18:55,764 [foster.py] => All params: 22395581
2022-10-08 06:18:55,764 [foster.py] => Trainable params: 11210348
2022-10-08 06:18:55,775 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 06:19:00,116 [foster.py] => Task 3, Epoch 1/34 => Loss 6.476, Loss_clf 1.977, Loss_fe 2.539, Loss_kd 1.514, Train_accy 31.59, Test_accy 38.69
2022-10-08 06:19:03,826 [foster.py] => Task 3, Epoch 2/34 => Loss 4.940, Loss_clf 1.206, Loss_fe 1.797, Loss_kd 1.497, Train_accy 30.33
2022-10-08 06:19:07,507 [foster.py] => Task 3, Epoch 3/34 => Loss 4.662, Loss_clf 1.108, Loss_fe 1.607, Loss_kd 1.505, Train_accy 33.36
2022-10-08 06:19:11,031 [foster.py] => Task 3, Epoch 4/34 => Loss 4.532, Loss_clf 1.076, Loss_fe 1.511, Loss_kd 1.504, Train_accy 35.87
2022-10-08 06:19:15,712 [foster.py] => Task 3, Epoch 5/34 => Loss 4.352, Loss_clf 1.013, Loss_fe 1.400, Loss_kd 1.499, Train_accy 33.36
2022-10-08 06:19:21,681 [foster.py] => Task 3, Epoch 6/34 => Loss 4.285, Loss_clf 1.003, Loss_fe 1.334, Loss_kd 1.506, Train_accy 34.76, Test_accy 44.64
2022-10-08 06:19:26,398 [foster.py] => Task 3, Epoch 7/34 => Loss 4.204, Loss_clf 0.986, Loss_fe 1.277, Loss_kd 1.500, Train_accy 34.69
2022-10-08 06:19:31,089 [foster.py] => Task 3, Epoch 8/34 => Loss 4.110, Loss_clf 0.956, Loss_fe 1.219, Loss_kd 1.495, Train_accy 36.46
2022-10-08 06:19:35,799 [foster.py] => Task 3, Epoch 9/34 => Loss 4.036, Loss_clf 0.923, Loss_fe 1.174, Loss_kd 1.499, Train_accy 35.42
2022-10-08 06:19:40,468 [foster.py] => Task 3, Epoch 10/34 => Loss 3.996, Loss_clf 0.919, Loss_fe 1.131, Loss_kd 1.504, Train_accy 35.87
2022-10-08 06:19:46,372 [foster.py] => Task 3, Epoch 11/34 => Loss 3.960, Loss_clf 0.919, Loss_fe 1.099, Loss_kd 1.501, Train_accy 38.45, Test_accy 44.84
2022-10-08 06:19:50,955 [foster.py] => Task 3, Epoch 12/34 => Loss 3.900, Loss_clf 0.887, Loss_fe 1.075, Loss_kd 1.498, Train_accy 38.38
2022-10-08 06:19:55,608 [foster.py] => Task 3, Epoch 13/34 => Loss 3.846, Loss_clf 0.863, Loss_fe 1.033, Loss_kd 1.506, Train_accy 38.30
2022-10-08 06:20:00,200 [foster.py] => Task 3, Epoch 14/34 => Loss 3.845, Loss_clf 0.871, Loss_fe 1.031, Loss_kd 1.502, Train_accy 39.26
2022-10-08 06:20:04,921 [foster.py] => Task 3, Epoch 15/34 => Loss 3.783, Loss_clf 0.850, Loss_fe 0.996, Loss_kd 1.497, Train_accy 38.75
2022-10-08 06:20:10,899 [foster.py] => Task 3, Epoch 16/34 => Loss 3.797, Loss_clf 0.853, Loss_fe 0.990, Loss_kd 1.510, Train_accy 41.03, Test_accy 46.23
2022-10-08 06:20:14,589 [foster.py] => Task 3, Epoch 17/34 => Loss 3.755, Loss_clf 0.840, Loss_fe 0.969, Loss_kd 1.504, Train_accy 37.64
2022-10-08 06:20:18,366 [foster.py] => Task 3, Epoch 18/34 => Loss 3.711, Loss_clf 0.819, Loss_fe 0.954, Loss_kd 1.498, Train_accy 40.07
2022-10-08 06:20:22,142 [foster.py] => Task 3, Epoch 19/34 => Loss 3.676, Loss_clf 0.803, Loss_fe 0.928, Loss_kd 1.503, Train_accy 40.15
2022-10-08 06:20:25,839 [foster.py] => Task 3, Epoch 20/34 => Loss 3.621, Loss_clf 0.777, Loss_fe 0.892, Loss_kd 1.508, Train_accy 41.25
2022-10-08 06:20:30,782 [foster.py] => Task 3, Epoch 21/34 => Loss 3.616, Loss_clf 0.781, Loss_fe 0.889, Loss_kd 1.505, Train_accy 42.66, Test_accy 45.44
2022-10-08 06:20:34,513 [foster.py] => Task 3, Epoch 22/34 => Loss 3.646, Loss_clf 0.795, Loss_fe 0.905, Loss_kd 1.504, Train_accy 40.15
2022-10-08 06:20:38,249 [foster.py] => Task 3, Epoch 23/34 => Loss 3.631, Loss_clf 0.782, Loss_fe 0.904, Loss_kd 1.503, Train_accy 41.70
2022-10-08 06:20:42,011 [foster.py] => Task 3, Epoch 24/34 => Loss 3.632, Loss_clf 0.791, Loss_fe 0.898, Loss_kd 1.502, Train_accy 41.33
2022-10-08 06:20:45,783 [foster.py] => Task 3, Epoch 25/34 => Loss 3.587, Loss_clf 0.764, Loss_fe 0.867, Loss_kd 1.512, Train_accy 42.95
2022-10-08 06:20:50,802 [foster.py] => Task 3, Epoch 26/34 => Loss 3.594, Loss_clf 0.768, Loss_fe 0.884, Loss_kd 1.501, Train_accy 41.99, Test_accy 45.44
2022-10-08 06:20:54,525 [foster.py] => Task 3, Epoch 27/34 => Loss 3.564, Loss_clf 0.754, Loss_fe 0.865, Loss_kd 1.503, Train_accy 41.40
2022-10-08 06:20:58,283 [foster.py] => Task 3, Epoch 28/34 => Loss 3.580, Loss_clf 0.769, Loss_fe 0.877, Loss_kd 1.494, Train_accy 40.37
2022-10-08 06:21:02,157 [foster.py] => Task 3, Epoch 29/34 => Loss 3.557, Loss_clf 0.757, Loss_fe 0.855, Loss_kd 1.503, Train_accy 41.62
2022-10-08 06:21:05,985 [foster.py] => Task 3, Epoch 30/34 => Loss 3.593, Loss_clf 0.763, Loss_fe 0.883, Loss_kd 1.505, Train_accy 41.55
2022-10-08 06:21:11,467 [foster.py] => Task 3, Epoch 31/34 => Loss 3.572, Loss_clf 0.759, Loss_fe 0.870, Loss_kd 1.502, Train_accy 40.59, Test_accy 45.83
2022-10-08 06:21:15,640 [foster.py] => Task 3, Epoch 32/34 => Loss 3.550, Loss_clf 0.747, Loss_fe 0.849, Loss_kd 1.509, Train_accy 43.17
2022-10-08 06:21:19,782 [foster.py] => Task 3, Epoch 33/34 => Loss 3.525, Loss_clf 0.733, Loss_fe 0.850, Loss_kd 1.502, Train_accy 41.85
2022-10-08 06:21:23,992 [foster.py] => Task 3, Epoch 34/34 => Loss 3.573, Loss_clf 0.752, Loss_fe 0.876, Loss_kd 1.503, Train_accy 42.58
2022-10-08 06:21:23,992 [foster.py] => do not weight align teacher!
2022-10-08 06:21:23,993 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 06:21:30,249 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.433,  Train_accy 13.06, Test_accy 32.94
2022-10-08 06:21:35,260 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.376,  Train_accy 13.28
2022-10-08 06:21:40,264 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.348,  Train_accy 13.43
2022-10-08 06:21:45,187 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.336,  Train_accy 13.65
2022-10-08 06:21:51,268 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.329,  Train_accy 14.10
2022-10-08 06:21:59,832 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.323,  Train_accy 13.43, Test_accy 34.13
2022-10-08 06:22:06,022 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.319,  Train_accy 13.80
2022-10-08 06:22:12,164 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.314,  Train_accy 13.87
2022-10-08 06:22:18,291 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.305,  Train_accy 14.61
2022-10-08 06:22:23,581 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.304,  Train_accy 13.80
2022-10-08 06:22:29,853 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.301,  Train_accy 14.32, Test_accy 34.52
2022-10-08 06:22:35,174 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.293,  Train_accy 14.24
2022-10-08 06:22:40,538 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.293,  Train_accy 13.95
2022-10-08 06:22:45,264 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.300,  Train_accy 14.32
2022-10-08 06:22:50,019 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.293,  Train_accy 14.83
2022-10-08 06:22:55,684 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.289,  Train_accy 14.32, Test_accy 35.32
2022-10-08 06:23:00,108 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.284,  Train_accy 14.10
2022-10-08 06:23:04,808 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.286,  Train_accy 14.91
2022-10-08 06:23:09,439 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.291,  Train_accy 14.91
2022-10-08 06:23:14,000 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.289,  Train_accy 14.76
2022-10-08 06:23:19,505 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.293,  Train_accy 14.69, Test_accy 35.71
2022-10-08 06:23:24,206 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.286,  Train_accy 14.91
2022-10-08 06:23:29,555 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.292,  Train_accy 15.13
2022-10-08 06:23:36,475 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.282,  Train_accy 14.54
2022-10-08 06:23:43,244 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.282,  Train_accy 14.91
2022-10-08 06:23:51,024 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.287,  Train_accy 14.69, Test_accy 35.12
2022-10-08 06:23:51,025 [foster.py] => do not weight align student!
2022-10-08 06:23:51,957 [foster.py] => darknet eval: 
2022-10-08 06:23:51,957 [foster.py] => CNN top1 curve: 35.12
2022-10-08 06:23:51,957 [foster.py] => CNN top5 curve: 83.53
2022-10-08 06:23:51,958 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 06:24:04,457 [foster.py] => Exemplar size: 440
2022-10-08 06:24:04,457 [trainer.py] => CNN: {'total': 46.43, 'old': 50.8, 'new': 33.85, 'base': 79.19, 'compound': 32.68}
2022-10-08 06:24:04,457 [trainer.py] => CNN top1 curve: [87.25, 61.73, 50.53, 46.43]
2022-10-08 06:24:04,457 [trainer.py] => CNN base curve: [87.25, 79.19, 78.52, 79.19]
2022-10-08 06:24:04,457 [trainer.py] => CNN old curve: [87.25, 79.19, 58.12, 50.8]
2022-10-08 06:24:04,457 [trainer.py] => CNN new curve: [0, 41.41, 28.87, 33.85]
2022-10-08 06:24:04,457 [trainer.py] => CNN compound curve: [0, 41.41, 32.0, 32.68]
2022-10-08 06:24:04,457 [trainer.py] => NME: {'total': 54.56, 'old': 55.61, 'new': 51.54, 'base': 65.77, 'compound': 49.86}
2022-10-08 06:24:04,457 [trainer.py] => NME top1 curve: [89.26, 68.23, 59.36, 54.56]
2022-10-08 06:24:04,457 [trainer.py] => NME base curve: [89.26, 73.15, 68.46, 65.77]
2022-10-08 06:24:04,457 [trainer.py] => NME old curve: [89.26, 73.15, 62.09, 55.61]
2022-10-08 06:24:04,457 [trainer.py] => NME new curve: [0, 62.5, 51.55, 51.54]
2022-10-08 06:24:04,457 [trainer.py] => NME compound curve: [0, 62.5, 53.33, 49.86]
2022-10-08 06:24:04,459 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 06:24:04,459 [trainer.py] => prefix: cil
2022-10-08 06:24:04,459 [trainer.py] => dataset: CFEE
2022-10-08 06:24:04,459 [trainer.py] => memory_size: 2000
2022-10-08 06:24:04,459 [trainer.py] => memory_per_class: 20
2022-10-08 06:24:04,459 [trainer.py] => fixed_memory: True
2022-10-08 06:24:04,459 [trainer.py] => shuffle: True
2022-10-08 06:24:04,459 [trainer.py] => init_cls: 7
2022-10-08 06:24:04,459 [trainer.py] => increment: 5
2022-10-08 06:24:04,459 [trainer.py] => model_name: foster
2022-10-08 06:24:04,459 [trainer.py] => convnet_type: resnet18
2022-10-08 06:24:04,459 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 06:24:04,459 [trainer.py] => seed: 1993
2022-10-08 06:24:04,459 [trainer.py] => beta1: 0.96
2022-10-08 06:24:04,459 [trainer.py] => beta2: 0.97
2022-10-08 06:24:04,459 [trainer.py] => oofc: ft
2022-10-08 06:24:04,459 [trainer.py] => is_teacher_wa: False
2022-10-08 06:24:04,459 [trainer.py] => is_student_wa: False
2022-10-08 06:24:04,459 [trainer.py] => lambda_okd: 1
2022-10-08 06:24:04,459 [trainer.py] => wa_value: 1
2022-10-08 06:24:04,459 [trainer.py] => init_epochs: 40
2022-10-08 06:24:04,459 [trainer.py] => init_lr: 0.01
2022-10-08 06:24:04,460 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 06:24:04,460 [trainer.py] => boosting_epochs: 34
2022-10-08 06:24:04,460 [trainer.py] => compression_epochs: 26
2022-10-08 06:24:04,460 [trainer.py] => lr: 0.001
2022-10-08 06:24:04,460 [trainer.py] => batch_size: 32
2022-10-08 06:24:04,460 [trainer.py] => weight_decay: 0.0005
2022-10-08 06:24:04,460 [trainer.py] => num_workers: 8
2022-10-08 06:24:04,460 [trainer.py] => T: 2
2022-10-08 06:24:04,460 [trainer.py] => nb_runs: 3
2022-10-08 06:24:04,460 [trainer.py] => fold: 10
2022-10-08 06:24:04,460 [data.py] => ========== Fold:8 ==========
2022-10-08 06:24:04,465 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 13, 17, 15, 9, 11, 20, 18, 12, 14, 7, 10, 19, 21, 16, 8]
2022-10-08 06:24:04,736 [foster.py] => Learning on 0-7
2022-10-08 06:24:04,736 [foster.py] => All params: 11183694
2022-10-08 06:24:04,736 [foster.py] => Trainable params: 11183694
2022-10-08 06:24:07,489 [foster.py] => Task 0, Epoch 1/40 => Loss 1.346, Train_accy 50.03
2022-10-08 06:24:10,911 [foster.py] => Task 0, Epoch 2/40 => Loss 0.576, Train_accy 81.16, Test_accy 82.28
2022-10-08 06:24:14,501 [foster.py] => Task 0, Epoch 3/40 => Loss 0.385, Train_accy 86.61, Test_accy 82.28
2022-10-08 06:24:17,959 [foster.py] => Task 0, Epoch 4/40 => Loss 0.298, Train_accy 88.82, Test_accy 87.34
2022-10-08 06:24:21,540 [foster.py] => Task 0, Epoch 5/40 => Loss 0.240, Train_accy 91.93, Test_accy 88.61
2022-10-08 06:24:24,735 [foster.py] => Task 0, Epoch 6/40 => Loss 0.207, Train_accy 92.55
2022-10-08 06:24:28,262 [foster.py] => Task 0, Epoch 7/40 => Loss 0.158, Train_accy 94.69, Test_accy 88.61
2022-10-08 06:24:31,938 [foster.py] => Task 0, Epoch 8/40 => Loss 0.124, Train_accy 96.48, Test_accy 84.81
2022-10-08 06:24:35,864 [foster.py] => Task 0, Epoch 9/40 => Loss 0.116, Train_accy 96.14, Test_accy 86.71
2022-10-08 06:24:39,533 [foster.py] => Task 0, Epoch 10/40 => Loss 0.101, Train_accy 97.31, Test_accy 82.28
2022-10-08 06:24:42,642 [foster.py] => Task 0, Epoch 11/40 => Loss 0.094, Train_accy 97.10
2022-10-08 06:24:46,314 [foster.py] => Task 0, Epoch 12/40 => Loss 0.089, Train_accy 97.03, Test_accy 89.24
2022-10-08 06:24:50,220 [foster.py] => Task 0, Epoch 13/40 => Loss 0.064, Train_accy 98.27, Test_accy 89.24
2022-10-08 06:24:54,067 [foster.py] => Task 0, Epoch 14/40 => Loss 0.063, Train_accy 97.65, Test_accy 88.61
2022-10-08 06:24:58,073 [foster.py] => Task 0, Epoch 15/40 => Loss 0.056, Train_accy 98.90, Test_accy 89.87
2022-10-08 06:25:01,102 [foster.py] => Task 0, Epoch 16/40 => Loss 0.056, Train_accy 98.21
2022-10-08 06:25:04,829 [foster.py] => Task 0, Epoch 17/40 => Loss 0.046, Train_accy 98.41, Test_accy 87.34
2022-10-08 06:25:08,771 [foster.py] => Task 0, Epoch 18/40 => Loss 0.046, Train_accy 99.10, Test_accy 88.61
2022-10-08 06:25:12,705 [foster.py] => Task 0, Epoch 19/40 => Loss 0.041, Train_accy 98.96, Test_accy 85.44
2022-10-08 06:25:16,626 [foster.py] => Task 0, Epoch 20/40 => Loss 0.031, Train_accy 99.17, Test_accy 87.34
2022-10-08 06:25:19,888 [foster.py] => Task 0, Epoch 21/40 => Loss 0.037, Train_accy 99.10
2022-10-08 06:25:23,797 [foster.py] => Task 0, Epoch 22/40 => Loss 0.026, Train_accy 99.65, Test_accy 89.24
2022-10-08 06:25:27,687 [foster.py] => Task 0, Epoch 23/40 => Loss 0.021, Train_accy 99.86, Test_accy 86.71
2022-10-08 06:25:31,632 [foster.py] => Task 0, Epoch 24/40 => Loss 0.027, Train_accy 99.38, Test_accy 86.71
2022-10-08 06:25:35,482 [foster.py] => Task 0, Epoch 25/40 => Loss 0.023, Train_accy 99.65, Test_accy 87.34
2022-10-08 06:25:38,746 [foster.py] => Task 0, Epoch 26/40 => Loss 0.020, Train_accy 99.59
2022-10-08 06:25:42,792 [foster.py] => Task 0, Epoch 27/40 => Loss 0.019, Train_accy 99.79, Test_accy 86.08
2022-10-08 06:25:46,650 [foster.py] => Task 0, Epoch 28/40 => Loss 0.021, Train_accy 99.59, Test_accy 87.34
2022-10-08 06:25:50,581 [foster.py] => Task 0, Epoch 29/40 => Loss 0.017, Train_accy 99.72, Test_accy 86.71
2022-10-08 06:25:54,362 [foster.py] => Task 0, Epoch 30/40 => Loss 0.017, Train_accy 99.86, Test_accy 86.08
2022-10-08 06:25:57,505 [foster.py] => Task 0, Epoch 31/40 => Loss 0.013, Train_accy 99.86
2022-10-08 06:26:01,426 [foster.py] => Task 0, Epoch 32/40 => Loss 0.030, Train_accy 99.65, Test_accy 87.34
2022-10-08 06:26:05,152 [foster.py] => Task 0, Epoch 33/40 => Loss 0.013, Train_accy 100.00, Test_accy 86.71
2022-10-08 06:26:09,067 [foster.py] => Task 0, Epoch 34/40 => Loss 0.017, Train_accy 99.79, Test_accy 86.71
2022-10-08 06:26:13,007 [foster.py] => Task 0, Epoch 35/40 => Loss 0.014, Train_accy 99.79, Test_accy 85.44
2022-10-08 06:26:16,019 [foster.py] => Task 0, Epoch 36/40 => Loss 0.021, Train_accy 99.65
2022-10-08 06:26:20,013 [foster.py] => Task 0, Epoch 37/40 => Loss 0.018, Train_accy 99.65, Test_accy 85.44
2022-10-08 06:26:23,987 [foster.py] => Task 0, Epoch 38/40 => Loss 0.018, Train_accy 99.65, Test_accy 87.34
2022-10-08 06:26:28,117 [foster.py] => Task 0, Epoch 39/40 => Loss 0.014, Train_accy 99.86, Test_accy 86.08
2022-10-08 06:26:32,069 [foster.py] => Task 0, Epoch 40/40 => Loss 0.015, Train_accy 99.72, Test_accy 86.71
2022-10-08 06:26:32,070 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 06:26:39,374 [foster.py] => Exemplar size: 140
2022-10-08 06:26:39,374 [trainer.py] => CNN: {'total': 86.71, 'old': 86.71, 'new': 0, 'base': 86.71, 'compound': 0}
2022-10-08 06:26:39,374 [trainer.py] => CNN top1 curve: [86.71]
2022-10-08 06:26:39,374 [trainer.py] => CNN base curve: [86.71]
2022-10-08 06:26:39,374 [trainer.py] => CNN old curve: [86.71]
2022-10-08 06:26:39,374 [trainer.py] => CNN new curve: [0]
2022-10-08 06:26:39,374 [trainer.py] => CNN compound curve: [0]
2022-10-08 06:26:39,374 [trainer.py] => NME: {'total': 85.44, 'old': 85.44, 'new': 0, 'base': 85.44, 'compound': 0}
2022-10-08 06:26:39,374 [trainer.py] => NME top1 curve: [85.44]
2022-10-08 06:26:39,374 [trainer.py] => NME base curve: [85.44]
2022-10-08 06:26:39,374 [trainer.py] => NME old curve: [85.44]
2022-10-08 06:26:39,374 [trainer.py] => NME new curve: [0]
2022-10-08 06:26:39,374 [trainer.py] => NME compound curve: [0]
2022-10-08 06:26:39,643 [foster.py] => Learning on 7-12
2022-10-08 06:26:39,644 [foster.py] => All params: 22375071
2022-10-08 06:26:39,644 [foster.py] => Trainable params: 11194968
2022-10-08 06:26:39,660 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 06:26:43,397 [foster.py] => Task 1, Epoch 1/34 => Loss 4.672, Loss_clf 2.091, Loss_fe 1.945, Loss_kd 0.371, Train_accy 36.09, Test_accy 65.14
2022-10-08 06:26:46,386 [foster.py] => Task 1, Epoch 2/34 => Loss 2.548, Loss_clf 0.697, Loss_fe 1.225, Loss_kd 0.366, Train_accy 64.00
2022-10-08 06:26:49,787 [foster.py] => Task 1, Epoch 3/34 => Loss 2.192, Loss_clf 0.569, Loss_fe 1.007, Loss_kd 0.359, Train_accy 46.68
2022-10-08 06:26:53,246 [foster.py] => Task 1, Epoch 4/34 => Loss 2.025, Loss_clf 0.535, Loss_fe 0.880, Loss_kd 0.356, Train_accy 44.44
2022-10-08 06:26:56,516 [foster.py] => Task 1, Epoch 5/34 => Loss 1.898, Loss_clf 0.498, Loss_fe 0.789, Loss_kd 0.357, Train_accy 45.48
2022-10-08 06:27:06,043 [foster.py] => Task 1, Epoch 6/34 => Loss 1.830, Loss_clf 0.481, Loss_fe 0.742, Loss_kd 0.355, Train_accy 47.63, Test_accy 60.21
2022-10-08 06:27:10,958 [foster.py] => Task 1, Epoch 7/34 => Loss 1.781, Loss_clf 0.473, Loss_fe 0.696, Loss_kd 0.357, Train_accy 46.43
2022-10-08 06:27:14,700 [foster.py] => Task 1, Epoch 8/34 => Loss 1.721, Loss_clf 0.449, Loss_fe 0.655, Loss_kd 0.360, Train_accy 47.72
2022-10-08 06:27:18,470 [foster.py] => Task 1, Epoch 9/34 => Loss 1.677, Loss_clf 0.438, Loss_fe 0.625, Loss_kd 0.358, Train_accy 47.63
2022-10-08 06:27:22,271 [foster.py] => Task 1, Epoch 10/34 => Loss 1.669, Loss_clf 0.444, Loss_fe 0.621, Loss_kd 0.352, Train_accy 47.11
2022-10-08 06:27:27,017 [foster.py] => Task 1, Epoch 11/34 => Loss 1.609, Loss_clf 0.427, Loss_fe 0.579, Loss_kd 0.352, Train_accy 49.18, Test_accy 61.97
2022-10-08 06:27:30,725 [foster.py] => Task 1, Epoch 12/34 => Loss 1.580, Loss_clf 0.411, Loss_fe 0.568, Loss_kd 0.351, Train_accy 46.77
2022-10-08 06:27:34,490 [foster.py] => Task 1, Epoch 13/34 => Loss 1.552, Loss_clf 0.398, Loss_fe 0.546, Loss_kd 0.355, Train_accy 47.55
2022-10-08 06:27:37,942 [foster.py] => Task 1, Epoch 14/34 => Loss 1.524, Loss_clf 0.391, Loss_fe 0.526, Loss_kd 0.354, Train_accy 48.92
2022-10-08 06:27:41,364 [foster.py] => Task 1, Epoch 15/34 => Loss 1.531, Loss_clf 0.390, Loss_fe 0.523, Loss_kd 0.361, Train_accy 47.72
2022-10-08 06:27:45,599 [foster.py] => Task 1, Epoch 16/34 => Loss 1.500, Loss_clf 0.386, Loss_fe 0.507, Loss_kd 0.354, Train_accy 49.61, Test_accy 61.62
2022-10-08 06:27:49,043 [foster.py] => Task 1, Epoch 17/34 => Loss 1.482, Loss_clf 0.371, Loss_fe 0.497, Loss_kd 0.358, Train_accy 47.46
2022-10-08 06:27:52,508 [foster.py] => Task 1, Epoch 18/34 => Loss 1.456, Loss_clf 0.363, Loss_fe 0.490, Loss_kd 0.352, Train_accy 48.15
2022-10-08 06:27:55,887 [foster.py] => Task 1, Epoch 19/34 => Loss 1.456, Loss_clf 0.369, Loss_fe 0.485, Loss_kd 0.351, Train_accy 49.44
2022-10-08 06:27:59,282 [foster.py] => Task 1, Epoch 20/34 => Loss 1.428, Loss_clf 0.358, Loss_fe 0.468, Loss_kd 0.351, Train_accy 49.44
2022-10-08 06:28:03,649 [foster.py] => Task 1, Epoch 21/34 => Loss 1.454, Loss_clf 0.367, Loss_fe 0.483, Loss_kd 0.352, Train_accy 49.70, Test_accy 61.62
2022-10-08 06:28:07,041 [foster.py] => Task 1, Epoch 22/34 => Loss 1.425, Loss_clf 0.357, Loss_fe 0.473, Loss_kd 0.347, Train_accy 49.78
2022-10-08 06:28:10,392 [foster.py] => Task 1, Epoch 23/34 => Loss 1.417, Loss_clf 0.351, Loss_fe 0.457, Loss_kd 0.355, Train_accy 49.61
2022-10-08 06:28:13,834 [foster.py] => Task 1, Epoch 24/34 => Loss 1.415, Loss_clf 0.344, Loss_fe 0.460, Loss_kd 0.357, Train_accy 49.87
2022-10-08 06:28:17,280 [foster.py] => Task 1, Epoch 25/34 => Loss 1.387, Loss_clf 0.339, Loss_fe 0.451, Loss_kd 0.348, Train_accy 48.66
2022-10-08 06:28:21,544 [foster.py] => Task 1, Epoch 26/34 => Loss 1.399, Loss_clf 0.338, Loss_fe 0.448, Loss_kd 0.357, Train_accy 48.06, Test_accy 61.62
2022-10-08 06:28:24,953 [foster.py] => Task 1, Epoch 27/34 => Loss 1.404, Loss_clf 0.335, Loss_fe 0.458, Loss_kd 0.356, Train_accy 50.47
2022-10-08 06:28:28,347 [foster.py] => Task 1, Epoch 28/34 => Loss 1.423, Loss_clf 0.356, Loss_fe 0.467, Loss_kd 0.350, Train_accy 48.15
2022-10-08 06:28:31,700 [foster.py] => Task 1, Epoch 29/34 => Loss 1.365, Loss_clf 0.326, Loss_fe 0.433, Loss_kd 0.354, Train_accy 49.18
2022-10-08 06:28:35,146 [foster.py] => Task 1, Epoch 30/34 => Loss 1.388, Loss_clf 0.334, Loss_fe 0.444, Loss_kd 0.356, Train_accy 50.82
2022-10-08 06:28:39,487 [foster.py] => Task 1, Epoch 31/34 => Loss 1.386, Loss_clf 0.328, Loss_fe 0.448, Loss_kd 0.356, Train_accy 49.18, Test_accy 61.97
2022-10-08 06:28:42,884 [foster.py] => Task 1, Epoch 32/34 => Loss 1.394, Loss_clf 0.338, Loss_fe 0.452, Loss_kd 0.352, Train_accy 49.18
2022-10-08 06:28:46,316 [foster.py] => Task 1, Epoch 33/34 => Loss 1.363, Loss_clf 0.328, Loss_fe 0.436, Loss_kd 0.350, Train_accy 48.66
2022-10-08 06:28:49,767 [foster.py] => Task 1, Epoch 34/34 => Loss 1.371, Loss_clf 0.329, Loss_fe 0.439, Loss_kd 0.352, Train_accy 48.32
2022-10-08 06:28:49,768 [foster.py] => do not weight align teacher!
2022-10-08 06:28:49,768 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 06:28:54,823 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.655,  Train_accy 11.97, Test_accy 46.13
2022-10-08 06:28:58,821 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.528,  Train_accy 11.89
2022-10-08 06:29:02,988 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.456,  Train_accy 13.01
2022-10-08 06:29:07,218 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.432,  Train_accy 15.16
2022-10-08 06:29:11,329 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.415,  Train_accy 17.74
2022-10-08 06:29:16,361 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.393,  Train_accy 18.60, Test_accy 50.35
2022-10-08 06:29:20,491 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.360,  Train_accy 20.33
2022-10-08 06:29:24,551 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.354,  Train_accy 20.50
2022-10-08 06:29:28,602 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.342,  Train_accy 23.69
2022-10-08 06:29:32,732 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.359,  Train_accy 22.74
2022-10-08 06:29:37,711 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.336,  Train_accy 24.03, Test_accy 52.46
2022-10-08 06:29:42,027 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.328,  Train_accy 24.12
2022-10-08 06:29:46,318 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.317,  Train_accy 24.98
2022-10-08 06:29:50,450 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.332,  Train_accy 25.24
2022-10-08 06:29:54,628 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.319,  Train_accy 26.53
2022-10-08 06:29:59,719 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.321,  Train_accy 26.18, Test_accy 53.17
2022-10-08 06:30:09,102 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.319,  Train_accy 25.41
2022-10-08 06:30:16,155 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.303,  Train_accy 25.75
2022-10-08 06:30:21,976 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.324,  Train_accy 26.18
2022-10-08 06:30:27,790 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.316,  Train_accy 25.32
2022-10-08 06:30:34,257 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.308,  Train_accy 27.39, Test_accy 54.23
2022-10-08 06:30:37,842 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.300,  Train_accy 25.58
2022-10-08 06:30:41,472 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.323,  Train_accy 26.70
2022-10-08 06:30:45,735 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.310,  Train_accy 25.84
2022-10-08 06:30:49,973 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.311,  Train_accy 27.30
2022-10-08 06:30:55,220 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.318,  Train_accy 27.65, Test_accy 54.23
2022-10-08 06:30:55,220 [foster.py] => do not weight align student!
2022-10-08 06:30:55,922 [foster.py] => darknet eval: 
2022-10-08 06:30:55,922 [foster.py] => CNN top1 curve: 54.23
2022-10-08 06:30:55,922 [foster.py] => CNN top5 curve: 98.59
2022-10-08 06:30:55,923 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 06:31:04,510 [foster.py] => Exemplar size: 240
2022-10-08 06:31:04,510 [trainer.py] => CNN: {'total': 61.97, 'old': 83.54, 'new': 34.92, 'base': 83.54, 'compound': 34.92}
2022-10-08 06:31:04,511 [trainer.py] => CNN top1 curve: [86.71, 61.97]
2022-10-08 06:31:04,511 [trainer.py] => CNN base curve: [86.71, 83.54]
2022-10-08 06:31:04,511 [trainer.py] => CNN old curve: [86.71, 83.54]
2022-10-08 06:31:04,511 [trainer.py] => CNN new curve: [0, 34.92]
2022-10-08 06:31:04,511 [trainer.py] => CNN compound curve: [0, 34.92]
2022-10-08 06:31:04,511 [trainer.py] => NME: {'total': 67.96, 'old': 68.35, 'new': 67.46, 'base': 68.35, 'compound': 67.46}
2022-10-08 06:31:04,511 [trainer.py] => NME top1 curve: [85.44, 67.96]
2022-10-08 06:31:04,511 [trainer.py] => NME base curve: [85.44, 68.35]
2022-10-08 06:31:04,511 [trainer.py] => NME old curve: [85.44, 68.35]
2022-10-08 06:31:04,511 [trainer.py] => NME new curve: [0, 67.46]
2022-10-08 06:31:04,511 [trainer.py] => NME compound curve: [0, 67.46]
2022-10-08 06:31:04,784 [foster.py] => Learning on 12-17
2022-10-08 06:31:04,785 [foster.py] => All params: 22385326
2022-10-08 06:31:04,785 [foster.py] => Trainable params: 11202658
2022-10-08 06:31:04,795 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 06:31:08,958 [foster.py] => Task 2, Epoch 1/34 => Loss 5.669, Loss_clf 2.038, Loss_fe 2.214, Loss_kd 1.000, Train_accy 36.79, Test_accy 44.23
2022-10-08 06:31:12,376 [foster.py] => Task 2, Epoch 2/34 => Loss 3.829, Loss_clf 0.982, Loss_fe 1.499, Loss_kd 0.951, Train_accy 40.66
2022-10-08 06:31:15,872 [foster.py] => Task 2, Epoch 3/34 => Loss 3.518, Loss_clf 0.864, Loss_fe 1.304, Loss_kd 0.953, Train_accy 41.06
2022-10-08 06:31:19,200 [foster.py] => Task 2, Epoch 4/34 => Loss 3.374, Loss_clf 0.825, Loss_fe 1.196, Loss_kd 0.955, Train_accy 39.48
2022-10-08 06:31:23,023 [foster.py] => Task 2, Epoch 5/34 => Loss 3.272, Loss_clf 0.798, Loss_fe 1.117, Loss_kd 0.958, Train_accy 39.32
2022-10-08 06:31:27,451 [foster.py] => Task 2, Epoch 6/34 => Loss 3.198, Loss_clf 0.769, Loss_fe 1.057, Loss_kd 0.968, Train_accy 39.95, Test_accy 48.40
2022-10-08 06:31:31,091 [foster.py] => Task 2, Epoch 7/34 => Loss 3.084, Loss_clf 0.736, Loss_fe 0.989, Loss_kd 0.959, Train_accy 40.66
2022-10-08 06:31:34,764 [foster.py] => Task 2, Epoch 8/34 => Loss 3.008, Loss_clf 0.707, Loss_fe 0.936, Loss_kd 0.964, Train_accy 41.38
2022-10-08 06:31:38,229 [foster.py] => Task 2, Epoch 9/34 => Loss 2.983, Loss_clf 0.711, Loss_fe 0.913, Loss_kd 0.959, Train_accy 41.53
2022-10-08 06:31:41,979 [foster.py] => Task 2, Epoch 10/34 => Loss 2.916, Loss_clf 0.678, Loss_fe 0.879, Loss_kd 0.959, Train_accy 40.74
2022-10-08 06:31:46,823 [foster.py] => Task 2, Epoch 11/34 => Loss 2.890, Loss_clf 0.673, Loss_fe 0.853, Loss_kd 0.963, Train_accy 42.96, Test_accy 49.39
2022-10-08 06:31:51,852 [foster.py] => Task 2, Epoch 12/34 => Loss 2.799, Loss_clf 0.641, Loss_fe 0.807, Loss_kd 0.954, Train_accy 41.14
2022-10-08 06:31:56,911 [foster.py] => Task 2, Epoch 13/34 => Loss 2.821, Loss_clf 0.655, Loss_fe 0.806, Loss_kd 0.960, Train_accy 42.80
2022-10-08 06:32:01,867 [foster.py] => Task 2, Epoch 14/34 => Loss 2.766, Loss_clf 0.638, Loss_fe 0.774, Loss_kd 0.956, Train_accy 44.78
2022-10-08 06:32:06,351 [foster.py] => Task 2, Epoch 15/34 => Loss 2.732, Loss_clf 0.624, Loss_fe 0.751, Loss_kd 0.958, Train_accy 43.35
2022-10-08 06:32:11,839 [foster.py] => Task 2, Epoch 16/34 => Loss 2.739, Loss_clf 0.626, Loss_fe 0.753, Loss_kd 0.961, Train_accy 43.35, Test_accy 49.63
2022-10-08 06:32:15,642 [foster.py] => Task 2, Epoch 17/34 => Loss 2.692, Loss_clf 0.603, Loss_fe 0.736, Loss_kd 0.955, Train_accy 42.96
2022-10-08 06:32:19,480 [foster.py] => Task 2, Epoch 18/34 => Loss 2.661, Loss_clf 0.590, Loss_fe 0.707, Loss_kd 0.963, Train_accy 44.94
2022-10-08 06:32:23,375 [foster.py] => Task 2, Epoch 19/34 => Loss 2.665, Loss_clf 0.599, Loss_fe 0.710, Loss_kd 0.957, Train_accy 44.22
2022-10-08 06:32:27,226 [foster.py] => Task 2, Epoch 20/34 => Loss 2.615, Loss_clf 0.574, Loss_fe 0.679, Loss_kd 0.962, Train_accy 47.23
2022-10-08 06:32:32,210 [foster.py] => Task 2, Epoch 21/34 => Loss 2.652, Loss_clf 0.599, Loss_fe 0.691, Loss_kd 0.962, Train_accy 44.70, Test_accy 50.12
2022-10-08 06:32:36,008 [foster.py] => Task 2, Epoch 22/34 => Loss 2.579, Loss_clf 0.567, Loss_fe 0.659, Loss_kd 0.955, Train_accy 44.22
2022-10-08 06:32:39,839 [foster.py] => Task 2, Epoch 23/34 => Loss 2.601, Loss_clf 0.574, Loss_fe 0.664, Loss_kd 0.962, Train_accy 45.81
2022-10-08 06:32:43,684 [foster.py] => Task 2, Epoch 24/34 => Loss 2.599, Loss_clf 0.570, Loss_fe 0.674, Loss_kd 0.956, Train_accy 45.09
2022-10-08 06:32:47,566 [foster.py] => Task 2, Epoch 25/34 => Loss 2.578, Loss_clf 0.564, Loss_fe 0.651, Loss_kd 0.962, Train_accy 47.07
2022-10-08 06:32:52,570 [foster.py] => Task 2, Epoch 26/34 => Loss 2.583, Loss_clf 0.565, Loss_fe 0.655, Loss_kd 0.962, Train_accy 45.02, Test_accy 50.61
2022-10-08 06:32:56,292 [foster.py] => Task 2, Epoch 27/34 => Loss 2.562, Loss_clf 0.552, Loss_fe 0.650, Loss_kd 0.959, Train_accy 46.91
2022-10-08 06:33:00,127 [foster.py] => Task 2, Epoch 28/34 => Loss 2.559, Loss_clf 0.553, Loss_fe 0.648, Loss_kd 0.958, Train_accy 46.99
2022-10-08 06:33:03,595 [foster.py] => Task 2, Epoch 29/34 => Loss 2.541, Loss_clf 0.544, Loss_fe 0.634, Loss_kd 0.962, Train_accy 46.60
2022-10-08 06:33:07,196 [foster.py] => Task 2, Epoch 30/34 => Loss 2.548, Loss_clf 0.554, Loss_fe 0.641, Loss_kd 0.955, Train_accy 45.89
2022-10-08 06:33:11,932 [foster.py] => Task 2, Epoch 31/34 => Loss 2.569, Loss_clf 0.561, Loss_fe 0.660, Loss_kd 0.952, Train_accy 45.65, Test_accy 50.37
2022-10-08 06:33:16,439 [foster.py] => Task 2, Epoch 32/34 => Loss 2.545, Loss_clf 0.534, Loss_fe 0.640, Loss_kd 0.967, Train_accy 46.12
2022-10-08 06:33:20,963 [foster.py] => Task 2, Epoch 33/34 => Loss 2.530, Loss_clf 0.548, Loss_fe 0.631, Loss_kd 0.954, Train_accy 46.68
2022-10-08 06:33:25,542 [foster.py] => Task 2, Epoch 34/34 => Loss 2.554, Loss_clf 0.555, Loss_fe 0.647, Loss_kd 0.954, Train_accy 46.44
2022-10-08 06:33:25,543 [foster.py] => do not weight align teacher!
2022-10-08 06:33:25,543 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 06:33:31,319 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.095,  Train_accy 12.26, Test_accy 36.86
2022-10-08 06:33:35,949 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 2.019,  Train_accy 12.26
2022-10-08 06:33:40,549 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.971,  Train_accy 12.74
2022-10-08 06:33:45,192 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.955,  Train_accy 12.50
2022-10-08 06:33:49,929 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.936,  Train_accy 12.82
2022-10-08 06:33:55,425 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.922,  Train_accy 12.58, Test_accy 39.31
2022-10-08 06:34:00,155 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.912,  Train_accy 13.37
2022-10-08 06:34:04,842 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.909,  Train_accy 13.21
2022-10-08 06:34:09,575 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.896,  Train_accy 13.05
2022-10-08 06:34:14,371 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.891,  Train_accy 13.29
2022-10-08 06:34:19,930 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.884,  Train_accy 13.45, Test_accy 40.54
2022-10-08 06:34:24,672 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.884,  Train_accy 13.77
2022-10-08 06:34:29,367 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.883,  Train_accy 14.64
2022-10-08 06:34:34,120 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.872,  Train_accy 13.53
2022-10-08 06:34:38,865 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.874,  Train_accy 13.77
2022-10-08 06:34:44,412 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.873,  Train_accy 14.24, Test_accy 41.03
2022-10-08 06:34:49,129 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.869,  Train_accy 14.24
2022-10-08 06:34:53,920 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.873,  Train_accy 14.00
2022-10-08 06:34:58,623 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.865,  Train_accy 14.56
2022-10-08 06:35:03,334 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.867,  Train_accy 14.32
2022-10-08 06:35:08,851 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.867,  Train_accy 14.48, Test_accy 40.79
2022-10-08 06:35:13,094 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.861,  Train_accy 14.72
2022-10-08 06:35:17,927 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.863,  Train_accy 14.40
2022-10-08 06:35:23,563 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.862,  Train_accy 14.79
2022-10-08 06:35:29,081 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.865,  Train_accy 15.27
2022-10-08 06:35:35,421 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.868,  Train_accy 14.95, Test_accy 41.52
2022-10-08 06:35:35,422 [foster.py] => do not weight align student!
2022-10-08 06:35:36,302 [foster.py] => darknet eval: 
2022-10-08 06:35:36,302 [foster.py] => CNN top1 curve: 41.52
2022-10-08 06:35:36,302 [foster.py] => CNN top5 curve: 93.12
2022-10-08 06:35:36,302 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 06:35:46,286 [foster.py] => Exemplar size: 340
2022-10-08 06:35:46,286 [trainer.py] => CNN: {'total': 50.86, 'old': 56.34, 'new': 38.21, 'base': 79.75, 'compound': 32.53}
2022-10-08 06:35:46,286 [trainer.py] => CNN top1 curve: [86.71, 61.97, 50.86]
2022-10-08 06:35:46,286 [trainer.py] => CNN base curve: [86.71, 83.54, 79.75]
2022-10-08 06:35:46,286 [trainer.py] => CNN old curve: [86.71, 83.54, 56.34]
2022-10-08 06:35:46,286 [trainer.py] => CNN new curve: [0, 34.92, 38.21]
2022-10-08 06:35:46,286 [trainer.py] => CNN compound curve: [0, 34.92, 32.53]
2022-10-08 06:35:46,286 [trainer.py] => NME: {'total': 57.74, 'old': 59.15, 'new': 54.47, 'base': 66.46, 'compound': 52.21}
2022-10-08 06:35:46,286 [trainer.py] => NME top1 curve: [85.44, 67.96, 57.74]
2022-10-08 06:35:46,286 [trainer.py] => NME base curve: [85.44, 68.35, 66.46]
2022-10-08 06:35:46,286 [trainer.py] => NME old curve: [85.44, 68.35, 59.15]
2022-10-08 06:35:46,286 [trainer.py] => NME new curve: [0, 67.46, 54.47]
2022-10-08 06:35:46,286 [trainer.py] => NME compound curve: [0, 67.46, 52.21]
2022-10-08 06:35:46,509 [foster.py] => Learning on 17-22
2022-10-08 06:35:46,509 [foster.py] => All params: 22395581
2022-10-08 06:35:46,509 [foster.py] => Trainable params: 11210348
2022-10-08 06:35:46,518 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 06:35:50,884 [foster.py] => Task 3, Epoch 1/34 => Loss 6.701, Loss_clf 2.145, Loss_fe 2.587, Loss_kd 1.521, Train_accy 31.99, Test_accy 38.29
2022-10-08 06:35:54,149 [foster.py] => Task 3, Epoch 2/34 => Loss 4.989, Loss_clf 1.233, Loss_fe 1.810, Loss_kd 1.504, Train_accy 31.20
2022-10-08 06:35:57,518 [foster.py] => Task 3, Epoch 3/34 => Loss 4.717, Loss_clf 1.167, Loss_fe 1.616, Loss_kd 1.494, Train_accy 35.66
2022-10-08 06:36:01,053 [foster.py] => Task 3, Epoch 4/34 => Loss 4.569, Loss_clf 1.123, Loss_fe 1.509, Loss_kd 1.497, Train_accy 32.71
2022-10-08 06:36:04,623 [foster.py] => Task 3, Epoch 5/34 => Loss 4.380, Loss_clf 1.057, Loss_fe 1.384, Loss_kd 1.499, Train_accy 35.37
2022-10-08 06:36:09,941 [foster.py] => Task 3, Epoch 6/34 => Loss 4.310, Loss_clf 1.047, Loss_fe 1.329, Loss_kd 1.495, Train_accy 35.52, Test_accy 42.06
2022-10-08 06:36:14,084 [foster.py] => Task 3, Epoch 7/34 => Loss 4.237, Loss_clf 1.026, Loss_fe 1.278, Loss_kd 1.493, Train_accy 35.73
2022-10-08 06:36:18,193 [foster.py] => Task 3, Epoch 8/34 => Loss 4.186, Loss_clf 0.996, Loss_fe 1.237, Loss_kd 1.509, Train_accy 34.80
2022-10-08 06:36:22,325 [foster.py] => Task 3, Epoch 9/34 => Loss 4.079, Loss_clf 0.972, Loss_fe 1.162, Loss_kd 1.503, Train_accy 37.82
2022-10-08 06:36:26,447 [foster.py] => Task 3, Epoch 10/34 => Loss 4.033, Loss_clf 0.960, Loss_fe 1.132, Loss_kd 1.500, Train_accy 38.40
2022-10-08 06:36:31,562 [foster.py] => Task 3, Epoch 11/34 => Loss 3.950, Loss_clf 0.929, Loss_fe 1.098, Loss_kd 1.486, Train_accy 37.61, Test_accy 42.86
2022-10-08 06:36:35,595 [foster.py] => Task 3, Epoch 12/34 => Loss 3.909, Loss_clf 0.916, Loss_fe 1.051, Loss_kd 1.501, Train_accy 38.11
2022-10-08 06:36:39,592 [foster.py] => Task 3, Epoch 13/34 => Loss 3.909, Loss_clf 0.911, Loss_fe 1.057, Loss_kd 1.500, Train_accy 40.20
2022-10-08 06:36:43,583 [foster.py] => Task 3, Epoch 14/34 => Loss 3.816, Loss_clf 0.872, Loss_fe 1.001, Loss_kd 1.501, Train_accy 38.83
2022-10-08 06:36:47,578 [foster.py] => Task 3, Epoch 15/34 => Loss 3.819, Loss_clf 0.882, Loss_fe 0.995, Loss_kd 1.500, Train_accy 38.98
2022-10-08 06:36:52,597 [foster.py] => Task 3, Epoch 16/34 => Loss 3.757, Loss_clf 0.862, Loss_fe 0.959, Loss_kd 1.496, Train_accy 39.48, Test_accy 43.25
2022-10-08 06:36:56,179 [foster.py] => Task 3, Epoch 17/34 => Loss 3.706, Loss_clf 0.829, Loss_fe 0.937, Loss_kd 1.500, Train_accy 40.85
2022-10-08 06:36:59,699 [foster.py] => Task 3, Epoch 18/34 => Loss 3.728, Loss_clf 0.852, Loss_fe 0.943, Loss_kd 1.494, Train_accy 40.13
2022-10-08 06:37:03,207 [foster.py] => Task 3, Epoch 19/34 => Loss 3.725, Loss_clf 0.844, Loss_fe 0.940, Loss_kd 1.499, Train_accy 40.27
2022-10-08 06:37:06,773 [foster.py] => Task 3, Epoch 20/34 => Loss 3.700, Loss_clf 0.822, Loss_fe 0.931, Loss_kd 1.504, Train_accy 39.70
2022-10-08 06:37:11,360 [foster.py] => Task 3, Epoch 21/34 => Loss 3.689, Loss_clf 0.824, Loss_fe 0.922, Loss_kd 1.502, Train_accy 39.91, Test_accy 44.64
2022-10-08 06:37:14,641 [foster.py] => Task 3, Epoch 22/34 => Loss 3.642, Loss_clf 0.804, Loss_fe 0.896, Loss_kd 1.500, Train_accy 41.35
2022-10-08 06:37:17,859 [foster.py] => Task 3, Epoch 23/34 => Loss 3.624, Loss_clf 0.802, Loss_fe 0.884, Loss_kd 1.497, Train_accy 42.15
2022-10-08 06:37:21,060 [foster.py] => Task 3, Epoch 24/34 => Loss 3.654, Loss_clf 0.817, Loss_fe 0.890, Loss_kd 1.504, Train_accy 41.71
2022-10-08 06:37:24,238 [foster.py] => Task 3, Epoch 25/34 => Loss 3.629, Loss_clf 0.793, Loss_fe 0.886, Loss_kd 1.506, Train_accy 42.29
2022-10-08 06:37:29,123 [foster.py] => Task 3, Epoch 26/34 => Loss 3.611, Loss_clf 0.787, Loss_fe 0.873, Loss_kd 1.508, Train_accy 40.71, Test_accy 45.44
2022-10-08 06:37:32,866 [foster.py] => Task 3, Epoch 27/34 => Loss 3.587, Loss_clf 0.776, Loss_fe 0.865, Loss_kd 1.504, Train_accy 43.08
2022-10-08 06:37:36,108 [foster.py] => Task 3, Epoch 28/34 => Loss 3.590, Loss_clf 0.787, Loss_fe 0.858, Loss_kd 1.502, Train_accy 40.35
2022-10-08 06:37:39,262 [foster.py] => Task 3, Epoch 29/34 => Loss 3.581, Loss_clf 0.782, Loss_fe 0.860, Loss_kd 1.498, Train_accy 42.22
2022-10-08 06:37:42,293 [foster.py] => Task 3, Epoch 30/34 => Loss 3.587, Loss_clf 0.779, Loss_fe 0.861, Loss_kd 1.505, Train_accy 43.16
2022-10-08 06:37:46,545 [foster.py] => Task 3, Epoch 31/34 => Loss 3.557, Loss_clf 0.772, Loss_fe 0.835, Loss_kd 1.507, Train_accy 41.14, Test_accy 46.03
2022-10-08 06:37:49,654 [foster.py] => Task 3, Epoch 32/34 => Loss 3.569, Loss_clf 0.776, Loss_fe 0.846, Loss_kd 1.505, Train_accy 43.88
2022-10-08 06:37:52,635 [foster.py] => Task 3, Epoch 33/34 => Loss 3.566, Loss_clf 0.775, Loss_fe 0.852, Loss_kd 1.498, Train_accy 41.28
2022-10-08 06:37:55,666 [foster.py] => Task 3, Epoch 34/34 => Loss 3.541, Loss_clf 0.765, Loss_fe 0.836, Loss_kd 1.499, Train_accy 43.30
2022-10-08 06:37:55,666 [foster.py] => do not weight align teacher!
2022-10-08 06:37:55,667 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 06:38:00,132 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.459,  Train_accy 12.10, Test_accy 33.73
2022-10-08 06:38:03,616 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.388,  Train_accy 13.11
2022-10-08 06:38:07,142 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.368,  Train_accy 12.97
2022-10-08 06:38:11,001 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.357,  Train_accy 13.11
2022-10-08 06:38:14,879 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.348,  Train_accy 13.40
2022-10-08 06:38:19,480 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.340,  Train_accy 13.40, Test_accy 35.91
2022-10-08 06:38:22,799 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.330,  Train_accy 13.18
2022-10-08 06:38:26,040 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.324,  Train_accy 13.26
2022-10-08 06:38:29,285 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.319,  Train_accy 13.18
2022-10-08 06:38:32,575 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.317,  Train_accy 13.40
2022-10-08 06:38:36,691 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.326,  Train_accy 13.83, Test_accy 37.50
2022-10-08 06:38:39,854 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.312,  Train_accy 13.40
2022-10-08 06:38:43,189 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.319,  Train_accy 13.62
2022-10-08 06:38:46,585 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.311,  Train_accy 13.90
2022-10-08 06:38:50,030 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.307,  Train_accy 14.27
2022-10-08 06:38:54,088 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.302,  Train_accy 13.54, Test_accy 37.50
2022-10-08 06:38:57,262 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.307,  Train_accy 13.83
2022-10-08 06:39:00,526 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.307,  Train_accy 13.83
2022-10-08 06:39:03,660 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.314,  Train_accy 13.69
2022-10-08 06:39:06,865 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.298,  Train_accy 14.12
2022-10-08 06:39:10,978 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.301,  Train_accy 13.98, Test_accy 37.70
2022-10-08 06:39:14,130 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.308,  Train_accy 13.98
2022-10-08 06:39:17,306 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.311,  Train_accy 14.27
2022-10-08 06:39:20,454 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.305,  Train_accy 14.41
2022-10-08 06:39:23,587 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.307,  Train_accy 13.69
2022-10-08 06:39:27,574 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.290,  Train_accy 14.41, Test_accy 37.90
2022-10-08 06:39:27,575 [foster.py] => do not weight align student!
2022-10-08 06:39:28,346 [foster.py] => darknet eval: 
2022-10-08 06:39:28,346 [foster.py] => CNN top1 curve: 37.9
2022-10-08 06:39:28,346 [foster.py] => CNN top5 curve: 84.52
2022-10-08 06:39:28,346 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 06:39:39,224 [foster.py] => Exemplar size: 440
2022-10-08 06:39:39,224 [trainer.py] => CNN: {'total': 45.83, 'old': 48.4, 'new': 35.05, 'base': 76.58, 'compound': 31.79}
2022-10-08 06:39:39,225 [trainer.py] => CNN top1 curve: [86.71, 61.97, 50.86, 45.83]
2022-10-08 06:39:39,225 [trainer.py] => CNN base curve: [86.71, 83.54, 79.75, 76.58]
2022-10-08 06:39:39,225 [trainer.py] => CNN old curve: [86.71, 83.54, 56.34, 48.4]
2022-10-08 06:39:39,225 [trainer.py] => CNN new curve: [0, 34.92, 38.21, 35.05]
2022-10-08 06:39:39,225 [trainer.py] => CNN compound curve: [0, 34.92, 32.53, 31.79]
2022-10-08 06:39:39,225 [trainer.py] => NME: {'total': 55.36, 'old': 56.02, 'new': 52.58, 'base': 66.46, 'compound': 50.29}
2022-10-08 06:39:39,225 [trainer.py] => NME top1 curve: [85.44, 67.96, 57.74, 55.36]
2022-10-08 06:39:39,225 [trainer.py] => NME base curve: [85.44, 68.35, 66.46, 66.46]
2022-10-08 06:39:39,225 [trainer.py] => NME old curve: [85.44, 68.35, 59.15, 56.02]
2022-10-08 06:39:39,225 [trainer.py] => NME new curve: [0, 67.46, 54.47, 52.58]
2022-10-08 06:39:39,225 [trainer.py] => NME compound curve: [0, 67.46, 52.21, 50.29]
2022-10-08 06:39:39,226 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 06:39:39,226 [trainer.py] => prefix: cil
2022-10-08 06:39:39,226 [trainer.py] => dataset: CFEE
2022-10-08 06:39:39,226 [trainer.py] => memory_size: 2000
2022-10-08 06:39:39,226 [trainer.py] => memory_per_class: 20
2022-10-08 06:39:39,226 [trainer.py] => fixed_memory: True
2022-10-08 06:39:39,226 [trainer.py] => shuffle: True
2022-10-08 06:39:39,226 [trainer.py] => init_cls: 7
2022-10-08 06:39:39,226 [trainer.py] => increment: 5
2022-10-08 06:39:39,226 [trainer.py] => model_name: foster
2022-10-08 06:39:39,226 [trainer.py] => convnet_type: resnet18
2022-10-08 06:39:39,226 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 06:39:39,226 [trainer.py] => seed: 1993
2022-10-08 06:39:39,226 [trainer.py] => beta1: 0.96
2022-10-08 06:39:39,227 [trainer.py] => beta2: 0.97
2022-10-08 06:39:39,227 [trainer.py] => oofc: ft
2022-10-08 06:39:39,227 [trainer.py] => is_teacher_wa: False
2022-10-08 06:39:39,227 [trainer.py] => is_student_wa: False
2022-10-08 06:39:39,227 [trainer.py] => lambda_okd: 1
2022-10-08 06:39:39,227 [trainer.py] => wa_value: 1
2022-10-08 06:39:39,227 [trainer.py] => init_epochs: 40
2022-10-08 06:39:39,227 [trainer.py] => init_lr: 0.01
2022-10-08 06:39:39,227 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 06:39:39,227 [trainer.py] => boosting_epochs: 34
2022-10-08 06:39:39,227 [trainer.py] => compression_epochs: 26
2022-10-08 06:39:39,227 [trainer.py] => lr: 0.001
2022-10-08 06:39:39,227 [trainer.py] => batch_size: 32
2022-10-08 06:39:39,227 [trainer.py] => weight_decay: 0.0005
2022-10-08 06:39:39,227 [trainer.py] => num_workers: 8
2022-10-08 06:39:39,227 [trainer.py] => T: 2
2022-10-08 06:39:39,227 [trainer.py] => nb_runs: 3
2022-10-08 06:39:39,227 [trainer.py] => fold: 10
2022-10-08 06:39:39,227 [data.py] => ========== Fold:9 ==========
2022-10-08 06:39:39,232 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 13, 17, 15, 9, 11, 20, 18, 12, 14, 7, 10, 19, 21, 16, 8]
2022-10-08 06:39:39,443 [foster.py] => Learning on 0-7
2022-10-08 06:39:39,443 [foster.py] => All params: 11183694
2022-10-08 06:39:39,443 [foster.py] => Trainable params: 11183694
2022-10-08 06:39:41,680 [foster.py] => Task 0, Epoch 1/40 => Loss 1.371, Train_accy 49.62
2022-10-08 06:39:44,455 [foster.py] => Task 0, Epoch 2/40 => Loss 0.558, Train_accy 80.39, Test_accy 78.66
2022-10-08 06:39:47,239 [foster.py] => Task 0, Epoch 3/40 => Loss 0.361, Train_accy 87.39, Test_accy 85.37
2022-10-08 06:39:50,062 [foster.py] => Task 0, Epoch 4/40 => Loss 0.284, Train_accy 89.74, Test_accy 83.54
2022-10-08 06:39:52,884 [foster.py] => Task 0, Epoch 5/40 => Loss 0.242, Train_accy 92.79, Test_accy 78.66
2022-10-08 06:39:55,157 [foster.py] => Task 0, Epoch 6/40 => Loss 0.252, Train_accy 91.61
2022-10-08 06:39:57,966 [foster.py] => Task 0, Epoch 7/40 => Loss 0.176, Train_accy 94.25, Test_accy 85.37
2022-10-08 06:40:00,751 [foster.py] => Task 0, Epoch 8/40 => Loss 0.160, Train_accy 94.46, Test_accy 83.54
2022-10-08 06:40:03,578 [foster.py] => Task 0, Epoch 9/40 => Loss 0.141, Train_accy 95.15, Test_accy 85.37
2022-10-08 06:40:06,404 [foster.py] => Task 0, Epoch 10/40 => Loss 0.115, Train_accy 96.40, Test_accy 85.37
2022-10-08 06:40:08,682 [foster.py] => Task 0, Epoch 11/40 => Loss 0.098, Train_accy 97.02
2022-10-08 06:40:11,506 [foster.py] => Task 0, Epoch 12/40 => Loss 0.117, Train_accy 96.60, Test_accy 83.54
2022-10-08 06:40:14,354 [foster.py] => Task 0, Epoch 13/40 => Loss 0.102, Train_accy 97.23, Test_accy 84.15
2022-10-08 06:40:17,171 [foster.py] => Task 0, Epoch 14/40 => Loss 0.081, Train_accy 97.23, Test_accy 83.54
2022-10-08 06:40:19,985 [foster.py] => Task 0, Epoch 15/40 => Loss 0.100, Train_accy 98.20, Test_accy 83.54
2022-10-08 06:40:22,207 [foster.py] => Task 0, Epoch 16/40 => Loss 0.060, Train_accy 98.61
2022-10-08 06:40:25,021 [foster.py] => Task 0, Epoch 17/40 => Loss 0.046, Train_accy 98.96, Test_accy 82.93
2022-10-08 06:40:27,864 [foster.py] => Task 0, Epoch 18/40 => Loss 0.028, Train_accy 99.51, Test_accy 84.76
2022-10-08 06:40:30,647 [foster.py] => Task 0, Epoch 19/40 => Loss 0.036, Train_accy 99.10, Test_accy 82.32
2022-10-08 06:40:33,507 [foster.py] => Task 0, Epoch 20/40 => Loss 0.027, Train_accy 99.58, Test_accy 83.54
2022-10-08 06:40:35,737 [foster.py] => Task 0, Epoch 21/40 => Loss 0.020, Train_accy 99.79
2022-10-08 06:40:38,613 [foster.py] => Task 0, Epoch 22/40 => Loss 0.022, Train_accy 99.45, Test_accy 84.76
2022-10-08 06:40:41,458 [foster.py] => Task 0, Epoch 23/40 => Loss 0.022, Train_accy 99.72, Test_accy 84.15
2022-10-08 06:40:44,281 [foster.py] => Task 0, Epoch 24/40 => Loss 0.042, Train_accy 99.51, Test_accy 82.93
2022-10-08 06:40:47,114 [foster.py] => Task 0, Epoch 25/40 => Loss 0.028, Train_accy 99.24, Test_accy 84.15
2022-10-08 06:40:49,336 [foster.py] => Task 0, Epoch 26/40 => Loss 0.034, Train_accy 99.51
2022-10-08 06:40:52,130 [foster.py] => Task 0, Epoch 27/40 => Loss 0.025, Train_accy 99.51, Test_accy 85.37
2022-10-08 06:40:54,953 [foster.py] => Task 0, Epoch 28/40 => Loss 0.034, Train_accy 99.65, Test_accy 84.76
2022-10-08 06:40:57,753 [foster.py] => Task 0, Epoch 29/40 => Loss 0.019, Train_accy 99.79, Test_accy 84.76
2022-10-08 06:41:00,574 [foster.py] => Task 0, Epoch 30/40 => Loss 0.026, Train_accy 99.51, Test_accy 85.98
2022-10-08 06:41:02,831 [foster.py] => Task 0, Epoch 31/40 => Loss 0.017, Train_accy 99.72
2022-10-08 06:41:05,700 [foster.py] => Task 0, Epoch 32/40 => Loss 0.016, Train_accy 99.65, Test_accy 82.93
2022-10-08 06:41:08,529 [foster.py] => Task 0, Epoch 33/40 => Loss 0.017, Train_accy 99.65, Test_accy 84.15
2022-10-08 06:41:11,350 [foster.py] => Task 0, Epoch 34/40 => Loss 0.018, Train_accy 99.65, Test_accy 82.32
2022-10-08 06:41:14,178 [foster.py] => Task 0, Epoch 35/40 => Loss 0.022, Train_accy 99.79, Test_accy 84.15
2022-10-08 06:41:16,451 [foster.py] => Task 0, Epoch 36/40 => Loss 0.013, Train_accy 99.93
2022-10-08 06:41:19,272 [foster.py] => Task 0, Epoch 37/40 => Loss 0.033, Train_accy 99.86, Test_accy 85.37
2022-10-08 06:41:22,099 [foster.py] => Task 0, Epoch 38/40 => Loss 0.041, Train_accy 99.58, Test_accy 83.54
2022-10-08 06:41:24,935 [foster.py] => Task 0, Epoch 39/40 => Loss 0.013, Train_accy 99.79, Test_accy 82.32
2022-10-08 06:41:27,824 [foster.py] => Task 0, Epoch 40/40 => Loss 0.018, Train_accy 99.65, Test_accy 82.93
2022-10-08 06:41:27,824 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 06:41:34,204 [foster.py] => Exemplar size: 140
2022-10-08 06:41:34,204 [trainer.py] => CNN: {'total': 82.93, 'old': 82.93, 'new': 0, 'base': 82.93, 'compound': 0}
2022-10-08 06:41:34,204 [trainer.py] => CNN top1 curve: [82.93]
2022-10-08 06:41:34,204 [trainer.py] => CNN base curve: [82.93]
2022-10-08 06:41:34,204 [trainer.py] => CNN old curve: [82.93]
2022-10-08 06:41:34,204 [trainer.py] => CNN new curve: [0]
2022-10-08 06:41:34,204 [trainer.py] => CNN compound curve: [0]
2022-10-08 06:41:34,204 [trainer.py] => NME: {'total': 84.76, 'old': 84.76, 'new': 0, 'base': 84.76, 'compound': 0}
2022-10-08 06:41:34,204 [trainer.py] => NME top1 curve: [84.76]
2022-10-08 06:41:34,204 [trainer.py] => NME base curve: [84.76]
2022-10-08 06:41:34,204 [trainer.py] => NME old curve: [84.76]
2022-10-08 06:41:34,204 [trainer.py] => NME new curve: [0]
2022-10-08 06:41:34,204 [trainer.py] => NME compound curve: [0]
2022-10-08 06:41:34,423 [foster.py] => Learning on 7-12
2022-10-08 06:41:34,423 [foster.py] => All params: 22375071
2022-10-08 06:41:34,423 [foster.py] => Trainable params: 11194968
2022-10-08 06:41:34,432 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 06:41:37,406 [foster.py] => Task 1, Epoch 1/34 => Loss 4.849, Loss_clf 2.186, Loss_fe 2.025, Loss_kd 0.372, Train_accy 34.29, Test_accy 58.05
2022-10-08 06:41:39,724 [foster.py] => Task 1, Epoch 2/34 => Loss 2.562, Loss_clf 0.730, Loss_fe 1.197, Loss_kd 0.371, Train_accy 62.08
2022-10-08 06:41:42,032 [foster.py] => Task 1, Epoch 3/34 => Loss 2.197, Loss_clf 0.601, Loss_fe 0.979, Loss_kd 0.360, Train_accy 44.51
2022-10-08 06:41:44,326 [foster.py] => Task 1, Epoch 4/34 => Loss 2.043, Loss_clf 0.557, Loss_fe 0.863, Loss_kd 0.364, Train_accy 42.82
2022-10-08 06:41:46,626 [foster.py] => Task 1, Epoch 5/34 => Loss 1.923, Loss_clf 0.530, Loss_fe 0.778, Loss_kd 0.359, Train_accy 46.03
2022-10-08 06:41:49,669 [foster.py] => Task 1, Epoch 6/34 => Loss 1.830, Loss_clf 0.498, Loss_fe 0.721, Loss_kd 0.356, Train_accy 45.69, Test_accy 60.67
2022-10-08 06:41:51,956 [foster.py] => Task 1, Epoch 7/34 => Loss 1.794, Loss_clf 0.491, Loss_fe 0.686, Loss_kd 0.361, Train_accy 47.55
2022-10-08 06:41:54,237 [foster.py] => Task 1, Epoch 8/34 => Loss 1.753, Loss_clf 0.480, Loss_fe 0.652, Loss_kd 0.362, Train_accy 42.57
2022-10-08 06:41:56,573 [foster.py] => Task 1, Epoch 9/34 => Loss 1.701, Loss_clf 0.460, Loss_fe 0.628, Loss_kd 0.357, Train_accy 47.04
2022-10-08 06:41:58,844 [foster.py] => Task 1, Epoch 10/34 => Loss 1.676, Loss_clf 0.458, Loss_fe 0.604, Loss_kd 0.358, Train_accy 47.80
2022-10-08 06:42:01,861 [foster.py] => Task 1, Epoch 11/34 => Loss 1.634, Loss_clf 0.441, Loss_fe 0.578, Loss_kd 0.359, Train_accy 46.88, Test_accy 61.05
2022-10-08 06:42:04,121 [foster.py] => Task 1, Epoch 12/34 => Loss 1.627, Loss_clf 0.437, Loss_fe 0.573, Loss_kd 0.360, Train_accy 46.28
2022-10-08 06:42:06,463 [foster.py] => Task 1, Epoch 13/34 => Loss 1.568, Loss_clf 0.416, Loss_fe 0.540, Loss_kd 0.357, Train_accy 45.27
2022-10-08 06:42:08,781 [foster.py] => Task 1, Epoch 14/34 => Loss 1.581, Loss_clf 0.423, Loss_fe 0.544, Loss_kd 0.358, Train_accy 47.47
2022-10-08 06:42:11,081 [foster.py] => Task 1, Epoch 15/34 => Loss 1.558, Loss_clf 0.415, Loss_fe 0.530, Loss_kd 0.357, Train_accy 47.30
2022-10-08 06:42:14,129 [foster.py] => Task 1, Epoch 16/34 => Loss 1.555, Loss_clf 0.414, Loss_fe 0.532, Loss_kd 0.355, Train_accy 48.06, Test_accy 61.80
2022-10-08 06:42:16,505 [foster.py] => Task 1, Epoch 17/34 => Loss 1.503, Loss_clf 0.388, Loss_fe 0.503, Loss_kd 0.357, Train_accy 48.06
2022-10-08 06:42:18,869 [foster.py] => Task 1, Epoch 18/34 => Loss 1.474, Loss_clf 0.377, Loss_fe 0.487, Loss_kd 0.356, Train_accy 47.13
2022-10-08 06:42:21,236 [foster.py] => Task 1, Epoch 19/34 => Loss 1.491, Loss_clf 0.389, Loss_fe 0.489, Loss_kd 0.358, Train_accy 46.54
2022-10-08 06:42:23,619 [foster.py] => Task 1, Epoch 20/34 => Loss 1.475, Loss_clf 0.377, Loss_fe 0.483, Loss_kd 0.359, Train_accy 48.40
2022-10-08 06:42:26,721 [foster.py] => Task 1, Epoch 21/34 => Loss 1.440, Loss_clf 0.366, Loss_fe 0.461, Loss_kd 0.358, Train_accy 49.41, Test_accy 61.80
2022-10-08 06:42:29,098 [foster.py] => Task 1, Epoch 22/34 => Loss 1.461, Loss_clf 0.376, Loss_fe 0.466, Loss_kd 0.361, Train_accy 47.47
2022-10-08 06:42:31,439 [foster.py] => Task 1, Epoch 23/34 => Loss 1.449, Loss_clf 0.369, Loss_fe 0.465, Loss_kd 0.359, Train_accy 47.55
2022-10-08 06:42:33,781 [foster.py] => Task 1, Epoch 24/34 => Loss 1.426, Loss_clf 0.358, Loss_fe 0.458, Loss_kd 0.356, Train_accy 48.14
2022-10-08 06:42:36,169 [foster.py] => Task 1, Epoch 25/34 => Loss 1.431, Loss_clf 0.357, Loss_fe 0.456, Loss_kd 0.360, Train_accy 47.97
2022-10-08 06:42:39,244 [foster.py] => Task 1, Epoch 26/34 => Loss 1.425, Loss_clf 0.359, Loss_fe 0.450, Loss_kd 0.359, Train_accy 49.49, Test_accy 61.42
2022-10-08 06:42:41,587 [foster.py] => Task 1, Epoch 27/34 => Loss 1.452, Loss_clf 0.366, Loss_fe 0.472, Loss_kd 0.358, Train_accy 46.71
2022-10-08 06:42:43,883 [foster.py] => Task 1, Epoch 28/34 => Loss 1.403, Loss_clf 0.352, Loss_fe 0.448, Loss_kd 0.352, Train_accy 46.88
2022-10-08 06:42:46,258 [foster.py] => Task 1, Epoch 29/34 => Loss 1.411, Loss_clf 0.349, Loss_fe 0.447, Loss_kd 0.359, Train_accy 48.48
2022-10-08 06:42:48,547 [foster.py] => Task 1, Epoch 30/34 => Loss 1.410, Loss_clf 0.353, Loss_fe 0.442, Loss_kd 0.359, Train_accy 48.56
2022-10-08 06:42:53,463 [foster.py] => Task 1, Epoch 31/34 => Loss 1.400, Loss_clf 0.340, Loss_fe 0.443, Loss_kd 0.360, Train_accy 48.65, Test_accy 62.55
2022-10-08 06:42:55,945 [foster.py] => Task 1, Epoch 32/34 => Loss 1.414, Loss_clf 0.355, Loss_fe 0.444, Loss_kd 0.359, Train_accy 49.16
2022-10-08 06:42:58,397 [foster.py] => Task 1, Epoch 33/34 => Loss 1.451, Loss_clf 0.369, Loss_fe 0.466, Loss_kd 0.360, Train_accy 46.96
2022-10-08 06:43:00,773 [foster.py] => Task 1, Epoch 34/34 => Loss 1.395, Loss_clf 0.344, Loss_fe 0.440, Loss_kd 0.356, Train_accy 47.30
2022-10-08 06:43:00,773 [foster.py] => do not weight align teacher!
2022-10-08 06:43:00,774 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 06:43:04,365 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.640,  Train_accy 11.66, Test_accy 49.06
2022-10-08 06:43:07,005 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.529,  Train_accy 11.82
2022-10-08 06:43:09,661 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.467,  Train_accy 12.25
2022-10-08 06:43:12,326 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.434,  Train_accy 12.84
2022-10-08 06:43:14,972 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.415,  Train_accy 14.78
2022-10-08 06:43:18,269 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.392,  Train_accy 15.71, Test_accy 51.69
2022-10-08 06:43:20,893 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.393,  Train_accy 16.39
2022-10-08 06:43:23,529 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.370,  Train_accy 16.81
2022-10-08 06:43:26,231 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.365,  Train_accy 17.65
2022-10-08 06:43:28,912 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.356,  Train_accy 17.74
2022-10-08 06:43:33,047 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.353,  Train_accy 17.91, Test_accy 53.93
2022-10-08 06:43:35,948 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.350,  Train_accy 19.51
2022-10-08 06:43:38,755 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.357,  Train_accy 20.35
2022-10-08 06:43:41,605 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.342,  Train_accy 19.68
2022-10-08 06:43:44,427 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.352,  Train_accy 20.27
2022-10-08 06:43:47,803 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.336,  Train_accy 20.44, Test_accy 54.68
2022-10-08 06:43:50,469 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.338,  Train_accy 20.02
2022-10-08 06:43:53,168 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.338,  Train_accy 20.44
2022-10-08 06:43:55,834 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.328,  Train_accy 21.03
2022-10-08 06:43:58,494 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.331,  Train_accy 21.03
2022-10-08 06:44:01,846 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.327,  Train_accy 20.35, Test_accy 54.68
2022-10-08 06:44:04,463 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.322,  Train_accy 21.71
2022-10-08 06:44:07,105 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.331,  Train_accy 22.21
2022-10-08 06:44:09,759 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.325,  Train_accy 21.54
2022-10-08 06:44:12,430 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.322,  Train_accy 21.54
2022-10-08 06:44:15,733 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.324,  Train_accy 20.95, Test_accy 55.06
2022-10-08 06:44:15,734 [foster.py] => do not weight align student!
2022-10-08 06:44:16,377 [foster.py] => darknet eval: 
2022-10-08 06:44:16,377 [foster.py] => CNN top1 curve: 55.06
2022-10-08 06:44:16,377 [foster.py] => CNN top5 curve: 97.0
2022-10-08 06:44:16,378 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 06:44:23,926 [foster.py] => Exemplar size: 240
2022-10-08 06:44:23,927 [trainer.py] => CNN: {'total': 61.8, 'old': 78.05, 'new': 35.92, 'base': 78.05, 'compound': 35.92}
2022-10-08 06:44:23,927 [trainer.py] => CNN top1 curve: [82.93, 61.8]
2022-10-08 06:44:23,927 [trainer.py] => CNN base curve: [82.93, 78.05]
2022-10-08 06:44:23,927 [trainer.py] => CNN old curve: [82.93, 78.05]
2022-10-08 06:44:23,927 [trainer.py] => CNN new curve: [0, 35.92]
2022-10-08 06:44:23,927 [trainer.py] => CNN compound curve: [0, 35.92]
2022-10-08 06:44:23,927 [trainer.py] => NME: {'total': 69.66, 'old': 74.39, 'new': 62.14, 'base': 74.39, 'compound': 62.14}
2022-10-08 06:44:23,927 [trainer.py] => NME top1 curve: [84.76, 69.66]
2022-10-08 06:44:23,927 [trainer.py] => NME base curve: [84.76, 74.39]
2022-10-08 06:44:23,927 [trainer.py] => NME old curve: [84.76, 74.39]
2022-10-08 06:44:23,927 [trainer.py] => NME new curve: [0, 62.14]
2022-10-08 06:44:23,927 [trainer.py] => NME compound curve: [0, 62.14]
2022-10-08 06:44:24,146 [foster.py] => Learning on 12-17
2022-10-08 06:44:24,146 [foster.py] => All params: 22385326
2022-10-08 06:44:24,147 [foster.py] => Trainable params: 11202658
2022-10-08 06:44:24,155 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 06:44:27,427 [foster.py] => Task 2, Epoch 1/34 => Loss 5.710, Loss_clf 2.146, Loss_fe 2.161, Loss_kd 0.990, Train_accy 36.93, Test_accy 46.61
2022-10-08 06:44:29,819 [foster.py] => Task 2, Epoch 2/34 => Loss 3.843, Loss_clf 1.017, Loss_fe 1.502, Loss_kd 0.935, Train_accy 40.94
2022-10-08 06:44:32,277 [foster.py] => Task 2, Epoch 3/34 => Loss 3.576, Loss_clf 0.914, Loss_fe 1.324, Loss_kd 0.944, Train_accy 39.45
2022-10-08 06:44:34,694 [foster.py] => Task 2, Epoch 4/34 => Loss 3.360, Loss_clf 0.831, Loss_fe 1.193, Loss_kd 0.943, Train_accy 39.45
2022-10-08 06:44:37,129 [foster.py] => Task 2, Epoch 5/34 => Loss 3.255, Loss_clf 0.801, Loss_fe 1.122, Loss_kd 0.940, Train_accy 39.37
2022-10-08 06:44:40,357 [foster.py] => Task 2, Epoch 6/34 => Loss 3.187, Loss_clf 0.779, Loss_fe 1.067, Loss_kd 0.947, Train_accy 38.66, Test_accy 48.18
2022-10-08 06:44:42,789 [foster.py] => Task 2, Epoch 7/34 => Loss 3.140, Loss_clf 0.781, Loss_fe 1.019, Loss_kd 0.946, Train_accy 40.79
2022-10-08 06:44:45,250 [foster.py] => Task 2, Epoch 8/34 => Loss 3.041, Loss_clf 0.736, Loss_fe 0.964, Loss_kd 0.947, Train_accy 38.90
2022-10-08 06:44:47,714 [foster.py] => Task 2, Epoch 9/34 => Loss 3.006, Loss_clf 0.727, Loss_fe 0.932, Loss_kd 0.951, Train_accy 41.65
2022-10-08 06:44:50,180 [foster.py] => Task 2, Epoch 10/34 => Loss 2.938, Loss_clf 0.705, Loss_fe 0.899, Loss_kd 0.942, Train_accy 39.37
2022-10-08 06:44:53,479 [foster.py] => Task 2, Epoch 11/34 => Loss 2.886, Loss_clf 0.692, Loss_fe 0.870, Loss_kd 0.935, Train_accy 41.42, Test_accy 49.74
2022-10-08 06:44:55,899 [foster.py] => Task 2, Epoch 12/34 => Loss 2.873, Loss_clf 0.684, Loss_fe 0.850, Loss_kd 0.945, Train_accy 42.05
2022-10-08 06:44:58,465 [foster.py] => Task 2, Epoch 13/34 => Loss 2.839, Loss_clf 0.674, Loss_fe 0.829, Loss_kd 0.943, Train_accy 41.73
2022-10-08 06:45:00,940 [foster.py] => Task 2, Epoch 14/34 => Loss 2.787, Loss_clf 0.651, Loss_fe 0.801, Loss_kd 0.942, Train_accy 43.86
2022-10-08 06:45:03,427 [foster.py] => Task 2, Epoch 15/34 => Loss 2.769, Loss_clf 0.647, Loss_fe 0.778, Loss_kd 0.948, Train_accy 42.36
2022-10-08 06:45:06,704 [foster.py] => Task 2, Epoch 16/34 => Loss 2.739, Loss_clf 0.633, Loss_fe 0.762, Loss_kd 0.949, Train_accy 43.39, Test_accy 50.26
2022-10-08 06:45:09,148 [foster.py] => Task 2, Epoch 17/34 => Loss 2.708, Loss_clf 0.617, Loss_fe 0.749, Loss_kd 0.948, Train_accy 44.41
2022-10-08 06:45:11,639 [foster.py] => Task 2, Epoch 18/34 => Loss 2.682, Loss_clf 0.615, Loss_fe 0.727, Loss_kd 0.946, Train_accy 43.94
2022-10-08 06:45:14,084 [foster.py] => Task 2, Epoch 19/34 => Loss 2.679, Loss_clf 0.609, Loss_fe 0.727, Loss_kd 0.948, Train_accy 43.23
2022-10-08 06:45:16,509 [foster.py] => Task 2, Epoch 20/34 => Loss 2.660, Loss_clf 0.606, Loss_fe 0.721, Loss_kd 0.941, Train_accy 43.15
2022-10-08 06:45:19,791 [foster.py] => Task 2, Epoch 21/34 => Loss 2.643, Loss_clf 0.591, Loss_fe 0.705, Loss_kd 0.950, Train_accy 43.54, Test_accy 51.30
2022-10-08 06:45:22,242 [foster.py] => Task 2, Epoch 22/34 => Loss 2.656, Loss_clf 0.608, Loss_fe 0.713, Loss_kd 0.942, Train_accy 42.52
2022-10-08 06:45:24,735 [foster.py] => Task 2, Epoch 23/34 => Loss 2.634, Loss_clf 0.594, Loss_fe 0.697, Loss_kd 0.948, Train_accy 44.65
2022-10-08 06:45:27,211 [foster.py] => Task 2, Epoch 24/34 => Loss 2.575, Loss_clf 0.573, Loss_fe 0.672, Loss_kd 0.939, Train_accy 44.57
2022-10-08 06:45:29,705 [foster.py] => Task 2, Epoch 25/34 => Loss 2.601, Loss_clf 0.577, Loss_fe 0.686, Loss_kd 0.945, Train_accy 45.75
2022-10-08 06:45:32,950 [foster.py] => Task 2, Epoch 26/34 => Loss 2.591, Loss_clf 0.577, Loss_fe 0.677, Loss_kd 0.944, Train_accy 43.78, Test_accy 51.56
2022-10-08 06:45:35,412 [foster.py] => Task 2, Epoch 27/34 => Loss 2.593, Loss_clf 0.571, Loss_fe 0.678, Loss_kd 0.949, Train_accy 44.80
2022-10-08 06:45:37,913 [foster.py] => Task 2, Epoch 28/34 => Loss 2.583, Loss_clf 0.564, Loss_fe 0.678, Loss_kd 0.947, Train_accy 45.04
2022-10-08 06:45:40,370 [foster.py] => Task 2, Epoch 29/34 => Loss 2.583, Loss_clf 0.573, Loss_fe 0.670, Loss_kd 0.946, Train_accy 45.98
2022-10-08 06:45:42,867 [foster.py] => Task 2, Epoch 30/34 => Loss 2.587, Loss_clf 0.573, Loss_fe 0.675, Loss_kd 0.945, Train_accy 44.72
2022-10-08 06:45:46,305 [foster.py] => Task 2, Epoch 31/34 => Loss 2.581, Loss_clf 0.564, Loss_fe 0.674, Loss_kd 0.948, Train_accy 45.20, Test_accy 52.08
2022-10-08 06:45:49,320 [foster.py] => Task 2, Epoch 32/34 => Loss 2.567, Loss_clf 0.565, Loss_fe 0.664, Loss_kd 0.945, Train_accy 45.98
2022-10-08 06:45:52,042 [foster.py] => Task 2, Epoch 33/34 => Loss 2.574, Loss_clf 0.567, Loss_fe 0.669, Loss_kd 0.945, Train_accy 44.33
2022-10-08 06:45:54,673 [foster.py] => Task 2, Epoch 34/34 => Loss 2.593, Loss_clf 0.578, Loss_fe 0.664, Loss_kd 0.953, Train_accy 45.20
2022-10-08 06:45:54,673 [foster.py] => do not weight align teacher!
2022-10-08 06:45:54,674 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 06:45:58,569 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.084,  Train_accy 11.81, Test_accy 37.24
2022-10-08 06:46:01,449 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 2.021,  Train_accy 11.81
2022-10-08 06:46:04,316 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.986,  Train_accy 12.36
2022-10-08 06:46:07,163 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.960,  Train_accy 12.28
2022-10-08 06:46:09,973 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.947,  Train_accy 12.44
2022-10-08 06:46:13,520 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.929,  Train_accy 12.52, Test_accy 38.54
2022-10-08 06:46:16,389 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.924,  Train_accy 12.91
2022-10-08 06:46:19,175 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.912,  Train_accy 12.91
2022-10-08 06:46:22,022 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.906,  Train_accy 12.99
2022-10-08 06:46:24,923 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.905,  Train_accy 13.31
2022-10-08 06:46:28,605 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.900,  Train_accy 13.31, Test_accy 38.80
2022-10-08 06:46:32,008 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.891,  Train_accy 13.07
2022-10-08 06:46:35,059 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.884,  Train_accy 13.62
2022-10-08 06:46:38,080 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.879,  Train_accy 13.86
2022-10-08 06:46:41,011 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.883,  Train_accy 14.09
2022-10-08 06:46:44,698 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.878,  Train_accy 14.17, Test_accy 39.58
2022-10-08 06:46:47,571 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.879,  Train_accy 14.57
2022-10-08 06:46:50,350 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.882,  Train_accy 14.09
2022-10-08 06:46:53,135 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.868,  Train_accy 15.20
2022-10-08 06:46:56,052 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.869,  Train_accy 14.57
2022-10-08 06:46:59,577 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.869,  Train_accy 15.28, Test_accy 40.10
2022-10-08 06:47:02,388 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.869,  Train_accy 14.49
2022-10-08 06:47:05,213 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.864,  Train_accy 14.96
2022-10-08 06:47:08,023 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.864,  Train_accy 14.02
2022-10-08 06:47:10,866 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.869,  Train_accy 14.25
2022-10-08 06:47:14,381 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.865,  Train_accy 14.33, Test_accy 39.06
2022-10-08 06:47:14,381 [foster.py] => do not weight align student!
2022-10-08 06:47:15,081 [foster.py] => darknet eval: 
2022-10-08 06:47:15,082 [foster.py] => CNN top1 curve: 39.06
2022-10-08 06:47:15,082 [foster.py] => CNN top5 curve: 92.97
2022-10-08 06:47:15,082 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 06:47:24,280 [foster.py] => Exemplar size: 340
2022-10-08 06:47:24,280 [trainer.py] => CNN: {'total': 51.82, 'old': 58.05, 'new': 37.61, 'base': 78.05, 'compound': 32.27}
2022-10-08 06:47:24,280 [trainer.py] => CNN top1 curve: [82.93, 61.8, 51.82]
2022-10-08 06:47:24,280 [trainer.py] => CNN base curve: [82.93, 78.05, 78.05]
2022-10-08 06:47:24,280 [trainer.py] => CNN old curve: [82.93, 78.05, 58.05]
2022-10-08 06:47:24,280 [trainer.py] => CNN new curve: [0, 35.92, 37.61]
2022-10-08 06:47:24,280 [trainer.py] => CNN compound curve: [0, 35.92, 32.27]
2022-10-08 06:47:24,280 [trainer.py] => NME: {'total': 62.5, 'old': 62.55, 'new': 62.39, 'base': 71.95, 'compound': 55.45}
2022-10-08 06:47:24,280 [trainer.py] => NME top1 curve: [84.76, 69.66, 62.5]
2022-10-08 06:47:24,280 [trainer.py] => NME base curve: [84.76, 74.39, 71.95]
2022-10-08 06:47:24,280 [trainer.py] => NME old curve: [84.76, 74.39, 62.55]
2022-10-08 06:47:24,280 [trainer.py] => NME new curve: [0, 62.14, 62.39]
2022-10-08 06:47:24,280 [trainer.py] => NME compound curve: [0, 62.14, 55.45]
2022-10-08 06:47:24,499 [foster.py] => Learning on 17-22
2022-10-08 06:47:24,500 [foster.py] => All params: 22395581
2022-10-08 06:47:24,500 [foster.py] => Trainable params: 11210348
2022-10-08 06:47:24,509 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 06:47:27,935 [foster.py] => Task 3, Epoch 1/34 => Loss 6.721, Loss_clf 2.228, Loss_fe 2.532, Loss_kd 1.516, Train_accy 32.97, Test_accy 35.71
2022-10-08 06:47:30,474 [foster.py] => Task 3, Epoch 2/34 => Loss 5.044, Loss_clf 1.276, Loss_fe 1.857, Loss_kd 1.476, Train_accy 29.16
2022-10-08 06:47:33,044 [foster.py] => Task 3, Epoch 3/34 => Loss 4.747, Loss_clf 1.167, Loss_fe 1.655, Loss_kd 1.488, Train_accy 31.58
2022-10-08 06:47:35,624 [foster.py] => Task 3, Epoch 4/34 => Loss 4.575, Loss_clf 1.122, Loss_fe 1.536, Loss_kd 1.481, Train_accy 33.41
2022-10-08 06:47:38,248 [foster.py] => Task 3, Epoch 5/34 => Loss 4.438, Loss_clf 1.084, Loss_fe 1.434, Loss_kd 1.484, Train_accy 32.67
2022-10-08 06:47:41,830 [foster.py] => Task 3, Epoch 6/34 => Loss 4.367, Loss_clf 1.073, Loss_fe 1.376, Loss_kd 1.482, Train_accy 35.60, Test_accy 42.26
2022-10-08 06:47:44,371 [foster.py] => Task 3, Epoch 7/34 => Loss 4.232, Loss_clf 1.023, Loss_fe 1.298, Loss_kd 1.477, Train_accy 34.58
2022-10-08 06:47:46,955 [foster.py] => Task 3, Epoch 8/34 => Loss 4.189, Loss_clf 1.013, Loss_fe 1.255, Loss_kd 1.485, Train_accy 35.09
2022-10-08 06:47:49,559 [foster.py] => Task 3, Epoch 9/34 => Loss 4.112, Loss_clf 0.981, Loss_fe 1.205, Loss_kd 1.489, Train_accy 36.63
2022-10-08 06:47:52,161 [foster.py] => Task 3, Epoch 10/34 => Loss 4.047, Loss_clf 0.970, Loss_fe 1.161, Loss_kd 1.481, Train_accy 35.31
2022-10-08 06:47:55,669 [foster.py] => Task 3, Epoch 11/34 => Loss 4.020, Loss_clf 0.955, Loss_fe 1.140, Loss_kd 1.488, Train_accy 36.56, Test_accy 43.25
2022-10-08 06:47:58,280 [foster.py] => Task 3, Epoch 12/34 => Loss 3.949, Loss_clf 0.925, Loss_fe 1.096, Loss_kd 1.490, Train_accy 39.12
2022-10-08 06:48:00,870 [foster.py] => Task 3, Epoch 13/34 => Loss 3.928, Loss_clf 0.931, Loss_fe 1.077, Loss_kd 1.484, Train_accy 36.48
2022-10-08 06:48:03,435 [foster.py] => Task 3, Epoch 14/34 => Loss 3.869, Loss_clf 0.905, Loss_fe 1.046, Loss_kd 1.483, Train_accy 37.29
2022-10-08 06:48:06,026 [foster.py] => Task 3, Epoch 15/34 => Loss 3.823, Loss_clf 0.875, Loss_fe 1.024, Loss_kd 1.487, Train_accy 38.75
2022-10-08 06:48:09,563 [foster.py] => Task 3, Epoch 16/34 => Loss 3.829, Loss_clf 0.896, Loss_fe 1.020, Loss_kd 1.478, Train_accy 37.66, Test_accy 43.06
2022-10-08 06:48:12,183 [foster.py] => Task 3, Epoch 17/34 => Loss 3.789, Loss_clf 0.871, Loss_fe 0.992, Loss_kd 1.488, Train_accy 38.46
2022-10-08 06:48:14,807 [foster.py] => Task 3, Epoch 18/34 => Loss 3.728, Loss_clf 0.850, Loss_fe 0.966, Loss_kd 1.477, Train_accy 38.10
2022-10-08 06:48:17,400 [foster.py] => Task 3, Epoch 19/34 => Loss 3.722, Loss_clf 0.850, Loss_fe 0.953, Loss_kd 1.482, Train_accy 39.93
2022-10-08 06:48:19,996 [foster.py] => Task 3, Epoch 20/34 => Loss 3.724, Loss_clf 0.850, Loss_fe 0.947, Loss_kd 1.489, Train_accy 38.32
2022-10-08 06:48:23,524 [foster.py] => Task 3, Epoch 21/34 => Loss 3.682, Loss_clf 0.833, Loss_fe 0.931, Loss_kd 1.482, Train_accy 40.37, Test_accy 44.64
2022-10-08 06:48:26,095 [foster.py] => Task 3, Epoch 22/34 => Loss 3.691, Loss_clf 0.839, Loss_fe 0.938, Loss_kd 1.479, Train_accy 37.88
2022-10-08 06:48:28,739 [foster.py] => Task 3, Epoch 23/34 => Loss 3.666, Loss_clf 0.823, Loss_fe 0.926, Loss_kd 1.481, Train_accy 39.63
2022-10-08 06:48:31,374 [foster.py] => Task 3, Epoch 24/34 => Loss 3.667, Loss_clf 0.820, Loss_fe 0.916, Loss_kd 1.492, Train_accy 40.95
2022-10-08 06:48:34,004 [foster.py] => Task 3, Epoch 25/34 => Loss 3.645, Loss_clf 0.808, Loss_fe 0.911, Loss_kd 1.488, Train_accy 40.29
2022-10-08 06:48:37,524 [foster.py] => Task 3, Epoch 26/34 => Loss 3.650, Loss_clf 0.811, Loss_fe 0.910, Loss_kd 1.491, Train_accy 40.00, Test_accy 44.64
2022-10-08 06:48:40,171 [foster.py] => Task 3, Epoch 27/34 => Loss 3.605, Loss_clf 0.797, Loss_fe 0.892, Loss_kd 1.481, Train_accy 39.85
2022-10-08 06:48:42,800 [foster.py] => Task 3, Epoch 28/34 => Loss 3.640, Loss_clf 0.811, Loss_fe 0.908, Loss_kd 1.485, Train_accy 40.37
2022-10-08 06:48:45,425 [foster.py] => Task 3, Epoch 29/34 => Loss 3.612, Loss_clf 0.797, Loss_fe 0.896, Loss_kd 1.483, Train_accy 40.66
2022-10-08 06:48:48,120 [foster.py] => Task 3, Epoch 30/34 => Loss 3.627, Loss_clf 0.804, Loss_fe 0.900, Loss_kd 1.486, Train_accy 41.10
2022-10-08 06:48:51,770 [foster.py] => Task 3, Epoch 31/34 => Loss 3.571, Loss_clf 0.784, Loss_fe 0.866, Loss_kd 1.484, Train_accy 41.61, Test_accy 44.44
2022-10-08 06:48:54,497 [foster.py] => Task 3, Epoch 32/34 => Loss 3.599, Loss_clf 0.793, Loss_fe 0.887, Loss_kd 1.483, Train_accy 41.39
2022-10-08 06:48:57,230 [foster.py] => Task 3, Epoch 33/34 => Loss 3.596, Loss_clf 0.793, Loss_fe 0.873, Loss_kd 1.492, Train_accy 41.76
2022-10-08 06:49:02,470 [foster.py] => Task 3, Epoch 34/34 => Loss 3.603, Loss_clf 0.787, Loss_fe 0.885, Loss_kd 1.493, Train_accy 42.42
2022-10-08 06:49:02,470 [foster.py] => do not weight align teacher!
2022-10-08 06:49:02,471 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 06:49:07,023 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.440,  Train_accy 11.79, Test_accy 30.95
2022-10-08 06:49:10,029 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.393,  Train_accy 12.82
2022-10-08 06:49:13,037 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.362,  Train_accy 13.11
2022-10-08 06:49:16,024 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.363,  Train_accy 13.63
2022-10-08 06:49:19,019 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.356,  Train_accy 13.26
2022-10-08 06:49:22,727 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.342,  Train_accy 13.99, Test_accy 33.33
2022-10-08 06:49:25,682 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.336,  Train_accy 13.77
2022-10-08 06:49:28,684 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.332,  Train_accy 13.41
2022-10-08 06:49:31,671 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.326,  Train_accy 12.82
2022-10-08 06:49:34,635 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.324,  Train_accy 13.33
2022-10-08 06:49:38,412 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.319,  Train_accy 13.92, Test_accy 34.33
2022-10-08 06:49:41,387 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.320,  Train_accy 13.99
2022-10-08 06:49:44,353 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.306,  Train_accy 13.26
2022-10-08 06:49:48,655 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.316,  Train_accy 14.07
2022-10-08 06:49:52,246 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.309,  Train_accy 13.70
2022-10-08 06:49:56,281 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.312,  Train_accy 13.55, Test_accy 34.92
2022-10-08 06:49:59,399 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.313,  Train_accy 14.07
2022-10-08 06:50:02,398 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.314,  Train_accy 13.63
2022-10-08 06:50:05,366 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.311,  Train_accy 14.29
2022-10-08 06:50:08,329 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.306,  Train_accy 13.33
2022-10-08 06:50:12,116 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.312,  Train_accy 14.14, Test_accy 34.72
2022-10-08 06:50:15,105 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.311,  Train_accy 14.14
2022-10-08 06:50:18,097 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.312,  Train_accy 13.99
2022-10-08 06:50:21,087 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.309,  Train_accy 13.99
2022-10-08 06:50:24,065 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.307,  Train_accy 14.36
2022-10-08 06:50:27,793 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.299,  Train_accy 13.92, Test_accy 34.13
2022-10-08 06:50:27,793 [foster.py] => do not weight align student!
2022-10-08 06:50:28,566 [foster.py] => darknet eval: 
2022-10-08 06:50:28,566 [foster.py] => CNN top1 curve: 34.13
2022-10-08 06:50:28,566 [foster.py] => CNN top5 curve: 80.36
2022-10-08 06:50:28,567 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 06:50:39,575 [foster.py] => Exemplar size: 440
2022-10-08 06:50:39,575 [trainer.py] => CNN: {'total': 44.64, 'old': 47.66, 'new': 35.0, 'base': 74.39, 'compound': 30.29}
2022-10-08 06:50:39,576 [trainer.py] => CNN top1 curve: [82.93, 61.8, 51.82, 44.64]
2022-10-08 06:50:39,576 [trainer.py] => CNN base curve: [82.93, 78.05, 78.05, 74.39]
2022-10-08 06:50:39,576 [trainer.py] => CNN old curve: [82.93, 78.05, 58.05, 47.66]
2022-10-08 06:50:39,576 [trainer.py] => CNN new curve: [0, 35.92, 37.61, 35.0]
2022-10-08 06:50:39,576 [trainer.py] => CNN compound curve: [0, 35.92, 32.27, 30.29]
2022-10-08 06:50:39,576 [trainer.py] => NME: {'total': 55.56, 'old': 57.03, 'new': 50.83, 'base': 69.51, 'compound': 48.82}
2022-10-08 06:50:39,576 [trainer.py] => NME top1 curve: [84.76, 69.66, 62.5, 55.56]
2022-10-08 06:50:39,576 [trainer.py] => NME base curve: [84.76, 74.39, 71.95, 69.51]
2022-10-08 06:50:39,576 [trainer.py] => NME old curve: [84.76, 74.39, 62.55, 57.03]
2022-10-08 06:50:39,576 [trainer.py] => NME new curve: [0, 62.14, 62.39, 50.83]
2022-10-08 06:50:39,576 [trainer.py] => NME compound curve: [0, 62.14, 55.45, 48.82]
2022-10-08 06:50:39,577 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 06:50:39,577 [trainer.py] => prefix: cil
2022-10-08 06:50:39,577 [trainer.py] => dataset: CFEE
2022-10-08 06:50:39,577 [trainer.py] => memory_size: 2000
2022-10-08 06:50:39,577 [trainer.py] => memory_per_class: 20
2022-10-08 06:50:39,577 [trainer.py] => fixed_memory: True
2022-10-08 06:50:39,577 [trainer.py] => shuffle: True
2022-10-08 06:50:39,577 [trainer.py] => init_cls: 7
2022-10-08 06:50:39,577 [trainer.py] => increment: 5
2022-10-08 06:50:39,577 [trainer.py] => model_name: foster
2022-10-08 06:50:39,577 [trainer.py] => convnet_type: resnet18
2022-10-08 06:50:39,578 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 06:50:39,578 [trainer.py] => seed: 1993
2022-10-08 06:50:39,578 [trainer.py] => beta1: 0.96
2022-10-08 06:50:39,578 [trainer.py] => beta2: 0.97
2022-10-08 06:50:39,578 [trainer.py] => oofc: ft
2022-10-08 06:50:39,578 [trainer.py] => is_teacher_wa: False
2022-10-08 06:50:39,578 [trainer.py] => is_student_wa: False
2022-10-08 06:50:39,578 [trainer.py] => lambda_okd: 1
2022-10-08 06:50:39,578 [trainer.py] => wa_value: 1
2022-10-08 06:50:39,578 [trainer.py] => init_epochs: 40
2022-10-08 06:50:39,578 [trainer.py] => init_lr: 0.01
2022-10-08 06:50:39,578 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 06:50:39,578 [trainer.py] => boosting_epochs: 34
2022-10-08 06:50:39,578 [trainer.py] => compression_epochs: 26
2022-10-08 06:50:39,578 [trainer.py] => lr: 0.001
2022-10-08 06:50:39,578 [trainer.py] => batch_size: 32
2022-10-08 06:50:39,578 [trainer.py] => weight_decay: 0.0005
2022-10-08 06:50:39,578 [trainer.py] => num_workers: 8
2022-10-08 06:50:39,578 [trainer.py] => T: 2
2022-10-08 06:50:39,578 [trainer.py] => nb_runs: 3
2022-10-08 06:50:39,578 [trainer.py] => fold: 10
2022-10-08 06:50:39,578 [data.py] => ========== Fold:0 ==========
2022-10-08 06:50:39,583 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 8, 15, 13, 17, 9, 11, 19, 21, 14, 10, 18, 12, 7, 16]
2022-10-08 06:50:39,794 [foster.py] => Learning on 0-7
2022-10-08 06:50:39,794 [foster.py] => All params: 11183694
2022-10-08 06:50:39,794 [foster.py] => Trainable params: 11183694
2022-10-08 06:50:42,029 [foster.py] => Task 0, Epoch 1/40 => Loss 1.317, Train_accy 50.84
2022-10-08 06:50:44,827 [foster.py] => Task 0, Epoch 2/40 => Loss 0.530, Train_accy 81.19, Test_accy 85.31
2022-10-08 06:50:47,656 [foster.py] => Task 0, Epoch 3/40 => Loss 0.371, Train_accy 87.62, Test_accy 85.88
2022-10-08 06:50:50,479 [foster.py] => Task 0, Epoch 4/40 => Loss 0.275, Train_accy 89.58, Test_accy 83.05
2022-10-08 06:50:53,262 [foster.py] => Task 0, Epoch 5/40 => Loss 0.239, Train_accy 91.68, Test_accy 88.70
2022-10-08 06:50:55,499 [foster.py] => Task 0, Epoch 6/40 => Loss 0.197, Train_accy 92.31
2022-10-08 06:50:58,266 [foster.py] => Task 0, Epoch 7/40 => Loss 0.167, Train_accy 94.55, Test_accy 85.88
2022-10-08 06:51:01,077 [foster.py] => Task 0, Epoch 8/40 => Loss 0.130, Train_accy 95.94, Test_accy 86.44
2022-10-08 06:51:03,958 [foster.py] => Task 0, Epoch 9/40 => Loss 0.129, Train_accy 96.01, Test_accy 86.44
2022-10-08 06:51:06,783 [foster.py] => Task 0, Epoch 10/40 => Loss 0.088, Train_accy 97.76, Test_accy 88.14
2022-10-08 06:51:09,031 [foster.py] => Task 0, Epoch 11/40 => Loss 0.101, Train_accy 96.99
2022-10-08 06:51:11,826 [foster.py] => Task 0, Epoch 12/40 => Loss 0.074, Train_accy 97.76, Test_accy 87.01
2022-10-08 06:51:14,653 [foster.py] => Task 0, Epoch 13/40 => Loss 0.057, Train_accy 98.46, Test_accy 88.14
2022-10-08 06:51:17,475 [foster.py] => Task 0, Epoch 14/40 => Loss 0.047, Train_accy 98.88, Test_accy 90.96
2022-10-08 06:51:20,245 [foster.py] => Task 0, Epoch 15/40 => Loss 0.055, Train_accy 98.39, Test_accy 87.01
2022-10-08 06:51:22,503 [foster.py] => Task 0, Epoch 16/40 => Loss 0.036, Train_accy 99.23
2022-10-08 06:51:25,263 [foster.py] => Task 0, Epoch 17/40 => Loss 0.035, Train_accy 99.02, Test_accy 88.70
2022-10-08 06:51:28,042 [foster.py] => Task 0, Epoch 18/40 => Loss 0.038, Train_accy 98.74, Test_accy 90.40
2022-10-08 06:51:30,864 [foster.py] => Task 0, Epoch 19/40 => Loss 0.033, Train_accy 99.23, Test_accy 90.96
2022-10-08 06:51:33,718 [foster.py] => Task 0, Epoch 20/40 => Loss 0.029, Train_accy 99.30, Test_accy 90.40
2022-10-08 06:51:35,994 [foster.py] => Task 0, Epoch 21/40 => Loss 0.024, Train_accy 99.72
2022-10-08 06:51:38,800 [foster.py] => Task 0, Epoch 22/40 => Loss 0.025, Train_accy 99.58, Test_accy 89.83
2022-10-08 06:51:41,639 [foster.py] => Task 0, Epoch 23/40 => Loss 0.023, Train_accy 99.44, Test_accy 89.27
2022-10-08 06:51:44,478 [foster.py] => Task 0, Epoch 24/40 => Loss 0.019, Train_accy 99.79, Test_accy 89.27
2022-10-08 06:51:47,305 [foster.py] => Task 0, Epoch 25/40 => Loss 0.021, Train_accy 99.65, Test_accy 90.40
2022-10-08 06:51:49,567 [foster.py] => Task 0, Epoch 26/40 => Loss 0.024, Train_accy 99.58
2022-10-08 06:51:52,435 [foster.py] => Task 0, Epoch 27/40 => Loss 0.016, Train_accy 99.79, Test_accy 89.83
2022-10-08 06:51:55,287 [foster.py] => Task 0, Epoch 28/40 => Loss 0.015, Train_accy 99.72, Test_accy 89.83
2022-10-08 06:51:58,071 [foster.py] => Task 0, Epoch 29/40 => Loss 0.018, Train_accy 99.65, Test_accy 89.83
2022-10-08 06:52:00,942 [foster.py] => Task 0, Epoch 30/40 => Loss 0.012, Train_accy 99.93, Test_accy 90.40
2022-10-08 06:52:03,200 [foster.py] => Task 0, Epoch 31/40 => Loss 0.014, Train_accy 99.79
2022-10-08 06:52:06,016 [foster.py] => Task 0, Epoch 32/40 => Loss 0.014, Train_accy 99.86, Test_accy 89.83
2022-10-08 06:52:08,805 [foster.py] => Task 0, Epoch 33/40 => Loss 0.015, Train_accy 99.65, Test_accy 89.83
2022-10-08 06:52:11,622 [foster.py] => Task 0, Epoch 34/40 => Loss 0.013, Train_accy 99.93, Test_accy 90.40
2022-10-08 06:52:14,449 [foster.py] => Task 0, Epoch 35/40 => Loss 0.012, Train_accy 99.72, Test_accy 89.83
2022-10-08 06:52:16,693 [foster.py] => Task 0, Epoch 36/40 => Loss 0.015, Train_accy 99.93
2022-10-08 06:52:19,584 [foster.py] => Task 0, Epoch 37/40 => Loss 0.014, Train_accy 99.86, Test_accy 88.70
2022-10-08 06:52:22,399 [foster.py] => Task 0, Epoch 38/40 => Loss 0.015, Train_accy 99.79, Test_accy 89.83
2022-10-08 06:52:25,210 [foster.py] => Task 0, Epoch 39/40 => Loss 0.013, Train_accy 99.86, Test_accy 89.83
2022-10-08 06:52:27,989 [foster.py] => Task 0, Epoch 40/40 => Loss 0.013, Train_accy 100.00, Test_accy 89.27
2022-10-08 06:52:27,990 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 06:52:34,312 [foster.py] => Exemplar size: 140
2022-10-08 06:52:34,312 [trainer.py] => CNN: {'total': 89.27, 'old': 89.27, 'new': 0, 'base': 89.27, 'compound': 0}
2022-10-08 06:52:34,312 [trainer.py] => CNN top1 curve: [89.27]
2022-10-08 06:52:34,312 [trainer.py] => CNN base curve: [89.27]
2022-10-08 06:52:34,312 [trainer.py] => CNN old curve: [89.27]
2022-10-08 06:52:34,312 [trainer.py] => CNN new curve: [0]
2022-10-08 06:52:34,312 [trainer.py] => CNN compound curve: [0]
2022-10-08 06:52:34,312 [trainer.py] => NME: {'total': 90.96, 'old': 90.96, 'new': 0, 'base': 90.96, 'compound': 0}
2022-10-08 06:52:34,312 [trainer.py] => NME top1 curve: [90.96]
2022-10-08 06:52:34,312 [trainer.py] => NME base curve: [90.96]
2022-10-08 06:52:34,313 [trainer.py] => NME old curve: [90.96]
2022-10-08 06:52:34,313 [trainer.py] => NME new curve: [0]
2022-10-08 06:52:34,313 [trainer.py] => NME compound curve: [0]
2022-10-08 06:52:34,531 [foster.py] => Learning on 7-12
2022-10-08 06:52:34,532 [foster.py] => All params: 22375071
2022-10-08 06:52:34,532 [foster.py] => Trainable params: 11194968
2022-10-08 06:52:34,541 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 06:52:37,498 [foster.py] => Task 1, Epoch 1/34 => Loss 4.991, Loss_clf 2.172, Loss_fe 2.084, Loss_kd 0.429, Train_accy 39.91, Test_accy 72.15
2022-10-08 06:52:39,804 [foster.py] => Task 1, Epoch 2/34 => Loss 2.602, Loss_clf 0.662, Loss_fe 1.237, Loss_kd 0.411, Train_accy 66.18
2022-10-08 06:52:42,143 [foster.py] => Task 1, Epoch 3/34 => Loss 2.214, Loss_clf 0.532, Loss_fe 0.989, Loss_kd 0.404, Train_accy 53.39
2022-10-08 06:52:44,424 [foster.py] => Task 1, Epoch 4/34 => Loss 2.020, Loss_clf 0.474, Loss_fe 0.858, Loss_kd 0.401, Train_accy 53.91
2022-10-08 06:52:46,727 [foster.py] => Task 1, Epoch 5/34 => Loss 1.905, Loss_clf 0.449, Loss_fe 0.768, Loss_kd 0.401, Train_accy 54.94
2022-10-08 06:52:49,777 [foster.py] => Task 1, Epoch 6/34 => Loss 1.790, Loss_clf 0.416, Loss_fe 0.687, Loss_kd 0.401, Train_accy 53.73, Test_accy 69.13
2022-10-08 06:52:52,018 [foster.py] => Task 1, Epoch 7/34 => Loss 1.764, Loss_clf 0.416, Loss_fe 0.658, Loss_kd 0.403, Train_accy 57.00
2022-10-08 06:52:54,292 [foster.py] => Task 1, Epoch 8/34 => Loss 1.697, Loss_clf 0.399, Loss_fe 0.608, Loss_kd 0.402, Train_accy 57.25
2022-10-08 06:52:56,568 [foster.py] => Task 1, Epoch 9/34 => Loss 1.674, Loss_clf 0.393, Loss_fe 0.592, Loss_kd 0.402, Train_accy 56.65
2022-10-08 06:52:58,870 [foster.py] => Task 1, Epoch 10/34 => Loss 1.602, Loss_clf 0.366, Loss_fe 0.546, Loss_kd 0.403, Train_accy 57.94
2022-10-08 06:53:01,918 [foster.py] => Task 1, Epoch 11/34 => Loss 1.588, Loss_clf 0.372, Loss_fe 0.530, Loss_kd 0.400, Train_accy 57.00, Test_accy 69.80
2022-10-08 06:53:04,218 [foster.py] => Task 1, Epoch 12/34 => Loss 1.569, Loss_clf 0.363, Loss_fe 0.519, Loss_kd 0.401, Train_accy 57.25
2022-10-08 06:53:06,553 [foster.py] => Task 1, Epoch 13/34 => Loss 1.540, Loss_clf 0.355, Loss_fe 0.500, Loss_kd 0.400, Train_accy 56.14
2022-10-08 06:53:08,846 [foster.py] => Task 1, Epoch 14/34 => Loss 1.492, Loss_clf 0.342, Loss_fe 0.471, Loss_kd 0.396, Train_accy 58.97
2022-10-08 06:53:11,193 [foster.py] => Task 1, Epoch 15/34 => Loss 1.494, Loss_clf 0.343, Loss_fe 0.461, Loss_kd 0.403, Train_accy 59.06
2022-10-08 06:53:14,258 [foster.py] => Task 1, Epoch 16/34 => Loss 1.458, Loss_clf 0.329, Loss_fe 0.448, Loss_kd 0.397, Train_accy 57.68, Test_accy 69.80
2022-10-08 06:53:16,633 [foster.py] => Task 1, Epoch 17/34 => Loss 1.438, Loss_clf 0.315, Loss_fe 0.432, Loss_kd 0.403, Train_accy 60.26
2022-10-08 06:53:18,926 [foster.py] => Task 1, Epoch 18/34 => Loss 1.430, Loss_clf 0.315, Loss_fe 0.426, Loss_kd 0.402, Train_accy 61.63
2022-10-08 06:53:21,220 [foster.py] => Task 1, Epoch 19/34 => Loss 1.380, Loss_clf 0.301, Loss_fe 0.397, Loss_kd 0.398, Train_accy 61.37
2022-10-08 06:53:23,562 [foster.py] => Task 1, Epoch 20/34 => Loss 1.397, Loss_clf 0.298, Loss_fe 0.407, Loss_kd 0.403, Train_accy 62.40
2022-10-08 06:53:26,631 [foster.py] => Task 1, Epoch 21/34 => Loss 1.366, Loss_clf 0.286, Loss_fe 0.387, Loss_kd 0.405, Train_accy 62.75, Test_accy 69.80
2022-10-08 06:53:28,930 [foster.py] => Task 1, Epoch 22/34 => Loss 1.421, Loss_clf 0.314, Loss_fe 0.414, Loss_kd 0.404, Train_accy 61.20
2022-10-08 06:53:31,277 [foster.py] => Task 1, Epoch 23/34 => Loss 1.371, Loss_clf 0.290, Loss_fe 0.394, Loss_kd 0.401, Train_accy 61.03
2022-10-08 06:53:33,616 [foster.py] => Task 1, Epoch 24/34 => Loss 1.336, Loss_clf 0.280, Loss_fe 0.380, Loss_kd 0.394, Train_accy 60.60
2022-10-08 06:53:35,958 [foster.py] => Task 1, Epoch 25/34 => Loss 1.378, Loss_clf 0.300, Loss_fe 0.393, Loss_kd 0.400, Train_accy 60.94
2022-10-08 06:53:39,009 [foster.py] => Task 1, Epoch 26/34 => Loss 1.345, Loss_clf 0.287, Loss_fe 0.372, Loss_kd 0.400, Train_accy 60.09, Test_accy 70.81
2022-10-08 06:53:41,310 [foster.py] => Task 1, Epoch 27/34 => Loss 1.345, Loss_clf 0.279, Loss_fe 0.376, Loss_kd 0.403, Train_accy 59.91
2022-10-08 06:53:43,694 [foster.py] => Task 1, Epoch 28/34 => Loss 1.330, Loss_clf 0.280, Loss_fe 0.365, Loss_kd 0.399, Train_accy 61.03
2022-10-08 06:53:45,998 [foster.py] => Task 1, Epoch 29/34 => Loss 1.342, Loss_clf 0.283, Loss_fe 0.379, Loss_kd 0.397, Train_accy 60.60
2022-10-08 06:53:48,307 [foster.py] => Task 1, Epoch 30/34 => Loss 1.332, Loss_clf 0.277, Loss_fe 0.366, Loss_kd 0.402, Train_accy 60.69
2022-10-08 06:53:51,347 [foster.py] => Task 1, Epoch 31/34 => Loss 1.321, Loss_clf 0.274, Loss_fe 0.361, Loss_kd 0.400, Train_accy 61.20, Test_accy 70.13
2022-10-08 06:53:53,660 [foster.py] => Task 1, Epoch 32/34 => Loss 1.332, Loss_clf 0.281, Loss_fe 0.367, Loss_kd 0.399, Train_accy 61.80
2022-10-08 06:53:55,994 [foster.py] => Task 1, Epoch 33/34 => Loss 1.337, Loss_clf 0.277, Loss_fe 0.371, Loss_kd 0.402, Train_accy 61.46
2022-10-08 06:53:58,283 [foster.py] => Task 1, Epoch 34/34 => Loss 1.355, Loss_clf 0.286, Loss_fe 0.384, Loss_kd 0.399, Train_accy 61.03
2022-10-08 06:53:58,284 [foster.py] => do not weight align teacher!
2022-10-08 06:53:58,284 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 06:54:01,832 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.827,  Train_accy 11.93, Test_accy 52.68
2022-10-08 06:54:04,506 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.647,  Train_accy 12.10
2022-10-08 06:54:07,134 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.579,  Train_accy 13.39
2022-10-08 06:54:09,766 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.550,  Train_accy 14.68
2022-10-08 06:54:12,428 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.528,  Train_accy 16.65
2022-10-08 06:54:15,756 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.495,  Train_accy 18.20, Test_accy 55.70
2022-10-08 06:54:18,459 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.479,  Train_accy 19.91
2022-10-08 06:54:21,112 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.470,  Train_accy 22.06
2022-10-08 06:54:23,781 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.455,  Train_accy 21.97
2022-10-08 06:54:26,420 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.439,  Train_accy 24.46
2022-10-08 06:54:29,768 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.435,  Train_accy 25.24, Test_accy 56.71
2022-10-08 06:54:32,412 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.439,  Train_accy 25.92
2022-10-08 06:54:35,129 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.432,  Train_accy 26.61
2022-10-08 06:54:37,765 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.424,  Train_accy 26.27
2022-10-08 06:54:40,393 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.422,  Train_accy 28.76
2022-10-08 06:54:43,700 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.419,  Train_accy 27.12, Test_accy 59.40
2022-10-08 06:54:46,405 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.419,  Train_accy 28.07
2022-10-08 06:54:49,110 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.413,  Train_accy 27.47
2022-10-08 06:54:51,756 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.405,  Train_accy 27.98
2022-10-08 06:54:54,473 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.404,  Train_accy 29.27
2022-10-08 06:54:57,794 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.413,  Train_accy 28.50, Test_accy 60.07
2022-10-08 06:55:00,465 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.408,  Train_accy 27.55
2022-10-08 06:55:03,176 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.404,  Train_accy 26.95
2022-10-08 06:55:05,859 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.396,  Train_accy 28.07
2022-10-08 06:55:08,499 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.399,  Train_accy 28.33
2022-10-08 06:55:11,882 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.400,  Train_accy 28.07, Test_accy 60.40
2022-10-08 06:55:11,882 [foster.py] => do not weight align student!
2022-10-08 06:55:12,536 [foster.py] => darknet eval: 
2022-10-08 06:55:12,536 [foster.py] => CNN top1 curve: 60.4
2022-10-08 06:55:12,536 [foster.py] => CNN top5 curve: 98.99
2022-10-08 06:55:12,536 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 06:55:20,076 [foster.py] => Exemplar size: 240
2022-10-08 06:55:20,076 [trainer.py] => CNN: {'total': 70.81, 'old': 82.49, 'new': 53.72, 'base': 82.49, 'compound': 53.72}
2022-10-08 06:55:20,076 [trainer.py] => CNN top1 curve: [89.27, 70.81]
2022-10-08 06:55:20,077 [trainer.py] => CNN base curve: [89.27, 82.49]
2022-10-08 06:55:20,077 [trainer.py] => CNN old curve: [89.27, 82.49]
2022-10-08 06:55:20,077 [trainer.py] => CNN new curve: [0, 53.72]
2022-10-08 06:55:20,077 [trainer.py] => CNN compound curve: [0, 53.72]
2022-10-08 06:55:20,077 [trainer.py] => NME: {'total': 77.85, 'old': 80.79, 'new': 73.55, 'base': 80.79, 'compound': 73.55}
2022-10-08 06:55:20,077 [trainer.py] => NME top1 curve: [90.96, 77.85]
2022-10-08 06:55:20,077 [trainer.py] => NME base curve: [90.96, 80.79]
2022-10-08 06:55:20,077 [trainer.py] => NME old curve: [90.96, 80.79]
2022-10-08 06:55:20,077 [trainer.py] => NME new curve: [0, 73.55]
2022-10-08 06:55:20,077 [trainer.py] => NME compound curve: [0, 73.55]
2022-10-08 06:55:20,297 [foster.py] => Learning on 12-17
2022-10-08 06:55:20,297 [foster.py] => All params: 22385326
2022-10-08 06:55:20,298 [foster.py] => Trainable params: 11202658
2022-10-08 06:55:20,306 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 06:55:23,587 [foster.py] => Task 2, Epoch 1/34 => Loss 5.701, Loss_clf 2.016, Loss_fe 2.259, Loss_kd 1.007, Train_accy 35.32, Test_accy 49.51
2022-10-08 06:55:26,067 [foster.py] => Task 2, Epoch 2/34 => Loss 3.999, Loss_clf 1.051, Loss_fe 1.564, Loss_kd 0.977, Train_accy 36.41
2022-10-08 06:55:28,569 [foster.py] => Task 2, Epoch 3/34 => Loss 3.720, Loss_clf 0.943, Loss_fe 1.382, Loss_kd 0.985, Train_accy 35.24
2022-10-08 06:55:30,970 [foster.py] => Task 2, Epoch 4/34 => Loss 3.544, Loss_clf 0.893, Loss_fe 1.272, Loss_kd 0.973, Train_accy 36.65
2022-10-08 06:55:33,430 [foster.py] => Task 2, Epoch 5/34 => Loss 3.450, Loss_clf 0.873, Loss_fe 1.193, Loss_kd 0.977, Train_accy 38.21
2022-10-08 06:55:36,762 [foster.py] => Task 2, Epoch 6/34 => Loss 3.362, Loss_clf 0.845, Loss_fe 1.131, Loss_kd 0.978, Train_accy 38.53, Test_accy 55.15
2022-10-08 06:55:39,227 [foster.py] => Task 2, Epoch 7/34 => Loss 3.304, Loss_clf 0.842, Loss_fe 1.085, Loss_kd 0.971, Train_accy 38.45
2022-10-08 06:55:41,728 [foster.py] => Task 2, Epoch 8/34 => Loss 3.249, Loss_clf 0.822, Loss_fe 1.044, Loss_kd 0.976, Train_accy 40.17
2022-10-08 06:55:44,233 [foster.py] => Task 2, Epoch 9/34 => Loss 3.195, Loss_clf 0.804, Loss_fe 1.007, Loss_kd 0.977, Train_accy 39.23
2022-10-08 06:55:46,714 [foster.py] => Task 2, Epoch 10/34 => Loss 3.134, Loss_clf 0.783, Loss_fe 0.964, Loss_kd 0.979, Train_accy 39.23
2022-10-08 06:55:50,012 [foster.py] => Task 2, Epoch 11/34 => Loss 3.069, Loss_clf 0.771, Loss_fe 0.922, Loss_kd 0.972, Train_accy 39.78, Test_accy 55.15
2022-10-08 06:55:52,552 [foster.py] => Task 2, Epoch 12/34 => Loss 3.057, Loss_clf 0.756, Loss_fe 0.917, Loss_kd 0.977, Train_accy 39.62
2022-10-08 06:55:55,008 [foster.py] => Task 2, Epoch 13/34 => Loss 2.996, Loss_clf 0.731, Loss_fe 0.881, Loss_kd 0.977, Train_accy 41.50
2022-10-08 06:55:57,503 [foster.py] => Task 2, Epoch 14/34 => Loss 2.940, Loss_clf 0.710, Loss_fe 0.842, Loss_kd 0.980, Train_accy 40.25
2022-10-08 06:55:59,953 [foster.py] => Task 2, Epoch 15/34 => Loss 2.916, Loss_clf 0.706, Loss_fe 0.829, Loss_kd 0.974, Train_accy 43.23
2022-10-08 06:56:03,243 [foster.py] => Task 2, Epoch 16/34 => Loss 2.918, Loss_clf 0.706, Loss_fe 0.826, Loss_kd 0.979, Train_accy 40.80, Test_accy 57.11
2022-10-08 06:56:05,719 [foster.py] => Task 2, Epoch 17/34 => Loss 2.855, Loss_clf 0.675, Loss_fe 0.794, Loss_kd 0.978, Train_accy 43.46
2022-10-08 06:56:08,224 [foster.py] => Task 2, Epoch 18/34 => Loss 2.871, Loss_clf 0.691, Loss_fe 0.798, Loss_kd 0.975, Train_accy 41.58
2022-10-08 06:56:10,703 [foster.py] => Task 2, Epoch 19/34 => Loss 2.847, Loss_clf 0.677, Loss_fe 0.787, Loss_kd 0.976, Train_accy 43.38
2022-10-08 06:56:13,181 [foster.py] => Task 2, Epoch 20/34 => Loss 2.836, Loss_clf 0.674, Loss_fe 0.778, Loss_kd 0.977, Train_accy 40.33
2022-10-08 06:56:16,505 [foster.py] => Task 2, Epoch 21/34 => Loss 2.769, Loss_clf 0.636, Loss_fe 0.741, Loss_kd 0.983, Train_accy 44.32, Test_accy 57.84
2022-10-08 06:56:18,993 [foster.py] => Task 2, Epoch 22/34 => Loss 2.769, Loss_clf 0.638, Loss_fe 0.748, Loss_kd 0.976, Train_accy 43.62
2022-10-08 06:56:21,467 [foster.py] => Task 2, Epoch 23/34 => Loss 2.792, Loss_clf 0.654, Loss_fe 0.752, Loss_kd 0.979, Train_accy 44.95
2022-10-08 06:56:23,945 [foster.py] => Task 2, Epoch 24/34 => Loss 2.761, Loss_clf 0.642, Loss_fe 0.741, Loss_kd 0.973, Train_accy 44.09
2022-10-08 06:56:26,438 [foster.py] => Task 2, Epoch 25/34 => Loss 2.722, Loss_clf 0.618, Loss_fe 0.717, Loss_kd 0.979, Train_accy 44.48
2022-10-08 06:56:29,764 [foster.py] => Task 2, Epoch 26/34 => Loss 2.716, Loss_clf 0.622, Loss_fe 0.708, Loss_kd 0.978, Train_accy 44.87, Test_accy 57.60
2022-10-08 06:56:32,216 [foster.py] => Task 2, Epoch 27/34 => Loss 2.775, Loss_clf 0.649, Loss_fe 0.739, Loss_kd 0.980, Train_accy 44.48
2022-10-08 06:56:34,713 [foster.py] => Task 2, Epoch 28/34 => Loss 2.688, Loss_clf 0.604, Loss_fe 0.696, Loss_kd 0.980, Train_accy 44.71
2022-10-08 06:56:37,216 [foster.py] => Task 2, Epoch 29/34 => Loss 2.709, Loss_clf 0.616, Loss_fe 0.710, Loss_kd 0.976, Train_accy 44.40
2022-10-08 06:56:39,680 [foster.py] => Task 2, Epoch 30/34 => Loss 2.716, Loss_clf 0.624, Loss_fe 0.712, Loss_kd 0.974, Train_accy 43.85
2022-10-08 06:56:42,960 [foster.py] => Task 2, Epoch 31/34 => Loss 2.679, Loss_clf 0.602, Loss_fe 0.697, Loss_kd 0.974, Train_accy 44.71, Test_accy 57.11
2022-10-08 06:56:45,411 [foster.py] => Task 2, Epoch 32/34 => Loss 2.685, Loss_clf 0.593, Loss_fe 0.695, Loss_kd 0.986, Train_accy 46.99
2022-10-08 06:56:47,845 [foster.py] => Task 2, Epoch 33/34 => Loss 2.677, Loss_clf 0.600, Loss_fe 0.687, Loss_kd 0.981, Train_accy 46.20
2022-10-08 06:56:50,310 [foster.py] => Task 2, Epoch 34/34 => Loss 2.697, Loss_clf 0.606, Loss_fe 0.703, Loss_kd 0.980, Train_accy 45.18
2022-10-08 06:56:50,310 [foster.py] => do not weight align teacher!
2022-10-08 06:56:50,310 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 06:56:54,262 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.077,  Train_accy 12.06, Test_accy 40.69
2022-10-08 06:56:58,545 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 2.005,  Train_accy 13.00
2022-10-08 06:57:01,856 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.981,  Train_accy 12.84
2022-10-08 06:57:04,997 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.963,  Train_accy 13.47
2022-10-08 06:57:08,128 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.947,  Train_accy 13.55
2022-10-08 06:57:11,782 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.945,  Train_accy 13.31, Test_accy 46.08
2022-10-08 06:57:14,605 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.945,  Train_accy 13.78
2022-10-08 06:57:17,412 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.941,  Train_accy 13.47
2022-10-08 06:57:20,210 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.929,  Train_accy 13.94
2022-10-08 06:57:23,039 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.924,  Train_accy 13.94
2022-10-08 06:57:26,562 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.924,  Train_accy 13.78, Test_accy 47.06
2022-10-08 06:57:29,375 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.927,  Train_accy 13.94
2022-10-08 06:57:32,195 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.919,  Train_accy 14.41
2022-10-08 06:57:34,980 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.908,  Train_accy 13.86
2022-10-08 06:57:37,814 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.918,  Train_accy 13.70
2022-10-08 06:57:41,326 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.907,  Train_accy 14.49, Test_accy 47.79
2022-10-08 06:57:44,150 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.904,  Train_accy 14.10
2022-10-08 06:57:46,974 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.902,  Train_accy 14.10
2022-10-08 06:57:49,846 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.904,  Train_accy 14.02
2022-10-08 06:57:52,693 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.900,  Train_accy 14.25
2022-10-08 06:57:56,267 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.909,  Train_accy 14.10, Test_accy 48.53
2022-10-08 06:57:59,098 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.911,  Train_accy 14.33
2022-10-08 06:58:01,965 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.905,  Train_accy 14.10
2022-10-08 06:58:04,828 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.898,  Train_accy 14.88
2022-10-08 06:58:07,711 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.906,  Train_accy 14.33
2022-10-08 06:58:11,264 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.910,  Train_accy 14.80, Test_accy 49.26
2022-10-08 06:58:11,265 [foster.py] => do not weight align student!
2022-10-08 06:58:11,976 [foster.py] => darknet eval: 
2022-10-08 06:58:11,976 [foster.py] => CNN top1 curve: 49.26
2022-10-08 06:58:11,976 [foster.py] => CNN top5 curve: 94.61
2022-10-08 06:58:11,976 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 06:58:21,316 [foster.py] => Exemplar size: 340
2022-10-08 06:58:21,316 [trainer.py] => CNN: {'total': 57.6, 'old': 65.77, 'new': 35.45, 'base': 80.23, 'compound': 40.26}
2022-10-08 06:58:21,316 [trainer.py] => CNN top1 curve: [89.27, 70.81, 57.6]
2022-10-08 06:58:21,316 [trainer.py] => CNN base curve: [89.27, 82.49, 80.23]
2022-10-08 06:58:21,316 [trainer.py] => CNN old curve: [89.27, 82.49, 65.77]
2022-10-08 06:58:21,316 [trainer.py] => CNN new curve: [0, 53.72, 35.45]
2022-10-08 06:58:21,316 [trainer.py] => CNN compound curve: [0, 53.72, 40.26]
2022-10-08 06:58:21,316 [trainer.py] => NME: {'total': 63.73, 'old': 68.12, 'new': 51.82, 'base': 71.75, 'compound': 57.58}
2022-10-08 06:58:21,316 [trainer.py] => NME top1 curve: [90.96, 77.85, 63.73]
2022-10-08 06:58:21,316 [trainer.py] => NME base curve: [90.96, 80.79, 71.75]
2022-10-08 06:58:21,316 [trainer.py] => NME old curve: [90.96, 80.79, 68.12]
2022-10-08 06:58:21,316 [trainer.py] => NME new curve: [0, 73.55, 51.82]
2022-10-08 06:58:21,316 [trainer.py] => NME compound curve: [0, 73.55, 57.58]
2022-10-08 06:58:21,534 [foster.py] => Learning on 17-22
2022-10-08 06:58:21,535 [foster.py] => All params: 22395581
2022-10-08 06:58:21,535 [foster.py] => Trainable params: 11210348
2022-10-08 06:58:21,544 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 06:58:25,027 [foster.py] => Task 3, Epoch 1/34 => Loss 6.630, Loss_clf 2.270, Loss_fe 2.491, Loss_kd 1.444, Train_accy 30.96, Test_accy 44.75
2022-10-08 06:58:27,621 [foster.py] => Task 3, Epoch 2/34 => Loss 4.750, Loss_clf 1.198, Loss_fe 1.728, Loss_kd 1.409, Train_accy 29.30
2022-10-08 06:58:30,311 [foster.py] => Task 3, Epoch 3/34 => Loss 4.474, Loss_clf 1.088, Loss_fe 1.548, Loss_kd 1.421, Train_accy 29.59
2022-10-08 06:58:32,964 [foster.py] => Task 3, Epoch 4/34 => Loss 4.317, Loss_clf 1.047, Loss_fe 1.440, Loss_kd 1.414, Train_accy 31.82
2022-10-08 06:58:35,576 [foster.py] => Task 3, Epoch 5/34 => Loss 4.205, Loss_clf 1.021, Loss_fe 1.356, Loss_kd 1.413, Train_accy 32.18
2022-10-08 06:58:39,101 [foster.py] => Task 3, Epoch 6/34 => Loss 4.125, Loss_clf 1.000, Loss_fe 1.301, Loss_kd 1.409, Train_accy 31.32, Test_accy 46.14
2022-10-08 06:58:41,719 [foster.py] => Task 3, Epoch 7/34 => Loss 4.047, Loss_clf 0.988, Loss_fe 1.231, Loss_kd 1.412, Train_accy 32.83
2022-10-08 06:58:44,374 [foster.py] => Task 3, Epoch 8/34 => Loss 3.994, Loss_clf 0.964, Loss_fe 1.196, Loss_kd 1.417, Train_accy 32.33
2022-10-08 06:58:46,987 [foster.py] => Task 3, Epoch 9/34 => Loss 3.910, Loss_clf 0.938, Loss_fe 1.154, Loss_kd 1.405, Train_accy 31.39
2022-10-08 06:58:49,655 [foster.py] => Task 3, Epoch 10/34 => Loss 3.893, Loss_clf 0.942, Loss_fe 1.126, Loss_kd 1.411, Train_accy 31.75
2022-10-08 06:58:53,252 [foster.py] => Task 3, Epoch 11/34 => Loss 3.842, Loss_clf 0.930, Loss_fe 1.096, Loss_kd 1.404, Train_accy 33.55, Test_accy 47.33
2022-10-08 06:58:55,894 [foster.py] => Task 3, Epoch 12/34 => Loss 3.775, Loss_clf 0.907, Loss_fe 1.056, Loss_kd 1.400, Train_accy 33.48
2022-10-08 06:58:58,542 [foster.py] => Task 3, Epoch 13/34 => Loss 3.752, Loss_clf 0.882, Loss_fe 1.042, Loss_kd 1.413, Train_accy 32.97
2022-10-08 06:59:01,188 [foster.py] => Task 3, Epoch 14/34 => Loss 3.716, Loss_clf 0.883, Loss_fe 1.014, Loss_kd 1.406, Train_accy 33.55
2022-10-08 06:59:03,853 [foster.py] => Task 3, Epoch 15/34 => Loss 3.701, Loss_clf 0.876, Loss_fe 1.001, Loss_kd 1.409, Train_accy 34.27
2022-10-08 06:59:07,428 [foster.py] => Task 3, Epoch 16/34 => Loss 3.640, Loss_clf 0.852, Loss_fe 0.964, Loss_kd 1.410, Train_accy 34.41, Test_accy 48.51
2022-10-08 06:59:10,073 [foster.py] => Task 3, Epoch 17/34 => Loss 3.658, Loss_clf 0.849, Loss_fe 0.972, Loss_kd 1.420, Train_accy 34.13
2022-10-08 06:59:12,718 [foster.py] => Task 3, Epoch 18/34 => Loss 3.598, Loss_clf 0.833, Loss_fe 0.951, Loss_kd 1.402, Train_accy 33.41
2022-10-08 06:59:15,412 [foster.py] => Task 3, Epoch 19/34 => Loss 3.602, Loss_clf 0.839, Loss_fe 0.939, Loss_kd 1.409, Train_accy 35.21
2022-10-08 06:59:18,035 [foster.py] => Task 3, Epoch 20/34 => Loss 3.586, Loss_clf 0.830, Loss_fe 0.932, Loss_kd 1.410, Train_accy 35.35
2022-10-08 06:59:21,628 [foster.py] => Task 3, Epoch 21/34 => Loss 3.573, Loss_clf 0.821, Loss_fe 0.924, Loss_kd 1.412, Train_accy 36.07, Test_accy 48.12
2022-10-08 06:59:24,277 [foster.py] => Task 3, Epoch 22/34 => Loss 3.540, Loss_clf 0.809, Loss_fe 0.907, Loss_kd 1.410, Train_accy 36.00
2022-10-08 06:59:26,957 [foster.py] => Task 3, Epoch 23/34 => Loss 3.539, Loss_clf 0.804, Loss_fe 0.911, Loss_kd 1.409, Train_accy 36.57
2022-10-08 06:59:29,674 [foster.py] => Task 3, Epoch 24/34 => Loss 3.523, Loss_clf 0.805, Loss_fe 0.899, Loss_kd 1.406, Train_accy 35.13
2022-10-08 06:59:32,330 [foster.py] => Task 3, Epoch 25/34 => Loss 3.498, Loss_clf 0.787, Loss_fe 0.890, Loss_kd 1.407, Train_accy 35.85
2022-10-08 06:59:35,899 [foster.py] => Task 3, Epoch 26/34 => Loss 3.480, Loss_clf 0.784, Loss_fe 0.873, Loss_kd 1.409, Train_accy 37.15, Test_accy 49.31
2022-10-08 06:59:38,555 [foster.py] => Task 3, Epoch 27/34 => Loss 3.512, Loss_clf 0.790, Loss_fe 0.896, Loss_kd 1.412, Train_accy 36.93
2022-10-08 06:59:41,259 [foster.py] => Task 3, Epoch 28/34 => Loss 3.486, Loss_clf 0.785, Loss_fe 0.883, Loss_kd 1.405, Train_accy 35.85
2022-10-08 06:59:43,950 [foster.py] => Task 3, Epoch 29/34 => Loss 3.486, Loss_clf 0.786, Loss_fe 0.876, Loss_kd 1.409, Train_accy 36.21
2022-10-08 06:59:46,619 [foster.py] => Task 3, Epoch 30/34 => Loss 3.496, Loss_clf 0.775, Loss_fe 0.887, Loss_kd 1.417, Train_accy 36.93
2022-10-08 06:59:50,265 [foster.py] => Task 3, Epoch 31/34 => Loss 3.496, Loss_clf 0.787, Loss_fe 0.883, Loss_kd 1.411, Train_accy 36.43, Test_accy 49.50
2022-10-08 06:59:52,889 [foster.py] => Task 3, Epoch 32/34 => Loss 3.448, Loss_clf 0.766, Loss_fe 0.860, Loss_kd 1.408, Train_accy 35.64
2022-10-08 06:59:55,512 [foster.py] => Task 3, Epoch 33/34 => Loss 3.461, Loss_clf 0.776, Loss_fe 0.864, Loss_kd 1.407, Train_accy 36.79
2022-10-08 06:59:58,164 [foster.py] => Task 3, Epoch 34/34 => Loss 3.496, Loss_clf 0.780, Loss_fe 0.883, Loss_kd 1.416, Train_accy 35.21
2022-10-08 06:59:58,164 [foster.py] => do not weight align teacher!
2022-10-08 06:59:58,165 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 07:00:02,227 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.349,  Train_accy 12.74, Test_accy 39.41
2022-10-08 07:00:05,317 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.291,  Train_accy 12.89
2022-10-08 07:00:08,318 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.263,  Train_accy 13.61
2022-10-08 07:00:11,344 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.254,  Train_accy 13.39
2022-10-08 07:00:14,463 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.256,  Train_accy 13.61
2022-10-08 07:00:18,389 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.237,  Train_accy 13.10, Test_accy 42.38
2022-10-08 07:00:21,520 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.224,  Train_accy 13.53
2022-10-08 07:00:24,619 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.215,  Train_accy 14.18
2022-10-08 07:00:27,706 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.224,  Train_accy 14.04
2022-10-08 07:00:30,808 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.206,  Train_accy 13.89
2022-10-08 07:00:34,608 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.200,  Train_accy 14.47, Test_accy 42.97
2022-10-08 07:00:37,707 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.213,  Train_accy 14.54
2022-10-08 07:00:40,777 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.206,  Train_accy 15.05
2022-10-08 07:00:43,882 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.204,  Train_accy 15.12
2022-10-08 07:00:47,133 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.193,  Train_accy 15.05
2022-10-08 07:00:51,290 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.196,  Train_accy 15.26, Test_accy 42.97
2022-10-08 07:00:54,358 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.193,  Train_accy 14.90
2022-10-08 07:00:57,500 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.179,  Train_accy 15.91
2022-10-08 07:01:00,581 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.205,  Train_accy 14.47
2022-10-08 07:01:03,615 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.188,  Train_accy 15.33
2022-10-08 07:01:07,445 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.189,  Train_accy 15.33, Test_accy 42.77
2022-10-08 07:01:10,483 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.190,  Train_accy 15.77
2022-10-08 07:01:13,521 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.185,  Train_accy 15.12
2022-10-08 07:01:16,570 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.182,  Train_accy 14.69
2022-10-08 07:01:19,633 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.192,  Train_accy 14.83
2022-10-08 07:01:26,227 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.194,  Train_accy 14.54, Test_accy 43.17
2022-10-08 07:01:26,227 [foster.py] => do not weight align student!
2022-10-08 07:01:27,041 [foster.py] => darknet eval: 
2022-10-08 07:01:27,041 [foster.py] => CNN top1 curve: 43.17
2022-10-08 07:01:27,041 [foster.py] => CNN top5 curve: 87.13
2022-10-08 07:01:27,042 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 07:01:38,089 [foster.py] => Exemplar size: 440
2022-10-08 07:01:38,090 [trainer.py] => CNN: {'total': 49.11, 'old': 55.64, 'new': 21.65, 'base': 79.1, 'compound': 32.93}
2022-10-08 07:01:38,090 [trainer.py] => CNN top1 curve: [89.27, 70.81, 57.6, 49.11]
2022-10-08 07:01:38,090 [trainer.py] => CNN base curve: [89.27, 82.49, 80.23, 79.1]
2022-10-08 07:01:38,090 [trainer.py] => CNN old curve: [89.27, 82.49, 65.77, 55.64]
2022-10-08 07:01:38,090 [trainer.py] => CNN new curve: [0, 53.72, 35.45, 21.65]
2022-10-08 07:01:38,090 [trainer.py] => CNN compound curve: [0, 53.72, 40.26, 32.93]
2022-10-08 07:01:38,090 [trainer.py] => NME: {'total': 58.61, 'old': 62.01, 'new': 44.33, 'base': 71.75, 'compound': 51.52}
2022-10-08 07:01:38,090 [trainer.py] => NME top1 curve: [90.96, 77.85, 63.73, 58.61]
2022-10-08 07:01:38,090 [trainer.py] => NME base curve: [90.96, 80.79, 71.75, 71.75]
2022-10-08 07:01:38,090 [trainer.py] => NME old curve: [90.96, 80.79, 68.12, 62.01]
2022-10-08 07:01:38,090 [trainer.py] => NME new curve: [0, 73.55, 51.82, 44.33]
2022-10-08 07:01:38,090 [trainer.py] => NME compound curve: [0, 73.55, 57.58, 51.52]
2022-10-08 07:01:38,091 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 07:01:38,091 [trainer.py] => prefix: cil
2022-10-08 07:01:38,091 [trainer.py] => dataset: CFEE
2022-10-08 07:01:38,091 [trainer.py] => memory_size: 2000
2022-10-08 07:01:38,091 [trainer.py] => memory_per_class: 20
2022-10-08 07:01:38,091 [trainer.py] => fixed_memory: True
2022-10-08 07:01:38,091 [trainer.py] => shuffle: True
2022-10-08 07:01:38,091 [trainer.py] => init_cls: 7
2022-10-08 07:01:38,091 [trainer.py] => increment: 5
2022-10-08 07:01:38,092 [trainer.py] => model_name: foster
2022-10-08 07:01:38,092 [trainer.py] => convnet_type: resnet18
2022-10-08 07:01:38,092 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 07:01:38,092 [trainer.py] => seed: 1993
2022-10-08 07:01:38,092 [trainer.py] => beta1: 0.96
2022-10-08 07:01:38,092 [trainer.py] => beta2: 0.97
2022-10-08 07:01:38,092 [trainer.py] => oofc: ft
2022-10-08 07:01:38,092 [trainer.py] => is_teacher_wa: False
2022-10-08 07:01:38,092 [trainer.py] => is_student_wa: False
2022-10-08 07:01:38,092 [trainer.py] => lambda_okd: 1
2022-10-08 07:01:38,092 [trainer.py] => wa_value: 1
2022-10-08 07:01:38,092 [trainer.py] => init_epochs: 40
2022-10-08 07:01:38,092 [trainer.py] => init_lr: 0.01
2022-10-08 07:01:38,092 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 07:01:38,092 [trainer.py] => boosting_epochs: 34
2022-10-08 07:01:38,092 [trainer.py] => compression_epochs: 26
2022-10-08 07:01:38,092 [trainer.py] => lr: 0.001
2022-10-08 07:01:38,092 [trainer.py] => batch_size: 32
2022-10-08 07:01:38,092 [trainer.py] => weight_decay: 0.0005
2022-10-08 07:01:38,092 [trainer.py] => num_workers: 8
2022-10-08 07:01:38,092 [trainer.py] => T: 2
2022-10-08 07:01:38,092 [trainer.py] => nb_runs: 3
2022-10-08 07:01:38,092 [trainer.py] => fold: 10
2022-10-08 07:01:38,092 [data.py] => ========== Fold:1 ==========
2022-10-08 07:01:38,097 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 8, 15, 13, 17, 9, 11, 19, 21, 14, 10, 18, 12, 7, 16]
2022-10-08 07:01:38,308 [foster.py] => Learning on 0-7
2022-10-08 07:01:38,308 [foster.py] => All params: 11183694
2022-10-08 07:01:38,309 [foster.py] => Trainable params: 11183694
2022-10-08 07:01:40,549 [foster.py] => Task 0, Epoch 1/40 => Loss 1.417, Train_accy 44.89
2022-10-08 07:01:43,331 [foster.py] => Task 0, Epoch 2/40 => Loss 0.553, Train_accy 81.22, Test_accy 82.43
2022-10-08 07:01:46,107 [foster.py] => Task 0, Epoch 3/40 => Loss 0.351, Train_accy 87.80, Test_accy 88.51
2022-10-08 07:01:48,935 [foster.py] => Task 0, Epoch 4/40 => Loss 0.292, Train_accy 89.65, Test_accy 87.84
2022-10-08 07:01:51,725 [foster.py] => Task 0, Epoch 5/40 => Loss 0.225, Train_accy 92.12, Test_accy 86.49
2022-10-08 07:01:53,996 [foster.py] => Task 0, Epoch 6/40 => Loss 0.216, Train_accy 92.46
2022-10-08 07:01:56,762 [foster.py] => Task 0, Epoch 7/40 => Loss 0.186, Train_accy 93.49, Test_accy 88.51
2022-10-08 07:01:59,567 [foster.py] => Task 0, Epoch 8/40 => Loss 0.124, Train_accy 96.37, Test_accy 85.14
2022-10-08 07:02:02,392 [foster.py] => Task 0, Epoch 9/40 => Loss 0.114, Train_accy 96.85, Test_accy 90.54
2022-10-08 07:02:05,150 [foster.py] => Task 0, Epoch 10/40 => Loss 0.098, Train_accy 96.85, Test_accy 89.19
2022-10-08 07:02:07,397 [foster.py] => Task 0, Epoch 11/40 => Loss 0.086, Train_accy 97.67
2022-10-08 07:02:10,169 [foster.py] => Task 0, Epoch 12/40 => Loss 0.073, Train_accy 97.81, Test_accy 89.86
2022-10-08 07:02:12,982 [foster.py] => Task 0, Epoch 13/40 => Loss 0.069, Train_accy 98.08, Test_accy 87.16
2022-10-08 07:02:15,825 [foster.py] => Task 0, Epoch 14/40 => Loss 0.051, Train_accy 98.42, Test_accy 89.19
2022-10-08 07:02:18,740 [foster.py] => Task 0, Epoch 15/40 => Loss 0.058, Train_accy 98.36, Test_accy 88.51
2022-10-08 07:02:20,975 [foster.py] => Task 0, Epoch 16/40 => Loss 0.042, Train_accy 99.25
2022-10-08 07:02:23,750 [foster.py] => Task 0, Epoch 17/40 => Loss 0.039, Train_accy 99.18, Test_accy 88.51
2022-10-08 07:02:26,572 [foster.py] => Task 0, Epoch 18/40 => Loss 0.036, Train_accy 99.11, Test_accy 87.84
2022-10-08 07:02:29,398 [foster.py] => Task 0, Epoch 19/40 => Loss 0.037, Train_accy 98.90, Test_accy 87.16
2022-10-08 07:02:32,249 [foster.py] => Task 0, Epoch 20/40 => Loss 0.033, Train_accy 98.97, Test_accy 87.16
2022-10-08 07:02:34,548 [foster.py] => Task 0, Epoch 21/40 => Loss 0.028, Train_accy 99.31
2022-10-08 07:02:37,366 [foster.py] => Task 0, Epoch 22/40 => Loss 0.021, Train_accy 99.79, Test_accy 87.84
2022-10-08 07:02:40,193 [foster.py] => Task 0, Epoch 23/40 => Loss 0.026, Train_accy 99.38, Test_accy 89.19
2022-10-08 07:02:43,042 [foster.py] => Task 0, Epoch 24/40 => Loss 0.018, Train_accy 99.79, Test_accy 88.51
2022-10-08 07:02:45,889 [foster.py] => Task 0, Epoch 25/40 => Loss 0.020, Train_accy 99.79, Test_accy 88.51
2022-10-08 07:02:48,133 [foster.py] => Task 0, Epoch 26/40 => Loss 0.023, Train_accy 99.45
2022-10-08 07:02:50,934 [foster.py] => Task 0, Epoch 27/40 => Loss 0.020, Train_accy 99.73, Test_accy 88.51
2022-10-08 07:02:53,748 [foster.py] => Task 0, Epoch 28/40 => Loss 0.018, Train_accy 99.73, Test_accy 90.54
2022-10-08 07:02:56,557 [foster.py] => Task 0, Epoch 29/40 => Loss 0.023, Train_accy 99.45, Test_accy 89.19
2022-10-08 07:02:59,417 [foster.py] => Task 0, Epoch 30/40 => Loss 0.016, Train_accy 99.66, Test_accy 88.51
2022-10-08 07:03:01,664 [foster.py] => Task 0, Epoch 31/40 => Loss 0.018, Train_accy 99.79
2022-10-08 07:03:04,490 [foster.py] => Task 0, Epoch 32/40 => Loss 0.014, Train_accy 99.79, Test_accy 88.51
2022-10-08 07:03:07,317 [foster.py] => Task 0, Epoch 33/40 => Loss 0.013, Train_accy 99.86, Test_accy 87.84
2022-10-08 07:03:10,176 [foster.py] => Task 0, Epoch 34/40 => Loss 0.013, Train_accy 99.93, Test_accy 87.84
2022-10-08 07:03:12,990 [foster.py] => Task 0, Epoch 35/40 => Loss 0.016, Train_accy 99.86, Test_accy 88.51
2022-10-08 07:03:15,283 [foster.py] => Task 0, Epoch 36/40 => Loss 0.015, Train_accy 99.86
2022-10-08 07:03:18,148 [foster.py] => Task 0, Epoch 37/40 => Loss 0.014, Train_accy 99.79, Test_accy 89.19
2022-10-08 07:03:21,041 [foster.py] => Task 0, Epoch 38/40 => Loss 0.012, Train_accy 99.93, Test_accy 88.51
2022-10-08 07:03:23,861 [foster.py] => Task 0, Epoch 39/40 => Loss 0.013, Train_accy 99.93, Test_accy 88.51
2022-10-08 07:03:26,718 [foster.py] => Task 0, Epoch 40/40 => Loss 0.017, Train_accy 99.73, Test_accy 89.19
2022-10-08 07:03:26,718 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 07:03:33,032 [foster.py] => Exemplar size: 140
2022-10-08 07:03:33,032 [trainer.py] => CNN: {'total': 89.19, 'old': 89.19, 'new': 0, 'base': 89.19, 'compound': 0}
2022-10-08 07:03:33,032 [trainer.py] => CNN top1 curve: [89.19]
2022-10-08 07:03:33,032 [trainer.py] => CNN base curve: [89.19]
2022-10-08 07:03:33,032 [trainer.py] => CNN old curve: [89.19]
2022-10-08 07:03:33,032 [trainer.py] => CNN new curve: [0]
2022-10-08 07:03:33,032 [trainer.py] => CNN compound curve: [0]
2022-10-08 07:03:33,032 [trainer.py] => NME: {'total': 89.19, 'old': 89.19, 'new': 0, 'base': 89.19, 'compound': 0}
2022-10-08 07:03:33,032 [trainer.py] => NME top1 curve: [89.19]
2022-10-08 07:03:33,032 [trainer.py] => NME base curve: [89.19]
2022-10-08 07:03:33,032 [trainer.py] => NME old curve: [89.19]
2022-10-08 07:03:33,032 [trainer.py] => NME new curve: [0]
2022-10-08 07:03:33,032 [trainer.py] => NME compound curve: [0]
2022-10-08 07:03:33,251 [foster.py] => Learning on 7-12
2022-10-08 07:03:33,251 [foster.py] => All params: 22375071
2022-10-08 07:03:33,252 [foster.py] => Trainable params: 11194968
2022-10-08 07:03:33,260 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 07:03:36,260 [foster.py] => Task 1, Epoch 1/34 => Loss 4.761, Loss_clf 2.091, Loss_fe 1.965, Loss_kd 0.411, Train_accy 37.86, Test_accy 65.15
2022-10-08 07:03:38,551 [foster.py] => Task 1, Epoch 2/34 => Loss 2.506, Loss_clf 0.670, Loss_fe 1.158, Loss_kd 0.395, Train_accy 65.81
2022-10-08 07:03:40,820 [foster.py] => Task 1, Epoch 3/34 => Loss 2.108, Loss_clf 0.528, Loss_fe 0.925, Loss_kd 0.383, Train_accy 52.31
2022-10-08 07:03:43,119 [foster.py] => Task 1, Epoch 4/34 => Loss 1.966, Loss_clf 0.475, Loss_fe 0.823, Loss_kd 0.390, Train_accy 52.91
2022-10-08 07:03:45,378 [foster.py] => Task 1, Epoch 5/34 => Loss 1.864, Loss_clf 0.458, Loss_fe 0.742, Loss_kd 0.387, Train_accy 53.76
2022-10-08 07:03:48,424 [foster.py] => Task 1, Epoch 6/34 => Loss 1.760, Loss_clf 0.420, Loss_fe 0.676, Loss_kd 0.387, Train_accy 53.08, Test_accy 65.15
2022-10-08 07:03:50,707 [foster.py] => Task 1, Epoch 7/34 => Loss 1.720, Loss_clf 0.413, Loss_fe 0.643, Loss_kd 0.387, Train_accy 54.02
2022-10-08 07:03:52,995 [foster.py] => Task 1, Epoch 8/34 => Loss 1.653, Loss_clf 0.401, Loss_fe 0.591, Loss_kd 0.386, Train_accy 57.01
2022-10-08 07:03:55,298 [foster.py] => Task 1, Epoch 9/34 => Loss 1.593, Loss_clf 0.380, Loss_fe 0.559, Loss_kd 0.381, Train_accy 54.27
2022-10-08 07:03:57,591 [foster.py] => Task 1, Epoch 10/34 => Loss 1.567, Loss_clf 0.370, Loss_fe 0.536, Loss_kd 0.386, Train_accy 57.78
2022-10-08 07:04:00,552 [foster.py] => Task 1, Epoch 11/34 => Loss 1.517, Loss_clf 0.354, Loss_fe 0.505, Loss_kd 0.384, Train_accy 56.75, Test_accy 65.15
2022-10-08 07:04:02,835 [foster.py] => Task 1, Epoch 12/34 => Loss 1.509, Loss_clf 0.341, Loss_fe 0.503, Loss_kd 0.389, Train_accy 58.89
2022-10-08 07:04:05,171 [foster.py] => Task 1, Epoch 13/34 => Loss 1.456, Loss_clf 0.333, Loss_fe 0.465, Loss_kd 0.383, Train_accy 57.01
2022-10-08 07:04:07,471 [foster.py] => Task 1, Epoch 14/34 => Loss 1.462, Loss_clf 0.336, Loss_fe 0.459, Loss_kd 0.390, Train_accy 59.23
2022-10-08 07:04:09,763 [foster.py] => Task 1, Epoch 15/34 => Loss 1.417, Loss_clf 0.321, Loss_fe 0.442, Loss_kd 0.382, Train_accy 57.44
2022-10-08 07:04:12,740 [foster.py] => Task 1, Epoch 16/34 => Loss 1.424, Loss_clf 0.330, Loss_fe 0.445, Loss_kd 0.379, Train_accy 57.69, Test_accy 65.53
2022-10-08 07:04:15,032 [foster.py] => Task 1, Epoch 17/34 => Loss 1.395, Loss_clf 0.311, Loss_fe 0.422, Loss_kd 0.386, Train_accy 59.74
2022-10-08 07:04:17,322 [foster.py] => Task 1, Epoch 18/34 => Loss 1.390, Loss_clf 0.302, Loss_fe 0.425, Loss_kd 0.386, Train_accy 60.85
2022-10-08 07:04:19,703 [foster.py] => Task 1, Epoch 19/34 => Loss 1.366, Loss_clf 0.302, Loss_fe 0.407, Loss_kd 0.384, Train_accy 58.80
2022-10-08 07:04:21,998 [foster.py] => Task 1, Epoch 20/34 => Loss 1.356, Loss_clf 0.295, Loss_fe 0.404, Loss_kd 0.383, Train_accy 59.49
2022-10-08 07:04:25,022 [foster.py] => Task 1, Epoch 21/34 => Loss 1.327, Loss_clf 0.282, Loss_fe 0.383, Loss_kd 0.386, Train_accy 58.80, Test_accy 65.15
2022-10-08 07:04:27,359 [foster.py] => Task 1, Epoch 22/34 => Loss 1.305, Loss_clf 0.273, Loss_fe 0.376, Loss_kd 0.382, Train_accy 60.17
2022-10-08 07:04:29,686 [foster.py] => Task 1, Epoch 23/34 => Loss 1.329, Loss_clf 0.283, Loss_fe 0.383, Loss_kd 0.387, Train_accy 59.49
2022-10-08 07:04:31,994 [foster.py] => Task 1, Epoch 24/34 => Loss 1.327, Loss_clf 0.277, Loss_fe 0.388, Loss_kd 0.386, Train_accy 58.89
2022-10-08 07:04:34,328 [foster.py] => Task 1, Epoch 25/34 => Loss 1.302, Loss_clf 0.275, Loss_fe 0.370, Loss_kd 0.383, Train_accy 60.00
2022-10-08 07:04:37,353 [foster.py] => Task 1, Epoch 26/34 => Loss 1.313, Loss_clf 0.278, Loss_fe 0.376, Loss_kd 0.384, Train_accy 60.09, Test_accy 65.53
2022-10-08 07:04:39,658 [foster.py] => Task 1, Epoch 27/34 => Loss 1.302, Loss_clf 0.272, Loss_fe 0.368, Loss_kd 0.386, Train_accy 59.91
2022-10-08 07:04:41,984 [foster.py] => Task 1, Epoch 28/34 => Loss 1.303, Loss_clf 0.274, Loss_fe 0.372, Loss_kd 0.383, Train_accy 59.66
2022-10-08 07:04:44,327 [foster.py] => Task 1, Epoch 29/34 => Loss 1.304, Loss_clf 0.275, Loss_fe 0.365, Loss_kd 0.387, Train_accy 60.51
2022-10-08 07:04:46,599 [foster.py] => Task 1, Epoch 30/34 => Loss 1.262, Loss_clf 0.258, Loss_fe 0.350, Loss_kd 0.381, Train_accy 59.15
2022-10-08 07:04:49,646 [foster.py] => Task 1, Epoch 31/34 => Loss 1.289, Loss_clf 0.266, Loss_fe 0.364, Loss_kd 0.384, Train_accy 60.00, Test_accy 67.05
2022-10-08 07:04:51,983 [foster.py] => Task 1, Epoch 32/34 => Loss 1.299, Loss_clf 0.276, Loss_fe 0.370, Loss_kd 0.381, Train_accy 59.74
2022-10-08 07:04:54,298 [foster.py] => Task 1, Epoch 33/34 => Loss 1.287, Loss_clf 0.266, Loss_fe 0.362, Loss_kd 0.384, Train_accy 59.83
2022-10-08 07:04:56,609 [foster.py] => Task 1, Epoch 34/34 => Loss 1.287, Loss_clf 0.264, Loss_fe 0.356, Loss_kd 0.389, Train_accy 59.91
2022-10-08 07:04:56,609 [foster.py] => do not weight align teacher!
2022-10-08 07:04:56,610 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 07:05:00,161 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.833,  Train_accy 11.45, Test_accy 47.35
2022-10-08 07:05:02,798 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.633,  Train_accy 12.22
2022-10-08 07:05:05,426 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.566,  Train_accy 12.91
2022-10-08 07:05:08,095 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.531,  Train_accy 14.02
2022-10-08 07:05:10,735 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.515,  Train_accy 15.30
2022-10-08 07:05:14,035 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.485,  Train_accy 17.18, Test_accy 52.65
2022-10-08 07:05:16,672 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.471,  Train_accy 18.89
2022-10-08 07:05:19,356 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.452,  Train_accy 19.49
2022-10-08 07:05:22,013 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.437,  Train_accy 20.09
2022-10-08 07:05:24,664 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.430,  Train_accy 20.60
2022-10-08 07:05:27,958 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.425,  Train_accy 22.31, Test_accy 55.68
2022-10-08 07:05:30,566 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.421,  Train_accy 23.08
2022-10-08 07:05:33,281 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.405,  Train_accy 24.44
2022-10-08 07:05:35,890 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.412,  Train_accy 25.04
2022-10-08 07:05:38,568 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.394,  Train_accy 24.87
2022-10-08 07:05:41,863 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.401,  Train_accy 25.73, Test_accy 56.06
2022-10-08 07:05:44,513 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.396,  Train_accy 27.52
2022-10-08 07:05:47,206 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.399,  Train_accy 24.02
2022-10-08 07:05:49,927 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.393,  Train_accy 26.07
2022-10-08 07:05:52,571 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.394,  Train_accy 26.58
2022-10-08 07:05:55,943 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.386,  Train_accy 27.09, Test_accy 56.44
2022-10-08 07:05:58,667 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.383,  Train_accy 25.47
2022-10-08 07:06:01,361 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.389,  Train_accy 27.26
2022-10-08 07:06:04,046 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.388,  Train_accy 26.75
2022-10-08 07:06:06,757 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.382,  Train_accy 27.26
2022-10-08 07:06:10,068 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.396,  Train_accy 26.84, Test_accy 56.44
2022-10-08 07:06:10,069 [foster.py] => do not weight align student!
2022-10-08 07:06:10,702 [foster.py] => darknet eval: 
2022-10-08 07:06:10,702 [foster.py] => CNN top1 curve: 56.44
2022-10-08 07:06:10,702 [foster.py] => CNN top5 curve: 97.73
2022-10-08 07:06:10,702 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 07:06:18,206 [foster.py] => Exemplar size: 240
2022-10-08 07:06:18,207 [trainer.py] => CNN: {'total': 65.53, 'old': 84.46, 'new': 41.38, 'base': 84.46, 'compound': 41.38}
2022-10-08 07:06:18,207 [trainer.py] => CNN top1 curve: [89.19, 65.53]
2022-10-08 07:06:18,207 [trainer.py] => CNN base curve: [89.19, 84.46]
2022-10-08 07:06:18,207 [trainer.py] => CNN old curve: [89.19, 84.46]
2022-10-08 07:06:18,207 [trainer.py] => CNN new curve: [0, 41.38]
2022-10-08 07:06:18,207 [trainer.py] => CNN compound curve: [0, 41.38]
2022-10-08 07:06:18,207 [trainer.py] => NME: {'total': 72.73, 'old': 80.41, 'new': 62.93, 'base': 80.41, 'compound': 62.93}
2022-10-08 07:06:18,207 [trainer.py] => NME top1 curve: [89.19, 72.73]
2022-10-08 07:06:18,207 [trainer.py] => NME base curve: [89.19, 80.41]
2022-10-08 07:06:18,207 [trainer.py] => NME old curve: [89.19, 80.41]
2022-10-08 07:06:18,207 [trainer.py] => NME new curve: [0, 62.93]
2022-10-08 07:06:18,207 [trainer.py] => NME compound curve: [0, 62.93]
2022-10-08 07:06:18,425 [foster.py] => Learning on 12-17
2022-10-08 07:06:18,426 [foster.py] => All params: 22385326
2022-10-08 07:06:18,426 [foster.py] => Trainable params: 11202658
2022-10-08 07:06:18,435 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 07:06:21,648 [foster.py] => Task 2, Epoch 1/34 => Loss 5.858, Loss_clf 2.129, Loss_fe 2.335, Loss_kd 0.984, Train_accy 33.52, Test_accy 40.26
2022-10-08 07:06:24,042 [foster.py] => Task 2, Epoch 2/34 => Loss 4.069, Loss_clf 1.093, Loss_fe 1.610, Loss_kd 0.964, Train_accy 36.35
2022-10-08 07:06:26,495 [foster.py] => Task 2, Epoch 3/34 => Loss 3.738, Loss_clf 0.969, Loss_fe 1.413, Loss_kd 0.957, Train_accy 35.41
2022-10-08 07:06:28,914 [foster.py] => Task 2, Epoch 4/34 => Loss 3.648, Loss_clf 0.955, Loss_fe 1.331, Loss_kd 0.962, Train_accy 35.80
2022-10-08 07:06:31,350 [foster.py] => Task 2, Epoch 5/34 => Loss 3.487, Loss_clf 0.898, Loss_fe 1.225, Loss_kd 0.963, Train_accy 37.06
2022-10-08 07:06:34,625 [foster.py] => Task 2, Epoch 6/34 => Loss 3.427, Loss_clf 0.889, Loss_fe 1.186, Loss_kd 0.954, Train_accy 35.01, Test_accy 47.89
2022-10-08 07:06:37,078 [foster.py] => Task 2, Epoch 7/34 => Loss 3.328, Loss_clf 0.856, Loss_fe 1.127, Loss_kd 0.949, Train_accy 37.06
2022-10-08 07:06:39,506 [foster.py] => Task 2, Epoch 8/34 => Loss 3.242, Loss_clf 0.824, Loss_fe 1.066, Loss_kd 0.954, Train_accy 36.27
2022-10-08 07:06:41,968 [foster.py] => Task 2, Epoch 9/34 => Loss 3.197, Loss_clf 0.810, Loss_fe 1.032, Loss_kd 0.956, Train_accy 37.84
2022-10-08 07:06:44,418 [foster.py] => Task 2, Epoch 10/34 => Loss 3.145, Loss_clf 0.795, Loss_fe 0.996, Loss_kd 0.956, Train_accy 38.95
2022-10-08 07:06:47,677 [foster.py] => Task 2, Epoch 11/34 => Loss 3.118, Loss_clf 0.797, Loss_fe 0.971, Loss_kd 0.952, Train_accy 37.14, Test_accy 49.74
2022-10-08 07:06:50,144 [foster.py] => Task 2, Epoch 12/34 => Loss 3.068, Loss_clf 0.776, Loss_fe 0.945, Loss_kd 0.950, Train_accy 39.34
2022-10-08 07:06:52,607 [foster.py] => Task 2, Epoch 13/34 => Loss 3.026, Loss_clf 0.748, Loss_fe 0.914, Loss_kd 0.962, Train_accy 37.69
2022-10-08 07:06:55,095 [foster.py] => Task 2, Epoch 14/34 => Loss 2.972, Loss_clf 0.738, Loss_fe 0.879, Loss_kd 0.957, Train_accy 39.18
2022-10-08 07:06:57,556 [foster.py] => Task 2, Epoch 15/34 => Loss 2.955, Loss_clf 0.727, Loss_fe 0.876, Loss_kd 0.955, Train_accy 39.18
2022-10-08 07:07:00,875 [foster.py] => Task 2, Epoch 16/34 => Loss 2.904, Loss_clf 0.705, Loss_fe 0.838, Loss_kd 0.960, Train_accy 40.68, Test_accy 49.21
2022-10-08 07:07:03,365 [foster.py] => Task 2, Epoch 17/34 => Loss 2.910, Loss_clf 0.709, Loss_fe 0.847, Loss_kd 0.956, Train_accy 39.89
2022-10-08 07:07:05,859 [foster.py] => Task 2, Epoch 18/34 => Loss 2.834, Loss_clf 0.674, Loss_fe 0.806, Loss_kd 0.956, Train_accy 41.07
2022-10-08 07:07:08,295 [foster.py] => Task 2, Epoch 19/34 => Loss 2.839, Loss_clf 0.677, Loss_fe 0.798, Loss_kd 0.962, Train_accy 40.44
2022-10-08 07:07:10,741 [foster.py] => Task 2, Epoch 20/34 => Loss 2.835, Loss_clf 0.681, Loss_fe 0.790, Loss_kd 0.962, Train_accy 40.20
2022-10-08 07:07:14,046 [foster.py] => Task 2, Epoch 21/34 => Loss 2.800, Loss_clf 0.673, Loss_fe 0.771, Loss_kd 0.957, Train_accy 41.15, Test_accy 49.21
2022-10-08 07:07:16,457 [foster.py] => Task 2, Epoch 22/34 => Loss 2.822, Loss_clf 0.677, Loss_fe 0.794, Loss_kd 0.954, Train_accy 40.36
2022-10-08 07:07:18,906 [foster.py] => Task 2, Epoch 23/34 => Loss 2.783, Loss_clf 0.661, Loss_fe 0.764, Loss_kd 0.958, Train_accy 42.33
2022-10-08 07:07:21,417 [foster.py] => Task 2, Epoch 24/34 => Loss 2.764, Loss_clf 0.645, Loss_fe 0.750, Loss_kd 0.966, Train_accy 42.88
2022-10-08 07:07:23,826 [foster.py] => Task 2, Epoch 25/34 => Loss 2.723, Loss_clf 0.629, Loss_fe 0.741, Loss_kd 0.955, Train_accy 42.09
2022-10-08 07:07:27,089 [foster.py] => Task 2, Epoch 26/34 => Loss 2.755, Loss_clf 0.645, Loss_fe 0.748, Loss_kd 0.961, Train_accy 43.12, Test_accy 49.21
2022-10-08 07:07:29,528 [foster.py] => Task 2, Epoch 27/34 => Loss 2.763, Loss_clf 0.647, Loss_fe 0.759, Loss_kd 0.958, Train_accy 42.09
2022-10-08 07:07:31,995 [foster.py] => Task 2, Epoch 28/34 => Loss 2.718, Loss_clf 0.625, Loss_fe 0.736, Loss_kd 0.958, Train_accy 43.90
2022-10-08 07:07:34,467 [foster.py] => Task 2, Epoch 29/34 => Loss 2.737, Loss_clf 0.637, Loss_fe 0.738, Loss_kd 0.961, Train_accy 42.80
2022-10-08 07:07:36,913 [foster.py] => Task 2, Epoch 30/34 => Loss 2.704, Loss_clf 0.621, Loss_fe 0.726, Loss_kd 0.958, Train_accy 44.06
2022-10-08 07:07:40,250 [foster.py] => Task 2, Epoch 31/34 => Loss 2.735, Loss_clf 0.639, Loss_fe 0.739, Loss_kd 0.958, Train_accy 42.01, Test_accy 49.21
2022-10-08 07:07:42,693 [foster.py] => Task 2, Epoch 32/34 => Loss 2.742, Loss_clf 0.639, Loss_fe 0.736, Loss_kd 0.965, Train_accy 42.64
2022-10-08 07:07:45,147 [foster.py] => Task 2, Epoch 33/34 => Loss 2.727, Loss_clf 0.634, Loss_fe 0.735, Loss_kd 0.959, Train_accy 43.04
2022-10-08 07:07:47,609 [foster.py] => Task 2, Epoch 34/34 => Loss 2.710, Loss_clf 0.626, Loss_fe 0.731, Loss_kd 0.955, Train_accy 42.80
2022-10-08 07:07:47,609 [foster.py] => do not weight align teacher!
2022-10-08 07:07:47,610 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 07:07:51,413 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.105,  Train_accy 11.80, Test_accy 37.63
2022-10-08 07:07:54,276 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 2.008,  Train_accy 12.75
2022-10-08 07:07:57,136 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.979,  Train_accy 12.67
2022-10-08 07:07:59,968 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.954,  Train_accy 13.06
2022-10-08 07:08:02,827 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.941,  Train_accy 12.98
2022-10-08 07:08:06,385 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.929,  Train_accy 13.14, Test_accy 40.79
2022-10-08 07:08:09,177 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.923,  Train_accy 13.06
2022-10-08 07:08:12,005 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.918,  Train_accy 13.06
2022-10-08 07:08:14,880 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.917,  Train_accy 13.38
2022-10-08 07:08:17,764 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.914,  Train_accy 13.14
2022-10-08 07:08:21,328 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.905,  Train_accy 13.14, Test_accy 40.53
2022-10-08 07:08:24,181 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.902,  Train_accy 13.53
2022-10-08 07:08:27,041 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.895,  Train_accy 13.14
2022-10-08 07:08:29,912 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.897,  Train_accy 13.30
2022-10-08 07:08:32,762 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.892,  Train_accy 13.38
2022-10-08 07:08:36,364 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.887,  Train_accy 13.69, Test_accy 41.05
2022-10-08 07:08:39,234 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.892,  Train_accy 13.53
2022-10-08 07:08:42,108 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.881,  Train_accy 13.38
2022-10-08 07:08:44,959 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.884,  Train_accy 13.93
2022-10-08 07:08:47,806 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.889,  Train_accy 13.22
2022-10-08 07:08:51,325 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.888,  Train_accy 13.69, Test_accy 41.58
2022-10-08 07:08:54,117 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.885,  Train_accy 13.77
2022-10-08 07:08:56,924 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.896,  Train_accy 13.22
2022-10-08 07:08:59,787 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.881,  Train_accy 13.61
2022-10-08 07:09:02,606 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.887,  Train_accy 13.85
2022-10-08 07:09:06,309 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.887,  Train_accy 13.61, Test_accy 41.05
2022-10-08 07:09:06,309 [foster.py] => do not weight align student!
2022-10-08 07:09:07,002 [foster.py] => darknet eval: 
2022-10-08 07:09:07,002 [foster.py] => CNN top1 curve: 41.05
2022-10-08 07:09:07,002 [foster.py] => CNN top5 curve: 92.89
2022-10-08 07:09:07,002 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 07:09:16,257 [foster.py] => Exemplar size: 340
2022-10-08 07:09:16,257 [trainer.py] => CNN: {'total': 49.21, 'old': 57.95, 'new': 29.31, 'base': 80.41, 'compound': 29.31}
2022-10-08 07:09:16,257 [trainer.py] => CNN top1 curve: [89.19, 65.53, 49.21]
2022-10-08 07:09:16,257 [trainer.py] => CNN base curve: [89.19, 84.46, 80.41]
2022-10-08 07:09:16,257 [trainer.py] => CNN old curve: [89.19, 84.46, 57.95]
2022-10-08 07:09:16,257 [trainer.py] => CNN new curve: [0, 41.38, 29.31]
2022-10-08 07:09:16,257 [trainer.py] => CNN compound curve: [0, 41.38, 29.31]
2022-10-08 07:09:16,257 [trainer.py] => NME: {'total': 56.84, 'old': 62.88, 'new': 43.1, 'base': 68.24, 'compound': 49.57}
2022-10-08 07:09:16,257 [trainer.py] => NME top1 curve: [89.19, 72.73, 56.84]
2022-10-08 07:09:16,257 [trainer.py] => NME base curve: [89.19, 80.41, 68.24]
2022-10-08 07:09:16,257 [trainer.py] => NME old curve: [89.19, 80.41, 62.88]
2022-10-08 07:09:16,257 [trainer.py] => NME new curve: [0, 62.93, 43.1]
2022-10-08 07:09:16,257 [trainer.py] => NME compound curve: [0, 62.93, 49.57]
2022-10-08 07:09:16,476 [foster.py] => Learning on 17-22
2022-10-08 07:09:16,476 [foster.py] => All params: 22395581
2022-10-08 07:09:16,476 [foster.py] => Trainable params: 11210348
2022-10-08 07:09:16,485 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 07:09:19,941 [foster.py] => Task 3, Epoch 1/34 => Loss 6.679, Loss_clf 2.207, Loss_fe 2.594, Loss_kd 1.451, Train_accy 30.42, Test_accy 36.63
2022-10-08 07:09:22,479 [foster.py] => Task 3, Epoch 2/34 => Loss 4.878, Loss_clf 1.234, Loss_fe 1.800, Loss_kd 1.425, Train_accy 28.88
2022-10-08 07:09:25,079 [foster.py] => Task 3, Epoch 3/34 => Loss 4.589, Loss_clf 1.131, Loss_fe 1.617, Loss_kd 1.422, Train_accy 28.80
2022-10-08 07:09:27,624 [foster.py] => Task 3, Epoch 4/34 => Loss 4.418, Loss_clf 1.092, Loss_fe 1.498, Loss_kd 1.413, Train_accy 28.73
2022-10-08 07:09:30,238 [foster.py] => Task 3, Epoch 5/34 => Loss 4.327, Loss_clf 1.073, Loss_fe 1.414, Loss_kd 1.421, Train_accy 29.10
2022-10-08 07:09:33,788 [foster.py] => Task 3, Epoch 6/34 => Loss 4.170, Loss_clf 1.011, Loss_fe 1.319, Loss_kd 1.422, Train_accy 29.46, Test_accy 38.81
2022-10-08 07:09:36,392 [foster.py] => Task 3, Epoch 7/34 => Loss 4.092, Loss_clf 0.990, Loss_fe 1.276, Loss_kd 1.411, Train_accy 29.02
2022-10-08 07:09:38,921 [foster.py] => Task 3, Epoch 8/34 => Loss 4.038, Loss_clf 0.976, Loss_fe 1.228, Loss_kd 1.417, Train_accy 31.01
2022-10-08 07:09:41,516 [foster.py] => Task 3, Epoch 9/34 => Loss 3.987, Loss_clf 0.960, Loss_fe 1.190, Loss_kd 1.419, Train_accy 31.01
2022-10-08 07:09:44,124 [foster.py] => Task 3, Epoch 10/34 => Loss 3.949, Loss_clf 0.954, Loss_fe 1.158, Loss_kd 1.420, Train_accy 31.37
2022-10-08 07:09:47,637 [foster.py] => Task 3, Epoch 11/34 => Loss 3.877, Loss_clf 0.924, Loss_fe 1.112, Loss_kd 1.423, Train_accy 31.96, Test_accy 39.41
2022-10-08 07:09:50,219 [foster.py] => Task 3, Epoch 12/34 => Loss 3.820, Loss_clf 0.921, Loss_fe 1.080, Loss_kd 1.405, Train_accy 31.08
2022-10-08 07:09:52,839 [foster.py] => Task 3, Epoch 13/34 => Loss 3.831, Loss_clf 0.918, Loss_fe 1.077, Loss_kd 1.419, Train_accy 32.48
2022-10-08 07:09:55,454 [foster.py] => Task 3, Epoch 14/34 => Loss 3.819, Loss_clf 0.919, Loss_fe 1.065, Loss_kd 1.418, Train_accy 33.28
2022-10-08 07:09:58,072 [foster.py] => Task 3, Epoch 15/34 => Loss 3.731, Loss_clf 0.878, Loss_fe 1.014, Loss_kd 1.421, Train_accy 33.21
2022-10-08 07:10:01,589 [foster.py] => Task 3, Epoch 16/34 => Loss 3.688, Loss_clf 0.866, Loss_fe 0.988, Loss_kd 1.417, Train_accy 32.26, Test_accy 41.19
2022-10-08 07:10:04,202 [foster.py] => Task 3, Epoch 17/34 => Loss 3.696, Loss_clf 0.873, Loss_fe 0.992, Loss_kd 1.415, Train_accy 32.40
2022-10-08 07:10:06,766 [foster.py] => Task 3, Epoch 18/34 => Loss 3.682, Loss_clf 0.868, Loss_fe 0.977, Loss_kd 1.419, Train_accy 33.21
2022-10-08 07:10:09,366 [foster.py] => Task 3, Epoch 19/34 => Loss 3.643, Loss_clf 0.839, Loss_fe 0.963, Loss_kd 1.422, Train_accy 33.28
2022-10-08 07:10:11,960 [foster.py] => Task 3, Epoch 20/34 => Loss 3.632, Loss_clf 0.841, Loss_fe 0.948, Loss_kd 1.424, Train_accy 33.95
2022-10-08 07:10:15,494 [foster.py] => Task 3, Epoch 21/34 => Loss 3.627, Loss_clf 0.842, Loss_fe 0.944, Loss_kd 1.422, Train_accy 33.06, Test_accy 40.79
2022-10-08 07:10:18,093 [foster.py] => Task 3, Epoch 22/34 => Loss 3.629, Loss_clf 0.839, Loss_fe 0.952, Loss_kd 1.420, Train_accy 34.68
2022-10-08 07:10:20,710 [foster.py] => Task 3, Epoch 23/34 => Loss 3.574, Loss_clf 0.813, Loss_fe 0.915, Loss_kd 1.426, Train_accy 35.27
2022-10-08 07:10:23,300 [foster.py] => Task 3, Epoch 24/34 => Loss 3.550, Loss_clf 0.812, Loss_fe 0.900, Loss_kd 1.420, Train_accy 35.78
2022-10-08 07:10:25,930 [foster.py] => Task 3, Epoch 25/34 => Loss 3.594, Loss_clf 0.825, Loss_fe 0.921, Loss_kd 1.428, Train_accy 33.87
2022-10-08 07:10:29,410 [foster.py] => Task 3, Epoch 26/34 => Loss 3.592, Loss_clf 0.831, Loss_fe 0.914, Loss_kd 1.427, Train_accy 35.49, Test_accy 41.39
2022-10-08 07:10:32,013 [foster.py] => Task 3, Epoch 27/34 => Loss 3.554, Loss_clf 0.813, Loss_fe 0.900, Loss_kd 1.422, Train_accy 34.53
2022-10-08 07:10:34,579 [foster.py] => Task 3, Epoch 28/34 => Loss 3.530, Loss_clf 0.803, Loss_fe 0.889, Loss_kd 1.420, Train_accy 35.42
2022-10-08 07:10:37,205 [foster.py] => Task 3, Epoch 29/34 => Loss 3.545, Loss_clf 0.804, Loss_fe 0.903, Loss_kd 1.421, Train_accy 34.68
2022-10-08 07:10:39,756 [foster.py] => Task 3, Epoch 30/34 => Loss 3.567, Loss_clf 0.810, Loss_fe 0.906, Loss_kd 1.430, Train_accy 34.53
2022-10-08 07:10:43,334 [foster.py] => Task 3, Epoch 31/34 => Loss 3.532, Loss_clf 0.799, Loss_fe 0.888, Loss_kd 1.425, Train_accy 34.53, Test_accy 41.58
2022-10-08 07:10:45,913 [foster.py] => Task 3, Epoch 32/34 => Loss 3.530, Loss_clf 0.796, Loss_fe 0.890, Loss_kd 1.424, Train_accy 34.68
2022-10-08 07:10:48,502 [foster.py] => Task 3, Epoch 33/34 => Loss 3.529, Loss_clf 0.800, Loss_fe 0.891, Loss_kd 1.421, Train_accy 35.49
2022-10-08 07:10:51,086 [foster.py] => Task 3, Epoch 34/34 => Loss 3.548, Loss_clf 0.799, Loss_fe 0.902, Loss_kd 1.427, Train_accy 34.61
2022-10-08 07:10:51,087 [foster.py] => do not weight align teacher!
2022-10-08 07:10:51,088 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 07:10:55,067 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.358,  Train_accy 12.71, Test_accy 32.08
2022-10-08 07:10:58,064 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.308,  Train_accy 12.78
2022-10-08 07:11:01,067 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.281,  Train_accy 12.64
2022-10-08 07:11:04,042 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.264,  Train_accy 13.23
2022-10-08 07:11:07,075 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.256,  Train_accy 12.86
2022-10-08 07:11:10,897 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.243,  Train_accy 12.86, Test_accy 31.88
2022-10-08 07:11:13,904 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.241,  Train_accy 13.67
2022-10-08 07:11:16,948 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.235,  Train_accy 13.23
2022-10-08 07:11:19,905 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.226,  Train_accy 13.59
2022-10-08 07:11:22,946 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.230,  Train_accy 13.37
2022-10-08 07:11:29,496 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.219,  Train_accy 13.52, Test_accy 32.08
2022-10-08 07:11:32,728 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.221,  Train_accy 13.01
2022-10-08 07:11:35,859 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.215,  Train_accy 13.81
2022-10-08 07:11:38,984 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.214,  Train_accy 13.59
2022-10-08 07:11:42,004 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.211,  Train_accy 13.52
2022-10-08 07:11:45,817 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.201,  Train_accy 13.23, Test_accy 32.48
2022-10-08 07:11:48,755 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.201,  Train_accy 14.03
2022-10-08 07:11:51,724 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.200,  Train_accy 13.23
2022-10-08 07:11:54,724 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.199,  Train_accy 13.96
2022-10-08 07:11:57,693 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.208,  Train_accy 14.18
2022-10-08 07:12:01,456 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.212,  Train_accy 13.81, Test_accy 32.28
2022-10-08 07:12:04,385 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.204,  Train_accy 13.67
2022-10-08 07:12:07,333 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.200,  Train_accy 14.18
2022-10-08 07:12:10,326 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.206,  Train_accy 14.11
2022-10-08 07:12:13,303 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.201,  Train_accy 14.33
2022-10-08 07:12:17,022 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.206,  Train_accy 14.11, Test_accy 32.87
2022-10-08 07:12:17,023 [foster.py] => do not weight align student!
2022-10-08 07:12:17,797 [foster.py] => darknet eval: 
2022-10-08 07:12:17,797 [foster.py] => CNN top1 curve: 32.87
2022-10-08 07:12:17,797 [foster.py] => CNN top5 curve: 82.18
2022-10-08 07:12:17,798 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 07:12:28,666 [foster.py] => Exemplar size: 440
2022-10-08 07:12:28,666 [trainer.py] => CNN: {'total': 41.19, 'old': 47.37, 'new': 22.4, 'base': 78.38, 'compound': 25.77}
2022-10-08 07:12:28,666 [trainer.py] => CNN top1 curve: [89.19, 65.53, 49.21, 41.19]
2022-10-08 07:12:28,666 [trainer.py] => CNN base curve: [89.19, 84.46, 80.41, 78.38]
2022-10-08 07:12:28,666 [trainer.py] => CNN old curve: [89.19, 84.46, 57.95, 47.37]
2022-10-08 07:12:28,666 [trainer.py] => CNN new curve: [0, 41.38, 29.31, 22.4]
2022-10-08 07:12:28,666 [trainer.py] => CNN compound curve: [0, 41.38, 29.31, 25.77]
2022-10-08 07:12:28,666 [trainer.py] => NME: {'total': 48.12, 'old': 50.53, 'new': 40.8, 'base': 60.81, 'compound': 42.86}
2022-10-08 07:12:28,666 [trainer.py] => NME top1 curve: [89.19, 72.73, 56.84, 48.12]
2022-10-08 07:12:28,666 [trainer.py] => NME base curve: [89.19, 80.41, 68.24, 60.81]
2022-10-08 07:12:28,666 [trainer.py] => NME old curve: [89.19, 80.41, 62.88, 50.53]
2022-10-08 07:12:28,666 [trainer.py] => NME new curve: [0, 62.93, 43.1, 40.8]
2022-10-08 07:12:28,666 [trainer.py] => NME compound curve: [0, 62.93, 49.57, 42.86]
2022-10-08 07:12:28,667 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 07:12:28,667 [trainer.py] => prefix: cil
2022-10-08 07:12:28,667 [trainer.py] => dataset: CFEE
2022-10-08 07:12:28,667 [trainer.py] => memory_size: 2000
2022-10-08 07:12:28,668 [trainer.py] => memory_per_class: 20
2022-10-08 07:12:28,668 [trainer.py] => fixed_memory: True
2022-10-08 07:12:28,668 [trainer.py] => shuffle: True
2022-10-08 07:12:28,668 [trainer.py] => init_cls: 7
2022-10-08 07:12:28,668 [trainer.py] => increment: 5
2022-10-08 07:12:28,668 [trainer.py] => model_name: foster
2022-10-08 07:12:28,668 [trainer.py] => convnet_type: resnet18
2022-10-08 07:12:28,668 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 07:12:28,668 [trainer.py] => seed: 1993
2022-10-08 07:12:28,668 [trainer.py] => beta1: 0.96
2022-10-08 07:12:28,668 [trainer.py] => beta2: 0.97
2022-10-08 07:12:28,668 [trainer.py] => oofc: ft
2022-10-08 07:12:28,668 [trainer.py] => is_teacher_wa: False
2022-10-08 07:12:28,668 [trainer.py] => is_student_wa: False
2022-10-08 07:12:28,668 [trainer.py] => lambda_okd: 1
2022-10-08 07:12:28,668 [trainer.py] => wa_value: 1
2022-10-08 07:12:28,668 [trainer.py] => init_epochs: 40
2022-10-08 07:12:28,668 [trainer.py] => init_lr: 0.01
2022-10-08 07:12:28,668 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 07:12:28,668 [trainer.py] => boosting_epochs: 34
2022-10-08 07:12:28,668 [trainer.py] => compression_epochs: 26
2022-10-08 07:12:28,668 [trainer.py] => lr: 0.001
2022-10-08 07:12:28,668 [trainer.py] => batch_size: 32
2022-10-08 07:12:28,668 [trainer.py] => weight_decay: 0.0005
2022-10-08 07:12:28,668 [trainer.py] => num_workers: 8
2022-10-08 07:12:28,668 [trainer.py] => T: 2
2022-10-08 07:12:28,668 [trainer.py] => nb_runs: 3
2022-10-08 07:12:28,668 [trainer.py] => fold: 10
2022-10-08 07:12:28,668 [data.py] => ========== Fold:2 ==========
2022-10-08 07:12:28,674 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 8, 15, 13, 17, 9, 11, 19, 21, 14, 10, 18, 12, 7, 16]
2022-10-08 07:12:28,884 [foster.py] => Learning on 0-7
2022-10-08 07:12:28,884 [foster.py] => All params: 11183694
2022-10-08 07:12:28,884 [foster.py] => Trainable params: 11183694
2022-10-08 07:12:31,160 [foster.py] => Task 0, Epoch 1/40 => Loss 1.314, Train_accy 52.93
2022-10-08 07:12:33,948 [foster.py] => Task 0, Epoch 2/40 => Loss 0.549, Train_accy 80.33, Test_accy 86.71
2022-10-08 07:12:36,699 [foster.py] => Task 0, Epoch 3/40 => Loss 0.362, Train_accy 87.23, Test_accy 81.65
2022-10-08 07:12:39,511 [foster.py] => Task 0, Epoch 4/40 => Loss 0.297, Train_accy 88.96, Test_accy 86.08
2022-10-08 07:12:42,299 [foster.py] => Task 0, Epoch 5/40 => Loss 0.235, Train_accy 92.41, Test_accy 85.44
2022-10-08 07:12:44,563 [foster.py] => Task 0, Epoch 6/40 => Loss 0.176, Train_accy 93.93
2022-10-08 07:12:47,437 [foster.py] => Task 0, Epoch 7/40 => Loss 0.188, Train_accy 93.65, Test_accy 87.97
2022-10-08 07:12:50,222 [foster.py] => Task 0, Epoch 8/40 => Loss 0.141, Train_accy 95.65, Test_accy 86.71
2022-10-08 07:12:53,014 [foster.py] => Task 0, Epoch 9/40 => Loss 0.124, Train_accy 95.72, Test_accy 85.44
2022-10-08 07:12:55,815 [foster.py] => Task 0, Epoch 10/40 => Loss 0.098, Train_accy 97.24, Test_accy 86.08
2022-10-08 07:12:58,099 [foster.py] => Task 0, Epoch 11/40 => Loss 0.083, Train_accy 97.38
2022-10-08 07:13:00,897 [foster.py] => Task 0, Epoch 12/40 => Loss 0.067, Train_accy 98.07, Test_accy 86.71
2022-10-08 07:13:03,727 [foster.py] => Task 0, Epoch 13/40 => Loss 0.068, Train_accy 98.21, Test_accy 86.08
2022-10-08 07:13:06,573 [foster.py] => Task 0, Epoch 14/40 => Loss 0.056, Train_accy 98.48, Test_accy 82.91
2022-10-08 07:13:09,397 [foster.py] => Task 0, Epoch 15/40 => Loss 0.057, Train_accy 98.62, Test_accy 87.34
2022-10-08 07:13:11,683 [foster.py] => Task 0, Epoch 16/40 => Loss 0.050, Train_accy 98.62
2022-10-08 07:13:14,538 [foster.py] => Task 0, Epoch 17/40 => Loss 0.040, Train_accy 99.03, Test_accy 86.71
2022-10-08 07:13:17,385 [foster.py] => Task 0, Epoch 18/40 => Loss 0.035, Train_accy 99.24, Test_accy 87.97
2022-10-08 07:13:20,239 [foster.py] => Task 0, Epoch 19/40 => Loss 0.028, Train_accy 99.31, Test_accy 86.08
2022-10-08 07:13:22,997 [foster.py] => Task 0, Epoch 20/40 => Loss 0.029, Train_accy 99.52, Test_accy 84.81
2022-10-08 07:13:25,226 [foster.py] => Task 0, Epoch 21/40 => Loss 0.030, Train_accy 99.10
2022-10-08 07:13:28,072 [foster.py] => Task 0, Epoch 22/40 => Loss 0.024, Train_accy 99.38, Test_accy 86.08
2022-10-08 07:13:30,886 [foster.py] => Task 0, Epoch 23/40 => Loss 0.023, Train_accy 99.52, Test_accy 87.97
2022-10-08 07:13:33,685 [foster.py] => Task 0, Epoch 24/40 => Loss 0.022, Train_accy 99.38, Test_accy 87.34
2022-10-08 07:13:36,479 [foster.py] => Task 0, Epoch 25/40 => Loss 0.020, Train_accy 99.52, Test_accy 86.08
2022-10-08 07:13:38,721 [foster.py] => Task 0, Epoch 26/40 => Loss 0.014, Train_accy 99.79
2022-10-08 07:13:41,533 [foster.py] => Task 0, Epoch 27/40 => Loss 0.015, Train_accy 99.79, Test_accy 87.97
2022-10-08 07:13:44,400 [foster.py] => Task 0, Epoch 28/40 => Loss 0.014, Train_accy 99.93, Test_accy 86.71
2022-10-08 07:13:47,232 [foster.py] => Task 0, Epoch 29/40 => Loss 0.016, Train_accy 99.86, Test_accy 87.34
2022-10-08 07:13:50,045 [foster.py] => Task 0, Epoch 30/40 => Loss 0.029, Train_accy 99.65, Test_accy 87.34
2022-10-08 07:13:52,306 [foster.py] => Task 0, Epoch 31/40 => Loss 0.017, Train_accy 99.59
2022-10-08 07:13:55,116 [foster.py] => Task 0, Epoch 32/40 => Loss 0.012, Train_accy 99.86, Test_accy 86.08
2022-10-08 07:13:57,974 [foster.py] => Task 0, Epoch 33/40 => Loss 0.019, Train_accy 99.59, Test_accy 86.08
2022-10-08 07:14:00,793 [foster.py] => Task 0, Epoch 34/40 => Loss 0.015, Train_accy 99.86, Test_accy 85.44
2022-10-08 07:14:03,635 [foster.py] => Task 0, Epoch 35/40 => Loss 0.014, Train_accy 99.86, Test_accy 86.71
2022-10-08 07:14:05,919 [foster.py] => Task 0, Epoch 36/40 => Loss 0.018, Train_accy 99.72
2022-10-08 07:14:08,759 [foster.py] => Task 0, Epoch 37/40 => Loss 0.018, Train_accy 99.86, Test_accy 87.97
2022-10-08 07:14:11,626 [foster.py] => Task 0, Epoch 38/40 => Loss 0.011, Train_accy 99.93, Test_accy 86.71
2022-10-08 07:14:14,466 [foster.py] => Task 0, Epoch 39/40 => Loss 0.022, Train_accy 99.59, Test_accy 86.71
2022-10-08 07:14:17,367 [foster.py] => Task 0, Epoch 40/40 => Loss 0.018, Train_accy 99.79, Test_accy 86.71
2022-10-08 07:14:17,368 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 07:14:23,634 [foster.py] => Exemplar size: 140
2022-10-08 07:14:23,634 [trainer.py] => CNN: {'total': 86.71, 'old': 86.71, 'new': 0, 'base': 86.71, 'compound': 0}
2022-10-08 07:14:23,634 [trainer.py] => CNN top1 curve: [86.71]
2022-10-08 07:14:23,634 [trainer.py] => CNN base curve: [86.71]
2022-10-08 07:14:23,634 [trainer.py] => CNN old curve: [86.71]
2022-10-08 07:14:23,635 [trainer.py] => CNN new curve: [0]
2022-10-08 07:14:23,635 [trainer.py] => CNN compound curve: [0]
2022-10-08 07:14:23,635 [trainer.py] => NME: {'total': 86.08, 'old': 86.08, 'new': 0, 'base': 86.08, 'compound': 0}
2022-10-08 07:14:23,635 [trainer.py] => NME top1 curve: [86.08]
2022-10-08 07:14:23,635 [trainer.py] => NME base curve: [86.08]
2022-10-08 07:14:23,635 [trainer.py] => NME old curve: [86.08]
2022-10-08 07:14:23,635 [trainer.py] => NME new curve: [0]
2022-10-08 07:14:23,635 [trainer.py] => NME compound curve: [0]
2022-10-08 07:14:23,855 [foster.py] => Learning on 7-12
2022-10-08 07:14:23,855 [foster.py] => All params: 22375071
2022-10-08 07:14:23,855 [foster.py] => Trainable params: 11194968
2022-10-08 07:14:23,864 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 07:14:26,896 [foster.py] => Task 1, Epoch 1/34 => Loss 4.716, Loss_clf 2.130, Loss_fe 1.863, Loss_kd 0.422, Train_accy 40.56, Test_accy 68.66
2022-10-08 07:14:29,152 [foster.py] => Task 1, Epoch 2/34 => Loss 2.541, Loss_clf 0.698, Loss_fe 1.171, Loss_kd 0.392, Train_accy 68.28
2022-10-08 07:14:31,454 [foster.py] => Task 1, Epoch 3/34 => Loss 2.168, Loss_clf 0.554, Loss_fe 0.957, Loss_kd 0.384, Train_accy 51.11
2022-10-08 07:14:33,762 [foster.py] => Task 1, Epoch 4/34 => Loss 1.979, Loss_clf 0.488, Loss_fe 0.832, Loss_kd 0.384, Train_accy 52.04
2022-10-08 07:14:36,067 [foster.py] => Task 1, Epoch 5/34 => Loss 1.878, Loss_clf 0.459, Loss_fe 0.752, Loss_kd 0.389, Train_accy 52.89
2022-10-08 07:14:39,067 [foster.py] => Task 1, Epoch 6/34 => Loss 1.822, Loss_clf 0.447, Loss_fe 0.713, Loss_kd 0.386, Train_accy 53.49, Test_accy 67.54
2022-10-08 07:14:41,379 [foster.py] => Task 1, Epoch 7/34 => Loss 1.745, Loss_clf 0.419, Loss_fe 0.659, Loss_kd 0.389, Train_accy 55.53
2022-10-08 07:14:43,655 [foster.py] => Task 1, Epoch 8/34 => Loss 1.692, Loss_clf 0.410, Loss_fe 0.627, Loss_kd 0.382, Train_accy 54.59
2022-10-08 07:14:46,014 [foster.py] => Task 1, Epoch 9/34 => Loss 1.710, Loss_clf 0.431, Loss_fe 0.621, Loss_kd 0.384, Train_accy 53.49
2022-10-08 07:14:48,327 [foster.py] => Task 1, Epoch 10/34 => Loss 1.637, Loss_clf 0.398, Loss_fe 0.581, Loss_kd 0.384, Train_accy 54.85
2022-10-08 07:14:51,359 [foster.py] => Task 1, Epoch 11/34 => Loss 1.563, Loss_clf 0.369, Loss_fe 0.541, Loss_kd 0.381, Train_accy 54.08, Test_accy 67.91
2022-10-08 07:14:53,666 [foster.py] => Task 1, Epoch 12/34 => Loss 1.540, Loss_clf 0.364, Loss_fe 0.519, Loss_kd 0.383, Train_accy 56.12
2022-10-08 07:14:56,017 [foster.py] => Task 1, Epoch 13/34 => Loss 1.514, Loss_clf 0.349, Loss_fe 0.505, Loss_kd 0.385, Train_accy 56.55
2022-10-08 07:14:58,319 [foster.py] => Task 1, Epoch 14/34 => Loss 1.505, Loss_clf 0.350, Loss_fe 0.495, Loss_kd 0.385, Train_accy 56.89
2022-10-08 07:15:00,655 [foster.py] => Task 1, Epoch 15/34 => Loss 1.457, Loss_clf 0.333, Loss_fe 0.466, Loss_kd 0.384, Train_accy 55.95
2022-10-08 07:15:03,708 [foster.py] => Task 1, Epoch 16/34 => Loss 1.469, Loss_clf 0.337, Loss_fe 0.473, Loss_kd 0.384, Train_accy 57.14, Test_accy 67.91
2022-10-08 07:15:06,006 [foster.py] => Task 1, Epoch 17/34 => Loss 1.432, Loss_clf 0.319, Loss_fe 0.451, Loss_kd 0.386, Train_accy 57.31
2022-10-08 07:15:08,306 [foster.py] => Task 1, Epoch 18/34 => Loss 1.419, Loss_clf 0.317, Loss_fe 0.439, Loss_kd 0.387, Train_accy 57.99
2022-10-08 07:15:10,624 [foster.py] => Task 1, Epoch 19/34 => Loss 1.393, Loss_clf 0.311, Loss_fe 0.427, Loss_kd 0.383, Train_accy 58.93
2022-10-08 07:15:12,985 [foster.py] => Task 1, Epoch 20/34 => Loss 1.381, Loss_clf 0.303, Loss_fe 0.426, Loss_kd 0.380, Train_accy 58.59
2022-10-08 07:15:16,001 [foster.py] => Task 1, Epoch 21/34 => Loss 1.388, Loss_clf 0.305, Loss_fe 0.428, Loss_kd 0.382, Train_accy 58.93, Test_accy 67.16
2022-10-08 07:15:18,279 [foster.py] => Task 1, Epoch 22/34 => Loss 1.387, Loss_clf 0.308, Loss_fe 0.417, Loss_kd 0.386, Train_accy 58.93
2022-10-08 07:15:20,578 [foster.py] => Task 1, Epoch 23/34 => Loss 1.384, Loss_clf 0.299, Loss_fe 0.421, Loss_kd 0.388, Train_accy 57.82
2022-10-08 07:15:22,883 [foster.py] => Task 1, Epoch 24/34 => Loss 1.347, Loss_clf 0.281, Loss_fe 0.402, Loss_kd 0.387, Train_accy 57.99
2022-10-08 07:15:25,178 [foster.py] => Task 1, Epoch 25/34 => Loss 1.353, Loss_clf 0.294, Loss_fe 0.400, Loss_kd 0.385, Train_accy 58.16
2022-10-08 07:15:28,162 [foster.py] => Task 1, Epoch 26/34 => Loss 1.360, Loss_clf 0.289, Loss_fe 0.406, Loss_kd 0.388, Train_accy 59.44, Test_accy 66.04
2022-10-08 07:15:30,463 [foster.py] => Task 1, Epoch 27/34 => Loss 1.357, Loss_clf 0.299, Loss_fe 0.402, Loss_kd 0.383, Train_accy 58.42
2022-10-08 07:15:32,741 [foster.py] => Task 1, Epoch 28/34 => Loss 1.307, Loss_clf 0.272, Loss_fe 0.379, Loss_kd 0.383, Train_accy 58.50
2022-10-08 07:15:35,077 [foster.py] => Task 1, Epoch 29/34 => Loss 1.307, Loss_clf 0.271, Loss_fe 0.373, Loss_kd 0.387, Train_accy 58.67
2022-10-08 07:15:37,411 [foster.py] => Task 1, Epoch 30/34 => Loss 1.331, Loss_clf 0.289, Loss_fe 0.387, Loss_kd 0.382, Train_accy 57.74
2022-10-08 07:15:40,430 [foster.py] => Task 1, Epoch 31/34 => Loss 1.320, Loss_clf 0.277, Loss_fe 0.379, Loss_kd 0.387, Train_accy 59.78, Test_accy 66.42
2022-10-08 07:15:42,750 [foster.py] => Task 1, Epoch 32/34 => Loss 1.340, Loss_clf 0.284, Loss_fe 0.393, Loss_kd 0.386, Train_accy 59.10
2022-10-08 07:15:45,093 [foster.py] => Task 1, Epoch 33/34 => Loss 1.307, Loss_clf 0.269, Loss_fe 0.378, Loss_kd 0.385, Train_accy 58.59
2022-10-08 07:15:47,412 [foster.py] => Task 1, Epoch 34/34 => Loss 1.350, Loss_clf 0.288, Loss_fe 0.396, Loss_kd 0.388, Train_accy 59.10
2022-10-08 07:15:47,412 [foster.py] => do not weight align teacher!
2022-10-08 07:15:47,413 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 07:15:50,974 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.835,  Train_accy 11.65, Test_accy 50.37
2022-10-08 07:15:53,627 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.644,  Train_accy 12.24
2022-10-08 07:15:56,277 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.564,  Train_accy 14.03
2022-10-08 07:15:58,942 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.530,  Train_accy 14.97
2022-10-08 07:16:01,603 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.507,  Train_accy 18.11
2022-10-08 07:16:04,890 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.476,  Train_accy 19.56, Test_accy 53.36
2022-10-08 07:16:07,570 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.461,  Train_accy 20.49
2022-10-08 07:16:10,308 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.448,  Train_accy 21.43
2022-10-08 07:16:12,931 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.430,  Train_accy 24.15
2022-10-08 07:16:15,651 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.429,  Train_accy 24.57
2022-10-08 07:16:18,984 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.414,  Train_accy 25.09, Test_accy 56.72
2022-10-08 07:16:21,727 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.415,  Train_accy 26.28
2022-10-08 07:16:24,379 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.398,  Train_accy 27.38
2022-10-08 07:16:27,059 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.401,  Train_accy 26.96
2022-10-08 07:16:29,663 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.388,  Train_accy 28.40
2022-10-08 07:16:32,973 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.392,  Train_accy 28.32, Test_accy 57.84
2022-10-08 07:16:35,630 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.391,  Train_accy 27.81
2022-10-08 07:16:38,270 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.386,  Train_accy 27.89
2022-10-08 07:16:40,943 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.397,  Train_accy 30.02
2022-10-08 07:16:43,585 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.381,  Train_accy 27.98
2022-10-08 07:16:46,896 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.389,  Train_accy 29.85, Test_accy 58.21
2022-10-08 07:16:49,609 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.383,  Train_accy 29.68
2022-10-08 07:16:52,265 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.380,  Train_accy 29.17
2022-10-08 07:16:54,939 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.377,  Train_accy 30.10
2022-10-08 07:16:57,576 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.394,  Train_accy 29.25
2022-10-08 07:17:00,864 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.371,  Train_accy 29.76, Test_accy 58.21
2022-10-08 07:17:00,864 [foster.py] => do not weight align student!
2022-10-08 07:17:01,499 [foster.py] => darknet eval: 
2022-10-08 07:17:01,499 [foster.py] => CNN top1 curve: 58.21
2022-10-08 07:17:01,499 [foster.py] => CNN top5 curve: 99.25
2022-10-08 07:17:01,500 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 07:17:09,040 [foster.py] => Exemplar size: 240
2022-10-08 07:17:09,040 [trainer.py] => CNN: {'total': 66.42, 'old': 82.28, 'new': 43.64, 'base': 82.28, 'compound': 43.64}
2022-10-08 07:17:09,040 [trainer.py] => CNN top1 curve: [86.71, 66.42]
2022-10-08 07:17:09,041 [trainer.py] => CNN base curve: [86.71, 82.28]
2022-10-08 07:17:09,041 [trainer.py] => CNN old curve: [86.71, 82.28]
2022-10-08 07:17:09,041 [trainer.py] => CNN new curve: [0, 43.64]
2022-10-08 07:17:09,041 [trainer.py] => CNN compound curve: [0, 43.64]
2022-10-08 07:17:09,041 [trainer.py] => NME: {'total': 76.12, 'old': 79.11, 'new': 71.82, 'base': 79.11, 'compound': 71.82}
2022-10-08 07:17:09,041 [trainer.py] => NME top1 curve: [86.08, 76.12]
2022-10-08 07:17:09,041 [trainer.py] => NME base curve: [86.08, 79.11]
2022-10-08 07:17:09,041 [trainer.py] => NME old curve: [86.08, 79.11]
2022-10-08 07:17:09,041 [trainer.py] => NME new curve: [0, 71.82]
2022-10-08 07:17:09,041 [trainer.py] => NME compound curve: [0, 71.82]
2022-10-08 07:17:09,261 [foster.py] => Learning on 12-17
2022-10-08 07:17:09,261 [foster.py] => All params: 22385326
2022-10-08 07:17:09,261 [foster.py] => Trainable params: 11202658
2022-10-08 07:17:09,270 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 07:17:12,464 [foster.py] => Task 2, Epoch 1/34 => Loss 5.739, Loss_clf 2.092, Loss_fe 2.250, Loss_kd 0.986, Train_accy 34.36, Test_accy 44.30
2022-10-08 07:17:14,888 [foster.py] => Task 2, Epoch 2/34 => Loss 3.996, Loss_clf 1.071, Loss_fe 1.557, Loss_kd 0.966, Train_accy 35.93
2022-10-08 07:17:17,347 [foster.py] => Task 2, Epoch 3/34 => Loss 3.717, Loss_clf 0.993, Loss_fe 1.371, Loss_kd 0.955, Train_accy 34.04
2022-10-08 07:17:19,814 [foster.py] => Task 2, Epoch 4/34 => Loss 3.588, Loss_clf 0.944, Loss_fe 1.284, Loss_kd 0.960, Train_accy 35.86
2022-10-08 07:17:22,241 [foster.py] => Task 2, Epoch 5/34 => Loss 3.448, Loss_clf 0.900, Loss_fe 1.193, Loss_kd 0.956, Train_accy 34.83
2022-10-08 07:17:25,459 [foster.py] => Task 2, Epoch 6/34 => Loss 3.357, Loss_clf 0.868, Loss_fe 1.134, Loss_kd 0.957, Train_accy 34.52, Test_accy 49.74
2022-10-08 07:17:27,930 [foster.py] => Task 2, Epoch 7/34 => Loss 3.303, Loss_clf 0.852, Loss_fe 1.083, Loss_kd 0.965, Train_accy 35.22
2022-10-08 07:17:30,367 [foster.py] => Task 2, Epoch 8/34 => Loss 3.262, Loss_clf 0.852, Loss_fe 1.050, Loss_kd 0.960, Train_accy 37.04
2022-10-08 07:17:32,789 [foster.py] => Task 2, Epoch 9/34 => Loss 3.150, Loss_clf 0.804, Loss_fe 0.987, Loss_kd 0.959, Train_accy 35.22
2022-10-08 07:17:35,275 [foster.py] => Task 2, Epoch 10/34 => Loss 3.111, Loss_clf 0.790, Loss_fe 0.953, Loss_kd 0.966, Train_accy 35.93
2022-10-08 07:17:38,545 [foster.py] => Task 2, Epoch 11/34 => Loss 3.017, Loss_clf 0.751, Loss_fe 0.904, Loss_kd 0.962, Train_accy 38.30, Test_accy 50.26
2022-10-08 07:17:41,028 [foster.py] => Task 2, Epoch 12/34 => Loss 3.020, Loss_clf 0.762, Loss_fe 0.903, Loss_kd 0.957, Train_accy 36.96
2022-10-08 07:17:43,498 [foster.py] => Task 2, Epoch 13/34 => Loss 2.971, Loss_clf 0.744, Loss_fe 0.869, Loss_kd 0.958, Train_accy 37.98
2022-10-08 07:17:45,927 [foster.py] => Task 2, Epoch 14/34 => Loss 2.949, Loss_clf 0.735, Loss_fe 0.848, Loss_kd 0.965, Train_accy 38.06
2022-10-08 07:17:48,382 [foster.py] => Task 2, Epoch 15/34 => Loss 2.914, Loss_clf 0.718, Loss_fe 0.827, Loss_kd 0.966, Train_accy 38.30
2022-10-08 07:17:51,648 [foster.py] => Task 2, Epoch 16/34 => Loss 2.879, Loss_clf 0.706, Loss_fe 0.815, Loss_kd 0.958, Train_accy 41.13, Test_accy 52.59
2022-10-08 07:17:54,159 [foster.py] => Task 2, Epoch 17/34 => Loss 2.871, Loss_clf 0.696, Loss_fe 0.810, Loss_kd 0.963, Train_accy 38.85
2022-10-08 07:17:56,642 [foster.py] => Task 2, Epoch 18/34 => Loss 2.822, Loss_clf 0.671, Loss_fe 0.778, Loss_kd 0.969, Train_accy 41.84
2022-10-08 07:17:59,131 [foster.py] => Task 2, Epoch 19/34 => Loss 2.791, Loss_clf 0.660, Loss_fe 0.767, Loss_kd 0.963, Train_accy 40.27
2022-10-08 07:18:01,574 [foster.py] => Task 2, Epoch 20/34 => Loss 2.742, Loss_clf 0.645, Loss_fe 0.740, Loss_kd 0.958, Train_accy 39.64
2022-10-08 07:18:04,862 [foster.py] => Task 2, Epoch 21/34 => Loss 2.742, Loss_clf 0.642, Loss_fe 0.734, Loss_kd 0.964, Train_accy 40.19, Test_accy 53.89
2022-10-08 07:18:07,276 [foster.py] => Task 2, Epoch 22/34 => Loss 2.748, Loss_clf 0.648, Loss_fe 0.737, Loss_kd 0.962, Train_accy 40.74
2022-10-08 07:18:09,711 [foster.py] => Task 2, Epoch 23/34 => Loss 2.742, Loss_clf 0.641, Loss_fe 0.739, Loss_kd 0.961, Train_accy 40.11
2022-10-08 07:18:12,180 [foster.py] => Task 2, Epoch 24/34 => Loss 2.736, Loss_clf 0.636, Loss_fe 0.733, Loss_kd 0.965, Train_accy 41.45
2022-10-08 07:18:14,657 [foster.py] => Task 2, Epoch 25/34 => Loss 2.716, Loss_clf 0.633, Loss_fe 0.721, Loss_kd 0.962, Train_accy 41.06
2022-10-08 07:18:17,898 [foster.py] => Task 2, Epoch 26/34 => Loss 2.688, Loss_clf 0.618, Loss_fe 0.709, Loss_kd 0.961, Train_accy 40.82, Test_accy 53.63
2022-10-08 07:18:20,377 [foster.py] => Task 2, Epoch 27/34 => Loss 2.676, Loss_clf 0.612, Loss_fe 0.696, Loss_kd 0.966, Train_accy 42.00
2022-10-08 07:18:22,803 [foster.py] => Task 2, Epoch 28/34 => Loss 2.704, Loss_clf 0.624, Loss_fe 0.718, Loss_kd 0.961, Train_accy 42.63
2022-10-08 07:18:25,237 [foster.py] => Task 2, Epoch 29/34 => Loss 2.663, Loss_clf 0.612, Loss_fe 0.692, Loss_kd 0.959, Train_accy 42.71
2022-10-08 07:18:27,759 [foster.py] => Task 2, Epoch 30/34 => Loss 2.667, Loss_clf 0.608, Loss_fe 0.696, Loss_kd 0.962, Train_accy 41.61
2022-10-08 07:18:31,063 [foster.py] => Task 2, Epoch 31/34 => Loss 2.688, Loss_clf 0.615, Loss_fe 0.712, Loss_kd 0.961, Train_accy 41.84, Test_accy 53.11
2022-10-08 07:18:33,494 [foster.py] => Task 2, Epoch 32/34 => Loss 2.675, Loss_clf 0.608, Loss_fe 0.699, Loss_kd 0.965, Train_accy 42.87
2022-10-08 07:18:35,936 [foster.py] => Task 2, Epoch 33/34 => Loss 2.678, Loss_clf 0.614, Loss_fe 0.701, Loss_kd 0.962, Train_accy 42.87
2022-10-08 07:18:38,425 [foster.py] => Task 2, Epoch 34/34 => Loss 2.681, Loss_clf 0.617, Loss_fe 0.699, Loss_kd 0.964, Train_accy 42.16
2022-10-08 07:18:38,426 [foster.py] => do not weight align teacher!
2022-10-08 07:18:38,426 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 07:18:42,227 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.101,  Train_accy 12.06, Test_accy 39.90
2022-10-08 07:18:45,073 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.998,  Train_accy 13.40
2022-10-08 07:18:47,862 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.964,  Train_accy 13.08
2022-10-08 07:18:50,736 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.939,  Train_accy 13.16
2022-10-08 07:18:53,532 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.937,  Train_accy 13.16
2022-10-08 07:18:57,115 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.921,  Train_accy 13.55, Test_accy 42.75
2022-10-08 07:18:59,925 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.915,  Train_accy 13.71
2022-10-08 07:19:02,772 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.919,  Train_accy 13.63
2022-10-08 07:19:05,610 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.906,  Train_accy 13.32
2022-10-08 07:19:08,429 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.893,  Train_accy 13.87
2022-10-08 07:19:11,919 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.899,  Train_accy 13.79, Test_accy 42.75
2022-10-08 07:19:14,675 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.897,  Train_accy 13.79
2022-10-08 07:19:17,495 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.886,  Train_accy 13.79
2022-10-08 07:19:20,336 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.889,  Train_accy 13.87
2022-10-08 07:19:23,292 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.891,  Train_accy 14.11
2022-10-08 07:19:26,946 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.885,  Train_accy 14.50, Test_accy 42.75
2022-10-08 07:19:29,754 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.884,  Train_accy 14.18
2022-10-08 07:19:32,545 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.883,  Train_accy 13.95
2022-10-08 07:19:35,446 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.878,  Train_accy 14.18
2022-10-08 07:19:38,281 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.876,  Train_accy 14.18
2022-10-08 07:19:41,866 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.881,  Train_accy 13.79, Test_accy 43.01
2022-10-08 07:19:44,684 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.880,  Train_accy 13.87
2022-10-08 07:19:47,534 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.879,  Train_accy 14.74
2022-10-08 07:19:50,405 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.870,  Train_accy 13.63
2022-10-08 07:19:53,247 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.876,  Train_accy 14.18
2022-10-08 07:19:56,755 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.878,  Train_accy 14.26, Test_accy 43.01
2022-10-08 07:19:56,756 [foster.py] => do not weight align student!
2022-10-08 07:19:57,467 [foster.py] => darknet eval: 
2022-10-08 07:19:57,468 [foster.py] => CNN top1 curve: 43.01
2022-10-08 07:19:57,468 [foster.py] => CNN top5 curve: 93.26
2022-10-08 07:19:57,468 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 07:20:06,699 [foster.py] => Exemplar size: 340
2022-10-08 07:20:06,700 [trainer.py] => CNN: {'total': 53.11, 'old': 63.06, 'new': 30.51, 'base': 79.11, 'compound': 35.09}
2022-10-08 07:20:06,700 [trainer.py] => CNN top1 curve: [86.71, 66.42, 53.11]
2022-10-08 07:20:06,700 [trainer.py] => CNN base curve: [86.71, 82.28, 79.11]
2022-10-08 07:20:06,700 [trainer.py] => CNN old curve: [86.71, 82.28, 63.06]
2022-10-08 07:20:06,700 [trainer.py] => CNN new curve: [0, 43.64, 30.51]
2022-10-08 07:20:06,700 [trainer.py] => CNN compound curve: [0, 43.64, 35.09]
2022-10-08 07:20:06,700 [trainer.py] => NME: {'total': 61.92, 'old': 66.79, 'new': 50.85, 'base': 70.89, 'compound': 55.7}
2022-10-08 07:20:06,700 [trainer.py] => NME top1 curve: [86.08, 76.12, 61.92]
2022-10-08 07:20:06,700 [trainer.py] => NME base curve: [86.08, 79.11, 70.89]
2022-10-08 07:20:06,700 [trainer.py] => NME old curve: [86.08, 79.11, 66.79]
2022-10-08 07:20:06,700 [trainer.py] => NME new curve: [0, 71.82, 50.85]
2022-10-08 07:20:06,700 [trainer.py] => NME compound curve: [0, 71.82, 55.7]
2022-10-08 07:20:06,918 [foster.py] => Learning on 17-22
2022-10-08 07:20:06,918 [foster.py] => All params: 22395581
2022-10-08 07:20:06,918 [foster.py] => Trainable params: 11210348
2022-10-08 07:20:06,927 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 07:20:10,459 [foster.py] => Task 3, Epoch 1/34 => Loss 6.461, Loss_clf 2.184, Loss_fe 2.455, Loss_kd 1.408, Train_accy 31.38, Test_accy 37.23
2022-10-08 07:20:13,066 [foster.py] => Task 3, Epoch 2/34 => Loss 4.761, Loss_clf 1.207, Loss_fe 1.754, Loss_kd 1.391, Train_accy 29.63
2022-10-08 07:20:15,720 [foster.py] => Task 3, Epoch 3/34 => Loss 4.496, Loss_clf 1.116, Loss_fe 1.592, Loss_kd 1.382, Train_accy 30.29
2022-10-08 07:20:18,375 [foster.py] => Task 3, Epoch 4/34 => Loss 4.333, Loss_clf 1.070, Loss_fe 1.477, Loss_kd 1.380, Train_accy 30.72
2022-10-08 07:20:20,966 [foster.py] => Task 3, Epoch 5/34 => Loss 4.211, Loss_clf 1.037, Loss_fe 1.385, Loss_kd 1.383, Train_accy 30.36
2022-10-08 07:20:24,553 [foster.py] => Task 3, Epoch 6/34 => Loss 4.132, Loss_clf 1.016, Loss_fe 1.328, Loss_kd 1.382, Train_accy 31.31, Test_accy 39.21
2022-10-08 07:20:27,140 [foster.py] => Task 3, Epoch 7/34 => Loss 4.062, Loss_clf 0.998, Loss_fe 1.283, Loss_kd 1.377, Train_accy 30.36
2022-10-08 07:20:29,728 [foster.py] => Task 3, Epoch 8/34 => Loss 3.986, Loss_clf 0.974, Loss_fe 1.229, Loss_kd 1.378, Train_accy 31.09
2022-10-08 07:20:32,288 [foster.py] => Task 3, Epoch 9/34 => Loss 3.941, Loss_clf 0.966, Loss_fe 1.194, Loss_kd 1.376, Train_accy 32.41
2022-10-08 07:20:34,974 [foster.py] => Task 3, Epoch 10/34 => Loss 3.889, Loss_clf 0.949, Loss_fe 1.153, Loss_kd 1.382, Train_accy 32.19
2022-10-08 07:20:38,472 [foster.py] => Task 3, Epoch 11/34 => Loss 3.835, Loss_clf 0.934, Loss_fe 1.118, Loss_kd 1.377, Train_accy 31.82, Test_accy 40.00
2022-10-08 07:20:41,191 [foster.py] => Task 3, Epoch 12/34 => Loss 3.810, Loss_clf 0.926, Loss_fe 1.089, Loss_kd 1.387, Train_accy 32.33
2022-10-08 07:20:43,884 [foster.py] => Task 3, Epoch 13/34 => Loss 3.746, Loss_clf 0.902, Loss_fe 1.062, Loss_kd 1.377, Train_accy 32.85
2022-10-08 07:20:46,531 [foster.py] => Task 3, Epoch 14/34 => Loss 3.684, Loss_clf 0.875, Loss_fe 1.020, Loss_kd 1.382, Train_accy 34.09
2022-10-08 07:20:49,153 [foster.py] => Task 3, Epoch 15/34 => Loss 3.682, Loss_clf 0.868, Loss_fe 1.015, Loss_kd 1.390, Train_accy 33.72
2022-10-08 07:20:52,766 [foster.py] => Task 3, Epoch 16/34 => Loss 3.643, Loss_clf 0.860, Loss_fe 0.996, Loss_kd 1.381, Train_accy 34.31, Test_accy 41.58
2022-10-08 07:20:55,414 [foster.py] => Task 3, Epoch 17/34 => Loss 3.638, Loss_clf 0.860, Loss_fe 0.992, Loss_kd 1.380, Train_accy 32.63
2022-10-08 07:20:57,975 [foster.py] => Task 3, Epoch 18/34 => Loss 3.648, Loss_clf 0.863, Loss_fe 0.998, Loss_kd 1.380, Train_accy 33.65
2022-10-08 07:21:00,553 [foster.py] => Task 3, Epoch 19/34 => Loss 3.615, Loss_clf 0.858, Loss_fe 0.976, Loss_kd 1.376, Train_accy 34.31
2022-10-08 07:21:03,140 [foster.py] => Task 3, Epoch 20/34 => Loss 3.546, Loss_clf 0.815, Loss_fe 0.940, Loss_kd 1.384, Train_accy 34.24
2022-10-08 07:21:06,791 [foster.py] => Task 3, Epoch 21/34 => Loss 3.524, Loss_clf 0.814, Loss_fe 0.926, Loss_kd 1.379, Train_accy 34.75, Test_accy 42.97
2022-10-08 07:21:09,580 [foster.py] => Task 3, Epoch 22/34 => Loss 3.587, Loss_clf 0.838, Loss_fe 0.958, Loss_kd 1.383, Train_accy 31.75
2022-10-08 07:21:12,328 [foster.py] => Task 3, Epoch 23/34 => Loss 3.532, Loss_clf 0.820, Loss_fe 0.925, Loss_kd 1.381, Train_accy 34.97
2022-10-08 07:21:15,039 [foster.py] => Task 3, Epoch 24/34 => Loss 3.512, Loss_clf 0.810, Loss_fe 0.915, Loss_kd 1.381, Train_accy 34.75
2022-10-08 07:21:17,830 [foster.py] => Task 3, Epoch 25/34 => Loss 3.524, Loss_clf 0.818, Loss_fe 0.927, Loss_kd 1.375, Train_accy 34.60
2022-10-08 07:21:21,561 [foster.py] => Task 3, Epoch 26/34 => Loss 3.505, Loss_clf 0.805, Loss_fe 0.909, Loss_kd 1.383, Train_accy 34.60, Test_accy 43.17
2022-10-08 07:21:24,293 [foster.py] => Task 3, Epoch 27/34 => Loss 3.453, Loss_clf 0.781, Loss_fe 0.887, Loss_kd 1.380, Train_accy 35.19
2022-10-08 07:21:27,030 [foster.py] => Task 3, Epoch 28/34 => Loss 3.489, Loss_clf 0.799, Loss_fe 0.898, Loss_kd 1.385, Train_accy 34.09
2022-10-08 07:21:29,764 [foster.py] => Task 3, Epoch 29/34 => Loss 3.501, Loss_clf 0.802, Loss_fe 0.914, Loss_kd 1.379, Train_accy 34.75
2022-10-08 07:21:32,513 [foster.py] => Task 3, Epoch 30/34 => Loss 3.479, Loss_clf 0.796, Loss_fe 0.896, Loss_kd 1.381, Train_accy 35.70
2022-10-08 07:21:36,219 [foster.py] => Task 3, Epoch 31/34 => Loss 3.495, Loss_clf 0.797, Loss_fe 0.904, Loss_kd 1.386, Train_accy 35.63, Test_accy 43.56
2022-10-08 07:21:38,968 [foster.py] => Task 3, Epoch 32/34 => Loss 3.460, Loss_clf 0.786, Loss_fe 0.886, Loss_kd 1.382, Train_accy 35.41
2022-10-08 07:21:41,678 [foster.py] => Task 3, Epoch 33/34 => Loss 3.493, Loss_clf 0.798, Loss_fe 0.905, Loss_kd 1.383, Train_accy 34.60
2022-10-08 07:21:44,410 [foster.py] => Task 3, Epoch 34/34 => Loss 3.465, Loss_clf 0.784, Loss_fe 0.893, Loss_kd 1.381, Train_accy 35.26
2022-10-08 07:21:44,411 [foster.py] => do not weight align teacher!
2022-10-08 07:21:44,411 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 07:21:48,443 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.326,  Train_accy 12.73, Test_accy 33.07
2022-10-08 07:21:51,472 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.270,  Train_accy 13.46
2022-10-08 07:21:54,485 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.246,  Train_accy 13.83
2022-10-08 07:21:57,577 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.240,  Train_accy 13.53
2022-10-08 07:22:00,550 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.228,  Train_accy 13.31
2022-10-08 07:22:04,323 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.207,  Train_accy 14.12, Test_accy 34.26
2022-10-08 07:22:07,348 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.208,  Train_accy 13.75
2022-10-08 07:22:10,405 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.194,  Train_accy 14.19
2022-10-08 07:22:13,442 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.199,  Train_accy 13.53
2022-10-08 07:22:16,462 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.187,  Train_accy 14.19
2022-10-08 07:22:20,294 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.196,  Train_accy 14.41, Test_accy 34.85
2022-10-08 07:22:23,916 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.175,  Train_accy 14.48
2022-10-08 07:22:27,147 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.180,  Train_accy 14.26
2022-10-08 07:22:30,310 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.176,  Train_accy 14.05
2022-10-08 07:22:33,439 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.168,  Train_accy 15.14
2022-10-08 07:22:37,345 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.170,  Train_accy 15.07, Test_accy 36.24
2022-10-08 07:22:40,380 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.166,  Train_accy 14.78
2022-10-08 07:22:43,395 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.173,  Train_accy 15.00
2022-10-08 07:22:46,458 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.167,  Train_accy 14.85
2022-10-08 07:22:49,486 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.169,  Train_accy 15.95
2022-10-08 07:22:53,260 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.163,  Train_accy 15.73, Test_accy 35.25
2022-10-08 07:22:56,242 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.165,  Train_accy 15.14
2022-10-08 07:22:59,310 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.178,  Train_accy 15.00
2022-10-08 07:23:02,317 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.168,  Train_accy 14.78
2022-10-08 07:23:05,315 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.159,  Train_accy 15.14
2022-10-08 07:23:09,130 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.175,  Train_accy 14.63, Test_accy 36.63
2022-10-08 07:23:09,130 [foster.py] => do not weight align student!
2022-10-08 07:23:09,901 [foster.py] => darknet eval: 
2022-10-08 07:23:09,901 [foster.py] => CNN top1 curve: 36.63
2022-10-08 07:23:09,901 [foster.py] => CNN top5 curve: 84.75
2022-10-08 07:23:09,901 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 07:23:20,881 [foster.py] => Exemplar size: 440
2022-10-08 07:23:20,881 [trainer.py] => CNN: {'total': 43.17, 'old': 51.04, 'new': 17.65, 'base': 78.48, 'compound': 27.09}
2022-10-08 07:23:20,882 [trainer.py] => CNN top1 curve: [86.71, 66.42, 53.11, 43.17]
2022-10-08 07:23:20,882 [trainer.py] => CNN base curve: [86.71, 82.28, 79.11, 78.48]
2022-10-08 07:23:20,882 [trainer.py] => CNN old curve: [86.71, 82.28, 63.06, 51.04]
2022-10-08 07:23:20,882 [trainer.py] => CNN new curve: [0, 43.64, 30.51, 17.65]
2022-10-08 07:23:20,882 [trainer.py] => CNN compound curve: [0, 43.64, 35.09, 27.09]
2022-10-08 07:23:20,882 [trainer.py] => NME: {'total': 52.28, 'old': 56.22, 'new': 39.5, 'base': 68.99, 'compound': 44.67}
2022-10-08 07:23:20,882 [trainer.py] => NME top1 curve: [86.08, 76.12, 61.92, 52.28]
2022-10-08 07:23:20,882 [trainer.py] => NME base curve: [86.08, 79.11, 70.89, 68.99]
2022-10-08 07:23:20,882 [trainer.py] => NME old curve: [86.08, 79.11, 66.79, 56.22]
2022-10-08 07:23:20,882 [trainer.py] => NME new curve: [0, 71.82, 50.85, 39.5]
2022-10-08 07:23:20,882 [trainer.py] => NME compound curve: [0, 71.82, 55.7, 44.67]
2022-10-08 07:23:20,883 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 07:23:20,883 [trainer.py] => prefix: cil
2022-10-08 07:23:20,883 [trainer.py] => dataset: CFEE
2022-10-08 07:23:20,883 [trainer.py] => memory_size: 2000
2022-10-08 07:23:20,883 [trainer.py] => memory_per_class: 20
2022-10-08 07:23:20,883 [trainer.py] => fixed_memory: True
2022-10-08 07:23:20,883 [trainer.py] => shuffle: True
2022-10-08 07:23:20,883 [trainer.py] => init_cls: 7
2022-10-08 07:23:20,883 [trainer.py] => increment: 5
2022-10-08 07:23:20,883 [trainer.py] => model_name: foster
2022-10-08 07:23:20,883 [trainer.py] => convnet_type: resnet18
2022-10-08 07:23:20,883 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 07:23:20,884 [trainer.py] => seed: 1993
2022-10-08 07:23:20,884 [trainer.py] => beta1: 0.96
2022-10-08 07:23:20,884 [trainer.py] => beta2: 0.97
2022-10-08 07:23:20,884 [trainer.py] => oofc: ft
2022-10-08 07:23:20,884 [trainer.py] => is_teacher_wa: False
2022-10-08 07:23:20,884 [trainer.py] => is_student_wa: False
2022-10-08 07:23:20,884 [trainer.py] => lambda_okd: 1
2022-10-08 07:23:20,884 [trainer.py] => wa_value: 1
2022-10-08 07:23:20,884 [trainer.py] => init_epochs: 40
2022-10-08 07:23:20,884 [trainer.py] => init_lr: 0.01
2022-10-08 07:23:20,884 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 07:23:20,884 [trainer.py] => boosting_epochs: 34
2022-10-08 07:23:20,884 [trainer.py] => compression_epochs: 26
2022-10-08 07:23:20,884 [trainer.py] => lr: 0.001
2022-10-08 07:23:20,884 [trainer.py] => batch_size: 32
2022-10-08 07:23:20,884 [trainer.py] => weight_decay: 0.0005
2022-10-08 07:23:20,884 [trainer.py] => num_workers: 8
2022-10-08 07:23:20,884 [trainer.py] => T: 2
2022-10-08 07:23:20,884 [trainer.py] => nb_runs: 3
2022-10-08 07:23:20,884 [trainer.py] => fold: 10
2022-10-08 07:23:20,884 [data.py] => ========== Fold:3 ==========
2022-10-08 07:23:20,889 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 8, 15, 13, 17, 9, 11, 19, 21, 14, 10, 18, 12, 7, 16]
2022-10-08 07:23:21,100 [foster.py] => Learning on 0-7
2022-10-08 07:23:21,100 [foster.py] => All params: 11183694
2022-10-08 07:23:21,101 [foster.py] => Trainable params: 11183694
2022-10-08 07:23:23,358 [foster.py] => Task 0, Epoch 1/40 => Loss 1.348, Train_accy 50.98
2022-10-08 07:23:26,172 [foster.py] => Task 0, Epoch 2/40 => Loss 0.512, Train_accy 82.28, Test_accy 80.45
2022-10-08 07:23:28,947 [foster.py] => Task 0, Epoch 3/40 => Loss 0.347, Train_accy 88.17, Test_accy 83.80
2022-10-08 07:23:31,738 [foster.py] => Task 0, Epoch 4/40 => Loss 0.278, Train_accy 89.57, Test_accy 86.59
2022-10-08 07:23:34,548 [foster.py] => Task 0, Epoch 5/40 => Loss 0.221, Train_accy 92.30, Test_accy 85.47
2022-10-08 07:23:36,781 [foster.py] => Task 0, Epoch 6/40 => Loss 0.177, Train_accy 93.77
2022-10-08 07:23:39,588 [foster.py] => Task 0, Epoch 7/40 => Loss 0.143, Train_accy 94.68, Test_accy 84.92
2022-10-08 07:23:42,405 [foster.py] => Task 0, Epoch 8/40 => Loss 0.129, Train_accy 95.59, Test_accy 82.68
2022-10-08 07:23:45,245 [foster.py] => Task 0, Epoch 9/40 => Loss 0.101, Train_accy 96.92, Test_accy 85.47
2022-10-08 07:23:48,076 [foster.py] => Task 0, Epoch 10/40 => Loss 0.095, Train_accy 97.27, Test_accy 86.03
2022-10-08 07:23:50,296 [foster.py] => Task 0, Epoch 11/40 => Loss 0.095, Train_accy 96.71
2022-10-08 07:23:53,162 [foster.py] => Task 0, Epoch 12/40 => Loss 0.075, Train_accy 97.41, Test_accy 85.47
2022-10-08 07:23:55,987 [foster.py] => Task 0, Epoch 13/40 => Loss 0.060, Train_accy 97.97, Test_accy 85.47
2022-10-08 07:23:58,787 [foster.py] => Task 0, Epoch 14/40 => Loss 0.053, Train_accy 98.53, Test_accy 87.15
2022-10-08 07:24:01,612 [foster.py] => Task 0, Epoch 15/40 => Loss 0.056, Train_accy 98.60, Test_accy 87.15
2022-10-08 07:24:03,827 [foster.py] => Task 0, Epoch 16/40 => Loss 0.044, Train_accy 98.81
2022-10-08 07:24:06,672 [foster.py] => Task 0, Epoch 17/40 => Loss 0.037, Train_accy 99.09, Test_accy 88.27
2022-10-08 07:24:09,512 [foster.py] => Task 0, Epoch 18/40 => Loss 0.038, Train_accy 98.88, Test_accy 87.71
2022-10-08 07:24:12,344 [foster.py] => Task 0, Epoch 19/40 => Loss 0.029, Train_accy 99.16, Test_accy 86.59
2022-10-08 07:24:15,150 [foster.py] => Task 0, Epoch 20/40 => Loss 0.025, Train_accy 99.72, Test_accy 86.03
2022-10-08 07:24:17,354 [foster.py] => Task 0, Epoch 21/40 => Loss 0.022, Train_accy 99.72
2022-10-08 07:24:20,202 [foster.py] => Task 0, Epoch 22/40 => Loss 0.022, Train_accy 99.44, Test_accy 84.92
2022-10-08 07:24:23,015 [foster.py] => Task 0, Epoch 23/40 => Loss 0.015, Train_accy 100.00, Test_accy 86.59
2022-10-08 07:24:25,828 [foster.py] => Task 0, Epoch 24/40 => Loss 0.017, Train_accy 99.72, Test_accy 84.92
2022-10-08 07:24:28,667 [foster.py] => Task 0, Epoch 25/40 => Loss 0.019, Train_accy 99.65, Test_accy 84.36
2022-10-08 07:24:30,943 [foster.py] => Task 0, Epoch 26/40 => Loss 0.019, Train_accy 99.65
2022-10-08 07:24:33,770 [foster.py] => Task 0, Epoch 27/40 => Loss 0.016, Train_accy 99.65, Test_accy 84.36
2022-10-08 07:24:36,606 [foster.py] => Task 0, Epoch 28/40 => Loss 0.017, Train_accy 99.86, Test_accy 83.80
2022-10-08 07:24:39,403 [foster.py] => Task 0, Epoch 29/40 => Loss 0.013, Train_accy 99.79, Test_accy 83.80
2022-10-08 07:24:42,233 [foster.py] => Task 0, Epoch 30/40 => Loss 0.015, Train_accy 99.86, Test_accy 84.36
2022-10-08 07:24:44,517 [foster.py] => Task 0, Epoch 31/40 => Loss 0.012, Train_accy 99.93
2022-10-08 07:24:47,345 [foster.py] => Task 0, Epoch 32/40 => Loss 0.014, Train_accy 99.86, Test_accy 84.36
2022-10-08 07:24:50,185 [foster.py] => Task 0, Epoch 33/40 => Loss 0.014, Train_accy 99.72, Test_accy 84.92
2022-10-08 07:24:53,014 [foster.py] => Task 0, Epoch 34/40 => Loss 0.013, Train_accy 99.79, Test_accy 83.80
2022-10-08 07:24:55,852 [foster.py] => Task 0, Epoch 35/40 => Loss 0.009, Train_accy 99.86, Test_accy 84.92
2022-10-08 07:24:58,104 [foster.py] => Task 0, Epoch 36/40 => Loss 0.011, Train_accy 99.93
2022-10-08 07:25:00,883 [foster.py] => Task 0, Epoch 37/40 => Loss 0.015, Train_accy 99.86, Test_accy 84.92
2022-10-08 07:25:03,711 [foster.py] => Task 0, Epoch 38/40 => Loss 0.014, Train_accy 99.86, Test_accy 83.80
2022-10-08 07:25:06,532 [foster.py] => Task 0, Epoch 39/40 => Loss 0.016, Train_accy 99.72, Test_accy 85.47
2022-10-08 07:25:09,344 [foster.py] => Task 0, Epoch 40/40 => Loss 0.013, Train_accy 99.79, Test_accy 84.36
2022-10-08 07:25:09,345 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 07:25:15,713 [foster.py] => Exemplar size: 140
2022-10-08 07:25:15,713 [trainer.py] => CNN: {'total': 84.36, 'old': 84.36, 'new': 0, 'base': 84.36, 'compound': 0}
2022-10-08 07:25:15,713 [trainer.py] => CNN top1 curve: [84.36]
2022-10-08 07:25:15,713 [trainer.py] => CNN base curve: [84.36]
2022-10-08 07:25:15,713 [trainer.py] => CNN old curve: [84.36]
2022-10-08 07:25:15,713 [trainer.py] => CNN new curve: [0]
2022-10-08 07:25:15,713 [trainer.py] => CNN compound curve: [0]
2022-10-08 07:25:15,713 [trainer.py] => NME: {'total': 83.24, 'old': 83.24, 'new': 0, 'base': 83.24, 'compound': 0}
2022-10-08 07:25:15,713 [trainer.py] => NME top1 curve: [83.24]
2022-10-08 07:25:15,713 [trainer.py] => NME base curve: [83.24]
2022-10-08 07:25:15,713 [trainer.py] => NME old curve: [83.24]
2022-10-08 07:25:15,713 [trainer.py] => NME new curve: [0]
2022-10-08 07:25:15,713 [trainer.py] => NME compound curve: [0]
2022-10-08 07:25:15,932 [foster.py] => Learning on 7-12
2022-10-08 07:25:15,932 [foster.py] => All params: 22375071
2022-10-08 07:25:15,932 [foster.py] => Trainable params: 11194968
2022-10-08 07:25:15,941 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 07:25:18,927 [foster.py] => Task 1, Epoch 1/34 => Loss 4.729, Loss_clf 1.963, Loss_fe 2.040, Loss_kd 0.424, Train_accy 39.85, Test_accy 66.32
2022-10-08 07:25:21,208 [foster.py] => Task 1, Epoch 2/34 => Loss 2.594, Loss_clf 0.669, Loss_fe 1.230, Loss_kd 0.406, Train_accy 62.19
2022-10-08 07:25:23,503 [foster.py] => Task 1, Epoch 3/34 => Loss 2.237, Loss_clf 0.558, Loss_fe 1.001, Loss_kd 0.396, Train_accy 47.15
2022-10-08 07:25:25,794 [foster.py] => Task 1, Epoch 4/34 => Loss 2.051, Loss_clf 0.503, Loss_fe 0.869, Loss_kd 0.396, Train_accy 53.02
2022-10-08 07:25:28,075 [foster.py] => Task 1, Epoch 5/34 => Loss 1.946, Loss_clf 0.471, Loss_fe 0.794, Loss_kd 0.397, Train_accy 50.72
2022-10-08 07:25:31,135 [foster.py] => Task 1, Epoch 6/34 => Loss 1.843, Loss_clf 0.447, Loss_fe 0.718, Loss_kd 0.395, Train_accy 50.89, Test_accy 68.40
2022-10-08 07:25:33,445 [foster.py] => Task 1, Epoch 7/34 => Loss 1.788, Loss_clf 0.439, Loss_fe 0.674, Loss_kd 0.393, Train_accy 50.64
2022-10-08 07:25:35,785 [foster.py] => Task 1, Epoch 8/34 => Loss 1.723, Loss_clf 0.420, Loss_fe 0.627, Loss_kd 0.395, Train_accy 52.25
2022-10-08 07:25:38,103 [foster.py] => Task 1, Epoch 9/34 => Loss 1.640, Loss_clf 0.384, Loss_fe 0.584, Loss_kd 0.392, Train_accy 51.49
2022-10-08 07:25:40,424 [foster.py] => Task 1, Epoch 10/34 => Loss 1.637, Loss_clf 0.399, Loss_fe 0.561, Loss_kd 0.395, Train_accy 54.89
2022-10-08 07:25:43,471 [foster.py] => Task 1, Epoch 11/34 => Loss 1.620, Loss_clf 0.391, Loss_fe 0.553, Loss_kd 0.395, Train_accy 51.74, Test_accy 68.75
2022-10-08 07:25:45,806 [foster.py] => Task 1, Epoch 12/34 => Loss 1.570, Loss_clf 0.363, Loss_fe 0.525, Loss_kd 0.397, Train_accy 54.04
2022-10-08 07:25:48,107 [foster.py] => Task 1, Epoch 13/34 => Loss 1.517, Loss_clf 0.350, Loss_fe 0.493, Loss_kd 0.393, Train_accy 55.48
2022-10-08 07:25:50,423 [foster.py] => Task 1, Epoch 14/34 => Loss 1.493, Loss_clf 0.344, Loss_fe 0.478, Loss_kd 0.392, Train_accy 55.56
2022-10-08 07:25:52,724 [foster.py] => Task 1, Epoch 15/34 => Loss 1.475, Loss_clf 0.335, Loss_fe 0.461, Loss_kd 0.396, Train_accy 56.24
2022-10-08 07:25:55,736 [foster.py] => Task 1, Epoch 16/34 => Loss 1.492, Loss_clf 0.347, Loss_fe 0.469, Loss_kd 0.395, Train_accy 57.09, Test_accy 69.10
2022-10-08 07:25:58,062 [foster.py] => Task 1, Epoch 17/34 => Loss 1.455, Loss_clf 0.335, Loss_fe 0.447, Loss_kd 0.393, Train_accy 56.41
2022-10-08 07:26:00,374 [foster.py] => Task 1, Epoch 18/34 => Loss 1.415, Loss_clf 0.311, Loss_fe 0.425, Loss_kd 0.396, Train_accy 56.24
2022-10-08 07:26:02,655 [foster.py] => Task 1, Epoch 19/34 => Loss 1.401, Loss_clf 0.305, Loss_fe 0.414, Loss_kd 0.398, Train_accy 57.60
2022-10-08 07:26:05,018 [foster.py] => Task 1, Epoch 20/34 => Loss 1.402, Loss_clf 0.310, Loss_fe 0.417, Loss_kd 0.394, Train_accy 56.50
2022-10-08 07:26:08,083 [foster.py] => Task 1, Epoch 21/34 => Loss 1.412, Loss_clf 0.314, Loss_fe 0.418, Loss_kd 0.397, Train_accy 57.60, Test_accy 69.44
2022-10-08 07:26:10,393 [foster.py] => Task 1, Epoch 22/34 => Loss 1.370, Loss_clf 0.302, Loss_fe 0.399, Loss_kd 0.390, Train_accy 57.60
2022-10-08 07:26:12,713 [foster.py] => Task 1, Epoch 23/34 => Loss 1.384, Loss_clf 0.295, Loss_fe 0.398, Loss_kd 0.403, Train_accy 59.30
2022-10-08 07:26:15,044 [foster.py] => Task 1, Epoch 24/34 => Loss 1.367, Loss_clf 0.289, Loss_fe 0.392, Loss_kd 0.401, Train_accy 58.96
2022-10-08 07:26:17,349 [foster.py] => Task 1, Epoch 25/34 => Loss 1.359, Loss_clf 0.293, Loss_fe 0.393, Loss_kd 0.392, Train_accy 57.35
2022-10-08 07:26:20,375 [foster.py] => Task 1, Epoch 26/34 => Loss 1.343, Loss_clf 0.286, Loss_fe 0.376, Loss_kd 0.398, Train_accy 57.09, Test_accy 69.10
2022-10-08 07:26:22,724 [foster.py] => Task 1, Epoch 27/34 => Loss 1.359, Loss_clf 0.288, Loss_fe 0.386, Loss_kd 0.399, Train_accy 59.39
2022-10-08 07:26:25,048 [foster.py] => Task 1, Epoch 28/34 => Loss 1.340, Loss_clf 0.282, Loss_fe 0.378, Loss_kd 0.396, Train_accy 58.03
2022-10-08 07:26:27,402 [foster.py] => Task 1, Epoch 29/34 => Loss 1.332, Loss_clf 0.281, Loss_fe 0.378, Loss_kd 0.392, Train_accy 58.11
2022-10-08 07:26:29,739 [foster.py] => Task 1, Epoch 30/34 => Loss 1.344, Loss_clf 0.287, Loss_fe 0.382, Loss_kd 0.394, Train_accy 59.22
2022-10-08 07:26:32,808 [foster.py] => Task 1, Epoch 31/34 => Loss 1.342, Loss_clf 0.283, Loss_fe 0.382, Loss_kd 0.395, Train_accy 58.03, Test_accy 69.44
2022-10-08 07:26:35,114 [foster.py] => Task 1, Epoch 32/34 => Loss 1.344, Loss_clf 0.287, Loss_fe 0.385, Loss_kd 0.392, Train_accy 58.28
2022-10-08 07:26:37,388 [foster.py] => Task 1, Epoch 33/34 => Loss 1.326, Loss_clf 0.278, Loss_fe 0.375, Loss_kd 0.393, Train_accy 58.03
2022-10-08 07:26:39,708 [foster.py] => Task 1, Epoch 34/34 => Loss 1.335, Loss_clf 0.280, Loss_fe 0.373, Loss_kd 0.397, Train_accy 59.13
2022-10-08 07:26:39,709 [foster.py] => do not weight align teacher!
2022-10-08 07:26:39,709 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 07:26:43,217 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.831,  Train_accy 11.81, Test_accy 51.74
2022-10-08 07:26:45,875 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.640,  Train_accy 11.98
2022-10-08 07:26:48,558 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.550,  Train_accy 12.91
2022-10-08 07:26:51,241 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.521,  Train_accy 14.36
2022-10-08 07:26:53,924 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.492,  Train_accy 15.55
2022-10-08 07:26:57,217 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.476,  Train_accy 17.84, Test_accy 54.51
2022-10-08 07:26:59,873 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.456,  Train_accy 19.54
2022-10-08 07:27:02,539 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.435,  Train_accy 20.22
2022-10-08 07:27:05,264 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.437,  Train_accy 20.82
2022-10-08 07:27:07,944 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.423,  Train_accy 22.09
2022-10-08 07:27:11,317 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.418,  Train_accy 25.15, Test_accy 56.60
2022-10-08 07:27:13,995 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.420,  Train_accy 24.47
2022-10-08 07:27:16,679 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.402,  Train_accy 24.81
2022-10-08 07:27:19,295 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.399,  Train_accy 24.89
2022-10-08 07:27:21,939 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.400,  Train_accy 25.91
2022-10-08 07:27:25,268 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.393,  Train_accy 26.93, Test_accy 59.03
2022-10-08 07:27:27,979 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.392,  Train_accy 26.51
2022-10-08 07:27:30,629 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.389,  Train_accy 26.85
2022-10-08 07:27:33,317 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.391,  Train_accy 28.29
2022-10-08 07:27:35,947 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.386,  Train_accy 27.19
2022-10-08 07:27:39,258 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.393,  Train_accy 27.44, Test_accy 59.03
2022-10-08 07:27:41,964 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.380,  Train_accy 26.34
2022-10-08 07:27:44,615 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.386,  Train_accy 28.29
2022-10-08 07:27:47,272 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.384,  Train_accy 26.17
2022-10-08 07:27:49,931 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.382,  Train_accy 27.70
2022-10-08 07:27:53,275 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.385,  Train_accy 26.25, Test_accy 59.38
2022-10-08 07:27:53,276 [foster.py] => do not weight align student!
2022-10-08 07:27:53,933 [foster.py] => darknet eval: 
2022-10-08 07:27:53,933 [foster.py] => CNN top1 curve: 59.38
2022-10-08 07:27:53,933 [foster.py] => CNN top5 curve: 96.88
2022-10-08 07:27:53,933 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 07:28:01,504 [foster.py] => Exemplar size: 240
2022-10-08 07:28:01,505 [trainer.py] => CNN: {'total': 69.44, 'old': 81.56, 'new': 49.54, 'base': 81.56, 'compound': 49.54}
2022-10-08 07:28:01,505 [trainer.py] => CNN top1 curve: [84.36, 69.44]
2022-10-08 07:28:01,505 [trainer.py] => CNN base curve: [84.36, 81.56]
2022-10-08 07:28:01,505 [trainer.py] => CNN old curve: [84.36, 81.56]
2022-10-08 07:28:01,505 [trainer.py] => CNN new curve: [0, 49.54]
2022-10-08 07:28:01,505 [trainer.py] => CNN compound curve: [0, 49.54]
2022-10-08 07:28:01,505 [trainer.py] => NME: {'total': 71.88, 'old': 72.63, 'new': 70.64, 'base': 72.63, 'compound': 70.64}
2022-10-08 07:28:01,505 [trainer.py] => NME top1 curve: [83.24, 71.88]
2022-10-08 07:28:01,505 [trainer.py] => NME base curve: [83.24, 72.63]
2022-10-08 07:28:01,505 [trainer.py] => NME old curve: [83.24, 72.63]
2022-10-08 07:28:01,505 [trainer.py] => NME new curve: [0, 70.64]
2022-10-08 07:28:01,505 [trainer.py] => NME compound curve: [0, 70.64]
2022-10-08 07:28:01,724 [foster.py] => Learning on 12-17
2022-10-08 07:28:01,725 [foster.py] => All params: 22385326
2022-10-08 07:28:01,725 [foster.py] => Trainable params: 11202658
2022-10-08 07:28:01,733 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 07:28:04,969 [foster.py] => Task 2, Epoch 1/34 => Loss 5.870, Loss_clf 2.264, Loss_fe 2.200, Loss_kd 0.992, Train_accy 33.05, Test_accy 43.54
2022-10-08 07:28:07,419 [foster.py] => Task 2, Epoch 2/34 => Loss 4.021, Loss_clf 1.090, Loss_fe 1.582, Loss_kd 0.952, Train_accy 39.30
2022-10-08 07:28:09,877 [foster.py] => Task 2, Epoch 3/34 => Loss 3.703, Loss_clf 0.964, Loss_fe 1.382, Loss_kd 0.957, Train_accy 35.55
2022-10-08 07:28:12,327 [foster.py] => Task 2, Epoch 4/34 => Loss 3.566, Loss_clf 0.936, Loss_fe 1.280, Loss_kd 0.953, Train_accy 37.34
2022-10-08 07:28:14,843 [foster.py] => Task 2, Epoch 5/34 => Loss 3.478, Loss_clf 0.914, Loss_fe 1.209, Loss_kd 0.957, Train_accy 38.20
2022-10-08 07:28:18,131 [foster.py] => Task 2, Epoch 6/34 => Loss 3.372, Loss_clf 0.882, Loss_fe 1.146, Loss_kd 0.948, Train_accy 37.19, Test_accy 50.63
2022-10-08 07:28:20,607 [foster.py] => Task 2, Epoch 7/34 => Loss 3.298, Loss_clf 0.862, Loss_fe 1.084, Loss_kd 0.954, Train_accy 37.97
2022-10-08 07:28:23,097 [foster.py] => Task 2, Epoch 8/34 => Loss 3.257, Loss_clf 0.855, Loss_fe 1.051, Loss_kd 0.954, Train_accy 39.06
2022-10-08 07:28:25,555 [foster.py] => Task 2, Epoch 9/34 => Loss 3.158, Loss_clf 0.818, Loss_fe 0.993, Loss_kd 0.951, Train_accy 37.89
2022-10-08 07:28:28,003 [foster.py] => Task 2, Epoch 10/34 => Loss 3.153, Loss_clf 0.809, Loss_fe 0.988, Loss_kd 0.956, Train_accy 36.88
2022-10-08 07:28:31,343 [foster.py] => Task 2, Epoch 11/34 => Loss 3.073, Loss_clf 0.785, Loss_fe 0.936, Loss_kd 0.954, Train_accy 40.00, Test_accy 51.90
2022-10-08 07:28:33,879 [foster.py] => Task 2, Epoch 12/34 => Loss 3.038, Loss_clf 0.780, Loss_fe 0.911, Loss_kd 0.951, Train_accy 40.39
2022-10-08 07:28:36,390 [foster.py] => Task 2, Epoch 13/34 => Loss 3.021, Loss_clf 0.771, Loss_fe 0.898, Loss_kd 0.955, Train_accy 40.00
2022-10-08 07:28:38,879 [foster.py] => Task 2, Epoch 14/34 => Loss 2.995, Loss_clf 0.770, Loss_fe 0.876, Loss_kd 0.953, Train_accy 42.19
2022-10-08 07:28:41,383 [foster.py] => Task 2, Epoch 15/34 => Loss 2.915, Loss_clf 0.730, Loss_fe 0.836, Loss_kd 0.952, Train_accy 40.08
2022-10-08 07:28:44,719 [foster.py] => Task 2, Epoch 16/34 => Loss 2.921, Loss_clf 0.728, Loss_fe 0.840, Loss_kd 0.955, Train_accy 40.62, Test_accy 51.65
2022-10-08 07:28:47,260 [foster.py] => Task 2, Epoch 17/34 => Loss 2.858, Loss_clf 0.708, Loss_fe 0.802, Loss_kd 0.952, Train_accy 41.64
2022-10-08 07:28:49,693 [foster.py] => Task 2, Epoch 18/34 => Loss 2.868, Loss_clf 0.707, Loss_fe 0.798, Loss_kd 0.962, Train_accy 41.56
2022-10-08 07:28:52,167 [foster.py] => Task 2, Epoch 19/34 => Loss 2.845, Loss_clf 0.697, Loss_fe 0.796, Loss_kd 0.954, Train_accy 42.27
2022-10-08 07:28:54,644 [foster.py] => Task 2, Epoch 20/34 => Loss 2.837, Loss_clf 0.699, Loss_fe 0.783, Loss_kd 0.956, Train_accy 43.05
2022-10-08 07:28:57,946 [foster.py] => Task 2, Epoch 21/34 => Loss 2.777, Loss_clf 0.666, Loss_fe 0.755, Loss_kd 0.957, Train_accy 43.05, Test_accy 52.41
2022-10-08 07:29:00,404 [foster.py] => Task 2, Epoch 22/34 => Loss 2.795, Loss_clf 0.681, Loss_fe 0.764, Loss_kd 0.953, Train_accy 43.44
2022-10-08 07:29:02,901 [foster.py] => Task 2, Epoch 23/34 => Loss 2.772, Loss_clf 0.672, Loss_fe 0.745, Loss_kd 0.956, Train_accy 43.28
2022-10-08 07:29:05,393 [foster.py] => Task 2, Epoch 24/34 => Loss 2.752, Loss_clf 0.667, Loss_fe 0.737, Loss_kd 0.951, Train_accy 44.14
2022-10-08 07:29:07,874 [foster.py] => Task 2, Epoch 25/34 => Loss 2.782, Loss_clf 0.670, Loss_fe 0.754, Loss_kd 0.959, Train_accy 44.61
2022-10-08 07:29:11,148 [foster.py] => Task 2, Epoch 26/34 => Loss 2.749, Loss_clf 0.652, Loss_fe 0.735, Loss_kd 0.961, Train_accy 44.69, Test_accy 53.67
2022-10-08 07:29:13,649 [foster.py] => Task 2, Epoch 27/34 => Loss 2.722, Loss_clf 0.646, Loss_fe 0.724, Loss_kd 0.954, Train_accy 44.92
2022-10-08 07:29:16,185 [foster.py] => Task 2, Epoch 28/34 => Loss 2.685, Loss_clf 0.631, Loss_fe 0.705, Loss_kd 0.952, Train_accy 42.42
2022-10-08 07:29:18,662 [foster.py] => Task 2, Epoch 29/34 => Loss 2.670, Loss_clf 0.618, Loss_fe 0.702, Loss_kd 0.953, Train_accy 44.38
2022-10-08 07:29:21,198 [foster.py] => Task 2, Epoch 30/34 => Loss 2.713, Loss_clf 0.646, Loss_fe 0.714, Loss_kd 0.955, Train_accy 43.98
2022-10-08 07:29:24,499 [foster.py] => Task 2, Epoch 31/34 => Loss 2.701, Loss_clf 0.637, Loss_fe 0.709, Loss_kd 0.956, Train_accy 45.70, Test_accy 53.92
2022-10-08 07:29:26,934 [foster.py] => Task 2, Epoch 32/34 => Loss 2.694, Loss_clf 0.633, Loss_fe 0.709, Loss_kd 0.954, Train_accy 45.16
2022-10-08 07:29:29,431 [foster.py] => Task 2, Epoch 33/34 => Loss 2.704, Loss_clf 0.633, Loss_fe 0.718, Loss_kd 0.955, Train_accy 43.12
2022-10-08 07:29:31,918 [foster.py] => Task 2, Epoch 34/34 => Loss 2.712, Loss_clf 0.640, Loss_fe 0.721, Loss_kd 0.954, Train_accy 43.67
2022-10-08 07:29:31,919 [foster.py] => do not weight align teacher!
2022-10-08 07:29:31,919 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 07:29:35,683 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.101,  Train_accy 11.95, Test_accy 42.78
2022-10-08 07:29:38,568 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 2.009,  Train_accy 12.97
2022-10-08 07:29:41,408 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.981,  Train_accy 12.89
2022-10-08 07:29:44,267 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.952,  Train_accy 13.12
2022-10-08 07:29:47,104 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.938,  Train_accy 12.81
2022-10-08 07:29:50,674 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.920,  Train_accy 12.73, Test_accy 46.33
2022-10-08 07:29:53,529 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.919,  Train_accy 13.36
2022-10-08 07:29:56,367 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.908,  Train_accy 12.97
2022-10-08 07:29:59,214 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.911,  Train_accy 12.97
2022-10-08 07:30:02,107 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.897,  Train_accy 13.05
2022-10-08 07:30:05,718 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.901,  Train_accy 13.52, Test_accy 47.34
2022-10-08 07:30:08,579 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.904,  Train_accy 13.52
2022-10-08 07:30:11,448 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.894,  Train_accy 13.44
2022-10-08 07:30:14,278 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.896,  Train_accy 13.75
2022-10-08 07:30:17,126 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.887,  Train_accy 13.05
2022-10-08 07:30:20,763 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.899,  Train_accy 13.20, Test_accy 47.85
2022-10-08 07:30:23,640 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.896,  Train_accy 13.67
2022-10-08 07:30:26,491 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.898,  Train_accy 13.59
2022-10-08 07:30:29,335 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.880,  Train_accy 13.28
2022-10-08 07:30:32,206 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.891,  Train_accy 13.98
2022-10-08 07:30:35,790 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.880,  Train_accy 13.75, Test_accy 47.59
2022-10-08 07:30:38,629 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.879,  Train_accy 13.52
2022-10-08 07:30:41,441 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.880,  Train_accy 14.14
2022-10-08 07:30:44,353 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.885,  Train_accy 14.38
2022-10-08 07:30:47,237 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.881,  Train_accy 13.67
2022-10-08 07:30:50,846 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.889,  Train_accy 13.28, Test_accy 47.59
2022-10-08 07:30:50,846 [foster.py] => do not weight align student!
2022-10-08 07:30:51,544 [foster.py] => darknet eval: 
2022-10-08 07:30:51,544 [foster.py] => CNN top1 curve: 47.59
2022-10-08 07:30:51,544 [foster.py] => CNN top5 curve: 92.91
2022-10-08 07:30:51,545 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 07:31:00,807 [foster.py] => Exemplar size: 340
2022-10-08 07:31:00,807 [trainer.py] => CNN: {'total': 54.18, 'old': 65.28, 'new': 24.3, 'base': 78.77, 'compound': 33.8}
2022-10-08 07:31:00,807 [trainer.py] => CNN top1 curve: [84.36, 69.44, 54.18]
2022-10-08 07:31:00,807 [trainer.py] => CNN base curve: [84.36, 81.56, 78.77]
2022-10-08 07:31:00,807 [trainer.py] => CNN old curve: [84.36, 81.56, 65.28]
2022-10-08 07:31:00,807 [trainer.py] => CNN new curve: [0, 49.54, 24.3]
2022-10-08 07:31:00,807 [trainer.py] => CNN compound curve: [0, 49.54, 33.8]
2022-10-08 07:31:00,807 [trainer.py] => NME: {'total': 60.25, 'old': 63.19, 'new': 52.34, 'base': 63.13, 'compound': 57.87}
2022-10-08 07:31:00,807 [trainer.py] => NME top1 curve: [83.24, 71.88, 60.25]
2022-10-08 07:31:00,807 [trainer.py] => NME base curve: [83.24, 72.63, 63.13]
2022-10-08 07:31:00,807 [trainer.py] => NME old curve: [83.24, 72.63, 63.19]
2022-10-08 07:31:00,807 [trainer.py] => NME new curve: [0, 70.64, 52.34]
2022-10-08 07:31:00,807 [trainer.py] => NME compound curve: [0, 70.64, 57.87]
2022-10-08 07:31:01,024 [foster.py] => Learning on 17-22
2022-10-08 07:31:01,025 [foster.py] => All params: 22395581
2022-10-08 07:31:01,025 [foster.py] => Trainable params: 11210348
2022-10-08 07:31:01,034 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 07:31:04,550 [foster.py] => Task 3, Epoch 1/34 => Loss 6.564, Loss_clf 2.268, Loss_fe 2.439, Loss_kd 1.435, Train_accy 28.92, Test_accy 41.78
2022-10-08 07:31:07,134 [foster.py] => Task 3, Epoch 2/34 => Loss 4.801, Loss_clf 1.220, Loss_fe 1.750, Loss_kd 1.415, Train_accy 29.29
2022-10-08 07:31:09,747 [foster.py] => Task 3, Epoch 3/34 => Loss 4.537, Loss_clf 1.128, Loss_fe 1.574, Loss_kd 1.418, Train_accy 30.96
2022-10-08 07:31:12,334 [foster.py] => Task 3, Epoch 4/34 => Loss 4.369, Loss_clf 1.075, Loss_fe 1.460, Loss_kd 1.417, Train_accy 31.69
2022-10-08 07:31:15,014 [foster.py] => Task 3, Epoch 5/34 => Loss 4.262, Loss_clf 1.054, Loss_fe 1.387, Loss_kd 1.407, Train_accy 31.18
2022-10-08 07:31:18,586 [foster.py] => Task 3, Epoch 6/34 => Loss 4.145, Loss_clf 1.019, Loss_fe 1.314, Loss_kd 1.400, Train_accy 31.25, Test_accy 44.16
2022-10-08 07:31:21,211 [foster.py] => Task 3, Epoch 7/34 => Loss 4.094, Loss_clf 0.996, Loss_fe 1.267, Loss_kd 1.415, Train_accy 32.49
2022-10-08 07:31:23,780 [foster.py] => Task 3, Epoch 8/34 => Loss 4.015, Loss_clf 0.984, Loss_fe 1.212, Loss_kd 1.405, Train_accy 31.54
2022-10-08 07:31:26,364 [foster.py] => Task 3, Epoch 9/34 => Loss 3.984, Loss_clf 0.992, Loss_fe 1.182, Loss_kd 1.399, Train_accy 31.90
2022-10-08 07:31:28,967 [foster.py] => Task 3, Epoch 10/34 => Loss 3.932, Loss_clf 0.966, Loss_fe 1.148, Loss_kd 1.405, Train_accy 33.14
2022-10-08 07:31:32,529 [foster.py] => Task 3, Epoch 11/34 => Loss 3.906, Loss_clf 0.954, Loss_fe 1.124, Loss_kd 1.413, Train_accy 34.23, Test_accy 46.14
2022-10-08 07:31:35,121 [foster.py] => Task 3, Epoch 12/34 => Loss 3.789, Loss_clf 0.909, Loss_fe 1.061, Loss_kd 1.405, Train_accy 33.21
2022-10-08 07:31:37,790 [foster.py] => Task 3, Epoch 13/34 => Loss 3.807, Loss_clf 0.919, Loss_fe 1.065, Loss_kd 1.408, Train_accy 32.12
2022-10-08 07:31:40,433 [foster.py] => Task 3, Epoch 14/34 => Loss 3.741, Loss_clf 0.888, Loss_fe 1.024, Loss_kd 1.414, Train_accy 34.81
2022-10-08 07:31:43,082 [foster.py] => Task 3, Epoch 15/34 => Loss 3.718, Loss_clf 0.886, Loss_fe 1.006, Loss_kd 1.411, Train_accy 33.65
2022-10-08 07:31:46,653 [foster.py] => Task 3, Epoch 16/34 => Loss 3.695, Loss_clf 0.878, Loss_fe 0.990, Loss_kd 1.411, Train_accy 33.36, Test_accy 47.33
2022-10-08 07:31:49,300 [foster.py] => Task 3, Epoch 17/34 => Loss 3.645, Loss_clf 0.855, Loss_fe 0.969, Loss_kd 1.407, Train_accy 35.68
2022-10-08 07:31:51,884 [foster.py] => Task 3, Epoch 18/34 => Loss 3.668, Loss_clf 0.869, Loss_fe 0.971, Loss_kd 1.413, Train_accy 34.38
2022-10-08 07:31:54,543 [foster.py] => Task 3, Epoch 19/34 => Loss 3.642, Loss_clf 0.857, Loss_fe 0.961, Loss_kd 1.410, Train_accy 35.17
2022-10-08 07:31:57,101 [foster.py] => Task 3, Epoch 20/34 => Loss 3.602, Loss_clf 0.841, Loss_fe 0.936, Loss_kd 1.411, Train_accy 33.58
2022-10-08 07:32:00,620 [foster.py] => Task 3, Epoch 21/34 => Loss 3.600, Loss_clf 0.841, Loss_fe 0.929, Loss_kd 1.413, Train_accy 37.57, Test_accy 46.73
2022-10-08 07:32:03,228 [foster.py] => Task 3, Epoch 22/34 => Loss 3.622, Loss_clf 0.847, Loss_fe 0.941, Loss_kd 1.418, Train_accy 34.38
2022-10-08 07:32:05,862 [foster.py] => Task 3, Epoch 23/34 => Loss 3.570, Loss_clf 0.827, Loss_fe 0.914, Loss_kd 1.414, Train_accy 34.30
2022-10-08 07:32:08,515 [foster.py] => Task 3, Epoch 24/34 => Loss 3.569, Loss_clf 0.830, Loss_fe 0.912, Loss_kd 1.411, Train_accy 37.50
2022-10-08 07:32:11,091 [foster.py] => Task 3, Epoch 25/34 => Loss 3.559, Loss_clf 0.819, Loss_fe 0.908, Loss_kd 1.416, Train_accy 37.72
2022-10-08 07:32:14,629 [foster.py] => Task 3, Epoch 26/34 => Loss 3.556, Loss_clf 0.820, Loss_fe 0.904, Loss_kd 1.416, Train_accy 35.17, Test_accy 47.92
2022-10-08 07:32:17,319 [foster.py] => Task 3, Epoch 27/34 => Loss 3.547, Loss_clf 0.820, Loss_fe 0.898, Loss_kd 1.413, Train_accy 35.03
2022-10-08 07:32:19,917 [foster.py] => Task 3, Epoch 28/34 => Loss 3.539, Loss_clf 0.814, Loss_fe 0.895, Loss_kd 1.414, Train_accy 36.26
2022-10-08 07:32:22,613 [foster.py] => Task 3, Epoch 29/34 => Loss 3.541, Loss_clf 0.811, Loss_fe 0.900, Loss_kd 1.414, Train_accy 36.63
2022-10-08 07:32:25,272 [foster.py] => Task 3, Epoch 30/34 => Loss 3.517, Loss_clf 0.797, Loss_fe 0.893, Loss_kd 1.412, Train_accy 36.41
2022-10-08 07:32:28,819 [foster.py] => Task 3, Epoch 31/34 => Loss 3.538, Loss_clf 0.810, Loss_fe 0.905, Loss_kd 1.408, Train_accy 37.43, Test_accy 47.52
2022-10-08 07:32:31,533 [foster.py] => Task 3, Epoch 32/34 => Loss 3.536, Loss_clf 0.812, Loss_fe 0.892, Loss_kd 1.415, Train_accy 35.10
2022-10-08 07:32:34,107 [foster.py] => Task 3, Epoch 33/34 => Loss 3.523, Loss_clf 0.807, Loss_fe 0.887, Loss_kd 1.414, Train_accy 36.26
2022-10-08 07:32:36,801 [foster.py] => Task 3, Epoch 34/34 => Loss 3.520, Loss_clf 0.805, Loss_fe 0.886, Loss_kd 1.413, Train_accy 35.97
2022-10-08 07:32:36,801 [foster.py] => do not weight align teacher!
2022-10-08 07:32:36,802 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 07:32:40,829 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.343,  Train_accy 12.57, Test_accy 38.22
2022-10-08 07:32:43,807 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.291,  Train_accy 13.59
2022-10-08 07:32:46,812 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.276,  Train_accy 13.23
2022-10-08 07:32:49,785 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.255,  Train_accy 13.08
2022-10-08 07:32:52,828 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.248,  Train_accy 13.15
2022-10-08 07:32:56,632 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.241,  Train_accy 13.44, Test_accy 38.81
2022-10-08 07:32:59,681 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.230,  Train_accy 13.44
2022-10-08 07:33:02,698 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.223,  Train_accy 13.81
2022-10-08 07:33:05,695 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.219,  Train_accy 13.66
2022-10-08 07:33:08,767 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.217,  Train_accy 14.03
2022-10-08 07:33:12,588 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.202,  Train_accy 14.61, Test_accy 39.60
2022-10-08 07:33:15,555 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.204,  Train_accy 15.55
2022-10-08 07:33:21,285 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.202,  Train_accy 15.04
2022-10-08 07:33:25,075 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.201,  Train_accy 14.39
2022-10-08 07:33:28,349 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.201,  Train_accy 15.04
2022-10-08 07:33:32,271 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.207,  Train_accy 14.61, Test_accy 40.40
2022-10-08 07:33:35,251 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.206,  Train_accy 14.39
2022-10-08 07:33:38,200 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.193,  Train_accy 15.04
2022-10-08 07:33:41,130 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.194,  Train_accy 15.04
2022-10-08 07:33:44,091 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.191,  Train_accy 15.26
2022-10-08 07:33:47,896 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.198,  Train_accy 15.92, Test_accy 40.59
2022-10-08 07:33:50,865 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.194,  Train_accy 15.48
2022-10-08 07:33:53,877 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.190,  Train_accy 16.42
2022-10-08 07:33:56,887 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.198,  Train_accy 15.62
2022-10-08 07:33:59,904 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.188,  Train_accy 16.13
2022-10-08 07:34:03,685 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.192,  Train_accy 15.48, Test_accy 40.59
2022-10-08 07:34:03,685 [foster.py] => do not weight align student!
2022-10-08 07:34:04,458 [foster.py] => darknet eval: 
2022-10-08 07:34:04,458 [foster.py] => CNN top1 curve: 40.59
2022-10-08 07:34:04,458 [foster.py] => CNN top5 curve: 83.96
2022-10-08 07:34:04,459 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 07:34:15,433 [foster.py] => Exemplar size: 440
2022-10-08 07:34:15,433 [trainer.py] => CNN: {'total': 47.33, 'old': 52.91, 'new': 27.27, 'base': 76.54, 'compound': 31.29}
2022-10-08 07:34:15,433 [trainer.py] => CNN top1 curve: [84.36, 69.44, 54.18, 47.33]
2022-10-08 07:34:15,433 [trainer.py] => CNN base curve: [84.36, 81.56, 78.77, 76.54]
2022-10-08 07:34:15,433 [trainer.py] => CNN old curve: [84.36, 81.56, 65.28, 52.91]
2022-10-08 07:34:15,433 [trainer.py] => CNN new curve: [0, 49.54, 24.3, 27.27]
2022-10-08 07:34:15,433 [trainer.py] => CNN compound curve: [0, 49.54, 33.8, 31.29]
2022-10-08 07:34:15,433 [trainer.py] => NME: {'total': 54.06, 'old': 57.47, 'new': 41.82, 'base': 64.8, 'compound': 48.16}
2022-10-08 07:34:15,433 [trainer.py] => NME top1 curve: [83.24, 71.88, 60.25, 54.06]
2022-10-08 07:34:15,433 [trainer.py] => NME base curve: [83.24, 72.63, 63.13, 64.8]
2022-10-08 07:34:15,433 [trainer.py] => NME old curve: [83.24, 72.63, 63.19, 57.47]
2022-10-08 07:34:15,433 [trainer.py] => NME new curve: [0, 70.64, 52.34, 41.82]
2022-10-08 07:34:15,433 [trainer.py] => NME compound curve: [0, 70.64, 57.87, 48.16]
2022-10-08 07:34:15,434 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 07:34:15,434 [trainer.py] => prefix: cil
2022-10-08 07:34:15,434 [trainer.py] => dataset: CFEE
2022-10-08 07:34:15,434 [trainer.py] => memory_size: 2000
2022-10-08 07:34:15,435 [trainer.py] => memory_per_class: 20
2022-10-08 07:34:15,435 [trainer.py] => fixed_memory: True
2022-10-08 07:34:15,435 [trainer.py] => shuffle: True
2022-10-08 07:34:15,435 [trainer.py] => init_cls: 7
2022-10-08 07:34:15,435 [trainer.py] => increment: 5
2022-10-08 07:34:15,435 [trainer.py] => model_name: foster
2022-10-08 07:34:15,435 [trainer.py] => convnet_type: resnet18
2022-10-08 07:34:15,435 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 07:34:15,435 [trainer.py] => seed: 1993
2022-10-08 07:34:15,435 [trainer.py] => beta1: 0.96
2022-10-08 07:34:15,435 [trainer.py] => beta2: 0.97
2022-10-08 07:34:15,435 [trainer.py] => oofc: ft
2022-10-08 07:34:15,435 [trainer.py] => is_teacher_wa: False
2022-10-08 07:34:15,435 [trainer.py] => is_student_wa: False
2022-10-08 07:34:15,435 [trainer.py] => lambda_okd: 1
2022-10-08 07:34:15,435 [trainer.py] => wa_value: 1
2022-10-08 07:34:15,435 [trainer.py] => init_epochs: 40
2022-10-08 07:34:15,435 [trainer.py] => init_lr: 0.01
2022-10-08 07:34:15,435 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 07:34:15,435 [trainer.py] => boosting_epochs: 34
2022-10-08 07:34:15,435 [trainer.py] => compression_epochs: 26
2022-10-08 07:34:15,435 [trainer.py] => lr: 0.001
2022-10-08 07:34:15,435 [trainer.py] => batch_size: 32
2022-10-08 07:34:15,435 [trainer.py] => weight_decay: 0.0005
2022-10-08 07:34:15,435 [trainer.py] => num_workers: 8
2022-10-08 07:34:15,435 [trainer.py] => T: 2
2022-10-08 07:34:15,435 [trainer.py] => nb_runs: 3
2022-10-08 07:34:15,435 [trainer.py] => fold: 10
2022-10-08 07:34:15,436 [data.py] => ========== Fold:4 ==========
2022-10-08 07:34:15,441 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 8, 15, 13, 17, 9, 11, 19, 21, 14, 10, 18, 12, 7, 16]
2022-10-08 07:34:15,650 [foster.py] => Learning on 0-7
2022-10-08 07:34:15,651 [foster.py] => All params: 11183694
2022-10-08 07:34:15,651 [foster.py] => Trainable params: 11183694
2022-10-08 07:34:17,899 [foster.py] => Task 0, Epoch 1/40 => Loss 1.330, Train_accy 51.61
2022-10-08 07:34:20,734 [foster.py] => Task 0, Epoch 2/40 => Loss 0.520, Train_accy 83.39, Test_accy 84.72
2022-10-08 07:34:23,545 [foster.py] => Task 0, Epoch 3/40 => Loss 0.336, Train_accy 89.06, Test_accy 83.33
2022-10-08 07:34:26,354 [foster.py] => Task 0, Epoch 4/40 => Loss 0.283, Train_accy 90.50, Test_accy 83.33
2022-10-08 07:34:29,210 [foster.py] => Task 0, Epoch 5/40 => Loss 0.199, Train_accy 93.78, Test_accy 84.03
2022-10-08 07:34:31,492 [foster.py] => Task 0, Epoch 6/40 => Loss 0.178, Train_accy 94.26
2022-10-08 07:34:34,330 [foster.py] => Task 0, Epoch 7/40 => Loss 0.164, Train_accy 93.98, Test_accy 84.72
2022-10-08 07:34:37,193 [foster.py] => Task 0, Epoch 8/40 => Loss 0.123, Train_accy 96.17, Test_accy 86.11
2022-10-08 07:34:40,031 [foster.py] => Task 0, Epoch 9/40 => Loss 0.112, Train_accy 96.24, Test_accy 86.11
2022-10-08 07:34:42,827 [foster.py] => Task 0, Epoch 10/40 => Loss 0.086, Train_accy 97.74, Test_accy 85.42
2022-10-08 07:34:45,084 [foster.py] => Task 0, Epoch 11/40 => Loss 0.089, Train_accy 97.33
2022-10-08 07:34:47,964 [foster.py] => Task 0, Epoch 12/40 => Loss 0.067, Train_accy 98.02, Test_accy 84.72
2022-10-08 07:34:50,754 [foster.py] => Task 0, Epoch 13/40 => Loss 0.053, Train_accy 98.43, Test_accy 84.03
2022-10-08 07:34:53,589 [foster.py] => Task 0, Epoch 14/40 => Loss 0.057, Train_accy 98.15, Test_accy 82.64
2022-10-08 07:34:56,448 [foster.py] => Task 0, Epoch 15/40 => Loss 0.045, Train_accy 98.97, Test_accy 84.72
2022-10-08 07:34:58,740 [foster.py] => Task 0, Epoch 16/40 => Loss 0.041, Train_accy 99.04
2022-10-08 07:35:01,564 [foster.py] => Task 0, Epoch 17/40 => Loss 0.042, Train_accy 98.77, Test_accy 85.42
2022-10-08 07:35:04,386 [foster.py] => Task 0, Epoch 18/40 => Loss 0.041, Train_accy 98.70, Test_accy 83.33
2022-10-08 07:35:07,226 [foster.py] => Task 0, Epoch 19/40 => Loss 0.027, Train_accy 99.59, Test_accy 84.03
2022-10-08 07:35:10,091 [foster.py] => Task 0, Epoch 20/40 => Loss 0.022, Train_accy 99.66, Test_accy 85.42
2022-10-08 07:35:12,355 [foster.py] => Task 0, Epoch 21/40 => Loss 0.025, Train_accy 99.59
2022-10-08 07:35:15,152 [foster.py] => Task 0, Epoch 22/40 => Loss 0.021, Train_accy 99.59, Test_accy 85.42
2022-10-08 07:35:17,971 [foster.py] => Task 0, Epoch 23/40 => Loss 0.020, Train_accy 99.79, Test_accy 84.72
2022-10-08 07:35:20,781 [foster.py] => Task 0, Epoch 24/40 => Loss 0.022, Train_accy 99.66, Test_accy 87.50
2022-10-08 07:35:23,631 [foster.py] => Task 0, Epoch 25/40 => Loss 0.016, Train_accy 99.73, Test_accy 86.11
2022-10-08 07:35:25,931 [foster.py] => Task 0, Epoch 26/40 => Loss 0.019, Train_accy 99.73
2022-10-08 07:35:28,735 [foster.py] => Task 0, Epoch 27/40 => Loss 0.018, Train_accy 99.73, Test_accy 85.42
2022-10-08 07:35:31,557 [foster.py] => Task 0, Epoch 28/40 => Loss 0.019, Train_accy 99.59, Test_accy 86.11
2022-10-08 07:35:34,406 [foster.py] => Task 0, Epoch 29/40 => Loss 0.017, Train_accy 99.79, Test_accy 86.11
2022-10-08 07:35:37,231 [foster.py] => Task 0, Epoch 30/40 => Loss 0.017, Train_accy 99.59, Test_accy 85.42
2022-10-08 07:35:39,509 [foster.py] => Task 0, Epoch 31/40 => Loss 0.015, Train_accy 99.86
2022-10-08 07:35:42,343 [foster.py] => Task 0, Epoch 32/40 => Loss 0.015, Train_accy 99.79, Test_accy 85.42
2022-10-08 07:35:45,198 [foster.py] => Task 0, Epoch 33/40 => Loss 0.012, Train_accy 99.93, Test_accy 85.42
2022-10-08 07:35:48,023 [foster.py] => Task 0, Epoch 34/40 => Loss 0.012, Train_accy 99.93, Test_accy 85.42
2022-10-08 07:35:50,950 [foster.py] => Task 0, Epoch 35/40 => Loss 0.014, Train_accy 99.66, Test_accy 85.42
2022-10-08 07:35:53,237 [foster.py] => Task 0, Epoch 36/40 => Loss 0.011, Train_accy 99.86
2022-10-08 07:35:56,114 [foster.py] => Task 0, Epoch 37/40 => Loss 0.015, Train_accy 99.73, Test_accy 86.81
2022-10-08 07:35:58,951 [foster.py] => Task 0, Epoch 38/40 => Loss 0.011, Train_accy 99.93, Test_accy 85.42
2022-10-08 07:36:01,812 [foster.py] => Task 0, Epoch 39/40 => Loss 0.014, Train_accy 99.73, Test_accy 85.42
2022-10-08 07:36:04,656 [foster.py] => Task 0, Epoch 40/40 => Loss 0.014, Train_accy 99.86, Test_accy 86.11
2022-10-08 07:36:04,656 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 07:36:10,936 [foster.py] => Exemplar size: 140
2022-10-08 07:36:10,936 [trainer.py] => CNN: {'total': 86.11, 'old': 86.11, 'new': 0, 'base': 86.11, 'compound': 0}
2022-10-08 07:36:10,936 [trainer.py] => CNN top1 curve: [86.11]
2022-10-08 07:36:10,936 [trainer.py] => CNN base curve: [86.11]
2022-10-08 07:36:10,936 [trainer.py] => CNN old curve: [86.11]
2022-10-08 07:36:10,936 [trainer.py] => CNN new curve: [0]
2022-10-08 07:36:10,936 [trainer.py] => CNN compound curve: [0]
2022-10-08 07:36:10,937 [trainer.py] => NME: {'total': 86.81, 'old': 86.81, 'new': 0, 'base': 86.81, 'compound': 0}
2022-10-08 07:36:10,937 [trainer.py] => NME top1 curve: [86.81]
2022-10-08 07:36:10,937 [trainer.py] => NME base curve: [86.81]
2022-10-08 07:36:10,937 [trainer.py] => NME old curve: [86.81]
2022-10-08 07:36:10,937 [trainer.py] => NME new curve: [0]
2022-10-08 07:36:10,937 [trainer.py] => NME compound curve: [0]
2022-10-08 07:36:11,156 [foster.py] => Learning on 7-12
2022-10-08 07:36:11,156 [foster.py] => All params: 22375071
2022-10-08 07:36:11,156 [foster.py] => Trainable params: 11194968
2022-10-08 07:36:11,165 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 07:36:14,152 [foster.py] => Task 1, Epoch 1/34 => Loss 4.739, Loss_clf 2.060, Loss_fe 1.952, Loss_kd 0.424, Train_accy 39.69, Test_accy 71.48
2022-10-08 07:36:16,397 [foster.py] => Task 1, Epoch 2/34 => Loss 2.460, Loss_clf 0.641, Loss_fe 1.136, Loss_kd 0.398, Train_accy 67.55
2022-10-08 07:36:18,661 [foster.py] => Task 1, Epoch 3/34 => Loss 2.136, Loss_clf 0.530, Loss_fe 0.928, Loss_kd 0.395, Train_accy 57.16
2022-10-08 07:36:20,949 [foster.py] => Task 1, Epoch 4/34 => Loss 1.946, Loss_clf 0.462, Loss_fe 0.811, Loss_kd 0.392, Train_accy 56.39
2022-10-08 07:36:23,234 [foster.py] => Task 1, Epoch 5/34 => Loss 1.864, Loss_clf 0.451, Loss_fe 0.742, Loss_kd 0.391, Train_accy 56.64
2022-10-08 07:36:26,248 [foster.py] => Task 1, Epoch 6/34 => Loss 1.770, Loss_clf 0.422, Loss_fe 0.676, Loss_kd 0.392, Train_accy 57.58, Test_accy 67.97
2022-10-08 07:36:28,538 [foster.py] => Task 1, Epoch 7/34 => Loss 1.748, Loss_clf 0.431, Loss_fe 0.652, Loss_kd 0.388, Train_accy 54.17
2022-10-08 07:36:30,863 [foster.py] => Task 1, Epoch 8/34 => Loss 1.674, Loss_clf 0.401, Loss_fe 0.603, Loss_kd 0.390, Train_accy 57.16
2022-10-08 07:36:33,134 [foster.py] => Task 1, Epoch 9/34 => Loss 1.605, Loss_clf 0.373, Loss_fe 0.562, Loss_kd 0.391, Train_accy 58.60
2022-10-08 07:36:35,441 [foster.py] => Task 1, Epoch 10/34 => Loss 1.587, Loss_clf 0.378, Loss_fe 0.537, Loss_kd 0.392, Train_accy 58.52
2022-10-08 07:36:38,497 [foster.py] => Task 1, Epoch 11/34 => Loss 1.571, Loss_clf 0.368, Loss_fe 0.528, Loss_kd 0.394, Train_accy 59.54, Test_accy 69.53
2022-10-08 07:36:40,787 [foster.py] => Task 1, Epoch 12/34 => Loss 1.510, Loss_clf 0.344, Loss_fe 0.496, Loss_kd 0.391, Train_accy 60.22
2022-10-08 07:36:43,106 [foster.py] => Task 1, Epoch 13/34 => Loss 1.491, Loss_clf 0.337, Loss_fe 0.482, Loss_kd 0.392, Train_accy 59.97
2022-10-08 07:36:45,393 [foster.py] => Task 1, Epoch 14/34 => Loss 1.479, Loss_clf 0.335, Loss_fe 0.476, Loss_kd 0.390, Train_accy 61.50
2022-10-08 07:36:47,729 [foster.py] => Task 1, Epoch 15/34 => Loss 1.469, Loss_clf 0.337, Loss_fe 0.458, Loss_kd 0.393, Train_accy 61.50
2022-10-08 07:36:50,781 [foster.py] => Task 1, Epoch 16/34 => Loss 1.415, Loss_clf 0.313, Loss_fe 0.443, Loss_kd 0.385, Train_accy 60.14, Test_accy 70.31
2022-10-08 07:36:53,096 [foster.py] => Task 1, Epoch 17/34 => Loss 1.429, Loss_clf 0.310, Loss_fe 0.435, Loss_kd 0.398, Train_accy 60.90
2022-10-08 07:36:55,376 [foster.py] => Task 1, Epoch 18/34 => Loss 1.394, Loss_clf 0.301, Loss_fe 0.419, Loss_kd 0.393, Train_accy 60.65
2022-10-08 07:36:57,697 [foster.py] => Task 1, Epoch 19/34 => Loss 1.352, Loss_clf 0.283, Loss_fe 0.397, Loss_kd 0.392, Train_accy 63.20
2022-10-08 07:36:59,971 [foster.py] => Task 1, Epoch 20/34 => Loss 1.350, Loss_clf 0.287, Loss_fe 0.392, Loss_kd 0.392, Train_accy 62.10
2022-10-08 07:37:03,056 [foster.py] => Task 1, Epoch 21/34 => Loss 1.370, Loss_clf 0.296, Loss_fe 0.397, Loss_kd 0.395, Train_accy 62.52, Test_accy 69.92
2022-10-08 07:37:05,372 [foster.py] => Task 1, Epoch 22/34 => Loss 1.336, Loss_clf 0.278, Loss_fe 0.387, Loss_kd 0.392, Train_accy 63.63
2022-10-08 07:37:07,727 [foster.py] => Task 1, Epoch 23/34 => Loss 1.326, Loss_clf 0.274, Loss_fe 0.385, Loss_kd 0.390, Train_accy 62.35
2022-10-08 07:37:10,040 [foster.py] => Task 1, Epoch 24/34 => Loss 1.325, Loss_clf 0.274, Loss_fe 0.375, Loss_kd 0.394, Train_accy 63.88
2022-10-08 07:37:12,370 [foster.py] => Task 1, Epoch 25/34 => Loss 1.311, Loss_clf 0.269, Loss_fe 0.372, Loss_kd 0.391, Train_accy 62.95
2022-10-08 07:37:15,399 [foster.py] => Task 1, Epoch 26/34 => Loss 1.334, Loss_clf 0.280, Loss_fe 0.384, Loss_kd 0.391, Train_accy 62.61, Test_accy 69.92
2022-10-08 07:37:17,700 [foster.py] => Task 1, Epoch 27/34 => Loss 1.328, Loss_clf 0.277, Loss_fe 0.383, Loss_kd 0.390, Train_accy 62.35
2022-10-08 07:37:20,082 [foster.py] => Task 1, Epoch 28/34 => Loss 1.329, Loss_clf 0.280, Loss_fe 0.385, Loss_kd 0.388, Train_accy 61.67
2022-10-08 07:37:22,407 [foster.py] => Task 1, Epoch 29/34 => Loss 1.347, Loss_clf 0.282, Loss_fe 0.391, Loss_kd 0.393, Train_accy 62.52
2022-10-08 07:37:24,750 [foster.py] => Task 1, Epoch 30/34 => Loss 1.353, Loss_clf 0.282, Loss_fe 0.389, Loss_kd 0.398, Train_accy 64.65
2022-10-08 07:37:27,763 [foster.py] => Task 1, Epoch 31/34 => Loss 1.296, Loss_clf 0.264, Loss_fe 0.365, Loss_kd 0.389, Train_accy 62.27, Test_accy 70.31
2022-10-08 07:37:30,090 [foster.py] => Task 1, Epoch 32/34 => Loss 1.293, Loss_clf 0.267, Loss_fe 0.357, Loss_kd 0.390, Train_accy 63.63
2022-10-08 07:37:32,403 [foster.py] => Task 1, Epoch 33/34 => Loss 1.276, Loss_clf 0.256, Loss_fe 0.355, Loss_kd 0.388, Train_accy 62.10
2022-10-08 07:37:34,691 [foster.py] => Task 1, Epoch 34/34 => Loss 1.302, Loss_clf 0.263, Loss_fe 0.362, Loss_kd 0.395, Train_accy 63.88
2022-10-08 07:37:34,691 [foster.py] => do not weight align teacher!
2022-10-08 07:37:34,692 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 07:37:38,175 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.861,  Train_accy 11.75, Test_accy 47.27
2022-10-08 07:37:40,840 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.658,  Train_accy 11.93
2022-10-08 07:37:43,488 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.591,  Train_accy 13.46
2022-10-08 07:37:46,151 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.549,  Train_accy 17.21
2022-10-08 07:37:48,804 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.524,  Train_accy 18.48
2022-10-08 07:37:52,089 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.502,  Train_accy 20.87, Test_accy 50.78
2022-10-08 07:37:54,726 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.486,  Train_accy 22.83
2022-10-08 07:37:57,334 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.465,  Train_accy 23.08
2022-10-08 07:37:59,971 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.455,  Train_accy 24.11
2022-10-08 07:38:02,639 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.452,  Train_accy 24.45
2022-10-08 07:38:05,880 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.438,  Train_accy 27.68, Test_accy 53.91
2022-10-08 07:38:08,564 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.440,  Train_accy 28.19
2022-10-08 07:38:11,264 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.427,  Train_accy 26.24
2022-10-08 07:38:13,964 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.417,  Train_accy 28.28
2022-10-08 07:38:16,589 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.416,  Train_accy 28.28
2022-10-08 07:38:19,886 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.415,  Train_accy 30.24, Test_accy 55.86
2022-10-08 07:38:22,547 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.409,  Train_accy 28.88
2022-10-08 07:38:25,192 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.398,  Train_accy 30.75
2022-10-08 07:38:27,848 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.403,  Train_accy 30.66
2022-10-08 07:38:30,465 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.407,  Train_accy 29.30
2022-10-08 07:38:33,775 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.398,  Train_accy 29.98, Test_accy 55.86
2022-10-08 07:38:36,418 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.401,  Train_accy 29.47
2022-10-08 07:38:39,074 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.405,  Train_accy 30.92
2022-10-08 07:38:41,708 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.404,  Train_accy 31.01
2022-10-08 07:38:44,374 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.413,  Train_accy 30.15
2022-10-08 07:38:47,762 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.413,  Train_accy 31.43, Test_accy 57.03
2022-10-08 07:38:47,763 [foster.py] => do not weight align student!
2022-10-08 07:38:48,451 [foster.py] => darknet eval: 
2022-10-08 07:38:48,451 [foster.py] => CNN top1 curve: 57.03
2022-10-08 07:38:48,452 [foster.py] => CNN top5 curve: 97.66
2022-10-08 07:38:48,452 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 07:38:56,067 [foster.py] => Exemplar size: 240
2022-10-08 07:38:56,067 [trainer.py] => CNN: {'total': 69.92, 'old': 82.64, 'new': 53.57, 'base': 82.64, 'compound': 53.57}
2022-10-08 07:38:56,067 [trainer.py] => CNN top1 curve: [86.11, 69.92]
2022-10-08 07:38:56,067 [trainer.py] => CNN base curve: [86.11, 82.64]
2022-10-08 07:38:56,067 [trainer.py] => CNN old curve: [86.11, 82.64]
2022-10-08 07:38:56,067 [trainer.py] => CNN new curve: [0, 53.57]
2022-10-08 07:38:56,067 [trainer.py] => CNN compound curve: [0, 53.57]
2022-10-08 07:38:56,067 [trainer.py] => NME: {'total': 82.42, 'old': 84.03, 'new': 80.36, 'base': 84.03, 'compound': 80.36}
2022-10-08 07:38:56,067 [trainer.py] => NME top1 curve: [86.81, 82.42]
2022-10-08 07:38:56,067 [trainer.py] => NME base curve: [86.81, 84.03]
2022-10-08 07:38:56,067 [trainer.py] => NME old curve: [86.81, 84.03]
2022-10-08 07:38:56,067 [trainer.py] => NME new curve: [0, 80.36]
2022-10-08 07:38:56,067 [trainer.py] => NME compound curve: [0, 80.36]
2022-10-08 07:38:56,288 [foster.py] => Learning on 12-17
2022-10-08 07:38:56,289 [foster.py] => All params: 22385326
2022-10-08 07:38:56,289 [foster.py] => Trainable params: 11202658
2022-10-08 07:38:56,298 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 07:38:59,630 [foster.py] => Task 2, Epoch 1/34 => Loss 5.783, Loss_clf 2.183, Loss_fe 2.199, Loss_kd 0.989, Train_accy 34.96, Test_accy 44.15
2022-10-08 07:39:02,058 [foster.py] => Task 2, Epoch 2/34 => Loss 3.973, Loss_clf 1.058, Loss_fe 1.567, Loss_kd 0.951, Train_accy 37.10
2022-10-08 07:39:04,541 [foster.py] => Task 2, Epoch 3/34 => Loss 3.708, Loss_clf 0.963, Loss_fe 1.389, Loss_kd 0.956, Train_accy 36.62
2022-10-08 07:39:06,975 [foster.py] => Task 2, Epoch 4/34 => Loss 3.558, Loss_clf 0.928, Loss_fe 1.289, Loss_kd 0.946, Train_accy 34.81
2022-10-08 07:39:09,442 [foster.py] => Task 2, Epoch 5/34 => Loss 3.424, Loss_clf 0.882, Loss_fe 1.195, Loss_kd 0.950, Train_accy 36.78
2022-10-08 07:39:12,646 [foster.py] => Task 2, Epoch 6/34 => Loss 3.331, Loss_clf 0.851, Loss_fe 1.132, Loss_kd 0.952, Train_accy 36.46, Test_accy 48.14
2022-10-08 07:39:15,096 [foster.py] => Task 2, Epoch 7/34 => Loss 3.271, Loss_clf 0.851, Loss_fe 1.085, Loss_kd 0.942, Train_accy 35.99
2022-10-08 07:39:17,559 [foster.py] => Task 2, Epoch 8/34 => Loss 3.213, Loss_clf 0.826, Loss_fe 1.044, Loss_kd 0.948, Train_accy 37.41
2022-10-08 07:39:20,045 [foster.py] => Task 2, Epoch 9/34 => Loss 3.146, Loss_clf 0.813, Loss_fe 0.990, Loss_kd 0.948, Train_accy 37.65
2022-10-08 07:39:22,521 [foster.py] => Task 2, Epoch 10/34 => Loss 3.078, Loss_clf 0.780, Loss_fe 0.957, Loss_kd 0.946, Train_accy 38.83
2022-10-08 07:39:25,767 [foster.py] => Task 2, Epoch 11/34 => Loss 3.025, Loss_clf 0.763, Loss_fe 0.921, Loss_kd 0.947, Train_accy 38.67, Test_accy 49.20
2022-10-08 07:39:28,245 [foster.py] => Task 2, Epoch 12/34 => Loss 2.997, Loss_clf 0.747, Loss_fe 0.915, Loss_kd 0.942, Train_accy 40.25
2022-10-08 07:39:30,713 [foster.py] => Task 2, Epoch 13/34 => Loss 2.966, Loss_clf 0.732, Loss_fe 0.893, Loss_kd 0.946, Train_accy 37.25
2022-10-08 07:39:33,150 [foster.py] => Task 2, Epoch 14/34 => Loss 2.936, Loss_clf 0.725, Loss_fe 0.865, Loss_kd 0.950, Train_accy 40.65
2022-10-08 07:39:35,588 [foster.py] => Task 2, Epoch 15/34 => Loss 2.886, Loss_clf 0.708, Loss_fe 0.844, Loss_kd 0.941, Train_accy 41.52
2022-10-08 07:39:38,884 [foster.py] => Task 2, Epoch 16/34 => Loss 2.893, Loss_clf 0.711, Loss_fe 0.841, Loss_kd 0.947, Train_accy 40.73, Test_accy 50.27
2022-10-08 07:39:41,332 [foster.py] => Task 2, Epoch 17/34 => Loss 2.850, Loss_clf 0.690, Loss_fe 0.810, Loss_kd 0.953, Train_accy 40.57
2022-10-08 07:39:43,775 [foster.py] => Task 2, Epoch 18/34 => Loss 2.856, Loss_clf 0.702, Loss_fe 0.807, Loss_kd 0.951, Train_accy 40.96
2022-10-08 07:39:46,183 [foster.py] => Task 2, Epoch 19/34 => Loss 2.810, Loss_clf 0.680, Loss_fe 0.789, Loss_kd 0.947, Train_accy 41.44
2022-10-08 07:39:48,639 [foster.py] => Task 2, Epoch 20/34 => Loss 2.738, Loss_clf 0.649, Loss_fe 0.749, Loss_kd 0.946, Train_accy 42.30
2022-10-08 07:39:51,854 [foster.py] => Task 2, Epoch 21/34 => Loss 2.751, Loss_clf 0.655, Loss_fe 0.752, Loss_kd 0.948, Train_accy 41.75, Test_accy 49.20
2022-10-08 07:39:54,300 [foster.py] => Task 2, Epoch 22/34 => Loss 2.778, Loss_clf 0.662, Loss_fe 0.770, Loss_kd 0.950, Train_accy 41.75
2022-10-08 07:39:56,748 [foster.py] => Task 2, Epoch 23/34 => Loss 2.729, Loss_clf 0.640, Loss_fe 0.752, Loss_kd 0.943, Train_accy 42.78
2022-10-08 07:39:59,201 [foster.py] => Task 2, Epoch 24/34 => Loss 2.696, Loss_clf 0.630, Loss_fe 0.728, Loss_kd 0.945, Train_accy 42.86
2022-10-08 07:40:01,647 [foster.py] => Task 2, Epoch 25/34 => Loss 2.675, Loss_clf 0.625, Loss_fe 0.711, Loss_kd 0.944, Train_accy 42.86
2022-10-08 07:40:04,929 [foster.py] => Task 2, Epoch 26/34 => Loss 2.728, Loss_clf 0.641, Loss_fe 0.746, Loss_kd 0.946, Train_accy 43.65, Test_accy 48.94
2022-10-08 07:40:07,389 [foster.py] => Task 2, Epoch 27/34 => Loss 2.682, Loss_clf 0.619, Loss_fe 0.724, Loss_kd 0.945, Train_accy 43.65
2022-10-08 07:40:09,805 [foster.py] => Task 2, Epoch 28/34 => Loss 2.685, Loss_clf 0.624, Loss_fe 0.720, Loss_kd 0.946, Train_accy 42.62
2022-10-08 07:40:12,227 [foster.py] => Task 2, Epoch 29/34 => Loss 2.689, Loss_clf 0.620, Loss_fe 0.721, Loss_kd 0.951, Train_accy 42.54
2022-10-08 07:40:14,690 [foster.py] => Task 2, Epoch 30/34 => Loss 2.651, Loss_clf 0.601, Loss_fe 0.701, Loss_kd 0.952, Train_accy 43.96
2022-10-08 07:40:17,943 [foster.py] => Task 2, Epoch 31/34 => Loss 2.684, Loss_clf 0.624, Loss_fe 0.721, Loss_kd 0.945, Train_accy 43.57, Test_accy 48.67
2022-10-08 07:40:20,430 [foster.py] => Task 2, Epoch 32/34 => Loss 2.659, Loss_clf 0.610, Loss_fe 0.703, Loss_kd 0.950, Train_accy 43.25
2022-10-08 07:40:22,935 [foster.py] => Task 2, Epoch 33/34 => Loss 2.645, Loss_clf 0.607, Loss_fe 0.697, Loss_kd 0.947, Train_accy 43.01
2022-10-08 07:40:25,397 [foster.py] => Task 2, Epoch 34/34 => Loss 2.684, Loss_clf 0.619, Loss_fe 0.719, Loss_kd 0.950, Train_accy 43.41
2022-10-08 07:40:25,398 [foster.py] => do not weight align teacher!
2022-10-08 07:40:25,398 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 07:40:29,084 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.065,  Train_accy 12.55, Test_accy 39.36
2022-10-08 07:40:31,874 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.982,  Train_accy 12.71
2022-10-08 07:40:34,675 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.969,  Train_accy 13.02
2022-10-08 07:40:37,531 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.941,  Train_accy 13.34
2022-10-08 07:40:40,383 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.932,  Train_accy 13.50
2022-10-08 07:40:46,500 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.910,  Train_accy 13.26, Test_accy 42.02
2022-10-08 07:40:49,467 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.915,  Train_accy 13.73
2022-10-08 07:40:52,396 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.903,  Train_accy 13.50
2022-10-08 07:40:55,283 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.897,  Train_accy 13.81
2022-10-08 07:40:58,049 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.899,  Train_accy 13.50
2022-10-08 07:41:01,598 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.890,  Train_accy 14.21, Test_accy 41.76
2022-10-08 07:41:04,392 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.886,  Train_accy 14.13
2022-10-08 07:41:07,222 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.889,  Train_accy 13.58
2022-10-08 07:41:10,040 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.877,  Train_accy 13.58
2022-10-08 07:41:12,813 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.883,  Train_accy 14.13
2022-10-08 07:41:16,307 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.880,  Train_accy 13.81, Test_accy 42.55
2022-10-08 07:41:19,080 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.879,  Train_accy 14.13
2022-10-08 07:41:21,835 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.875,  Train_accy 14.21
2022-10-08 07:41:24,638 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.873,  Train_accy 14.13
2022-10-08 07:41:27,429 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.877,  Train_accy 14.13
2022-10-08 07:41:30,892 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.874,  Train_accy 13.81, Test_accy 42.29
2022-10-08 07:41:33,718 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.867,  Train_accy 14.21
2022-10-08 07:41:36,556 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.883,  Train_accy 14.44
2022-10-08 07:41:39,391 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.871,  Train_accy 14.13
2022-10-08 07:41:42,190 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.879,  Train_accy 14.13
2022-10-08 07:41:45,745 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.883,  Train_accy 14.21, Test_accy 42.55
2022-10-08 07:41:45,746 [foster.py] => do not weight align student!
2022-10-08 07:41:46,469 [foster.py] => darknet eval: 
2022-10-08 07:41:46,469 [foster.py] => CNN top1 curve: 42.55
2022-10-08 07:41:46,469 [foster.py] => CNN top5 curve: 94.41
2022-10-08 07:41:46,469 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 07:41:55,732 [foster.py] => Exemplar size: 340
2022-10-08 07:41:55,733 [trainer.py] => CNN: {'total': 48.94, 'old': 60.94, 'new': 23.33, 'base': 80.56, 'compound': 29.31}
2022-10-08 07:41:55,733 [trainer.py] => CNN top1 curve: [86.11, 69.92, 48.94]
2022-10-08 07:41:55,733 [trainer.py] => CNN base curve: [86.11, 82.64, 80.56]
2022-10-08 07:41:55,733 [trainer.py] => CNN old curve: [86.11, 82.64, 60.94]
2022-10-08 07:41:55,733 [trainer.py] => CNN new curve: [0, 53.57, 23.33]
2022-10-08 07:41:55,733 [trainer.py] => CNN compound curve: [0, 53.57, 29.31]
2022-10-08 07:41:55,733 [trainer.py] => NME: {'total': 64.36, 'old': 71.88, 'new': 48.33, 'base': 75.69, 'compound': 57.33}
2022-10-08 07:41:55,733 [trainer.py] => NME top1 curve: [86.81, 82.42, 64.36]
2022-10-08 07:41:55,733 [trainer.py] => NME base curve: [86.81, 84.03, 75.69]
2022-10-08 07:41:55,733 [trainer.py] => NME old curve: [86.81, 84.03, 71.88]
2022-10-08 07:41:55,733 [trainer.py] => NME new curve: [0, 80.36, 48.33]
2022-10-08 07:41:55,733 [trainer.py] => NME compound curve: [0, 80.36, 57.33]
2022-10-08 07:41:55,951 [foster.py] => Learning on 17-22
2022-10-08 07:41:55,951 [foster.py] => All params: 22395581
2022-10-08 07:41:55,952 [foster.py] => Trainable params: 11210348
2022-10-08 07:41:55,960 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 07:41:59,425 [foster.py] => Task 3, Epoch 1/34 => Loss 6.567, Loss_clf 2.238, Loss_fe 2.455, Loss_kd 1.449, Train_accy 30.29, Test_accy 38.22
2022-10-08 07:42:01,999 [foster.py] => Task 3, Epoch 2/34 => Loss 4.814, Loss_clf 1.200, Loss_fe 1.760, Loss_kd 1.433, Train_accy 30.21
2022-10-08 07:42:04,558 [foster.py] => Task 3, Epoch 3/34 => Loss 4.527, Loss_clf 1.093, Loss_fe 1.582, Loss_kd 1.432, Train_accy 32.65
2022-10-08 07:42:07,101 [foster.py] => Task 3, Epoch 4/34 => Loss 4.439, Loss_clf 1.085, Loss_fe 1.496, Loss_kd 1.436, Train_accy 33.31
2022-10-08 07:42:09,647 [foster.py] => Task 3, Epoch 5/34 => Loss 4.296, Loss_clf 1.049, Loss_fe 1.403, Loss_kd 1.425, Train_accy 32.13
2022-10-08 07:42:13,168 [foster.py] => Task 3, Epoch 6/34 => Loss 4.186, Loss_clf 1.014, Loss_fe 1.327, Loss_kd 1.426, Train_accy 33.01, Test_accy 40.59
2022-10-08 07:42:15,734 [foster.py] => Task 3, Epoch 7/34 => Loss 4.130, Loss_clf 1.011, Loss_fe 1.278, Loss_kd 1.422, Train_accy 34.64
2022-10-08 07:42:18,318 [foster.py] => Task 3, Epoch 8/34 => Loss 4.066, Loss_clf 0.981, Loss_fe 1.239, Loss_kd 1.426, Train_accy 33.16
2022-10-08 07:42:20,929 [foster.py] => Task 3, Epoch 9/34 => Loss 3.999, Loss_clf 0.966, Loss_fe 1.189, Loss_kd 1.425, Train_accy 35.22
2022-10-08 07:42:23,515 [foster.py] => Task 3, Epoch 10/34 => Loss 3.907, Loss_clf 0.936, Loss_fe 1.139, Loss_kd 1.416, Train_accy 34.34
2022-10-08 07:42:27,040 [foster.py] => Task 3, Epoch 11/34 => Loss 3.880, Loss_clf 0.924, Loss_fe 1.113, Loss_kd 1.424, Train_accy 34.93, Test_accy 40.99
2022-10-08 07:42:29,618 [foster.py] => Task 3, Epoch 12/34 => Loss 3.841, Loss_clf 0.922, Loss_fe 1.081, Loss_kd 1.420, Train_accy 35.89
2022-10-08 07:42:32,178 [foster.py] => Task 3, Epoch 13/34 => Loss 3.822, Loss_clf 0.904, Loss_fe 1.063, Loss_kd 1.433, Train_accy 36.04
2022-10-08 07:42:34,767 [foster.py] => Task 3, Epoch 14/34 => Loss 3.791, Loss_clf 0.892, Loss_fe 1.046, Loss_kd 1.432, Train_accy 37.73
2022-10-08 07:42:37,333 [foster.py] => Task 3, Epoch 15/34 => Loss 3.710, Loss_clf 0.861, Loss_fe 0.999, Loss_kd 1.430, Train_accy 37.51
2022-10-08 07:42:40,846 [foster.py] => Task 3, Epoch 16/34 => Loss 3.744, Loss_clf 0.885, Loss_fe 1.005, Loss_kd 1.433, Train_accy 36.40, Test_accy 41.78
2022-10-08 07:42:43,400 [foster.py] => Task 3, Epoch 17/34 => Loss 3.703, Loss_clf 0.863, Loss_fe 1.001, Loss_kd 1.421, Train_accy 36.62
2022-10-08 07:42:45,971 [foster.py] => Task 3, Epoch 18/34 => Loss 3.663, Loss_clf 0.850, Loss_fe 0.964, Loss_kd 1.429, Train_accy 37.44
2022-10-08 07:42:48,576 [foster.py] => Task 3, Epoch 19/34 => Loss 3.649, Loss_clf 0.845, Loss_fe 0.959, Loss_kd 1.426, Train_accy 36.85
2022-10-08 07:42:51,152 [foster.py] => Task 3, Epoch 20/34 => Loss 3.619, Loss_clf 0.829, Loss_fe 0.939, Loss_kd 1.431, Train_accy 39.35
2022-10-08 07:42:54,645 [foster.py] => Task 3, Epoch 21/34 => Loss 3.596, Loss_clf 0.821, Loss_fe 0.926, Loss_kd 1.428, Train_accy 36.33, Test_accy 42.97
2022-10-08 07:42:57,188 [foster.py] => Task 3, Epoch 22/34 => Loss 3.616, Loss_clf 0.834, Loss_fe 0.937, Loss_kd 1.426, Train_accy 36.99
2022-10-08 07:42:59,805 [foster.py] => Task 3, Epoch 23/34 => Loss 3.607, Loss_clf 0.827, Loss_fe 0.937, Loss_kd 1.425, Train_accy 38.98
2022-10-08 07:43:02,403 [foster.py] => Task 3, Epoch 24/34 => Loss 3.538, Loss_clf 0.796, Loss_fe 0.899, Loss_kd 1.424, Train_accy 38.47
2022-10-08 07:43:04,982 [foster.py] => Task 3, Epoch 25/34 => Loss 3.563, Loss_clf 0.810, Loss_fe 0.904, Loss_kd 1.428, Train_accy 38.91
2022-10-08 07:43:08,496 [foster.py] => Task 3, Epoch 26/34 => Loss 3.560, Loss_clf 0.808, Loss_fe 0.907, Loss_kd 1.426, Train_accy 38.10, Test_accy 42.97
2022-10-08 07:43:11,107 [foster.py] => Task 3, Epoch 27/34 => Loss 3.523, Loss_clf 0.786, Loss_fe 0.891, Loss_kd 1.426, Train_accy 39.06
2022-10-08 07:43:13,670 [foster.py] => Task 3, Epoch 28/34 => Loss 3.534, Loss_clf 0.789, Loss_fe 0.898, Loss_kd 1.427, Train_accy 38.54
2022-10-08 07:43:16,249 [foster.py] => Task 3, Epoch 29/34 => Loss 3.525, Loss_clf 0.794, Loss_fe 0.891, Loss_kd 1.421, Train_accy 38.32
2022-10-08 07:43:18,815 [foster.py] => Task 3, Epoch 30/34 => Loss 3.558, Loss_clf 0.807, Loss_fe 0.909, Loss_kd 1.423, Train_accy 38.98
2022-10-08 07:43:22,347 [foster.py] => Task 3, Epoch 31/34 => Loss 3.526, Loss_clf 0.789, Loss_fe 0.886, Loss_kd 1.430, Train_accy 39.57, Test_accy 42.57
2022-10-08 07:43:24,929 [foster.py] => Task 3, Epoch 32/34 => Loss 3.543, Loss_clf 0.801, Loss_fe 0.897, Loss_kd 1.426, Train_accy 37.80
2022-10-08 07:43:27,562 [foster.py] => Task 3, Epoch 33/34 => Loss 3.523, Loss_clf 0.792, Loss_fe 0.885, Loss_kd 1.426, Train_accy 39.28
2022-10-08 07:43:30,155 [foster.py] => Task 3, Epoch 34/34 => Loss 3.538, Loss_clf 0.787, Loss_fe 0.904, Loss_kd 1.427, Train_accy 37.73
2022-10-08 07:43:30,155 [foster.py] => do not weight align teacher!
2022-10-08 07:43:30,156 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 07:43:34,182 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.377,  Train_accy 13.19, Test_accy 32.48
2022-10-08 07:43:37,230 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.325,  Train_accy 13.49
2022-10-08 07:43:40,162 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.298,  Train_accy 13.19
2022-10-08 07:43:43,191 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.269,  Train_accy 12.97
2022-10-08 07:43:46,161 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.266,  Train_accy 13.56
2022-10-08 07:43:50,237 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.262,  Train_accy 13.85, Test_accy 34.06
2022-10-08 07:43:54,568 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.250,  Train_accy 13.63
2022-10-08 07:43:58,161 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.246,  Train_accy 13.49
2022-10-08 07:44:01,444 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.234,  Train_accy 13.41
2022-10-08 07:44:04,528 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.239,  Train_accy 14.44
2022-10-08 07:44:08,361 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.226,  Train_accy 15.25, Test_accy 34.46
2022-10-08 07:44:11,307 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.220,  Train_accy 15.18
2022-10-08 07:44:14,209 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.216,  Train_accy 15.11
2022-10-08 07:44:17,104 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.213,  Train_accy 15.11
2022-10-08 07:44:20,030 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.216,  Train_accy 15.48
2022-10-08 07:44:23,783 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.220,  Train_accy 15.33, Test_accy 34.85
2022-10-08 07:44:26,719 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.212,  Train_accy 15.84
2022-10-08 07:44:29,667 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.213,  Train_accy 15.77
2022-10-08 07:44:32,623 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.211,  Train_accy 15.84
2022-10-08 07:44:35,580 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.209,  Train_accy 16.14
2022-10-08 07:44:39,282 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.210,  Train_accy 15.48, Test_accy 36.24
2022-10-08 07:44:42,221 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.208,  Train_accy 16.14
2022-10-08 07:44:45,207 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.210,  Train_accy 16.36
2022-10-08 07:44:48,147 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.209,  Train_accy 16.14
2022-10-08 07:44:51,047 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.209,  Train_accy 16.06
2022-10-08 07:44:54,940 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.209,  Train_accy 15.40, Test_accy 36.04
2022-10-08 07:44:54,941 [foster.py] => do not weight align student!
2022-10-08 07:44:55,708 [foster.py] => darknet eval: 
2022-10-08 07:44:55,709 [foster.py] => CNN top1 curve: 36.04
2022-10-08 07:44:55,709 [foster.py] => CNN top5 curve: 78.42
2022-10-08 07:44:55,709 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 07:45:06,698 [foster.py] => Exemplar size: 440
2022-10-08 07:45:06,698 [trainer.py] => CNN: {'total': 42.77, 'old': 51.6, 'new': 17.05, 'base': 79.17, 'compound': 28.25}
2022-10-08 07:45:06,698 [trainer.py] => CNN top1 curve: [86.11, 69.92, 48.94, 42.77]
2022-10-08 07:45:06,698 [trainer.py] => CNN base curve: [86.11, 82.64, 80.56, 79.17]
2022-10-08 07:45:06,698 [trainer.py] => CNN old curve: [86.11, 82.64, 60.94, 51.6]
2022-10-08 07:45:06,698 [trainer.py] => CNN new curve: [0, 53.57, 23.33, 17.05]
2022-10-08 07:45:06,698 [trainer.py] => CNN compound curve: [0, 53.57, 29.31, 28.25]
2022-10-08 07:45:06,698 [trainer.py] => NME: {'total': 52.87, 'old': 57.98, 'new': 37.98, 'base': 71.53, 'compound': 45.43}
2022-10-08 07:45:06,698 [trainer.py] => NME top1 curve: [86.81, 82.42, 64.36, 52.87]
2022-10-08 07:45:06,698 [trainer.py] => NME base curve: [86.81, 84.03, 75.69, 71.53]
2022-10-08 07:45:06,698 [trainer.py] => NME old curve: [86.81, 84.03, 71.88, 57.98]
2022-10-08 07:45:06,698 [trainer.py] => NME new curve: [0, 80.36, 48.33, 37.98]
2022-10-08 07:45:06,698 [trainer.py] => NME compound curve: [0, 80.36, 57.33, 45.43]
2022-10-08 07:45:06,700 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 07:45:06,700 [trainer.py] => prefix: cil
2022-10-08 07:45:06,700 [trainer.py] => dataset: CFEE
2022-10-08 07:45:06,700 [trainer.py] => memory_size: 2000
2022-10-08 07:45:06,700 [trainer.py] => memory_per_class: 20
2022-10-08 07:45:06,700 [trainer.py] => fixed_memory: True
2022-10-08 07:45:06,700 [trainer.py] => shuffle: True
2022-10-08 07:45:06,700 [trainer.py] => init_cls: 7
2022-10-08 07:45:06,700 [trainer.py] => increment: 5
2022-10-08 07:45:06,700 [trainer.py] => model_name: foster
2022-10-08 07:45:06,700 [trainer.py] => convnet_type: resnet18
2022-10-08 07:45:06,700 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 07:45:06,700 [trainer.py] => seed: 1993
2022-10-08 07:45:06,700 [trainer.py] => beta1: 0.96
2022-10-08 07:45:06,700 [trainer.py] => beta2: 0.97
2022-10-08 07:45:06,700 [trainer.py] => oofc: ft
2022-10-08 07:45:06,700 [trainer.py] => is_teacher_wa: False
2022-10-08 07:45:06,700 [trainer.py] => is_student_wa: False
2022-10-08 07:45:06,700 [trainer.py] => lambda_okd: 1
2022-10-08 07:45:06,700 [trainer.py] => wa_value: 1
2022-10-08 07:45:06,700 [trainer.py] => init_epochs: 40
2022-10-08 07:45:06,700 [trainer.py] => init_lr: 0.01
2022-10-08 07:45:06,700 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 07:45:06,700 [trainer.py] => boosting_epochs: 34
2022-10-08 07:45:06,700 [trainer.py] => compression_epochs: 26
2022-10-08 07:45:06,700 [trainer.py] => lr: 0.001
2022-10-08 07:45:06,701 [trainer.py] => batch_size: 32
2022-10-08 07:45:06,701 [trainer.py] => weight_decay: 0.0005
2022-10-08 07:45:06,701 [trainer.py] => num_workers: 8
2022-10-08 07:45:06,701 [trainer.py] => T: 2
2022-10-08 07:45:06,701 [trainer.py] => nb_runs: 3
2022-10-08 07:45:06,701 [trainer.py] => fold: 10
2022-10-08 07:45:06,701 [data.py] => ========== Fold:5 ==========
2022-10-08 07:45:06,706 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 8, 15, 13, 17, 9, 11, 19, 21, 14, 10, 18, 12, 7, 16]
2022-10-08 07:45:06,920 [foster.py] => Learning on 0-7
2022-10-08 07:45:06,920 [foster.py] => All params: 11183694
2022-10-08 07:45:06,921 [foster.py] => Trainable params: 11183694
2022-10-08 07:45:09,166 [foster.py] => Task 0, Epoch 1/40 => Loss 1.370, Train_accy 49.44
2022-10-08 07:45:12,000 [foster.py] => Task 0, Epoch 2/40 => Loss 0.561, Train_accy 81.57, Test_accy 82.84
2022-10-08 07:45:14,778 [foster.py] => Task 0, Epoch 3/40 => Loss 0.362, Train_accy 87.13, Test_accy 85.21
2022-10-08 07:45:17,524 [foster.py] => Task 0, Epoch 4/40 => Loss 0.281, Train_accy 90.19, Test_accy 86.98
2022-10-08 07:45:20,344 [foster.py] => Task 0, Epoch 5/40 => Loss 0.230, Train_accy 91.93, Test_accy 88.76
2022-10-08 07:45:22,602 [foster.py] => Task 0, Epoch 6/40 => Loss 0.183, Train_accy 94.30
2022-10-08 07:45:25,388 [foster.py] => Task 0, Epoch 7/40 => Loss 0.158, Train_accy 94.37, Test_accy 87.57
2022-10-08 07:45:28,204 [foster.py] => Task 0, Epoch 8/40 => Loss 0.130, Train_accy 95.90, Test_accy 87.57
2022-10-08 07:45:30,993 [foster.py] => Task 0, Epoch 9/40 => Loss 0.115, Train_accy 96.11, Test_accy 89.35
2022-10-08 07:45:33,788 [foster.py] => Task 0, Epoch 10/40 => Loss 0.091, Train_accy 97.29, Test_accy 87.57
2022-10-08 07:45:36,030 [foster.py] => Task 0, Epoch 11/40 => Loss 0.089, Train_accy 97.01
2022-10-08 07:45:38,835 [foster.py] => Task 0, Epoch 12/40 => Loss 0.072, Train_accy 98.05, Test_accy 86.39
2022-10-08 07:45:41,648 [foster.py] => Task 0, Epoch 13/40 => Loss 0.060, Train_accy 98.68, Test_accy 87.57
2022-10-08 07:45:44,461 [foster.py] => Task 0, Epoch 14/40 => Loss 0.074, Train_accy 97.15, Test_accy 86.98
2022-10-08 07:45:47,299 [foster.py] => Task 0, Epoch 15/40 => Loss 0.054, Train_accy 98.61, Test_accy 88.17
2022-10-08 07:45:49,578 [foster.py] => Task 0, Epoch 16/40 => Loss 0.044, Train_accy 98.75
2022-10-08 07:45:52,368 [foster.py] => Task 0, Epoch 17/40 => Loss 0.041, Train_accy 98.75, Test_accy 88.76
2022-10-08 07:45:55,182 [foster.py] => Task 0, Epoch 18/40 => Loss 0.030, Train_accy 99.51, Test_accy 89.35
2022-10-08 07:45:58,008 [foster.py] => Task 0, Epoch 19/40 => Loss 0.029, Train_accy 99.30, Test_accy 88.17
2022-10-08 07:46:00,818 [foster.py] => Task 0, Epoch 20/40 => Loss 0.026, Train_accy 99.24, Test_accy 88.17
2022-10-08 07:46:03,015 [foster.py] => Task 0, Epoch 21/40 => Loss 0.027, Train_accy 99.30
2022-10-08 07:46:05,855 [foster.py] => Task 0, Epoch 22/40 => Loss 0.032, Train_accy 99.17, Test_accy 87.57
2022-10-08 07:46:08,676 [foster.py] => Task 0, Epoch 23/40 => Loss 0.023, Train_accy 99.58, Test_accy 88.76
2022-10-08 07:46:11,510 [foster.py] => Task 0, Epoch 24/40 => Loss 0.018, Train_accy 99.72, Test_accy 87.57
2022-10-08 07:46:14,377 [foster.py] => Task 0, Epoch 25/40 => Loss 0.018, Train_accy 99.72, Test_accy 88.76
2022-10-08 07:46:16,615 [foster.py] => Task 0, Epoch 26/40 => Loss 0.018, Train_accy 99.72
2022-10-08 07:46:19,454 [foster.py] => Task 0, Epoch 27/40 => Loss 0.023, Train_accy 99.51, Test_accy 86.98
2022-10-08 07:46:22,312 [foster.py] => Task 0, Epoch 28/40 => Loss 0.014, Train_accy 99.93, Test_accy 87.57
2022-10-08 07:46:25,158 [foster.py] => Task 0, Epoch 29/40 => Loss 0.014, Train_accy 100.00, Test_accy 86.98
2022-10-08 07:46:28,029 [foster.py] => Task 0, Epoch 30/40 => Loss 0.018, Train_accy 99.72, Test_accy 88.76
2022-10-08 07:46:30,287 [foster.py] => Task 0, Epoch 31/40 => Loss 0.015, Train_accy 99.86
2022-10-08 07:46:33,151 [foster.py] => Task 0, Epoch 32/40 => Loss 0.012, Train_accy 100.00, Test_accy 89.35
2022-10-08 07:46:35,983 [foster.py] => Task 0, Epoch 33/40 => Loss 0.014, Train_accy 99.86, Test_accy 89.35
2022-10-08 07:46:38,816 [foster.py] => Task 0, Epoch 34/40 => Loss 0.012, Train_accy 99.93, Test_accy 88.76
2022-10-08 07:46:41,602 [foster.py] => Task 0, Epoch 35/40 => Loss 0.012, Train_accy 99.86, Test_accy 88.17
2022-10-08 07:46:43,866 [foster.py] => Task 0, Epoch 36/40 => Loss 0.011, Train_accy 99.93
2022-10-08 07:46:46,698 [foster.py] => Task 0, Epoch 37/40 => Loss 0.010, Train_accy 100.00, Test_accy 88.76
2022-10-08 07:46:49,504 [foster.py] => Task 0, Epoch 38/40 => Loss 0.012, Train_accy 99.93, Test_accy 88.17
2022-10-08 07:46:52,313 [foster.py] => Task 0, Epoch 39/40 => Loss 0.014, Train_accy 99.86, Test_accy 87.57
2022-10-08 07:46:55,120 [foster.py] => Task 0, Epoch 40/40 => Loss 0.012, Train_accy 99.86, Test_accy 88.17
2022-10-08 07:46:55,120 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 07:47:01,409 [foster.py] => Exemplar size: 140
2022-10-08 07:47:01,409 [trainer.py] => CNN: {'total': 88.17, 'old': 88.17, 'new': 0, 'base': 88.17, 'compound': 0}
2022-10-08 07:47:01,409 [trainer.py] => CNN top1 curve: [88.17]
2022-10-08 07:47:01,409 [trainer.py] => CNN base curve: [88.17]
2022-10-08 07:47:01,409 [trainer.py] => CNN old curve: [88.17]
2022-10-08 07:47:01,409 [trainer.py] => CNN new curve: [0]
2022-10-08 07:47:01,409 [trainer.py] => CNN compound curve: [0]
2022-10-08 07:47:01,409 [trainer.py] => NME: {'total': 86.98, 'old': 86.98, 'new': 0, 'base': 86.98, 'compound': 0}
2022-10-08 07:47:01,409 [trainer.py] => NME top1 curve: [86.98]
2022-10-08 07:47:01,409 [trainer.py] => NME base curve: [86.98]
2022-10-08 07:47:01,409 [trainer.py] => NME old curve: [86.98]
2022-10-08 07:47:01,409 [trainer.py] => NME new curve: [0]
2022-10-08 07:47:01,410 [trainer.py] => NME compound curve: [0]
2022-10-08 07:47:01,627 [foster.py] => Learning on 7-12
2022-10-08 07:47:01,627 [foster.py] => All params: 22375071
2022-10-08 07:47:01,628 [foster.py] => Trainable params: 11194968
2022-10-08 07:47:01,636 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 07:47:04,657 [foster.py] => Task 1, Epoch 1/34 => Loss 4.677, Loss_clf 2.116, Loss_fe 1.846, Loss_kd 0.417, Train_accy 39.00, Test_accy 68.73
2022-10-08 07:47:06,933 [foster.py] => Task 1, Epoch 2/34 => Loss 2.513, Loss_clf 0.661, Loss_fe 1.169, Loss_kd 0.398, Train_accy 63.66
2022-10-08 07:47:09,173 [foster.py] => Task 1, Epoch 3/34 => Loss 2.160, Loss_clf 0.538, Loss_fe 0.952, Loss_kd 0.391, Train_accy 50.95
2022-10-08 07:47:11,428 [foster.py] => Task 1, Epoch 4/34 => Loss 1.994, Loss_clf 0.487, Loss_fe 0.842, Loss_kd 0.388, Train_accy 49.91
2022-10-08 07:47:13,748 [foster.py] => Task 1, Epoch 5/34 => Loss 1.853, Loss_clf 0.443, Loss_fe 0.743, Loss_kd 0.389, Train_accy 49.48
2022-10-08 07:47:16,772 [foster.py] => Task 1, Epoch 6/34 => Loss 1.749, Loss_clf 0.425, Loss_fe 0.677, Loss_kd 0.377, Train_accy 51.80, Test_accy 68.04
2022-10-08 07:47:19,055 [foster.py] => Task 1, Epoch 7/34 => Loss 1.719, Loss_clf 0.416, Loss_fe 0.646, Loss_kd 0.384, Train_accy 50.77
2022-10-08 07:47:21,373 [foster.py] => Task 1, Epoch 8/34 => Loss 1.641, Loss_clf 0.388, Loss_fe 0.591, Loss_kd 0.387, Train_accy 52.49
2022-10-08 07:47:23,682 [foster.py] => Task 1, Epoch 9/34 => Loss 1.599, Loss_clf 0.376, Loss_fe 0.557, Loss_kd 0.388, Train_accy 54.90
2022-10-08 07:47:26,009 [foster.py] => Task 1, Epoch 10/34 => Loss 1.575, Loss_clf 0.370, Loss_fe 0.540, Loss_kd 0.388, Train_accy 55.24
2022-10-08 07:47:29,055 [foster.py] => Task 1, Epoch 11/34 => Loss 1.524, Loss_clf 0.350, Loss_fe 0.509, Loss_kd 0.388, Train_accy 55.07, Test_accy 68.38
2022-10-08 07:47:31,321 [foster.py] => Task 1, Epoch 12/34 => Loss 1.503, Loss_clf 0.347, Loss_fe 0.490, Loss_kd 0.388, Train_accy 54.73
2022-10-08 07:47:33,625 [foster.py] => Task 1, Epoch 13/34 => Loss 1.475, Loss_clf 0.337, Loss_fe 0.478, Loss_kd 0.385, Train_accy 54.98
2022-10-08 07:47:35,938 [foster.py] => Task 1, Epoch 14/34 => Loss 1.451, Loss_clf 0.329, Loss_fe 0.461, Loss_kd 0.385, Train_accy 56.53
2022-10-08 07:47:38,293 [foster.py] => Task 1, Epoch 15/34 => Loss 1.403, Loss_clf 0.307, Loss_fe 0.430, Loss_kd 0.388, Train_accy 56.79
2022-10-08 07:47:41,316 [foster.py] => Task 1, Epoch 16/34 => Loss 1.378, Loss_clf 0.301, Loss_fe 0.420, Loss_kd 0.383, Train_accy 56.10, Test_accy 70.10
2022-10-08 07:47:43,603 [foster.py] => Task 1, Epoch 17/34 => Loss 1.394, Loss_clf 0.306, Loss_fe 0.425, Loss_kd 0.387, Train_accy 56.10
2022-10-08 07:47:45,886 [foster.py] => Task 1, Epoch 18/34 => Loss 1.404, Loss_clf 0.311, Loss_fe 0.435, Loss_kd 0.384, Train_accy 55.84
2022-10-08 07:47:48,213 [foster.py] => Task 1, Epoch 19/34 => Loss 1.380, Loss_clf 0.305, Loss_fe 0.416, Loss_kd 0.384, Train_accy 56.44
2022-10-08 07:47:50,528 [foster.py] => Task 1, Epoch 20/34 => Loss 1.355, Loss_clf 0.293, Loss_fe 0.395, Loss_kd 0.388, Train_accy 57.82
2022-10-08 07:47:53,546 [foster.py] => Task 1, Epoch 21/34 => Loss 1.348, Loss_clf 0.290, Loss_fe 0.400, Loss_kd 0.384, Train_accy 56.62, Test_accy 70.10
2022-10-08 07:47:55,823 [foster.py] => Task 1, Epoch 22/34 => Loss 1.328, Loss_clf 0.287, Loss_fe 0.388, Loss_kd 0.381, Train_accy 56.62
2022-10-08 07:47:58,088 [foster.py] => Task 1, Epoch 23/34 => Loss 1.283, Loss_clf 0.264, Loss_fe 0.361, Loss_kd 0.383, Train_accy 57.90
2022-10-08 07:48:00,391 [foster.py] => Task 1, Epoch 24/34 => Loss 1.317, Loss_clf 0.272, Loss_fe 0.378, Loss_kd 0.389, Train_accy 57.65
2022-10-08 07:48:02,682 [foster.py] => Task 1, Epoch 25/34 => Loss 1.331, Loss_clf 0.285, Loss_fe 0.387, Loss_kd 0.384, Train_accy 58.25
2022-10-08 07:48:05,677 [foster.py] => Task 1, Epoch 26/34 => Loss 1.271, Loss_clf 0.254, Loss_fe 0.352, Loss_kd 0.388, Train_accy 59.36, Test_accy 71.13
2022-10-08 07:48:07,993 [foster.py] => Task 1, Epoch 27/34 => Loss 1.287, Loss_clf 0.265, Loss_fe 0.354, Loss_kd 0.390, Train_accy 59.36
2022-10-08 07:48:10,311 [foster.py] => Task 1, Epoch 28/34 => Loss 1.282, Loss_clf 0.262, Loss_fe 0.361, Loss_kd 0.384, Train_accy 58.68
2022-10-08 07:48:12,645 [foster.py] => Task 1, Epoch 29/34 => Loss 1.299, Loss_clf 0.274, Loss_fe 0.369, Loss_kd 0.383, Train_accy 57.56
2022-10-08 07:48:14,942 [foster.py] => Task 1, Epoch 30/34 => Loss 1.314, Loss_clf 0.276, Loss_fe 0.373, Loss_kd 0.388, Train_accy 58.42
2022-10-08 07:48:17,939 [foster.py] => Task 1, Epoch 31/34 => Loss 1.288, Loss_clf 0.266, Loss_fe 0.363, Loss_kd 0.385, Train_accy 57.22, Test_accy 71.13
2022-10-08 07:48:20,225 [foster.py] => Task 1, Epoch 32/34 => Loss 1.253, Loss_clf 0.246, Loss_fe 0.341, Loss_kd 0.389, Train_accy 58.68
2022-10-08 07:48:22,514 [foster.py] => Task 1, Epoch 33/34 => Loss 1.255, Loss_clf 0.260, Loss_fe 0.344, Loss_kd 0.379, Train_accy 59.19
2022-10-08 07:48:24,835 [foster.py] => Task 1, Epoch 34/34 => Loss 1.275, Loss_clf 0.261, Loss_fe 0.352, Loss_kd 0.386, Train_accy 59.71
2022-10-08 07:48:24,835 [foster.py] => do not weight align teacher!
2022-10-08 07:48:24,835 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 07:48:28,365 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.835,  Train_accy 11.94, Test_accy 49.83
2022-10-08 07:48:31,005 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.649,  Train_accy 12.03
2022-10-08 07:48:33,603 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.575,  Train_accy 12.71
2022-10-08 07:48:36,219 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.524,  Train_accy 15.55
2022-10-08 07:48:38,809 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.513,  Train_accy 16.24
2022-10-08 07:48:42,108 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.475,  Train_accy 17.87, Test_accy 52.92
2022-10-08 07:48:44,769 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.451,  Train_accy 20.27
2022-10-08 07:48:47,386 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.446,  Train_accy 20.10
2022-10-08 07:48:49,982 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.428,  Train_accy 21.39
2022-10-08 07:48:52,657 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.423,  Train_accy 22.25
2022-10-08 07:48:55,925 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.413,  Train_accy 24.48, Test_accy 56.70
2022-10-08 07:48:58,634 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.412,  Train_accy 24.66
2022-10-08 07:49:01,304 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.402,  Train_accy 25.00
2022-10-08 07:49:03,968 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.405,  Train_accy 25.17
2022-10-08 07:49:06,575 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.383,  Train_accy 25.69
2022-10-08 07:49:09,858 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.395,  Train_accy 25.95, Test_accy 58.76
2022-10-08 07:49:12,468 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.382,  Train_accy 26.46
2022-10-08 07:49:15,117 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.381,  Train_accy 26.55
2022-10-08 07:49:17,743 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.385,  Train_accy 27.84
2022-10-08 07:49:20,393 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.384,  Train_accy 28.52
2022-10-08 07:49:23,655 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.367,  Train_accy 28.18, Test_accy 59.11
2022-10-08 07:49:26,366 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.376,  Train_accy 27.84
2022-10-08 07:49:28,981 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.383,  Train_accy 27.15
2022-10-08 07:49:31,591 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.379,  Train_accy 28.35
2022-10-08 07:49:34,270 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.374,  Train_accy 28.01
2022-10-08 07:49:39,723 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.379,  Train_accy 27.84, Test_accy 57.73
2022-10-08 07:49:39,723 [foster.py] => do not weight align student!
2022-10-08 07:49:40,371 [foster.py] => darknet eval: 
2022-10-08 07:49:40,371 [foster.py] => CNN top1 curve: 57.73
2022-10-08 07:49:40,371 [foster.py] => CNN top5 curve: 97.25
2022-10-08 07:49:40,371 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 07:49:47,972 [foster.py] => Exemplar size: 240
2022-10-08 07:49:47,973 [trainer.py] => CNN: {'total': 71.13, 'old': 88.17, 'new': 47.54, 'base': 88.17, 'compound': 47.54}
2022-10-08 07:49:47,973 [trainer.py] => CNN top1 curve: [88.17, 71.13]
2022-10-08 07:49:47,973 [trainer.py] => CNN base curve: [88.17, 88.17]
2022-10-08 07:49:47,973 [trainer.py] => CNN old curve: [88.17, 88.17]
2022-10-08 07:49:47,973 [trainer.py] => CNN new curve: [0, 47.54]
2022-10-08 07:49:47,973 [trainer.py] => CNN compound curve: [0, 47.54]
2022-10-08 07:49:47,973 [trainer.py] => NME: {'total': 79.04, 'old': 83.43, 'new': 72.95, 'base': 83.43, 'compound': 72.95}
2022-10-08 07:49:47,973 [trainer.py] => NME top1 curve: [86.98, 79.04]
2022-10-08 07:49:47,973 [trainer.py] => NME base curve: [86.98, 83.43]
2022-10-08 07:49:47,973 [trainer.py] => NME old curve: [86.98, 83.43]
2022-10-08 07:49:47,973 [trainer.py] => NME new curve: [0, 72.95]
2022-10-08 07:49:47,973 [trainer.py] => NME compound curve: [0, 72.95]
2022-10-08 07:49:48,190 [foster.py] => Learning on 12-17
2022-10-08 07:49:48,191 [foster.py] => All params: 22385326
2022-10-08 07:49:48,191 [foster.py] => Trainable params: 11202658
2022-10-08 07:49:48,200 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 07:49:51,539 [foster.py] => Task 2, Epoch 1/34 => Loss 5.891, Loss_clf 2.268, Loss_fe 2.232, Loss_kd 0.982, Train_accy 34.50, Test_accy 44.50
2022-10-08 07:49:53,972 [foster.py] => Task 2, Epoch 2/34 => Loss 3.974, Loss_clf 1.077, Loss_fe 1.544, Loss_kd 0.955, Train_accy 35.43
2022-10-08 07:49:56,410 [foster.py] => Task 2, Epoch 3/34 => Loss 3.644, Loss_clf 0.945, Loss_fe 1.346, Loss_kd 0.955, Train_accy 32.87
2022-10-08 07:49:58,896 [foster.py] => Task 2, Epoch 4/34 => Loss 3.507, Loss_clf 0.915, Loss_fe 1.243, Loss_kd 0.952, Train_accy 35.20
2022-10-08 07:50:01,403 [foster.py] => Task 2, Epoch 5/34 => Loss 3.396, Loss_clf 0.881, Loss_fe 1.175, Loss_kd 0.946, Train_accy 34.19
2022-10-08 07:50:04,702 [foster.py] => Task 2, Epoch 6/34 => Loss 3.368, Loss_clf 0.893, Loss_fe 1.126, Loss_kd 0.952, Train_accy 34.42, Test_accy 51.92
2022-10-08 07:50:07,203 [foster.py] => Task 2, Epoch 7/34 => Loss 3.266, Loss_clf 0.852, Loss_fe 1.069, Loss_kd 0.949, Train_accy 34.19
2022-10-08 07:50:09,663 [foster.py] => Task 2, Epoch 8/34 => Loss 3.203, Loss_clf 0.823, Loss_fe 1.028, Loss_kd 0.955, Train_accy 36.21
2022-10-08 07:50:12,123 [foster.py] => Task 2, Epoch 9/34 => Loss 3.134, Loss_clf 0.800, Loss_fe 0.970, Loss_kd 0.963, Train_accy 34.42
2022-10-08 07:50:14,625 [foster.py] => Task 2, Epoch 10/34 => Loss 3.130, Loss_clf 0.811, Loss_fe 0.965, Loss_kd 0.956, Train_accy 36.13
2022-10-08 07:50:17,933 [foster.py] => Task 2, Epoch 11/34 => Loss 3.042, Loss_clf 0.776, Loss_fe 0.916, Loss_kd 0.953, Train_accy 37.68, Test_accy 53.71
2022-10-08 07:50:20,388 [foster.py] => Task 2, Epoch 12/34 => Loss 2.985, Loss_clf 0.753, Loss_fe 0.886, Loss_kd 0.950, Train_accy 38.15
2022-10-08 07:50:22,896 [foster.py] => Task 2, Epoch 13/34 => Loss 3.002, Loss_clf 0.763, Loss_fe 0.881, Loss_kd 0.959, Train_accy 37.53
2022-10-08 07:50:25,327 [foster.py] => Task 2, Epoch 14/34 => Loss 2.913, Loss_clf 0.728, Loss_fe 0.834, Loss_kd 0.954, Train_accy 37.53
2022-10-08 07:50:27,836 [foster.py] => Task 2, Epoch 15/34 => Loss 2.869, Loss_clf 0.703, Loss_fe 0.810, Loss_kd 0.956, Train_accy 38.07
2022-10-08 07:50:31,132 [foster.py] => Task 2, Epoch 16/34 => Loss 2.883, Loss_clf 0.711, Loss_fe 0.812, Loss_kd 0.960, Train_accy 38.69, Test_accy 53.71
2022-10-08 07:50:33,595 [foster.py] => Task 2, Epoch 17/34 => Loss 2.827, Loss_clf 0.692, Loss_fe 0.786, Loss_kd 0.953, Train_accy 38.15
2022-10-08 07:50:36,011 [foster.py] => Task 2, Epoch 18/34 => Loss 2.829, Loss_clf 0.697, Loss_fe 0.786, Loss_kd 0.950, Train_accy 39.08
2022-10-08 07:50:38,529 [foster.py] => Task 2, Epoch 19/34 => Loss 2.780, Loss_clf 0.666, Loss_fe 0.757, Loss_kd 0.958, Train_accy 39.63
2022-10-08 07:50:41,051 [foster.py] => Task 2, Epoch 20/34 => Loss 2.766, Loss_clf 0.671, Loss_fe 0.752, Loss_kd 0.948, Train_accy 39.63
2022-10-08 07:50:44,383 [foster.py] => Task 2, Epoch 21/34 => Loss 2.712, Loss_clf 0.634, Loss_fe 0.722, Loss_kd 0.957, Train_accy 40.87, Test_accy 55.50
2022-10-08 07:50:46,978 [foster.py] => Task 2, Epoch 22/34 => Loss 2.751, Loss_clf 0.664, Loss_fe 0.738, Loss_kd 0.953, Train_accy 39.70
2022-10-08 07:50:49,426 [foster.py] => Task 2, Epoch 23/34 => Loss 2.759, Loss_clf 0.665, Loss_fe 0.742, Loss_kd 0.954, Train_accy 39.47
2022-10-08 07:50:51,934 [foster.py] => Task 2, Epoch 24/34 => Loss 2.732, Loss_clf 0.651, Loss_fe 0.731, Loss_kd 0.953, Train_accy 38.93
2022-10-08 07:50:54,423 [foster.py] => Task 2, Epoch 25/34 => Loss 2.711, Loss_clf 0.640, Loss_fe 0.714, Loss_kd 0.958, Train_accy 40.95
2022-10-08 07:50:57,792 [foster.py] => Task 2, Epoch 26/34 => Loss 2.686, Loss_clf 0.628, Loss_fe 0.711, Loss_kd 0.950, Train_accy 39.70, Test_accy 55.24
2022-10-08 07:51:00,337 [foster.py] => Task 2, Epoch 27/34 => Loss 2.707, Loss_clf 0.632, Loss_fe 0.722, Loss_kd 0.955, Train_accy 41.03
2022-10-08 07:51:02,822 [foster.py] => Task 2, Epoch 28/34 => Loss 2.675, Loss_clf 0.619, Loss_fe 0.698, Loss_kd 0.959, Train_accy 42.58
2022-10-08 07:51:05,366 [foster.py] => Task 2, Epoch 29/34 => Loss 2.639, Loss_clf 0.610, Loss_fe 0.689, Loss_kd 0.946, Train_accy 40.09
2022-10-08 07:51:07,857 [foster.py] => Task 2, Epoch 30/34 => Loss 2.703, Loss_clf 0.634, Loss_fe 0.719, Loss_kd 0.953, Train_accy 40.09
2022-10-08 07:51:11,134 [foster.py] => Task 2, Epoch 31/34 => Loss 2.710, Loss_clf 0.642, Loss_fe 0.721, Loss_kd 0.951, Train_accy 40.02, Test_accy 55.75
2022-10-08 07:51:13,608 [foster.py] => Task 2, Epoch 32/34 => Loss 2.630, Loss_clf 0.597, Loss_fe 0.677, Loss_kd 0.957, Train_accy 40.02
2022-10-08 07:51:16,052 [foster.py] => Task 2, Epoch 33/34 => Loss 2.667, Loss_clf 0.610, Loss_fe 0.699, Loss_kd 0.958, Train_accy 41.80
2022-10-08 07:51:18,560 [foster.py] => Task 2, Epoch 34/34 => Loss 2.671, Loss_clf 0.621, Loss_fe 0.695, Loss_kd 0.957, Train_accy 42.35
2022-10-08 07:51:18,561 [foster.py] => do not weight align teacher!
2022-10-08 07:51:18,561 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 07:51:22,353 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.068,  Train_accy 11.66, Test_accy 43.73
2022-10-08 07:51:25,191 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.989,  Train_accy 12.74
2022-10-08 07:51:28,033 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.944,  Train_accy 12.51
2022-10-08 07:51:30,842 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.923,  Train_accy 13.21
2022-10-08 07:51:33,729 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.929,  Train_accy 13.36
2022-10-08 07:51:37,272 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.907,  Train_accy 13.21, Test_accy 45.78
2022-10-08 07:51:40,116 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.916,  Train_accy 12.98
2022-10-08 07:51:42,984 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.899,  Train_accy 13.36
2022-10-08 07:51:45,800 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.901,  Train_accy 12.90
2022-10-08 07:51:48,735 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.898,  Train_accy 13.52
2022-10-08 07:51:52,403 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.888,  Train_accy 13.68, Test_accy 48.08
2022-10-08 07:51:55,291 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.881,  Train_accy 13.36
2022-10-08 07:51:58,120 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.881,  Train_accy 13.44
2022-10-08 07:52:00,980 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.884,  Train_accy 13.83
2022-10-08 07:52:03,910 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.879,  Train_accy 13.83
2022-10-08 07:52:07,497 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.872,  Train_accy 13.36, Test_accy 47.83
2022-10-08 07:52:10,356 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.885,  Train_accy 13.99
2022-10-08 07:52:13,231 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.880,  Train_accy 13.83
2022-10-08 07:52:16,061 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.878,  Train_accy 14.53
2022-10-08 07:52:18,939 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.885,  Train_accy 13.99
2022-10-08 07:52:22,471 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.871,  Train_accy 14.30, Test_accy 47.83
2022-10-08 07:52:25,343 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.861,  Train_accy 14.22
2022-10-08 07:52:28,232 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.861,  Train_accy 14.45
2022-10-08 07:52:31,085 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.862,  Train_accy 13.91
2022-10-08 07:52:33,947 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.882,  Train_accy 14.76
2022-10-08 07:52:37,531 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.865,  Train_accy 13.83, Test_accy 48.85
2022-10-08 07:52:37,532 [foster.py] => do not weight align student!
2022-10-08 07:52:38,270 [foster.py] => darknet eval: 
2022-10-08 07:52:38,270 [foster.py] => CNN top1 curve: 48.85
2022-10-08 07:52:38,270 [foster.py] => CNN top5 curve: 92.58
2022-10-08 07:52:38,271 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 07:52:47,468 [foster.py] => Exemplar size: 340
2022-10-08 07:52:47,468 [trainer.py] => CNN: {'total': 55.24, 'old': 65.98, 'new': 24.0, 'base': 85.8, 'compound': 31.98}
2022-10-08 07:52:47,468 [trainer.py] => CNN top1 curve: [88.17, 71.13, 55.24]
2022-10-08 07:52:47,468 [trainer.py] => CNN base curve: [88.17, 88.17, 85.8]
2022-10-08 07:52:47,468 [trainer.py] => CNN old curve: [88.17, 88.17, 65.98]
2022-10-08 07:52:47,468 [trainer.py] => CNN new curve: [0, 47.54, 24.0]
2022-10-08 07:52:47,468 [trainer.py] => CNN compound curve: [0, 47.54, 31.98]
2022-10-08 07:52:47,468 [trainer.py] => NME: {'total': 62.66, 'old': 67.01, 'new': 50.0, 'base': 74.56, 'compound': 53.6}
2022-10-08 07:52:47,468 [trainer.py] => NME top1 curve: [86.98, 79.04, 62.66]
2022-10-08 07:52:47,468 [trainer.py] => NME base curve: [86.98, 83.43, 74.56]
2022-10-08 07:52:47,468 [trainer.py] => NME old curve: [86.98, 83.43, 67.01]
2022-10-08 07:52:47,468 [trainer.py] => NME new curve: [0, 72.95, 50.0]
2022-10-08 07:52:47,468 [trainer.py] => NME compound curve: [0, 72.95, 53.6]
2022-10-08 07:52:47,687 [foster.py] => Learning on 17-22
2022-10-08 07:52:47,688 [foster.py] => All params: 22395581
2022-10-08 07:52:47,688 [foster.py] => Trainable params: 11210348
2022-10-08 07:52:47,697 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 07:52:51,121 [foster.py] => Task 3, Epoch 1/34 => Loss 6.453, Loss_clf 2.097, Loss_fe 2.498, Loss_kd 1.436, Train_accy 31.63, Test_accy 42.97
2022-10-08 07:52:53,691 [foster.py] => Task 3, Epoch 2/34 => Loss 4.797, Loss_clf 1.214, Loss_fe 1.772, Loss_kd 1.400, Train_accy 27.84
2022-10-08 07:52:56,271 [foster.py] => Task 3, Epoch 3/34 => Loss 4.540, Loss_clf 1.134, Loss_fe 1.603, Loss_kd 1.394, Train_accy 28.21
2022-10-08 07:52:58,839 [foster.py] => Task 3, Epoch 4/34 => Loss 4.342, Loss_clf 1.067, Loss_fe 1.471, Loss_kd 1.395, Train_accy 27.92
2022-10-08 07:53:01,424 [foster.py] => Task 3, Epoch 5/34 => Loss 4.242, Loss_clf 1.048, Loss_fe 1.398, Loss_kd 1.387, Train_accy 30.39
2022-10-08 07:53:04,888 [foster.py] => Task 3, Epoch 6/34 => Loss 4.159, Loss_clf 1.031, Loss_fe 1.335, Loss_kd 1.386, Train_accy 29.88, Test_accy 44.55
2022-10-08 07:53:07,495 [foster.py] => Task 3, Epoch 7/34 => Loss 4.070, Loss_clf 0.996, Loss_fe 1.275, Loss_kd 1.390, Train_accy 29.45
2022-10-08 07:53:10,106 [foster.py] => Task 3, Epoch 8/34 => Loss 3.981, Loss_clf 0.956, Loss_fe 1.221, Loss_kd 1.394, Train_accy 29.59
2022-10-08 07:53:12,692 [foster.py] => Task 3, Epoch 9/34 => Loss 3.964, Loss_clf 0.971, Loss_fe 1.187, Loss_kd 1.395, Train_accy 31.12
2022-10-08 07:53:15,321 [foster.py] => Task 3, Epoch 10/34 => Loss 3.915, Loss_clf 0.957, Loss_fe 1.151, Loss_kd 1.397, Train_accy 30.32
2022-10-08 07:53:18,910 [foster.py] => Task 3, Epoch 11/34 => Loss 3.852, Loss_clf 0.938, Loss_fe 1.117, Loss_kd 1.389, Train_accy 31.05, Test_accy 44.16
2022-10-08 07:53:21,472 [foster.py] => Task 3, Epoch 12/34 => Loss 3.803, Loss_clf 0.918, Loss_fe 1.085, Loss_kd 1.391, Train_accy 31.63
2022-10-08 07:53:24,071 [foster.py] => Task 3, Epoch 13/34 => Loss 3.787, Loss_clf 0.910, Loss_fe 1.070, Loss_kd 1.396, Train_accy 30.32
2022-10-08 07:53:26,753 [foster.py] => Task 3, Epoch 14/34 => Loss 3.707, Loss_clf 0.888, Loss_fe 1.026, Loss_kd 1.386, Train_accy 31.05
2022-10-08 07:53:29,367 [foster.py] => Task 3, Epoch 15/34 => Loss 3.692, Loss_clf 0.875, Loss_fe 1.019, Loss_kd 1.390, Train_accy 30.25
2022-10-08 07:53:32,892 [foster.py] => Task 3, Epoch 16/34 => Loss 3.685, Loss_clf 0.872, Loss_fe 1.008, Loss_kd 1.395, Train_accy 32.87, Test_accy 45.35
2022-10-08 07:53:35,483 [foster.py] => Task 3, Epoch 17/34 => Loss 3.640, Loss_clf 0.861, Loss_fe 0.980, Loss_kd 1.391, Train_accy 31.27
2022-10-08 07:53:38,076 [foster.py] => Task 3, Epoch 18/34 => Loss 3.606, Loss_clf 0.838, Loss_fe 0.965, Loss_kd 1.394, Train_accy 32.29
2022-10-08 07:53:40,696 [foster.py] => Task 3, Epoch 19/34 => Loss 3.566, Loss_clf 0.821, Loss_fe 0.940, Loss_kd 1.394, Train_accy 33.02
2022-10-08 07:53:43,291 [foster.py] => Task 3, Epoch 20/34 => Loss 3.613, Loss_clf 0.840, Loss_fe 0.959, Loss_kd 1.401, Train_accy 33.89
2022-10-08 07:53:46,820 [foster.py] => Task 3, Epoch 21/34 => Loss 3.586, Loss_clf 0.837, Loss_fe 0.945, Loss_kd 1.394, Train_accy 31.71, Test_accy 44.95
2022-10-08 07:53:49,441 [foster.py] => Task 3, Epoch 22/34 => Loss 3.582, Loss_clf 0.822, Loss_fe 0.945, Loss_kd 1.402, Train_accy 33.38
2022-10-08 07:53:52,029 [foster.py] => Task 3, Epoch 23/34 => Loss 3.566, Loss_clf 0.829, Loss_fe 0.935, Loss_kd 1.392, Train_accy 33.38
2022-10-08 07:53:54,658 [foster.py] => Task 3, Epoch 24/34 => Loss 3.513, Loss_clf 0.808, Loss_fe 0.911, Loss_kd 1.386, Train_accy 34.40
2022-10-08 07:53:57,245 [foster.py] => Task 3, Epoch 25/34 => Loss 3.535, Loss_clf 0.816, Loss_fe 0.910, Loss_kd 1.398, Train_accy 34.18
2022-10-08 07:54:00,802 [foster.py] => Task 3, Epoch 26/34 => Loss 3.487, Loss_clf 0.794, Loss_fe 0.891, Loss_kd 1.392, Train_accy 32.00, Test_accy 45.54
2022-10-08 07:54:03,368 [foster.py] => Task 3, Epoch 27/34 => Loss 3.488, Loss_clf 0.794, Loss_fe 0.896, Loss_kd 1.390, Train_accy 32.94
2022-10-08 07:54:06,023 [foster.py] => Task 3, Epoch 28/34 => Loss 3.477, Loss_clf 0.778, Loss_fe 0.883, Loss_kd 1.402, Train_accy 34.99
2022-10-08 07:54:08,585 [foster.py] => Task 3, Epoch 29/34 => Loss 3.474, Loss_clf 0.789, Loss_fe 0.883, Loss_kd 1.392, Train_accy 34.18
2022-10-08 07:54:11,193 [foster.py] => Task 3, Epoch 30/34 => Loss 3.493, Loss_clf 0.793, Loss_fe 0.894, Loss_kd 1.395, Train_accy 33.67
2022-10-08 07:54:14,766 [foster.py] => Task 3, Epoch 31/34 => Loss 3.486, Loss_clf 0.795, Loss_fe 0.887, Loss_kd 1.394, Train_accy 34.69, Test_accy 45.54
2022-10-08 07:54:17,409 [foster.py] => Task 3, Epoch 32/34 => Loss 3.498, Loss_clf 0.792, Loss_fe 0.892, Loss_kd 1.402, Train_accy 33.53
2022-10-08 07:54:20,021 [foster.py] => Task 3, Epoch 33/34 => Loss 3.515, Loss_clf 0.793, Loss_fe 0.902, Loss_kd 1.406, Train_accy 34.18
2022-10-08 07:54:22,603 [foster.py] => Task 3, Epoch 34/34 => Loss 3.509, Loss_clf 0.802, Loss_fe 0.902, Loss_kd 1.395, Train_accy 34.40
2022-10-08 07:54:22,604 [foster.py] => do not weight align teacher!
2022-10-08 07:54:22,604 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 07:54:26,559 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.343,  Train_accy 12.54, Test_accy 38.61
2022-10-08 07:54:29,551 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.282,  Train_accy 13.27
2022-10-08 07:54:32,574 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.260,  Train_accy 13.05
2022-10-08 07:54:35,559 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.245,  Train_accy 13.19
2022-10-08 07:54:38,570 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.230,  Train_accy 13.12
2022-10-08 07:54:42,373 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.232,  Train_accy 13.48, Test_accy 38.81
2022-10-08 07:54:45,333 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.221,  Train_accy 13.41
2022-10-08 07:54:48,303 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.213,  Train_accy 13.27
2022-10-08 07:54:51,286 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.200,  Train_accy 13.85
2022-10-08 07:54:54,298 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.203,  Train_accy 13.27
2022-10-08 07:54:58,129 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.199,  Train_accy 14.29, Test_accy 39.60
2022-10-08 07:55:01,182 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.194,  Train_accy 13.41
2022-10-08 07:55:04,214 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.201,  Train_accy 14.21
2022-10-08 07:55:07,257 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.191,  Train_accy 14.29
2022-10-08 07:55:10,357 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.202,  Train_accy 14.50
2022-10-08 07:55:17,668 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.183,  Train_accy 14.21, Test_accy 39.60
2022-10-08 07:55:20,843 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.194,  Train_accy 14.29
2022-10-08 07:55:23,947 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.192,  Train_accy 13.85
2022-10-08 07:55:26,942 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.184,  Train_accy 14.29
2022-10-08 07:55:29,943 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.182,  Train_accy 14.43
2022-10-08 07:55:33,699 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.189,  Train_accy 14.58, Test_accy 39.80
2022-10-08 07:55:36,643 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.190,  Train_accy 14.50
2022-10-08 07:55:39,639 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.178,  Train_accy 14.58
2022-10-08 07:55:42,619 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.193,  Train_accy 15.23
2022-10-08 07:55:45,613 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.175,  Train_accy 14.29
2022-10-08 07:55:49,389 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.182,  Train_accy 15.01, Test_accy 39.60
2022-10-08 07:55:49,389 [foster.py] => do not weight align student!
2022-10-08 07:55:50,163 [foster.py] => darknet eval: 
2022-10-08 07:55:50,163 [foster.py] => CNN top1 curve: 39.6
2022-10-08 07:55:50,163 [foster.py] => CNN top5 curve: 81.39
2022-10-08 07:55:50,164 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 07:56:01,043 [foster.py] => Exemplar size: 440
2022-10-08 07:56:01,043 [trainer.py] => CNN: {'total': 45.54, 'old': 53.96, 'new': 16.67, 'base': 82.84, 'compound': 26.79}
2022-10-08 07:56:01,043 [trainer.py] => CNN top1 curve: [88.17, 71.13, 55.24, 45.54]
2022-10-08 07:56:01,043 [trainer.py] => CNN base curve: [88.17, 88.17, 85.8, 82.84]
2022-10-08 07:56:01,043 [trainer.py] => CNN old curve: [88.17, 88.17, 65.98, 53.96]
2022-10-08 07:56:01,043 [trainer.py] => CNN new curve: [0, 47.54, 24.0, 16.67]
2022-10-08 07:56:01,043 [trainer.py] => CNN compound curve: [0, 47.54, 31.98, 26.79]
2022-10-08 07:56:01,043 [trainer.py] => NME: {'total': 52.87, 'old': 55.5, 'new': 43.86, 'base': 69.82, 'compound': 44.35}
2022-10-08 07:56:01,043 [trainer.py] => NME top1 curve: [86.98, 79.04, 62.66, 52.87]
2022-10-08 07:56:01,043 [trainer.py] => NME base curve: [86.98, 83.43, 74.56, 69.82]
2022-10-08 07:56:01,043 [trainer.py] => NME old curve: [86.98, 83.43, 67.01, 55.5]
2022-10-08 07:56:01,043 [trainer.py] => NME new curve: [0, 72.95, 50.0, 43.86]
2022-10-08 07:56:01,043 [trainer.py] => NME compound curve: [0, 72.95, 53.6, 44.35]
2022-10-08 07:56:01,044 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 07:56:01,044 [trainer.py] => prefix: cil
2022-10-08 07:56:01,044 [trainer.py] => dataset: CFEE
2022-10-08 07:56:01,045 [trainer.py] => memory_size: 2000
2022-10-08 07:56:01,045 [trainer.py] => memory_per_class: 20
2022-10-08 07:56:01,045 [trainer.py] => fixed_memory: True
2022-10-08 07:56:01,045 [trainer.py] => shuffle: True
2022-10-08 07:56:01,045 [trainer.py] => init_cls: 7
2022-10-08 07:56:01,045 [trainer.py] => increment: 5
2022-10-08 07:56:01,045 [trainer.py] => model_name: foster
2022-10-08 07:56:01,045 [trainer.py] => convnet_type: resnet18
2022-10-08 07:56:01,045 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 07:56:01,045 [trainer.py] => seed: 1993
2022-10-08 07:56:01,045 [trainer.py] => beta1: 0.96
2022-10-08 07:56:01,045 [trainer.py] => beta2: 0.97
2022-10-08 07:56:01,045 [trainer.py] => oofc: ft
2022-10-08 07:56:01,045 [trainer.py] => is_teacher_wa: False
2022-10-08 07:56:01,045 [trainer.py] => is_student_wa: False
2022-10-08 07:56:01,045 [trainer.py] => lambda_okd: 1
2022-10-08 07:56:01,045 [trainer.py] => wa_value: 1
2022-10-08 07:56:01,045 [trainer.py] => init_epochs: 40
2022-10-08 07:56:01,045 [trainer.py] => init_lr: 0.01
2022-10-08 07:56:01,045 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 07:56:01,045 [trainer.py] => boosting_epochs: 34
2022-10-08 07:56:01,045 [trainer.py] => compression_epochs: 26
2022-10-08 07:56:01,045 [trainer.py] => lr: 0.001
2022-10-08 07:56:01,045 [trainer.py] => batch_size: 32
2022-10-08 07:56:01,045 [trainer.py] => weight_decay: 0.0005
2022-10-08 07:56:01,045 [trainer.py] => num_workers: 8
2022-10-08 07:56:01,045 [trainer.py] => T: 2
2022-10-08 07:56:01,045 [trainer.py] => nb_runs: 3
2022-10-08 07:56:01,045 [trainer.py] => fold: 10
2022-10-08 07:56:01,045 [data.py] => ========== Fold:6 ==========
2022-10-08 07:56:01,051 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 8, 15, 13, 17, 9, 11, 19, 21, 14, 10, 18, 12, 7, 16]
2022-10-08 07:56:01,261 [foster.py] => Learning on 0-7
2022-10-08 07:56:01,261 [foster.py] => All params: 11183694
2022-10-08 07:56:01,261 [foster.py] => Trainable params: 11183694
2022-10-08 07:56:03,503 [foster.py] => Task 0, Epoch 1/40 => Loss 1.333, Train_accy 49.17
2022-10-08 07:56:06,351 [foster.py] => Task 0, Epoch 2/40 => Loss 0.560, Train_accy 80.77, Test_accy 83.23
2022-10-08 07:56:09,168 [foster.py] => Task 0, Epoch 3/40 => Loss 0.358, Train_accy 86.17, Test_accy 80.75
2022-10-08 07:56:11,965 [foster.py] => Task 0, Epoch 4/40 => Loss 0.308, Train_accy 89.76, Test_accy 88.20
2022-10-08 07:56:14,804 [foster.py] => Task 0, Epoch 5/40 => Loss 0.250, Train_accy 91.01, Test_accy 88.82
2022-10-08 07:56:17,040 [foster.py] => Task 0, Epoch 6/40 => Loss 0.195, Train_accy 93.08
2022-10-08 07:56:19,860 [foster.py] => Task 0, Epoch 7/40 => Loss 0.168, Train_accy 94.74, Test_accy 87.58
2022-10-08 07:56:22,705 [foster.py] => Task 0, Epoch 8/40 => Loss 0.150, Train_accy 94.74, Test_accy 85.09
2022-10-08 07:56:25,604 [foster.py] => Task 0, Epoch 9/40 => Loss 0.133, Train_accy 95.78, Test_accy 88.20
2022-10-08 07:56:28,398 [foster.py] => Task 0, Epoch 10/40 => Loss 0.111, Train_accy 96.68, Test_accy 85.71
2022-10-08 07:56:30,665 [foster.py] => Task 0, Epoch 11/40 => Loss 0.112, Train_accy 96.33
2022-10-08 07:56:33,538 [foster.py] => Task 0, Epoch 12/40 => Loss 0.083, Train_accy 97.16, Test_accy 86.96
2022-10-08 07:56:36,340 [foster.py] => Task 0, Epoch 13/40 => Loss 0.073, Train_accy 97.99, Test_accy 85.71
2022-10-08 07:56:39,155 [foster.py] => Task 0, Epoch 14/40 => Loss 0.063, Train_accy 98.06, Test_accy 83.23
2022-10-08 07:56:41,942 [foster.py] => Task 0, Epoch 15/40 => Loss 0.051, Train_accy 98.89, Test_accy 88.20
2022-10-08 07:56:44,191 [foster.py] => Task 0, Epoch 16/40 => Loss 0.065, Train_accy 98.62
2022-10-08 07:56:47,026 [foster.py] => Task 0, Epoch 17/40 => Loss 0.044, Train_accy 99.03, Test_accy 91.93
2022-10-08 07:56:49,868 [foster.py] => Task 0, Epoch 18/40 => Loss 0.040, Train_accy 99.10, Test_accy 88.82
2022-10-08 07:56:52,708 [foster.py] => Task 0, Epoch 19/40 => Loss 0.031, Train_accy 99.24, Test_accy 88.82
2022-10-08 07:56:55,522 [foster.py] => Task 0, Epoch 20/40 => Loss 0.032, Train_accy 99.31, Test_accy 90.68
2022-10-08 07:56:57,813 [foster.py] => Task 0, Epoch 21/40 => Loss 0.030, Train_accy 99.24
2022-10-08 07:57:00,641 [foster.py] => Task 0, Epoch 22/40 => Loss 0.032, Train_accy 99.38, Test_accy 87.58
2022-10-08 07:57:03,482 [foster.py] => Task 0, Epoch 23/40 => Loss 0.026, Train_accy 99.38, Test_accy 89.44
2022-10-08 07:57:06,321 [foster.py] => Task 0, Epoch 24/40 => Loss 0.022, Train_accy 99.79, Test_accy 88.82
2022-10-08 07:57:09,168 [foster.py] => Task 0, Epoch 25/40 => Loss 0.046, Train_accy 99.17, Test_accy 90.68
2022-10-08 07:57:11,456 [foster.py] => Task 0, Epoch 26/40 => Loss 0.022, Train_accy 99.65
2022-10-08 07:57:14,279 [foster.py] => Task 0, Epoch 27/40 => Loss 0.021, Train_accy 99.72, Test_accy 90.68
2022-10-08 07:57:17,139 [foster.py] => Task 0, Epoch 28/40 => Loss 0.023, Train_accy 99.65, Test_accy 90.68
2022-10-08 07:57:19,976 [foster.py] => Task 0, Epoch 29/40 => Loss 0.019, Train_accy 99.79, Test_accy 90.68
2022-10-08 07:57:22,812 [foster.py] => Task 0, Epoch 30/40 => Loss 0.011, Train_accy 99.86, Test_accy 90.68
2022-10-08 07:57:25,073 [foster.py] => Task 0, Epoch 31/40 => Loss 0.022, Train_accy 99.52
2022-10-08 07:57:27,938 [foster.py] => Task 0, Epoch 32/40 => Loss 0.014, Train_accy 99.86, Test_accy 88.20
2022-10-08 07:57:30,770 [foster.py] => Task 0, Epoch 33/40 => Loss 0.017, Train_accy 99.79, Test_accy 91.30
2022-10-08 07:57:33,563 [foster.py] => Task 0, Epoch 34/40 => Loss 0.019, Train_accy 99.79, Test_accy 90.06
2022-10-08 07:57:36,381 [foster.py] => Task 0, Epoch 35/40 => Loss 0.014, Train_accy 99.93, Test_accy 90.06
2022-10-08 07:57:38,611 [foster.py] => Task 0, Epoch 36/40 => Loss 0.012, Train_accy 99.93
2022-10-08 07:57:41,422 [foster.py] => Task 0, Epoch 37/40 => Loss 0.014, Train_accy 99.86, Test_accy 90.68
2022-10-08 07:57:44,256 [foster.py] => Task 0, Epoch 38/40 => Loss 0.019, Train_accy 99.65, Test_accy 91.30
2022-10-08 07:57:47,085 [foster.py] => Task 0, Epoch 39/40 => Loss 0.011, Train_accy 100.00, Test_accy 91.30
2022-10-08 07:57:49,955 [foster.py] => Task 0, Epoch 40/40 => Loss 0.015, Train_accy 99.86, Test_accy 91.93
2022-10-08 07:57:49,956 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 07:57:56,304 [foster.py] => Exemplar size: 140
2022-10-08 07:57:56,304 [trainer.py] => CNN: {'total': 91.93, 'old': 91.93, 'new': 0, 'base': 91.93, 'compound': 0}
2022-10-08 07:57:56,304 [trainer.py] => CNN top1 curve: [91.93]
2022-10-08 07:57:56,304 [trainer.py] => CNN base curve: [91.93]
2022-10-08 07:57:56,304 [trainer.py] => CNN old curve: [91.93]
2022-10-08 07:57:56,304 [trainer.py] => CNN new curve: [0]
2022-10-08 07:57:56,304 [trainer.py] => CNN compound curve: [0]
2022-10-08 07:57:56,304 [trainer.py] => NME: {'total': 91.3, 'old': 91.3, 'new': 0, 'base': 91.3, 'compound': 0}
2022-10-08 07:57:56,304 [trainer.py] => NME top1 curve: [91.3]
2022-10-08 07:57:56,305 [trainer.py] => NME base curve: [91.3]
2022-10-08 07:57:56,305 [trainer.py] => NME old curve: [91.3]
2022-10-08 07:57:56,305 [trainer.py] => NME new curve: [0]
2022-10-08 07:57:56,305 [trainer.py] => NME compound curve: [0]
2022-10-08 07:57:56,524 [foster.py] => Learning on 7-12
2022-10-08 07:57:56,525 [foster.py] => All params: 22375071
2022-10-08 07:57:56,525 [foster.py] => Trainable params: 11194968
2022-10-08 07:57:56,534 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 07:57:59,576 [foster.py] => Task 1, Epoch 1/34 => Loss 4.757, Loss_clf 2.139, Loss_fe 1.896, Loss_kd 0.421, Train_accy 39.74, Test_accy 65.70
2022-10-08 07:58:01,833 [foster.py] => Task 1, Epoch 2/34 => Loss 2.478, Loss_clf 0.645, Loss_fe 1.144, Loss_kd 0.402, Train_accy 67.18
2022-10-08 07:58:04,110 [foster.py] => Task 1, Epoch 3/34 => Loss 2.130, Loss_clf 0.525, Loss_fe 0.940, Loss_kd 0.388, Train_accy 51.54
2022-10-08 07:58:06,405 [foster.py] => Task 1, Epoch 4/34 => Loss 1.991, Loss_clf 0.474, Loss_fe 0.835, Loss_kd 0.398, Train_accy 55.04
2022-10-08 07:58:08,689 [foster.py] => Task 1, Epoch 5/34 => Loss 1.904, Loss_clf 0.467, Loss_fe 0.770, Loss_kd 0.389, Train_accy 53.16
2022-10-08 07:58:11,699 [foster.py] => Task 1, Epoch 6/34 => Loss 1.846, Loss_clf 0.452, Loss_fe 0.714, Loss_kd 0.397, Train_accy 53.42, Test_accy 72.92
2022-10-08 07:58:13,998 [foster.py] => Task 1, Epoch 7/34 => Loss 1.737, Loss_clf 0.413, Loss_fe 0.654, Loss_kd 0.391, Train_accy 52.91
2022-10-08 07:58:16,262 [foster.py] => Task 1, Epoch 8/34 => Loss 1.718, Loss_clf 0.415, Loss_fe 0.619, Loss_kd 0.399, Train_accy 55.73
2022-10-08 07:58:18,552 [foster.py] => Task 1, Epoch 9/34 => Loss 1.637, Loss_clf 0.393, Loss_fe 0.576, Loss_kd 0.390, Train_accy 54.79
2022-10-08 07:58:20,866 [foster.py] => Task 1, Epoch 10/34 => Loss 1.596, Loss_clf 0.376, Loss_fe 0.543, Loss_kd 0.395, Train_accy 56.15
2022-10-08 07:58:23,830 [foster.py] => Task 1, Epoch 11/34 => Loss 1.567, Loss_clf 0.362, Loss_fe 0.526, Loss_kd 0.396, Train_accy 57.09, Test_accy 72.20
2022-10-08 07:58:26,140 [foster.py] => Task 1, Epoch 12/34 => Loss 1.536, Loss_clf 0.358, Loss_fe 0.505, Loss_kd 0.393, Train_accy 56.07
2022-10-08 07:58:28,387 [foster.py] => Task 1, Epoch 13/34 => Loss 1.560, Loss_clf 0.364, Loss_fe 0.509, Loss_kd 0.401, Train_accy 56.92
2022-10-08 07:58:30,681 [foster.py] => Task 1, Epoch 14/34 => Loss 1.481, Loss_clf 0.337, Loss_fe 0.470, Loss_kd 0.394, Train_accy 56.24
2022-10-08 07:58:32,994 [foster.py] => Task 1, Epoch 15/34 => Loss 1.451, Loss_clf 0.328, Loss_fe 0.454, Loss_kd 0.390, Train_accy 55.13
2022-10-08 07:58:36,009 [foster.py] => Task 1, Epoch 16/34 => Loss 1.516, Loss_clf 0.356, Loss_fe 0.484, Loss_kd 0.394, Train_accy 55.81, Test_accy 72.56
2022-10-08 07:58:38,303 [foster.py] => Task 1, Epoch 17/34 => Loss 1.450, Loss_clf 0.326, Loss_fe 0.453, Loss_kd 0.391, Train_accy 58.55
2022-10-08 07:58:40,646 [foster.py] => Task 1, Epoch 18/34 => Loss 1.446, Loss_clf 0.325, Loss_fe 0.443, Loss_kd 0.395, Train_accy 58.03
2022-10-08 07:58:42,956 [foster.py] => Task 1, Epoch 19/34 => Loss 1.413, Loss_clf 0.324, Loss_fe 0.426, Loss_kd 0.387, Train_accy 57.09
2022-10-08 07:58:45,258 [foster.py] => Task 1, Epoch 20/34 => Loss 1.411, Loss_clf 0.315, Loss_fe 0.421, Loss_kd 0.394, Train_accy 58.72
2022-10-08 07:58:48,308 [foster.py] => Task 1, Epoch 21/34 => Loss 1.376, Loss_clf 0.303, Loss_fe 0.403, Loss_kd 0.391, Train_accy 57.18, Test_accy 73.29
2022-10-08 07:58:50,686 [foster.py] => Task 1, Epoch 22/34 => Loss 1.374, Loss_clf 0.300, Loss_fe 0.400, Loss_kd 0.393, Train_accy 59.32
2022-10-08 07:58:52,960 [foster.py] => Task 1, Epoch 23/34 => Loss 1.381, Loss_clf 0.302, Loss_fe 0.405, Loss_kd 0.393, Train_accy 57.52
2022-10-08 07:58:55,265 [foster.py] => Task 1, Epoch 24/34 => Loss 1.397, Loss_clf 0.306, Loss_fe 0.414, Loss_kd 0.395, Train_accy 58.80
2022-10-08 07:58:57,579 [foster.py] => Task 1, Epoch 25/34 => Loss 1.376, Loss_clf 0.308, Loss_fe 0.402, Loss_kd 0.389, Train_accy 57.52
2022-10-08 07:59:00,592 [foster.py] => Task 1, Epoch 26/34 => Loss 1.370, Loss_clf 0.299, Loss_fe 0.388, Loss_kd 0.399, Train_accy 57.95, Test_accy 73.29
2022-10-08 07:59:02,892 [foster.py] => Task 1, Epoch 27/34 => Loss 1.344, Loss_clf 0.295, Loss_fe 0.391, Loss_kd 0.384, Train_accy 57.26
2022-10-08 07:59:05,158 [foster.py] => Task 1, Epoch 28/34 => Loss 1.349, Loss_clf 0.289, Loss_fe 0.392, Loss_kd 0.390, Train_accy 58.89
2022-10-08 07:59:07,468 [foster.py] => Task 1, Epoch 29/34 => Loss 1.381, Loss_clf 0.314, Loss_fe 0.398, Loss_kd 0.390, Train_accy 58.21
2022-10-08 07:59:09,831 [foster.py] => Task 1, Epoch 30/34 => Loss 1.357, Loss_clf 0.300, Loss_fe 0.387, Loss_kd 0.391, Train_accy 59.15
2022-10-08 07:59:12,847 [foster.py] => Task 1, Epoch 31/34 => Loss 1.352, Loss_clf 0.299, Loss_fe 0.389, Loss_kd 0.387, Train_accy 56.92, Test_accy 73.29
2022-10-08 07:59:15,101 [foster.py] => Task 1, Epoch 32/34 => Loss 1.366, Loss_clf 0.295, Loss_fe 0.397, Loss_kd 0.393, Train_accy 59.06
2022-10-08 07:59:17,415 [foster.py] => Task 1, Epoch 33/34 => Loss 1.343, Loss_clf 0.292, Loss_fe 0.383, Loss_kd 0.390, Train_accy 57.69
2022-10-08 07:59:19,778 [foster.py] => Task 1, Epoch 34/34 => Loss 1.372, Loss_clf 0.301, Loss_fe 0.399, Loss_kd 0.392, Train_accy 57.95
2022-10-08 07:59:19,779 [foster.py] => do not weight align teacher!
2022-10-08 07:59:19,779 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 07:59:23,280 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.847,  Train_accy 11.88, Test_accy 52.71
2022-10-08 07:59:25,893 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.652,  Train_accy 12.05
2022-10-08 07:59:28,611 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.571,  Train_accy 13.33
2022-10-08 07:59:31,288 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.530,  Train_accy 14.62
2022-10-08 07:59:33,944 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.502,  Train_accy 17.44
2022-10-08 07:59:37,261 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.486,  Train_accy 19.06, Test_accy 57.76
2022-10-08 07:59:39,949 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.475,  Train_accy 21.20
2022-10-08 07:59:42,576 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.445,  Train_accy 23.76
2022-10-08 07:59:45,220 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.454,  Train_accy 24.27
2022-10-08 07:59:47,947 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.429,  Train_accy 24.44
2022-10-08 07:59:51,235 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.432,  Train_accy 26.24, Test_accy 61.37
2022-10-08 07:59:53,984 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.430,  Train_accy 28.21
2022-10-08 07:59:56,705 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.412,  Train_accy 27.52
2022-10-08 07:59:59,324 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.416,  Train_accy 28.29
2022-10-08 08:00:02,056 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.405,  Train_accy 28.46
2022-10-08 08:00:05,351 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.417,  Train_accy 29.15, Test_accy 62.09
2022-10-08 08:00:08,046 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.424,  Train_accy 27.95
2022-10-08 08:00:10,661 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.396,  Train_accy 28.38
2022-10-08 08:00:13,338 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.402,  Train_accy 30.60
2022-10-08 08:00:16,038 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.400,  Train_accy 29.32
2022-10-08 08:00:19,402 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.392,  Train_accy 28.80, Test_accy 63.54
2022-10-08 08:00:22,079 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.405,  Train_accy 30.17
2022-10-08 08:00:24,758 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.402,  Train_accy 30.60
2022-10-08 08:00:27,406 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.398,  Train_accy 29.74
2022-10-08 08:00:30,051 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.403,  Train_accy 29.91
2022-10-08 08:00:33,442 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.406,  Train_accy 31.20, Test_accy 63.18
2022-10-08 08:00:33,443 [foster.py] => do not weight align student!
2022-10-08 08:00:34,091 [foster.py] => darknet eval: 
2022-10-08 08:00:34,091 [foster.py] => CNN top1 curve: 63.18
2022-10-08 08:00:34,091 [foster.py] => CNN top5 curve: 97.83
2022-10-08 08:00:34,092 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 08:00:41,724 [foster.py] => Exemplar size: 240
2022-10-08 08:00:41,724 [trainer.py] => CNN: {'total': 73.65, 'old': 84.47, 'new': 58.62, 'base': 84.47, 'compound': 58.62}
2022-10-08 08:00:41,724 [trainer.py] => CNN top1 curve: [91.93, 73.65]
2022-10-08 08:00:41,724 [trainer.py] => CNN base curve: [91.93, 84.47]
2022-10-08 08:00:41,724 [trainer.py] => CNN old curve: [91.93, 84.47]
2022-10-08 08:00:41,725 [trainer.py] => CNN new curve: [0, 58.62]
2022-10-08 08:00:41,725 [trainer.py] => CNN compound curve: [0, 58.62]
2022-10-08 08:00:41,725 [trainer.py] => NME: {'total': 78.7, 'old': 80.75, 'new': 75.86, 'base': 80.75, 'compound': 75.86}
2022-10-08 08:00:41,725 [trainer.py] => NME top1 curve: [91.3, 78.7]
2022-10-08 08:00:41,725 [trainer.py] => NME base curve: [91.3, 80.75]
2022-10-08 08:00:41,725 [trainer.py] => NME old curve: [91.3, 80.75]
2022-10-08 08:00:41,725 [trainer.py] => NME new curve: [0, 75.86]
2022-10-08 08:00:41,725 [trainer.py] => NME compound curve: [0, 75.86]
2022-10-08 08:00:41,947 [foster.py] => Learning on 12-17
2022-10-08 08:00:41,948 [foster.py] => All params: 22385326
2022-10-08 08:00:41,948 [foster.py] => Trainable params: 11202658
2022-10-08 08:00:41,957 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 08:00:45,258 [foster.py] => Task 2, Epoch 1/34 => Loss 5.749, Loss_clf 2.141, Loss_fe 2.202, Loss_kd 0.992, Train_accy 35.76, Test_accy 47.30
2022-10-08 08:00:47,667 [foster.py] => Task 2, Epoch 2/34 => Loss 4.003, Loss_clf 1.072, Loss_fe 1.579, Loss_kd 0.954, Train_accy 37.18
2022-10-08 08:00:50,151 [foster.py] => Task 2, Epoch 3/34 => Loss 3.704, Loss_clf 0.969, Loss_fe 1.387, Loss_kd 0.951, Train_accy 36.39
2022-10-08 08:00:52,603 [foster.py] => Task 2, Epoch 4/34 => Loss 3.553, Loss_clf 0.928, Loss_fe 1.284, Loss_kd 0.947, Train_accy 35.84
2022-10-08 08:00:55,016 [foster.py] => Task 2, Epoch 5/34 => Loss 3.431, Loss_clf 0.890, Loss_fe 1.198, Loss_kd 0.948, Train_accy 38.04
2022-10-08 08:00:58,320 [foster.py] => Task 2, Epoch 6/34 => Loss 3.353, Loss_clf 0.877, Loss_fe 1.129, Loss_kd 0.951, Train_accy 36.71, Test_accy 53.73
2022-10-08 08:01:00,772 [foster.py] => Task 2, Epoch 7/34 => Loss 3.285, Loss_clf 0.845, Loss_fe 1.090, Loss_kd 0.953, Train_accy 38.12
2022-10-08 08:01:03,253 [foster.py] => Task 2, Epoch 8/34 => Loss 3.207, Loss_clf 0.823, Loss_fe 1.035, Loss_kd 0.951, Train_accy 37.10
2022-10-08 08:01:05,701 [foster.py] => Task 2, Epoch 9/34 => Loss 3.117, Loss_clf 0.797, Loss_fe 0.978, Loss_kd 0.948, Train_accy 35.84
2022-10-08 08:01:08,192 [foster.py] => Task 2, Epoch 10/34 => Loss 3.103, Loss_clf 0.789, Loss_fe 0.962, Loss_kd 0.954, Train_accy 38.27
2022-10-08 08:01:11,535 [foster.py] => Task 2, Epoch 11/34 => Loss 3.044, Loss_clf 0.769, Loss_fe 0.930, Loss_kd 0.950, Train_accy 37.18, Test_accy 54.76
2022-10-08 08:01:13,989 [foster.py] => Task 2, Epoch 12/34 => Loss 3.002, Loss_clf 0.742, Loss_fe 0.907, Loss_kd 0.955, Train_accy 38.90
2022-10-08 08:01:16,506 [foster.py] => Task 2, Epoch 13/34 => Loss 2.958, Loss_clf 0.735, Loss_fe 0.875, Loss_kd 0.952, Train_accy 40.16
2022-10-08 08:01:18,999 [foster.py] => Task 2, Epoch 14/34 => Loss 2.899, Loss_clf 0.710, Loss_fe 0.844, Loss_kd 0.950, Train_accy 40.78
2022-10-08 08:01:21,517 [foster.py] => Task 2, Epoch 15/34 => Loss 2.871, Loss_clf 0.699, Loss_fe 0.823, Loss_kd 0.952, Train_accy 39.29
2022-10-08 08:01:24,862 [foster.py] => Task 2, Epoch 16/34 => Loss 2.855, Loss_clf 0.692, Loss_fe 0.812, Loss_kd 0.954, Train_accy 41.33, Test_accy 54.76
2022-10-08 08:01:27,331 [foster.py] => Task 2, Epoch 17/34 => Loss 2.856, Loss_clf 0.690, Loss_fe 0.808, Loss_kd 0.959, Train_accy 41.33
2022-10-08 08:01:29,816 [foster.py] => Task 2, Epoch 18/34 => Loss 2.827, Loss_clf 0.688, Loss_fe 0.794, Loss_kd 0.950, Train_accy 41.65
2022-10-08 08:01:32,317 [foster.py] => Task 2, Epoch 19/34 => Loss 2.815, Loss_clf 0.678, Loss_fe 0.790, Loss_kd 0.951, Train_accy 39.37
2022-10-08 08:01:34,828 [foster.py] => Task 2, Epoch 20/34 => Loss 2.768, Loss_clf 0.661, Loss_fe 0.762, Loss_kd 0.949, Train_accy 41.80
2022-10-08 08:01:38,123 [foster.py] => Task 2, Epoch 21/34 => Loss 2.756, Loss_clf 0.652, Loss_fe 0.753, Loss_kd 0.954, Train_accy 41.96, Test_accy 54.50
2022-10-08 08:01:40,606 [foster.py] => Task 2, Epoch 22/34 => Loss 2.722, Loss_clf 0.639, Loss_fe 0.732, Loss_kd 0.953, Train_accy 41.49
2022-10-08 08:01:43,099 [foster.py] => Task 2, Epoch 23/34 => Loss 2.723, Loss_clf 0.637, Loss_fe 0.729, Loss_kd 0.958, Train_accy 42.67
2022-10-08 08:01:45,640 [foster.py] => Task 2, Epoch 24/34 => Loss 2.718, Loss_clf 0.634, Loss_fe 0.735, Loss_kd 0.952, Train_accy 42.98
2022-10-08 08:01:48,140 [foster.py] => Task 2, Epoch 25/34 => Loss 2.716, Loss_clf 0.636, Loss_fe 0.733, Loss_kd 0.951, Train_accy 43.14
2022-10-08 08:01:51,475 [foster.py] => Task 2, Epoch 26/34 => Loss 2.717, Loss_clf 0.628, Loss_fe 0.735, Loss_kd 0.956, Train_accy 43.53, Test_accy 55.01
2022-10-08 08:01:53,936 [foster.py] => Task 2, Epoch 27/34 => Loss 2.689, Loss_clf 0.625, Loss_fe 0.720, Loss_kd 0.949, Train_accy 42.43
2022-10-08 08:01:56,500 [foster.py] => Task 2, Epoch 28/34 => Loss 2.662, Loss_clf 0.611, Loss_fe 0.701, Loss_kd 0.953, Train_accy 43.69
2022-10-08 08:01:58,956 [foster.py] => Task 2, Epoch 29/34 => Loss 2.638, Loss_clf 0.600, Loss_fe 0.692, Loss_kd 0.950, Train_accy 42.75
2022-10-08 08:02:01,490 [foster.py] => Task 2, Epoch 30/34 => Loss 2.655, Loss_clf 0.605, Loss_fe 0.698, Loss_kd 0.954, Train_accy 42.98
2022-10-08 08:02:04,845 [foster.py] => Task 2, Epoch 31/34 => Loss 2.656, Loss_clf 0.604, Loss_fe 0.703, Loss_kd 0.952, Train_accy 42.67, Test_accy 55.01
2022-10-08 08:02:07,391 [foster.py] => Task 2, Epoch 32/34 => Loss 2.653, Loss_clf 0.602, Loss_fe 0.699, Loss_kd 0.955, Train_accy 44.39
2022-10-08 08:02:09,881 [foster.py] => Task 2, Epoch 33/34 => Loss 2.663, Loss_clf 0.608, Loss_fe 0.702, Loss_kd 0.954, Train_accy 43.14
2022-10-08 08:02:12,419 [foster.py] => Task 2, Epoch 34/34 => Loss 2.662, Loss_clf 0.603, Loss_fe 0.701, Loss_kd 0.959, Train_accy 45.02
2022-10-08 08:02:12,419 [foster.py] => do not weight align teacher!
2022-10-08 08:02:12,420 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 08:02:16,294 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.090,  Train_accy 12.39, Test_accy 43.44
2022-10-08 08:02:19,608 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 2.004,  Train_accy 13.25
2022-10-08 08:02:22,661 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.971,  Train_accy 13.65
2022-10-08 08:02:25,723 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.947,  Train_accy 13.57
2022-10-08 08:02:28,671 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.923,  Train_accy 13.33
2022-10-08 08:02:32,385 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.914,  Train_accy 13.88, Test_accy 47.04
2022-10-08 08:02:35,362 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.920,  Train_accy 14.12
2022-10-08 08:02:38,319 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.908,  Train_accy 13.65
2022-10-08 08:02:41,235 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.903,  Train_accy 14.43
2022-10-08 08:02:44,167 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.895,  Train_accy 13.96
2022-10-08 08:02:49,465 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.899,  Train_accy 14.12, Test_accy 48.07
2022-10-08 08:02:52,500 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.889,  Train_accy 14.20
2022-10-08 08:02:55,496 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.896,  Train_accy 14.04
2022-10-08 08:02:58,423 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.885,  Train_accy 14.04
2022-10-08 08:03:01,317 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.883,  Train_accy 13.73
2022-10-08 08:03:04,926 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.879,  Train_accy 13.65, Test_accy 47.30
2022-10-08 08:03:07,778 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.867,  Train_accy 14.20
2022-10-08 08:03:10,650 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.875,  Train_accy 14.43
2022-10-08 08:03:13,584 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.875,  Train_accy 14.04
2022-10-08 08:03:16,476 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.880,  Train_accy 14.27
2022-10-08 08:03:20,197 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.876,  Train_accy 14.20, Test_accy 48.07
2022-10-08 08:03:23,076 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.858,  Train_accy 14.27
2022-10-08 08:03:25,985 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.869,  Train_accy 13.80
2022-10-08 08:03:28,933 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.868,  Train_accy 14.35
2022-10-08 08:03:32,005 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.871,  Train_accy 14.51
2022-10-08 08:03:35,786 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.880,  Train_accy 14.51, Test_accy 48.84
2022-10-08 08:03:35,786 [foster.py] => do not weight align student!
2022-10-08 08:03:36,530 [foster.py] => darknet eval: 
2022-10-08 08:03:36,531 [foster.py] => CNN top1 curve: 48.84
2022-10-08 08:03:36,531 [foster.py] => CNN top5 curve: 93.06
2022-10-08 08:03:36,531 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 08:03:45,866 [foster.py] => Exemplar size: 340
2022-10-08 08:03:45,866 [trainer.py] => CNN: {'total': 55.27, 'old': 64.62, 'new': 32.14, 'base': 81.37, 'compound': 36.84}
2022-10-08 08:03:45,866 [trainer.py] => CNN top1 curve: [91.93, 73.65, 55.27]
2022-10-08 08:03:45,866 [trainer.py] => CNN base curve: [91.93, 84.47, 81.37]
2022-10-08 08:03:45,867 [trainer.py] => CNN old curve: [91.93, 84.47, 64.62]
2022-10-08 08:03:45,867 [trainer.py] => CNN new curve: [0, 58.62, 32.14]
2022-10-08 08:03:45,867 [trainer.py] => CNN compound curve: [0, 58.62, 36.84]
2022-10-08 08:03:45,867 [trainer.py] => NME: {'total': 64.27, 'old': 67.87, 'new': 55.36, 'base': 72.05, 'compound': 58.77}
2022-10-08 08:03:45,867 [trainer.py] => NME top1 curve: [91.3, 78.7, 64.27]
2022-10-08 08:03:45,867 [trainer.py] => NME base curve: [91.3, 80.75, 72.05]
2022-10-08 08:03:45,867 [trainer.py] => NME old curve: [91.3, 80.75, 67.87]
2022-10-08 08:03:45,867 [trainer.py] => NME new curve: [0, 75.86, 55.36]
2022-10-08 08:03:45,867 [trainer.py] => NME compound curve: [0, 75.86, 58.77]
2022-10-08 08:03:46,090 [foster.py] => Learning on 17-22
2022-10-08 08:03:46,091 [foster.py] => All params: 22395581
2022-10-08 08:03:46,091 [foster.py] => Trainable params: 11210348
2022-10-08 08:03:46,100 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 08:03:49,627 [foster.py] => Task 3, Epoch 1/34 => Loss 6.597, Loss_clf 2.252, Loss_fe 2.488, Loss_kd 1.435, Train_accy 32.17, Test_accy 42.86
2022-10-08 08:03:52,264 [foster.py] => Task 3, Epoch 2/34 => Loss 4.780, Loss_clf 1.195, Loss_fe 1.755, Loss_kd 1.414, Train_accy 31.15
2022-10-08 08:03:54,907 [foster.py] => Task 3, Epoch 3/34 => Loss 4.539, Loss_clf 1.123, Loss_fe 1.595, Loss_kd 1.408, Train_accy 32.17
2022-10-08 08:03:57,580 [foster.py] => Task 3, Epoch 4/34 => Loss 4.348, Loss_clf 1.060, Loss_fe 1.468, Loss_kd 1.407, Train_accy 31.07
2022-10-08 08:04:00,213 [foster.py] => Task 3, Epoch 5/34 => Loss 4.238, Loss_clf 1.028, Loss_fe 1.388, Loss_kd 1.408, Train_accy 32.24
2022-10-08 08:04:03,769 [foster.py] => Task 3, Epoch 6/34 => Loss 4.143, Loss_clf 1.010, Loss_fe 1.316, Loss_kd 1.404, Train_accy 34.94, Test_accy 43.25
2022-10-08 08:04:06,436 [foster.py] => Task 3, Epoch 7/34 => Loss 4.091, Loss_clf 0.998, Loss_fe 1.268, Loss_kd 1.410, Train_accy 33.41
2022-10-08 08:04:09,091 [foster.py] => Task 3, Epoch 8/34 => Loss 4.019, Loss_clf 0.975, Loss_fe 1.217, Loss_kd 1.412, Train_accy 33.92
2022-10-08 08:04:11,811 [foster.py] => Task 3, Epoch 9/34 => Loss 3.984, Loss_clf 0.977, Loss_fe 1.199, Loss_kd 1.397, Train_accy 33.63
2022-10-08 08:04:14,451 [foster.py] => Task 3, Epoch 10/34 => Loss 3.903, Loss_clf 0.946, Loss_fe 1.142, Loss_kd 1.402, Train_accy 34.43
2022-10-08 08:04:18,006 [foster.py] => Task 3, Epoch 11/34 => Loss 3.877, Loss_clf 0.928, Loss_fe 1.124, Loss_kd 1.410, Train_accy 34.87, Test_accy 44.84
2022-10-08 08:04:20,703 [foster.py] => Task 3, Epoch 12/34 => Loss 3.849, Loss_clf 0.915, Loss_fe 1.109, Loss_kd 1.411, Train_accy 35.23
2022-10-08 08:04:23,424 [foster.py] => Task 3, Epoch 13/34 => Loss 3.770, Loss_clf 0.894, Loss_fe 1.055, Loss_kd 1.407, Train_accy 35.38
2022-10-08 08:04:26,085 [foster.py] => Task 3, Epoch 14/34 => Loss 3.798, Loss_clf 0.908, Loss_fe 1.067, Loss_kd 1.408, Train_accy 36.32
2022-10-08 08:04:28,761 [foster.py] => Task 3, Epoch 15/34 => Loss 3.732, Loss_clf 0.882, Loss_fe 1.028, Loss_kd 1.408, Train_accy 34.50
2022-10-08 08:04:32,434 [foster.py] => Task 3, Epoch 16/34 => Loss 3.710, Loss_clf 0.878, Loss_fe 1.011, Loss_kd 1.407, Train_accy 35.30, Test_accy 44.84
2022-10-08 08:04:35,123 [foster.py] => Task 3, Epoch 17/34 => Loss 3.677, Loss_clf 0.857, Loss_fe 0.994, Loss_kd 1.411, Train_accy 35.08
2022-10-08 08:04:37,814 [foster.py] => Task 3, Epoch 18/34 => Loss 3.627, Loss_clf 0.848, Loss_fe 0.967, Loss_kd 1.400, Train_accy 34.94
2022-10-08 08:04:40,562 [foster.py] => Task 3, Epoch 19/34 => Loss 3.648, Loss_clf 0.849, Loss_fe 0.975, Loss_kd 1.410, Train_accy 35.89
2022-10-08 08:04:46,681 [foster.py] => Task 3, Epoch 20/34 => Loss 3.623, Loss_clf 0.847, Loss_fe 0.951, Loss_kd 1.410, Train_accy 36.54
2022-10-08 08:04:51,103 [foster.py] => Task 3, Epoch 21/34 => Loss 3.617, Loss_clf 0.837, Loss_fe 0.955, Loss_kd 1.410, Train_accy 36.18, Test_accy 44.64
2022-10-08 08:04:53,835 [foster.py] => Task 3, Epoch 22/34 => Loss 3.558, Loss_clf 0.815, Loss_fe 0.924, Loss_kd 1.405, Train_accy 36.18
2022-10-08 08:04:56,566 [foster.py] => Task 3, Epoch 23/34 => Loss 3.587, Loss_clf 0.828, Loss_fe 0.942, Loss_kd 1.404, Train_accy 36.18
2022-10-08 08:04:59,281 [foster.py] => Task 3, Epoch 24/34 => Loss 3.551, Loss_clf 0.810, Loss_fe 0.916, Loss_kd 1.411, Train_accy 39.17
2022-10-08 08:05:01,943 [foster.py] => Task 3, Epoch 25/34 => Loss 3.573, Loss_clf 0.817, Loss_fe 0.923, Loss_kd 1.417, Train_accy 37.05
2022-10-08 08:05:05,533 [foster.py] => Task 3, Epoch 26/34 => Loss 3.533, Loss_clf 0.799, Loss_fe 0.912, Loss_kd 1.408, Train_accy 36.76, Test_accy 46.23
2022-10-08 08:05:08,257 [foster.py] => Task 3, Epoch 27/34 => Loss 3.526, Loss_clf 0.804, Loss_fe 0.904, Loss_kd 1.404, Train_accy 37.78
2022-10-08 08:05:10,944 [foster.py] => Task 3, Epoch 28/34 => Loss 3.540, Loss_clf 0.804, Loss_fe 0.912, Loss_kd 1.409, Train_accy 37.78
2022-10-08 08:05:13,614 [foster.py] => Task 3, Epoch 29/34 => Loss 3.549, Loss_clf 0.804, Loss_fe 0.914, Loss_kd 1.414, Train_accy 38.44
2022-10-08 08:05:16,270 [foster.py] => Task 3, Epoch 30/34 => Loss 3.517, Loss_clf 0.795, Loss_fe 0.896, Loss_kd 1.411, Train_accy 38.07
2022-10-08 08:05:19,882 [foster.py] => Task 3, Epoch 31/34 => Loss 3.523, Loss_clf 0.799, Loss_fe 0.900, Loss_kd 1.409, Train_accy 39.97, Test_accy 46.03
2022-10-08 08:05:22,581 [foster.py] => Task 3, Epoch 32/34 => Loss 3.522, Loss_clf 0.802, Loss_fe 0.907, Loss_kd 1.401, Train_accy 37.05
2022-10-08 08:05:25,259 [foster.py] => Task 3, Epoch 33/34 => Loss 3.530, Loss_clf 0.805, Loss_fe 0.910, Loss_kd 1.403, Train_accy 37.20
2022-10-08 08:05:27,961 [foster.py] => Task 3, Epoch 34/34 => Loss 3.517, Loss_clf 0.800, Loss_fe 0.899, Loss_kd 1.405, Train_accy 37.93
2022-10-08 08:05:27,961 [foster.py] => do not weight align teacher!
2022-10-08 08:05:27,962 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 08:05:32,183 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.339,  Train_accy 12.62, Test_accy 37.70
2022-10-08 08:05:35,487 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.294,  Train_accy 13.35
2022-10-08 08:05:38,712 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.275,  Train_accy 13.49
2022-10-08 08:05:41,898 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.248,  Train_accy 13.27
2022-10-08 08:05:45,189 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.251,  Train_accy 13.64
2022-10-08 08:05:49,309 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.240,  Train_accy 13.86, Test_accy 37.90
2022-10-08 08:05:52,529 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.229,  Train_accy 13.71
2022-10-08 08:05:55,790 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.228,  Train_accy 14.88
2022-10-08 08:05:59,012 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.213,  Train_accy 14.66
2022-10-08 08:06:02,660 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.213,  Train_accy 15.68
2022-10-08 08:06:06,848 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.202,  Train_accy 15.46, Test_accy 37.70
2022-10-08 08:06:10,575 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.202,  Train_accy 16.19
2022-10-08 08:06:14,085 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.200,  Train_accy 16.05
2022-10-08 08:06:17,309 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.193,  Train_accy 15.97
2022-10-08 08:06:20,636 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.193,  Train_accy 16.19
2022-10-08 08:06:24,683 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.190,  Train_accy 16.63, Test_accy 38.69
2022-10-08 08:06:27,772 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.186,  Train_accy 16.19
2022-10-08 08:06:30,900 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.194,  Train_accy 16.41
2022-10-08 08:06:37,553 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.184,  Train_accy 16.48
2022-10-08 08:06:41,289 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.189,  Train_accy 16.85
2022-10-08 08:06:45,338 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.190,  Train_accy 16.78, Test_accy 38.89
2022-10-08 08:06:48,390 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.200,  Train_accy 17.36
2022-10-08 08:06:51,429 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.190,  Train_accy 17.51
2022-10-08 08:06:54,465 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.183,  Train_accy 16.63
2022-10-08 08:06:59,954 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.188,  Train_accy 17.29
2022-10-08 08:07:04,737 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.192,  Train_accy 16.56, Test_accy 39.48
2022-10-08 08:07:04,738 [foster.py] => do not weight align student!
2022-10-08 08:07:05,538 [foster.py] => darknet eval: 
2022-10-08 08:07:05,538 [foster.py] => CNN top1 curve: 39.48
2022-10-08 08:07:05,538 [foster.py] => CNN top5 curve: 83.53
2022-10-08 08:07:05,539 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 08:07:16,630 [foster.py] => Exemplar size: 440
2022-10-08 08:07:16,630 [trainer.py] => CNN: {'total': 46.03, 'old': 54.76, 'new': 16.52, 'base': 78.88, 'compound': 30.61}
2022-10-08 08:07:16,630 [trainer.py] => CNN top1 curve: [91.93, 73.65, 55.27, 46.03]
2022-10-08 08:07:16,630 [trainer.py] => CNN base curve: [91.93, 84.47, 81.37, 78.88]
2022-10-08 08:07:16,630 [trainer.py] => CNN old curve: [91.93, 84.47, 64.62, 54.76]
2022-10-08 08:07:16,630 [trainer.py] => CNN new curve: [0, 58.62, 32.14, 16.52]
2022-10-08 08:07:16,630 [trainer.py] => CNN compound curve: [0, 58.62, 36.84, 30.61]
2022-10-08 08:07:16,630 [trainer.py] => NME: {'total': 53.97, 'old': 55.78, 'new': 47.83, 'base': 65.22, 'compound': 48.69}
2022-10-08 08:07:16,630 [trainer.py] => NME top1 curve: [91.3, 78.7, 64.27, 53.97]
2022-10-08 08:07:16,630 [trainer.py] => NME base curve: [91.3, 80.75, 72.05, 65.22]
2022-10-08 08:07:16,630 [trainer.py] => NME old curve: [91.3, 80.75, 67.87, 55.78]
2022-10-08 08:07:16,630 [trainer.py] => NME new curve: [0, 75.86, 55.36, 47.83]
2022-10-08 08:07:16,630 [trainer.py] => NME compound curve: [0, 75.86, 58.77, 48.69]
2022-10-08 08:07:16,631 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 08:07:16,631 [trainer.py] => prefix: cil
2022-10-08 08:07:16,632 [trainer.py] => dataset: CFEE
2022-10-08 08:07:16,632 [trainer.py] => memory_size: 2000
2022-10-08 08:07:16,632 [trainer.py] => memory_per_class: 20
2022-10-08 08:07:16,632 [trainer.py] => fixed_memory: True
2022-10-08 08:07:16,632 [trainer.py] => shuffle: True
2022-10-08 08:07:16,632 [trainer.py] => init_cls: 7
2022-10-08 08:07:16,632 [trainer.py] => increment: 5
2022-10-08 08:07:16,632 [trainer.py] => model_name: foster
2022-10-08 08:07:16,632 [trainer.py] => convnet_type: resnet18
2022-10-08 08:07:16,632 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 08:07:16,632 [trainer.py] => seed: 1993
2022-10-08 08:07:16,632 [trainer.py] => beta1: 0.96
2022-10-08 08:07:16,632 [trainer.py] => beta2: 0.97
2022-10-08 08:07:16,632 [trainer.py] => oofc: ft
2022-10-08 08:07:16,632 [trainer.py] => is_teacher_wa: False
2022-10-08 08:07:16,632 [trainer.py] => is_student_wa: False
2022-10-08 08:07:16,632 [trainer.py] => lambda_okd: 1
2022-10-08 08:07:16,632 [trainer.py] => wa_value: 1
2022-10-08 08:07:16,632 [trainer.py] => init_epochs: 40
2022-10-08 08:07:16,632 [trainer.py] => init_lr: 0.01
2022-10-08 08:07:16,632 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 08:07:16,632 [trainer.py] => boosting_epochs: 34
2022-10-08 08:07:16,632 [trainer.py] => compression_epochs: 26
2022-10-08 08:07:16,632 [trainer.py] => lr: 0.001
2022-10-08 08:07:16,632 [trainer.py] => batch_size: 32
2022-10-08 08:07:16,632 [trainer.py] => weight_decay: 0.0005
2022-10-08 08:07:16,632 [trainer.py] => num_workers: 8
2022-10-08 08:07:16,632 [trainer.py] => T: 2
2022-10-08 08:07:16,632 [trainer.py] => nb_runs: 3
2022-10-08 08:07:16,632 [trainer.py] => fold: 10
2022-10-08 08:07:16,633 [data.py] => ========== Fold:7 ==========
2022-10-08 08:07:16,638 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 8, 15, 13, 17, 9, 11, 19, 21, 14, 10, 18, 12, 7, 16]
2022-10-08 08:07:16,854 [foster.py] => Learning on 0-7
2022-10-08 08:07:16,854 [foster.py] => All params: 11183694
2022-10-08 08:07:16,854 [foster.py] => Trainable params: 11183694
2022-10-08 08:07:19,155 [foster.py] => Task 0, Epoch 1/40 => Loss 1.373, Train_accy 49.66
2022-10-08 08:07:22,045 [foster.py] => Task 0, Epoch 2/40 => Loss 0.565, Train_accy 79.97, Test_accy 83.22
2022-10-08 08:07:24,985 [foster.py] => Task 0, Epoch 3/40 => Loss 0.369, Train_accy 88.27, Test_accy 86.58
2022-10-08 08:07:27,907 [foster.py] => Task 0, Epoch 4/40 => Loss 0.286, Train_accy 90.19, Test_accy 87.92
2022-10-08 08:07:30,799 [foster.py] => Task 0, Epoch 5/40 => Loss 0.216, Train_accy 92.39, Test_accy 85.91
2022-10-08 08:07:33,136 [foster.py] => Task 0, Epoch 6/40 => Loss 0.196, Train_accy 93.07
2022-10-08 08:07:36,076 [foster.py] => Task 0, Epoch 7/40 => Loss 0.151, Train_accy 94.99, Test_accy 88.59
2022-10-08 08:07:38,994 [foster.py] => Task 0, Epoch 8/40 => Loss 0.124, Train_accy 95.75, Test_accy 87.25
2022-10-08 08:07:41,952 [foster.py] => Task 0, Epoch 9/40 => Loss 0.089, Train_accy 97.26, Test_accy 86.58
2022-10-08 08:07:44,885 [foster.py] => Task 0, Epoch 10/40 => Loss 0.093, Train_accy 96.71, Test_accy 88.59
2022-10-08 08:07:47,241 [foster.py] => Task 0, Epoch 11/40 => Loss 0.075, Train_accy 98.29
2022-10-08 08:07:50,146 [foster.py] => Task 0, Epoch 12/40 => Loss 0.063, Train_accy 98.49, Test_accy 89.26
2022-10-08 08:07:53,114 [foster.py] => Task 0, Epoch 13/40 => Loss 0.070, Train_accy 98.01, Test_accy 83.89
2022-10-08 08:07:56,055 [foster.py] => Task 0, Epoch 14/40 => Loss 0.054, Train_accy 98.56, Test_accy 87.92
2022-10-08 08:07:58,967 [foster.py] => Task 0, Epoch 15/40 => Loss 0.052, Train_accy 98.56, Test_accy 85.23
2022-10-08 08:08:01,350 [foster.py] => Task 0, Epoch 16/40 => Loss 0.039, Train_accy 99.04
2022-10-08 08:08:04,231 [foster.py] => Task 0, Epoch 17/40 => Loss 0.038, Train_accy 99.31, Test_accy 85.91
2022-10-08 08:08:07,128 [foster.py] => Task 0, Epoch 18/40 => Loss 0.045, Train_accy 98.49, Test_accy 86.58
2022-10-08 08:08:10,101 [foster.py] => Task 0, Epoch 19/40 => Loss 0.036, Train_accy 99.18, Test_accy 87.92
2022-10-08 08:08:13,016 [foster.py] => Task 0, Epoch 20/40 => Loss 0.028, Train_accy 99.59, Test_accy 90.60
2022-10-08 08:08:15,377 [foster.py] => Task 0, Epoch 21/40 => Loss 0.028, Train_accy 99.18
2022-10-08 08:08:18,315 [foster.py] => Task 0, Epoch 22/40 => Loss 0.021, Train_accy 99.66, Test_accy 85.91
2022-10-08 08:08:21,195 [foster.py] => Task 0, Epoch 23/40 => Loss 0.027, Train_accy 99.25, Test_accy 86.58
2022-10-08 08:08:24,170 [foster.py] => Task 0, Epoch 24/40 => Loss 0.020, Train_accy 99.86, Test_accy 87.25
2022-10-08 08:08:27,079 [foster.py] => Task 0, Epoch 25/40 => Loss 0.020, Train_accy 99.66, Test_accy 87.25
2022-10-08 08:08:29,436 [foster.py] => Task 0, Epoch 26/40 => Loss 0.019, Train_accy 99.79
2022-10-08 08:08:32,367 [foster.py] => Task 0, Epoch 27/40 => Loss 0.014, Train_accy 99.93, Test_accy 87.25
2022-10-08 08:08:35,320 [foster.py] => Task 0, Epoch 28/40 => Loss 0.012, Train_accy 99.86, Test_accy 88.59
2022-10-08 08:08:38,269 [foster.py] => Task 0, Epoch 29/40 => Loss 0.014, Train_accy 99.86, Test_accy 87.92
2022-10-08 08:08:41,227 [foster.py] => Task 0, Epoch 30/40 => Loss 0.015, Train_accy 99.73, Test_accy 88.59
2022-10-08 08:08:43,642 [foster.py] => Task 0, Epoch 31/40 => Loss 0.013, Train_accy 99.93
2022-10-08 08:08:46,587 [foster.py] => Task 0, Epoch 32/40 => Loss 0.016, Train_accy 99.79, Test_accy 87.25
2022-10-08 08:08:49,549 [foster.py] => Task 0, Epoch 33/40 => Loss 0.013, Train_accy 99.93, Test_accy 87.92
2022-10-08 08:08:52,480 [foster.py] => Task 0, Epoch 34/40 => Loss 0.011, Train_accy 99.93, Test_accy 88.59
2022-10-08 08:08:55,402 [foster.py] => Task 0, Epoch 35/40 => Loss 0.015, Train_accy 99.73, Test_accy 87.92
2022-10-08 08:08:57,752 [foster.py] => Task 0, Epoch 36/40 => Loss 0.016, Train_accy 99.73
2022-10-08 08:09:00,750 [foster.py] => Task 0, Epoch 37/40 => Loss 0.015, Train_accy 99.59, Test_accy 87.92
2022-10-08 08:09:03,719 [foster.py] => Task 0, Epoch 38/40 => Loss 0.012, Train_accy 99.86, Test_accy 87.92
2022-10-08 08:09:06,664 [foster.py] => Task 0, Epoch 39/40 => Loss 0.013, Train_accy 99.86, Test_accy 87.25
2022-10-08 08:09:09,625 [foster.py] => Task 0, Epoch 40/40 => Loss 0.012, Train_accy 99.86, Test_accy 87.92
2022-10-08 08:09:09,625 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 08:09:15,986 [foster.py] => Exemplar size: 140
2022-10-08 08:09:15,986 [trainer.py] => CNN: {'total': 87.92, 'old': 87.92, 'new': 0, 'base': 87.92, 'compound': 0}
2022-10-08 08:09:15,986 [trainer.py] => CNN top1 curve: [87.92]
2022-10-08 08:09:15,986 [trainer.py] => CNN base curve: [87.92]
2022-10-08 08:09:15,986 [trainer.py] => CNN old curve: [87.92]
2022-10-08 08:09:15,986 [trainer.py] => CNN new curve: [0]
2022-10-08 08:09:15,986 [trainer.py] => CNN compound curve: [0]
2022-10-08 08:09:15,986 [trainer.py] => NME: {'total': 86.58, 'old': 86.58, 'new': 0, 'base': 86.58, 'compound': 0}
2022-10-08 08:09:15,986 [trainer.py] => NME top1 curve: [86.58]
2022-10-08 08:09:15,986 [trainer.py] => NME base curve: [86.58]
2022-10-08 08:09:15,986 [trainer.py] => NME old curve: [86.58]
2022-10-08 08:09:15,986 [trainer.py] => NME new curve: [0]
2022-10-08 08:09:15,986 [trainer.py] => NME compound curve: [0]
2022-10-08 08:09:16,211 [foster.py] => Learning on 7-12
2022-10-08 08:09:16,212 [foster.py] => All params: 22375071
2022-10-08 08:09:16,212 [foster.py] => Trainable params: 11194968
2022-10-08 08:09:16,221 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 08:09:19,357 [foster.py] => Task 1, Epoch 1/34 => Loss 4.608, Loss_clf 1.929, Loss_fe 1.918, Loss_kd 0.444, Train_accy 37.87, Test_accy 67.16
2022-10-08 08:09:21,731 [foster.py] => Task 1, Epoch 2/34 => Loss 2.581, Loss_clf 0.662, Loss_fe 1.206, Loss_kd 0.416, Train_accy 63.07
2022-10-08 08:09:24,086 [foster.py] => Task 1, Epoch 3/34 => Loss 2.219, Loss_clf 0.538, Loss_fe 0.977, Loss_kd 0.411, Train_accy 50.64
2022-10-08 08:09:26,471 [foster.py] => Task 1, Epoch 4/34 => Loss 2.052, Loss_clf 0.489, Loss_fe 0.851, Loss_kd 0.415, Train_accy 52.96
2022-10-08 08:09:28,819 [foster.py] => Task 1, Epoch 5/34 => Loss 1.942, Loss_clf 0.465, Loss_fe 0.772, Loss_kd 0.411, Train_accy 53.64
2022-10-08 08:09:31,952 [foster.py] => Task 1, Epoch 6/34 => Loss 1.891, Loss_clf 0.457, Loss_fe 0.727, Loss_kd 0.413, Train_accy 52.53, Test_accy 69.78
2022-10-08 08:09:34,363 [foster.py] => Task 1, Epoch 7/34 => Loss 1.797, Loss_clf 0.426, Loss_fe 0.671, Loss_kd 0.408, Train_accy 54.07
2022-10-08 08:09:36,777 [foster.py] => Task 1, Epoch 8/34 => Loss 1.756, Loss_clf 0.414, Loss_fe 0.630, Loss_kd 0.415, Train_accy 56.30
2022-10-08 08:09:39,165 [foster.py] => Task 1, Epoch 9/34 => Loss 1.680, Loss_clf 0.388, Loss_fe 0.588, Loss_kd 0.411, Train_accy 54.58
2022-10-08 08:09:41,685 [foster.py] => Task 1, Epoch 10/34 => Loss 1.649, Loss_clf 0.383, Loss_fe 0.558, Loss_kd 0.413, Train_accy 56.56
2022-10-08 08:09:44,879 [foster.py] => Task 1, Epoch 11/34 => Loss 1.583, Loss_clf 0.357, Loss_fe 0.523, Loss_kd 0.410, Train_accy 58.10, Test_accy 69.78
2022-10-08 08:09:47,344 [foster.py] => Task 1, Epoch 12/34 => Loss 1.639, Loss_clf 0.384, Loss_fe 0.541, Loss_kd 0.416, Train_accy 56.38
2022-10-08 08:09:49,756 [foster.py] => Task 1, Epoch 13/34 => Loss 1.562, Loss_clf 0.350, Loss_fe 0.505, Loss_kd 0.413, Train_accy 57.33
2022-10-08 08:09:52,213 [foster.py] => Task 1, Epoch 14/34 => Loss 1.539, Loss_clf 0.354, Loss_fe 0.484, Loss_kd 0.409, Train_accy 57.93
2022-10-08 08:09:54,712 [foster.py] => Task 1, Epoch 15/34 => Loss 1.524, Loss_clf 0.342, Loss_fe 0.477, Loss_kd 0.412, Train_accy 58.61
2022-10-08 08:09:58,105 [foster.py] => Task 1, Epoch 16/34 => Loss 1.465, Loss_clf 0.317, Loss_fe 0.444, Loss_kd 0.411, Train_accy 60.24, Test_accy 69.78
2022-10-08 08:10:00,604 [foster.py] => Task 1, Epoch 17/34 => Loss 1.489, Loss_clf 0.327, Loss_fe 0.447, Loss_kd 0.417, Train_accy 58.87
2022-10-08 08:10:03,029 [foster.py] => Task 1, Epoch 18/34 => Loss 1.461, Loss_clf 0.322, Loss_fe 0.436, Loss_kd 0.410, Train_accy 61.18
2022-10-08 08:10:05,546 [foster.py] => Task 1, Epoch 19/34 => Loss 1.464, Loss_clf 0.325, Loss_fe 0.437, Loss_kd 0.410, Train_accy 58.35
2022-10-08 08:10:08,013 [foster.py] => Task 1, Epoch 20/34 => Loss 1.443, Loss_clf 0.312, Loss_fe 0.421, Loss_kd 0.414, Train_accy 59.98
2022-10-08 08:10:14,610 [foster.py] => Task 1, Epoch 21/34 => Loss 1.431, Loss_clf 0.308, Loss_fe 0.415, Loss_kd 0.414, Train_accy 60.41, Test_accy 71.64
2022-10-08 08:10:17,200 [foster.py] => Task 1, Epoch 22/34 => Loss 1.438, Loss_clf 0.310, Loss_fe 0.415, Loss_kd 0.416, Train_accy 61.01
2022-10-08 08:10:19,604 [foster.py] => Task 1, Epoch 23/34 => Loss 1.402, Loss_clf 0.295, Loss_fe 0.396, Loss_kd 0.415, Train_accy 61.01
2022-10-08 08:10:21,996 [foster.py] => Task 1, Epoch 24/34 => Loss 1.386, Loss_clf 0.290, Loss_fe 0.396, Loss_kd 0.408, Train_accy 59.90
2022-10-08 08:10:24,376 [foster.py] => Task 1, Epoch 25/34 => Loss 1.434, Loss_clf 0.309, Loss_fe 0.415, Loss_kd 0.415, Train_accy 60.50
2022-10-08 08:10:30,194 [foster.py] => Task 1, Epoch 26/34 => Loss 1.388, Loss_clf 0.293, Loss_fe 0.394, Loss_kd 0.409, Train_accy 59.38, Test_accy 71.27
2022-10-08 08:10:32,743 [foster.py] => Task 1, Epoch 27/34 => Loss 1.366, Loss_clf 0.291, Loss_fe 0.381, Loss_kd 0.405, Train_accy 59.13
2022-10-08 08:10:35,158 [foster.py] => Task 1, Epoch 28/34 => Loss 1.384, Loss_clf 0.288, Loss_fe 0.390, Loss_kd 0.412, Train_accy 61.01
2022-10-08 08:10:37,574 [foster.py] => Task 1, Epoch 29/34 => Loss 1.382, Loss_clf 0.288, Loss_fe 0.389, Loss_kd 0.411, Train_accy 61.01
2022-10-08 08:10:39,935 [foster.py] => Task 1, Epoch 30/34 => Loss 1.347, Loss_clf 0.274, Loss_fe 0.375, Loss_kd 0.407, Train_accy 60.41
2022-10-08 08:10:43,109 [foster.py] => Task 1, Epoch 31/34 => Loss 1.337, Loss_clf 0.265, Loss_fe 0.362, Loss_kd 0.414, Train_accy 60.93, Test_accy 71.27
2022-10-08 08:10:45,522 [foster.py] => Task 1, Epoch 32/34 => Loss 1.368, Loss_clf 0.281, Loss_fe 0.385, Loss_kd 0.409, Train_accy 60.33
2022-10-08 08:10:47,878 [foster.py] => Task 1, Epoch 33/34 => Loss 1.364, Loss_clf 0.287, Loss_fe 0.379, Loss_kd 0.407, Train_accy 59.73
2022-10-08 08:10:50,320 [foster.py] => Task 1, Epoch 34/34 => Loss 1.384, Loss_clf 0.289, Loss_fe 0.389, Loss_kd 0.412, Train_accy 59.55
2022-10-08 08:10:50,320 [foster.py] => do not weight align teacher!
2022-10-08 08:10:50,321 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 08:10:53,996 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.842,  Train_accy 11.91, Test_accy 46.27
2022-10-08 08:10:56,729 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.670,  Train_accy 11.91
2022-10-08 08:10:59,526 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.577,  Train_accy 12.77
2022-10-08 08:11:02,408 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.550,  Train_accy 14.14
2022-10-08 08:11:05,331 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.516,  Train_accy 16.80
2022-10-08 08:11:09,184 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.500,  Train_accy 17.48, Test_accy 50.75
2022-10-08 08:11:12,065 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.485,  Train_accy 19.54
2022-10-08 08:11:15,425 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.455,  Train_accy 21.68
2022-10-08 08:11:18,833 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.463,  Train_accy 22.19
2022-10-08 08:11:22,195 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.452,  Train_accy 23.14
2022-10-08 08:11:26,197 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.450,  Train_accy 24.51, Test_accy 54.85
2022-10-08 08:11:29,087 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.439,  Train_accy 24.85
2022-10-08 08:11:35,564 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.440,  Train_accy 27.08
2022-10-08 08:11:39,049 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.430,  Train_accy 27.08
2022-10-08 08:11:42,059 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.419,  Train_accy 26.56
2022-10-08 08:11:45,586 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.419,  Train_accy 26.48, Test_accy 57.84
2022-10-08 08:11:48,317 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.427,  Train_accy 28.11
2022-10-08 08:11:51,075 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.424,  Train_accy 26.99
2022-10-08 08:11:53,903 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.413,  Train_accy 29.22
2022-10-08 08:11:56,731 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.411,  Train_accy 27.08
2022-10-08 08:12:00,178 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.409,  Train_accy 27.68, Test_accy 58.58
2022-10-08 08:12:02,876 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.419,  Train_accy 29.22
2022-10-08 08:12:05,781 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.411,  Train_accy 29.73
2022-10-08 08:12:08,784 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.414,  Train_accy 29.13
2022-10-08 08:12:11,775 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.409,  Train_accy 28.53
2022-10-08 08:12:15,474 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.409,  Train_accy 28.36, Test_accy 58.21
2022-10-08 08:12:15,474 [foster.py] => do not weight align student!
2022-10-08 08:12:16,127 [foster.py] => darknet eval: 
2022-10-08 08:12:16,127 [foster.py] => CNN top1 curve: 58.21
2022-10-08 08:12:16,127 [foster.py] => CNN top5 curve: 98.51
2022-10-08 08:12:16,128 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 08:12:23,854 [foster.py] => Exemplar size: 240
2022-10-08 08:12:23,854 [trainer.py] => CNN: {'total': 70.9, 'old': 85.23, 'new': 52.94, 'base': 85.23, 'compound': 52.94}
2022-10-08 08:12:23,854 [trainer.py] => CNN top1 curve: [87.92, 70.9]
2022-10-08 08:12:23,854 [trainer.py] => CNN base curve: [87.92, 85.23]
2022-10-08 08:12:23,854 [trainer.py] => CNN old curve: [87.92, 85.23]
2022-10-08 08:12:23,854 [trainer.py] => CNN new curve: [0, 52.94]
2022-10-08 08:12:23,854 [trainer.py] => CNN compound curve: [0, 52.94]
2022-10-08 08:12:23,854 [trainer.py] => NME: {'total': 79.1, 'old': 83.89, 'new': 73.11, 'base': 83.89, 'compound': 73.11}
2022-10-08 08:12:23,854 [trainer.py] => NME top1 curve: [86.58, 79.1]
2022-10-08 08:12:23,854 [trainer.py] => NME base curve: [86.58, 83.89]
2022-10-08 08:12:23,854 [trainer.py] => NME old curve: [86.58, 83.89]
2022-10-08 08:12:23,854 [trainer.py] => NME new curve: [0, 73.11]
2022-10-08 08:12:23,855 [trainer.py] => NME compound curve: [0, 73.11]
2022-10-08 08:12:24,079 [foster.py] => Learning on 12-17
2022-10-08 08:12:24,080 [foster.py] => All params: 22385326
2022-10-08 08:12:24,080 [foster.py] => Trainable params: 11202658
2022-10-08 08:12:24,089 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 08:12:27,409 [foster.py] => Task 2, Epoch 1/34 => Loss 5.873, Loss_clf 2.167, Loss_fe 2.277, Loss_kd 1.009, Train_accy 33.73, Test_accy 41.96
2022-10-08 08:12:29,966 [foster.py] => Task 2, Epoch 2/34 => Loss 4.088, Loss_clf 1.070, Loss_fe 1.614, Loss_kd 0.991, Train_accy 37.55
2022-10-08 08:12:32,480 [foster.py] => Task 2, Epoch 3/34 => Loss 3.792, Loss_clf 0.968, Loss_fe 1.434, Loss_kd 0.980, Train_accy 37.63
2022-10-08 08:12:35,032 [foster.py] => Task 2, Epoch 4/34 => Loss 3.632, Loss_clf 0.929, Loss_fe 1.308, Loss_kd 0.984, Train_accy 37.87
2022-10-08 08:12:37,589 [foster.py] => Task 2, Epoch 5/34 => Loss 3.509, Loss_clf 0.891, Loss_fe 1.223, Loss_kd 0.984, Train_accy 37.87
2022-10-08 08:12:40,960 [foster.py] => Task 2, Epoch 6/34 => Loss 3.409, Loss_clf 0.863, Loss_fe 1.149, Loss_kd 0.987, Train_accy 36.36, Test_accy 48.49
2022-10-08 08:12:43,465 [foster.py] => Task 2, Epoch 7/34 => Loss 3.321, Loss_clf 0.840, Loss_fe 1.086, Loss_kd 0.984, Train_accy 37.55
2022-10-08 08:12:46,050 [foster.py] => Task 2, Epoch 8/34 => Loss 3.309, Loss_clf 0.835, Loss_fe 1.069, Loss_kd 0.992, Train_accy 39.70
2022-10-08 08:12:48,565 [foster.py] => Task 2, Epoch 9/34 => Loss 3.184, Loss_clf 0.792, Loss_fe 0.993, Loss_kd 0.987, Train_accy 39.46
2022-10-08 08:12:51,145 [foster.py] => Task 2, Epoch 10/34 => Loss 3.109, Loss_clf 0.771, Loss_fe 0.951, Loss_kd 0.979, Train_accy 38.35
2022-10-08 08:12:54,535 [foster.py] => Task 2, Epoch 11/34 => Loss 3.099, Loss_clf 0.767, Loss_fe 0.937, Loss_kd 0.984, Train_accy 42.32, Test_accy 49.50
2022-10-08 08:12:57,129 [foster.py] => Task 2, Epoch 12/34 => Loss 3.038, Loss_clf 0.746, Loss_fe 0.897, Loss_kd 0.985, Train_accy 40.41
2022-10-08 08:12:59,753 [foster.py] => Task 2, Epoch 13/34 => Loss 3.037, Loss_clf 0.749, Loss_fe 0.891, Loss_kd 0.985, Train_accy 41.37
2022-10-08 08:13:02,776 [foster.py] => Task 2, Epoch 14/34 => Loss 2.950, Loss_clf 0.720, Loss_fe 0.839, Loss_kd 0.982, Train_accy 41.05
2022-10-08 08:13:05,814 [foster.py] => Task 2, Epoch 15/34 => Loss 2.906, Loss_clf 0.693, Loss_fe 0.817, Loss_kd 0.985, Train_accy 43.20
2022-10-08 08:13:09,792 [foster.py] => Task 2, Epoch 16/34 => Loss 2.929, Loss_clf 0.711, Loss_fe 0.834, Loss_kd 0.978, Train_accy 40.97, Test_accy 50.50
2022-10-08 08:13:12,502 [foster.py] => Task 2, Epoch 17/34 => Loss 2.871, Loss_clf 0.672, Loss_fe 0.789, Loss_kd 0.995, Train_accy 44.07
2022-10-08 08:13:15,587 [foster.py] => Task 2, Epoch 18/34 => Loss 2.882, Loss_clf 0.681, Loss_fe 0.796, Loss_kd 0.992, Train_accy 43.75
2022-10-08 08:13:18,672 [foster.py] => Task 2, Epoch 19/34 => Loss 2.792, Loss_clf 0.649, Loss_fe 0.752, Loss_kd 0.982, Train_accy 43.36
2022-10-08 08:13:21,788 [foster.py] => Task 2, Epoch 20/34 => Loss 2.785, Loss_clf 0.642, Loss_fe 0.739, Loss_kd 0.991, Train_accy 44.23
2022-10-08 08:13:25,365 [foster.py] => Task 2, Epoch 21/34 => Loss 2.770, Loss_clf 0.634, Loss_fe 0.732, Loss_kd 0.991, Train_accy 44.55, Test_accy 51.01
2022-10-08 08:13:28,060 [foster.py] => Task 2, Epoch 22/34 => Loss 2.773, Loss_clf 0.638, Loss_fe 0.734, Loss_kd 0.988, Train_accy 44.39
2022-10-08 08:13:30,775 [foster.py] => Task 2, Epoch 23/34 => Loss 2.724, Loss_clf 0.610, Loss_fe 0.720, Loss_kd 0.984, Train_accy 46.06
2022-10-08 08:13:33,453 [foster.py] => Task 2, Epoch 24/34 => Loss 2.754, Loss_clf 0.627, Loss_fe 0.723, Loss_kd 0.991, Train_accy 44.47
2022-10-08 08:13:36,167 [foster.py] => Task 2, Epoch 25/34 => Loss 2.729, Loss_clf 0.622, Loss_fe 0.708, Loss_kd 0.988, Train_accy 44.79
2022-10-08 08:13:39,659 [foster.py] => Task 2, Epoch 26/34 => Loss 2.676, Loss_clf 0.598, Loss_fe 0.694, Loss_kd 0.977, Train_accy 45.03, Test_accy 50.25
2022-10-08 08:13:42,272 [foster.py] => Task 2, Epoch 27/34 => Loss 2.713, Loss_clf 0.603, Loss_fe 0.701, Loss_kd 0.994, Train_accy 45.82
2022-10-08 08:13:48,436 [foster.py] => Task 2, Epoch 28/34 => Loss 2.716, Loss_clf 0.602, Loss_fe 0.706, Loss_kd 0.993, Train_accy 44.95
2022-10-08 08:13:52,017 [foster.py] => Task 2, Epoch 29/34 => Loss 2.713, Loss_clf 0.607, Loss_fe 0.713, Loss_kd 0.983, Train_accy 46.14
2022-10-08 08:13:54,996 [foster.py] => Task 2, Epoch 30/34 => Loss 2.694, Loss_clf 0.604, Loss_fe 0.694, Loss_kd 0.985, Train_accy 45.11
2022-10-08 08:13:58,703 [foster.py] => Task 2, Epoch 31/34 => Loss 2.704, Loss_clf 0.599, Loss_fe 0.702, Loss_kd 0.990, Train_accy 45.19, Test_accy 50.75
2022-10-08 08:14:01,240 [foster.py] => Task 2, Epoch 32/34 => Loss 2.654, Loss_clf 0.591, Loss_fe 0.675, Loss_kd 0.980, Train_accy 47.02
2022-10-08 08:14:03,811 [foster.py] => Task 2, Epoch 33/34 => Loss 2.645, Loss_clf 0.583, Loss_fe 0.671, Loss_kd 0.982, Train_accy 46.62
2022-10-08 08:14:06,312 [foster.py] => Task 2, Epoch 34/34 => Loss 2.700, Loss_clf 0.592, Loss_fe 0.698, Loss_kd 0.995, Train_accy 45.51
2022-10-08 08:14:06,312 [foster.py] => do not weight align teacher!
2022-10-08 08:14:06,313 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 08:14:10,458 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.126,  Train_accy 12.25, Test_accy 39.20
2022-10-08 08:14:14,411 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 2.030,  Train_accy 12.89
2022-10-08 08:14:17,768 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.994,  Train_accy 13.05
2022-10-08 08:14:20,916 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.966,  Train_accy 13.60
2022-10-08 08:14:23,954 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.967,  Train_accy 13.60
2022-10-08 08:14:28,000 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.955,  Train_accy 13.29, Test_accy 41.96
2022-10-08 08:14:32,676 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.948,  Train_accy 13.68
2022-10-08 08:14:36,450 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.943,  Train_accy 14.16
2022-10-08 08:14:39,614 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.941,  Train_accy 14.00
2022-10-08 08:14:42,663 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.924,  Train_accy 14.16
2022-10-08 08:14:46,473 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.926,  Train_accy 13.76, Test_accy 43.22
2022-10-08 08:14:50,172 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.924,  Train_accy 13.84
2022-10-08 08:14:53,357 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.918,  Train_accy 13.76
2022-10-08 08:14:56,571 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.913,  Train_accy 14.48
2022-10-08 08:14:59,671 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.934,  Train_accy 14.48
2022-10-08 08:15:03,590 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.900,  Train_accy 14.64, Test_accy 43.22
2022-10-08 08:15:06,506 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.903,  Train_accy 14.00
2022-10-08 08:15:09,483 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.908,  Train_accy 14.72
2022-10-08 08:15:16,167 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.913,  Train_accy 14.80
2022-10-08 08:15:20,071 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.913,  Train_accy 14.40
2022-10-08 08:15:23,946 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.902,  Train_accy 14.40, Test_accy 42.96
2022-10-08 08:15:26,917 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.917,  Train_accy 15.04
2022-10-08 08:15:29,939 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.901,  Train_accy 15.04
2022-10-08 08:15:32,932 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.912,  Train_accy 14.72
2022-10-08 08:15:35,870 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.907,  Train_accy 14.16
2022-10-08 08:15:39,668 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.904,  Train_accy 14.16, Test_accy 43.72
2022-10-08 08:15:39,668 [foster.py] => do not weight align student!
2022-10-08 08:15:40,400 [foster.py] => darknet eval: 
2022-10-08 08:15:40,400 [foster.py] => CNN top1 curve: 43.72
2022-10-08 08:15:40,400 [foster.py] => CNN top5 curve: 93.97
2022-10-08 08:15:40,400 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 08:15:49,836 [foster.py] => Exemplar size: 340
2022-10-08 08:15:49,836 [trainer.py] => CNN: {'total': 50.25, 'old': 62.69, 'new': 24.62, 'base': 77.18, 'compound': 34.14}
2022-10-08 08:15:49,836 [trainer.py] => CNN top1 curve: [87.92, 70.9, 50.25]
2022-10-08 08:15:49,836 [trainer.py] => CNN base curve: [87.92, 85.23, 77.18]
2022-10-08 08:15:49,836 [trainer.py] => CNN old curve: [87.92, 85.23, 62.69]
2022-10-08 08:15:49,836 [trainer.py] => CNN new curve: [0, 52.94, 24.62]
2022-10-08 08:15:49,836 [trainer.py] => CNN compound curve: [0, 52.94, 34.14]
2022-10-08 08:15:49,836 [trainer.py] => NME: {'total': 66.83, 'old': 68.66, 'new': 63.08, 'base': 70.47, 'compound': 64.66}
2022-10-08 08:15:49,836 [trainer.py] => NME top1 curve: [86.58, 79.1, 66.83]
2022-10-08 08:15:49,836 [trainer.py] => NME base curve: [86.58, 83.89, 70.47]
2022-10-08 08:15:49,837 [trainer.py] => NME old curve: [86.58, 83.89, 68.66]
2022-10-08 08:15:49,837 [trainer.py] => NME new curve: [0, 73.11, 63.08]
2022-10-08 08:15:49,837 [trainer.py] => NME compound curve: [0, 73.11, 64.66]
2022-10-08 08:15:50,065 [foster.py] => Learning on 17-22
2022-10-08 08:15:50,066 [foster.py] => All params: 22395581
2022-10-08 08:15:50,066 [foster.py] => Trainable params: 11210348
2022-10-08 08:15:50,075 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 08:15:53,743 [foster.py] => Task 3, Epoch 1/34 => Loss 6.556, Loss_clf 2.207, Loss_fe 2.457, Loss_kd 1.462, Train_accy 33.19, Test_accy 36.71
2022-10-08 08:15:56,443 [foster.py] => Task 3, Epoch 2/34 => Loss 4.806, Loss_clf 1.199, Loss_fe 1.777, Loss_kd 1.414, Train_accy 28.77
2022-10-08 08:15:59,163 [foster.py] => Task 3, Epoch 3/34 => Loss 4.598, Loss_clf 1.113, Loss_fe 1.626, Loss_kd 1.437, Train_accy 30.65
2022-10-08 08:16:01,908 [foster.py] => Task 3, Epoch 4/34 => Loss 4.369, Loss_clf 1.069, Loss_fe 1.468, Loss_kd 1.417, Train_accy 31.67
2022-10-08 08:16:04,643 [foster.py] => Task 3, Epoch 5/34 => Loss 4.318, Loss_clf 1.042, Loss_fe 1.449, Loss_kd 1.412, Train_accy 31.38
2022-10-08 08:16:08,787 [foster.py] => Task 3, Epoch 6/34 => Loss 4.188, Loss_clf 1.007, Loss_fe 1.347, Loss_kd 1.417, Train_accy 31.59, Test_accy 40.48
2022-10-08 08:16:12,405 [foster.py] => Task 3, Epoch 7/34 => Loss 4.097, Loss_clf 0.996, Loss_fe 1.273, Loss_kd 1.412, Train_accy 32.61
2022-10-08 08:16:15,475 [foster.py] => Task 3, Epoch 8/34 => Loss 3.983, Loss_clf 0.945, Loss_fe 1.210, Loss_kd 1.412, Train_accy 32.90
2022-10-08 08:16:18,393 [foster.py] => Task 3, Epoch 9/34 => Loss 3.989, Loss_clf 0.958, Loss_fe 1.207, Loss_kd 1.410, Train_accy 32.83
2022-10-08 08:16:21,238 [foster.py] => Task 3, Epoch 10/34 => Loss 3.885, Loss_clf 0.919, Loss_fe 1.127, Loss_kd 1.421, Train_accy 32.17
2022-10-08 08:16:25,017 [foster.py] => Task 3, Epoch 11/34 => Loss 3.831, Loss_clf 0.904, Loss_fe 1.090, Loss_kd 1.419, Train_accy 33.12, Test_accy 42.26
2022-10-08 08:16:27,726 [foster.py] => Task 3, Epoch 12/34 => Loss 3.834, Loss_clf 0.909, Loss_fe 1.091, Loss_kd 1.417, Train_accy 34.13
2022-10-08 08:16:33,816 [foster.py] => Task 3, Epoch 13/34 => Loss 3.765, Loss_clf 0.870, Loss_fe 1.050, Loss_kd 1.426, Train_accy 34.35
2022-10-08 08:16:37,485 [foster.py] => Task 3, Epoch 14/34 => Loss 3.700, Loss_clf 0.857, Loss_fe 1.019, Loss_kd 1.409, Train_accy 35.22
2022-10-08 08:16:40,773 [foster.py] => Task 3, Epoch 15/34 => Loss 3.693, Loss_clf 0.860, Loss_fe 0.999, Loss_kd 1.417, Train_accy 34.93
2022-10-08 08:16:44,757 [foster.py] => Task 3, Epoch 16/34 => Loss 3.673, Loss_clf 0.843, Loss_fe 0.989, Loss_kd 1.422, Train_accy 34.28, Test_accy 43.25
2022-10-08 08:16:47,587 [foster.py] => Task 3, Epoch 17/34 => Loss 3.627, Loss_clf 0.838, Loss_fe 0.966, Loss_kd 1.408, Train_accy 35.94
2022-10-08 08:16:50,298 [foster.py] => Task 3, Epoch 18/34 => Loss 3.622, Loss_clf 0.823, Loss_fe 0.955, Loss_kd 1.425, Train_accy 34.57
2022-10-08 08:16:53,050 [foster.py] => Task 3, Epoch 19/34 => Loss 3.591, Loss_clf 0.819, Loss_fe 0.934, Loss_kd 1.420, Train_accy 35.43
2022-10-08 08:16:55,916 [foster.py] => Task 3, Epoch 20/34 => Loss 3.616, Loss_clf 0.827, Loss_fe 0.944, Loss_kd 1.426, Train_accy 34.20
2022-10-08 08:16:59,672 [foster.py] => Task 3, Epoch 21/34 => Loss 3.565, Loss_clf 0.807, Loss_fe 0.930, Loss_kd 1.413, Train_accy 35.43, Test_accy 43.45
2022-10-08 08:17:02,419 [foster.py] => Task 3, Epoch 22/34 => Loss 3.592, Loss_clf 0.815, Loss_fe 0.934, Loss_kd 1.424, Train_accy 35.80
2022-10-08 08:17:05,127 [foster.py] => Task 3, Epoch 23/34 => Loss 3.584, Loss_clf 0.805, Loss_fe 0.922, Loss_kd 1.435, Train_accy 36.96
2022-10-08 08:17:07,973 [foster.py] => Task 3, Epoch 24/34 => Loss 3.501, Loss_clf 0.770, Loss_fe 0.885, Loss_kd 1.426, Train_accy 37.32
2022-10-08 08:17:11,020 [foster.py] => Task 3, Epoch 25/34 => Loss 3.557, Loss_clf 0.803, Loss_fe 0.914, Loss_kd 1.422, Train_accy 37.75
2022-10-08 08:17:14,835 [foster.py] => Task 3, Epoch 26/34 => Loss 3.500, Loss_clf 0.778, Loss_fe 0.882, Loss_kd 1.422, Train_accy 36.81, Test_accy 44.05
2022-10-08 08:17:17,719 [foster.py] => Task 3, Epoch 27/34 => Loss 3.523, Loss_clf 0.789, Loss_fe 0.893, Loss_kd 1.422, Train_accy 37.32
2022-10-08 08:17:20,592 [foster.py] => Task 3, Epoch 28/34 => Loss 3.497, Loss_clf 0.764, Loss_fe 0.890, Loss_kd 1.424, Train_accy 36.74
2022-10-08 08:17:23,491 [foster.py] => Task 3, Epoch 29/34 => Loss 3.482, Loss_clf 0.765, Loss_fe 0.868, Loss_kd 1.428, Train_accy 37.32
2022-10-08 08:17:26,356 [foster.py] => Task 3, Epoch 30/34 => Loss 3.511, Loss_clf 0.776, Loss_fe 0.886, Loss_kd 1.429, Train_accy 36.96
2022-10-08 08:17:30,339 [foster.py] => Task 3, Epoch 31/34 => Loss 3.498, Loss_clf 0.773, Loss_fe 0.884, Loss_kd 1.422, Train_accy 37.97, Test_accy 44.05
2022-10-08 08:17:33,223 [foster.py] => Task 3, Epoch 32/34 => Loss 3.480, Loss_clf 0.760, Loss_fe 0.899, Loss_kd 1.408, Train_accy 36.59
2022-10-08 08:17:36,255 [foster.py] => Task 3, Epoch 33/34 => Loss 3.475, Loss_clf 0.757, Loss_fe 0.878, Loss_kd 1.422, Train_accy 37.10
2022-10-08 08:17:39,159 [foster.py] => Task 3, Epoch 34/34 => Loss 3.450, Loss_clf 0.738, Loss_fe 0.873, Loss_kd 1.421, Train_accy 38.33
2022-10-08 08:17:39,160 [foster.py] => do not weight align teacher!
2022-10-08 08:17:39,160 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 08:17:43,620 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.361,  Train_accy 12.68, Test_accy 34.13
2022-10-08 08:17:47,017 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.322,  Train_accy 13.48
2022-10-08 08:17:50,990 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.284,  Train_accy 13.04
2022-10-08 08:17:54,870 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.281,  Train_accy 13.33
2022-10-08 08:17:58,558 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.271,  Train_accy 13.84
2022-10-08 08:18:02,985 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.254,  Train_accy 13.19, Test_accy 35.52
2022-10-08 08:18:06,229 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.249,  Train_accy 14.06
2022-10-08 08:18:09,761 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.239,  Train_accy 13.77
2022-10-08 08:18:13,285 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.234,  Train_accy 13.91
2022-10-08 08:18:16,805 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.228,  Train_accy 14.20
2022-10-08 08:18:21,766 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.229,  Train_accy 14.71, Test_accy 36.11
2022-10-08 08:18:25,208 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.225,  Train_accy 14.64
2022-10-08 08:18:28,620 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.228,  Train_accy 14.49
2022-10-08 08:18:32,015 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.208,  Train_accy 14.57
2022-10-08 08:18:35,513 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.214,  Train_accy 15.07
2022-10-08 08:18:40,087 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.215,  Train_accy 14.71, Test_accy 36.71
2022-10-08 08:18:43,523 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.219,  Train_accy 15.65
2022-10-08 08:18:47,103 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.202,  Train_accy 15.51
2022-10-08 08:18:50,685 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.206,  Train_accy 16.09
2022-10-08 08:18:54,173 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.208,  Train_accy 16.30
2022-10-08 08:18:58,358 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.214,  Train_accy 15.51, Test_accy 36.90
2022-10-08 08:19:01,776 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.205,  Train_accy 15.72
2022-10-08 08:19:05,581 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.198,  Train_accy 15.36
2022-10-08 08:19:09,085 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.204,  Train_accy 15.51
2022-10-08 08:19:12,600 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.207,  Train_accy 15.72
2022-10-08 08:19:16,833 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.196,  Train_accy 16.88, Test_accy 37.30
2022-10-08 08:19:16,833 [foster.py] => do not weight align student!
2022-10-08 08:19:17,616 [foster.py] => darknet eval: 
2022-10-08 08:19:17,617 [foster.py] => CNN top1 curve: 37.3
2022-10-08 08:19:17,617 [foster.py] => CNN top5 curve: 83.53
2022-10-08 08:19:17,617 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 08:19:28,701 [foster.py] => Exemplar size: 440
2022-10-08 08:19:28,701 [trainer.py] => CNN: {'total': 43.65, 'old': 50.0, 'new': 19.81, 'base': 75.17, 'compound': 30.42}
2022-10-08 08:19:28,701 [trainer.py] => CNN top1 curve: [87.92, 70.9, 50.25, 43.65]
2022-10-08 08:19:28,701 [trainer.py] => CNN base curve: [87.92, 85.23, 77.18, 75.17]
2022-10-08 08:19:28,701 [trainer.py] => CNN old curve: [87.92, 85.23, 62.69, 50.0]
2022-10-08 08:19:28,701 [trainer.py] => CNN new curve: [0, 52.94, 24.62, 19.81]
2022-10-08 08:19:28,701 [trainer.py] => CNN compound curve: [0, 52.94, 34.14, 30.42]
2022-10-08 08:19:28,701 [trainer.py] => NME: {'total': 54.96, 'old': 58.04, 'new': 43.4, 'base': 67.79, 'compound': 49.58}
2022-10-08 08:19:28,701 [trainer.py] => NME top1 curve: [86.58, 79.1, 66.83, 54.96]
2022-10-08 08:19:28,701 [trainer.py] => NME base curve: [86.58, 83.89, 70.47, 67.79]
2022-10-08 08:19:28,701 [trainer.py] => NME old curve: [86.58, 83.89, 68.66, 58.04]
2022-10-08 08:19:28,701 [trainer.py] => NME new curve: [0, 73.11, 63.08, 43.4]
2022-10-08 08:19:28,701 [trainer.py] => NME compound curve: [0, 73.11, 64.66, 49.58]
2022-10-08 08:19:28,703 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 08:19:28,703 [trainer.py] => prefix: cil
2022-10-08 08:19:28,703 [trainer.py] => dataset: CFEE
2022-10-08 08:19:28,703 [trainer.py] => memory_size: 2000
2022-10-08 08:19:28,703 [trainer.py] => memory_per_class: 20
2022-10-08 08:19:28,703 [trainer.py] => fixed_memory: True
2022-10-08 08:19:28,703 [trainer.py] => shuffle: True
2022-10-08 08:19:28,703 [trainer.py] => init_cls: 7
2022-10-08 08:19:28,703 [trainer.py] => increment: 5
2022-10-08 08:19:28,703 [trainer.py] => model_name: foster
2022-10-08 08:19:28,703 [trainer.py] => convnet_type: resnet18
2022-10-08 08:19:28,703 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 08:19:28,703 [trainer.py] => seed: 1993
2022-10-08 08:19:28,703 [trainer.py] => beta1: 0.96
2022-10-08 08:19:28,703 [trainer.py] => beta2: 0.97
2022-10-08 08:19:28,703 [trainer.py] => oofc: ft
2022-10-08 08:19:28,703 [trainer.py] => is_teacher_wa: False
2022-10-08 08:19:28,703 [trainer.py] => is_student_wa: False
2022-10-08 08:19:28,703 [trainer.py] => lambda_okd: 1
2022-10-08 08:19:28,703 [trainer.py] => wa_value: 1
2022-10-08 08:19:28,703 [trainer.py] => init_epochs: 40
2022-10-08 08:19:28,703 [trainer.py] => init_lr: 0.01
2022-10-08 08:19:28,703 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 08:19:28,703 [trainer.py] => boosting_epochs: 34
2022-10-08 08:19:28,703 [trainer.py] => compression_epochs: 26
2022-10-08 08:19:28,703 [trainer.py] => lr: 0.001
2022-10-08 08:19:28,703 [trainer.py] => batch_size: 32
2022-10-08 08:19:28,703 [trainer.py] => weight_decay: 0.0005
2022-10-08 08:19:28,703 [trainer.py] => num_workers: 8
2022-10-08 08:19:28,703 [trainer.py] => T: 2
2022-10-08 08:19:28,704 [trainer.py] => nb_runs: 3
2022-10-08 08:19:28,704 [trainer.py] => fold: 10
2022-10-08 08:19:28,704 [data.py] => ========== Fold:8 ==========
2022-10-08 08:19:28,709 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 8, 15, 13, 17, 9, 11, 19, 21, 14, 10, 18, 12, 7, 16]
2022-10-08 08:19:28,928 [foster.py] => Learning on 0-7
2022-10-08 08:19:28,928 [foster.py] => All params: 11183694
2022-10-08 08:19:28,928 [foster.py] => Trainable params: 11183694
2022-10-08 08:19:31,327 [foster.py] => Task 0, Epoch 1/40 => Loss 1.354, Train_accy 50.59
2022-10-08 08:19:34,292 [foster.py] => Task 0, Epoch 2/40 => Loss 0.567, Train_accy 80.06, Test_accy 84.81
2022-10-08 08:19:37,247 [foster.py] => Task 0, Epoch 3/40 => Loss 0.358, Train_accy 87.16, Test_accy 87.34
2022-10-08 08:19:40,183 [foster.py] => Task 0, Epoch 4/40 => Loss 0.279, Train_accy 90.55, Test_accy 87.34
2022-10-08 08:19:43,136 [foster.py] => Task 0, Epoch 5/40 => Loss 0.221, Train_accy 92.96, Test_accy 85.44
2022-10-08 08:19:45,519 [foster.py] => Task 0, Epoch 6/40 => Loss 0.204, Train_accy 93.58
2022-10-08 08:19:48,429 [foster.py] => Task 0, Epoch 7/40 => Loss 0.170, Train_accy 93.93, Test_accy 86.71
2022-10-08 08:19:51,376 [foster.py] => Task 0, Epoch 8/40 => Loss 0.149, Train_accy 95.45, Test_accy 83.54
2022-10-08 08:19:54,341 [foster.py] => Task 0, Epoch 9/40 => Loss 0.117, Train_accy 95.51, Test_accy 86.08
2022-10-08 08:19:57,348 [foster.py] => Task 0, Epoch 10/40 => Loss 0.098, Train_accy 96.69, Test_accy 87.34
2022-10-08 08:19:59,715 [foster.py] => Task 0, Epoch 11/40 => Loss 0.082, Train_accy 97.58
2022-10-08 08:20:02,676 [foster.py] => Task 0, Epoch 12/40 => Loss 0.060, Train_accy 98.69, Test_accy 87.34
2022-10-08 08:20:05,669 [foster.py] => Task 0, Epoch 13/40 => Loss 0.055, Train_accy 98.55, Test_accy 88.61
2022-10-08 08:20:08,602 [foster.py] => Task 0, Epoch 14/40 => Loss 0.050, Train_accy 98.90, Test_accy 89.87
2022-10-08 08:20:11,581 [foster.py] => Task 0, Epoch 15/40 => Loss 0.042, Train_accy 98.90, Test_accy 86.71
2022-10-08 08:20:13,996 [foster.py] => Task 0, Epoch 16/40 => Loss 0.042, Train_accy 99.31
2022-10-08 08:20:17,000 [foster.py] => Task 0, Epoch 17/40 => Loss 0.037, Train_accy 98.90, Test_accy 88.61
2022-10-08 08:20:19,951 [foster.py] => Task 0, Epoch 18/40 => Loss 0.050, Train_accy 98.83, Test_accy 89.24
2022-10-08 08:20:22,889 [foster.py] => Task 0, Epoch 19/40 => Loss 0.043, Train_accy 99.10, Test_accy 89.24
2022-10-08 08:20:25,813 [foster.py] => Task 0, Epoch 20/40 => Loss 0.028, Train_accy 99.31, Test_accy 88.61
2022-10-08 08:20:28,167 [foster.py] => Task 0, Epoch 21/40 => Loss 0.020, Train_accy 99.72
2022-10-08 08:20:31,172 [foster.py] => Task 0, Epoch 22/40 => Loss 0.029, Train_accy 99.38, Test_accy 88.61
2022-10-08 08:20:34,664 [foster.py] => Task 0, Epoch 23/40 => Loss 0.021, Train_accy 99.65, Test_accy 89.87
2022-10-08 08:20:37,755 [foster.py] => Task 0, Epoch 24/40 => Loss 0.026, Train_accy 99.65, Test_accy 89.24
2022-10-08 08:20:40,728 [foster.py] => Task 0, Epoch 25/40 => Loss 0.023, Train_accy 99.52, Test_accy 87.34
2022-10-08 08:20:43,240 [foster.py] => Task 0, Epoch 26/40 => Loss 0.018, Train_accy 99.86
2022-10-08 08:20:46,312 [foster.py] => Task 0, Epoch 27/40 => Loss 0.018, Train_accy 99.72, Test_accy 88.61
2022-10-08 08:20:49,357 [foster.py] => Task 0, Epoch 28/40 => Loss 0.014, Train_accy 99.86, Test_accy 87.97
2022-10-08 08:20:52,300 [foster.py] => Task 0, Epoch 29/40 => Loss 0.015, Train_accy 99.86, Test_accy 89.24
2022-10-08 08:20:55,296 [foster.py] => Task 0, Epoch 30/40 => Loss 0.014, Train_accy 99.93, Test_accy 88.61
2022-10-08 08:20:57,715 [foster.py] => Task 0, Epoch 31/40 => Loss 0.014, Train_accy 99.86
2022-10-08 08:21:00,698 [foster.py] => Task 0, Epoch 32/40 => Loss 0.013, Train_accy 99.93, Test_accy 86.71
2022-10-08 08:21:03,676 [foster.py] => Task 0, Epoch 33/40 => Loss 0.013, Train_accy 99.93, Test_accy 88.61
2022-10-08 08:21:06,647 [foster.py] => Task 0, Epoch 34/40 => Loss 0.018, Train_accy 99.72, Test_accy 87.34
2022-10-08 08:21:09,563 [foster.py] => Task 0, Epoch 35/40 => Loss 0.016, Train_accy 99.65, Test_accy 87.34
2022-10-08 08:21:12,001 [foster.py] => Task 0, Epoch 36/40 => Loss 0.012, Train_accy 99.93
2022-10-08 08:21:14,973 [foster.py] => Task 0, Epoch 37/40 => Loss 0.011, Train_accy 99.86, Test_accy 87.97
2022-10-08 08:21:17,913 [foster.py] => Task 0, Epoch 38/40 => Loss 0.016, Train_accy 99.72, Test_accy 89.24
2022-10-08 08:21:20,876 [foster.py] => Task 0, Epoch 39/40 => Loss 0.014, Train_accy 99.86, Test_accy 87.34
2022-10-08 08:21:23,854 [foster.py] => Task 0, Epoch 40/40 => Loss 0.014, Train_accy 99.72, Test_accy 87.97
2022-10-08 08:21:23,855 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 08:21:30,271 [foster.py] => Exemplar size: 140
2022-10-08 08:21:30,271 [trainer.py] => CNN: {'total': 87.97, 'old': 87.97, 'new': 0, 'base': 87.97, 'compound': 0}
2022-10-08 08:21:30,271 [trainer.py] => CNN top1 curve: [87.97]
2022-10-08 08:21:30,271 [trainer.py] => CNN base curve: [87.97]
2022-10-08 08:21:30,271 [trainer.py] => CNN old curve: [87.97]
2022-10-08 08:21:30,271 [trainer.py] => CNN new curve: [0]
2022-10-08 08:21:30,271 [trainer.py] => CNN compound curve: [0]
2022-10-08 08:21:30,271 [trainer.py] => NME: {'total': 86.71, 'old': 86.71, 'new': 0, 'base': 86.71, 'compound': 0}
2022-10-08 08:21:30,271 [trainer.py] => NME top1 curve: [86.71]
2022-10-08 08:21:30,271 [trainer.py] => NME base curve: [86.71]
2022-10-08 08:21:30,271 [trainer.py] => NME old curve: [86.71]
2022-10-08 08:21:30,271 [trainer.py] => NME new curve: [0]
2022-10-08 08:21:30,271 [trainer.py] => NME compound curve: [0]
2022-10-08 08:21:30,497 [foster.py] => Learning on 7-12
2022-10-08 08:21:30,497 [foster.py] => All params: 22375071
2022-10-08 08:21:30,497 [foster.py] => Trainable params: 11194968
2022-10-08 08:21:30,506 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 08:21:33,710 [foster.py] => Task 1, Epoch 1/34 => Loss 4.879, Loss_clf 2.230, Loss_fe 1.920, Loss_kd 0.425, Train_accy 36.01, Test_accy 65.45
2022-10-08 08:21:36,086 [foster.py] => Task 1, Epoch 2/34 => Loss 2.561, Loss_clf 0.681, Loss_fe 1.175, Loss_kd 0.411, Train_accy 65.87
2022-10-08 08:21:38,523 [foster.py] => Task 1, Epoch 3/34 => Loss 2.156, Loss_clf 0.527, Loss_fe 0.948, Loss_kd 0.397, Train_accy 51.33
2022-10-08 08:21:40,913 [foster.py] => Task 1, Epoch 4/34 => Loss 2.017, Loss_clf 0.495, Loss_fe 0.837, Loss_kd 0.400, Train_accy 51.67
2022-10-08 08:21:43,392 [foster.py] => Task 1, Epoch 5/34 => Loss 1.889, Loss_clf 0.455, Loss_fe 0.751, Loss_kd 0.399, Train_accy 53.38
2022-10-08 08:21:46,557 [foster.py] => Task 1, Epoch 6/34 => Loss 1.801, Loss_clf 0.433, Loss_fe 0.681, Loss_kd 0.401, Train_accy 52.87, Test_accy 66.18
2022-10-08 08:21:49,026 [foster.py] => Task 1, Epoch 7/34 => Loss 1.745, Loss_clf 0.408, Loss_fe 0.651, Loss_kd 0.400, Train_accy 56.03
2022-10-08 08:21:51,486 [foster.py] => Task 1, Epoch 8/34 => Loss 1.703, Loss_clf 0.408, Loss_fe 0.608, Loss_kd 0.400, Train_accy 54.23
2022-10-08 08:21:53,954 [foster.py] => Task 1, Epoch 9/34 => Loss 1.616, Loss_clf 0.372, Loss_fe 0.566, Loss_kd 0.395, Train_accy 54.92
2022-10-08 08:21:56,511 [foster.py] => Task 1, Epoch 10/34 => Loss 1.611, Loss_clf 0.370, Loss_fe 0.559, Loss_kd 0.398, Train_accy 56.89
2022-10-08 08:22:00,196 [foster.py] => Task 1, Epoch 11/34 => Loss 1.577, Loss_clf 0.358, Loss_fe 0.533, Loss_kd 0.400, Train_accy 57.57, Test_accy 66.91
2022-10-08 08:22:02,859 [foster.py] => Task 1, Epoch 12/34 => Loss 1.520, Loss_clf 0.341, Loss_fe 0.501, Loss_kd 0.395, Train_accy 54.83
2022-10-08 08:22:05,529 [foster.py] => Task 1, Epoch 13/34 => Loss 1.488, Loss_clf 0.328, Loss_fe 0.475, Loss_kd 0.400, Train_accy 55.77
2022-10-08 08:22:08,090 [foster.py] => Task 1, Epoch 14/34 => Loss 1.504, Loss_clf 0.339, Loss_fe 0.480, Loss_kd 0.399, Train_accy 57.06
2022-10-08 08:22:10,617 [foster.py] => Task 1, Epoch 15/34 => Loss 1.473, Loss_clf 0.326, Loss_fe 0.468, Loss_kd 0.396, Train_accy 59.28
2022-10-08 08:22:14,244 [foster.py] => Task 1, Epoch 16/34 => Loss 1.432, Loss_clf 0.311, Loss_fe 0.438, Loss_kd 0.398, Train_accy 58.25, Test_accy 68.00
2022-10-08 08:22:16,730 [foster.py] => Task 1, Epoch 17/34 => Loss 1.461, Loss_clf 0.329, Loss_fe 0.447, Loss_kd 0.400, Train_accy 59.37
2022-10-08 08:22:19,245 [foster.py] => Task 1, Epoch 18/34 => Loss 1.428, Loss_clf 0.316, Loss_fe 0.435, Loss_kd 0.395, Train_accy 59.45
2022-10-08 08:22:21,880 [foster.py] => Task 1, Epoch 19/34 => Loss 1.407, Loss_clf 0.302, Loss_fe 0.421, Loss_kd 0.398, Train_accy 59.54
2022-10-08 08:22:24,544 [foster.py] => Task 1, Epoch 20/34 => Loss 1.389, Loss_clf 0.294, Loss_fe 0.410, Loss_kd 0.400, Train_accy 59.71
2022-10-08 08:22:28,504 [foster.py] => Task 1, Epoch 21/34 => Loss 1.392, Loss_clf 0.300, Loss_fe 0.411, Loss_kd 0.397, Train_accy 58.34, Test_accy 67.64
2022-10-08 08:22:33,010 [foster.py] => Task 1, Epoch 22/34 => Loss 1.369, Loss_clf 0.287, Loss_fe 0.406, Loss_kd 0.394, Train_accy 60.91
2022-10-08 08:22:36,139 [foster.py] => Task 1, Epoch 23/34 => Loss 1.339, Loss_clf 0.274, Loss_fe 0.379, Loss_kd 0.400, Train_accy 60.99
2022-10-08 08:22:39,227 [foster.py] => Task 1, Epoch 24/34 => Loss 1.341, Loss_clf 0.275, Loss_fe 0.384, Loss_kd 0.397, Train_accy 61.25
2022-10-08 08:22:42,041 [foster.py] => Task 1, Epoch 25/34 => Loss 1.357, Loss_clf 0.289, Loss_fe 0.389, Loss_kd 0.396, Train_accy 60.05
2022-10-08 08:22:45,582 [foster.py] => Task 1, Epoch 26/34 => Loss 1.354, Loss_clf 0.278, Loss_fe 0.392, Loss_kd 0.399, Train_accy 60.31, Test_accy 67.64
2022-10-08 08:22:48,018 [foster.py] => Task 1, Epoch 27/34 => Loss 1.332, Loss_clf 0.274, Loss_fe 0.376, Loss_kd 0.398, Train_accy 60.65
2022-10-08 08:22:50,453 [foster.py] => Task 1, Epoch 28/34 => Loss 1.312, Loss_clf 0.268, Loss_fe 0.367, Loss_kd 0.395, Train_accy 60.31
2022-10-08 08:22:52,896 [foster.py] => Task 1, Epoch 29/34 => Loss 1.328, Loss_clf 0.268, Loss_fe 0.375, Loss_kd 0.399, Train_accy 62.28
2022-10-08 08:22:55,269 [foster.py] => Task 1, Epoch 30/34 => Loss 1.339, Loss_clf 0.275, Loss_fe 0.381, Loss_kd 0.398, Train_accy 61.59
2022-10-08 08:22:58,468 [foster.py] => Task 1, Epoch 31/34 => Loss 1.326, Loss_clf 0.268, Loss_fe 0.377, Loss_kd 0.397, Train_accy 59.62, Test_accy 66.91
2022-10-08 08:23:00,919 [foster.py] => Task 1, Epoch 32/34 => Loss 1.351, Loss_clf 0.275, Loss_fe 0.386, Loss_kd 0.403, Train_accy 61.76
2022-10-08 08:23:03,340 [foster.py] => Task 1, Epoch 33/34 => Loss 1.313, Loss_clf 0.267, Loss_fe 0.372, Loss_kd 0.393, Train_accy 60.14
2022-10-08 08:23:05,946 [foster.py] => Task 1, Epoch 34/34 => Loss 1.316, Loss_clf 0.264, Loss_fe 0.373, Loss_kd 0.396, Train_accy 61.59
2022-10-08 08:23:05,947 [foster.py] => do not weight align teacher!
2022-10-08 08:23:05,947 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 08:23:09,888 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.827,  Train_accy 11.72, Test_accy 48.73
2022-10-08 08:23:12,843 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.645,  Train_accy 12.15
2022-10-08 08:23:15,834 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.571,  Train_accy 13.34
2022-10-08 08:23:19,525 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.535,  Train_accy 15.06
2022-10-08 08:23:23,150 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.496,  Train_accy 16.60
2022-10-08 08:23:27,220 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.491,  Train_accy 18.39, Test_accy 51.27
2022-10-08 08:23:30,067 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.470,  Train_accy 20.62
2022-10-08 08:23:32,951 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.458,  Train_accy 21.47
2022-10-08 08:23:35,964 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.460,  Train_accy 24.55
2022-10-08 08:23:39,106 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.421,  Train_accy 23.27
2022-10-08 08:23:42,984 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.435,  Train_accy 24.64, Test_accy 56.00
2022-10-08 08:23:45,826 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.429,  Train_accy 26.18
2022-10-08 08:23:49,280 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.427,  Train_accy 26.18
2022-10-08 08:23:52,486 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.423,  Train_accy 27.20
2022-10-08 08:23:55,686 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.409,  Train_accy 27.63
2022-10-08 08:23:59,539 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.405,  Train_accy 26.43, Test_accy 57.09
2022-10-08 08:24:02,542 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.407,  Train_accy 28.14
2022-10-08 08:24:05,497 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.413,  Train_accy 28.91
2022-10-08 08:24:08,477 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.407,  Train_accy 28.40
2022-10-08 08:24:15,863 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.407,  Train_accy 29.08
2022-10-08 08:24:20,313 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.402,  Train_accy 29.26, Test_accy 56.73
2022-10-08 08:24:23,219 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.402,  Train_accy 28.31
2022-10-08 08:24:26,035 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.406,  Train_accy 29.26
2022-10-08 08:24:28,880 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.415,  Train_accy 29.17
2022-10-08 08:24:31,705 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.403,  Train_accy 29.60
2022-10-08 08:24:35,164 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.406,  Train_accy 28.31, Test_accy 58.55
2022-10-08 08:24:35,164 [foster.py] => do not weight align student!
2022-10-08 08:24:35,828 [foster.py] => darknet eval: 
2022-10-08 08:24:35,828 [foster.py] => CNN top1 curve: 58.55
2022-10-08 08:24:35,828 [foster.py] => CNN top5 curve: 97.82
2022-10-08 08:24:35,829 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 08:24:43,525 [foster.py] => Exemplar size: 240
2022-10-08 08:24:43,526 [trainer.py] => CNN: {'total': 66.91, 'old': 84.81, 'new': 42.74, 'base': 84.81, 'compound': 42.74}
2022-10-08 08:24:43,526 [trainer.py] => CNN top1 curve: [87.97, 66.91]
2022-10-08 08:24:43,526 [trainer.py] => CNN base curve: [87.97, 84.81]
2022-10-08 08:24:43,526 [trainer.py] => CNN old curve: [87.97, 84.81]
2022-10-08 08:24:43,526 [trainer.py] => CNN new curve: [0, 42.74]
2022-10-08 08:24:43,526 [trainer.py] => CNN compound curve: [0, 42.74]
2022-10-08 08:24:43,526 [trainer.py] => NME: {'total': 77.09, 'old': 81.65, 'new': 70.94, 'base': 81.65, 'compound': 70.94}
2022-10-08 08:24:43,526 [trainer.py] => NME top1 curve: [86.71, 77.09]
2022-10-08 08:24:43,526 [trainer.py] => NME base curve: [86.71, 81.65]
2022-10-08 08:24:43,526 [trainer.py] => NME old curve: [86.71, 81.65]
2022-10-08 08:24:43,526 [trainer.py] => NME new curve: [0, 70.94]
2022-10-08 08:24:43,526 [trainer.py] => NME compound curve: [0, 70.94]
2022-10-08 08:24:43,750 [foster.py] => Learning on 12-17
2022-10-08 08:24:43,751 [foster.py] => All params: 22385326
2022-10-08 08:24:43,751 [foster.py] => Trainable params: 11202658
2022-10-08 08:24:43,760 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 08:24:47,136 [foster.py] => Task 2, Epoch 1/34 => Loss 5.841, Loss_clf 2.152, Loss_fe 2.265, Loss_kd 1.005, Train_accy 33.60, Test_accy 43.83
2022-10-08 08:24:49,655 [foster.py] => Task 2, Epoch 2/34 => Loss 4.039, Loss_clf 1.073, Loss_fe 1.579, Loss_kd 0.979, Train_accy 38.58
2022-10-08 08:24:52,183 [foster.py] => Task 2, Epoch 3/34 => Loss 3.784, Loss_clf 0.985, Loss_fe 1.404, Loss_kd 0.985, Train_accy 37.79
2022-10-08 08:24:54,733 [foster.py] => Task 2, Epoch 4/34 => Loss 3.646, Loss_clf 0.962, Loss_fe 1.305, Loss_kd 0.974, Train_accy 37.79
2022-10-08 08:24:57,314 [foster.py] => Task 2, Epoch 5/34 => Loss 3.483, Loss_clf 0.888, Loss_fe 1.210, Loss_kd 0.977, Train_accy 39.05
2022-10-08 08:25:00,718 [foster.py] => Task 2, Epoch 6/34 => Loss 3.431, Loss_clf 0.886, Loss_fe 1.154, Loss_kd 0.982, Train_accy 39.13, Test_accy 50.63
2022-10-08 08:25:03,284 [foster.py] => Task 2, Epoch 7/34 => Loss 3.344, Loss_clf 0.862, Loss_fe 1.097, Loss_kd 0.977, Train_accy 39.05
2022-10-08 08:25:05,852 [foster.py] => Task 2, Epoch 8/34 => Loss 3.300, Loss_clf 0.849, Loss_fe 1.061, Loss_kd 0.981, Train_accy 39.60
2022-10-08 08:25:08,738 [foster.py] => Task 2, Epoch 9/34 => Loss 3.201, Loss_clf 0.810, Loss_fe 1.013, Loss_kd 0.972, Train_accy 40.24
2022-10-08 08:25:11,862 [foster.py] => Task 2, Epoch 10/34 => Loss 3.141, Loss_clf 0.788, Loss_fe 0.972, Loss_kd 0.975, Train_accy 39.84
2022-10-08 08:25:15,653 [foster.py] => Task 2, Epoch 11/34 => Loss 3.076, Loss_clf 0.760, Loss_fe 0.932, Loss_kd 0.977, Train_accy 40.87, Test_accy 50.13
2022-10-08 08:25:18,292 [foster.py] => Task 2, Epoch 12/34 => Loss 3.059, Loss_clf 0.762, Loss_fe 0.912, Loss_kd 0.977, Train_accy 39.76
2022-10-08 08:25:20,961 [foster.py] => Task 2, Epoch 13/34 => Loss 2.995, Loss_clf 0.728, Loss_fe 0.881, Loss_kd 0.978, Train_accy 42.92
2022-10-08 08:25:23,612 [foster.py] => Task 2, Epoch 14/34 => Loss 2.991, Loss_clf 0.736, Loss_fe 0.872, Loss_kd 0.977, Train_accy 40.55
2022-10-08 08:25:26,406 [foster.py] => Task 2, Epoch 15/34 => Loss 2.931, Loss_clf 0.701, Loss_fe 0.840, Loss_kd 0.981, Train_accy 44.74
2022-10-08 08:25:30,076 [foster.py] => Task 2, Epoch 16/34 => Loss 2.929, Loss_clf 0.714, Loss_fe 0.832, Loss_kd 0.976, Train_accy 41.11, Test_accy 50.88
2022-10-08 08:25:32,756 [foster.py] => Task 2, Epoch 17/34 => Loss 2.891, Loss_clf 0.698, Loss_fe 0.813, Loss_kd 0.975, Train_accy 42.69
2022-10-08 08:25:35,501 [foster.py] => Task 2, Epoch 18/34 => Loss 2.854, Loss_clf 0.675, Loss_fe 0.794, Loss_kd 0.978, Train_accy 44.27
2022-10-08 08:25:38,296 [foster.py] => Task 2, Epoch 19/34 => Loss 2.807, Loss_clf 0.653, Loss_fe 0.767, Loss_kd 0.979, Train_accy 44.74
2022-10-08 08:25:41,347 [foster.py] => Task 2, Epoch 20/34 => Loss 2.866, Loss_clf 0.681, Loss_fe 0.799, Loss_kd 0.978, Train_accy 44.19
2022-10-08 08:25:45,041 [foster.py] => Task 2, Epoch 21/34 => Loss 2.791, Loss_clf 0.651, Loss_fe 0.753, Loss_kd 0.979, Train_accy 46.40, Test_accy 50.63
2022-10-08 08:25:47,847 [foster.py] => Task 2, Epoch 22/34 => Loss 2.798, Loss_clf 0.645, Loss_fe 0.761, Loss_kd 0.982, Train_accy 44.90
2022-10-08 08:25:50,683 [foster.py] => Task 2, Epoch 23/34 => Loss 2.753, Loss_clf 0.630, Loss_fe 0.738, Loss_kd 0.977, Train_accy 44.82
2022-10-08 08:25:53,552 [foster.py] => Task 2, Epoch 24/34 => Loss 2.738, Loss_clf 0.624, Loss_fe 0.725, Loss_kd 0.981, Train_accy 45.30
2022-10-08 08:25:56,330 [foster.py] => Task 2, Epoch 25/34 => Loss 2.743, Loss_clf 0.624, Loss_fe 0.734, Loss_kd 0.978, Train_accy 45.77
2022-10-08 08:25:59,997 [foster.py] => Task 2, Epoch 26/34 => Loss 2.745, Loss_clf 0.618, Loss_fe 0.736, Loss_kd 0.982, Train_accy 46.72, Test_accy 50.88
2022-10-08 08:26:02,723 [foster.py] => Task 2, Epoch 27/34 => Loss 2.705, Loss_clf 0.605, Loss_fe 0.716, Loss_kd 0.977, Train_accy 45.22
2022-10-08 08:26:05,698 [foster.py] => Task 2, Epoch 28/34 => Loss 2.712, Loss_clf 0.611, Loss_fe 0.709, Loss_kd 0.982, Train_accy 46.48
2022-10-08 08:26:08,591 [foster.py] => Task 2, Epoch 29/34 => Loss 2.691, Loss_clf 0.603, Loss_fe 0.705, Loss_kd 0.977, Train_accy 47.35
2022-10-08 08:26:11,529 [foster.py] => Task 2, Epoch 30/34 => Loss 2.702, Loss_clf 0.618, Loss_fe 0.705, Loss_kd 0.974, Train_accy 45.38
2022-10-08 08:26:15,297 [foster.py] => Task 2, Epoch 31/34 => Loss 2.690, Loss_clf 0.597, Loss_fe 0.705, Loss_kd 0.980, Train_accy 47.27, Test_accy 49.87
2022-10-08 08:26:18,077 [foster.py] => Task 2, Epoch 32/34 => Loss 2.717, Loss_clf 0.603, Loss_fe 0.722, Loss_kd 0.982, Train_accy 47.04
2022-10-08 08:26:20,843 [foster.py] => Task 2, Epoch 33/34 => Loss 2.716, Loss_clf 0.605, Loss_fe 0.720, Loss_kd 0.982, Train_accy 46.17
2022-10-08 08:26:23,521 [foster.py] => Task 2, Epoch 34/34 => Loss 2.716, Loss_clf 0.599, Loss_fe 0.712, Loss_kd 0.992, Train_accy 47.11
2022-10-08 08:26:23,522 [foster.py] => do not weight align teacher!
2022-10-08 08:26:23,522 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 08:26:28,022 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.107,  Train_accy 12.02, Test_accy 39.55
2022-10-08 08:26:31,303 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 2.022,  Train_accy 12.89
2022-10-08 08:26:34,601 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.992,  Train_accy 12.96
2022-10-08 08:26:37,885 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.984,  Train_accy 13.44
2022-10-08 08:26:41,603 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.958,  Train_accy 13.12
2022-10-08 08:26:46,071 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.940,  Train_accy 12.81, Test_accy 41.81
2022-10-08 08:26:49,533 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.952,  Train_accy 13.04
2022-10-08 08:26:52,929 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.933,  Train_accy 13.28
2022-10-08 08:26:56,183 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.932,  Train_accy 13.52
2022-10-08 08:26:59,449 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.916,  Train_accy 13.68
2022-10-08 08:27:03,366 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.922,  Train_accy 13.60, Test_accy 41.56
2022-10-08 08:27:06,606 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.924,  Train_accy 13.68
2022-10-08 08:27:09,900 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.918,  Train_accy 14.62
2022-10-08 08:27:13,251 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.920,  Train_accy 14.23
2022-10-08 08:27:16,576 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.908,  Train_accy 13.83
2022-10-08 08:27:20,703 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.900,  Train_accy 14.70, Test_accy 42.82
2022-10-08 08:27:23,873 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.893,  Train_accy 14.07
2022-10-08 08:27:31,105 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.908,  Train_accy 14.31
2022-10-08 08:27:34,971 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.908,  Train_accy 14.15
2022-10-08 08:27:38,217 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.911,  Train_accy 13.91
2022-10-08 08:27:42,201 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.906,  Train_accy 14.62, Test_accy 42.82
2022-10-08 08:27:45,219 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.912,  Train_accy 14.31
2022-10-08 08:27:48,227 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.911,  Train_accy 14.23
2022-10-08 08:27:51,434 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.911,  Train_accy 14.31
2022-10-08 08:27:54,530 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.896,  Train_accy 14.39
2022-10-08 08:27:58,439 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.907,  Train_accy 13.83, Test_accy 43.32
2022-10-08 08:27:58,439 [foster.py] => do not weight align student!
2022-10-08 08:27:59,206 [foster.py] => darknet eval: 
2022-10-08 08:27:59,206 [foster.py] => CNN top1 curve: 43.32
2022-10-08 08:27:59,206 [foster.py] => CNN top5 curve: 93.45
2022-10-08 08:27:59,207 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 08:28:08,861 [foster.py] => Exemplar size: 340
2022-10-08 08:28:08,861 [trainer.py] => CNN: {'total': 49.62, 'old': 61.82, 'new': 22.13, 'base': 80.38, 'compound': 29.29}
2022-10-08 08:28:08,861 [trainer.py] => CNN top1 curve: [87.97, 66.91, 49.62]
2022-10-08 08:28:08,861 [trainer.py] => CNN base curve: [87.97, 84.81, 80.38]
2022-10-08 08:28:08,861 [trainer.py] => CNN old curve: [87.97, 84.81, 61.82]
2022-10-08 08:28:08,861 [trainer.py] => CNN new curve: [0, 42.74, 22.13]
2022-10-08 08:28:08,861 [trainer.py] => CNN compound curve: [0, 42.74, 29.29]
2022-10-08 08:28:08,861 [trainer.py] => NME: {'total': 62.47, 'old': 68.36, 'new': 49.18, 'base': 71.52, 'compound': 56.49}
2022-10-08 08:28:08,861 [trainer.py] => NME top1 curve: [86.71, 77.09, 62.47]
2022-10-08 08:28:08,861 [trainer.py] => NME base curve: [86.71, 81.65, 71.52]
2022-10-08 08:28:08,861 [trainer.py] => NME old curve: [86.71, 81.65, 68.36]
2022-10-08 08:28:08,861 [trainer.py] => NME new curve: [0, 70.94, 49.18]
2022-10-08 08:28:08,861 [trainer.py] => NME compound curve: [0, 70.94, 56.49]
2022-10-08 08:28:09,099 [foster.py] => Learning on 17-22
2022-10-08 08:28:09,100 [foster.py] => All params: 22395581
2022-10-08 08:28:09,100 [foster.py] => Trainable params: 11210348
2022-10-08 08:28:09,109 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 08:28:12,704 [foster.py] => Task 3, Epoch 1/34 => Loss 6.528, Loss_clf 2.146, Loss_fe 2.473, Loss_kd 1.475, Train_accy 31.91, Test_accy 40.08
2022-10-08 08:28:15,452 [foster.py] => Task 3, Epoch 2/34 => Loss 4.832, Loss_clf 1.232, Loss_fe 1.737, Loss_kd 1.440, Train_accy 27.12
2022-10-08 08:28:18,211 [foster.py] => Task 3, Epoch 3/34 => Loss 4.582, Loss_clf 1.132, Loss_fe 1.586, Loss_kd 1.440, Train_accy 31.98
2022-10-08 08:28:20,919 [foster.py] => Task 3, Epoch 4/34 => Loss 4.485, Loss_clf 1.115, Loss_fe 1.501, Loss_kd 1.444, Train_accy 31.91
2022-10-08 08:28:23,688 [foster.py] => Task 3, Epoch 5/34 => Loss 4.325, Loss_clf 1.059, Loss_fe 1.398, Loss_kd 1.444, Train_accy 32.34
2022-10-08 08:28:27,429 [foster.py] => Task 3, Epoch 6/34 => Loss 4.188, Loss_clf 1.007, Loss_fe 1.328, Loss_kd 1.432, Train_accy 32.78, Test_accy 44.64
2022-10-08 08:28:30,159 [foster.py] => Task 3, Epoch 7/34 => Loss 4.181, Loss_clf 1.008, Loss_fe 1.299, Loss_kd 1.448, Train_accy 34.45
2022-10-08 08:28:32,974 [foster.py] => Task 3, Epoch 8/34 => Loss 4.084, Loss_clf 1.007, Loss_fe 1.227, Loss_kd 1.430, Train_accy 32.92
2022-10-08 08:28:35,835 [foster.py] => Task 3, Epoch 9/34 => Loss 4.085, Loss_clf 0.984, Loss_fe 1.238, Loss_kd 1.440, Train_accy 33.43
2022-10-08 08:28:39,381 [foster.py] => Task 3, Epoch 10/34 => Loss 3.961, Loss_clf 0.951, Loss_fe 1.147, Loss_kd 1.439, Train_accy 36.04
2022-10-08 08:28:43,958 [foster.py] => Task 3, Epoch 11/34 => Loss 3.939, Loss_clf 0.925, Loss_fe 1.130, Loss_kd 1.456, Train_accy 33.58, Test_accy 44.64
2022-10-08 08:28:46,947 [foster.py] => Task 3, Epoch 12/34 => Loss 3.880, Loss_clf 0.915, Loss_fe 1.100, Loss_kd 1.441, Train_accy 33.72
2022-10-08 08:28:49,980 [foster.py] => Task 3, Epoch 13/34 => Loss 3.867, Loss_clf 0.918, Loss_fe 1.095, Loss_kd 1.433, Train_accy 35.46
2022-10-08 08:28:53,345 [foster.py] => Task 3, Epoch 14/34 => Loss 3.844, Loss_clf 0.915, Loss_fe 1.053, Loss_kd 1.449, Train_accy 33.72
2022-10-08 08:28:56,610 [foster.py] => Task 3, Epoch 15/34 => Loss 3.766, Loss_clf 0.885, Loss_fe 1.016, Loss_kd 1.442, Train_accy 36.40
2022-10-08 08:29:00,543 [foster.py] => Task 3, Epoch 16/34 => Loss 3.768, Loss_clf 0.877, Loss_fe 1.017, Loss_kd 1.448, Train_accy 34.30, Test_accy 45.83
2022-10-08 08:29:03,387 [foster.py] => Task 3, Epoch 17/34 => Loss 3.701, Loss_clf 0.853, Loss_fe 0.988, Loss_kd 1.438, Train_accy 36.62
2022-10-08 08:29:06,407 [foster.py] => Task 3, Epoch 18/34 => Loss 3.716, Loss_clf 0.855, Loss_fe 0.983, Loss_kd 1.451, Train_accy 34.08
2022-10-08 08:29:09,257 [foster.py] => Task 3, Epoch 19/34 => Loss 3.640, Loss_clf 0.828, Loss_fe 0.953, Loss_kd 1.437, Train_accy 35.75
2022-10-08 08:29:12,175 [foster.py] => Task 3, Epoch 20/34 => Loss 3.681, Loss_clf 0.829, Loss_fe 0.990, Loss_kd 1.439, Train_accy 35.17
2022-10-08 08:29:16,145 [foster.py] => Task 3, Epoch 21/34 => Loss 3.646, Loss_clf 0.831, Loss_fe 0.953, Loss_kd 1.439, Train_accy 36.33, Test_accy 45.83
2022-10-08 08:29:19,025 [foster.py] => Task 3, Epoch 22/34 => Loss 3.703, Loss_clf 0.866, Loss_fe 0.969, Loss_kd 1.444, Train_accy 37.93
2022-10-08 08:29:21,904 [foster.py] => Task 3, Epoch 23/34 => Loss 3.621, Loss_clf 0.814, Loss_fe 0.946, Loss_kd 1.438, Train_accy 35.10
2022-10-08 08:29:25,957 [foster.py] => Task 3, Epoch 24/34 => Loss 3.627, Loss_clf 0.827, Loss_fe 0.942, Loss_kd 1.435, Train_accy 35.68
2022-10-08 08:29:29,307 [foster.py] => Task 3, Epoch 25/34 => Loss 3.691, Loss_clf 0.843, Loss_fe 0.972, Loss_kd 1.449, Train_accy 38.43
2022-10-08 08:29:33,622 [foster.py] => Task 3, Epoch 26/34 => Loss 3.554, Loss_clf 0.795, Loss_fe 0.893, Loss_kd 1.442, Train_accy 37.71, Test_accy 46.83
2022-10-08 08:29:36,579 [foster.py] => Task 3, Epoch 27/34 => Loss 3.591, Loss_clf 0.802, Loss_fe 0.915, Loss_kd 1.448, Train_accy 36.91
2022-10-08 08:29:39,522 [foster.py] => Task 3, Epoch 28/34 => Loss 3.566, Loss_clf 0.798, Loss_fe 0.900, Loss_kd 1.443, Train_accy 36.40
2022-10-08 08:29:42,433 [foster.py] => Task 3, Epoch 29/34 => Loss 3.563, Loss_clf 0.793, Loss_fe 0.906, Loss_kd 1.440, Train_accy 36.84
2022-10-08 08:29:45,510 [foster.py] => Task 3, Epoch 30/34 => Loss 3.569, Loss_clf 0.794, Loss_fe 0.918, Loss_kd 1.435, Train_accy 36.04
2022-10-08 08:29:49,681 [foster.py] => Task 3, Epoch 31/34 => Loss 3.508, Loss_clf 0.766, Loss_fe 0.877, Loss_kd 1.440, Train_accy 37.42, Test_accy 47.42
2022-10-08 08:29:52,561 [foster.py] => Task 3, Epoch 32/34 => Loss 3.563, Loss_clf 0.803, Loss_fe 0.904, Loss_kd 1.435, Train_accy 36.19
2022-10-08 08:29:59,319 [foster.py] => Task 3, Epoch 33/34 => Loss 3.553, Loss_clf 0.805, Loss_fe 0.893, Loss_kd 1.434, Train_accy 36.84
2022-10-08 08:30:02,956 [foster.py] => Task 3, Epoch 34/34 => Loss 3.531, Loss_clf 0.778, Loss_fe 0.881, Loss_kd 1.446, Train_accy 36.84
2022-10-08 08:30:02,956 [foster.py] => do not weight align teacher!
2022-10-08 08:30:02,957 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 08:30:07,520 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.384,  Train_accy 13.05, Test_accy 37.30
2022-10-08 08:30:10,735 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.330,  Train_accy 13.49
2022-10-08 08:30:14,025 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.309,  Train_accy 12.84
2022-10-08 08:30:18,872 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.288,  Train_accy 13.42
2022-10-08 08:30:22,952 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.276,  Train_accy 13.49
2022-10-08 08:30:27,546 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.256,  Train_accy 13.42, Test_accy 36.51
2022-10-08 08:30:30,913 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.259,  Train_accy 12.91
2022-10-08 08:30:34,558 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.238,  Train_accy 14.07
2022-10-08 08:30:38,476 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.242,  Train_accy 14.14
2022-10-08 08:30:42,183 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.242,  Train_accy 14.00
2022-10-08 08:30:46,941 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.233,  Train_accy 14.21, Test_accy 38.10
2022-10-08 08:30:50,553 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.222,  Train_accy 14.79
2022-10-08 08:30:54,221 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.232,  Train_accy 14.43
2022-10-08 08:30:58,021 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.220,  Train_accy 14.72
2022-10-08 08:31:02,043 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.215,  Train_accy 15.23
2022-10-08 08:31:06,961 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.220,  Train_accy 15.45, Test_accy 38.29
2022-10-08 08:31:10,790 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.209,  Train_accy 15.08
2022-10-08 08:31:14,827 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.220,  Train_accy 14.65
2022-10-08 08:31:19,046 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.219,  Train_accy 15.08
2022-10-08 08:31:23,296 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.209,  Train_accy 14.72
2022-10-08 08:31:28,503 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.220,  Train_accy 16.03, Test_accy 38.89
2022-10-08 08:31:32,764 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.218,  Train_accy 15.45
2022-10-08 08:31:37,019 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.239,  Train_accy 15.95
2022-10-08 08:31:41,276 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.227,  Train_accy 15.59
2022-10-08 08:31:45,839 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.214,  Train_accy 15.45
2022-10-08 08:31:51,235 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.223,  Train_accy 15.74, Test_accy 37.50
2022-10-08 08:31:51,235 [foster.py] => do not weight align student!
2022-10-08 08:31:52,107 [foster.py] => darknet eval: 
2022-10-08 08:31:52,107 [foster.py] => CNN top1 curve: 37.5
2022-10-08 08:31:52,107 [foster.py] => CNN top5 curve: 83.33
2022-10-08 08:31:52,107 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 08:32:04,075 [foster.py] => Exemplar size: 440
2022-10-08 08:32:04,075 [trainer.py] => CNN: {'total': 46.83, 'old': 51.89, 'new': 28.04, 'base': 78.48, 'compound': 32.37}
2022-10-08 08:32:04,075 [trainer.py] => CNN top1 curve: [87.97, 66.91, 49.62, 46.83]
2022-10-08 08:32:04,075 [trainer.py] => CNN base curve: [87.97, 84.81, 80.38, 78.48]
2022-10-08 08:32:04,075 [trainer.py] => CNN old curve: [87.97, 84.81, 61.82, 51.89]
2022-10-08 08:32:04,075 [trainer.py] => CNN new curve: [0, 42.74, 22.13, 28.04]
2022-10-08 08:32:04,075 [trainer.py] => CNN compound curve: [0, 42.74, 29.29, 32.37]
2022-10-08 08:32:04,075 [trainer.py] => NME: {'total': 54.56, 'old': 56.93, 'new': 45.79, 'base': 64.56, 'compound': 50.0}
2022-10-08 08:32:04,075 [trainer.py] => NME top1 curve: [86.71, 77.09, 62.47, 54.56]
2022-10-08 08:32:04,075 [trainer.py] => NME base curve: [86.71, 81.65, 71.52, 64.56]
2022-10-08 08:32:04,075 [trainer.py] => NME old curve: [86.71, 81.65, 68.36, 56.93]
2022-10-08 08:32:04,075 [trainer.py] => NME new curve: [0, 70.94, 49.18, 45.79]
2022-10-08 08:32:04,075 [trainer.py] => NME compound curve: [0, 70.94, 56.49, 50.0]
2022-10-08 08:32:04,077 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 08:32:04,077 [trainer.py] => prefix: cil
2022-10-08 08:32:04,077 [trainer.py] => dataset: CFEE
2022-10-08 08:32:04,077 [trainer.py] => memory_size: 2000
2022-10-08 08:32:04,077 [trainer.py] => memory_per_class: 20
2022-10-08 08:32:04,077 [trainer.py] => fixed_memory: True
2022-10-08 08:32:04,077 [trainer.py] => shuffle: True
2022-10-08 08:32:04,077 [trainer.py] => init_cls: 7
2022-10-08 08:32:04,077 [trainer.py] => increment: 5
2022-10-08 08:32:04,077 [trainer.py] => model_name: foster
2022-10-08 08:32:04,077 [trainer.py] => convnet_type: resnet18
2022-10-08 08:32:04,077 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 08:32:04,077 [trainer.py] => seed: 1993
2022-10-08 08:32:04,077 [trainer.py] => beta1: 0.96
2022-10-08 08:32:04,077 [trainer.py] => beta2: 0.97
2022-10-08 08:32:04,077 [trainer.py] => oofc: ft
2022-10-08 08:32:04,078 [trainer.py] => is_teacher_wa: False
2022-10-08 08:32:04,078 [trainer.py] => is_student_wa: False
2022-10-08 08:32:04,078 [trainer.py] => lambda_okd: 1
2022-10-08 08:32:04,078 [trainer.py] => wa_value: 1
2022-10-08 08:32:04,078 [trainer.py] => init_epochs: 40
2022-10-08 08:32:04,078 [trainer.py] => init_lr: 0.01
2022-10-08 08:32:04,078 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 08:32:04,078 [trainer.py] => boosting_epochs: 34
2022-10-08 08:32:04,078 [trainer.py] => compression_epochs: 26
2022-10-08 08:32:04,078 [trainer.py] => lr: 0.001
2022-10-08 08:32:04,078 [trainer.py] => batch_size: 32
2022-10-08 08:32:04,078 [trainer.py] => weight_decay: 0.0005
2022-10-08 08:32:04,078 [trainer.py] => num_workers: 8
2022-10-08 08:32:04,078 [trainer.py] => T: 2
2022-10-08 08:32:04,078 [trainer.py] => nb_runs: 3
2022-10-08 08:32:04,078 [trainer.py] => fold: 10
2022-10-08 08:32:04,078 [data.py] => ========== Fold:9 ==========
2022-10-08 08:32:04,084 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 8, 15, 13, 17, 9, 11, 19, 21, 14, 10, 18, 12, 7, 16]
2022-10-08 08:32:04,435 [foster.py] => Learning on 0-7
2022-10-08 08:32:04,435 [foster.py] => All params: 11183694
2022-10-08 08:32:04,435 [foster.py] => Trainable params: 11183694
2022-10-08 08:32:06,982 [foster.py] => Task 0, Epoch 1/40 => Loss 1.356, Train_accy 49.83
2022-10-08 08:32:10,321 [foster.py] => Task 0, Epoch 2/40 => Loss 0.565, Train_accy 79.63, Test_accy 75.00
2022-10-08 08:32:13,736 [foster.py] => Task 0, Epoch 3/40 => Loss 0.428, Train_accy 86.69, Test_accy 79.88
2022-10-08 08:32:17,051 [foster.py] => Task 0, Epoch 4/40 => Loss 0.335, Train_accy 87.87, Test_accy 80.49
2022-10-08 08:32:20,558 [foster.py] => Task 0, Epoch 5/40 => Loss 0.263, Train_accy 90.16, Test_accy 81.71
2022-10-08 08:32:23,366 [foster.py] => Task 0, Epoch 6/40 => Loss 0.182, Train_accy 93.76
2022-10-08 08:32:26,839 [foster.py] => Task 0, Epoch 7/40 => Loss 0.193, Train_accy 93.76, Test_accy 82.93
2022-10-08 08:32:30,309 [foster.py] => Task 0, Epoch 8/40 => Loss 0.178, Train_accy 93.90, Test_accy 84.76
2022-10-08 08:32:34,175 [foster.py] => Task 0, Epoch 9/40 => Loss 0.179, Train_accy 93.69, Test_accy 82.93
2022-10-08 08:32:37,793 [foster.py] => Task 0, Epoch 10/40 => Loss 0.127, Train_accy 95.43, Test_accy 83.54
2022-10-08 08:32:40,769 [foster.py] => Task 0, Epoch 11/40 => Loss 0.083, Train_accy 97.51
2022-10-08 08:32:44,667 [foster.py] => Task 0, Epoch 12/40 => Loss 0.062, Train_accy 98.41, Test_accy 82.32
2022-10-08 08:32:48,260 [foster.py] => Task 0, Epoch 13/40 => Loss 0.069, Train_accy 97.99, Test_accy 82.32
2022-10-08 08:32:52,114 [foster.py] => Task 0, Epoch 14/40 => Loss 0.071, Train_accy 98.27, Test_accy 81.10
2022-10-08 08:32:55,935 [foster.py] => Task 0, Epoch 15/40 => Loss 0.126, Train_accy 98.06, Test_accy 84.15
2022-10-08 08:32:59,101 [foster.py] => Task 0, Epoch 16/40 => Loss 0.097, Train_accy 96.60
2022-10-08 08:33:02,817 [foster.py] => Task 0, Epoch 17/40 => Loss 0.074, Train_accy 98.61, Test_accy 85.37
2022-10-08 08:33:06,505 [foster.py] => Task 0, Epoch 18/40 => Loss 0.054, Train_accy 98.48, Test_accy 82.32
2022-10-08 08:33:10,466 [foster.py] => Task 0, Epoch 19/40 => Loss 0.040, Train_accy 98.61, Test_accy 82.93
2022-10-08 08:33:13,993 [foster.py] => Task 0, Epoch 20/40 => Loss 0.045, Train_accy 98.75, Test_accy 84.76
2022-10-08 08:33:17,250 [foster.py] => Task 0, Epoch 21/40 => Loss 0.034, Train_accy 99.17
2022-10-08 08:33:21,499 [foster.py] => Task 0, Epoch 22/40 => Loss 0.022, Train_accy 99.65, Test_accy 82.32
2022-10-08 08:33:25,655 [foster.py] => Task 0, Epoch 23/40 => Loss 0.044, Train_accy 99.58, Test_accy 85.37
2022-10-08 08:33:29,614 [foster.py] => Task 0, Epoch 24/40 => Loss 0.034, Train_accy 99.17, Test_accy 84.15
2022-10-08 08:33:33,661 [foster.py] => Task 0, Epoch 25/40 => Loss 0.040, Train_accy 99.10, Test_accy 85.37
2022-10-08 08:33:36,910 [foster.py] => Task 0, Epoch 26/40 => Loss 0.023, Train_accy 99.65
2022-10-08 08:33:40,998 [foster.py] => Task 0, Epoch 27/40 => Loss 0.027, Train_accy 99.45, Test_accy 84.15
2022-10-08 08:33:45,145 [foster.py] => Task 0, Epoch 28/40 => Loss 0.038, Train_accy 99.65, Test_accy 84.76
2022-10-08 08:33:49,338 [foster.py] => Task 0, Epoch 29/40 => Loss 0.038, Train_accy 99.38, Test_accy 85.98
2022-10-08 08:33:53,335 [foster.py] => Task 0, Epoch 30/40 => Loss 0.039, Train_accy 99.51, Test_accy 85.37
2022-10-08 08:33:56,744 [foster.py] => Task 0, Epoch 31/40 => Loss 0.020, Train_accy 99.65
2022-10-08 08:34:01,329 [foster.py] => Task 0, Epoch 32/40 => Loss 0.028, Train_accy 99.72, Test_accy 84.76
2022-10-08 08:34:05,352 [foster.py] => Task 0, Epoch 33/40 => Loss 0.060, Train_accy 99.86, Test_accy 82.93
2022-10-08 08:34:09,462 [foster.py] => Task 0, Epoch 34/40 => Loss 0.037, Train_accy 99.65, Test_accy 83.54
2022-10-08 08:34:13,490 [foster.py] => Task 0, Epoch 35/40 => Loss 0.046, Train_accy 99.58, Test_accy 84.76
2022-10-08 08:34:16,888 [foster.py] => Task 0, Epoch 36/40 => Loss 0.017, Train_accy 99.72
2022-10-08 08:34:21,172 [foster.py] => Task 0, Epoch 37/40 => Loss 0.020, Train_accy 99.86, Test_accy 84.15
2022-10-08 08:34:25,241 [foster.py] => Task 0, Epoch 38/40 => Loss 0.014, Train_accy 99.93, Test_accy 84.76
2022-10-08 08:34:29,604 [foster.py] => Task 0, Epoch 39/40 => Loss 0.018, Train_accy 99.38, Test_accy 84.76
2022-10-08 08:34:34,022 [foster.py] => Task 0, Epoch 40/40 => Loss 0.016, Train_accy 99.79, Test_accy 84.76
2022-10-08 08:34:34,023 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 08:34:41,522 [foster.py] => Exemplar size: 140
2022-10-08 08:34:41,522 [trainer.py] => CNN: {'total': 84.76, 'old': 84.76, 'new': 0, 'base': 84.76, 'compound': 0}
2022-10-08 08:34:41,522 [trainer.py] => CNN top1 curve: [84.76]
2022-10-08 08:34:41,522 [trainer.py] => CNN base curve: [84.76]
2022-10-08 08:34:41,522 [trainer.py] => CNN old curve: [84.76]
2022-10-08 08:34:41,522 [trainer.py] => CNN new curve: [0]
2022-10-08 08:34:41,522 [trainer.py] => CNN compound curve: [0]
2022-10-08 08:34:41,522 [trainer.py] => NME: {'total': 84.15, 'old': 84.15, 'new': 0, 'base': 84.15, 'compound': 0}
2022-10-08 08:34:41,522 [trainer.py] => NME top1 curve: [84.15]
2022-10-08 08:34:41,522 [trainer.py] => NME base curve: [84.15]
2022-10-08 08:34:41,522 [trainer.py] => NME old curve: [84.15]
2022-10-08 08:34:41,522 [trainer.py] => NME new curve: [0]
2022-10-08 08:34:41,522 [trainer.py] => NME compound curve: [0]
2022-10-08 08:34:41,788 [foster.py] => Learning on 7-12
2022-10-08 08:34:41,788 [foster.py] => All params: 22375071
2022-10-08 08:34:41,789 [foster.py] => Trainable params: 11194968
2022-10-08 08:34:41,798 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 08:34:45,584 [foster.py] => Task 1, Epoch 1/34 => Loss 4.740, Loss_clf 2.100, Loss_fe 1.944, Loss_kd 0.406, Train_accy 40.69, Test_accy 65.67
2022-10-08 08:34:49,070 [foster.py] => Task 1, Epoch 2/34 => Loss 2.500, Loss_clf 0.677, Loss_fe 1.184, Loss_kd 0.373, Train_accy 60.83
2022-10-08 08:34:53,442 [foster.py] => Task 1, Epoch 3/34 => Loss 2.129, Loss_clf 0.543, Loss_fe 0.960, Loss_kd 0.365, Train_accy 50.76
2022-10-08 08:34:57,017 [foster.py] => Task 1, Epoch 4/34 => Loss 1.965, Loss_clf 0.496, Loss_fe 0.842, Loss_kd 0.366, Train_accy 51.52
2022-10-08 08:35:01,084 [foster.py] => Task 1, Epoch 5/34 => Loss 1.855, Loss_clf 0.465, Loss_fe 0.760, Loss_kd 0.368, Train_accy 52.28
2022-10-08 08:35:05,541 [foster.py] => Task 1, Epoch 6/34 => Loss 1.770, Loss_clf 0.442, Loss_fe 0.707, Loss_kd 0.362, Train_accy 51.02, Test_accy 69.03
2022-10-08 08:35:09,330 [foster.py] => Task 1, Epoch 7/34 => Loss 1.696, Loss_clf 0.421, Loss_fe 0.648, Loss_kd 0.366, Train_accy 51.18
2022-10-08 08:35:13,235 [foster.py] => Task 1, Epoch 8/34 => Loss 1.663, Loss_clf 0.416, Loss_fe 0.616, Loss_kd 0.368, Train_accy 54.40
2022-10-08 08:35:17,277 [foster.py] => Task 1, Epoch 9/34 => Loss 1.599, Loss_clf 0.387, Loss_fe 0.584, Loss_kd 0.366, Train_accy 52.96
2022-10-08 08:35:21,278 [foster.py] => Task 1, Epoch 10/34 => Loss 1.556, Loss_clf 0.376, Loss_fe 0.551, Loss_kd 0.367, Train_accy 52.88
2022-10-08 08:35:26,388 [foster.py] => Task 1, Epoch 11/34 => Loss 1.534, Loss_clf 0.380, Loss_fe 0.539, Loss_kd 0.359, Train_accy 53.47, Test_accy 69.78
2022-10-08 08:35:30,390 [foster.py] => Task 1, Epoch 12/34 => Loss 1.520, Loss_clf 0.371, Loss_fe 0.522, Loss_kd 0.366, Train_accy 55.84
2022-10-08 08:35:34,792 [foster.py] => Task 1, Epoch 13/34 => Loss 1.466, Loss_clf 0.349, Loss_fe 0.491, Loss_kd 0.365, Train_accy 54.82
2022-10-08 08:35:39,239 [foster.py] => Task 1, Epoch 14/34 => Loss 1.471, Loss_clf 0.353, Loss_fe 0.497, Loss_kd 0.363, Train_accy 54.06
2022-10-08 08:35:43,290 [foster.py] => Task 1, Epoch 15/34 => Loss 1.434, Loss_clf 0.338, Loss_fe 0.473, Loss_kd 0.364, Train_accy 56.09
2022-10-08 08:35:48,667 [foster.py] => Task 1, Epoch 16/34 => Loss 1.420, Loss_clf 0.335, Loss_fe 0.462, Loss_kd 0.363, Train_accy 56.18, Test_accy 70.15
2022-10-08 08:35:52,675 [foster.py] => Task 1, Epoch 17/34 => Loss 1.412, Loss_clf 0.329, Loss_fe 0.454, Loss_kd 0.367, Train_accy 55.75
2022-10-08 08:35:57,081 [foster.py] => Task 1, Epoch 18/34 => Loss 1.391, Loss_clf 0.325, Loss_fe 0.441, Loss_kd 0.365, Train_accy 56.51
2022-10-08 08:36:01,254 [foster.py] => Task 1, Epoch 19/34 => Loss 1.358, Loss_clf 0.306, Loss_fe 0.422, Loss_kd 0.368, Train_accy 58.63
2022-10-08 08:36:05,522 [foster.py] => Task 1, Epoch 20/34 => Loss 1.353, Loss_clf 0.307, Loss_fe 0.417, Loss_kd 0.367, Train_accy 57.70
2022-10-08 08:36:10,810 [foster.py] => Task 1, Epoch 21/34 => Loss 1.327, Loss_clf 0.295, Loss_fe 0.413, Loss_kd 0.361, Train_accy 58.04, Test_accy 70.90
2022-10-08 08:36:15,023 [foster.py] => Task 1, Epoch 22/34 => Loss 1.348, Loss_clf 0.305, Loss_fe 0.411, Loss_kd 0.369, Train_accy 57.36
2022-10-08 08:36:19,151 [foster.py] => Task 1, Epoch 23/34 => Loss 1.314, Loss_clf 0.297, Loss_fe 0.399, Loss_kd 0.360, Train_accy 57.36
2022-10-08 08:36:23,155 [foster.py] => Task 1, Epoch 24/34 => Loss 1.342, Loss_clf 0.300, Loss_fe 0.414, Loss_kd 0.366, Train_accy 57.28
2022-10-08 08:36:27,971 [foster.py] => Task 1, Epoch 25/34 => Loss 1.321, Loss_clf 0.300, Loss_fe 0.397, Loss_kd 0.364, Train_accy 57.95
2022-10-08 08:36:33,707 [foster.py] => Task 1, Epoch 26/34 => Loss 1.301, Loss_clf 0.290, Loss_fe 0.391, Loss_kd 0.362, Train_accy 56.77, Test_accy 70.52
2022-10-08 08:36:38,132 [foster.py] => Task 1, Epoch 27/34 => Loss 1.299, Loss_clf 0.285, Loss_fe 0.389, Loss_kd 0.365, Train_accy 57.53
2022-10-08 08:36:42,385 [foster.py] => Task 1, Epoch 28/34 => Loss 1.282, Loss_clf 0.279, Loss_fe 0.374, Loss_kd 0.367, Train_accy 58.88
2022-10-08 08:36:47,412 [foster.py] => Task 1, Epoch 29/34 => Loss 1.276, Loss_clf 0.277, Loss_fe 0.378, Loss_kd 0.362, Train_accy 58.71
2022-10-08 08:36:52,195 [foster.py] => Task 1, Epoch 30/34 => Loss 1.310, Loss_clf 0.288, Loss_fe 0.398, Loss_kd 0.364, Train_accy 58.46
2022-10-08 08:36:57,260 [foster.py] => Task 1, Epoch 31/34 => Loss 1.288, Loss_clf 0.283, Loss_fe 0.379, Loss_kd 0.365, Train_accy 58.38, Test_accy 70.52
2022-10-08 08:37:02,922 [foster.py] => Task 1, Epoch 32/34 => Loss 1.301, Loss_clf 0.290, Loss_fe 0.387, Loss_kd 0.364, Train_accy 57.70
2022-10-08 08:37:07,104 [foster.py] => Task 1, Epoch 33/34 => Loss 1.294, Loss_clf 0.290, Loss_fe 0.381, Loss_kd 0.364, Train_accy 58.21
2022-10-08 08:37:11,811 [foster.py] => Task 1, Epoch 34/34 => Loss 1.285, Loss_clf 0.278, Loss_fe 0.386, Loss_kd 0.363, Train_accy 57.78
2022-10-08 08:37:11,811 [foster.py] => do not weight align teacher!
2022-10-08 08:37:11,811 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 08:37:19,296 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.829,  Train_accy 11.51, Test_accy 51.49
2022-10-08 08:37:24,719 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.645,  Train_accy 11.76
2022-10-08 08:37:29,964 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.555,  Train_accy 12.44
2022-10-08 08:37:35,385 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.507,  Train_accy 13.79
2022-10-08 08:37:41,666 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.479,  Train_accy 14.64
2022-10-08 08:37:48,506 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.467,  Train_accy 16.75, Test_accy 51.87
2022-10-08 08:37:54,191 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.447,  Train_accy 17.17
2022-10-08 08:38:00,789 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.436,  Train_accy 19.63
2022-10-08 08:38:06,140 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.426,  Train_accy 20.90
2022-10-08 08:38:12,438 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.419,  Train_accy 20.73
2022-10-08 08:38:19,605 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.404,  Train_accy 22.00, Test_accy 57.09
2022-10-08 08:38:25,307 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.404,  Train_accy 23.18
2022-10-08 08:38:30,981 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.393,  Train_accy 23.18
2022-10-08 08:38:37,170 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.397,  Train_accy 23.52
2022-10-08 08:38:43,052 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.379,  Train_accy 24.03
2022-10-08 08:38:50,404 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.373,  Train_accy 24.62, Test_accy 58.21
2022-10-08 08:38:57,317 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.380,  Train_accy 25.13
2022-10-08 08:39:03,136 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.375,  Train_accy 26.14
2022-10-08 08:39:08,545 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.369,  Train_accy 24.96
2022-10-08 08:39:16,203 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.371,  Train_accy 24.70
2022-10-08 08:39:22,850 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.376,  Train_accy 24.79, Test_accy 60.07
2022-10-08 08:39:28,754 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.359,  Train_accy 26.23
2022-10-08 08:39:34,633 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.376,  Train_accy 26.31
2022-10-08 08:39:40,812 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.368,  Train_accy 26.57
2022-10-08 08:39:46,548 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.377,  Train_accy 25.13
2022-10-08 08:39:53,404 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.373,  Train_accy 25.80, Test_accy 58.58
2022-10-08 08:39:53,404 [foster.py] => do not weight align student!
2022-10-08 08:39:54,273 [foster.py] => darknet eval: 
2022-10-08 08:39:54,274 [foster.py] => CNN top1 curve: 58.58
2022-10-08 08:39:54,274 [foster.py] => CNN top5 curve: 97.39
2022-10-08 08:39:54,274 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 08:40:03,623 [foster.py] => Exemplar size: 240
2022-10-08 08:40:03,623 [trainer.py] => CNN: {'total': 70.9, 'old': 79.88, 'new': 56.73, 'base': 79.88, 'compound': 56.73}
2022-10-08 08:40:03,623 [trainer.py] => CNN top1 curve: [84.76, 70.9]
2022-10-08 08:40:03,623 [trainer.py] => CNN base curve: [84.76, 79.88]
2022-10-08 08:40:03,623 [trainer.py] => CNN old curve: [84.76, 79.88]
2022-10-08 08:40:03,623 [trainer.py] => CNN new curve: [0, 56.73]
2022-10-08 08:40:03,623 [trainer.py] => CNN compound curve: [0, 56.73]
2022-10-08 08:40:03,623 [trainer.py] => NME: {'total': 77.99, 'old': 78.05, 'new': 77.88, 'base': 78.05, 'compound': 77.88}
2022-10-08 08:40:03,623 [trainer.py] => NME top1 curve: [84.15, 77.99]
2022-10-08 08:40:03,623 [trainer.py] => NME base curve: [84.15, 78.05]
2022-10-08 08:40:03,623 [trainer.py] => NME old curve: [84.15, 78.05]
2022-10-08 08:40:03,623 [trainer.py] => NME new curve: [0, 77.88]
2022-10-08 08:40:03,623 [trainer.py] => NME compound curve: [0, 77.88]
2022-10-08 08:40:03,883 [foster.py] => Learning on 12-17
2022-10-08 08:40:03,883 [foster.py] => All params: 22385326
2022-10-08 08:40:03,884 [foster.py] => Trainable params: 11202658
2022-10-08 08:40:03,893 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 08:40:11,239 [foster.py] => Task 2, Epoch 1/34 => Loss 6.019, Loss_clf 2.197, Loss_fe 2.417, Loss_kd 0.992, Train_accy 35.06, Test_accy 41.32
2022-10-08 08:40:16,938 [foster.py] => Task 2, Epoch 2/34 => Loss 4.070, Loss_clf 1.103, Loss_fe 1.604, Loss_kd 0.962, Train_accy 40.71
2022-10-08 08:40:22,494 [foster.py] => Task 2, Epoch 3/34 => Loss 3.765, Loss_clf 0.988, Loss_fe 1.410, Loss_kd 0.965, Train_accy 37.73
2022-10-08 08:40:28,817 [foster.py] => Task 2, Epoch 4/34 => Loss 3.583, Loss_clf 0.927, Loss_fe 1.285, Loss_kd 0.968, Train_accy 38.43
2022-10-08 08:40:34,289 [foster.py] => Task 2, Epoch 5/34 => Loss 3.450, Loss_clf 0.895, Loss_fe 1.193, Loss_kd 0.961, Train_accy 38.75
2022-10-08 08:40:41,272 [foster.py] => Task 2, Epoch 6/34 => Loss 3.364, Loss_clf 0.870, Loss_fe 1.132, Loss_kd 0.961, Train_accy 38.27, Test_accy 51.58
2022-10-08 08:40:46,718 [foster.py] => Task 2, Epoch 7/34 => Loss 3.306, Loss_clf 0.857, Loss_fe 1.091, Loss_kd 0.958, Train_accy 40.39
2022-10-08 08:40:52,182 [foster.py] => Task 2, Epoch 8/34 => Loss 3.250, Loss_clf 0.834, Loss_fe 1.051, Loss_kd 0.964, Train_accy 39.84
2022-10-08 08:40:57,465 [foster.py] => Task 2, Epoch 9/34 => Loss 3.191, Loss_clf 0.819, Loss_fe 1.007, Loss_kd 0.964, Train_accy 41.02
2022-10-08 08:41:03,115 [foster.py] => Task 2, Epoch 10/34 => Loss 3.148, Loss_clf 0.812, Loss_fe 0.975, Loss_kd 0.960, Train_accy 42.04
2022-10-08 08:41:09,675 [foster.py] => Task 2, Epoch 11/34 => Loss 3.079, Loss_clf 0.783, Loss_fe 0.925, Loss_kd 0.968, Train_accy 40.94, Test_accy 51.84
2022-10-08 08:41:15,220 [foster.py] => Task 2, Epoch 12/34 => Loss 3.046, Loss_clf 0.764, Loss_fe 0.916, Loss_kd 0.964, Train_accy 41.10
2022-10-08 08:41:21,178 [foster.py] => Task 2, Epoch 13/34 => Loss 3.011, Loss_clf 0.747, Loss_fe 0.892, Loss_kd 0.968, Train_accy 43.29
2022-10-08 08:41:26,399 [foster.py] => Task 2, Epoch 14/34 => Loss 2.992, Loss_clf 0.750, Loss_fe 0.879, Loss_kd 0.962, Train_accy 42.98
2022-10-08 08:41:34,199 [foster.py] => Task 2, Epoch 15/34 => Loss 2.924, Loss_clf 0.721, Loss_fe 0.845, Loss_kd 0.959, Train_accy 41.33
2022-10-08 08:41:40,896 [foster.py] => Task 2, Epoch 16/34 => Loss 2.896, Loss_clf 0.708, Loss_fe 0.823, Loss_kd 0.964, Train_accy 45.02, Test_accy 53.16
2022-10-08 08:41:46,497 [foster.py] => Task 2, Epoch 17/34 => Loss 2.913, Loss_clf 0.719, Loss_fe 0.836, Loss_kd 0.959, Train_accy 41.41
2022-10-08 08:41:52,914 [foster.py] => Task 2, Epoch 18/34 => Loss 2.863, Loss_clf 0.695, Loss_fe 0.806, Loss_kd 0.962, Train_accy 43.53
2022-10-08 08:41:58,304 [foster.py] => Task 2, Epoch 19/34 => Loss 2.872, Loss_clf 0.696, Loss_fe 0.812, Loss_kd 0.963, Train_accy 43.61
2022-10-08 08:42:05,434 [foster.py] => Task 2, Epoch 20/34 => Loss 2.819, Loss_clf 0.680, Loss_fe 0.783, Loss_kd 0.957, Train_accy 42.67
2022-10-08 08:42:12,042 [foster.py] => Task 2, Epoch 21/34 => Loss 2.783, Loss_clf 0.660, Loss_fe 0.763, Loss_kd 0.960, Train_accy 44.63, Test_accy 53.42
2022-10-08 08:42:17,475 [foster.py] => Task 2, Epoch 22/34 => Loss 2.793, Loss_clf 0.664, Loss_fe 0.768, Loss_kd 0.960, Train_accy 42.82
2022-10-08 08:42:23,164 [foster.py] => Task 2, Epoch 23/34 => Loss 2.762, Loss_clf 0.644, Loss_fe 0.750, Loss_kd 0.966, Train_accy 45.49
2022-10-08 08:42:30,194 [foster.py] => Task 2, Epoch 24/34 => Loss 2.743, Loss_clf 0.639, Loss_fe 0.736, Loss_kd 0.965, Train_accy 45.18
2022-10-08 08:42:36,418 [foster.py] => Task 2, Epoch 25/34 => Loss 2.740, Loss_clf 0.644, Loss_fe 0.734, Loss_kd 0.962, Train_accy 48.00
2022-10-08 08:42:42,712 [foster.py] => Task 2, Epoch 26/34 => Loss 2.743, Loss_clf 0.644, Loss_fe 0.734, Loss_kd 0.963, Train_accy 44.94, Test_accy 53.42
2022-10-08 08:42:49,447 [foster.py] => Task 2, Epoch 27/34 => Loss 2.735, Loss_clf 0.637, Loss_fe 0.739, Loss_kd 0.959, Train_accy 44.24
2022-10-08 08:42:54,790 [foster.py] => Task 2, Epoch 28/34 => Loss 2.747, Loss_clf 0.645, Loss_fe 0.736, Loss_kd 0.964, Train_accy 45.33
2022-10-08 08:43:01,164 [foster.py] => Task 2, Epoch 29/34 => Loss 2.720, Loss_clf 0.635, Loss_fe 0.719, Loss_kd 0.964, Train_accy 46.27
2022-10-08 08:43:06,816 [foster.py] => Task 2, Epoch 30/34 => Loss 2.733, Loss_clf 0.637, Loss_fe 0.732, Loss_kd 0.963, Train_accy 44.63
2022-10-08 08:43:13,543 [foster.py] => Task 2, Epoch 31/34 => Loss 2.720, Loss_clf 0.624, Loss_fe 0.723, Loss_kd 0.969, Train_accy 46.35, Test_accy 54.74
2022-10-08 08:43:19,809 [foster.py] => Task 2, Epoch 32/34 => Loss 2.699, Loss_clf 0.618, Loss_fe 0.711, Loss_kd 0.968, Train_accy 46.51
2022-10-08 08:43:26,247 [foster.py] => Task 2, Epoch 33/34 => Loss 2.717, Loss_clf 0.631, Loss_fe 0.722, Loss_kd 0.963, Train_accy 45.25
2022-10-08 08:43:31,887 [foster.py] => Task 2, Epoch 34/34 => Loss 2.690, Loss_clf 0.610, Loss_fe 0.710, Loss_kd 0.967, Train_accy 45.49
2022-10-08 08:43:31,888 [foster.py] => do not weight align teacher!
2022-10-08 08:43:31,888 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 08:43:41,488 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.118,  Train_accy 12.31, Test_accy 40.00
2022-10-08 08:43:49,142 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 2.018,  Train_accy 12.86
2022-10-08 08:43:56,569 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.984,  Train_accy 12.94
2022-10-08 08:44:04,077 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.966,  Train_accy 13.10
2022-10-08 08:44:12,255 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.964,  Train_accy 13.18
2022-10-08 08:44:21,657 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.947,  Train_accy 13.25, Test_accy 43.16
2022-10-08 08:44:28,222 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.943,  Train_accy 13.10
2022-10-08 08:44:34,979 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.931,  Train_accy 13.65
2022-10-08 08:44:43,415 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.920,  Train_accy 13.80
2022-10-08 08:44:50,380 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.934,  Train_accy 12.94
2022-10-08 08:44:58,663 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.911,  Train_accy 13.49, Test_accy 43.16
2022-10-08 08:45:05,864 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.907,  Train_accy 13.88
2022-10-08 08:45:12,735 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.906,  Train_accy 14.20
2022-10-08 08:45:21,216 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.919,  Train_accy 14.35
2022-10-08 08:45:28,292 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.904,  Train_accy 14.35
2022-10-08 08:45:36,646 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.902,  Train_accy 14.51, Test_accy 44.47
2022-10-08 08:45:46,194 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.906,  Train_accy 14.75
2022-10-08 08:45:53,673 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.904,  Train_accy 14.35
2022-10-08 08:46:00,728 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.900,  Train_accy 14.27
2022-10-08 08:46:08,518 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.900,  Train_accy 14.12
2022-10-08 08:46:16,687 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.899,  Train_accy 14.67, Test_accy 44.47
2022-10-08 08:46:23,673 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.903,  Train_accy 14.67
2022-10-08 08:46:32,057 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.902,  Train_accy 13.88
2022-10-08 08:46:38,988 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.904,  Train_accy 14.12
2022-10-08 08:46:46,833 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.899,  Train_accy 14.35
2022-10-08 08:46:55,639 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.905,  Train_accy 14.75, Test_accy 45.00
2022-10-08 08:46:55,640 [foster.py] => do not weight align student!
2022-10-08 08:46:56,605 [foster.py] => darknet eval: 
2022-10-08 08:46:56,605 [foster.py] => CNN top1 curve: 45.0
2022-10-08 08:46:56,605 [foster.py] => CNN top5 curve: 94.74
2022-10-08 08:46:56,606 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 08:47:11,398 [foster.py] => Exemplar size: 340
2022-10-08 08:47:11,398 [trainer.py] => CNN: {'total': 54.21, 'old': 63.81, 'new': 31.25, 'base': 76.22, 'compound': 37.5}
2022-10-08 08:47:11,399 [trainer.py] => CNN top1 curve: [84.76, 70.9, 54.21]
2022-10-08 08:47:11,399 [trainer.py] => CNN base curve: [84.76, 79.88, 76.22]
2022-10-08 08:47:11,399 [trainer.py] => CNN old curve: [84.76, 79.88, 63.81]
2022-10-08 08:47:11,399 [trainer.py] => CNN new curve: [0, 56.73, 31.25]
2022-10-08 08:47:11,399 [trainer.py] => CNN compound curve: [0, 56.73, 37.5]
2022-10-08 08:47:11,399 [trainer.py] => NME: {'total': 64.47, 'old': 69.4, 'new': 52.68, 'base': 68.9, 'compound': 61.11}
2022-10-08 08:47:11,399 [trainer.py] => NME top1 curve: [84.15, 77.99, 64.47]
2022-10-08 08:47:11,399 [trainer.py] => NME base curve: [84.15, 78.05, 68.9]
2022-10-08 08:47:11,399 [trainer.py] => NME old curve: [84.15, 78.05, 69.4]
2022-10-08 08:47:11,399 [trainer.py] => NME new curve: [0, 77.88, 52.68]
2022-10-08 08:47:11,399 [trainer.py] => NME compound curve: [0, 77.88, 61.11]
2022-10-08 08:47:11,730 [foster.py] => Learning on 17-22
2022-10-08 08:47:11,730 [foster.py] => All params: 22395581
2022-10-08 08:47:11,731 [foster.py] => Trainable params: 11210348
2022-10-08 08:47:11,742 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 08:47:20,164 [foster.py] => Task 3, Epoch 1/34 => Loss 6.661, Loss_clf 2.219, Loss_fe 2.533, Loss_kd 1.475, Train_accy 30.98, Test_accy 39.48
2022-10-08 08:47:26,004 [foster.py] => Task 3, Epoch 2/34 => Loss 4.893, Loss_clf 1.224, Loss_fe 1.798, Loss_kd 1.446, Train_accy 29.07
2022-10-08 08:47:31,459 [foster.py] => Task 3, Epoch 3/34 => Loss 4.638, Loss_clf 1.138, Loss_fe 1.625, Loss_kd 1.449, Train_accy 30.91
2022-10-08 08:47:37,366 [foster.py] => Task 3, Epoch 4/34 => Loss 4.450, Loss_clf 1.083, Loss_fe 1.503, Loss_kd 1.440, Train_accy 30.32
2022-10-08 08:47:43,540 [foster.py] => Task 3, Epoch 5/34 => Loss 4.325, Loss_clf 1.038, Loss_fe 1.419, Loss_kd 1.444, Train_accy 32.53
2022-10-08 08:47:50,240 [foster.py] => Task 3, Epoch 6/34 => Loss 4.222, Loss_clf 1.015, Loss_fe 1.339, Loss_kd 1.444, Train_accy 32.75, Test_accy 42.66
2022-10-08 08:47:56,220 [foster.py] => Task 3, Epoch 7/34 => Loss 4.103, Loss_clf 0.976, Loss_fe 1.264, Loss_kd 1.440, Train_accy 33.26
2022-10-08 08:48:01,834 [foster.py] => Task 3, Epoch 8/34 => Loss 4.076, Loss_clf 0.971, Loss_fe 1.236, Loss_kd 1.444, Train_accy 32.97
2022-10-08 08:48:07,074 [foster.py] => Task 3, Epoch 9/34 => Loss 4.018, Loss_clf 0.959, Loss_fe 1.198, Loss_kd 1.438, Train_accy 33.70
2022-10-08 08:48:13,899 [foster.py] => Task 3, Epoch 10/34 => Loss 3.963, Loss_clf 0.940, Loss_fe 1.156, Loss_kd 1.443, Train_accy 33.48
2022-10-08 08:48:20,772 [foster.py] => Task 3, Epoch 11/34 => Loss 3.951, Loss_clf 0.947, Loss_fe 1.139, Loss_kd 1.441, Train_accy 34.80, Test_accy 44.64
2022-10-08 08:48:26,621 [foster.py] => Task 3, Epoch 12/34 => Loss 3.932, Loss_clf 0.947, Loss_fe 1.123, Loss_kd 1.439, Train_accy 33.99
2022-10-08 08:48:32,330 [foster.py] => Task 3, Epoch 13/34 => Loss 3.850, Loss_clf 0.904, Loss_fe 1.074, Loss_kd 1.446, Train_accy 36.05
2022-10-08 08:48:37,938 [foster.py] => Task 3, Epoch 14/34 => Loss 3.803, Loss_clf 0.891, Loss_fe 1.046, Loss_kd 1.442, Train_accy 33.33
2022-10-08 08:48:43,886 [foster.py] => Task 3, Epoch 15/34 => Loss 3.777, Loss_clf 0.874, Loss_fe 1.032, Loss_kd 1.446, Train_accy 35.46
2022-10-08 08:48:51,572 [foster.py] => Task 3, Epoch 16/34 => Loss 3.753, Loss_clf 0.866, Loss_fe 1.008, Loss_kd 1.452, Train_accy 37.81, Test_accy 45.04
2022-10-08 08:48:57,236 [foster.py] => Task 3, Epoch 17/34 => Loss 3.753, Loss_clf 0.866, Loss_fe 1.013, Loss_kd 1.448, Train_accy 35.46
2022-10-08 08:49:03,100 [foster.py] => Task 3, Epoch 18/34 => Loss 3.731, Loss_clf 0.876, Loss_fe 0.994, Loss_kd 1.439, Train_accy 35.02
2022-10-08 08:49:08,766 [foster.py] => Task 3, Epoch 19/34 => Loss 3.701, Loss_clf 0.853, Loss_fe 0.976, Loss_kd 1.447, Train_accy 36.86
2022-10-08 08:49:14,924 [foster.py] => Task 3, Epoch 20/34 => Loss 3.691, Loss_clf 0.852, Loss_fe 0.961, Loss_kd 1.451, Train_accy 36.42
2022-10-08 08:49:21,546 [foster.py] => Task 3, Epoch 21/34 => Loss 3.704, Loss_clf 0.850, Loss_fe 0.978, Loss_kd 1.450, Train_accy 36.42, Test_accy 45.44
2022-10-08 08:49:27,858 [foster.py] => Task 3, Epoch 22/34 => Loss 3.636, Loss_clf 0.828, Loss_fe 0.936, Loss_kd 1.447, Train_accy 38.18
2022-10-08 08:49:33,287 [foster.py] => Task 3, Epoch 23/34 => Loss 3.610, Loss_clf 0.812, Loss_fe 0.929, Loss_kd 1.444, Train_accy 36.49
2022-10-08 08:49:38,820 [foster.py] => Task 3, Epoch 24/34 => Loss 3.628, Loss_clf 0.819, Loss_fe 0.939, Loss_kd 1.445, Train_accy 36.93
2022-10-08 08:49:44,470 [foster.py] => Task 3, Epoch 25/34 => Loss 3.606, Loss_clf 0.807, Loss_fe 0.924, Loss_kd 1.449, Train_accy 38.03
2022-10-08 08:49:51,545 [foster.py] => Task 3, Epoch 26/34 => Loss 3.622, Loss_clf 0.814, Loss_fe 0.935, Loss_kd 1.447, Train_accy 36.64, Test_accy 46.03
2022-10-08 08:49:57,859 [foster.py] => Task 3, Epoch 27/34 => Loss 3.600, Loss_clf 0.811, Loss_fe 0.920, Loss_kd 1.444, Train_accy 38.11
2022-10-08 08:50:03,611 [foster.py] => Task 3, Epoch 28/34 => Loss 3.588, Loss_clf 0.816, Loss_fe 0.907, Loss_kd 1.442, Train_accy 35.61
2022-10-08 08:50:09,224 [foster.py] => Task 3, Epoch 29/34 => Loss 3.587, Loss_clf 0.802, Loss_fe 0.911, Loss_kd 1.448, Train_accy 37.74
2022-10-08 08:50:15,578 [foster.py] => Task 3, Epoch 30/34 => Loss 3.570, Loss_clf 0.799, Loss_fe 0.899, Loss_kd 1.447, Train_accy 37.67
2022-10-08 08:50:22,000 [foster.py] => Task 3, Epoch 31/34 => Loss 3.579, Loss_clf 0.804, Loss_fe 0.906, Loss_kd 1.444, Train_accy 37.89, Test_accy 46.03
2022-10-08 08:50:27,540 [foster.py] => Task 3, Epoch 32/34 => Loss 3.564, Loss_clf 0.788, Loss_fe 0.896, Loss_kd 1.453, Train_accy 38.55
2022-10-08 08:50:33,409 [foster.py] => Task 3, Epoch 33/34 => Loss 3.567, Loss_clf 0.791, Loss_fe 0.902, Loss_kd 1.447, Train_accy 38.69
2022-10-08 08:50:38,914 [foster.py] => Task 3, Epoch 34/34 => Loss 3.616, Loss_clf 0.826, Loss_fe 0.925, Loss_kd 1.441, Train_accy 36.20
2022-10-08 08:50:38,914 [foster.py] => do not weight align teacher!
2022-10-08 08:50:38,915 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 08:50:47,006 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.364,  Train_accy 13.00, Test_accy 36.11
2022-10-08 08:50:53,107 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.316,  Train_accy 13.66
2022-10-08 08:50:59,642 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.299,  Train_accy 14.10
2022-10-08 08:51:06,486 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.288,  Train_accy 13.88
2022-10-08 08:51:13,280 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.268,  Train_accy 14.02
2022-10-08 08:51:20,964 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.269,  Train_accy 13.95, Test_accy 37.50
2022-10-08 08:51:27,582 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.270,  Train_accy 13.88
2022-10-08 08:51:33,868 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.238,  Train_accy 13.88
2022-10-08 08:51:40,642 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.233,  Train_accy 14.61
2022-10-08 08:51:46,990 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.228,  Train_accy 14.90
2022-10-08 08:51:55,307 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.233,  Train_accy 14.76, Test_accy 38.29
2022-10-08 08:52:01,731 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.227,  Train_accy 15.12
2022-10-08 08:52:07,868 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.234,  Train_accy 15.57
2022-10-08 08:52:14,914 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.229,  Train_accy 15.79
2022-10-08 08:52:21,629 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.223,  Train_accy 15.64
2022-10-08 08:52:30,115 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.218,  Train_accy 15.71, Test_accy 38.69
2022-10-08 08:52:37,444 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.215,  Train_accy 15.27
2022-10-08 08:52:44,230 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.218,  Train_accy 16.30
2022-10-08 08:52:50,476 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.214,  Train_accy 15.71
2022-10-08 08:52:57,228 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.217,  Train_accy 16.30
2022-10-08 08:53:04,486 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.215,  Train_accy 16.45, Test_accy 38.89
2022-10-08 08:53:11,433 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.220,  Train_accy 16.37
2022-10-08 08:53:18,272 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.212,  Train_accy 16.23
2022-10-08 08:53:24,990 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.216,  Train_accy 15.79
2022-10-08 08:53:31,326 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.212,  Train_accy 16.96
2022-10-08 08:53:39,439 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.213,  Train_accy 16.01, Test_accy 39.29
2022-10-08 08:53:39,440 [foster.py] => do not weight align student!
2022-10-08 08:53:40,611 [foster.py] => darknet eval: 
2022-10-08 08:53:40,611 [foster.py] => CNN top1 curve: 39.29
2022-10-08 08:53:40,611 [foster.py] => CNN top5 curve: 81.15
2022-10-08 08:53:40,612 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 08:53:55,302 [foster.py] => Exemplar size: 440
2022-10-08 08:53:55,302 [trainer.py] => CNN: {'total': 45.63, 'old': 51.84, 'new': 26.61, 'base': 73.78, 'compound': 32.06}
2022-10-08 08:53:55,302 [trainer.py] => CNN top1 curve: [84.76, 70.9, 54.21, 45.63]
2022-10-08 08:53:55,302 [trainer.py] => CNN base curve: [84.76, 79.88, 76.22, 73.78]
2022-10-08 08:53:55,302 [trainer.py] => CNN old curve: [84.76, 79.88, 63.81, 51.84]
2022-10-08 08:53:55,303 [trainer.py] => CNN new curve: [0, 56.73, 31.25, 26.61]
2022-10-08 08:53:55,303 [trainer.py] => CNN compound curve: [0, 56.73, 37.5, 32.06]
2022-10-08 08:53:55,303 [trainer.py] => NME: {'total': 55.36, 'old': 57.89, 'new': 47.58, 'base': 67.68, 'compound': 49.41}
2022-10-08 08:53:55,303 [trainer.py] => NME top1 curve: [84.15, 77.99, 64.47, 55.36]
2022-10-08 08:53:55,303 [trainer.py] => NME base curve: [84.15, 78.05, 68.9, 67.68]
2022-10-08 08:53:55,303 [trainer.py] => NME old curve: [84.15, 78.05, 69.4, 57.89]
2022-10-08 08:53:55,303 [trainer.py] => NME new curve: [0, 77.88, 52.68, 47.58]
2022-10-08 08:53:55,303 [trainer.py] => NME compound curve: [0, 77.88, 61.11, 49.41]
2022-10-08 08:53:55,304 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 08:53:55,305 [trainer.py] => prefix: cil
2022-10-08 08:53:55,305 [trainer.py] => dataset: CFEE
2022-10-08 08:53:55,305 [trainer.py] => memory_size: 2000
2022-10-08 08:53:55,305 [trainer.py] => memory_per_class: 20
2022-10-08 08:53:55,305 [trainer.py] => fixed_memory: True
2022-10-08 08:53:55,305 [trainer.py] => shuffle: True
2022-10-08 08:53:55,305 [trainer.py] => init_cls: 7
2022-10-08 08:53:55,305 [trainer.py] => increment: 5
2022-10-08 08:53:55,305 [trainer.py] => model_name: foster
2022-10-08 08:53:55,305 [trainer.py] => convnet_type: resnet18
2022-10-08 08:53:55,305 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 08:53:55,305 [trainer.py] => seed: 1993
2022-10-08 08:53:55,305 [trainer.py] => beta1: 0.96
2022-10-08 08:53:55,305 [trainer.py] => beta2: 0.97
2022-10-08 08:53:55,305 [trainer.py] => oofc: ft
2022-10-08 08:53:55,305 [trainer.py] => is_teacher_wa: False
2022-10-08 08:53:55,305 [trainer.py] => is_student_wa: False
2022-10-08 08:53:55,305 [trainer.py] => lambda_okd: 1
2022-10-08 08:53:55,305 [trainer.py] => wa_value: 1
2022-10-08 08:53:55,305 [trainer.py] => init_epochs: 40
2022-10-08 08:53:55,305 [trainer.py] => init_lr: 0.01
2022-10-08 08:53:55,305 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 08:53:55,305 [trainer.py] => boosting_epochs: 34
2022-10-08 08:53:55,305 [trainer.py] => compression_epochs: 26
2022-10-08 08:53:55,305 [trainer.py] => lr: 0.001
2022-10-08 08:53:55,305 [trainer.py] => batch_size: 32
2022-10-08 08:53:55,305 [trainer.py] => weight_decay: 0.0005
2022-10-08 08:53:55,306 [trainer.py] => num_workers: 8
2022-10-08 08:53:55,306 [trainer.py] => T: 2
2022-10-08 08:53:55,306 [trainer.py] => nb_runs: 3
2022-10-08 08:53:55,306 [trainer.py] => fold: 10
2022-10-08 08:53:55,306 [data.py] => ========== Fold:0 ==========
2022-10-08 08:53:55,312 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 12, 10, 19, 21, 17, 18, 8, 7, 9, 14, 15, 13, 11, 16]
2022-10-08 08:53:55,543 [foster.py] => Learning on 0-7
2022-10-08 08:53:55,543 [foster.py] => All params: 11183694
2022-10-08 08:53:55,544 [foster.py] => Trainable params: 11183694
2022-10-08 08:53:59,203 [foster.py] => Task 0, Epoch 1/40 => Loss 1.342, Train_accy 51.75
2022-10-08 08:54:03,954 [foster.py] => Task 0, Epoch 2/40 => Loss 0.564, Train_accy 80.49, Test_accy 80.23
2022-10-08 08:54:08,758 [foster.py] => Task 0, Epoch 3/40 => Loss 0.395, Train_accy 85.80, Test_accy 85.88
2022-10-08 08:54:12,997 [foster.py] => Task 0, Epoch 4/40 => Loss 0.286, Train_accy 90.35, Test_accy 84.18
2022-10-08 08:54:17,921 [foster.py] => Task 0, Epoch 5/40 => Loss 0.224, Train_accy 92.24, Test_accy 85.88
2022-10-08 08:54:22,742 [foster.py] => Task 0, Epoch 6/40 => Loss 0.198, Train_accy 93.29
2022-10-08 08:54:27,825 [foster.py] => Task 0, Epoch 7/40 => Loss 0.165, Train_accy 94.97, Test_accy 90.40
2022-10-08 08:54:33,036 [foster.py] => Task 0, Epoch 8/40 => Loss 0.126, Train_accy 96.08, Test_accy 88.14
2022-10-08 08:54:38,305 [foster.py] => Task 0, Epoch 9/40 => Loss 0.115, Train_accy 96.64, Test_accy 87.57
2022-10-08 08:54:43,400 [foster.py] => Task 0, Epoch 10/40 => Loss 0.091, Train_accy 97.27, Test_accy 90.40
2022-10-08 08:54:47,629 [foster.py] => Task 0, Epoch 11/40 => Loss 0.088, Train_accy 97.69
2022-10-08 08:54:53,112 [foster.py] => Task 0, Epoch 12/40 => Loss 0.079, Train_accy 97.69, Test_accy 83.62
2022-10-08 08:54:58,083 [foster.py] => Task 0, Epoch 13/40 => Loss 0.069, Train_accy 98.04, Test_accy 87.57
2022-10-08 08:55:02,766 [foster.py] => Task 0, Epoch 14/40 => Loss 0.050, Train_accy 98.67, Test_accy 89.83
2022-10-08 08:55:07,395 [foster.py] => Task 0, Epoch 15/40 => Loss 0.051, Train_accy 98.95, Test_accy 87.01
2022-10-08 08:55:12,157 [foster.py] => Task 0, Epoch 16/40 => Loss 0.054, Train_accy 98.60
2022-10-08 08:55:17,633 [foster.py] => Task 0, Epoch 17/40 => Loss 0.040, Train_accy 98.81, Test_accy 87.57
2022-10-08 08:55:22,934 [foster.py] => Task 0, Epoch 18/40 => Loss 0.038, Train_accy 99.30, Test_accy 87.01
2022-10-08 08:55:27,855 [foster.py] => Task 0, Epoch 19/40 => Loss 0.025, Train_accy 99.51, Test_accy 89.27
2022-10-08 08:55:32,829 [foster.py] => Task 0, Epoch 20/40 => Loss 0.025, Train_accy 99.65, Test_accy 89.27
2022-10-08 08:55:37,250 [foster.py] => Task 0, Epoch 21/40 => Loss 0.028, Train_accy 99.30
2022-10-08 08:55:42,189 [foster.py] => Task 0, Epoch 22/40 => Loss 0.027, Train_accy 99.23, Test_accy 89.83
2022-10-08 08:55:47,333 [foster.py] => Task 0, Epoch 23/40 => Loss 0.025, Train_accy 99.30, Test_accy 88.70
2022-10-08 08:55:52,343 [foster.py] => Task 0, Epoch 24/40 => Loss 0.019, Train_accy 99.65, Test_accy 88.70
2022-10-08 08:55:57,524 [foster.py] => Task 0, Epoch 25/40 => Loss 0.016, Train_accy 99.79, Test_accy 88.14
2022-10-08 08:56:01,759 [foster.py] => Task 0, Epoch 26/40 => Loss 0.019, Train_accy 99.72
2022-10-08 08:56:06,579 [foster.py] => Task 0, Epoch 27/40 => Loss 0.019, Train_accy 99.58, Test_accy 88.70
2022-10-08 08:56:11,520 [foster.py] => Task 0, Epoch 28/40 => Loss 0.019, Train_accy 99.44, Test_accy 88.14
2022-10-08 08:56:16,876 [foster.py] => Task 0, Epoch 29/40 => Loss 0.018, Train_accy 99.72, Test_accy 88.70
2022-10-08 08:56:22,364 [foster.py] => Task 0, Epoch 30/40 => Loss 0.020, Train_accy 99.58, Test_accy 88.70
2022-10-08 08:56:26,475 [foster.py] => Task 0, Epoch 31/40 => Loss 0.017, Train_accy 99.72
2022-10-08 08:56:32,448 [foster.py] => Task 0, Epoch 32/40 => Loss 0.017, Train_accy 99.65, Test_accy 89.27
2022-10-08 08:56:36,921 [foster.py] => Task 0, Epoch 33/40 => Loss 0.013, Train_accy 99.79, Test_accy 88.70
2022-10-08 08:56:41,663 [foster.py] => Task 0, Epoch 34/40 => Loss 0.018, Train_accy 99.79, Test_accy 88.70
2022-10-08 08:56:46,729 [foster.py] => Task 0, Epoch 35/40 => Loss 0.015, Train_accy 99.86, Test_accy 88.70
2022-10-08 08:56:51,468 [foster.py] => Task 0, Epoch 36/40 => Loss 0.017, Train_accy 99.65
2022-10-08 08:56:56,895 [foster.py] => Task 0, Epoch 37/40 => Loss 0.016, Train_accy 99.58, Test_accy 88.70
2022-10-08 08:57:02,214 [foster.py] => Task 0, Epoch 38/40 => Loss 0.012, Train_accy 99.86, Test_accy 88.70
2022-10-08 08:57:07,456 [foster.py] => Task 0, Epoch 39/40 => Loss 0.017, Train_accy 99.79, Test_accy 89.27
2022-10-08 08:57:13,241 [foster.py] => Task 0, Epoch 40/40 => Loss 0.012, Train_accy 99.93, Test_accy 88.70
2022-10-08 08:57:13,242 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 08:57:21,019 [foster.py] => Exemplar size: 140
2022-10-08 08:57:21,019 [trainer.py] => CNN: {'total': 88.7, 'old': 88.7, 'new': 0, 'base': 88.7, 'compound': 0}
2022-10-08 08:57:21,019 [trainer.py] => CNN top1 curve: [88.7]
2022-10-08 08:57:21,019 [trainer.py] => CNN base curve: [88.7]
2022-10-08 08:57:21,019 [trainer.py] => CNN old curve: [88.7]
2022-10-08 08:57:21,019 [trainer.py] => CNN new curve: [0]
2022-10-08 08:57:21,019 [trainer.py] => CNN compound curve: [0]
2022-10-08 08:57:21,020 [trainer.py] => NME: {'total': 90.4, 'old': 90.4, 'new': 0, 'base': 90.4, 'compound': 0}
2022-10-08 08:57:21,020 [trainer.py] => NME top1 curve: [90.4]
2022-10-08 08:57:21,020 [trainer.py] => NME base curve: [90.4]
2022-10-08 08:57:21,020 [trainer.py] => NME old curve: [90.4]
2022-10-08 08:57:21,020 [trainer.py] => NME new curve: [0]
2022-10-08 08:57:21,020 [trainer.py] => NME compound curve: [0]
2022-10-08 08:57:21,276 [foster.py] => Learning on 7-12
2022-10-08 08:57:21,276 [foster.py] => All params: 22375071
2022-10-08 08:57:21,276 [foster.py] => Trainable params: 11194968
2022-10-08 08:57:21,287 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 08:57:26,850 [foster.py] => Task 1, Epoch 1/34 => Loss 5.104, Loss_clf 2.367, Loss_fe 2.131, Loss_kd 0.353, Train_accy 28.22, Test_accy 60.87
2022-10-08 08:57:31,122 [foster.py] => Task 1, Epoch 2/34 => Loss 3.122, Loss_clf 1.060, Loss_fe 1.493, Loss_kd 0.332, Train_accy 45.66
2022-10-08 08:57:35,325 [foster.py] => Task 1, Epoch 3/34 => Loss 2.799, Loss_clf 0.941, Loss_fe 1.325, Loss_kd 0.311, Train_accy 36.39
2022-10-08 08:57:40,348 [foster.py] => Task 1, Epoch 4/34 => Loss 2.684, Loss_clf 0.904, Loss_fe 1.229, Loss_kd 0.321, Train_accy 37.24
2022-10-08 08:57:45,077 [foster.py] => Task 1, Epoch 5/34 => Loss 2.603, Loss_clf 0.885, Loss_fe 1.160, Loss_kd 0.325, Train_accy 39.17
2022-10-08 08:57:51,072 [foster.py] => Task 1, Epoch 6/34 => Loss 2.555, Loss_clf 0.878, Loss_fe 1.136, Loss_kd 0.315, Train_accy 38.08, Test_accy 61.96
2022-10-08 08:57:55,559 [foster.py] => Task 1, Epoch 7/34 => Loss 2.444, Loss_clf 0.837, Loss_fe 1.070, Loss_kd 0.313, Train_accy 40.78
2022-10-08 08:58:00,171 [foster.py] => Task 1, Epoch 8/34 => Loss 2.427, Loss_clf 0.834, Loss_fe 1.046, Loss_kd 0.319, Train_accy 39.60
2022-10-08 08:58:04,865 [foster.py] => Task 1, Epoch 9/34 => Loss 2.303, Loss_clf 0.774, Loss_fe 0.970, Loss_kd 0.326, Train_accy 39.76
2022-10-08 08:58:09,814 [foster.py] => Task 1, Epoch 10/34 => Loss 2.247, Loss_clf 0.771, Loss_fe 0.929, Loss_kd 0.319, Train_accy 40.78
2022-10-08 08:58:15,583 [foster.py] => Task 1, Epoch 11/34 => Loss 2.253, Loss_clf 0.783, Loss_fe 0.929, Loss_kd 0.316, Train_accy 40.78, Test_accy 61.96
2022-10-08 08:58:19,690 [foster.py] => Task 1, Epoch 12/34 => Loss 2.242, Loss_clf 0.773, Loss_fe 0.924, Loss_kd 0.318, Train_accy 42.38
2022-10-08 08:58:25,709 [foster.py] => Task 1, Epoch 13/34 => Loss 2.147, Loss_clf 0.741, Loss_fe 0.868, Loss_kd 0.314, Train_accy 41.28
2022-10-08 08:58:30,883 [foster.py] => Task 1, Epoch 14/34 => Loss 2.103, Loss_clf 0.712, Loss_fe 0.851, Loss_kd 0.315, Train_accy 42.97
2022-10-08 08:58:35,807 [foster.py] => Task 1, Epoch 15/34 => Loss 2.140, Loss_clf 0.741, Loss_fe 0.862, Loss_kd 0.314, Train_accy 42.54
2022-10-08 08:58:42,191 [foster.py] => Task 1, Epoch 16/34 => Loss 2.077, Loss_clf 0.707, Loss_fe 0.835, Loss_kd 0.312, Train_accy 43.47, Test_accy 62.68
2022-10-08 08:58:47,090 [foster.py] => Task 1, Epoch 17/34 => Loss 2.083, Loss_clf 0.706, Loss_fe 0.846, Loss_kd 0.310, Train_accy 44.73
2022-10-08 08:58:51,811 [foster.py] => Task 1, Epoch 18/34 => Loss 2.016, Loss_clf 0.645, Loss_fe 0.832, Loss_kd 0.315, Train_accy 44.31
2022-10-08 08:58:56,769 [foster.py] => Task 1, Epoch 19/34 => Loss 2.038, Loss_clf 0.685, Loss_fe 0.815, Loss_kd 0.313, Train_accy 45.58
2022-10-08 08:59:01,696 [foster.py] => Task 1, Epoch 20/34 => Loss 1.960, Loss_clf 0.638, Loss_fe 0.779, Loss_kd 0.316, Train_accy 46.84
2022-10-08 08:59:07,686 [foster.py] => Task 1, Epoch 21/34 => Loss 1.974, Loss_clf 0.661, Loss_fe 0.774, Loss_kd 0.314, Train_accy 48.86, Test_accy 63.04
2022-10-08 08:59:12,526 [foster.py] => Task 1, Epoch 22/34 => Loss 1.948, Loss_clf 0.642, Loss_fe 0.767, Loss_kd 0.314, Train_accy 46.25
2022-10-08 08:59:17,625 [foster.py] => Task 1, Epoch 23/34 => Loss 1.946, Loss_clf 0.645, Loss_fe 0.766, Loss_kd 0.312, Train_accy 46.25
2022-10-08 08:59:22,509 [foster.py] => Task 1, Epoch 24/34 => Loss 1.915, Loss_clf 0.626, Loss_fe 0.743, Loss_kd 0.318, Train_accy 47.77
2022-10-08 08:59:27,385 [foster.py] => Task 1, Epoch 25/34 => Loss 1.881, Loss_clf 0.609, Loss_fe 0.723, Loss_kd 0.320, Train_accy 45.75
2022-10-08 08:59:33,543 [foster.py] => Task 1, Epoch 26/34 => Loss 1.870, Loss_clf 0.607, Loss_fe 0.723, Loss_kd 0.315, Train_accy 46.84, Test_accy 62.68
2022-10-08 08:59:38,115 [foster.py] => Task 1, Epoch 27/34 => Loss 1.877, Loss_clf 0.608, Loss_fe 0.729, Loss_kd 0.315, Train_accy 46.84
2022-10-08 08:59:43,062 [foster.py] => Task 1, Epoch 28/34 => Loss 1.876, Loss_clf 0.612, Loss_fe 0.729, Loss_kd 0.312, Train_accy 47.01
2022-10-08 08:59:48,267 [foster.py] => Task 1, Epoch 29/34 => Loss 1.870, Loss_clf 0.601, Loss_fe 0.722, Loss_kd 0.319, Train_accy 47.85
2022-10-08 08:59:53,297 [foster.py] => Task 1, Epoch 30/34 => Loss 1.907, Loss_clf 0.625, Loss_fe 0.750, Loss_kd 0.311, Train_accy 46.50
2022-10-08 08:59:59,032 [foster.py] => Task 1, Epoch 31/34 => Loss 1.808, Loss_clf 0.570, Loss_fe 0.699, Loss_kd 0.315, Train_accy 48.61, Test_accy 63.77
2022-10-08 09:00:04,039 [foster.py] => Task 1, Epoch 32/34 => Loss 1.836, Loss_clf 0.594, Loss_fe 0.706, Loss_kd 0.313, Train_accy 48.36
2022-10-08 09:00:09,150 [foster.py] => Task 1, Epoch 33/34 => Loss 1.863, Loss_clf 0.595, Loss_fe 0.738, Loss_kd 0.309, Train_accy 47.51
2022-10-08 09:00:13,924 [foster.py] => Task 1, Epoch 34/34 => Loss 1.865, Loss_clf 0.595, Loss_fe 0.722, Loss_kd 0.320, Train_accy 47.77
2022-10-08 09:00:13,924 [foster.py] => do not weight align teacher!
2022-10-08 09:00:13,925 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 09:00:21,910 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.918,  Train_accy 11.37, Test_accy 54.71
2022-10-08 09:00:27,470 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.704,  Train_accy 11.88
2022-10-08 09:00:33,233 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.622,  Train_accy 12.64
2022-10-08 09:00:39,590 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.585,  Train_accy 13.65
2022-10-08 09:00:45,807 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.590,  Train_accy 14.66
2022-10-08 09:00:52,634 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.569,  Train_accy 14.57, Test_accy 56.88
2022-10-08 09:00:58,614 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.545,  Train_accy 16.01
2022-10-08 09:01:04,063 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.543,  Train_accy 16.09
2022-10-08 09:01:10,068 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.531,  Train_accy 17.44
2022-10-08 09:01:16,528 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.514,  Train_accy 17.02
2022-10-08 09:01:23,048 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.514,  Train_accy 17.19, Test_accy 58.33
2022-10-08 09:01:28,228 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.525,  Train_accy 18.11
2022-10-08 09:01:35,006 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.487,  Train_accy 17.02
2022-10-08 09:01:42,971 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.486,  Train_accy 18.28
2022-10-08 09:01:48,417 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.475,  Train_accy 17.19
2022-10-08 09:01:55,257 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.493,  Train_accy 17.69, Test_accy 59.78
2022-10-08 09:02:01,003 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.507,  Train_accy 18.87
2022-10-08 09:02:07,278 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.496,  Train_accy 17.86
2022-10-08 09:02:14,309 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.490,  Train_accy 19.38
2022-10-08 09:02:20,329 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.483,  Train_accy 19.12
2022-10-08 09:02:27,320 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.499,  Train_accy 18.37, Test_accy 58.70
2022-10-08 09:02:33,436 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.493,  Train_accy 19.71
2022-10-08 09:02:39,531 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.497,  Train_accy 19.38
2022-10-08 09:02:45,667 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.492,  Train_accy 19.21
2022-10-08 09:02:51,495 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.489,  Train_accy 19.46
2022-10-08 09:02:59,298 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.463,  Train_accy 18.62, Test_accy 59.42
2022-10-08 09:02:59,299 [foster.py] => do not weight align student!
2022-10-08 09:03:00,083 [foster.py] => darknet eval: 
2022-10-08 09:03:00,083 [foster.py] => CNN top1 curve: 59.42
2022-10-08 09:03:00,083 [foster.py] => CNN top5 curve: 97.1
2022-10-08 09:03:00,084 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 09:03:09,896 [foster.py] => Exemplar size: 240
2022-10-08 09:03:09,896 [trainer.py] => CNN: {'total': 63.41, 'old': 80.79, 'new': 32.32, 'base': 80.79, 'compound': 32.32}
2022-10-08 09:03:09,897 [trainer.py] => CNN top1 curve: [88.7, 63.41]
2022-10-08 09:03:09,897 [trainer.py] => CNN base curve: [88.7, 80.79]
2022-10-08 09:03:09,897 [trainer.py] => CNN old curve: [88.7, 80.79]
2022-10-08 09:03:09,897 [trainer.py] => CNN new curve: [0, 32.32]
2022-10-08 09:03:09,897 [trainer.py] => CNN compound curve: [0, 32.32]
2022-10-08 09:03:09,897 [trainer.py] => NME: {'total': 69.93, 'old': 80.79, 'new': 50.51, 'base': 80.79, 'compound': 50.51}
2022-10-08 09:03:09,897 [trainer.py] => NME top1 curve: [90.4, 69.93]
2022-10-08 09:03:09,897 [trainer.py] => NME base curve: [90.4, 80.79]
2022-10-08 09:03:09,897 [trainer.py] => NME old curve: [90.4, 80.79]
2022-10-08 09:03:09,897 [trainer.py] => NME new curve: [0, 50.51]
2022-10-08 09:03:09,897 [trainer.py] => NME compound curve: [0, 50.51]
2022-10-08 09:03:10,334 [foster.py] => Learning on 12-17
2022-10-08 09:03:10,335 [foster.py] => All params: 22385326
2022-10-08 09:03:10,336 [foster.py] => Trainable params: 11202658
2022-10-08 09:03:10,353 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 09:03:16,195 [foster.py] => Task 2, Epoch 1/34 => Loss 5.702, Loss_clf 1.970, Loss_fe 2.248, Loss_kd 1.047, Train_accy 38.33, Test_accy 50.62
2022-10-08 09:03:21,236 [foster.py] => Task 2, Epoch 2/34 => Loss 3.796, Loss_clf 0.899, Loss_fe 1.454, Loss_kd 1.019, Train_accy 44.68
2022-10-08 09:03:26,821 [foster.py] => Task 2, Epoch 3/34 => Loss 3.477, Loss_clf 0.789, Loss_fe 1.252, Loss_kd 1.013, Train_accy 38.97
2022-10-08 09:03:32,291 [foster.py] => Task 2, Epoch 4/34 => Loss 3.287, Loss_clf 0.724, Loss_fe 1.116, Loss_kd 1.022, Train_accy 41.27
2022-10-08 09:03:37,605 [foster.py] => Task 2, Epoch 5/34 => Loss 3.167, Loss_clf 0.690, Loss_fe 1.034, Loss_kd 1.019, Train_accy 41.19
2022-10-08 09:03:43,719 [foster.py] => Task 2, Epoch 6/34 => Loss 3.061, Loss_clf 0.652, Loss_fe 0.972, Loss_kd 1.014, Train_accy 43.57, Test_accy 51.87
2022-10-08 09:03:49,156 [foster.py] => Task 2, Epoch 7/34 => Loss 2.989, Loss_clf 0.636, Loss_fe 0.911, Loss_kd 1.018, Train_accy 44.60
2022-10-08 09:03:55,001 [foster.py] => Task 2, Epoch 8/34 => Loss 2.953, Loss_clf 0.625, Loss_fe 0.890, Loss_kd 1.015, Train_accy 43.97
2022-10-08 09:04:00,319 [foster.py] => Task 2, Epoch 9/34 => Loss 2.889, Loss_clf 0.611, Loss_fe 0.844, Loss_kd 1.013, Train_accy 44.21
2022-10-08 09:04:05,242 [foster.py] => Task 2, Epoch 10/34 => Loss 2.842, Loss_clf 0.588, Loss_fe 0.803, Loss_kd 1.023, Train_accy 46.43
2022-10-08 09:04:12,650 [foster.py] => Task 2, Epoch 11/34 => Loss 2.778, Loss_clf 0.572, Loss_fe 0.769, Loss_kd 1.015, Train_accy 46.11, Test_accy 52.12
2022-10-08 09:04:17,583 [foster.py] => Task 2, Epoch 12/34 => Loss 2.768, Loss_clf 0.568, Loss_fe 0.755, Loss_kd 1.020, Train_accy 45.63
2022-10-08 09:04:23,248 [foster.py] => Task 2, Epoch 13/34 => Loss 2.723, Loss_clf 0.556, Loss_fe 0.730, Loss_kd 1.014, Train_accy 47.94
2022-10-08 09:04:28,332 [foster.py] => Task 2, Epoch 14/34 => Loss 2.708, Loss_clf 0.546, Loss_fe 0.718, Loss_kd 1.019, Train_accy 47.54
2022-10-08 09:04:34,244 [foster.py] => Task 2, Epoch 15/34 => Loss 2.704, Loss_clf 0.554, Loss_fe 0.707, Loss_kd 1.018, Train_accy 47.22
2022-10-08 09:04:41,794 [foster.py] => Task 2, Epoch 16/34 => Loss 2.644, Loss_clf 0.530, Loss_fe 0.679, Loss_kd 1.013, Train_accy 46.43, Test_accy 54.61
2022-10-08 09:04:46,271 [foster.py] => Task 2, Epoch 17/34 => Loss 2.669, Loss_clf 0.539, Loss_fe 0.691, Loss_kd 1.015, Train_accy 48.25
2022-10-08 09:04:52,247 [foster.py] => Task 2, Epoch 18/34 => Loss 2.629, Loss_clf 0.521, Loss_fe 0.659, Loss_kd 1.023, Train_accy 49.68
2022-10-08 09:04:57,271 [foster.py] => Task 2, Epoch 19/34 => Loss 2.634, Loss_clf 0.528, Loss_fe 0.668, Loss_kd 1.015, Train_accy 49.29
2022-10-08 09:05:02,550 [foster.py] => Task 2, Epoch 20/34 => Loss 2.587, Loss_clf 0.496, Loss_fe 0.641, Loss_kd 1.023, Train_accy 48.10
2022-10-08 09:05:09,182 [foster.py] => Task 2, Epoch 21/34 => Loss 2.594, Loss_clf 0.514, Loss_fe 0.642, Loss_kd 1.015, Train_accy 46.11, Test_accy 53.62
2022-10-08 09:05:14,854 [foster.py] => Task 2, Epoch 22/34 => Loss 2.577, Loss_clf 0.505, Loss_fe 0.630, Loss_kd 1.018, Train_accy 47.94
2022-10-08 09:05:20,235 [foster.py] => Task 2, Epoch 23/34 => Loss 2.546, Loss_clf 0.490, Loss_fe 0.620, Loss_kd 1.014, Train_accy 47.54
2022-10-08 09:05:25,305 [foster.py] => Task 2, Epoch 24/34 => Loss 2.555, Loss_clf 0.488, Loss_fe 0.622, Loss_kd 1.021, Train_accy 48.17
2022-10-08 09:05:31,409 [foster.py] => Task 2, Epoch 25/34 => Loss 2.528, Loss_clf 0.477, Loss_fe 0.603, Loss_kd 1.022, Train_accy 47.54
2022-10-08 09:05:38,010 [foster.py] => Task 2, Epoch 26/34 => Loss 2.535, Loss_clf 0.481, Loss_fe 0.605, Loss_kd 1.023, Train_accy 50.95, Test_accy 53.37
2022-10-08 09:05:43,138 [foster.py] => Task 2, Epoch 27/34 => Loss 2.545, Loss_clf 0.492, Loss_fe 0.606, Loss_kd 1.022, Train_accy 49.44
2022-10-08 09:05:48,394 [foster.py] => Task 2, Epoch 28/34 => Loss 2.549, Loss_clf 0.493, Loss_fe 0.612, Loss_kd 1.019, Train_accy 49.29
2022-10-08 09:05:53,675 [foster.py] => Task 2, Epoch 29/34 => Loss 2.550, Loss_clf 0.490, Loss_fe 0.613, Loss_kd 1.021, Train_accy 49.29
2022-10-08 09:05:59,093 [foster.py] => Task 2, Epoch 30/34 => Loss 2.531, Loss_clf 0.486, Loss_fe 0.594, Loss_kd 1.024, Train_accy 49.44
2022-10-08 09:06:05,116 [foster.py] => Task 2, Epoch 31/34 => Loss 2.504, Loss_clf 0.465, Loss_fe 0.593, Loss_kd 1.020, Train_accy 48.49, Test_accy 53.62
2022-10-08 09:06:11,214 [foster.py] => Task 2, Epoch 32/34 => Loss 2.504, Loss_clf 0.469, Loss_fe 0.591, Loss_kd 1.020, Train_accy 49.37
2022-10-08 09:06:16,902 [foster.py] => Task 2, Epoch 33/34 => Loss 2.521, Loss_clf 0.473, Loss_fe 0.601, Loss_kd 1.022, Train_accy 48.97
2022-10-08 09:06:23,649 [foster.py] => Task 2, Epoch 34/34 => Loss 2.513, Loss_clf 0.476, Loss_fe 0.599, Loss_kd 1.015, Train_accy 48.33
2022-10-08 09:06:23,649 [foster.py] => do not weight align teacher!
2022-10-08 09:06:23,650 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 09:06:30,642 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.162,  Train_accy 11.59, Test_accy 39.15
2022-10-08 09:06:37,193 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 2.035,  Train_accy 12.06
2022-10-08 09:06:44,616 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.995,  Train_accy 11.98
2022-10-08 09:06:51,671 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.972,  Train_accy 12.54
2022-10-08 09:06:58,778 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.951,  Train_accy 11.98
2022-10-08 09:07:06,954 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.951,  Train_accy 12.14, Test_accy 41.15
2022-10-08 09:07:13,994 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.937,  Train_accy 12.46
2022-10-08 09:07:20,703 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.930,  Train_accy 12.46
2022-10-08 09:07:27,338 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.923,  Train_accy 12.38
2022-10-08 09:07:34,803 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.918,  Train_accy 13.10
2022-10-08 09:07:43,469 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.915,  Train_accy 13.65, Test_accy 41.40
2022-10-08 09:07:50,702 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.894,  Train_accy 13.49
2022-10-08 09:07:58,022 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.894,  Train_accy 13.10
2022-10-08 09:08:05,349 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.895,  Train_accy 13.89
2022-10-08 09:08:12,328 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.896,  Train_accy 14.37
2022-10-08 09:08:19,971 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.893,  Train_accy 14.13, Test_accy 40.65
2022-10-08 09:08:27,741 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.895,  Train_accy 14.37
2022-10-08 09:08:34,887 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.895,  Train_accy 14.21
2022-10-08 09:08:41,572 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.889,  Train_accy 14.21
2022-10-08 09:08:48,754 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.882,  Train_accy 14.84
2022-10-08 09:08:58,595 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.889,  Train_accy 14.92, Test_accy 41.15
2022-10-08 09:09:06,892 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.884,  Train_accy 15.08
2022-10-08 09:09:14,160 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.893,  Train_accy 14.84
2022-10-08 09:09:21,334 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.892,  Train_accy 15.71
2022-10-08 09:09:28,512 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.889,  Train_accy 14.60
2022-10-08 09:09:37,359 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.876,  Train_accy 14.68, Test_accy 41.65
2022-10-08 09:09:37,359 [foster.py] => do not weight align student!
2022-10-08 09:09:38,243 [foster.py] => darknet eval: 
2022-10-08 09:09:38,243 [foster.py] => CNN top1 curve: 41.65
2022-10-08 09:09:38,243 [foster.py] => CNN top5 curve: 94.01
2022-10-08 09:09:38,244 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 09:09:50,596 [foster.py] => Exemplar size: 340
2022-10-08 09:09:50,596 [trainer.py] => CNN: {'total': 52.62, 'old': 56.52, 'new': 44.0, 'base': 79.1, 'compound': 31.7}
2022-10-08 09:09:50,596 [trainer.py] => CNN top1 curve: [88.7, 63.41, 52.62]
2022-10-08 09:09:50,596 [trainer.py] => CNN base curve: [88.7, 80.79, 79.1]
2022-10-08 09:09:50,596 [trainer.py] => CNN old curve: [88.7, 80.79, 56.52]
2022-10-08 09:09:50,596 [trainer.py] => CNN new curve: [0, 32.32, 44.0]
2022-10-08 09:09:50,596 [trainer.py] => CNN compound curve: [0, 32.32, 31.7]
2022-10-08 09:09:50,596 [trainer.py] => NME: {'total': 61.85, 'old': 58.33, 'new': 69.6, 'base': 70.62, 'compound': 54.91}
2022-10-08 09:09:50,597 [trainer.py] => NME top1 curve: [90.4, 69.93, 61.85]
2022-10-08 09:09:50,597 [trainer.py] => NME base curve: [90.4, 80.79, 70.62]
2022-10-08 09:09:50,597 [trainer.py] => NME old curve: [90.4, 80.79, 58.33]
2022-10-08 09:09:50,597 [trainer.py] => NME new curve: [0, 50.51, 69.6]
2022-10-08 09:09:50,597 [trainer.py] => NME compound curve: [0, 50.51, 54.91]
2022-10-08 09:09:50,905 [foster.py] => Learning on 17-22
2022-10-08 09:09:50,905 [foster.py] => All params: 22395581
2022-10-08 09:09:50,905 [foster.py] => Trainable params: 11210348
2022-10-08 09:09:50,916 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 09:09:58,330 [foster.py] => Task 3, Epoch 1/34 => Loss 6.628, Loss_clf 2.068, Loss_fe 2.494, Loss_kd 1.596, Train_accy 33.38, Test_accy 41.19
2022-10-08 09:10:04,734 [foster.py] => Task 3, Epoch 2/34 => Loss 4.994, Loss_clf 1.174, Loss_fe 1.771, Loss_kd 1.584, Train_accy 39.45
2022-10-08 09:10:11,375 [foster.py] => Task 3, Epoch 3/34 => Loss 4.696, Loss_clf 1.095, Loss_fe 1.567, Loss_kd 1.571, Train_accy 40.17
2022-10-08 09:10:18,213 [foster.py] => Task 3, Epoch 4/34 => Loss 4.464, Loss_clf 1.007, Loss_fe 1.421, Loss_kd 1.573, Train_accy 44.15
2022-10-08 09:10:25,031 [foster.py] => Task 3, Epoch 5/34 => Loss 4.334, Loss_clf 0.987, Loss_fe 1.308, Loss_kd 1.576, Train_accy 42.12
2022-10-08 09:10:32,456 [foster.py] => Task 3, Epoch 6/34 => Loss 4.254, Loss_clf 0.957, Loss_fe 1.248, Loss_kd 1.583, Train_accy 42.20, Test_accy 48.71
2022-10-08 09:10:39,966 [foster.py] => Task 3, Epoch 7/34 => Loss 4.151, Loss_clf 0.935, Loss_fe 1.172, Loss_kd 1.580, Train_accy 43.14
2022-10-08 09:10:46,961 [foster.py] => Task 3, Epoch 8/34 => Loss 4.097, Loss_clf 0.927, Loss_fe 1.132, Loss_kd 1.574, Train_accy 42.70
2022-10-08 09:10:53,300 [foster.py] => Task 3, Epoch 9/34 => Loss 4.025, Loss_clf 0.893, Loss_fe 1.076, Loss_kd 1.588, Train_accy 44.87
2022-10-08 09:11:00,659 [foster.py] => Task 3, Epoch 10/34 => Loss 3.963, Loss_clf 0.878, Loss_fe 1.038, Loss_kd 1.583, Train_accy 44.44
2022-10-08 09:11:08,828 [foster.py] => Task 3, Epoch 11/34 => Loss 3.930, Loss_clf 0.868, Loss_fe 1.013, Loss_kd 1.583, Train_accy 44.08, Test_accy 50.10
2022-10-08 09:11:16,111 [foster.py] => Task 3, Epoch 12/34 => Loss 3.877, Loss_clf 0.848, Loss_fe 0.980, Loss_kd 1.584, Train_accy 45.23
2022-10-08 09:11:22,892 [foster.py] => Task 3, Epoch 13/34 => Loss 3.863, Loss_clf 0.840, Loss_fe 0.974, Loss_kd 1.583, Train_accy 45.01
2022-10-08 09:11:30,090 [foster.py] => Task 3, Epoch 14/34 => Loss 3.833, Loss_clf 0.831, Loss_fe 0.950, Loss_kd 1.587, Train_accy 46.60
2022-10-08 09:11:36,599 [foster.py] => Task 3, Epoch 15/34 => Loss 3.793, Loss_clf 0.813, Loss_fe 0.935, Loss_kd 1.581, Train_accy 45.59
2022-10-08 09:11:45,978 [foster.py] => Task 3, Epoch 16/34 => Loss 3.730, Loss_clf 0.793, Loss_fe 0.890, Loss_kd 1.582, Train_accy 46.53, Test_accy 50.50
2022-10-08 09:11:53,704 [foster.py] => Task 3, Epoch 17/34 => Loss 3.733, Loss_clf 0.789, Loss_fe 0.891, Loss_kd 1.586, Train_accy 48.70
2022-10-08 09:12:00,370 [foster.py] => Task 3, Epoch 18/34 => Loss 3.737, Loss_clf 0.794, Loss_fe 0.893, Loss_kd 1.584, Train_accy 46.68
2022-10-08 09:12:06,646 [foster.py] => Task 3, Epoch 19/34 => Loss 3.664, Loss_clf 0.762, Loss_fe 0.850, Loss_kd 1.585, Train_accy 46.24
2022-10-08 09:12:13,520 [foster.py] => Task 3, Epoch 20/34 => Loss 3.681, Loss_clf 0.773, Loss_fe 0.856, Loss_kd 1.586, Train_accy 47.33
2022-10-08 09:12:22,337 [foster.py] => Task 3, Epoch 21/34 => Loss 3.654, Loss_clf 0.759, Loss_fe 0.849, Loss_kd 1.581, Train_accy 47.69, Test_accy 50.50
2022-10-08 09:12:28,475 [foster.py] => Task 3, Epoch 22/34 => Loss 3.654, Loss_clf 0.756, Loss_fe 0.841, Loss_kd 1.589, Train_accy 48.55
2022-10-08 09:12:36,010 [foster.py] => Task 3, Epoch 23/34 => Loss 3.653, Loss_clf 0.756, Loss_fe 0.843, Loss_kd 1.588, Train_accy 47.40
2022-10-08 09:12:42,192 [foster.py] => Task 3, Epoch 24/34 => Loss 3.650, Loss_clf 0.751, Loss_fe 0.839, Loss_kd 1.591, Train_accy 48.48
2022-10-08 09:12:49,322 [foster.py] => Task 3, Epoch 25/34 => Loss 3.632, Loss_clf 0.750, Loss_fe 0.822, Loss_kd 1.592, Train_accy 48.70
2022-10-08 09:12:57,605 [foster.py] => Task 3, Epoch 26/34 => Loss 3.651, Loss_clf 0.755, Loss_fe 0.841, Loss_kd 1.588, Train_accy 48.70, Test_accy 51.68
2022-10-08 09:13:04,814 [foster.py] => Task 3, Epoch 27/34 => Loss 3.566, Loss_clf 0.711, Loss_fe 0.797, Loss_kd 1.589, Train_accy 47.98
2022-10-08 09:13:12,791 [foster.py] => Task 3, Epoch 28/34 => Loss 3.590, Loss_clf 0.730, Loss_fe 0.813, Loss_kd 1.582, Train_accy 48.27
2022-10-08 09:13:19,230 [foster.py] => Task 3, Epoch 29/34 => Loss 3.588, Loss_clf 0.730, Loss_fe 0.811, Loss_kd 1.582, Train_accy 49.13
2022-10-08 09:13:27,323 [foster.py] => Task 3, Epoch 30/34 => Loss 3.587, Loss_clf 0.734, Loss_fe 0.801, Loss_kd 1.585, Train_accy 48.92
2022-10-08 09:13:35,636 [foster.py] => Task 3, Epoch 31/34 => Loss 3.574, Loss_clf 0.724, Loss_fe 0.799, Loss_kd 1.586, Train_accy 49.28, Test_accy 51.68
2022-10-08 09:13:42,533 [foster.py] => Task 3, Epoch 32/34 => Loss 3.638, Loss_clf 0.747, Loss_fe 0.833, Loss_kd 1.590, Train_accy 46.75
2022-10-08 09:13:49,502 [foster.py] => Task 3, Epoch 33/34 => Loss 3.560, Loss_clf 0.712, Loss_fe 0.792, Loss_kd 1.589, Train_accy 49.71
2022-10-08 09:13:56,072 [foster.py] => Task 3, Epoch 34/34 => Loss 3.578, Loss_clf 0.727, Loss_fe 0.796, Loss_kd 1.588, Train_accy 49.06
2022-10-08 09:13:56,073 [foster.py] => do not weight align teacher!
2022-10-08 09:13:56,073 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 09:14:04,800 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.519,  Train_accy 11.49, Test_accy 32.08
2022-10-08 09:14:13,847 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.457,  Train_accy 12.21
2022-10-08 09:14:21,571 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.442,  Train_accy 12.14
2022-10-08 09:14:30,084 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.435,  Train_accy 12.79
2022-10-08 09:14:39,489 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.416,  Train_accy 13.08
2022-10-08 09:14:48,216 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.410,  Train_accy 13.22, Test_accy 34.85
2022-10-08 09:14:57,499 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.400,  Train_accy 13.15
2022-10-08 09:15:05,680 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.395,  Train_accy 14.38
2022-10-08 09:15:14,414 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.394,  Train_accy 14.16
2022-10-08 09:15:22,707 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.392,  Train_accy 14.52
2022-10-08 09:15:32,635 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.380,  Train_accy 15.25, Test_accy 36.83
2022-10-08 09:15:40,757 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.380,  Train_accy 15.17
2022-10-08 09:15:49,925 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.381,  Train_accy 17.20
2022-10-08 09:16:00,003 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.369,  Train_accy 15.97
2022-10-08 09:16:07,796 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.377,  Train_accy 16.76
2022-10-08 09:16:17,152 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.374,  Train_accy 16.69, Test_accy 37.82
2022-10-08 09:16:24,200 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.372,  Train_accy 17.05
2022-10-08 09:16:30,918 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.373,  Train_accy 17.20
2022-10-08 09:16:36,914 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.375,  Train_accy 16.91
2022-10-08 09:16:42,964 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.360,  Train_accy 17.34
2022-10-08 09:16:49,648 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.370,  Train_accy 16.84, Test_accy 39.21
2022-10-08 09:16:55,845 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.364,  Train_accy 18.35
2022-10-08 09:17:01,243 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.372,  Train_accy 18.35
2022-10-08 09:17:07,137 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.364,  Train_accy 17.85
2022-10-08 09:17:13,110 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.365,  Train_accy 17.56
2022-10-08 09:17:19,210 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.367,  Train_accy 17.34, Test_accy 39.80
2022-10-08 09:17:19,211 [foster.py] => do not weight align student!
2022-10-08 09:17:20,132 [foster.py] => darknet eval: 
2022-10-08 09:17:20,133 [foster.py] => CNN top1 curve: 39.8
2022-10-08 09:17:20,133 [foster.py] => CNN top5 curve: 86.53
2022-10-08 09:17:20,133 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 09:17:31,926 [foster.py] => Exemplar size: 440
2022-10-08 09:17:31,926 [trainer.py] => CNN: {'total': 50.69, 'old': 52.62, 'new': 43.27, 'base': 74.01, 'compound': 38.11}
2022-10-08 09:17:31,926 [trainer.py] => CNN top1 curve: [88.7, 63.41, 52.62, 50.69]
2022-10-08 09:17:31,926 [trainer.py] => CNN base curve: [88.7, 80.79, 79.1, 74.01]
2022-10-08 09:17:31,926 [trainer.py] => CNN old curve: [88.7, 80.79, 56.52, 52.62]
2022-10-08 09:17:31,926 [trainer.py] => CNN new curve: [0, 32.32, 44.0, 43.27]
2022-10-08 09:17:31,926 [trainer.py] => CNN compound curve: [0, 32.32, 31.7, 38.11]
2022-10-08 09:17:31,926 [trainer.py] => NME: {'total': 58.61, 'old': 59.85, 'new': 53.85, 'base': 69.49, 'compound': 52.74}
2022-10-08 09:17:31,926 [trainer.py] => NME top1 curve: [90.4, 69.93, 61.85, 58.61]
2022-10-08 09:17:31,926 [trainer.py] => NME base curve: [90.4, 80.79, 70.62, 69.49]
2022-10-08 09:17:31,927 [trainer.py] => NME old curve: [90.4, 80.79, 58.33, 59.85]
2022-10-08 09:17:31,927 [trainer.py] => NME new curve: [0, 50.51, 69.6, 53.85]
2022-10-08 09:17:31,927 [trainer.py] => NME compound curve: [0, 50.51, 54.91, 52.74]
2022-10-08 09:17:31,928 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 09:17:31,928 [trainer.py] => prefix: cil
2022-10-08 09:17:31,928 [trainer.py] => dataset: CFEE
2022-10-08 09:17:31,928 [trainer.py] => memory_size: 2000
2022-10-08 09:17:31,928 [trainer.py] => memory_per_class: 20
2022-10-08 09:17:31,928 [trainer.py] => fixed_memory: True
2022-10-08 09:17:31,928 [trainer.py] => shuffle: True
2022-10-08 09:17:31,928 [trainer.py] => init_cls: 7
2022-10-08 09:17:31,928 [trainer.py] => increment: 5
2022-10-08 09:17:31,928 [trainer.py] => model_name: foster
2022-10-08 09:17:31,928 [trainer.py] => convnet_type: resnet18
2022-10-08 09:17:31,928 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 09:17:31,929 [trainer.py] => seed: 1993
2022-10-08 09:17:31,929 [trainer.py] => beta1: 0.96
2022-10-08 09:17:31,929 [trainer.py] => beta2: 0.97
2022-10-08 09:17:31,929 [trainer.py] => oofc: ft
2022-10-08 09:17:31,929 [trainer.py] => is_teacher_wa: False
2022-10-08 09:17:31,929 [trainer.py] => is_student_wa: False
2022-10-08 09:17:31,929 [trainer.py] => lambda_okd: 1
2022-10-08 09:17:31,929 [trainer.py] => wa_value: 1
2022-10-08 09:17:31,929 [trainer.py] => init_epochs: 40
2022-10-08 09:17:31,929 [trainer.py] => init_lr: 0.01
2022-10-08 09:17:31,929 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 09:17:31,929 [trainer.py] => boosting_epochs: 34
2022-10-08 09:17:31,929 [trainer.py] => compression_epochs: 26
2022-10-08 09:17:31,929 [trainer.py] => lr: 0.001
2022-10-08 09:17:31,929 [trainer.py] => batch_size: 32
2022-10-08 09:17:31,929 [trainer.py] => weight_decay: 0.0005
2022-10-08 09:17:31,929 [trainer.py] => num_workers: 8
2022-10-08 09:17:31,929 [trainer.py] => T: 2
2022-10-08 09:17:31,929 [trainer.py] => nb_runs: 3
2022-10-08 09:17:31,929 [trainer.py] => fold: 10
2022-10-08 09:17:31,929 [data.py] => ========== Fold:1 ==========
2022-10-08 09:17:31,935 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 12, 10, 19, 21, 17, 18, 8, 7, 9, 14, 15, 13, 11, 16]
2022-10-08 09:17:32,165 [foster.py] => Learning on 0-7
2022-10-08 09:17:32,165 [foster.py] => All params: 11183694
2022-10-08 09:17:32,165 [foster.py] => Trainable params: 11183694
2022-10-08 09:17:35,510 [foster.py] => Task 0, Epoch 1/40 => Loss 1.381, Train_accy 48.12
2022-10-08 09:17:39,188 [foster.py] => Task 0, Epoch 2/40 => Loss 0.568, Train_accy 80.12, Test_accy 83.11
2022-10-08 09:17:42,915 [foster.py] => Task 0, Epoch 3/40 => Loss 0.373, Train_accy 86.98, Test_accy 85.81
2022-10-08 09:17:46,811 [foster.py] => Task 0, Epoch 4/40 => Loss 0.287, Train_accy 89.10, Test_accy 85.14
2022-10-08 09:17:50,983 [foster.py] => Task 0, Epoch 5/40 => Loss 0.233, Train_accy 91.78, Test_accy 88.51
2022-10-08 09:17:54,450 [foster.py] => Task 0, Epoch 6/40 => Loss 0.210, Train_accy 92.25
2022-10-08 09:17:58,556 [foster.py] => Task 0, Epoch 7/40 => Loss 0.177, Train_accy 93.69, Test_accy 87.84
2022-10-08 09:18:02,445 [foster.py] => Task 0, Epoch 8/40 => Loss 0.139, Train_accy 95.20, Test_accy 89.86
2022-10-08 09:18:06,435 [foster.py] => Task 0, Epoch 9/40 => Loss 0.118, Train_accy 96.57, Test_accy 85.81
2022-10-08 09:18:10,224 [foster.py] => Task 0, Epoch 10/40 => Loss 0.097, Train_accy 97.05, Test_accy 89.19
2022-10-08 09:18:13,437 [foster.py] => Task 0, Epoch 11/40 => Loss 0.083, Train_accy 96.85
2022-10-08 09:18:17,333 [foster.py] => Task 0, Epoch 12/40 => Loss 0.066, Train_accy 98.36, Test_accy 87.84
2022-10-08 09:18:21,131 [foster.py] => Task 0, Epoch 13/40 => Loss 0.075, Train_accy 98.01, Test_accy 87.16
2022-10-08 09:18:25,153 [foster.py] => Task 0, Epoch 14/40 => Loss 0.054, Train_accy 98.63, Test_accy 87.84
2022-10-08 09:18:29,043 [foster.py] => Task 0, Epoch 15/40 => Loss 0.054, Train_accy 98.42, Test_accy 89.86
2022-10-08 09:18:32,411 [foster.py] => Task 0, Epoch 16/40 => Loss 0.041, Train_accy 99.25
2022-10-08 09:18:36,296 [foster.py] => Task 0, Epoch 17/40 => Loss 0.045, Train_accy 98.77, Test_accy 87.84
2022-10-08 09:18:40,026 [foster.py] => Task 0, Epoch 18/40 => Loss 0.040, Train_accy 99.18, Test_accy 88.51
2022-10-08 09:18:44,028 [foster.py] => Task 0, Epoch 19/40 => Loss 0.037, Train_accy 99.25, Test_accy 85.81
2022-10-08 09:18:48,005 [foster.py] => Task 0, Epoch 20/40 => Loss 0.030, Train_accy 99.52, Test_accy 87.84
2022-10-08 09:18:51,379 [foster.py] => Task 0, Epoch 21/40 => Loss 0.022, Train_accy 99.73
2022-10-08 09:18:55,387 [foster.py] => Task 0, Epoch 22/40 => Loss 0.025, Train_accy 99.38, Test_accy 87.84
2022-10-08 09:18:59,304 [foster.py] => Task 0, Epoch 23/40 => Loss 0.025, Train_accy 99.52, Test_accy 87.84
2022-10-08 09:19:03,334 [foster.py] => Task 0, Epoch 24/40 => Loss 0.019, Train_accy 99.73, Test_accy 87.84
2022-10-08 09:19:07,271 [foster.py] => Task 0, Epoch 25/40 => Loss 0.020, Train_accy 99.73, Test_accy 88.51
2022-10-08 09:19:10,598 [foster.py] => Task 0, Epoch 26/40 => Loss 0.019, Train_accy 99.66
2022-10-08 09:19:14,551 [foster.py] => Task 0, Epoch 27/40 => Loss 0.019, Train_accy 99.59, Test_accy 88.51
2022-10-08 09:19:18,196 [foster.py] => Task 0, Epoch 28/40 => Loss 0.017, Train_accy 99.73, Test_accy 88.51
2022-10-08 09:19:21,827 [foster.py] => Task 0, Epoch 29/40 => Loss 0.016, Train_accy 99.79, Test_accy 88.51
2022-10-08 09:19:25,184 [foster.py] => Task 0, Epoch 30/40 => Loss 0.015, Train_accy 99.79, Test_accy 88.51
2022-10-08 09:19:27,996 [foster.py] => Task 0, Epoch 31/40 => Loss 0.013, Train_accy 99.93
2022-10-08 09:19:31,812 [foster.py] => Task 0, Epoch 32/40 => Loss 0.011, Train_accy 100.00, Test_accy 89.19
2022-10-08 09:19:35,592 [foster.py] => Task 0, Epoch 33/40 => Loss 0.014, Train_accy 99.86, Test_accy 87.84
2022-10-08 09:19:39,091 [foster.py] => Task 0, Epoch 34/40 => Loss 0.012, Train_accy 99.93, Test_accy 88.51
2022-10-08 09:19:42,644 [foster.py] => Task 0, Epoch 35/40 => Loss 0.014, Train_accy 99.93, Test_accy 89.19
2022-10-08 09:19:45,636 [foster.py] => Task 0, Epoch 36/40 => Loss 0.012, Train_accy 99.93
2022-10-08 09:19:49,349 [foster.py] => Task 0, Epoch 37/40 => Loss 0.014, Train_accy 99.86, Test_accy 89.19
2022-10-08 09:19:58,594 [foster.py] => Task 0, Epoch 38/40 => Loss 0.015, Train_accy 99.86, Test_accy 88.51
2022-10-08 09:20:02,127 [foster.py] => Task 0, Epoch 39/40 => Loss 0.012, Train_accy 99.93, Test_accy 87.84
2022-10-08 09:20:05,174 [foster.py] => Task 0, Epoch 40/40 => Loss 0.015, Train_accy 99.93, Test_accy 88.51
2022-10-08 09:20:05,175 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 09:20:11,708 [foster.py] => Exemplar size: 140
2022-10-08 09:20:11,708 [trainer.py] => CNN: {'total': 88.51, 'old': 88.51, 'new': 0, 'base': 88.51, 'compound': 0}
2022-10-08 09:20:11,709 [trainer.py] => CNN top1 curve: [88.51]
2022-10-08 09:20:11,709 [trainer.py] => CNN base curve: [88.51]
2022-10-08 09:20:11,709 [trainer.py] => CNN old curve: [88.51]
2022-10-08 09:20:11,709 [trainer.py] => CNN new curve: [0]
2022-10-08 09:20:11,709 [trainer.py] => CNN compound curve: [0]
2022-10-08 09:20:11,709 [trainer.py] => NME: {'total': 89.19, 'old': 89.19, 'new': 0, 'base': 89.19, 'compound': 0}
2022-10-08 09:20:11,709 [trainer.py] => NME top1 curve: [89.19]
2022-10-08 09:20:11,709 [trainer.py] => NME base curve: [89.19]
2022-10-08 09:20:11,709 [trainer.py] => NME old curve: [89.19]
2022-10-08 09:20:11,709 [trainer.py] => NME new curve: [0]
2022-10-08 09:20:11,709 [trainer.py] => NME compound curve: [0]
2022-10-08 09:20:11,937 [foster.py] => Learning on 7-12
2022-10-08 09:20:11,938 [foster.py] => All params: 22375071
2022-10-08 09:20:11,938 [foster.py] => Trainable params: 11194968
2022-10-08 09:20:11,947 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 09:20:15,176 [foster.py] => Task 1, Epoch 1/34 => Loss 5.126, Loss_clf 2.448, Loss_fe 2.063, Loss_kd 0.359, Train_accy 28.92, Test_accy 53.76
2022-10-08 09:20:17,641 [foster.py] => Task 1, Epoch 2/34 => Loss 3.104, Loss_clf 1.066, Loss_fe 1.471, Loss_kd 0.331, Train_accy 43.20
2022-10-08 09:20:24,322 [foster.py] => Task 1, Epoch 3/34 => Loss 2.811, Loss_clf 0.952, Loss_fe 1.300, Loss_kd 0.326, Train_accy 36.80
2022-10-08 09:20:28,084 [foster.py] => Task 1, Epoch 4/34 => Loss 2.619, Loss_clf 0.884, Loss_fe 1.186, Loss_kd 0.320, Train_accy 37.92
2022-10-08 09:20:31,194 [foster.py] => Task 1, Epoch 5/34 => Loss 2.574, Loss_clf 0.891, Loss_fe 1.132, Loss_kd 0.322, Train_accy 38.35
2022-10-08 09:20:34,862 [foster.py] => Task 1, Epoch 6/34 => Loss 2.474, Loss_clf 0.841, Loss_fe 1.073, Loss_kd 0.327, Train_accy 39.48, Test_accy 59.14
2022-10-08 09:20:37,304 [foster.py] => Task 1, Epoch 7/34 => Loss 2.383, Loss_clf 0.815, Loss_fe 1.020, Loss_kd 0.320, Train_accy 38.35
2022-10-08 09:20:43,761 [foster.py] => Task 1, Epoch 8/34 => Loss 2.413, Loss_clf 0.828, Loss_fe 1.038, Loss_kd 0.319, Train_accy 38.10
2022-10-08 09:20:47,130 [foster.py] => Task 1, Epoch 9/34 => Loss 2.230, Loss_clf 0.746, Loss_fe 0.929, Loss_kd 0.324, Train_accy 37.40
2022-10-08 09:20:50,198 [foster.py] => Task 1, Epoch 10/34 => Loss 2.228, Loss_clf 0.752, Loss_fe 0.925, Loss_kd 0.321, Train_accy 40.78
2022-10-08 09:20:53,638 [foster.py] => Task 1, Epoch 11/34 => Loss 2.213, Loss_clf 0.748, Loss_fe 0.906, Loss_kd 0.326, Train_accy 38.44, Test_accy 59.86
2022-10-08 09:20:56,147 [foster.py] => Task 1, Epoch 12/34 => Loss 2.150, Loss_clf 0.728, Loss_fe 0.882, Loss_kd 0.315, Train_accy 41.99
2022-10-08 09:20:58,658 [foster.py] => Task 1, Epoch 13/34 => Loss 2.136, Loss_clf 0.725, Loss_fe 0.851, Loss_kd 0.327, Train_accy 41.13
2022-10-08 09:21:01,437 [foster.py] => Task 1, Epoch 14/34 => Loss 2.119, Loss_clf 0.715, Loss_fe 0.853, Loss_kd 0.322, Train_accy 42.08
2022-10-08 09:21:04,210 [foster.py] => Task 1, Epoch 15/34 => Loss 2.038, Loss_clf 0.688, Loss_fe 0.807, Loss_kd 0.316, Train_accy 42.86
2022-10-08 09:21:07,813 [foster.py] => Task 1, Epoch 16/34 => Loss 2.072, Loss_clf 0.695, Loss_fe 0.824, Loss_kd 0.323, Train_accy 43.46, Test_accy 61.29
2022-10-08 09:21:10,445 [foster.py] => Task 1, Epoch 17/34 => Loss 2.036, Loss_clf 0.699, Loss_fe 0.799, Loss_kd 0.314, Train_accy 42.60
2022-10-08 09:21:13,346 [foster.py] => Task 1, Epoch 18/34 => Loss 2.000, Loss_clf 0.675, Loss_fe 0.778, Loss_kd 0.319, Train_accy 44.33
2022-10-08 09:21:16,239 [foster.py] => Task 1, Epoch 19/34 => Loss 2.016, Loss_clf 0.690, Loss_fe 0.791, Loss_kd 0.312, Train_accy 44.42
2022-10-08 09:21:19,146 [foster.py] => Task 1, Epoch 20/34 => Loss 2.019, Loss_clf 0.675, Loss_fe 0.795, Loss_kd 0.320, Train_accy 46.49
2022-10-08 09:21:22,885 [foster.py] => Task 1, Epoch 21/34 => Loss 1.932, Loss_clf 0.626, Loss_fe 0.756, Loss_kd 0.321, Train_accy 48.05, Test_accy 62.01
2022-10-08 09:21:25,785 [foster.py] => Task 1, Epoch 22/34 => Loss 1.955, Loss_clf 0.667, Loss_fe 0.758, Loss_kd 0.309, Train_accy 44.33
2022-10-08 09:21:28,735 [foster.py] => Task 1, Epoch 23/34 => Loss 1.997, Loss_clf 0.669, Loss_fe 0.780, Loss_kd 0.320, Train_accy 45.19
2022-10-08 09:21:31,655 [foster.py] => Task 1, Epoch 24/34 => Loss 1.888, Loss_clf 0.614, Loss_fe 0.727, Loss_kd 0.319, Train_accy 46.32
2022-10-08 09:21:34,409 [foster.py] => Task 1, Epoch 25/34 => Loss 1.879, Loss_clf 0.605, Loss_fe 0.719, Loss_kd 0.324, Train_accy 47.71
2022-10-08 09:21:37,940 [foster.py] => Task 1, Epoch 26/34 => Loss 1.863, Loss_clf 0.607, Loss_fe 0.709, Loss_kd 0.319, Train_accy 47.53, Test_accy 61.65
2022-10-08 09:21:40,527 [foster.py] => Task 1, Epoch 27/34 => Loss 1.932, Loss_clf 0.621, Loss_fe 0.754, Loss_kd 0.324, Train_accy 46.58
2022-10-08 09:21:43,411 [foster.py] => Task 1, Epoch 28/34 => Loss 1.875, Loss_clf 0.595, Loss_fe 0.721, Loss_kd 0.326, Train_accy 45.97
2022-10-08 09:21:46,244 [foster.py] => Task 1, Epoch 29/34 => Loss 1.883, Loss_clf 0.599, Loss_fe 0.739, Loss_kd 0.318, Train_accy 47.19
2022-10-08 09:21:49,141 [foster.py] => Task 1, Epoch 30/34 => Loss 1.855, Loss_clf 0.604, Loss_fe 0.699, Loss_kd 0.322, Train_accy 46.23
2022-10-08 09:21:52,676 [foster.py] => Task 1, Epoch 31/34 => Loss 1.864, Loss_clf 0.597, Loss_fe 0.702, Loss_kd 0.329, Train_accy 46.06, Test_accy 61.65
2022-10-08 09:21:55,342 [foster.py] => Task 1, Epoch 32/34 => Loss 1.878, Loss_clf 0.608, Loss_fe 0.715, Loss_kd 0.324, Train_accy 47.71
2022-10-08 09:21:58,183 [foster.py] => Task 1, Epoch 33/34 => Loss 1.914, Loss_clf 0.622, Loss_fe 0.744, Loss_kd 0.320, Train_accy 46.75
2022-10-08 09:22:01,140 [foster.py] => Task 1, Epoch 34/34 => Loss 1.915, Loss_clf 0.628, Loss_fe 0.731, Loss_kd 0.324, Train_accy 47.71
2022-10-08 09:22:01,141 [foster.py] => do not weight align teacher!
2022-10-08 09:22:01,142 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 09:22:06,260 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.912,  Train_accy 11.00, Test_accy 44.09
2022-10-08 09:22:10,027 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.678,  Train_accy 12.03
2022-10-08 09:22:13,804 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.627,  Train_accy 12.64
2022-10-08 09:22:17,208 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.562,  Train_accy 13.07
2022-10-08 09:22:20,647 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.590,  Train_accy 14.20
2022-10-08 09:22:24,797 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.538,  Train_accy 13.07, Test_accy 45.16
2022-10-08 09:22:27,846 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.518,  Train_accy 14.20
2022-10-08 09:22:36,108 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.504,  Train_accy 14.72
2022-10-08 09:22:40,387 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.509,  Train_accy 14.55
2022-10-08 09:22:43,851 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.497,  Train_accy 14.72
2022-10-08 09:22:48,023 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.500,  Train_accy 14.46, Test_accy 46.24
2022-10-08 09:22:50,890 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.494,  Train_accy 14.98
2022-10-08 09:22:53,755 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.490,  Train_accy 14.72
2022-10-08 09:22:56,799 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.485,  Train_accy 16.28
2022-10-08 09:23:00,153 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.494,  Train_accy 15.32
2022-10-08 09:23:04,252 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.496,  Train_accy 15.93, Test_accy 47.31
2022-10-08 09:23:07,322 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.479,  Train_accy 16.36
2022-10-08 09:23:10,981 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.480,  Train_accy 15.93
2022-10-08 09:23:14,346 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.457,  Train_accy 16.45
2022-10-08 09:23:17,722 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.476,  Train_accy 16.80
2022-10-08 09:23:21,532 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.476,  Train_accy 16.80, Test_accy 48.03
2022-10-08 09:23:24,551 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.465,  Train_accy 16.10
2022-10-08 09:23:27,825 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.489,  Train_accy 17.06
2022-10-08 09:23:31,135 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.481,  Train_accy 16.28
2022-10-08 09:23:34,394 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.475,  Train_accy 16.80
2022-10-08 09:23:38,351 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.495,  Train_accy 16.62, Test_accy 48.03
2022-10-08 09:23:38,351 [foster.py] => do not weight align student!
2022-10-08 09:23:39,028 [foster.py] => darknet eval: 
2022-10-08 09:23:39,028 [foster.py] => CNN top1 curve: 48.03
2022-10-08 09:23:39,028 [foster.py] => CNN top5 curve: 95.7
2022-10-08 09:23:39,029 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 09:23:46,798 [foster.py] => Exemplar size: 240
2022-10-08 09:23:46,798 [trainer.py] => CNN: {'total': 60.93, 'old': 85.14, 'new': 33.59, 'base': 85.14, 'compound': 33.59}
2022-10-08 09:23:46,798 [trainer.py] => CNN top1 curve: [88.51, 60.93]
2022-10-08 09:23:46,798 [trainer.py] => CNN base curve: [88.51, 85.14]
2022-10-08 09:23:46,798 [trainer.py] => CNN old curve: [88.51, 85.14]
2022-10-08 09:23:46,798 [trainer.py] => CNN new curve: [0, 33.59]
2022-10-08 09:23:46,798 [trainer.py] => CNN compound curve: [0, 33.59]
2022-10-08 09:23:46,798 [trainer.py] => NME: {'total': 62.37, 'old': 79.05, 'new': 43.51, 'base': 79.05, 'compound': 43.51}
2022-10-08 09:23:46,798 [trainer.py] => NME top1 curve: [89.19, 62.37]
2022-10-08 09:23:46,798 [trainer.py] => NME base curve: [89.19, 79.05]
2022-10-08 09:23:46,798 [trainer.py] => NME old curve: [89.19, 79.05]
2022-10-08 09:23:46,798 [trainer.py] => NME new curve: [0, 43.51]
2022-10-08 09:23:46,798 [trainer.py] => NME compound curve: [0, 43.51]
2022-10-08 09:23:47,029 [foster.py] => Learning on 12-17
2022-10-08 09:23:47,029 [foster.py] => All params: 22385326
2022-10-08 09:23:47,029 [foster.py] => Trainable params: 11202658
2022-10-08 09:23:47,038 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 09:23:50,442 [foster.py] => Task 2, Epoch 1/34 => Loss 5.735, Loss_clf 2.037, Loss_fe 2.232, Loss_kd 1.035, Train_accy 41.71, Test_accy 43.01
2022-10-08 09:23:53,014 [foster.py] => Task 2, Epoch 2/34 => Loss 3.711, Loss_clf 0.863, Loss_fe 1.440, Loss_kd 0.993, Train_accy 42.25
2022-10-08 09:23:55,695 [foster.py] => Task 2, Epoch 3/34 => Loss 3.408, Loss_clf 0.762, Loss_fe 1.232, Loss_kd 0.998, Train_accy 39.83
2022-10-08 09:23:58,364 [foster.py] => Task 2, Epoch 4/34 => Loss 3.255, Loss_clf 0.722, Loss_fe 1.115, Loss_kd 1.001, Train_accy 41.00
2022-10-08 09:24:01,404 [foster.py] => Task 2, Epoch 5/34 => Loss 3.123, Loss_clf 0.677, Loss_fe 1.032, Loss_kd 0.999, Train_accy 38.50
2022-10-08 09:24:05,359 [foster.py] => Task 2, Epoch 6/34 => Loss 3.028, Loss_clf 0.648, Loss_fe 0.958, Loss_kd 1.003, Train_accy 41.31, Test_accy 42.75
2022-10-08 09:24:08,108 [foster.py] => Task 2, Epoch 7/34 => Loss 2.943, Loss_clf 0.622, Loss_fe 0.909, Loss_kd 0.996, Train_accy 41.86
2022-10-08 09:24:10,977 [foster.py] => Task 2, Epoch 8/34 => Loss 2.915, Loss_clf 0.626, Loss_fe 0.871, Loss_kd 1.000, Train_accy 40.69
2022-10-08 09:24:14,178 [foster.py] => Task 2, Epoch 9/34 => Loss 2.857, Loss_clf 0.612, Loss_fe 0.826, Loss_kd 1.002, Train_accy 42.49
2022-10-08 09:24:17,433 [foster.py] => Task 2, Epoch 10/34 => Loss 2.805, Loss_clf 0.592, Loss_fe 0.794, Loss_kd 1.002, Train_accy 42.33
2022-10-08 09:24:21,545 [foster.py] => Task 2, Epoch 11/34 => Loss 2.768, Loss_clf 0.581, Loss_fe 0.768, Loss_kd 1.002, Train_accy 42.80, Test_accy 44.56
2022-10-08 09:24:24,707 [foster.py] => Task 2, Epoch 12/34 => Loss 2.757, Loss_clf 0.582, Loss_fe 0.753, Loss_kd 1.004, Train_accy 41.55
2022-10-08 09:24:27,848 [foster.py] => Task 2, Epoch 13/34 => Loss 2.716, Loss_clf 0.567, Loss_fe 0.726, Loss_kd 1.005, Train_accy 41.47
2022-10-08 09:24:31,061 [foster.py] => Task 2, Epoch 14/34 => Loss 2.713, Loss_clf 0.571, Loss_fe 0.723, Loss_kd 1.002, Train_accy 44.05
2022-10-08 09:24:34,284 [foster.py] => Task 2, Epoch 15/34 => Loss 2.664, Loss_clf 0.554, Loss_fe 0.698, Loss_kd 0.996, Train_accy 42.10
2022-10-08 09:24:38,121 [foster.py] => Task 2, Epoch 16/34 => Loss 2.649, Loss_clf 0.543, Loss_fe 0.682, Loss_kd 1.006, Train_accy 43.66, Test_accy 43.01
2022-10-08 09:24:40,967 [foster.py] => Task 2, Epoch 17/34 => Loss 2.639, Loss_clf 0.538, Loss_fe 0.679, Loss_kd 1.004, Train_accy 44.84
2022-10-08 09:24:44,012 [foster.py] => Task 2, Epoch 18/34 => Loss 2.592, Loss_clf 0.520, Loss_fe 0.644, Loss_kd 1.007, Train_accy 45.07
2022-10-08 09:24:47,048 [foster.py] => Task 2, Epoch 19/34 => Loss 2.575, Loss_clf 0.521, Loss_fe 0.630, Loss_kd 1.005, Train_accy 44.29
2022-10-08 09:24:50,130 [foster.py] => Task 2, Epoch 20/34 => Loss 2.574, Loss_clf 0.521, Loss_fe 0.636, Loss_kd 1.001, Train_accy 44.05
2022-10-08 09:24:54,137 [foster.py] => Task 2, Epoch 21/34 => Loss 2.543, Loss_clf 0.504, Loss_fe 0.616, Loss_kd 1.005, Train_accy 46.17, Test_accy 44.04
2022-10-08 09:24:57,019 [foster.py] => Task 2, Epoch 22/34 => Loss 2.572, Loss_clf 0.519, Loss_fe 0.627, Loss_kd 1.006, Train_accy 44.21
2022-10-08 09:24:59,975 [foster.py] => Task 2, Epoch 23/34 => Loss 2.550, Loss_clf 0.505, Loss_fe 0.620, Loss_kd 1.007, Train_accy 44.99
2022-10-08 09:25:02,844 [foster.py] => Task 2, Epoch 24/34 => Loss 2.530, Loss_clf 0.500, Loss_fe 0.616, Loss_kd 0.998, Train_accy 45.31
2022-10-08 09:25:05,781 [foster.py] => Task 2, Epoch 25/34 => Loss 2.545, Loss_clf 0.512, Loss_fe 0.613, Loss_kd 1.003, Train_accy 46.01
2022-10-08 09:25:14,859 [foster.py] => Task 2, Epoch 26/34 => Loss 2.523, Loss_clf 0.496, Loss_fe 0.596, Loss_kd 1.011, Train_accy 46.40, Test_accy 44.04
2022-10-08 09:25:17,766 [foster.py] => Task 2, Epoch 27/34 => Loss 2.476, Loss_clf 0.479, Loss_fe 0.580, Loss_kd 1.000, Train_accy 45.07
2022-10-08 09:25:20,534 [foster.py] => Task 2, Epoch 28/34 => Loss 2.523, Loss_clf 0.498, Loss_fe 0.598, Loss_kd 1.008, Train_accy 46.48
2022-10-08 09:25:23,330 [foster.py] => Task 2, Epoch 29/34 => Loss 2.522, Loss_clf 0.501, Loss_fe 0.607, Loss_kd 0.999, Train_accy 44.60
2022-10-08 09:25:26,149 [foster.py] => Task 2, Epoch 30/34 => Loss 2.483, Loss_clf 0.481, Loss_fe 0.584, Loss_kd 1.001, Train_accy 46.95
2022-10-08 09:25:29,885 [foster.py] => Task 2, Epoch 31/34 => Loss 2.515, Loss_clf 0.493, Loss_fe 0.594, Loss_kd 1.008, Train_accy 47.65, Test_accy 44.82
2022-10-08 09:25:32,747 [foster.py] => Task 2, Epoch 32/34 => Loss 2.503, Loss_clf 0.491, Loss_fe 0.592, Loss_kd 1.002, Train_accy 44.91
2022-10-08 09:25:35,564 [foster.py] => Task 2, Epoch 33/34 => Loss 2.490, Loss_clf 0.483, Loss_fe 0.593, Loss_kd 0.998, Train_accy 45.46
2022-10-08 09:25:38,496 [foster.py] => Task 2, Epoch 34/34 => Loss 2.501, Loss_clf 0.491, Loss_fe 0.594, Loss_kd 1.000, Train_accy 45.15
2022-10-08 09:25:38,497 [foster.py] => do not weight align teacher!
2022-10-08 09:25:38,497 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 09:25:42,929 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.152,  Train_accy 10.95, Test_accy 34.20
2022-10-08 09:25:46,206 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 2.025,  Train_accy 10.88
2022-10-08 09:25:49,605 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.979,  Train_accy 11.11
2022-10-08 09:25:53,079 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.975,  Train_accy 11.03
2022-10-08 09:25:56,722 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.945,  Train_accy 11.74
2022-10-08 09:26:01,298 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.934,  Train_accy 11.97, Test_accy 34.97
2022-10-08 09:26:04,860 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.927,  Train_accy 11.58
2022-10-08 09:26:08,390 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.913,  Train_accy 12.36
2022-10-08 09:26:11,915 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.892,  Train_accy 12.28
2022-10-08 09:26:15,497 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.897,  Train_accy 12.60
2022-10-08 09:26:19,798 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.890,  Train_accy 13.30, Test_accy 35.75
2022-10-08 09:26:23,147 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.898,  Train_accy 12.83
2022-10-08 09:26:26,639 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.884,  Train_accy 13.30
2022-10-08 09:26:30,133 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.872,  Train_accy 13.54
2022-10-08 09:26:33,623 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.887,  Train_accy 13.54
2022-10-08 09:26:37,819 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.882,  Train_accy 14.48, Test_accy 35.49
2022-10-08 09:26:41,081 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.879,  Train_accy 15.34
2022-10-08 09:26:44,690 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.876,  Train_accy 14.16
2022-10-08 09:26:48,323 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.870,  Train_accy 14.16
2022-10-08 09:26:51,895 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.876,  Train_accy 14.63
2022-10-08 09:26:56,254 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.868,  Train_accy 14.48, Test_accy 37.31
2022-10-08 09:26:59,599 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.868,  Train_accy 14.79
2022-10-08 09:27:03,110 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.870,  Train_accy 15.02
2022-10-08 09:27:06,662 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.867,  Train_accy 14.48
2022-10-08 09:27:10,232 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.855,  Train_accy 14.32
2022-10-08 09:27:14,570 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.867,  Train_accy 14.71, Test_accy 36.27
2022-10-08 09:27:14,570 [foster.py] => do not weight align student!
2022-10-08 09:27:15,325 [foster.py] => darknet eval: 
2022-10-08 09:27:15,325 [foster.py] => CNN top1 curve: 36.27
2022-10-08 09:27:15,325 [foster.py] => CNN top5 curve: 93.78
2022-10-08 09:27:15,325 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 09:27:24,810 [foster.py] => Exemplar size: 340
2022-10-08 09:27:24,810 [trainer.py] => CNN: {'total': 44.56, 'old': 46.95, 'new': 38.32, 'base': 76.35, 'compound': 24.79}
2022-10-08 09:27:24,810 [trainer.py] => CNN top1 curve: [88.51, 60.93, 44.56]
2022-10-08 09:27:24,810 [trainer.py] => CNN base curve: [88.51, 85.14, 76.35]
2022-10-08 09:27:24,810 [trainer.py] => CNN old curve: [88.51, 85.14, 46.95]
2022-10-08 09:27:24,810 [trainer.py] => CNN new curve: [0, 33.59, 38.32]
2022-10-08 09:27:24,810 [trainer.py] => CNN compound curve: [0, 33.59, 24.79]
2022-10-08 09:27:24,810 [trainer.py] => NME: {'total': 55.18, 'old': 51.25, 'new': 65.42, 'base': 65.54, 'compound': 48.74}
2022-10-08 09:27:24,810 [trainer.py] => NME top1 curve: [89.19, 62.37, 55.18]
2022-10-08 09:27:24,810 [trainer.py] => NME base curve: [89.19, 79.05, 65.54]
2022-10-08 09:27:24,810 [trainer.py] => NME old curve: [89.19, 79.05, 51.25]
2022-10-08 09:27:24,810 [trainer.py] => NME new curve: [0, 43.51, 65.42]
2022-10-08 09:27:24,810 [trainer.py] => NME compound curve: [0, 43.51, 48.74]
2022-10-08 09:27:25,035 [foster.py] => Learning on 17-22
2022-10-08 09:27:25,036 [foster.py] => All params: 22395581
2022-10-08 09:27:25,036 [foster.py] => Trainable params: 11210348
2022-10-08 09:27:25,045 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 09:27:28,784 [foster.py] => Task 3, Epoch 1/34 => Loss 6.745, Loss_clf 2.086, Loss_fe 2.616, Loss_kd 1.579, Train_accy 33.09, Test_accy 29.70
2022-10-08 09:27:31,524 [foster.py] => Task 3, Epoch 2/34 => Loss 4.997, Loss_clf 1.189, Loss_fe 1.781, Loss_kd 1.567, Train_accy 38.13
2022-10-08 09:27:34,298 [foster.py] => Task 3, Epoch 3/34 => Loss 4.658, Loss_clf 1.084, Loss_fe 1.553, Loss_kd 1.562, Train_accy 39.74
2022-10-08 09:27:40,669 [foster.py] => Task 3, Epoch 4/34 => Loss 4.458, Loss_clf 1.023, Loss_fe 1.414, Loss_kd 1.562, Train_accy 41.34
2022-10-08 09:27:44,322 [foster.py] => Task 3, Epoch 5/34 => Loss 4.370, Loss_clf 1.008, Loss_fe 1.334, Loss_kd 1.568, Train_accy 42.22
2022-10-08 09:27:48,473 [foster.py] => Task 3, Epoch 6/34 => Loss 4.254, Loss_clf 0.972, Loss_fe 1.251, Loss_kd 1.570, Train_accy 41.71, Test_accy 39.80
2022-10-08 09:27:51,477 [foster.py] => Task 3, Epoch 7/34 => Loss 4.176, Loss_clf 0.951, Loss_fe 1.202, Loss_kd 1.564, Train_accy 43.90
2022-10-08 09:27:54,404 [foster.py] => Task 3, Epoch 8/34 => Loss 4.069, Loss_clf 0.914, Loss_fe 1.135, Loss_kd 1.561, Train_accy 40.83
2022-10-08 09:27:57,267 [foster.py] => Task 3, Epoch 9/34 => Loss 3.991, Loss_clf 0.881, Loss_fe 1.081, Loss_kd 1.568, Train_accy 44.85
2022-10-08 09:28:00,183 [foster.py] => Task 3, Epoch 10/34 => Loss 3.986, Loss_clf 0.896, Loss_fe 1.059, Loss_kd 1.570, Train_accy 44.12
2022-10-08 09:28:04,489 [foster.py] => Task 3, Epoch 11/34 => Loss 3.915, Loss_clf 0.869, Loss_fe 1.023, Loss_kd 1.564, Train_accy 43.17, Test_accy 40.99
2022-10-08 09:28:07,568 [foster.py] => Task 3, Epoch 12/34 => Loss 3.865, Loss_clf 0.848, Loss_fe 0.997, Loss_kd 1.560, Train_accy 44.27
2022-10-08 09:28:10,593 [foster.py] => Task 3, Epoch 13/34 => Loss 3.854, Loss_clf 0.842, Loss_fe 0.969, Loss_kd 1.579, Train_accy 43.39
2022-10-08 09:28:13,816 [foster.py] => Task 3, Epoch 14/34 => Loss 3.801, Loss_clf 0.837, Loss_fe 0.944, Loss_kd 1.561, Train_accy 44.56
2022-10-08 09:28:16,979 [foster.py] => Task 3, Epoch 15/34 => Loss 3.767, Loss_clf 0.817, Loss_fe 0.926, Loss_kd 1.564, Train_accy 45.51
2022-10-08 09:28:21,159 [foster.py] => Task 3, Epoch 16/34 => Loss 3.765, Loss_clf 0.811, Loss_fe 0.913, Loss_kd 1.577, Train_accy 45.80, Test_accy 41.98
2022-10-08 09:28:24,125 [foster.py] => Task 3, Epoch 17/34 => Loss 3.707, Loss_clf 0.788, Loss_fe 0.892, Loss_kd 1.566, Train_accy 46.02
2022-10-08 09:28:27,111 [foster.py] => Task 3, Epoch 18/34 => Loss 3.706, Loss_clf 0.789, Loss_fe 0.886, Loss_kd 1.570, Train_accy 46.31
2022-10-08 09:28:30,110 [foster.py] => Task 3, Epoch 19/34 => Loss 3.693, Loss_clf 0.781, Loss_fe 0.884, Loss_kd 1.567, Train_accy 45.65
2022-10-08 09:28:33,471 [foster.py] => Task 3, Epoch 20/34 => Loss 3.659, Loss_clf 0.768, Loss_fe 0.861, Loss_kd 1.568, Train_accy 45.80
2022-10-08 09:28:37,876 [foster.py] => Task 3, Epoch 21/34 => Loss 3.612, Loss_clf 0.743, Loss_fe 0.836, Loss_kd 1.571, Train_accy 47.55, Test_accy 41.19
2022-10-08 09:28:41,049 [foster.py] => Task 3, Epoch 22/34 => Loss 3.626, Loss_clf 0.762, Loss_fe 0.840, Loss_kd 1.564, Train_accy 46.82
2022-10-08 09:28:43,997 [foster.py] => Task 3, Epoch 23/34 => Loss 3.609, Loss_clf 0.756, Loss_fe 0.829, Loss_kd 1.564, Train_accy 47.33
2022-10-08 09:28:47,014 [foster.py] => Task 3, Epoch 24/34 => Loss 3.618, Loss_clf 0.749, Loss_fe 0.837, Loss_kd 1.570, Train_accy 46.09
2022-10-08 09:28:50,614 [foster.py] => Task 3, Epoch 25/34 => Loss 3.564, Loss_clf 0.724, Loss_fe 0.802, Loss_kd 1.575, Train_accy 48.94
2022-10-08 09:28:55,209 [foster.py] => Task 3, Epoch 26/34 => Loss 3.591, Loss_clf 0.735, Loss_fe 0.822, Loss_kd 1.571, Train_accy 47.48, Test_accy 41.98
2022-10-08 09:28:58,449 [foster.py] => Task 3, Epoch 27/34 => Loss 3.611, Loss_clf 0.748, Loss_fe 0.830, Loss_kd 1.571, Train_accy 47.92
2022-10-08 09:29:01,476 [foster.py] => Task 3, Epoch 28/34 => Loss 3.575, Loss_clf 0.737, Loss_fe 0.809, Loss_kd 1.568, Train_accy 46.60
2022-10-08 09:29:04,544 [foster.py] => Task 3, Epoch 29/34 => Loss 3.557, Loss_clf 0.723, Loss_fe 0.798, Loss_kd 1.573, Train_accy 48.65
2022-10-08 09:29:07,534 [foster.py] => Task 3, Epoch 30/34 => Loss 3.562, Loss_clf 0.729, Loss_fe 0.807, Loss_kd 1.566, Train_accy 48.28
2022-10-08 09:29:11,541 [foster.py] => Task 3, Epoch 31/34 => Loss 3.555, Loss_clf 0.718, Loss_fe 0.803, Loss_kd 1.572, Train_accy 49.01, Test_accy 42.18
2022-10-08 09:29:14,458 [foster.py] => Task 3, Epoch 32/34 => Loss 3.555, Loss_clf 0.719, Loss_fe 0.807, Loss_kd 1.568, Train_accy 48.36
2022-10-08 09:29:21,424 [foster.py] => Task 3, Epoch 33/34 => Loss 3.559, Loss_clf 0.728, Loss_fe 0.804, Loss_kd 1.566, Train_accy 48.43
2022-10-08 09:29:24,868 [foster.py] => Task 3, Epoch 34/34 => Loss 3.568, Loss_clf 0.724, Loss_fe 0.807, Loss_kd 1.574, Train_accy 47.55
2022-10-08 09:29:24,868 [foster.py] => do not weight align teacher!
2022-10-08 09:29:24,869 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 09:29:29,284 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.500,  Train_accy 11.69, Test_accy 27.92
2022-10-08 09:29:32,407 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.452,  Train_accy 11.76
2022-10-08 09:29:35,695 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.443,  Train_accy 12.05
2022-10-08 09:29:39,227 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.421,  Train_accy 11.47
2022-10-08 09:29:42,897 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.407,  Train_accy 11.98
2022-10-08 09:29:47,378 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.401,  Train_accy 12.13, Test_accy 29.90
2022-10-08 09:29:50,827 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.397,  Train_accy 12.05
2022-10-08 09:29:54,341 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.384,  Train_accy 13.00
2022-10-08 09:29:58,070 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.387,  Train_accy 13.00
2022-10-08 09:30:01,821 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.376,  Train_accy 13.73
2022-10-08 09:30:06,406 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.375,  Train_accy 13.29, Test_accy 30.69
2022-10-08 09:30:09,795 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.371,  Train_accy 13.81
2022-10-08 09:30:13,413 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.367,  Train_accy 14.10
2022-10-08 09:30:17,017 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.368,  Train_accy 14.61
2022-10-08 09:30:20,466 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.373,  Train_accy 14.32
2022-10-08 09:30:25,250 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.366,  Train_accy 13.95, Test_accy 32.67
2022-10-08 09:30:32,375 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.358,  Train_accy 14.76
2022-10-08 09:30:36,510 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.357,  Train_accy 14.97
2022-10-08 09:30:40,545 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.362,  Train_accy 14.39
2022-10-08 09:30:44,346 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.356,  Train_accy 14.90
2022-10-08 09:30:48,478 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.360,  Train_accy 15.78, Test_accy 32.48
2022-10-08 09:30:51,685 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.364,  Train_accy 15.12
2022-10-08 09:30:59,428 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.357,  Train_accy 15.05
2022-10-08 09:31:03,572 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.357,  Train_accy 15.63
2022-10-08 09:31:06,911 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.361,  Train_accy 15.56
2022-10-08 09:31:10,900 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.359,  Train_accy 15.56, Test_accy 32.67
2022-10-08 09:31:10,900 [foster.py] => do not weight align student!
2022-10-08 09:31:11,734 [foster.py] => darknet eval: 
2022-10-08 09:31:11,734 [foster.py] => CNN top1 curve: 32.67
2022-10-08 09:31:11,734 [foster.py] => CNN top5 curve: 82.18
2022-10-08 09:31:11,735 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 09:31:22,817 [foster.py] => Exemplar size: 440
2022-10-08 09:31:22,817 [trainer.py] => CNN: {'total': 42.18, 'old': 45.34, 'new': 31.93, 'base': 75.68, 'compound': 28.29}
2022-10-08 09:31:22,817 [trainer.py] => CNN top1 curve: [88.51, 60.93, 44.56, 42.18]
2022-10-08 09:31:22,817 [trainer.py] => CNN base curve: [88.51, 85.14, 76.35, 75.68]
2022-10-08 09:31:22,817 [trainer.py] => CNN old curve: [88.51, 85.14, 46.95, 45.34]
2022-10-08 09:31:22,817 [trainer.py] => CNN new curve: [0, 33.59, 38.32, 31.93]
2022-10-08 09:31:22,817 [trainer.py] => CNN compound curve: [0, 33.59, 24.79, 28.29]
2022-10-08 09:31:22,817 [trainer.py] => NME: {'total': 48.32, 'old': 49.74, 'new': 43.7, 'base': 61.49, 'compound': 42.86}
2022-10-08 09:31:22,817 [trainer.py] => NME top1 curve: [89.19, 62.37, 55.18, 48.32]
2022-10-08 09:31:22,817 [trainer.py] => NME base curve: [89.19, 79.05, 65.54, 61.49]
2022-10-08 09:31:22,817 [trainer.py] => NME old curve: [89.19, 79.05, 51.25, 49.74]
2022-10-08 09:31:22,817 [trainer.py] => NME new curve: [0, 43.51, 65.42, 43.7]
2022-10-08 09:31:22,817 [trainer.py] => NME compound curve: [0, 43.51, 48.74, 42.86]
2022-10-08 09:31:22,819 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 09:31:22,819 [trainer.py] => prefix: cil
2022-10-08 09:31:22,820 [trainer.py] => dataset: CFEE
2022-10-08 09:31:22,820 [trainer.py] => memory_size: 2000
2022-10-08 09:31:22,820 [trainer.py] => memory_per_class: 20
2022-10-08 09:31:22,820 [trainer.py] => fixed_memory: True
2022-10-08 09:31:22,820 [trainer.py] => shuffle: True
2022-10-08 09:31:22,820 [trainer.py] => init_cls: 7
2022-10-08 09:31:22,820 [trainer.py] => increment: 5
2022-10-08 09:31:22,820 [trainer.py] => model_name: foster
2022-10-08 09:31:22,820 [trainer.py] => convnet_type: resnet18
2022-10-08 09:31:22,820 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 09:31:22,820 [trainer.py] => seed: 1993
2022-10-08 09:31:22,820 [trainer.py] => beta1: 0.96
2022-10-08 09:31:22,820 [trainer.py] => beta2: 0.97
2022-10-08 09:31:22,820 [trainer.py] => oofc: ft
2022-10-08 09:31:22,820 [trainer.py] => is_teacher_wa: False
2022-10-08 09:31:22,820 [trainer.py] => is_student_wa: False
2022-10-08 09:31:22,820 [trainer.py] => lambda_okd: 1
2022-10-08 09:31:22,820 [trainer.py] => wa_value: 1
2022-10-08 09:31:22,820 [trainer.py] => init_epochs: 40
2022-10-08 09:31:22,820 [trainer.py] => init_lr: 0.01
2022-10-08 09:31:22,821 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 09:31:22,821 [trainer.py] => boosting_epochs: 34
2022-10-08 09:31:22,821 [trainer.py] => compression_epochs: 26
2022-10-08 09:31:22,821 [trainer.py] => lr: 0.001
2022-10-08 09:31:22,821 [trainer.py] => batch_size: 32
2022-10-08 09:31:22,821 [trainer.py] => weight_decay: 0.0005
2022-10-08 09:31:22,821 [trainer.py] => num_workers: 8
2022-10-08 09:31:22,821 [trainer.py] => T: 2
2022-10-08 09:31:22,821 [trainer.py] => nb_runs: 3
2022-10-08 09:31:22,821 [trainer.py] => fold: 10
2022-10-08 09:31:22,821 [data.py] => ========== Fold:2 ==========
2022-10-08 09:31:22,829 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 12, 10, 19, 21, 17, 18, 8, 7, 9, 14, 15, 13, 11, 16]
2022-10-08 09:31:23,056 [foster.py] => Learning on 0-7
2022-10-08 09:31:23,056 [foster.py] => All params: 11183694
2022-10-08 09:31:23,056 [foster.py] => Trainable params: 11183694
2022-10-08 09:31:25,413 [foster.py] => Task 0, Epoch 1/40 => Loss 1.310, Train_accy 52.17
2022-10-08 09:31:28,319 [foster.py] => Task 0, Epoch 2/40 => Loss 0.542, Train_accy 81.16, Test_accy 84.18
2022-10-08 09:31:31,257 [foster.py] => Task 0, Epoch 3/40 => Loss 0.358, Train_accy 87.44, Test_accy 81.65
2022-10-08 09:31:34,176 [foster.py] => Task 0, Epoch 4/40 => Loss 0.275, Train_accy 90.75, Test_accy 83.54
2022-10-08 09:31:37,152 [foster.py] => Task 0, Epoch 5/40 => Loss 0.250, Train_accy 91.44, Test_accy 82.91
2022-10-08 09:31:39,521 [foster.py] => Task 0, Epoch 6/40 => Loss 0.178, Train_accy 93.79
2022-10-08 09:31:42,545 [foster.py] => Task 0, Epoch 7/40 => Loss 0.155, Train_accy 94.48, Test_accy 85.44
2022-10-08 09:31:45,527 [foster.py] => Task 0, Epoch 8/40 => Loss 0.133, Train_accy 95.58, Test_accy 84.18
2022-10-08 09:31:48,489 [foster.py] => Task 0, Epoch 9/40 => Loss 0.095, Train_accy 96.83, Test_accy 86.71
2022-10-08 09:31:51,484 [foster.py] => Task 0, Epoch 10/40 => Loss 0.087, Train_accy 97.45, Test_accy 87.34
2022-10-08 09:31:53,850 [foster.py] => Task 0, Epoch 11/40 => Loss 0.082, Train_accy 97.52
2022-10-08 09:31:56,848 [foster.py] => Task 0, Epoch 12/40 => Loss 0.077, Train_accy 97.31, Test_accy 85.44
2022-10-08 09:31:59,811 [foster.py] => Task 0, Epoch 13/40 => Loss 0.061, Train_accy 98.00, Test_accy 86.08
2022-10-08 09:32:02,725 [foster.py] => Task 0, Epoch 14/40 => Loss 0.055, Train_accy 98.27, Test_accy 82.91
2022-10-08 09:32:05,674 [foster.py] => Task 0, Epoch 15/40 => Loss 0.042, Train_accy 98.55, Test_accy 84.81
2022-10-08 09:32:08,101 [foster.py] => Task 0, Epoch 16/40 => Loss 0.050, Train_accy 98.21
2022-10-08 09:32:12,352 [foster.py] => Task 0, Epoch 17/40 => Loss 0.048, Train_accy 98.48, Test_accy 84.81
2022-10-08 09:32:15,482 [foster.py] => Task 0, Epoch 18/40 => Loss 0.032, Train_accy 99.31, Test_accy 84.81
2022-10-08 09:32:18,406 [foster.py] => Task 0, Epoch 19/40 => Loss 0.029, Train_accy 99.38, Test_accy 84.81
2022-10-08 09:32:21,392 [foster.py] => Task 0, Epoch 20/40 => Loss 0.031, Train_accy 99.03, Test_accy 84.18
2022-10-08 09:32:23,821 [foster.py] => Task 0, Epoch 21/40 => Loss 0.023, Train_accy 99.65
2022-10-08 09:32:26,813 [foster.py] => Task 0, Epoch 22/40 => Loss 0.018, Train_accy 99.93, Test_accy 84.18
2022-10-08 09:32:29,846 [foster.py] => Task 0, Epoch 23/40 => Loss 0.022, Train_accy 99.59, Test_accy 84.81
2022-10-08 09:32:32,811 [foster.py] => Task 0, Epoch 24/40 => Loss 0.025, Train_accy 99.24, Test_accy 84.18
2022-10-08 09:32:35,775 [foster.py] => Task 0, Epoch 25/40 => Loss 0.024, Train_accy 99.52, Test_accy 86.71
2022-10-08 09:32:38,176 [foster.py] => Task 0, Epoch 26/40 => Loss 0.017, Train_accy 99.79
2022-10-08 09:32:41,099 [foster.py] => Task 0, Epoch 27/40 => Loss 0.016, Train_accy 100.00, Test_accy 84.18
2022-10-08 09:32:44,197 [foster.py] => Task 0, Epoch 28/40 => Loss 0.019, Train_accy 99.72, Test_accy 84.18
2022-10-08 09:32:48,902 [foster.py] => Task 0, Epoch 29/40 => Loss 0.016, Train_accy 99.72, Test_accy 83.54
2022-10-08 09:32:52,032 [foster.py] => Task 0, Epoch 30/40 => Loss 0.019, Train_accy 99.59, Test_accy 83.54
2022-10-08 09:32:54,439 [foster.py] => Task 0, Epoch 31/40 => Loss 0.015, Train_accy 99.72
2022-10-08 09:32:57,438 [foster.py] => Task 0, Epoch 32/40 => Loss 0.012, Train_accy 99.86, Test_accy 84.18
2022-10-08 09:33:00,340 [foster.py] => Task 0, Epoch 33/40 => Loss 0.015, Train_accy 99.86, Test_accy 84.18
2022-10-08 09:33:03,514 [foster.py] => Task 0, Epoch 34/40 => Loss 0.021, Train_accy 99.72, Test_accy 83.54
2022-10-08 09:33:09,167 [foster.py] => Task 0, Epoch 35/40 => Loss 0.013, Train_accy 100.00, Test_accy 84.81
2022-10-08 09:33:11,700 [foster.py] => Task 0, Epoch 36/40 => Loss 0.021, Train_accy 99.79
2022-10-08 09:33:14,769 [foster.py] => Task 0, Epoch 37/40 => Loss 0.018, Train_accy 99.86, Test_accy 83.54
2022-10-08 09:33:17,760 [foster.py] => Task 0, Epoch 38/40 => Loss 0.014, Train_accy 99.79, Test_accy 84.81
2022-10-08 09:33:20,687 [foster.py] => Task 0, Epoch 39/40 => Loss 0.014, Train_accy 99.86, Test_accy 84.18
2022-10-08 09:33:23,737 [foster.py] => Task 0, Epoch 40/40 => Loss 0.011, Train_accy 99.93, Test_accy 84.18
2022-10-08 09:33:23,737 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 09:33:30,202 [foster.py] => Exemplar size: 140
2022-10-08 09:33:30,202 [trainer.py] => CNN: {'total': 84.18, 'old': 84.18, 'new': 0, 'base': 84.18, 'compound': 0}
2022-10-08 09:33:30,202 [trainer.py] => CNN top1 curve: [84.18]
2022-10-08 09:33:30,202 [trainer.py] => CNN base curve: [84.18]
2022-10-08 09:33:30,202 [trainer.py] => CNN old curve: [84.18]
2022-10-08 09:33:30,202 [trainer.py] => CNN new curve: [0]
2022-10-08 09:33:30,202 [trainer.py] => CNN compound curve: [0]
2022-10-08 09:33:30,202 [trainer.py] => NME: {'total': 84.18, 'old': 84.18, 'new': 0, 'base': 84.18, 'compound': 0}
2022-10-08 09:33:30,202 [trainer.py] => NME top1 curve: [84.18]
2022-10-08 09:33:30,202 [trainer.py] => NME base curve: [84.18]
2022-10-08 09:33:30,202 [trainer.py] => NME old curve: [84.18]
2022-10-08 09:33:30,202 [trainer.py] => NME new curve: [0]
2022-10-08 09:33:30,202 [trainer.py] => NME compound curve: [0]
2022-10-08 09:33:30,427 [foster.py] => Learning on 7-12
2022-10-08 09:33:30,427 [foster.py] => All params: 22375071
2022-10-08 09:33:30,428 [foster.py] => Trainable params: 11194968
2022-10-08 09:33:30,436 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 09:33:33,549 [foster.py] => Task 1, Epoch 1/34 => Loss 5.246, Loss_clf 2.577, Loss_fe 2.032, Loss_kd 0.372, Train_accy 29.41, Test_accy 57.58
2022-10-08 09:33:35,970 [foster.py] => Task 1, Epoch 2/34 => Loss 3.181, Loss_clf 1.084, Loss_fe 1.502, Loss_kd 0.347, Train_accy 46.69
2022-10-08 09:33:38,437 [foster.py] => Task 1, Epoch 3/34 => Loss 2.831, Loss_clf 0.946, Loss_fe 1.321, Loss_kd 0.329, Train_accy 34.32
2022-10-08 09:33:40,824 [foster.py] => Task 1, Epoch 4/34 => Loss 2.672, Loss_clf 0.892, Loss_fe 1.226, Loss_kd 0.324, Train_accy 35.51
2022-10-08 09:33:43,270 [foster.py] => Task 1, Epoch 5/34 => Loss 2.553, Loss_clf 0.864, Loss_fe 1.139, Loss_kd 0.321, Train_accy 33.39
2022-10-08 09:33:46,512 [foster.py] => Task 1, Epoch 6/34 => Loss 2.466, Loss_clf 0.836, Loss_fe 1.071, Loss_kd 0.326, Train_accy 35.93, Test_accy 57.58
2022-10-08 09:33:48,919 [foster.py] => Task 1, Epoch 7/34 => Loss 2.367, Loss_clf 0.793, Loss_fe 1.020, Loss_kd 0.323, Train_accy 35.68
2022-10-08 09:33:51,342 [foster.py] => Task 1, Epoch 8/34 => Loss 2.306, Loss_clf 0.766, Loss_fe 0.985, Loss_kd 0.323, Train_accy 38.64
2022-10-08 09:33:54,037 [foster.py] => Task 1, Epoch 9/34 => Loss 2.255, Loss_clf 0.761, Loss_fe 0.942, Loss_kd 0.322, Train_accy 38.81
2022-10-08 09:33:56,747 [foster.py] => Task 1, Epoch 10/34 => Loss 2.240, Loss_clf 0.750, Loss_fe 0.930, Loss_kd 0.327, Train_accy 38.90
2022-10-08 09:34:00,114 [foster.py] => Task 1, Epoch 11/34 => Loss 2.221, Loss_clf 0.754, Loss_fe 0.912, Loss_kd 0.324, Train_accy 37.80, Test_accy 57.95
2022-10-08 09:34:02,642 [foster.py] => Task 1, Epoch 12/34 => Loss 2.131, Loss_clf 0.714, Loss_fe 0.871, Loss_kd 0.319, Train_accy 38.05
2022-10-08 09:34:05,153 [foster.py] => Task 1, Epoch 13/34 => Loss 2.109, Loss_clf 0.702, Loss_fe 0.857, Loss_kd 0.320, Train_accy 39.15
2022-10-08 09:34:08,372 [foster.py] => Task 1, Epoch 14/34 => Loss 2.043, Loss_clf 0.670, Loss_fe 0.820, Loss_kd 0.323, Train_accy 40.08
2022-10-08 09:34:11,650 [foster.py] => Task 1, Epoch 15/34 => Loss 2.012, Loss_clf 0.663, Loss_fe 0.803, Loss_kd 0.318, Train_accy 40.93
2022-10-08 09:34:15,380 [foster.py] => Task 1, Epoch 16/34 => Loss 2.000, Loss_clf 0.659, Loss_fe 0.787, Loss_kd 0.323, Train_accy 42.97, Test_accy 56.82
2022-10-08 09:34:18,027 [foster.py] => Task 1, Epoch 17/34 => Loss 1.966, Loss_clf 0.639, Loss_fe 0.776, Loss_kd 0.321, Train_accy 42.20
2022-10-08 09:34:20,631 [foster.py] => Task 1, Epoch 18/34 => Loss 1.947, Loss_clf 0.633, Loss_fe 0.762, Loss_kd 0.322, Train_accy 41.02
2022-10-08 09:34:23,279 [foster.py] => Task 1, Epoch 19/34 => Loss 1.928, Loss_clf 0.629, Loss_fe 0.746, Loss_kd 0.323, Train_accy 44.24
2022-10-08 09:34:25,841 [foster.py] => Task 1, Epoch 20/34 => Loss 1.898, Loss_clf 0.615, Loss_fe 0.734, Loss_kd 0.320, Train_accy 43.64
2022-10-08 09:34:32,091 [foster.py] => Task 1, Epoch 21/34 => Loss 1.863, Loss_clf 0.598, Loss_fe 0.714, Loss_kd 0.321, Train_accy 43.81, Test_accy 58.33
2022-10-08 09:34:34,925 [foster.py] => Task 1, Epoch 22/34 => Loss 1.877, Loss_clf 0.599, Loss_fe 0.719, Loss_kd 0.326, Train_accy 44.15
2022-10-08 09:34:37,619 [foster.py] => Task 1, Epoch 23/34 => Loss 1.823, Loss_clf 0.578, Loss_fe 0.696, Loss_kd 0.320, Train_accy 44.66
2022-10-08 09:34:40,205 [foster.py] => Task 1, Epoch 24/34 => Loss 1.809, Loss_clf 0.568, Loss_fe 0.686, Loss_kd 0.323, Train_accy 46.19
2022-10-08 09:34:42,751 [foster.py] => Task 1, Epoch 25/34 => Loss 1.803, Loss_clf 0.562, Loss_fe 0.689, Loss_kd 0.322, Train_accy 46.10
2022-10-08 09:34:46,100 [foster.py] => Task 1, Epoch 26/34 => Loss 1.814, Loss_clf 0.571, Loss_fe 0.692, Loss_kd 0.321, Train_accy 45.76, Test_accy 58.71
2022-10-08 09:34:48,584 [foster.py] => Task 1, Epoch 27/34 => Loss 1.791, Loss_clf 0.560, Loss_fe 0.681, Loss_kd 0.321, Train_accy 46.10
2022-10-08 09:34:51,121 [foster.py] => Task 1, Epoch 28/34 => Loss 1.818, Loss_clf 0.572, Loss_fe 0.694, Loss_kd 0.322, Train_accy 45.76
2022-10-08 09:34:53,946 [foster.py] => Task 1, Epoch 29/34 => Loss 1.793, Loss_clf 0.558, Loss_fe 0.679, Loss_kd 0.324, Train_accy 45.08
2022-10-08 09:34:56,722 [foster.py] => Task 1, Epoch 30/34 => Loss 1.794, Loss_clf 0.555, Loss_fe 0.691, Loss_kd 0.319, Train_accy 45.51
2022-10-08 09:35:00,311 [foster.py] => Task 1, Epoch 31/34 => Loss 1.818, Loss_clf 0.570, Loss_fe 0.698, Loss_kd 0.321, Train_accy 46.86, Test_accy 58.71
2022-10-08 09:35:02,856 [foster.py] => Task 1, Epoch 32/34 => Loss 1.799, Loss_clf 0.563, Loss_fe 0.683, Loss_kd 0.322, Train_accy 46.44
2022-10-08 09:35:05,436 [foster.py] => Task 1, Epoch 33/34 => Loss 1.821, Loss_clf 0.575, Loss_fe 0.693, Loss_kd 0.323, Train_accy 45.51
2022-10-08 09:35:07,966 [foster.py] => Task 1, Epoch 34/34 => Loss 1.802, Loss_clf 0.560, Loss_fe 0.684, Loss_kd 0.325, Train_accy 46.95
2022-10-08 09:35:07,966 [foster.py] => do not weight align teacher!
2022-10-08 09:35:07,967 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 09:35:11,693 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.941,  Train_accy 11.10, Test_accy 48.86
2022-10-08 09:35:14,726 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.687,  Train_accy 11.53
2022-10-08 09:35:17,859 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.605,  Train_accy 11.86
2022-10-08 09:35:21,059 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.572,  Train_accy 12.63
2022-10-08 09:35:24,292 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.538,  Train_accy 13.05
2022-10-08 09:35:28,195 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.531,  Train_accy 13.64, Test_accy 49.62
2022-10-08 09:35:33,070 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.527,  Train_accy 13.31
2022-10-08 09:35:37,240 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.518,  Train_accy 14.32
2022-10-08 09:35:40,808 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.505,  Train_accy 14.24
2022-10-08 09:35:44,049 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.498,  Train_accy 14.66
2022-10-08 09:35:47,741 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.495,  Train_accy 14.32, Test_accy 50.38
2022-10-08 09:35:50,590 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.483,  Train_accy 14.66
2022-10-08 09:35:53,466 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.471,  Train_accy 15.34
2022-10-08 09:35:56,285 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.473,  Train_accy 14.83
2022-10-08 09:35:59,221 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.485,  Train_accy 14.92
2022-10-08 09:36:02,891 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.470,  Train_accy 15.42, Test_accy 50.38
2022-10-08 09:36:05,936 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.480,  Train_accy 14.66
2022-10-08 09:36:09,179 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.474,  Train_accy 15.17
2022-10-08 09:36:12,403 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.461,  Train_accy 15.08
2022-10-08 09:36:15,479 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.464,  Train_accy 15.93
2022-10-08 09:36:19,223 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.459,  Train_accy 15.51, Test_accy 50.38
2022-10-08 09:36:22,173 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.474,  Train_accy 15.42
2022-10-08 09:36:25,342 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.467,  Train_accy 16.02
2022-10-08 09:36:28,519 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.469,  Train_accy 16.10
2022-10-08 09:36:31,666 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.460,  Train_accy 15.85
2022-10-08 09:36:35,491 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.459,  Train_accy 16.19, Test_accy 51.14
2022-10-08 09:36:35,492 [foster.py] => do not weight align student!
2022-10-08 09:36:36,141 [foster.py] => darknet eval: 
2022-10-08 09:36:36,141 [foster.py] => CNN top1 curve: 51.14
2022-10-08 09:36:36,141 [foster.py] => CNN top5 curve: 96.97
2022-10-08 09:36:36,142 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 09:36:43,914 [foster.py] => Exemplar size: 240
2022-10-08 09:36:43,914 [trainer.py] => CNN: {'total': 58.33, 'old': 76.58, 'new': 31.13, 'base': 76.58, 'compound': 31.13}
2022-10-08 09:36:43,914 [trainer.py] => CNN top1 curve: [84.18, 58.33]
2022-10-08 09:36:43,914 [trainer.py] => CNN base curve: [84.18, 76.58]
2022-10-08 09:36:43,915 [trainer.py] => CNN old curve: [84.18, 76.58]
2022-10-08 09:36:43,915 [trainer.py] => CNN new curve: [0, 31.13]
2022-10-08 09:36:43,915 [trainer.py] => CNN compound curve: [0, 31.13]
2022-10-08 09:36:43,915 [trainer.py] => NME: {'total': 65.91, 'old': 77.22, 'new': 49.06, 'base': 77.22, 'compound': 49.06}
2022-10-08 09:36:43,915 [trainer.py] => NME top1 curve: [84.18, 65.91]
2022-10-08 09:36:43,915 [trainer.py] => NME base curve: [84.18, 77.22]
2022-10-08 09:36:43,915 [trainer.py] => NME old curve: [84.18, 77.22]
2022-10-08 09:36:43,915 [trainer.py] => NME new curve: [0, 49.06]
2022-10-08 09:36:43,915 [trainer.py] => NME compound curve: [0, 49.06]
2022-10-08 09:36:44,141 [foster.py] => Learning on 12-17
2022-10-08 09:36:44,142 [foster.py] => All params: 22385326
2022-10-08 09:36:44,142 [foster.py] => Trainable params: 11202658
2022-10-08 09:36:44,151 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 09:36:47,483 [foster.py] => Task 2, Epoch 1/34 => Loss 5.644, Loss_clf 2.040, Loss_fe 2.168, Loss_kd 1.014, Train_accy 37.88, Test_accy 47.12
2022-10-08 09:36:50,086 [foster.py] => Task 2, Epoch 2/34 => Loss 3.713, Loss_clf 0.885, Loss_fe 1.432, Loss_kd 0.985, Train_accy 38.75
2022-10-08 09:36:52,727 [foster.py] => Task 2, Epoch 3/34 => Loss 3.417, Loss_clf 0.784, Loss_fe 1.232, Loss_kd 0.989, Train_accy 39.46
2022-10-08 09:36:55,301 [foster.py] => Task 2, Epoch 4/34 => Loss 3.205, Loss_clf 0.704, Loss_fe 1.098, Loss_kd 0.991, Train_accy 37.17
2022-10-08 09:36:57,888 [foster.py] => Task 2, Epoch 5/34 => Loss 3.099, Loss_clf 0.686, Loss_fe 1.013, Loss_kd 0.988, Train_accy 38.52
2022-10-08 09:37:01,526 [foster.py] => Task 2, Epoch 6/34 => Loss 3.006, Loss_clf 0.668, Loss_fe 0.947, Loss_kd 0.982, Train_accy 40.17, Test_accy 43.46
2022-10-08 09:37:04,407 [foster.py] => Task 2, Epoch 7/34 => Loss 2.950, Loss_clf 0.653, Loss_fe 0.907, Loss_kd 0.981, Train_accy 38.60
2022-10-08 09:37:07,280 [foster.py] => Task 2, Epoch 8/34 => Loss 2.924, Loss_clf 0.644, Loss_fe 0.877, Loss_kd 0.991, Train_accy 37.81
2022-10-08 09:37:10,083 [foster.py] => Task 2, Epoch 9/34 => Loss 2.823, Loss_clf 0.609, Loss_fe 0.820, Loss_kd 0.984, Train_accy 42.15
2022-10-08 09:37:12,789 [foster.py] => Task 2, Epoch 10/34 => Loss 2.816, Loss_clf 0.614, Loss_fe 0.803, Loss_kd 0.987, Train_accy 39.62
2022-10-08 09:37:16,524 [foster.py] => Task 2, Epoch 11/34 => Loss 2.752, Loss_clf 0.592, Loss_fe 0.774, Loss_kd 0.979, Train_accy 39.23, Test_accy 45.55
2022-10-08 09:37:19,427 [foster.py] => Task 2, Epoch 12/34 => Loss 2.725, Loss_clf 0.584, Loss_fe 0.747, Loss_kd 0.985, Train_accy 40.17
2022-10-08 09:37:22,368 [foster.py] => Task 2, Epoch 13/34 => Loss 2.695, Loss_clf 0.573, Loss_fe 0.729, Loss_kd 0.983, Train_accy 40.73
2022-10-08 09:37:25,319 [foster.py] => Task 2, Epoch 14/34 => Loss 2.637, Loss_clf 0.542, Loss_fe 0.692, Loss_kd 0.991, Train_accy 41.20
2022-10-08 09:37:28,085 [foster.py] => Task 2, Epoch 15/34 => Loss 2.678, Loss_clf 0.578, Loss_fe 0.709, Loss_kd 0.982, Train_accy 41.04
2022-10-08 09:37:31,686 [foster.py] => Task 2, Epoch 16/34 => Loss 2.633, Loss_clf 0.553, Loss_fe 0.685, Loss_kd 0.984, Train_accy 44.04, Test_accy 45.29
2022-10-08 09:37:34,406 [foster.py] => Task 2, Epoch 17/34 => Loss 2.587, Loss_clf 0.525, Loss_fe 0.658, Loss_kd 0.991, Train_accy 44.99
2022-10-08 09:37:37,167 [foster.py] => Task 2, Epoch 18/34 => Loss 2.581, Loss_clf 0.531, Loss_fe 0.653, Loss_kd 0.986, Train_accy 42.30
2022-10-08 09:37:40,034 [foster.py] => Task 2, Epoch 19/34 => Loss 2.577, Loss_clf 0.537, Loss_fe 0.644, Loss_kd 0.986, Train_accy 43.01
2022-10-08 09:37:42,851 [foster.py] => Task 2, Epoch 20/34 => Loss 2.560, Loss_clf 0.524, Loss_fe 0.634, Loss_kd 0.990, Train_accy 43.17
2022-10-08 09:37:46,572 [foster.py] => Task 2, Epoch 21/34 => Loss 2.522, Loss_clf 0.508, Loss_fe 0.615, Loss_kd 0.988, Train_accy 41.28, Test_accy 46.60
2022-10-08 09:37:49,417 [foster.py] => Task 2, Epoch 22/34 => Loss 2.516, Loss_clf 0.505, Loss_fe 0.620, Loss_kd 0.982, Train_accy 44.75
2022-10-08 09:37:52,265 [foster.py] => Task 2, Epoch 23/34 => Loss 2.534, Loss_clf 0.510, Loss_fe 0.619, Loss_kd 0.991, Train_accy 44.75
2022-10-08 09:37:55,081 [foster.py] => Task 2, Epoch 24/34 => Loss 2.509, Loss_clf 0.497, Loss_fe 0.603, Loss_kd 0.995, Train_accy 45.38
2022-10-08 09:37:57,947 [foster.py] => Task 2, Epoch 25/34 => Loss 2.525, Loss_clf 0.506, Loss_fe 0.614, Loss_kd 0.992, Train_accy 43.17
2022-10-08 09:38:01,742 [foster.py] => Task 2, Epoch 26/34 => Loss 2.502, Loss_clf 0.498, Loss_fe 0.613, Loss_kd 0.982, Train_accy 43.25, Test_accy 46.86
2022-10-08 09:38:04,426 [foster.py] => Task 2, Epoch 27/34 => Loss 2.505, Loss_clf 0.496, Loss_fe 0.603, Loss_kd 0.992, Train_accy 43.25
2022-10-08 09:38:07,167 [foster.py] => Task 2, Epoch 28/34 => Loss 2.490, Loss_clf 0.493, Loss_fe 0.597, Loss_kd 0.988, Train_accy 44.44
2022-10-08 09:38:10,355 [foster.py] => Task 2, Epoch 29/34 => Loss 2.492, Loss_clf 0.490, Loss_fe 0.601, Loss_kd 0.988, Train_accy 44.12
2022-10-08 09:38:13,662 [foster.py] => Task 2, Epoch 30/34 => Loss 2.468, Loss_clf 0.482, Loss_fe 0.584, Loss_kd 0.989, Train_accy 43.49
2022-10-08 09:38:17,775 [foster.py] => Task 2, Epoch 31/34 => Loss 2.466, Loss_clf 0.475, Loss_fe 0.582, Loss_kd 0.994, Train_accy 45.54, Test_accy 45.55
2022-10-08 09:38:20,605 [foster.py] => Task 2, Epoch 32/34 => Loss 2.491, Loss_clf 0.485, Loss_fe 0.592, Loss_kd 0.998, Train_accy 45.22
2022-10-08 09:38:23,346 [foster.py] => Task 2, Epoch 33/34 => Loss 2.466, Loss_clf 0.478, Loss_fe 0.590, Loss_kd 0.987, Train_accy 43.88
2022-10-08 09:38:26,259 [foster.py] => Task 2, Epoch 34/34 => Loss 2.455, Loss_clf 0.475, Loss_fe 0.580, Loss_kd 0.988, Train_accy 44.51
2022-10-08 09:38:26,260 [foster.py] => do not weight align teacher!
2022-10-08 09:38:26,260 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 09:38:30,462 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.115,  Train_accy 11.13, Test_accy 36.39
2022-10-08 09:38:35,123 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.996,  Train_accy 11.13
2022-10-08 09:38:39,316 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.955,  Train_accy 11.52
2022-10-08 09:38:43,152 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.928,  Train_accy 11.68
2022-10-08 09:38:46,712 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.928,  Train_accy 11.60
2022-10-08 09:38:50,712 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.905,  Train_accy 11.60, Test_accy 35.60
2022-10-08 09:38:53,812 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.903,  Train_accy 12.23
2022-10-08 09:38:57,293 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.893,  Train_accy 11.92
2022-10-08 09:39:00,786 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.871,  Train_accy 12.15
2022-10-08 09:39:04,067 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.876,  Train_accy 12.08
2022-10-08 09:39:08,086 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.873,  Train_accy 12.31, Test_accy 36.39
2022-10-08 09:39:11,241 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.858,  Train_accy 12.55
2022-10-08 09:39:14,545 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.870,  Train_accy 12.31
2022-10-08 09:39:18,259 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.859,  Train_accy 13.02
2022-10-08 09:39:21,907 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.865,  Train_accy 13.18
2022-10-08 09:39:26,267 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.848,  Train_accy 12.87, Test_accy 36.13
2022-10-08 09:39:29,468 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.850,  Train_accy 12.55
2022-10-08 09:39:32,916 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.861,  Train_accy 13.02
2022-10-08 09:39:36,456 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.862,  Train_accy 13.89
2022-10-08 09:39:39,718 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.847,  Train_accy 13.26
2022-10-08 09:39:43,727 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.848,  Train_accy 12.71, Test_accy 37.43
2022-10-08 09:39:47,030 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.847,  Train_accy 13.34
2022-10-08 09:39:50,409 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.846,  Train_accy 12.94
2022-10-08 09:39:53,897 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.852,  Train_accy 13.26
2022-10-08 09:39:57,456 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.839,  Train_accy 13.34
2022-10-08 09:40:01,477 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.844,  Train_accy 13.42, Test_accy 36.91
2022-10-08 09:40:01,478 [foster.py] => do not weight align student!
2022-10-08 09:40:02,215 [foster.py] => darknet eval: 
2022-10-08 09:40:02,215 [foster.py] => CNN top1 curve: 36.91
2022-10-08 09:40:02,215 [foster.py] => CNN top5 curve: 91.1
2022-10-08 09:40:02,216 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 09:40:11,719 [foster.py] => Exemplar size: 340
2022-10-08 09:40:11,719 [trainer.py] => CNN: {'total': 46.86, 'old': 53.41, 'new': 32.2, 'base': 76.58, 'compound': 25.89}
2022-10-08 09:40:11,719 [trainer.py] => CNN top1 curve: [84.18, 58.33, 46.86]
2022-10-08 09:40:11,719 [trainer.py] => CNN base curve: [84.18, 76.58, 76.58]
2022-10-08 09:40:11,719 [trainer.py] => CNN old curve: [84.18, 76.58, 53.41]
2022-10-08 09:40:11,719 [trainer.py] => CNN new curve: [0, 31.13, 32.2]
2022-10-08 09:40:11,719 [trainer.py] => CNN compound curve: [0, 31.13, 25.89]
2022-10-08 09:40:11,719 [trainer.py] => NME: {'total': 58.38, 'old': 56.44, 'new': 62.71, 'base': 70.89, 'compound': 49.55}
2022-10-08 09:40:11,719 [trainer.py] => NME top1 curve: [84.18, 65.91, 58.38]
2022-10-08 09:40:11,719 [trainer.py] => NME base curve: [84.18, 77.22, 70.89]
2022-10-08 09:40:11,719 [trainer.py] => NME old curve: [84.18, 77.22, 56.44]
2022-10-08 09:40:11,719 [trainer.py] => NME new curve: [0, 49.06, 62.71]
2022-10-08 09:40:11,719 [trainer.py] => NME compound curve: [0, 49.06, 49.55]
2022-10-08 09:40:11,941 [foster.py] => Learning on 17-22
2022-10-08 09:40:11,941 [foster.py] => All params: 22395581
2022-10-08 09:40:11,941 [foster.py] => Trainable params: 11210348
2022-10-08 09:40:11,950 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 09:40:15,595 [foster.py] => Task 3, Epoch 1/34 => Loss 6.793, Loss_clf 2.179, Loss_fe 2.556, Loss_kd 1.590, Train_accy 32.89, Test_accy 37.43
2022-10-08 09:40:18,333 [foster.py] => Task 3, Epoch 2/34 => Loss 5.061, Loss_clf 1.198, Loss_fe 1.814, Loss_kd 1.583, Train_accy 37.51
2022-10-08 09:40:21,059 [foster.py] => Task 3, Epoch 3/34 => Loss 4.706, Loss_clf 1.087, Loss_fe 1.577, Loss_kd 1.578, Train_accy 39.19
2022-10-08 09:40:23,790 [foster.py] => Task 3, Epoch 4/34 => Loss 4.486, Loss_clf 1.024, Loss_fe 1.415, Loss_kd 1.582, Train_accy 40.95
2022-10-08 09:40:26,595 [foster.py] => Task 3, Epoch 5/34 => Loss 4.372, Loss_clf 1.009, Loss_fe 1.319, Loss_kd 1.579, Train_accy 42.93
2022-10-08 09:40:30,315 [foster.py] => Task 3, Epoch 6/34 => Loss 4.262, Loss_clf 0.981, Loss_fe 1.243, Loss_kd 1.575, Train_accy 41.68, Test_accy 42.38
2022-10-08 09:40:33,021 [foster.py] => Task 3, Epoch 7/34 => Loss 4.135, Loss_clf 0.924, Loss_fe 1.167, Loss_kd 1.580, Train_accy 43.00
2022-10-08 09:40:35,849 [foster.py] => Task 3, Epoch 8/34 => Loss 4.083, Loss_clf 0.914, Loss_fe 1.122, Loss_kd 1.582, Train_accy 42.78
2022-10-08 09:40:38,730 [foster.py] => Task 3, Epoch 9/34 => Loss 4.016, Loss_clf 0.889, Loss_fe 1.075, Loss_kd 1.586, Train_accy 42.78
2022-10-08 09:40:41,688 [foster.py] => Task 3, Epoch 10/34 => Loss 3.932, Loss_clf 0.856, Loss_fe 1.032, Loss_kd 1.579, Train_accy 44.47
2022-10-08 09:40:46,004 [foster.py] => Task 3, Epoch 11/34 => Loss 3.890, Loss_clf 0.848, Loss_fe 1.003, Loss_kd 1.576, Train_accy 44.76, Test_accy 43.37
2022-10-08 09:40:49,023 [foster.py] => Task 3, Epoch 12/34 => Loss 3.888, Loss_clf 0.845, Loss_fe 0.992, Loss_kd 1.584, Train_accy 44.62
2022-10-08 09:40:52,043 [foster.py] => Task 3, Epoch 13/34 => Loss 3.838, Loss_clf 0.827, Loss_fe 0.966, Loss_kd 1.580, Train_accy 43.81
2022-10-08 09:40:55,050 [foster.py] => Task 3, Epoch 14/34 => Loss 3.783, Loss_clf 0.808, Loss_fe 0.930, Loss_kd 1.580, Train_accy 46.37
2022-10-08 09:40:58,034 [foster.py] => Task 3, Epoch 15/34 => Loss 3.791, Loss_clf 0.821, Loss_fe 0.929, Loss_kd 1.577, Train_accy 43.52
2022-10-08 09:41:02,107 [foster.py] => Task 3, Epoch 16/34 => Loss 3.728, Loss_clf 0.785, Loss_fe 0.892, Loss_kd 1.585, Train_accy 47.33, Test_accy 43.76
2022-10-08 09:41:05,058 [foster.py] => Task 3, Epoch 17/34 => Loss 3.738, Loss_clf 0.792, Loss_fe 0.892, Loss_kd 1.587, Train_accy 47.91
2022-10-08 09:41:12,779 [foster.py] => Task 3, Epoch 18/34 => Loss 3.680, Loss_clf 0.771, Loss_fe 0.866, Loss_kd 1.579, Train_accy 45.20
2022-10-08 09:41:16,884 [foster.py] => Task 3, Epoch 19/34 => Loss 3.699, Loss_clf 0.783, Loss_fe 0.868, Loss_kd 1.583, Train_accy 45.20
2022-10-08 09:41:20,246 [foster.py] => Task 3, Epoch 20/34 => Loss 3.645, Loss_clf 0.757, Loss_fe 0.843, Loss_kd 1.580, Train_accy 46.45
2022-10-08 09:41:24,184 [foster.py] => Task 3, Epoch 21/34 => Loss 3.613, Loss_clf 0.740, Loss_fe 0.824, Loss_kd 1.584, Train_accy 47.33, Test_accy 46.14
2022-10-08 09:41:26,945 [foster.py] => Task 3, Epoch 22/34 => Loss 3.605, Loss_clf 0.730, Loss_fe 0.822, Loss_kd 1.587, Train_accy 48.35
2022-10-08 09:41:29,670 [foster.py] => Task 3, Epoch 23/34 => Loss 3.597, Loss_clf 0.729, Loss_fe 0.821, Loss_kd 1.582, Train_accy 46.74
2022-10-08 09:41:32,407 [foster.py] => Task 3, Epoch 24/34 => Loss 3.605, Loss_clf 0.735, Loss_fe 0.824, Loss_kd 1.580, Train_accy 46.89
2022-10-08 09:41:35,175 [foster.py] => Task 3, Epoch 25/34 => Loss 3.584, Loss_clf 0.732, Loss_fe 0.802, Loss_kd 1.584, Train_accy 47.62
2022-10-08 09:41:42,597 [foster.py] => Task 3, Epoch 26/34 => Loss 3.582, Loss_clf 0.724, Loss_fe 0.802, Loss_kd 1.589, Train_accy 47.69, Test_accy 45.74
2022-10-08 09:41:45,433 [foster.py] => Task 3, Epoch 27/34 => Loss 3.576, Loss_clf 0.727, Loss_fe 0.802, Loss_kd 1.582, Train_accy 48.35
2022-10-08 09:41:48,269 [foster.py] => Task 3, Epoch 28/34 => Loss 3.570, Loss_clf 0.717, Loss_fe 0.802, Loss_kd 1.585, Train_accy 47.62
2022-10-08 09:41:51,040 [foster.py] => Task 3, Epoch 29/34 => Loss 3.572, Loss_clf 0.721, Loss_fe 0.794, Loss_kd 1.590, Train_accy 48.21
2022-10-08 09:41:53,796 [foster.py] => Task 3, Epoch 30/34 => Loss 3.549, Loss_clf 0.709, Loss_fe 0.783, Loss_kd 1.589, Train_accy 49.30
2022-10-08 09:41:57,585 [foster.py] => Task 3, Epoch 31/34 => Loss 3.562, Loss_clf 0.721, Loss_fe 0.791, Loss_kd 1.584, Train_accy 47.69, Test_accy 45.35
2022-10-08 09:42:00,379 [foster.py] => Task 3, Epoch 32/34 => Loss 3.537, Loss_clf 0.708, Loss_fe 0.777, Loss_kd 1.585, Train_accy 49.38
2022-10-08 09:42:03,214 [foster.py] => Task 3, Epoch 33/34 => Loss 3.576, Loss_clf 0.716, Loss_fe 0.801, Loss_kd 1.591, Train_accy 47.11
2022-10-08 09:42:06,195 [foster.py] => Task 3, Epoch 34/34 => Loss 3.549, Loss_clf 0.707, Loss_fe 0.793, Loss_kd 1.583, Train_accy 48.50
2022-10-08 09:42:06,196 [foster.py] => do not weight align teacher!
2022-10-08 09:42:06,196 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 09:42:10,576 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.503,  Train_accy 10.99, Test_accy 28.91
2022-10-08 09:42:13,815 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.457,  Train_accy 12.09
2022-10-08 09:42:17,369 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.448,  Train_accy 12.23
2022-10-08 09:42:21,191 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.426,  Train_accy 12.01
2022-10-08 09:42:25,023 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.413,  Train_accy 12.67
2022-10-08 09:42:29,662 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.413,  Train_accy 12.67, Test_accy 30.10
2022-10-08 09:42:33,017 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.405,  Train_accy 12.38
2022-10-08 09:42:36,939 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.402,  Train_accy 12.75
2022-10-08 09:42:40,504 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.394,  Train_accy 13.19
2022-10-08 09:42:43,907 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.390,  Train_accy 13.70
2022-10-08 09:42:48,114 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.387,  Train_accy 13.04, Test_accy 30.89
2022-10-08 09:42:51,357 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.379,  Train_accy 13.55
2022-10-08 09:42:54,800 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.379,  Train_accy 14.51
2022-10-08 09:42:58,268 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.375,  Train_accy 15.02
2022-10-08 09:43:02,015 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.379,  Train_accy 14.80
2022-10-08 09:43:06,470 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.364,  Train_accy 14.95, Test_accy 32.48
2022-10-08 09:43:09,919 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.377,  Train_accy 15.02
2022-10-08 09:43:13,479 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.372,  Train_accy 14.87
2022-10-08 09:43:17,029 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.368,  Train_accy 15.90
2022-10-08 09:43:21,302 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.369,  Train_accy 15.75
2022-10-08 09:43:26,133 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.367,  Train_accy 15.97, Test_accy 32.87
2022-10-08 09:43:29,819 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.370,  Train_accy 14.95
2022-10-08 09:43:33,323 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.371,  Train_accy 15.24
2022-10-08 09:43:36,745 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.364,  Train_accy 16.12
2022-10-08 09:43:40,182 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.373,  Train_accy 15.60
2022-10-08 09:43:44,283 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.363,  Train_accy 15.53, Test_accy 32.08
2022-10-08 09:43:44,284 [foster.py] => do not weight align student!
2022-10-08 09:43:45,108 [foster.py] => darknet eval: 
2022-10-08 09:43:45,108 [foster.py] => CNN top1 curve: 32.08
2022-10-08 09:43:45,108 [foster.py] => CNN top5 curve: 81.58
2022-10-08 09:43:45,108 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 09:43:56,266 [foster.py] => Exemplar size: 440
2022-10-08 09:43:56,266 [trainer.py] => CNN: {'total': 45.74, 'old': 46.07, 'new': 44.72, 'base': 74.68, 'compound': 32.56}
2022-10-08 09:43:56,266 [trainer.py] => CNN top1 curve: [84.18, 58.33, 46.86, 45.74]
2022-10-08 09:43:56,266 [trainer.py] => CNN base curve: [84.18, 76.58, 76.58, 74.68]
2022-10-08 09:43:56,267 [trainer.py] => CNN old curve: [84.18, 76.58, 53.41, 46.07]
2022-10-08 09:43:56,267 [trainer.py] => CNN new curve: [0, 31.13, 32.2, 44.72]
2022-10-08 09:43:56,267 [trainer.py] => CNN compound curve: [0, 31.13, 25.89, 32.56]
2022-10-08 09:43:56,267 [trainer.py] => NME: {'total': 54.06, 'old': 51.83, 'new': 60.98, 'base': 65.19, 'compound': 48.99}
2022-10-08 09:43:56,267 [trainer.py] => NME top1 curve: [84.18, 65.91, 58.38, 54.06]
2022-10-08 09:43:56,267 [trainer.py] => NME base curve: [84.18, 77.22, 70.89, 65.19]
2022-10-08 09:43:56,267 [trainer.py] => NME old curve: [84.18, 77.22, 56.44, 51.83]
2022-10-08 09:43:56,267 [trainer.py] => NME new curve: [0, 49.06, 62.71, 60.98]
2022-10-08 09:43:56,267 [trainer.py] => NME compound curve: [0, 49.06, 49.55, 48.99]
2022-10-08 09:43:56,268 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 09:43:56,268 [trainer.py] => prefix: cil
2022-10-08 09:43:56,268 [trainer.py] => dataset: CFEE
2022-10-08 09:43:56,268 [trainer.py] => memory_size: 2000
2022-10-08 09:43:56,268 [trainer.py] => memory_per_class: 20
2022-10-08 09:43:56,268 [trainer.py] => fixed_memory: True
2022-10-08 09:43:56,268 [trainer.py] => shuffle: True
2022-10-08 09:43:56,268 [trainer.py] => init_cls: 7
2022-10-08 09:43:56,268 [trainer.py] => increment: 5
2022-10-08 09:43:56,268 [trainer.py] => model_name: foster
2022-10-08 09:43:56,268 [trainer.py] => convnet_type: resnet18
2022-10-08 09:43:56,269 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 09:43:56,269 [trainer.py] => seed: 1993
2022-10-08 09:43:56,269 [trainer.py] => beta1: 0.96
2022-10-08 09:43:56,269 [trainer.py] => beta2: 0.97
2022-10-08 09:43:56,269 [trainer.py] => oofc: ft
2022-10-08 09:43:56,269 [trainer.py] => is_teacher_wa: False
2022-10-08 09:43:56,269 [trainer.py] => is_student_wa: False
2022-10-08 09:43:56,269 [trainer.py] => lambda_okd: 1
2022-10-08 09:43:56,269 [trainer.py] => wa_value: 1
2022-10-08 09:43:56,269 [trainer.py] => init_epochs: 40
2022-10-08 09:43:56,269 [trainer.py] => init_lr: 0.01
2022-10-08 09:43:56,269 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 09:43:56,269 [trainer.py] => boosting_epochs: 34
2022-10-08 09:43:56,269 [trainer.py] => compression_epochs: 26
2022-10-08 09:43:56,269 [trainer.py] => lr: 0.001
2022-10-08 09:43:56,269 [trainer.py] => batch_size: 32
2022-10-08 09:43:56,269 [trainer.py] => weight_decay: 0.0005
2022-10-08 09:43:56,269 [trainer.py] => num_workers: 8
2022-10-08 09:43:56,269 [trainer.py] => T: 2
2022-10-08 09:43:56,269 [trainer.py] => nb_runs: 3
2022-10-08 09:43:56,269 [trainer.py] => fold: 10
2022-10-08 09:43:56,269 [data.py] => ========== Fold:3 ==========
2022-10-08 09:43:56,274 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 12, 10, 19, 21, 17, 18, 8, 7, 9, 14, 15, 13, 11, 16]
2022-10-08 09:43:56,493 [foster.py] => Learning on 0-7
2022-10-08 09:43:56,493 [foster.py] => All params: 11183694
2022-10-08 09:43:56,494 [foster.py] => Trainable params: 11183694
2022-10-08 09:43:58,865 [foster.py] => Task 0, Epoch 1/40 => Loss 1.314, Train_accy 52.94
2022-10-08 09:44:01,826 [foster.py] => Task 0, Epoch 2/40 => Loss 0.511, Train_accy 83.05, Test_accy 82.12
2022-10-08 09:44:04,799 [foster.py] => Task 0, Epoch 3/40 => Loss 0.366, Train_accy 86.83, Test_accy 83.24
2022-10-08 09:44:07,742 [foster.py] => Task 0, Epoch 4/40 => Loss 0.276, Train_accy 90.90, Test_accy 86.03
2022-10-08 09:44:10,684 [foster.py] => Task 0, Epoch 5/40 => Loss 0.222, Train_accy 92.23, Test_accy 82.68
2022-10-08 09:44:13,013 [foster.py] => Task 0, Epoch 6/40 => Loss 0.177, Train_accy 94.33
2022-10-08 09:44:16,014 [foster.py] => Task 0, Epoch 7/40 => Loss 0.158, Train_accy 94.82, Test_accy 86.03
2022-10-08 09:44:19,069 [foster.py] => Task 0, Epoch 8/40 => Loss 0.132, Train_accy 96.08, Test_accy 84.92
2022-10-08 09:44:22,045 [foster.py] => Task 0, Epoch 9/40 => Loss 0.126, Train_accy 95.94, Test_accy 87.71
2022-10-08 09:44:24,955 [foster.py] => Task 0, Epoch 10/40 => Loss 0.090, Train_accy 97.48, Test_accy 84.92
2022-10-08 09:44:27,336 [foster.py] => Task 0, Epoch 11/40 => Loss 0.083, Train_accy 97.27
2022-10-08 09:44:30,304 [foster.py] => Task 0, Epoch 12/40 => Loss 0.072, Train_accy 97.55, Test_accy 86.59
2022-10-08 09:44:33,247 [foster.py] => Task 0, Epoch 13/40 => Loss 0.067, Train_accy 97.55, Test_accy 87.71
2022-10-08 09:44:36,293 [foster.py] => Task 0, Epoch 14/40 => Loss 0.053, Train_accy 98.32, Test_accy 86.03
2022-10-08 09:44:39,212 [foster.py] => Task 0, Epoch 15/40 => Loss 0.043, Train_accy 98.95, Test_accy 88.27
2022-10-08 09:44:41,573 [foster.py] => Task 0, Epoch 16/40 => Loss 0.037, Train_accy 99.02
2022-10-08 09:44:44,579 [foster.py] => Task 0, Epoch 17/40 => Loss 0.042, Train_accy 98.74, Test_accy 86.59
2022-10-08 09:44:47,585 [foster.py] => Task 0, Epoch 18/40 => Loss 0.033, Train_accy 99.30, Test_accy 87.71
2022-10-08 09:44:50,583 [foster.py] => Task 0, Epoch 19/40 => Loss 0.035, Train_accy 99.02, Test_accy 85.47
2022-10-08 09:44:53,669 [foster.py] => Task 0, Epoch 20/40 => Loss 0.028, Train_accy 99.37, Test_accy 86.03
2022-10-08 09:44:58,974 [foster.py] => Task 0, Epoch 21/40 => Loss 0.024, Train_accy 99.58
2022-10-08 09:45:02,882 [foster.py] => Task 0, Epoch 22/40 => Loss 0.024, Train_accy 99.58, Test_accy 86.03
2022-10-08 09:45:05,847 [foster.py] => Task 0, Epoch 23/40 => Loss 0.021, Train_accy 99.51, Test_accy 86.59
2022-10-08 09:45:08,771 [foster.py] => Task 0, Epoch 24/40 => Loss 0.022, Train_accy 99.58, Test_accy 87.71
2022-10-08 09:45:11,710 [foster.py] => Task 0, Epoch 25/40 => Loss 0.015, Train_accy 99.93, Test_accy 86.59
2022-10-08 09:45:14,070 [foster.py] => Task 0, Epoch 26/40 => Loss 0.015, Train_accy 99.72
2022-10-08 09:45:16,979 [foster.py] => Task 0, Epoch 27/40 => Loss 0.017, Train_accy 99.72, Test_accy 86.03
2022-10-08 09:45:19,924 [foster.py] => Task 0, Epoch 28/40 => Loss 0.016, Train_accy 99.86, Test_accy 88.83
2022-10-08 09:45:22,938 [foster.py] => Task 0, Epoch 29/40 => Loss 0.013, Train_accy 99.93, Test_accy 87.71
2022-10-08 09:45:25,928 [foster.py] => Task 0, Epoch 30/40 => Loss 0.018, Train_accy 99.65, Test_accy 87.15
2022-10-08 09:45:28,282 [foster.py] => Task 0, Epoch 31/40 => Loss 0.012, Train_accy 99.93
2022-10-08 09:45:31,163 [foster.py] => Task 0, Epoch 32/40 => Loss 0.014, Train_accy 99.79, Test_accy 87.15
2022-10-08 09:45:34,118 [foster.py] => Task 0, Epoch 33/40 => Loss 0.014, Train_accy 99.86, Test_accy 87.15
2022-10-08 09:45:37,091 [foster.py] => Task 0, Epoch 34/40 => Loss 0.016, Train_accy 99.72, Test_accy 87.15
2022-10-08 09:45:40,011 [foster.py] => Task 0, Epoch 35/40 => Loss 0.016, Train_accy 99.65, Test_accy 87.15
2022-10-08 09:45:42,413 [foster.py] => Task 0, Epoch 36/40 => Loss 0.012, Train_accy 99.86
2022-10-08 09:45:45,340 [foster.py] => Task 0, Epoch 37/40 => Loss 0.012, Train_accy 99.86, Test_accy 87.15
2022-10-08 09:45:48,526 [foster.py] => Task 0, Epoch 38/40 => Loss 0.015, Train_accy 99.72, Test_accy 88.27
2022-10-08 09:45:54,584 [foster.py] => Task 0, Epoch 39/40 => Loss 0.011, Train_accy 99.93, Test_accy 87.71
2022-10-08 09:45:57,770 [foster.py] => Task 0, Epoch 40/40 => Loss 0.015, Train_accy 99.72, Test_accy 87.15
2022-10-08 09:45:57,771 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 09:46:04,200 [foster.py] => Exemplar size: 140
2022-10-08 09:46:04,200 [trainer.py] => CNN: {'total': 87.15, 'old': 87.15, 'new': 0, 'base': 87.15, 'compound': 0}
2022-10-08 09:46:04,200 [trainer.py] => CNN top1 curve: [87.15]
2022-10-08 09:46:04,200 [trainer.py] => CNN base curve: [87.15]
2022-10-08 09:46:04,200 [trainer.py] => CNN old curve: [87.15]
2022-10-08 09:46:04,200 [trainer.py] => CNN new curve: [0]
2022-10-08 09:46:04,200 [trainer.py] => CNN compound curve: [0]
2022-10-08 09:46:04,200 [trainer.py] => NME: {'total': 87.15, 'old': 87.15, 'new': 0, 'base': 87.15, 'compound': 0}
2022-10-08 09:46:04,200 [trainer.py] => NME top1 curve: [87.15]
2022-10-08 09:46:04,200 [trainer.py] => NME base curve: [87.15]
2022-10-08 09:46:04,200 [trainer.py] => NME old curve: [87.15]
2022-10-08 09:46:04,200 [trainer.py] => NME new curve: [0]
2022-10-08 09:46:04,200 [trainer.py] => NME compound curve: [0]
2022-10-08 09:46:04,426 [foster.py] => Learning on 7-12
2022-10-08 09:46:04,427 [foster.py] => All params: 22375071
2022-10-08 09:46:04,427 [foster.py] => Trainable params: 11194968
2022-10-08 09:46:04,436 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 09:46:07,589 [foster.py] => Task 1, Epoch 1/34 => Loss 5.285, Loss_clf 2.486, Loss_fe 2.170, Loss_kd 0.367, Train_accy 28.71, Test_accy 57.04
2022-10-08 09:46:09,954 [foster.py] => Task 1, Epoch 2/34 => Loss 3.180, Loss_clf 1.084, Loss_fe 1.503, Loss_kd 0.346, Train_accy 44.80
2022-10-08 09:46:12,356 [foster.py] => Task 1, Epoch 3/34 => Loss 2.822, Loss_clf 0.947, Loss_fe 1.309, Loss_kd 0.330, Train_accy 37.39
2022-10-08 09:46:14,789 [foster.py] => Task 1, Epoch 4/34 => Loss 2.640, Loss_clf 0.894, Loss_fe 1.191, Loss_kd 0.324, Train_accy 36.54
2022-10-08 09:46:17,211 [foster.py] => Task 1, Epoch 5/34 => Loss 2.590, Loss_clf 0.880, Loss_fe 1.150, Loss_kd 0.327, Train_accy 37.65
2022-10-08 09:46:20,432 [foster.py] => Task 1, Epoch 6/34 => Loss 2.517, Loss_clf 0.860, Loss_fe 1.096, Loss_kd 0.327, Train_accy 37.73, Test_accy 61.51
2022-10-08 09:46:22,839 [foster.py] => Task 1, Epoch 7/34 => Loss 2.467, Loss_clf 0.856, Loss_fe 1.053, Loss_kd 0.326, Train_accy 39.35
2022-10-08 09:46:25,237 [foster.py] => Task 1, Epoch 8/34 => Loss 2.376, Loss_clf 0.811, Loss_fe 1.009, Loss_kd 0.324, Train_accy 40.29
2022-10-08 09:46:27,972 [foster.py] => Task 1, Epoch 9/34 => Loss 2.333, Loss_clf 0.794, Loss_fe 0.977, Loss_kd 0.328, Train_accy 40.12
2022-10-08 09:46:30,828 [foster.py] => Task 1, Epoch 10/34 => Loss 2.277, Loss_clf 0.774, Loss_fe 0.949, Loss_kd 0.323, Train_accy 41.99
2022-10-08 09:46:34,229 [foster.py] => Task 1, Epoch 11/34 => Loss 2.225, Loss_clf 0.754, Loss_fe 0.918, Loss_kd 0.323, Train_accy 40.89, Test_accy 61.51
2022-10-08 09:46:36,714 [foster.py] => Task 1, Epoch 12/34 => Loss 2.195, Loss_clf 0.742, Loss_fe 0.904, Loss_kd 0.320, Train_accy 41.06
2022-10-08 09:46:39,191 [foster.py] => Task 1, Epoch 13/34 => Loss 2.171, Loss_clf 0.735, Loss_fe 0.879, Loss_kd 0.325, Train_accy 43.27
2022-10-08 09:46:41,713 [foster.py] => Task 1, Epoch 14/34 => Loss 2.146, Loss_clf 0.725, Loss_fe 0.860, Loss_kd 0.327, Train_accy 40.55
2022-10-08 09:46:45,868 [foster.py] => Task 1, Epoch 15/34 => Loss 2.093, Loss_clf 0.705, Loss_fe 0.833, Loss_kd 0.324, Train_accy 43.10
2022-10-08 09:46:49,563 [foster.py] => Task 1, Epoch 16/34 => Loss 2.054, Loss_clf 0.684, Loss_fe 0.809, Loss_kd 0.327, Train_accy 43.61, Test_accy 60.82
2022-10-08 09:46:52,133 [foster.py] => Task 1, Epoch 17/34 => Loss 2.062, Loss_clf 0.696, Loss_fe 0.812, Loss_kd 0.323, Train_accy 43.95
2022-10-08 09:46:54,669 [foster.py] => Task 1, Epoch 18/34 => Loss 2.015, Loss_clf 0.667, Loss_fe 0.791, Loss_kd 0.325, Train_accy 44.80
2022-10-08 09:47:00,835 [foster.py] => Task 1, Epoch 19/34 => Loss 2.037, Loss_clf 0.685, Loss_fe 0.803, Loss_kd 0.321, Train_accy 43.61
2022-10-08 09:47:04,047 [foster.py] => Task 1, Epoch 20/34 => Loss 1.990, Loss_clf 0.659, Loss_fe 0.776, Loss_kd 0.324, Train_accy 43.70
2022-10-08 09:47:07,593 [foster.py] => Task 1, Epoch 21/34 => Loss 2.001, Loss_clf 0.671, Loss_fe 0.779, Loss_kd 0.322, Train_accy 45.14, Test_accy 62.89
2022-10-08 09:47:10,105 [foster.py] => Task 1, Epoch 22/34 => Loss 1.957, Loss_clf 0.648, Loss_fe 0.759, Loss_kd 0.321, Train_accy 45.57
2022-10-08 09:47:12,561 [foster.py] => Task 1, Epoch 23/34 => Loss 1.909, Loss_clf 0.621, Loss_fe 0.731, Loss_kd 0.325, Train_accy 46.08
2022-10-08 09:47:14,958 [foster.py] => Task 1, Epoch 24/34 => Loss 1.906, Loss_clf 0.621, Loss_fe 0.730, Loss_kd 0.324, Train_accy 47.79
2022-10-08 09:47:17,450 [foster.py] => Task 1, Epoch 25/34 => Loss 1.910, Loss_clf 0.625, Loss_fe 0.731, Loss_kd 0.323, Train_accy 47.61
2022-10-08 09:47:20,635 [foster.py] => Task 1, Epoch 26/34 => Loss 1.924, Loss_clf 0.624, Loss_fe 0.741, Loss_kd 0.326, Train_accy 46.76, Test_accy 63.23
2022-10-08 09:47:23,101 [foster.py] => Task 1, Epoch 27/34 => Loss 1.911, Loss_clf 0.624, Loss_fe 0.734, Loss_kd 0.322, Train_accy 44.80
2022-10-08 09:47:25,570 [foster.py] => Task 1, Epoch 28/34 => Loss 1.906, Loss_clf 0.620, Loss_fe 0.736, Loss_kd 0.321, Train_accy 47.61
2022-10-08 09:47:31,493 [foster.py] => Task 1, Epoch 29/34 => Loss 1.895, Loss_clf 0.613, Loss_fe 0.733, Loss_kd 0.321, Train_accy 46.00
2022-10-08 09:47:34,660 [foster.py] => Task 1, Epoch 30/34 => Loss 1.905, Loss_clf 0.621, Loss_fe 0.729, Loss_kd 0.324, Train_accy 47.96
2022-10-08 09:47:38,114 [foster.py] => Task 1, Epoch 31/34 => Loss 1.863, Loss_clf 0.594, Loss_fe 0.714, Loss_kd 0.323, Train_accy 46.25, Test_accy 63.23
2022-10-08 09:47:40,526 [foster.py] => Task 1, Epoch 32/34 => Loss 1.833, Loss_clf 0.590, Loss_fe 0.692, Loss_kd 0.322, Train_accy 46.85
2022-10-08 09:47:42,965 [foster.py] => Task 1, Epoch 33/34 => Loss 1.855, Loss_clf 0.596, Loss_fe 0.708, Loss_kd 0.321, Train_accy 47.70
2022-10-08 09:47:45,392 [foster.py] => Task 1, Epoch 34/34 => Loss 1.880, Loss_clf 0.603, Loss_fe 0.721, Loss_kd 0.324, Train_accy 47.02
2022-10-08 09:47:45,392 [foster.py] => do not weight align teacher!
2022-10-08 09:47:45,393 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 09:47:49,006 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.928,  Train_accy 11.41, Test_accy 49.48
2022-10-08 09:47:51,820 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.700,  Train_accy 11.75
2022-10-08 09:47:55,752 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.618,  Train_accy 12.61
2022-10-08 09:47:59,040 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.578,  Train_accy 12.69
2022-10-08 09:48:02,076 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.566,  Train_accy 13.54
2022-10-08 09:48:05,682 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.555,  Train_accy 13.46, Test_accy 54.30
2022-10-08 09:48:08,610 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.524,  Train_accy 14.99
2022-10-08 09:48:11,686 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.525,  Train_accy 15.33
2022-10-08 09:48:14,869 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.511,  Train_accy 15.25
2022-10-08 09:48:17,978 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.504,  Train_accy 16.01
2022-10-08 09:48:21,586 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.508,  Train_accy 16.01, Test_accy 54.64
2022-10-08 09:48:24,539 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.500,  Train_accy 16.35
2022-10-08 09:48:27,661 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.485,  Train_accy 16.87
2022-10-08 09:48:30,805 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.497,  Train_accy 17.04
2022-10-08 09:48:33,925 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.484,  Train_accy 16.87
2022-10-08 09:48:37,785 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.486,  Train_accy 17.89, Test_accy 54.64
2022-10-08 09:48:41,018 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.498,  Train_accy 18.06
2022-10-08 09:48:44,265 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.478,  Train_accy 17.29
2022-10-08 09:48:47,271 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.472,  Train_accy 17.12
2022-10-08 09:48:50,287 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.485,  Train_accy 17.63
2022-10-08 09:48:54,094 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.479,  Train_accy 17.21, Test_accy 54.30
2022-10-08 09:48:57,266 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.486,  Train_accy 17.55
2022-10-08 09:49:00,527 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.479,  Train_accy 17.80
2022-10-08 09:49:03,748 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.479,  Train_accy 18.23
2022-10-08 09:49:07,013 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.485,  Train_accy 17.12
2022-10-08 09:49:10,942 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.476,  Train_accy 16.52, Test_accy 54.64
2022-10-08 09:49:10,942 [foster.py] => do not weight align student!
2022-10-08 09:49:11,642 [foster.py] => darknet eval: 
2022-10-08 09:49:11,643 [foster.py] => CNN top1 curve: 54.64
2022-10-08 09:49:11,643 [foster.py] => CNN top5 curve: 95.19
2022-10-08 09:49:11,643 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 09:49:19,474 [foster.py] => Exemplar size: 240
2022-10-08 09:49:19,475 [trainer.py] => CNN: {'total': 63.23, 'old': 82.68, 'new': 32.14, 'base': 82.68, 'compound': 32.14}
2022-10-08 09:49:19,475 [trainer.py] => CNN top1 curve: [87.15, 63.23]
2022-10-08 09:49:19,475 [trainer.py] => CNN base curve: [87.15, 82.68]
2022-10-08 09:49:19,475 [trainer.py] => CNN old curve: [87.15, 82.68]
2022-10-08 09:49:19,475 [trainer.py] => CNN new curve: [0, 32.14]
2022-10-08 09:49:19,475 [trainer.py] => CNN compound curve: [0, 32.14]
2022-10-08 09:49:19,475 [trainer.py] => NME: {'total': 68.38, 'old': 77.65, 'new': 53.57, 'base': 77.65, 'compound': 53.57}
2022-10-08 09:49:19,475 [trainer.py] => NME top1 curve: [87.15, 68.38]
2022-10-08 09:49:19,475 [trainer.py] => NME base curve: [87.15, 77.65]
2022-10-08 09:49:19,475 [trainer.py] => NME old curve: [87.15, 77.65]
2022-10-08 09:49:19,475 [trainer.py] => NME new curve: [0, 53.57]
2022-10-08 09:49:19,475 [trainer.py] => NME compound curve: [0, 53.57]
2022-10-08 09:49:19,698 [foster.py] => Learning on 12-17
2022-10-08 09:49:19,698 [foster.py] => All params: 22385326
2022-10-08 09:49:19,699 [foster.py] => Trainable params: 11202658
2022-10-08 09:49:19,708 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 09:49:23,146 [foster.py] => Task 2, Epoch 1/34 => Loss 5.776, Loss_clf 2.130, Loss_fe 2.183, Loss_kd 1.032, Train_accy 42.88, Test_accy 48.59
2022-10-08 09:49:25,762 [foster.py] => Task 2, Epoch 2/34 => Loss 3.698, Loss_clf 0.886, Loss_fe 1.413, Loss_kd 0.988, Train_accy 47.16
2022-10-08 09:49:28,423 [foster.py] => Task 2, Epoch 3/34 => Loss 3.430, Loss_clf 0.798, Loss_fe 1.242, Loss_kd 0.982, Train_accy 40.78
2022-10-08 09:49:31,074 [foster.py] => Task 2, Epoch 4/34 => Loss 3.228, Loss_clf 0.730, Loss_fe 1.098, Loss_kd 0.988, Train_accy 45.14
2022-10-08 09:49:33,822 [foster.py] => Task 2, Epoch 5/34 => Loss 3.090, Loss_clf 0.684, Loss_fe 1.010, Loss_kd 0.986, Train_accy 43.04
2022-10-08 09:49:37,995 [foster.py] => Task 2, Epoch 6/34 => Loss 3.043, Loss_clf 0.674, Loss_fe 0.964, Loss_kd 0.992, Train_accy 43.89, Test_accy 51.41
2022-10-08 09:49:40,782 [foster.py] => Task 2, Epoch 7/34 => Loss 2.969, Loss_clf 0.641, Loss_fe 0.927, Loss_kd 0.989, Train_accy 44.44
2022-10-08 09:49:43,606 [foster.py] => Task 2, Epoch 8/34 => Loss 2.877, Loss_clf 0.620, Loss_fe 0.855, Loss_kd 0.991, Train_accy 41.87
2022-10-08 09:49:46,489 [foster.py] => Task 2, Epoch 9/34 => Loss 2.854, Loss_clf 0.605, Loss_fe 0.837, Loss_kd 0.997, Train_accy 46.54
2022-10-08 09:49:49,375 [foster.py] => Task 2, Epoch 10/34 => Loss 2.844, Loss_clf 0.609, Loss_fe 0.833, Loss_kd 0.989, Train_accy 43.35
2022-10-08 09:49:53,010 [foster.py] => Task 2, Epoch 11/34 => Loss 2.764, Loss_clf 0.580, Loss_fe 0.776, Loss_kd 0.994, Train_accy 44.12, Test_accy 51.92
2022-10-08 09:49:55,760 [foster.py] => Task 2, Epoch 12/34 => Loss 2.742, Loss_clf 0.583, Loss_fe 0.756, Loss_kd 0.991, Train_accy 44.67
2022-10-08 09:49:58,572 [foster.py] => Task 2, Epoch 13/34 => Loss 2.713, Loss_clf 0.577, Loss_fe 0.741, Loss_kd 0.985, Train_accy 46.46
2022-10-08 09:50:01,365 [foster.py] => Task 2, Epoch 14/34 => Loss 2.665, Loss_clf 0.544, Loss_fe 0.705, Loss_kd 0.999, Train_accy 44.67
2022-10-08 09:50:04,467 [foster.py] => Task 2, Epoch 15/34 => Loss 2.679, Loss_clf 0.557, Loss_fe 0.705, Loss_kd 1.000, Train_accy 46.15
2022-10-08 09:50:08,146 [foster.py] => Task 2, Epoch 16/34 => Loss 2.666, Loss_clf 0.557, Loss_fe 0.699, Loss_kd 0.995, Train_accy 45.06, Test_accy 53.20
2022-10-08 09:50:10,817 [foster.py] => Task 2, Epoch 17/34 => Loss 2.583, Loss_clf 0.521, Loss_fe 0.658, Loss_kd 0.991, Train_accy 43.89
2022-10-08 09:50:13,601 [foster.py] => Task 2, Epoch 18/34 => Loss 2.588, Loss_clf 0.536, Loss_fe 0.659, Loss_kd 0.983, Train_accy 46.30
2022-10-08 09:50:16,581 [foster.py] => Task 2, Epoch 19/34 => Loss 2.600, Loss_clf 0.520, Loss_fe 0.669, Loss_kd 0.996, Train_accy 47.08
2022-10-08 09:50:19,537 [foster.py] => Task 2, Epoch 20/34 => Loss 2.547, Loss_clf 0.506, Loss_fe 0.630, Loss_kd 0.996, Train_accy 48.25
2022-10-08 09:50:23,411 [foster.py] => Task 2, Epoch 21/34 => Loss 2.609, Loss_clf 0.548, Loss_fe 0.658, Loss_kd 0.991, Train_accy 48.72, Test_accy 54.22
2022-10-08 09:50:26,219 [foster.py] => Task 2, Epoch 22/34 => Loss 2.563, Loss_clf 0.527, Loss_fe 0.641, Loss_kd 0.985, Train_accy 46.61
2022-10-08 09:50:29,187 [foster.py] => Task 2, Epoch 23/34 => Loss 2.516, Loss_clf 0.493, Loss_fe 0.611, Loss_kd 0.997, Train_accy 47.39
2022-10-08 09:50:31,958 [foster.py] => Task 2, Epoch 24/34 => Loss 2.544, Loss_clf 0.511, Loss_fe 0.633, Loss_kd 0.989, Train_accy 47.70
2022-10-08 09:50:34,741 [foster.py] => Task 2, Epoch 25/34 => Loss 2.529, Loss_clf 0.502, Loss_fe 0.619, Loss_kd 0.994, Train_accy 48.09
2022-10-08 09:50:38,602 [foster.py] => Task 2, Epoch 26/34 => Loss 2.480, Loss_clf 0.480, Loss_fe 0.593, Loss_kd 0.993, Train_accy 47.86, Test_accy 53.71
2022-10-08 09:50:41,434 [foster.py] => Task 2, Epoch 27/34 => Loss 2.528, Loss_clf 0.497, Loss_fe 0.612, Loss_kd 1.001, Train_accy 49.49
2022-10-08 09:50:46,262 [foster.py] => Task 2, Epoch 28/34 => Loss 2.506, Loss_clf 0.485, Loss_fe 0.605, Loss_kd 1.000, Train_accy 47.70
2022-10-08 09:50:49,634 [foster.py] => Task 2, Epoch 29/34 => Loss 2.493, Loss_clf 0.478, Loss_fe 0.605, Loss_kd 0.995, Train_accy 48.64
2022-10-08 09:50:52,540 [foster.py] => Task 2, Epoch 30/34 => Loss 2.479, Loss_clf 0.480, Loss_fe 0.595, Loss_kd 0.991, Train_accy 46.93
2022-10-08 09:50:56,381 [foster.py] => Task 2, Epoch 31/34 => Loss 2.504, Loss_clf 0.489, Loss_fe 0.606, Loss_kd 0.995, Train_accy 47.32, Test_accy 53.96
2022-10-08 09:50:59,035 [foster.py] => Task 2, Epoch 32/34 => Loss 2.475, Loss_clf 0.474, Loss_fe 0.590, Loss_kd 0.996, Train_accy 47.32
2022-10-08 09:51:01,735 [foster.py] => Task 2, Epoch 33/34 => Loss 2.457, Loss_clf 0.481, Loss_fe 0.585, Loss_kd 0.982, Train_accy 47.86
2022-10-08 09:51:04,467 [foster.py] => Task 2, Epoch 34/34 => Loss 2.449, Loss_clf 0.465, Loss_fe 0.584, Loss_kd 0.989, Train_accy 46.77
2022-10-08 09:51:04,467 [foster.py] => do not weight align teacher!
2022-10-08 09:51:04,468 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 09:51:08,743 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.166,  Train_accy 11.28, Test_accy 39.64
2022-10-08 09:51:11,909 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 2.031,  Train_accy 11.21
2022-10-08 09:51:15,512 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.978,  Train_accy 11.44
2022-10-08 09:51:18,805 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.959,  Train_accy 11.44
2022-10-08 09:51:22,101 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.944,  Train_accy 11.52
2022-10-08 09:51:26,162 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.945,  Train_accy 11.75, Test_accy 40.15
2022-10-08 09:51:29,285 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.927,  Train_accy 11.98
2022-10-08 09:51:32,548 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.895,  Train_accy 12.68
2022-10-08 09:51:36,091 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.901,  Train_accy 12.37
2022-10-08 09:51:39,377 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.883,  Train_accy 12.92
2022-10-08 09:51:43,397 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.886,  Train_accy 14.40, Test_accy 41.18
2022-10-08 09:51:46,673 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.883,  Train_accy 14.09
2022-10-08 09:51:49,954 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.892,  Train_accy 14.40
2022-10-08 09:51:53,207 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.880,  Train_accy 14.55
2022-10-08 09:51:57,223 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.864,  Train_accy 15.10
2022-10-08 09:52:01,626 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.861,  Train_accy 15.02, Test_accy 42.46
2022-10-08 09:52:04,782 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.864,  Train_accy 14.55
2022-10-08 09:52:08,061 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.853,  Train_accy 14.63
2022-10-08 09:52:11,703 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.870,  Train_accy 15.49
2022-10-08 09:52:15,134 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.867,  Train_accy 15.64
2022-10-08 09:52:19,238 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.863,  Train_accy 16.19, Test_accy 43.48
2022-10-08 09:52:22,585 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.864,  Train_accy 15.64
2022-10-08 09:52:26,260 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.858,  Train_accy 16.26
2022-10-08 09:52:29,862 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.861,  Train_accy 15.56
2022-10-08 09:52:33,529 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.862,  Train_accy 15.80
2022-10-08 09:52:37,666 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.868,  Train_accy 16.42, Test_accy 42.46
2022-10-08 09:52:37,667 [foster.py] => do not weight align student!
2022-10-08 09:52:38,428 [foster.py] => darknet eval: 
2022-10-08 09:52:38,428 [foster.py] => CNN top1 curve: 42.46
2022-10-08 09:52:38,428 [foster.py] => CNN top5 curve: 92.84
2022-10-08 09:52:38,428 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 09:52:47,881 [foster.py] => Exemplar size: 340
2022-10-08 09:52:47,881 [trainer.py] => CNN: {'total': 54.22, 'old': 55.67, 'new': 50.0, 'base': 77.65, 'compound': 34.43}
2022-10-08 09:52:47,881 [trainer.py] => CNN top1 curve: [87.15, 63.23, 54.22]
2022-10-08 09:52:47,881 [trainer.py] => CNN base curve: [87.15, 82.68, 77.65]
2022-10-08 09:52:47,881 [trainer.py] => CNN old curve: [87.15, 82.68, 55.67]
2022-10-08 09:52:47,881 [trainer.py] => CNN new curve: [0, 32.14, 50.0]
2022-10-08 09:52:47,882 [trainer.py] => CNN compound curve: [0, 32.14, 34.43]
2022-10-08 09:52:47,882 [trainer.py] => NME: {'total': 61.89, 'old': 57.39, 'new': 75.0, 'base': 67.04, 'compound': 57.55}
2022-10-08 09:52:47,882 [trainer.py] => NME top1 curve: [87.15, 68.38, 61.89]
2022-10-08 09:52:47,882 [trainer.py] => NME base curve: [87.15, 77.65, 67.04]
2022-10-08 09:52:47,882 [trainer.py] => NME old curve: [87.15, 77.65, 57.39]
2022-10-08 09:52:47,882 [trainer.py] => NME new curve: [0, 53.57, 75.0]
2022-10-08 09:52:47,882 [trainer.py] => NME compound curve: [0, 53.57, 57.55]
2022-10-08 09:52:48,109 [foster.py] => Learning on 17-22
2022-10-08 09:52:48,110 [foster.py] => All params: 22395581
2022-10-08 09:52:48,110 [foster.py] => Trainable params: 11210348
2022-10-08 09:52:48,119 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 09:52:51,792 [foster.py] => Task 3, Epoch 1/34 => Loss 6.633, Loss_clf 2.036, Loss_fe 2.523, Loss_kd 1.603, Train_accy 33.48, Test_accy 41.58
2022-10-08 09:52:54,532 [foster.py] => Task 3, Epoch 2/34 => Loss 5.002, Loss_clf 1.165, Loss_fe 1.783, Loss_kd 1.587, Train_accy 39.45
2022-10-08 09:52:57,256 [foster.py] => Task 3, Epoch 3/34 => Loss 4.695, Loss_clf 1.078, Loss_fe 1.559, Loss_kd 1.590, Train_accy 42.14
2022-10-08 09:52:59,959 [foster.py] => Task 3, Epoch 4/34 => Loss 4.476, Loss_clf 1.014, Loss_fe 1.417, Loss_kd 1.579, Train_accy 43.01
2022-10-08 09:53:02,719 [foster.py] => Task 3, Epoch 5/34 => Loss 4.358, Loss_clf 0.975, Loss_fe 1.327, Loss_kd 1.588, Train_accy 44.76
2022-10-08 09:53:06,384 [foster.py] => Task 3, Epoch 6/34 => Loss 4.254, Loss_clf 0.953, Loss_fe 1.250, Loss_kd 1.585, Train_accy 45.34, Test_accy 46.73
2022-10-08 09:53:09,139 [foster.py] => Task 3, Epoch 7/34 => Loss 4.169, Loss_clf 0.938, Loss_fe 1.188, Loss_kd 1.579, Train_accy 44.40
2022-10-08 09:53:12,032 [foster.py] => Task 3, Epoch 8/34 => Loss 4.116, Loss_clf 0.914, Loss_fe 1.147, Loss_kd 1.588, Train_accy 46.22
2022-10-08 09:53:15,094 [foster.py] => Task 3, Epoch 9/34 => Loss 4.049, Loss_clf 0.902, Loss_fe 1.096, Loss_kd 1.585, Train_accy 44.61
2022-10-08 09:53:18,164 [foster.py] => Task 3, Epoch 10/34 => Loss 3.999, Loss_clf 0.879, Loss_fe 1.063, Loss_kd 1.589, Train_accy 45.85
2022-10-08 09:53:23,260 [foster.py] => Task 3, Epoch 11/34 => Loss 3.951, Loss_clf 0.865, Loss_fe 1.032, Loss_kd 1.587, Train_accy 46.22, Test_accy 48.71
2022-10-08 09:53:28,937 [foster.py] => Task 3, Epoch 12/34 => Loss 3.944, Loss_clf 0.866, Loss_fe 1.024, Loss_kd 1.588, Train_accy 46.07
2022-10-08 09:53:32,677 [foster.py] => Task 3, Epoch 13/34 => Loss 3.857, Loss_clf 0.828, Loss_fe 0.975, Loss_kd 1.587, Train_accy 48.11
2022-10-08 09:53:35,836 [foster.py] => Task 3, Epoch 14/34 => Loss 3.851, Loss_clf 0.840, Loss_fe 0.963, Loss_kd 1.582, Train_accy 47.16
2022-10-08 09:53:38,766 [foster.py] => Task 3, Epoch 15/34 => Loss 3.815, Loss_clf 0.816, Loss_fe 0.939, Loss_kd 1.592, Train_accy 48.18
2022-10-08 09:53:42,627 [foster.py] => Task 3, Epoch 16/34 => Loss 3.759, Loss_clf 0.794, Loss_fe 0.905, Loss_kd 1.592, Train_accy 47.45, Test_accy 50.69
2022-10-08 09:53:45,477 [foster.py] => Task 3, Epoch 17/34 => Loss 3.731, Loss_clf 0.777, Loss_fe 0.901, Loss_kd 1.587, Train_accy 48.03
2022-10-08 09:53:48,301 [foster.py] => Task 3, Epoch 18/34 => Loss 3.730, Loss_clf 0.780, Loss_fe 0.893, Loss_kd 1.589, Train_accy 50.00
2022-10-08 09:53:51,237 [foster.py] => Task 3, Epoch 19/34 => Loss 3.751, Loss_clf 0.792, Loss_fe 0.903, Loss_kd 1.589, Train_accy 48.54
2022-10-08 09:53:54,263 [foster.py] => Task 3, Epoch 20/34 => Loss 3.716, Loss_clf 0.774, Loss_fe 0.884, Loss_kd 1.591, Train_accy 48.47
2022-10-08 09:53:58,350 [foster.py] => Task 3, Epoch 21/34 => Loss 3.676, Loss_clf 0.756, Loss_fe 0.859, Loss_kd 1.593, Train_accy 49.93, Test_accy 50.30
2022-10-08 09:54:01,238 [foster.py] => Task 3, Epoch 22/34 => Loss 3.647, Loss_clf 0.750, Loss_fe 0.844, Loss_kd 1.586, Train_accy 48.47
2022-10-08 09:54:04,100 [foster.py] => Task 3, Epoch 23/34 => Loss 3.637, Loss_clf 0.737, Loss_fe 0.840, Loss_kd 1.591, Train_accy 50.29
2022-10-08 09:54:07,051 [foster.py] => Task 3, Epoch 24/34 => Loss 3.660, Loss_clf 0.752, Loss_fe 0.847, Loss_kd 1.593, Train_accy 48.54
2022-10-08 09:54:10,275 [foster.py] => Task 3, Epoch 25/34 => Loss 3.628, Loss_clf 0.740, Loss_fe 0.831, Loss_kd 1.589, Train_accy 50.87
2022-10-08 09:54:14,260 [foster.py] => Task 3, Epoch 26/34 => Loss 3.616, Loss_clf 0.734, Loss_fe 0.829, Loss_kd 1.587, Train_accy 49.71, Test_accy 51.09
2022-10-08 09:54:17,108 [foster.py] => Task 3, Epoch 27/34 => Loss 3.633, Loss_clf 0.745, Loss_fe 0.834, Loss_kd 1.587, Train_accy 48.76
2022-10-08 09:54:20,075 [foster.py] => Task 3, Epoch 28/34 => Loss 3.628, Loss_clf 0.734, Loss_fe 0.828, Loss_kd 1.597, Train_accy 50.29
2022-10-08 09:54:23,059 [foster.py] => Task 3, Epoch 29/34 => Loss 3.605, Loss_clf 0.735, Loss_fe 0.819, Loss_kd 1.585, Train_accy 50.58
2022-10-08 09:54:26,380 [foster.py] => Task 3, Epoch 30/34 => Loss 3.601, Loss_clf 0.726, Loss_fe 0.812, Loss_kd 1.594, Train_accy 50.29
2022-10-08 09:54:30,667 [foster.py] => Task 3, Epoch 31/34 => Loss 3.621, Loss_clf 0.735, Loss_fe 0.825, Loss_kd 1.592, Train_accy 50.95, Test_accy 51.49
2022-10-08 09:54:33,548 [foster.py] => Task 3, Epoch 32/34 => Loss 3.605, Loss_clf 0.725, Loss_fe 0.820, Loss_kd 1.591, Train_accy 50.51
2022-10-08 09:54:36,665 [foster.py] => Task 3, Epoch 33/34 => Loss 3.613, Loss_clf 0.741, Loss_fe 0.818, Loss_kd 1.587, Train_accy 49.27
2022-10-08 09:54:39,721 [foster.py] => Task 3, Epoch 34/34 => Loss 3.623, Loss_clf 0.737, Loss_fe 0.830, Loss_kd 1.588, Train_accy 50.66
2022-10-08 09:54:39,722 [foster.py] => do not weight align teacher!
2022-10-08 09:54:39,722 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 09:54:44,435 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.541,  Train_accy 11.06, Test_accy 34.06
2022-10-08 09:54:47,842 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.490,  Train_accy 11.79
2022-10-08 09:54:51,223 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.461,  Train_accy 12.45
2022-10-08 09:54:55,074 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.444,  Train_accy 12.45
2022-10-08 09:54:58,881 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.431,  Train_accy 12.74
2022-10-08 09:55:03,505 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.429,  Train_accy 13.54, Test_accy 38.22
2022-10-08 09:55:07,078 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.419,  Train_accy 13.54
2022-10-08 09:55:10,598 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.410,  Train_accy 13.39
2022-10-08 09:55:14,183 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.408,  Train_accy 14.99
2022-10-08 09:55:17,789 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.403,  Train_accy 14.34
2022-10-08 09:55:22,224 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.397,  Train_accy 15.14, Test_accy 39.21
2022-10-08 09:55:25,614 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.394,  Train_accy 15.65
2022-10-08 09:55:29,255 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.393,  Train_accy 14.85
2022-10-08 09:55:32,875 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.393,  Train_accy 16.30
2022-10-08 09:55:36,320 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.379,  Train_accy 15.87
2022-10-08 09:55:40,925 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.386,  Train_accy 17.03, Test_accy 39.80
2022-10-08 09:55:44,381 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.380,  Train_accy 16.23
2022-10-08 09:55:48,046 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.375,  Train_accy 16.96
2022-10-08 09:55:51,491 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.383,  Train_accy 16.59
2022-10-08 09:55:55,473 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.379,  Train_accy 18.20
2022-10-08 09:56:00,305 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.382,  Train_accy 17.18, Test_accy 40.00
2022-10-08 09:56:03,725 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.383,  Train_accy 17.39
2022-10-08 09:56:07,214 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.385,  Train_accy 17.18
2022-10-08 09:56:10,680 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.378,  Train_accy 17.76
2022-10-08 09:56:14,240 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.375,  Train_accy 17.32
2022-10-08 09:56:19,056 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.381,  Train_accy 17.54, Test_accy 39.41
2022-10-08 09:56:19,056 [foster.py] => do not weight align student!
2022-10-08 09:56:19,856 [foster.py] => darknet eval: 
2022-10-08 09:56:19,856 [foster.py] => CNN top1 curve: 39.41
2022-10-08 09:56:19,856 [foster.py] => CNN top5 curve: 82.57
2022-10-08 09:56:19,857 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 09:56:31,069 [foster.py] => Exemplar size: 440
2022-10-08 09:56:31,069 [trainer.py] => CNN: {'total': 50.69, 'old': 54.22, 'new': 38.6, 'base': 74.86, 'compound': 37.42}
2022-10-08 09:56:31,069 [trainer.py] => CNN top1 curve: [87.15, 63.23, 54.22, 50.69]
2022-10-08 09:56:31,069 [trainer.py] => CNN base curve: [87.15, 82.68, 77.65, 74.86]
2022-10-08 09:56:31,069 [trainer.py] => CNN old curve: [87.15, 82.68, 55.67, 54.22]
2022-10-08 09:56:31,069 [trainer.py] => CNN new curve: [0, 32.14, 50.0, 38.6]
2022-10-08 09:56:31,069 [trainer.py] => CNN compound curve: [0, 32.14, 34.43, 37.42]
2022-10-08 09:56:31,069 [trainer.py] => NME: {'total': 55.64, 'old': 57.29, 'new': 50.0, 'base': 63.13, 'compound': 51.53}
2022-10-08 09:56:31,069 [trainer.py] => NME top1 curve: [87.15, 68.38, 61.89, 55.64]
2022-10-08 09:56:31,069 [trainer.py] => NME base curve: [87.15, 77.65, 67.04, 63.13]
2022-10-08 09:56:31,069 [trainer.py] => NME old curve: [87.15, 77.65, 57.39, 57.29]
2022-10-08 09:56:31,070 [trainer.py] => NME new curve: [0, 53.57, 75.0, 50.0]
2022-10-08 09:56:31,070 [trainer.py] => NME compound curve: [0, 53.57, 57.55, 51.53]
2022-10-08 09:56:31,071 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 09:56:31,071 [trainer.py] => prefix: cil
2022-10-08 09:56:31,071 [trainer.py] => dataset: CFEE
2022-10-08 09:56:31,071 [trainer.py] => memory_size: 2000
2022-10-08 09:56:31,071 [trainer.py] => memory_per_class: 20
2022-10-08 09:56:31,071 [trainer.py] => fixed_memory: True
2022-10-08 09:56:31,071 [trainer.py] => shuffle: True
2022-10-08 09:56:31,071 [trainer.py] => init_cls: 7
2022-10-08 09:56:31,071 [trainer.py] => increment: 5
2022-10-08 09:56:31,071 [trainer.py] => model_name: foster
2022-10-08 09:56:31,071 [trainer.py] => convnet_type: resnet18
2022-10-08 09:56:31,071 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 09:56:31,071 [trainer.py] => seed: 1993
2022-10-08 09:56:31,071 [trainer.py] => beta1: 0.96
2022-10-08 09:56:31,071 [trainer.py] => beta2: 0.97
2022-10-08 09:56:31,071 [trainer.py] => oofc: ft
2022-10-08 09:56:31,071 [trainer.py] => is_teacher_wa: False
2022-10-08 09:56:31,071 [trainer.py] => is_student_wa: False
2022-10-08 09:56:31,071 [trainer.py] => lambda_okd: 1
2022-10-08 09:56:31,071 [trainer.py] => wa_value: 1
2022-10-08 09:56:31,071 [trainer.py] => init_epochs: 40
2022-10-08 09:56:31,072 [trainer.py] => init_lr: 0.01
2022-10-08 09:56:31,072 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 09:56:31,072 [trainer.py] => boosting_epochs: 34
2022-10-08 09:56:31,072 [trainer.py] => compression_epochs: 26
2022-10-08 09:56:31,072 [trainer.py] => lr: 0.001
2022-10-08 09:56:31,072 [trainer.py] => batch_size: 32
2022-10-08 09:56:31,072 [trainer.py] => weight_decay: 0.0005
2022-10-08 09:56:31,072 [trainer.py] => num_workers: 8
2022-10-08 09:56:31,072 [trainer.py] => T: 2
2022-10-08 09:56:31,072 [trainer.py] => nb_runs: 3
2022-10-08 09:56:31,072 [trainer.py] => fold: 10
2022-10-08 09:56:31,072 [data.py] => ========== Fold:4 ==========
2022-10-08 09:56:31,077 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 12, 10, 19, 21, 17, 18, 8, 7, 9, 14, 15, 13, 11, 16]
2022-10-08 09:56:31,293 [foster.py] => Learning on 0-7
2022-10-08 09:56:31,293 [foster.py] => All params: 11183694
2022-10-08 09:56:31,294 [foster.py] => Trainable params: 11183694
2022-10-08 09:56:33,697 [foster.py] => Task 0, Epoch 1/40 => Loss 1.351, Train_accy 53.38
2022-10-08 09:56:36,658 [foster.py] => Task 0, Epoch 2/40 => Loss 0.556, Train_accy 81.41, Test_accy 79.17
2022-10-08 09:56:39,595 [foster.py] => Task 0, Epoch 3/40 => Loss 0.356, Train_accy 87.15, Test_accy 86.11
2022-10-08 09:56:42,543 [foster.py] => Task 0, Epoch 4/40 => Loss 0.287, Train_accy 89.88, Test_accy 84.03
2022-10-08 09:56:45,506 [foster.py] => Task 0, Epoch 5/40 => Loss 0.209, Train_accy 93.30, Test_accy 85.42
2022-10-08 09:56:47,976 [foster.py] => Task 0, Epoch 6/40 => Loss 0.187, Train_accy 93.03
2022-10-08 09:56:51,012 [foster.py] => Task 0, Epoch 7/40 => Loss 0.156, Train_accy 94.33, Test_accy 84.03
2022-10-08 09:56:54,020 [foster.py] => Task 0, Epoch 8/40 => Loss 0.123, Train_accy 96.31, Test_accy 86.11
2022-10-08 09:56:57,019 [foster.py] => Task 0, Epoch 9/40 => Loss 0.112, Train_accy 96.24, Test_accy 85.42
2022-10-08 09:56:59,969 [foster.py] => Task 0, Epoch 10/40 => Loss 0.093, Train_accy 97.27, Test_accy 84.03
2022-10-08 09:57:02,392 [foster.py] => Task 0, Epoch 11/40 => Loss 0.073, Train_accy 97.68
2022-10-08 09:57:05,322 [foster.py] => Task 0, Epoch 12/40 => Loss 0.074, Train_accy 98.43, Test_accy 86.81
2022-10-08 09:57:08,308 [foster.py] => Task 0, Epoch 13/40 => Loss 0.054, Train_accy 98.84, Test_accy 86.11
2022-10-08 09:57:11,311 [foster.py] => Task 0, Epoch 14/40 => Loss 0.055, Train_accy 98.22, Test_accy 87.50
2022-10-08 09:57:14,251 [foster.py] => Task 0, Epoch 15/40 => Loss 0.047, Train_accy 98.77, Test_accy 85.42
2022-10-08 09:57:16,634 [foster.py] => Task 0, Epoch 16/40 => Loss 0.038, Train_accy 99.04
2022-10-08 09:57:19,685 [foster.py] => Task 0, Epoch 17/40 => Loss 0.035, Train_accy 99.18, Test_accy 87.50
2022-10-08 09:57:24,643 [foster.py] => Task 0, Epoch 18/40 => Loss 0.031, Train_accy 99.32, Test_accy 85.42
2022-10-08 09:57:28,055 [foster.py] => Task 0, Epoch 19/40 => Loss 0.034, Train_accy 98.97, Test_accy 86.11
2022-10-08 09:57:31,045 [foster.py] => Task 0, Epoch 20/40 => Loss 0.026, Train_accy 99.73, Test_accy 87.50
2022-10-08 09:57:33,455 [foster.py] => Task 0, Epoch 21/40 => Loss 0.029, Train_accy 99.25
2022-10-08 09:57:36,448 [foster.py] => Task 0, Epoch 22/40 => Loss 0.025, Train_accy 99.25, Test_accy 87.50
2022-10-08 09:57:41,246 [foster.py] => Task 0, Epoch 23/40 => Loss 0.020, Train_accy 99.66, Test_accy 87.50
2022-10-08 09:57:44,333 [foster.py] => Task 0, Epoch 24/40 => Loss 0.031, Train_accy 98.97, Test_accy 86.81
2022-10-08 09:57:47,282 [foster.py] => Task 0, Epoch 25/40 => Loss 0.021, Train_accy 99.45, Test_accy 87.50
2022-10-08 09:57:49,747 [foster.py] => Task 0, Epoch 26/40 => Loss 0.017, Train_accy 99.86
2022-10-08 09:57:52,771 [foster.py] => Task 0, Epoch 27/40 => Loss 0.018, Train_accy 99.79, Test_accy 86.81
2022-10-08 09:57:55,766 [foster.py] => Task 0, Epoch 28/40 => Loss 0.017, Train_accy 99.73, Test_accy 86.81
2022-10-08 09:57:58,703 [foster.py] => Task 0, Epoch 29/40 => Loss 0.014, Train_accy 99.86, Test_accy 87.50
2022-10-08 09:58:01,668 [foster.py] => Task 0, Epoch 30/40 => Loss 0.015, Train_accy 99.79, Test_accy 87.50
2022-10-08 09:58:04,056 [foster.py] => Task 0, Epoch 31/40 => Loss 0.015, Train_accy 99.86
2022-10-08 09:58:07,087 [foster.py] => Task 0, Epoch 32/40 => Loss 0.017, Train_accy 99.59, Test_accy 87.50
2022-10-08 09:58:10,045 [foster.py] => Task 0, Epoch 33/40 => Loss 0.013, Train_accy 99.86, Test_accy 87.50
2022-10-08 09:58:13,068 [foster.py] => Task 0, Epoch 34/40 => Loss 0.013, Train_accy 99.86, Test_accy 87.50
2022-10-08 09:58:16,043 [foster.py] => Task 0, Epoch 35/40 => Loss 0.012, Train_accy 99.93, Test_accy 86.81
2022-10-08 09:58:18,507 [foster.py] => Task 0, Epoch 36/40 => Loss 0.012, Train_accy 99.86
2022-10-08 09:58:21,492 [foster.py] => Task 0, Epoch 37/40 => Loss 0.013, Train_accy 99.73, Test_accy 87.50
2022-10-08 09:58:24,476 [foster.py] => Task 0, Epoch 38/40 => Loss 0.013, Train_accy 99.86, Test_accy 87.50
2022-10-08 09:58:27,409 [foster.py] => Task 0, Epoch 39/40 => Loss 0.014, Train_accy 99.86, Test_accy 88.19
2022-10-08 09:58:30,430 [foster.py] => Task 0, Epoch 40/40 => Loss 0.013, Train_accy 99.86, Test_accy 87.50
2022-10-08 09:58:30,431 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 09:58:36,895 [foster.py] => Exemplar size: 140
2022-10-08 09:58:36,895 [trainer.py] => CNN: {'total': 87.5, 'old': 87.5, 'new': 0, 'base': 87.5, 'compound': 0}
2022-10-08 09:58:36,895 [trainer.py] => CNN top1 curve: [87.5]
2022-10-08 09:58:36,895 [trainer.py] => CNN base curve: [87.5]
2022-10-08 09:58:36,895 [trainer.py] => CNN old curve: [87.5]
2022-10-08 09:58:36,895 [trainer.py] => CNN new curve: [0]
2022-10-08 09:58:36,895 [trainer.py] => CNN compound curve: [0]
2022-10-08 09:58:36,895 [trainer.py] => NME: {'total': 88.89, 'old': 88.89, 'new': 0, 'base': 88.89, 'compound': 0}
2022-10-08 09:58:36,895 [trainer.py] => NME top1 curve: [88.89]
2022-10-08 09:58:36,895 [trainer.py] => NME base curve: [88.89]
2022-10-08 09:58:36,895 [trainer.py] => NME old curve: [88.89]
2022-10-08 09:58:36,895 [trainer.py] => NME new curve: [0]
2022-10-08 09:58:36,895 [trainer.py] => NME compound curve: [0]
2022-10-08 09:58:37,122 [foster.py] => Learning on 7-12
2022-10-08 09:58:37,122 [foster.py] => All params: 22375071
2022-10-08 09:58:37,123 [foster.py] => Trainable params: 11194968
2022-10-08 09:58:37,132 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 09:58:40,236 [foster.py] => Task 1, Epoch 1/34 => Loss 5.304, Loss_clf 2.596, Loss_fe 2.067, Loss_kd 0.374, Train_accy 29.54, Test_accy 55.20
2022-10-08 09:58:42,598 [foster.py] => Task 1, Epoch 2/34 => Loss 3.127, Loss_clf 1.069, Loss_fe 1.482, Loss_kd 0.336, Train_accy 47.96
2022-10-08 09:58:45,022 [foster.py] => Task 1, Epoch 3/34 => Loss 2.781, Loss_clf 0.930, Loss_fe 1.302, Loss_kd 0.321, Train_accy 32.58
2022-10-08 09:58:47,467 [foster.py] => Task 1, Epoch 4/34 => Loss 2.629, Loss_clf 0.889, Loss_fe 1.195, Loss_kd 0.318, Train_accy 33.10
2022-10-08 09:58:49,860 [foster.py] => Task 1, Epoch 5/34 => Loss 2.513, Loss_clf 0.855, Loss_fe 1.118, Loss_kd 0.315, Train_accy 34.84
2022-10-08 09:58:53,080 [foster.py] => Task 1, Epoch 6/34 => Loss 2.443, Loss_clf 0.840, Loss_fe 1.062, Loss_kd 0.316, Train_accy 34.67, Test_accy 55.56
2022-10-08 09:58:55,555 [foster.py] => Task 1, Epoch 7/34 => Loss 2.384, Loss_clf 0.822, Loss_fe 1.017, Loss_kd 0.318, Train_accy 33.54
2022-10-08 09:59:01,762 [foster.py] => Task 1, Epoch 8/34 => Loss 2.327, Loss_clf 0.799, Loss_fe 0.981, Loss_kd 0.320, Train_accy 36.49
2022-10-08 09:59:05,410 [foster.py] => Task 1, Epoch 9/34 => Loss 2.277, Loss_clf 0.786, Loss_fe 0.947, Loss_kd 0.317, Train_accy 37.01
2022-10-08 09:59:08,154 [foster.py] => Task 1, Epoch 10/34 => Loss 2.199, Loss_clf 0.755, Loss_fe 0.898, Loss_kd 0.318, Train_accy 37.19
2022-10-08 09:59:11,371 [foster.py] => Task 1, Epoch 11/34 => Loss 2.203, Loss_clf 0.768, Loss_fe 0.896, Loss_kd 0.315, Train_accy 36.23, Test_accy 55.20
2022-10-08 09:59:13,709 [foster.py] => Task 1, Epoch 12/34 => Loss 2.105, Loss_clf 0.720, Loss_fe 0.852, Loss_kd 0.311, Train_accy 37.97
2022-10-08 09:59:16,086 [foster.py] => Task 1, Epoch 13/34 => Loss 2.122, Loss_clf 0.737, Loss_fe 0.846, Loss_kd 0.315, Train_accy 38.66
2022-10-08 09:59:18,496 [foster.py] => Task 1, Epoch 14/34 => Loss 2.085, Loss_clf 0.716, Loss_fe 0.831, Loss_kd 0.313, Train_accy 38.49
2022-10-08 09:59:20,891 [foster.py] => Task 1, Epoch 15/34 => Loss 2.043, Loss_clf 0.692, Loss_fe 0.814, Loss_kd 0.313, Train_accy 40.49
2022-10-08 09:59:27,279 [foster.py] => Task 1, Epoch 16/34 => Loss 2.048, Loss_clf 0.702, Loss_fe 0.803, Loss_kd 0.316, Train_accy 41.79, Test_accy 55.91
2022-10-08 09:59:29,888 [foster.py] => Task 1, Epoch 17/34 => Loss 1.972, Loss_clf 0.669, Loss_fe 0.767, Loss_kd 0.312, Train_accy 40.49
2022-10-08 09:59:32,395 [foster.py] => Task 1, Epoch 18/34 => Loss 1.966, Loss_clf 0.663, Loss_fe 0.764, Loss_kd 0.314, Train_accy 42.57
2022-10-08 09:59:34,829 [foster.py] => Task 1, Epoch 19/34 => Loss 1.945, Loss_clf 0.657, Loss_fe 0.753, Loss_kd 0.312, Train_accy 42.14
2022-10-08 09:59:37,301 [foster.py] => Task 1, Epoch 20/34 => Loss 1.928, Loss_clf 0.648, Loss_fe 0.740, Loss_kd 0.315, Train_accy 41.96
2022-10-08 09:59:40,542 [foster.py] => Task 1, Epoch 21/34 => Loss 1.934, Loss_clf 0.649, Loss_fe 0.750, Loss_kd 0.312, Train_accy 41.88, Test_accy 56.27
2022-10-08 09:59:43,006 [foster.py] => Task 1, Epoch 22/34 => Loss 1.910, Loss_clf 0.636, Loss_fe 0.736, Loss_kd 0.314, Train_accy 42.31
2022-10-08 09:59:45,368 [foster.py] => Task 1, Epoch 23/34 => Loss 1.861, Loss_clf 0.607, Loss_fe 0.709, Loss_kd 0.318, Train_accy 43.96
2022-10-08 09:59:47,851 [foster.py] => Task 1, Epoch 24/34 => Loss 1.905, Loss_clf 0.633, Loss_fe 0.736, Loss_kd 0.312, Train_accy 42.75
2022-10-08 09:59:50,374 [foster.py] => Task 1, Epoch 25/34 => Loss 1.893, Loss_clf 0.632, Loss_fe 0.722, Loss_kd 0.314, Train_accy 43.96
2022-10-08 09:59:53,758 [foster.py] => Task 1, Epoch 26/34 => Loss 1.863, Loss_clf 0.617, Loss_fe 0.708, Loss_kd 0.314, Train_accy 43.96, Test_accy 55.56
2022-10-08 09:59:56,191 [foster.py] => Task 1, Epoch 27/34 => Loss 1.825, Loss_clf 0.598, Loss_fe 0.693, Loss_kd 0.311, Train_accy 43.61
2022-10-08 09:59:58,662 [foster.py] => Task 1, Epoch 28/34 => Loss 1.841, Loss_clf 0.604, Loss_fe 0.700, Loss_kd 0.314, Train_accy 44.83
2022-10-08 10:00:01,423 [foster.py] => Task 1, Epoch 29/34 => Loss 1.810, Loss_clf 0.585, Loss_fe 0.685, Loss_kd 0.315, Train_accy 44.40
2022-10-08 10:00:04,089 [foster.py] => Task 1, Epoch 30/34 => Loss 1.824, Loss_clf 0.592, Loss_fe 0.694, Loss_kd 0.314, Train_accy 44.74
2022-10-08 10:00:07,410 [foster.py] => Task 1, Epoch 31/34 => Loss 1.858, Loss_clf 0.608, Loss_fe 0.704, Loss_kd 0.318, Train_accy 43.70, Test_accy 55.20
2022-10-08 10:00:09,838 [foster.py] => Task 1, Epoch 32/34 => Loss 1.836, Loss_clf 0.603, Loss_fe 0.695, Loss_kd 0.314, Train_accy 44.66
2022-10-08 10:00:12,355 [foster.py] => Task 1, Epoch 33/34 => Loss 1.820, Loss_clf 0.594, Loss_fe 0.685, Loss_kd 0.315, Train_accy 44.83
2022-10-08 10:00:17,672 [foster.py] => Task 1, Epoch 34/34 => Loss 1.822, Loss_clf 0.593, Loss_fe 0.691, Loss_kd 0.314, Train_accy 45.44
2022-10-08 10:00:17,672 [foster.py] => do not weight align teacher!
2022-10-08 10:00:17,672 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 10:00:21,910 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.854,  Train_accy 11.38, Test_accy 43.73
2022-10-08 10:00:24,677 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.642,  Train_accy 11.73
2022-10-08 10:00:27,524 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.565,  Train_accy 12.42
2022-10-08 10:00:30,311 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.530,  Train_accy 12.68
2022-10-08 10:00:33,237 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.505,  Train_accy 13.64
2022-10-08 10:00:37,630 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.498,  Train_accy 13.90, Test_accy 45.88
2022-10-08 10:00:40,545 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.473,  Train_accy 13.90
2022-10-08 10:00:43,430 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.478,  Train_accy 14.16
2022-10-08 10:00:46,389 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.471,  Train_accy 15.29
2022-10-08 10:00:49,349 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.459,  Train_accy 15.03
2022-10-08 10:00:53,349 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.451,  Train_accy 13.81, Test_accy 45.16
2022-10-08 10:00:56,185 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.444,  Train_accy 15.38
2022-10-08 10:00:59,218 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.445,  Train_accy 15.29
2022-10-08 10:01:02,771 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.445,  Train_accy 15.90
2022-10-08 10:01:06,030 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.446,  Train_accy 15.29
2022-10-08 10:01:09,744 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.430,  Train_accy 16.51, Test_accy 45.88
2022-10-08 10:01:12,583 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.449,  Train_accy 16.85
2022-10-08 10:01:15,525 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.435,  Train_accy 15.29
2022-10-08 10:01:18,628 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.434,  Train_accy 16.07
2022-10-08 10:01:21,641 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.433,  Train_accy 16.77
2022-10-08 10:01:25,707 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.439,  Train_accy 16.07, Test_accy 45.88
2022-10-08 10:01:28,876 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.433,  Train_accy 15.73
2022-10-08 10:01:31,899 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.435,  Train_accy 16.07
2022-10-08 10:01:35,065 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.424,  Train_accy 15.99
2022-10-08 10:01:38,176 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.433,  Train_accy 14.94
2022-10-08 10:01:41,912 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.445,  Train_accy 16.85, Test_accy 46.24
2022-10-08 10:01:41,913 [foster.py] => do not weight align student!
2022-10-08 10:01:42,594 [foster.py] => darknet eval: 
2022-10-08 10:01:42,595 [foster.py] => CNN top1 curve: 46.24
2022-10-08 10:01:42,595 [foster.py] => CNN top5 curve: 96.42
2022-10-08 10:01:42,595 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 10:01:50,261 [foster.py] => Exemplar size: 240
2022-10-08 10:01:50,261 [trainer.py] => CNN: {'total': 55.2, 'old': 84.03, 'new': 24.44, 'base': 84.03, 'compound': 24.44}
2022-10-08 10:01:50,261 [trainer.py] => CNN top1 curve: [87.5, 55.2]
2022-10-08 10:01:50,261 [trainer.py] => CNN base curve: [87.5, 84.03]
2022-10-08 10:01:50,261 [trainer.py] => CNN old curve: [87.5, 84.03]
2022-10-08 10:01:50,261 [trainer.py] => CNN new curve: [0, 24.44]
2022-10-08 10:01:50,261 [trainer.py] => CNN compound curve: [0, 24.44]
2022-10-08 10:01:50,261 [trainer.py] => NME: {'total': 65.95, 'old': 82.64, 'new': 48.15, 'base': 82.64, 'compound': 48.15}
2022-10-08 10:01:50,261 [trainer.py] => NME top1 curve: [88.89, 65.95]
2022-10-08 10:01:50,261 [trainer.py] => NME base curve: [88.89, 82.64]
2022-10-08 10:01:50,262 [trainer.py] => NME old curve: [88.89, 82.64]
2022-10-08 10:01:50,262 [trainer.py] => NME new curve: [0, 48.15]
2022-10-08 10:01:50,262 [trainer.py] => NME compound curve: [0, 48.15]
2022-10-08 10:01:50,487 [foster.py] => Learning on 12-17
2022-10-08 10:01:50,488 [foster.py] => All params: 22385326
2022-10-08 10:01:50,488 [foster.py] => Trainable params: 11202658
2022-10-08 10:01:50,497 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 10:01:53,898 [foster.py] => Task 2, Epoch 1/34 => Loss 5.721, Loss_clf 2.076, Loss_fe 2.224, Loss_kd 1.003, Train_accy 39.20, Test_accy 43.48
2022-10-08 10:01:56,497 [foster.py] => Task 2, Epoch 2/34 => Loss 3.702, Loss_clf 0.893, Loss_fe 1.441, Loss_kd 0.965, Train_accy 39.59
2022-10-08 10:01:59,092 [foster.py] => Task 2, Epoch 3/34 => Loss 3.366, Loss_clf 0.763, Loss_fe 1.238, Loss_kd 0.964, Train_accy 40.61
2022-10-08 10:02:01,669 [foster.py] => Task 2, Epoch 4/34 => Loss 3.219, Loss_clf 0.726, Loss_fe 1.120, Loss_kd 0.969, Train_accy 38.57
2022-10-08 10:02:05,915 [foster.py] => Task 2, Epoch 5/34 => Loss 3.077, Loss_clf 0.684, Loss_fe 1.031, Loss_kd 0.962, Train_accy 38.18
2022-10-08 10:02:10,197 [foster.py] => Task 2, Epoch 6/34 => Loss 2.975, Loss_clf 0.649, Loss_fe 0.961, Loss_kd 0.964, Train_accy 39.43, Test_accy 42.71
2022-10-08 10:02:12,850 [foster.py] => Task 2, Epoch 7/34 => Loss 2.875, Loss_clf 0.621, Loss_fe 0.893, Loss_kd 0.961, Train_accy 40.93
2022-10-08 10:02:15,506 [foster.py] => Task 2, Epoch 8/34 => Loss 2.847, Loss_clf 0.619, Loss_fe 0.867, Loss_kd 0.961, Train_accy 40.53
2022-10-08 10:02:18,134 [foster.py] => Task 2, Epoch 9/34 => Loss 2.829, Loss_clf 0.620, Loss_fe 0.839, Loss_kd 0.966, Train_accy 42.58
2022-10-08 10:02:20,799 [foster.py] => Task 2, Epoch 10/34 => Loss 2.731, Loss_clf 0.580, Loss_fe 0.786, Loss_kd 0.963, Train_accy 40.69
2022-10-08 10:02:24,240 [foster.py] => Task 2, Epoch 11/34 => Loss 2.717, Loss_clf 0.581, Loss_fe 0.766, Loss_kd 0.967, Train_accy 42.58, Test_accy 44.76
2022-10-08 10:02:26,839 [foster.py] => Task 2, Epoch 12/34 => Loss 2.680, Loss_clf 0.569, Loss_fe 0.747, Loss_kd 0.963, Train_accy 41.71
2022-10-08 10:02:30,459 [foster.py] => Task 2, Epoch 13/34 => Loss 2.655, Loss_clf 0.555, Loss_fe 0.733, Loss_kd 0.965, Train_accy 43.68
2022-10-08 10:02:33,487 [foster.py] => Task 2, Epoch 14/34 => Loss 2.608, Loss_clf 0.540, Loss_fe 0.701, Loss_kd 0.965, Train_accy 42.97
2022-10-08 10:02:36,303 [foster.py] => Task 2, Epoch 15/34 => Loss 2.588, Loss_clf 0.533, Loss_fe 0.683, Loss_kd 0.969, Train_accy 43.52
2022-10-08 10:02:40,048 [foster.py] => Task 2, Epoch 16/34 => Loss 2.541, Loss_clf 0.525, Loss_fe 0.660, Loss_kd 0.958, Train_accy 41.79, Test_accy 45.27
2022-10-08 10:02:42,733 [foster.py] => Task 2, Epoch 17/34 => Loss 2.537, Loss_clf 0.511, Loss_fe 0.653, Loss_kd 0.969, Train_accy 44.07
2022-10-08 10:02:45,372 [foster.py] => Task 2, Epoch 18/34 => Loss 2.545, Loss_clf 0.520, Loss_fe 0.656, Loss_kd 0.966, Train_accy 43.44
2022-10-08 10:02:48,204 [foster.py] => Task 2, Epoch 19/34 => Loss 2.504, Loss_clf 0.507, Loss_fe 0.635, Loss_kd 0.962, Train_accy 42.73
2022-10-08 10:02:54,563 [foster.py] => Task 2, Epoch 20/34 => Loss 2.532, Loss_clf 0.521, Loss_fe 0.646, Loss_kd 0.963, Train_accy 43.91
2022-10-08 10:02:58,877 [foster.py] => Task 2, Epoch 21/34 => Loss 2.476, Loss_clf 0.492, Loss_fe 0.612, Loss_kd 0.968, Train_accy 46.50, Test_accy 45.01
2022-10-08 10:03:01,617 [foster.py] => Task 2, Epoch 22/34 => Loss 2.472, Loss_clf 0.497, Loss_fe 0.612, Loss_kd 0.961, Train_accy 43.28
2022-10-08 10:03:04,264 [foster.py] => Task 2, Epoch 23/34 => Loss 2.488, Loss_clf 0.494, Loss_fe 0.621, Loss_kd 0.969, Train_accy 44.70
2022-10-08 10:03:06,881 [foster.py] => Task 2, Epoch 24/34 => Loss 2.435, Loss_clf 0.472, Loss_fe 0.597, Loss_kd 0.964, Train_accy 44.38
2022-10-08 10:03:09,470 [foster.py] => Task 2, Epoch 25/34 => Loss 2.437, Loss_clf 0.480, Loss_fe 0.588, Loss_kd 0.966, Train_accy 45.72
2022-10-08 10:03:13,564 [foster.py] => Task 2, Epoch 26/34 => Loss 2.452, Loss_clf 0.486, Loss_fe 0.600, Loss_kd 0.964, Train_accy 43.83, Test_accy 45.78
2022-10-08 10:03:17,461 [foster.py] => Task 2, Epoch 27/34 => Loss 2.423, Loss_clf 0.479, Loss_fe 0.577, Loss_kd 0.965, Train_accy 43.21
2022-10-08 10:03:20,602 [foster.py] => Task 2, Epoch 28/34 => Loss 2.426, Loss_clf 0.467, Loss_fe 0.587, Loss_kd 0.968, Train_accy 45.72
2022-10-08 10:03:23,400 [foster.py] => Task 2, Epoch 29/34 => Loss 2.438, Loss_clf 0.484, Loss_fe 0.592, Loss_kd 0.962, Train_accy 44.46
2022-10-08 10:03:26,088 [foster.py] => Task 2, Epoch 30/34 => Loss 2.425, Loss_clf 0.468, Loss_fe 0.583, Loss_kd 0.969, Train_accy 45.80
2022-10-08 10:03:32,595 [foster.py] => Task 2, Epoch 31/34 => Loss 2.429, Loss_clf 0.479, Loss_fe 0.584, Loss_kd 0.964, Train_accy 44.15, Test_accy 44.76
2022-10-08 10:03:35,345 [foster.py] => Task 2, Epoch 32/34 => Loss 2.400, Loss_clf 0.468, Loss_fe 0.567, Loss_kd 0.963, Train_accy 44.54
2022-10-08 10:03:38,058 [foster.py] => Task 2, Epoch 33/34 => Loss 2.427, Loss_clf 0.473, Loss_fe 0.589, Loss_kd 0.963, Train_accy 44.78
2022-10-08 10:03:40,718 [foster.py] => Task 2, Epoch 34/34 => Loss 2.387, Loss_clf 0.464, Loss_fe 0.570, Loss_kd 0.955, Train_accy 44.38
2022-10-08 10:03:40,718 [foster.py] => do not weight align teacher!
2022-10-08 10:03:40,719 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 10:03:44,644 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.101,  Train_accy 11.00, Test_accy 31.71
2022-10-08 10:03:47,661 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.966,  Train_accy 11.08
2022-10-08 10:03:50,832 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.939,  Train_accy 11.47
2022-10-08 10:03:54,013 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.913,  Train_accy 11.23
2022-10-08 10:03:57,345 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.907,  Train_accy 11.63
2022-10-08 10:04:01,697 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.890,  Train_accy 12.10, Test_accy 32.48
2022-10-08 10:04:04,843 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.883,  Train_accy 12.41
2022-10-08 10:04:08,056 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.866,  Train_accy 11.63
2022-10-08 10:04:11,491 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.869,  Train_accy 12.02
2022-10-08 10:04:14,741 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.855,  Train_accy 12.18
2022-10-08 10:04:18,771 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.846,  Train_accy 12.33, Test_accy 34.02
2022-10-08 10:04:22,116 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.848,  Train_accy 12.25
2022-10-08 10:04:25,625 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.842,  Train_accy 13.28
2022-10-08 10:04:29,324 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.846,  Train_accy 13.28
2022-10-08 10:04:32,707 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.837,  Train_accy 12.73
2022-10-08 10:04:36,693 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.836,  Train_accy 13.43, Test_accy 34.53
2022-10-08 10:04:39,802 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.832,  Train_accy 13.67
2022-10-08 10:04:43,566 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.836,  Train_accy 13.20
2022-10-08 10:04:47,034 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.826,  Train_accy 13.12
2022-10-08 10:04:50,294 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.829,  Train_accy 14.14
2022-10-08 10:04:54,267 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.816,  Train_accy 14.69, Test_accy 34.27
2022-10-08 10:04:57,323 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.812,  Train_accy 13.83
2022-10-08 10:05:00,622 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.822,  Train_accy 13.75
2022-10-08 10:05:04,123 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.821,  Train_accy 13.83
2022-10-08 10:05:07,725 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.816,  Train_accy 13.90
2022-10-08 10:05:12,022 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.828,  Train_accy 13.51, Test_accy 35.29
2022-10-08 10:05:12,022 [foster.py] => do not weight align student!
2022-10-08 10:05:12,785 [foster.py] => darknet eval: 
2022-10-08 10:05:12,785 [foster.py] => CNN top1 curve: 35.29
2022-10-08 10:05:12,785 [foster.py] => CNN top5 curve: 92.33
2022-10-08 10:05:12,785 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 10:05:22,175 [foster.py] => Exemplar size: 340
2022-10-08 10:05:22,175 [trainer.py] => CNN: {'total': 45.27, 'old': 49.82, 'new': 33.93, 'base': 81.94, 'compound': 23.89}
2022-10-08 10:05:22,176 [trainer.py] => CNN top1 curve: [87.5, 55.2, 45.27]
2022-10-08 10:05:22,176 [trainer.py] => CNN base curve: [87.5, 84.03, 81.94]
2022-10-08 10:05:22,176 [trainer.py] => CNN old curve: [87.5, 84.03, 49.82]
2022-10-08 10:05:22,176 [trainer.py] => CNN new curve: [0, 24.44, 33.93]
2022-10-08 10:05:22,176 [trainer.py] => CNN compound curve: [0, 24.44, 23.89]
2022-10-08 10:05:22,176 [trainer.py] => NME: {'total': 57.03, 'old': 54.12, 'new': 64.29, 'base': 71.53, 'compound': 48.58}
2022-10-08 10:05:22,176 [trainer.py] => NME top1 curve: [88.89, 65.95, 57.03]
2022-10-08 10:05:22,176 [trainer.py] => NME base curve: [88.89, 82.64, 71.53]
2022-10-08 10:05:22,176 [trainer.py] => NME old curve: [88.89, 82.64, 54.12]
2022-10-08 10:05:22,176 [trainer.py] => NME new curve: [0, 48.15, 64.29]
2022-10-08 10:05:22,176 [trainer.py] => NME compound curve: [0, 48.15, 48.58]
2022-10-08 10:05:22,400 [foster.py] => Learning on 17-22
2022-10-08 10:05:22,400 [foster.py] => All params: 22395581
2022-10-08 10:05:22,401 [foster.py] => Trainable params: 11210348
2022-10-08 10:05:22,410 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 10:05:26,083 [foster.py] => Task 3, Epoch 1/34 => Loss 6.639, Loss_clf 2.086, Loss_fe 2.491, Loss_kd 1.593, Train_accy 35.08, Test_accy 35.45
2022-10-08 10:05:28,799 [foster.py] => Task 3, Epoch 2/34 => Loss 4.964, Loss_clf 1.184, Loss_fe 1.744, Loss_kd 1.573, Train_accy 39.30
2022-10-08 10:05:31,558 [foster.py] => Task 3, Epoch 3/34 => Loss 4.629, Loss_clf 1.070, Loss_fe 1.528, Loss_kd 1.570, Train_accy 41.19
2022-10-08 10:05:34,286 [foster.py] => Task 3, Epoch 4/34 => Loss 4.487, Loss_clf 1.036, Loss_fe 1.411, Loss_kd 1.576, Train_accy 41.41
2022-10-08 10:05:37,061 [foster.py] => Task 3, Epoch 5/34 => Loss 4.370, Loss_clf 1.009, Loss_fe 1.318, Loss_kd 1.579, Train_accy 44.32
2022-10-08 10:05:40,832 [foster.py] => Task 3, Epoch 6/34 => Loss 4.230, Loss_clf 0.954, Loss_fe 1.231, Loss_kd 1.580, Train_accy 43.60, Test_accy 40.00
2022-10-08 10:05:43,626 [foster.py] => Task 3, Epoch 7/34 => Loss 4.168, Loss_clf 0.946, Loss_fe 1.189, Loss_kd 1.571, Train_accy 45.12
2022-10-08 10:05:46,613 [foster.py] => Task 3, Epoch 8/34 => Loss 4.074, Loss_clf 0.907, Loss_fe 1.125, Loss_kd 1.578, Train_accy 44.47
2022-10-08 10:05:49,462 [foster.py] => Task 3, Epoch 9/34 => Loss 4.025, Loss_clf 0.907, Loss_fe 1.082, Loss_kd 1.573, Train_accy 44.54
2022-10-08 10:05:55,727 [foster.py] => Task 3, Epoch 10/34 => Loss 3.973, Loss_clf 0.888, Loss_fe 1.048, Loss_kd 1.574, Train_accy 44.98
2022-10-08 10:06:00,387 [foster.py] => Task 3, Epoch 11/34 => Loss 3.961, Loss_clf 0.873, Loss_fe 1.045, Loss_kd 1.578, Train_accy 44.91, Test_accy 43.56
2022-10-08 10:06:03,250 [foster.py] => Task 3, Epoch 12/34 => Loss 3.887, Loss_clf 0.854, Loss_fe 0.989, Loss_kd 1.579, Train_accy 46.87
2022-10-08 10:06:06,093 [foster.py] => Task 3, Epoch 13/34 => Loss 3.817, Loss_clf 0.823, Loss_fe 0.948, Loss_kd 1.581, Train_accy 45.71
2022-10-08 10:06:08,889 [foster.py] => Task 3, Epoch 14/34 => Loss 3.819, Loss_clf 0.835, Loss_fe 0.943, Loss_kd 1.577, Train_accy 46.14
2022-10-08 10:06:11,781 [foster.py] => Task 3, Epoch 15/34 => Loss 3.765, Loss_clf 0.807, Loss_fe 0.918, Loss_kd 1.577, Train_accy 46.36
2022-10-08 10:06:15,636 [foster.py] => Task 3, Epoch 16/34 => Loss 3.738, Loss_clf 0.794, Loss_fe 0.898, Loss_kd 1.582, Train_accy 47.60, Test_accy 43.56
2022-10-08 10:06:18,443 [foster.py] => Task 3, Epoch 17/34 => Loss 3.720, Loss_clf 0.784, Loss_fe 0.895, Loss_kd 1.577, Train_accy 48.25
2022-10-08 10:06:21,389 [foster.py] => Task 3, Epoch 18/34 => Loss 3.699, Loss_clf 0.765, Loss_fe 0.879, Loss_kd 1.588, Train_accy 46.94
2022-10-08 10:06:24,921 [foster.py] => Task 3, Epoch 19/34 => Loss 3.697, Loss_clf 0.778, Loss_fe 0.870, Loss_kd 1.583, Train_accy 48.76
2022-10-08 10:06:28,223 [foster.py] => Task 3, Epoch 20/34 => Loss 3.686, Loss_clf 0.775, Loss_fe 0.863, Loss_kd 1.583, Train_accy 47.89
2022-10-08 10:06:32,295 [foster.py] => Task 3, Epoch 21/34 => Loss 3.681, Loss_clf 0.774, Loss_fe 0.865, Loss_kd 1.579, Train_accy 47.45, Test_accy 44.36
2022-10-08 10:06:35,274 [foster.py] => Task 3, Epoch 22/34 => Loss 3.614, Loss_clf 0.743, Loss_fe 0.821, Loss_kd 1.584, Train_accy 49.71
2022-10-08 10:06:38,656 [foster.py] => Task 3, Epoch 23/34 => Loss 3.636, Loss_clf 0.757, Loss_fe 0.837, Loss_kd 1.578, Train_accy 48.54
2022-10-08 10:06:41,732 [foster.py] => Task 3, Epoch 24/34 => Loss 3.622, Loss_clf 0.744, Loss_fe 0.831, Loss_kd 1.581, Train_accy 47.89
2022-10-08 10:06:44,894 [foster.py] => Task 3, Epoch 25/34 => Loss 3.612, Loss_clf 0.737, Loss_fe 0.823, Loss_kd 1.586, Train_accy 49.93
2022-10-08 10:06:48,777 [foster.py] => Task 3, Epoch 26/34 => Loss 3.562, Loss_clf 0.719, Loss_fe 0.796, Loss_kd 1.582, Train_accy 49.49, Test_accy 44.55
2022-10-08 10:06:51,582 [foster.py] => Task 3, Epoch 27/34 => Loss 3.582, Loss_clf 0.722, Loss_fe 0.807, Loss_kd 1.586, Train_accy 48.84
2022-10-08 10:06:54,613 [foster.py] => Task 3, Epoch 28/34 => Loss 3.591, Loss_clf 0.730, Loss_fe 0.816, Loss_kd 1.581, Train_accy 48.91
2022-10-08 10:06:57,615 [foster.py] => Task 3, Epoch 29/34 => Loss 3.568, Loss_clf 0.727, Loss_fe 0.795, Loss_kd 1.581, Train_accy 49.56
2022-10-08 10:07:00,556 [foster.py] => Task 3, Epoch 30/34 => Loss 3.576, Loss_clf 0.723, Loss_fe 0.809, Loss_kd 1.580, Train_accy 49.64
2022-10-08 10:07:05,576 [foster.py] => Task 3, Epoch 31/34 => Loss 3.564, Loss_clf 0.724, Loss_fe 0.793, Loss_kd 1.581, Train_accy 50.00, Test_accy 43.96
2022-10-08 10:07:10,870 [foster.py] => Task 3, Epoch 32/34 => Loss 3.588, Loss_clf 0.733, Loss_fe 0.808, Loss_kd 1.582, Train_accy 48.76
2022-10-08 10:07:14,158 [foster.py] => Task 3, Epoch 33/34 => Loss 3.586, Loss_clf 0.728, Loss_fe 0.806, Loss_kd 1.586, Train_accy 50.15
2022-10-08 10:07:17,013 [foster.py] => Task 3, Epoch 34/34 => Loss 3.575, Loss_clf 0.720, Loss_fe 0.803, Loss_kd 1.586, Train_accy 49.64
2022-10-08 10:07:17,013 [foster.py] => do not weight align teacher!
2022-10-08 10:07:17,014 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 10:07:21,289 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.516,  Train_accy 11.06, Test_accy 27.92
2022-10-08 10:07:24,573 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.474,  Train_accy 11.57
2022-10-08 10:07:27,887 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.441,  Train_accy 12.15
2022-10-08 10:07:32,501 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.431,  Train_accy 11.50
2022-10-08 10:07:36,452 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.424,  Train_accy 12.15
2022-10-08 10:07:40,903 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.412,  Train_accy 12.30, Test_accy 29.90
2022-10-08 10:07:44,191 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.407,  Train_accy 12.52
2022-10-08 10:07:47,558 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.398,  Train_accy 12.95
2022-10-08 10:07:50,902 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.395,  Train_accy 12.59
2022-10-08 10:07:54,371 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.396,  Train_accy 13.46
2022-10-08 10:07:58,740 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.385,  Train_accy 14.56, Test_accy 31.68
2022-10-08 10:08:02,022 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.379,  Train_accy 13.83
2022-10-08 10:08:05,598 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.378,  Train_accy 15.28
2022-10-08 10:08:09,132 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.370,  Train_accy 15.65
2022-10-08 10:08:12,680 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.374,  Train_accy 15.94
2022-10-08 10:08:17,138 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.371,  Train_accy 15.57, Test_accy 33.07
2022-10-08 10:08:20,462 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.376,  Train_accy 15.14
2022-10-08 10:08:23,834 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.368,  Train_accy 16.59
2022-10-08 10:08:27,351 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.369,  Train_accy 15.72
2022-10-08 10:08:30,835 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.366,  Train_accy 16.01
2022-10-08 10:08:39,885 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.371,  Train_accy 17.76, Test_accy 32.48
2022-10-08 10:08:43,288 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.372,  Train_accy 16.01
2022-10-08 10:08:46,488 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.368,  Train_accy 16.74
2022-10-08 10:08:49,658 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.362,  Train_accy 15.65
2022-10-08 10:08:53,015 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.365,  Train_accy 16.52
2022-10-08 10:08:57,128 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.370,  Train_accy 16.59, Test_accy 32.67
2022-10-08 10:08:57,129 [foster.py] => do not weight align student!
2022-10-08 10:08:57,956 [foster.py] => darknet eval: 
2022-10-08 10:08:57,956 [foster.py] => CNN top1 curve: 32.67
2022-10-08 10:08:57,956 [foster.py] => CNN top5 curve: 82.77
2022-10-08 10:08:57,956 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 10:09:09,116 [foster.py] => Exemplar size: 440
2022-10-08 10:09:09,116 [trainer.py] => CNN: {'total': 44.95, 'old': 46.55, 'new': 39.47, 'base': 78.47, 'compound': 31.58}
2022-10-08 10:09:09,116 [trainer.py] => CNN top1 curve: [87.5, 55.2, 45.27, 44.95]
2022-10-08 10:09:09,116 [trainer.py] => CNN base curve: [87.5, 84.03, 81.94, 78.47]
2022-10-08 10:09:09,116 [trainer.py] => CNN old curve: [87.5, 84.03, 49.82, 46.55]
2022-10-08 10:09:09,116 [trainer.py] => CNN new curve: [0, 24.44, 33.93, 39.47]
2022-10-08 10:09:09,116 [trainer.py] => CNN compound curve: [0, 24.44, 23.89, 31.58]
2022-10-08 10:09:09,116 [trainer.py] => NME: {'total': 52.87, 'old': 53.2, 'new': 51.75, 'base': 69.44, 'compound': 46.26}
2022-10-08 10:09:09,116 [trainer.py] => NME top1 curve: [88.89, 65.95, 57.03, 52.87]
2022-10-08 10:09:09,116 [trainer.py] => NME base curve: [88.89, 82.64, 71.53, 69.44]
2022-10-08 10:09:09,116 [trainer.py] => NME old curve: [88.89, 82.64, 54.12, 53.2]
2022-10-08 10:09:09,116 [trainer.py] => NME new curve: [0, 48.15, 64.29, 51.75]
2022-10-08 10:09:09,116 [trainer.py] => NME compound curve: [0, 48.15, 48.58, 46.26]
2022-10-08 10:09:09,117 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 10:09:09,117 [trainer.py] => prefix: cil
2022-10-08 10:09:09,117 [trainer.py] => dataset: CFEE
2022-10-08 10:09:09,117 [trainer.py] => memory_size: 2000
2022-10-08 10:09:09,117 [trainer.py] => memory_per_class: 20
2022-10-08 10:09:09,118 [trainer.py] => fixed_memory: True
2022-10-08 10:09:09,118 [trainer.py] => shuffle: True
2022-10-08 10:09:09,118 [trainer.py] => init_cls: 7
2022-10-08 10:09:09,118 [trainer.py] => increment: 5
2022-10-08 10:09:09,118 [trainer.py] => model_name: foster
2022-10-08 10:09:09,118 [trainer.py] => convnet_type: resnet18
2022-10-08 10:09:09,118 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 10:09:09,118 [trainer.py] => seed: 1993
2022-10-08 10:09:09,118 [trainer.py] => beta1: 0.96
2022-10-08 10:09:09,118 [trainer.py] => beta2: 0.97
2022-10-08 10:09:09,118 [trainer.py] => oofc: ft
2022-10-08 10:09:09,118 [trainer.py] => is_teacher_wa: False
2022-10-08 10:09:09,118 [trainer.py] => is_student_wa: False
2022-10-08 10:09:09,118 [trainer.py] => lambda_okd: 1
2022-10-08 10:09:09,118 [trainer.py] => wa_value: 1
2022-10-08 10:09:09,118 [trainer.py] => init_epochs: 40
2022-10-08 10:09:09,118 [trainer.py] => init_lr: 0.01
2022-10-08 10:09:09,118 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 10:09:09,118 [trainer.py] => boosting_epochs: 34
2022-10-08 10:09:09,118 [trainer.py] => compression_epochs: 26
2022-10-08 10:09:09,118 [trainer.py] => lr: 0.001
2022-10-08 10:09:09,118 [trainer.py] => batch_size: 32
2022-10-08 10:09:09,118 [trainer.py] => weight_decay: 0.0005
2022-10-08 10:09:09,118 [trainer.py] => num_workers: 8
2022-10-08 10:09:09,118 [trainer.py] => T: 2
2022-10-08 10:09:09,118 [trainer.py] => nb_runs: 3
2022-10-08 10:09:09,118 [trainer.py] => fold: 10
2022-10-08 10:09:09,119 [data.py] => ========== Fold:5 ==========
2022-10-08 10:09:09,124 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 12, 10, 19, 21, 17, 18, 8, 7, 9, 14, 15, 13, 11, 16]
2022-10-08 10:09:09,342 [foster.py] => Learning on 0-7
2022-10-08 10:09:09,342 [foster.py] => All params: 11183694
2022-10-08 10:09:09,342 [foster.py] => Trainable params: 11183694
2022-10-08 10:09:11,709 [foster.py] => Task 0, Epoch 1/40 => Loss 1.352, Train_accy 52.29
2022-10-08 10:09:14,636 [foster.py] => Task 0, Epoch 2/40 => Loss 0.575, Train_accy 80.46, Test_accy 84.62
2022-10-08 10:09:17,618 [foster.py] => Task 0, Epoch 3/40 => Loss 0.355, Train_accy 87.83, Test_accy 86.39
2022-10-08 10:09:20,535 [foster.py] => Task 0, Epoch 4/40 => Loss 0.302, Train_accy 89.92, Test_accy 85.21
2022-10-08 10:09:23,491 [foster.py] => Task 0, Epoch 5/40 => Loss 0.228, Train_accy 91.72, Test_accy 89.35
2022-10-08 10:09:25,871 [foster.py] => Task 0, Epoch 6/40 => Loss 0.195, Train_accy 94.02
2022-10-08 10:09:28,832 [foster.py] => Task 0, Epoch 7/40 => Loss 0.170, Train_accy 94.51, Test_accy 88.17
2022-10-08 10:09:31,774 [foster.py] => Task 0, Epoch 8/40 => Loss 0.129, Train_accy 95.83, Test_accy 90.53
2022-10-08 10:09:34,786 [foster.py] => Task 0, Epoch 9/40 => Loss 0.109, Train_accy 97.01, Test_accy 89.94
2022-10-08 10:09:37,787 [foster.py] => Task 0, Epoch 10/40 => Loss 0.086, Train_accy 97.57, Test_accy 87.57
2022-10-08 10:09:40,152 [foster.py] => Task 0, Epoch 11/40 => Loss 0.086, Train_accy 97.64
2022-10-08 10:09:43,242 [foster.py] => Task 0, Epoch 12/40 => Loss 0.078, Train_accy 97.91, Test_accy 89.94
2022-10-08 10:09:47,532 [foster.py] => Task 0, Epoch 13/40 => Loss 0.049, Train_accy 99.10, Test_accy 89.35
2022-10-08 10:09:50,578 [foster.py] => Task 0, Epoch 14/40 => Loss 0.051, Train_accy 98.68, Test_accy 89.94
2022-10-08 10:09:53,557 [foster.py] => Task 0, Epoch 15/40 => Loss 0.046, Train_accy 98.75, Test_accy 88.17
2022-10-08 10:09:55,995 [foster.py] => Task 0, Epoch 16/40 => Loss 0.046, Train_accy 98.61
2022-10-08 10:09:58,947 [foster.py] => Task 0, Epoch 17/40 => Loss 0.032, Train_accy 99.37, Test_accy 89.94
2022-10-08 10:10:01,939 [foster.py] => Task 0, Epoch 18/40 => Loss 0.030, Train_accy 99.24, Test_accy 88.76
2022-10-08 10:10:04,938 [foster.py] => Task 0, Epoch 19/40 => Loss 0.034, Train_accy 99.30, Test_accy 89.35
2022-10-08 10:10:07,914 [foster.py] => Task 0, Epoch 20/40 => Loss 0.031, Train_accy 99.10, Test_accy 86.39
2022-10-08 10:10:10,279 [foster.py] => Task 0, Epoch 21/40 => Loss 0.033, Train_accy 99.24
2022-10-08 10:10:13,210 [foster.py] => Task 0, Epoch 22/40 => Loss 0.022, Train_accy 99.79, Test_accy 88.17
2022-10-08 10:10:16,283 [foster.py] => Task 0, Epoch 23/40 => Loss 0.021, Train_accy 99.58, Test_accy 89.35
2022-10-08 10:10:19,831 [foster.py] => Task 0, Epoch 24/40 => Loss 0.018, Train_accy 99.72, Test_accy 89.35
2022-10-08 10:10:22,814 [foster.py] => Task 0, Epoch 25/40 => Loss 0.020, Train_accy 99.65, Test_accy 91.12
2022-10-08 10:10:25,192 [foster.py] => Task 0, Epoch 26/40 => Loss 0.016, Train_accy 99.93
2022-10-08 10:10:28,180 [foster.py] => Task 0, Epoch 27/40 => Loss 0.016, Train_accy 99.65, Test_accy 91.12
2022-10-08 10:10:31,186 [foster.py] => Task 0, Epoch 28/40 => Loss 0.017, Train_accy 99.86, Test_accy 89.35
2022-10-08 10:10:34,138 [foster.py] => Task 0, Epoch 29/40 => Loss 0.014, Train_accy 99.86, Test_accy 89.35
2022-10-08 10:10:37,085 [foster.py] => Task 0, Epoch 30/40 => Loss 0.012, Train_accy 99.79, Test_accy 89.94
2022-10-08 10:10:39,475 [foster.py] => Task 0, Epoch 31/40 => Loss 0.012, Train_accy 99.93
2022-10-08 10:10:42,507 [foster.py] => Task 0, Epoch 32/40 => Loss 0.012, Train_accy 99.86, Test_accy 89.35
2022-10-08 10:10:47,328 [foster.py] => Task 0, Epoch 33/40 => Loss 0.013, Train_accy 99.93, Test_accy 88.76
2022-10-08 10:10:50,407 [foster.py] => Task 0, Epoch 34/40 => Loss 0.012, Train_accy 100.00, Test_accy 89.94
2022-10-08 10:10:53,342 [foster.py] => Task 0, Epoch 35/40 => Loss 0.013, Train_accy 100.00, Test_accy 89.35
2022-10-08 10:10:55,695 [foster.py] => Task 0, Epoch 36/40 => Loss 0.011, Train_accy 99.93
2022-10-08 10:10:58,657 [foster.py] => Task 0, Epoch 37/40 => Loss 0.012, Train_accy 99.93, Test_accy 90.53
2022-10-08 10:11:01,612 [foster.py] => Task 0, Epoch 38/40 => Loss 0.014, Train_accy 99.72, Test_accy 89.35
2022-10-08 10:11:04,594 [foster.py] => Task 0, Epoch 39/40 => Loss 0.011, Train_accy 99.86, Test_accy 89.94
2022-10-08 10:11:07,582 [foster.py] => Task 0, Epoch 40/40 => Loss 0.012, Train_accy 99.86, Test_accy 89.94
2022-10-08 10:11:07,583 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 10:11:14,040 [foster.py] => Exemplar size: 140
2022-10-08 10:11:14,041 [trainer.py] => CNN: {'total': 89.94, 'old': 89.94, 'new': 0, 'base': 89.94, 'compound': 0}
2022-10-08 10:11:14,041 [trainer.py] => CNN top1 curve: [89.94]
2022-10-08 10:11:14,041 [trainer.py] => CNN base curve: [89.94]
2022-10-08 10:11:14,041 [trainer.py] => CNN old curve: [89.94]
2022-10-08 10:11:14,041 [trainer.py] => CNN new curve: [0]
2022-10-08 10:11:14,041 [trainer.py] => CNN compound curve: [0]
2022-10-08 10:11:14,041 [trainer.py] => NME: {'total': 89.35, 'old': 89.35, 'new': 0, 'base': 89.35, 'compound': 0}
2022-10-08 10:11:14,041 [trainer.py] => NME top1 curve: [89.35]
2022-10-08 10:11:14,041 [trainer.py] => NME base curve: [89.35]
2022-10-08 10:11:14,041 [trainer.py] => NME old curve: [89.35]
2022-10-08 10:11:14,041 [trainer.py] => NME new curve: [0]
2022-10-08 10:11:14,041 [trainer.py] => NME compound curve: [0]
2022-10-08 10:11:14,266 [foster.py] => Learning on 7-12
2022-10-08 10:11:14,266 [foster.py] => All params: 22375071
2022-10-08 10:11:14,266 [foster.py] => Trainable params: 11194968
2022-10-08 10:11:14,275 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 10:11:17,417 [foster.py] => Task 1, Epoch 1/34 => Loss 5.290, Loss_clf 2.533, Loss_fe 2.142, Loss_kd 0.359, Train_accy 26.27, Test_accy 55.52
2022-10-08 10:11:19,821 [foster.py] => Task 1, Epoch 2/34 => Loss 3.261, Loss_clf 1.129, Loss_fe 1.554, Loss_kd 0.337, Train_accy 44.29
2022-10-08 10:11:22,256 [foster.py] => Task 1, Epoch 3/34 => Loss 2.857, Loss_clf 0.953, Loss_fe 1.347, Loss_kd 0.325, Train_accy 35.79
2022-10-08 10:11:24,633 [foster.py] => Task 1, Epoch 4/34 => Loss 2.659, Loss_clf 0.886, Loss_fe 1.222, Loss_kd 0.321, Train_accy 35.88
2022-10-08 10:11:27,074 [foster.py] => Task 1, Epoch 5/34 => Loss 2.589, Loss_clf 0.877, Loss_fe 1.162, Loss_kd 0.321, Train_accy 38.97
2022-10-08 10:11:30,305 [foster.py] => Task 1, Epoch 6/34 => Loss 2.498, Loss_clf 0.851, Loss_fe 1.096, Loss_kd 0.321, Train_accy 37.25, Test_accy 59.31
2022-10-08 10:11:32,744 [foster.py] => Task 1, Epoch 7/34 => Loss 2.430, Loss_clf 0.835, Loss_fe 1.049, Loss_kd 0.319, Train_accy 37.17
2022-10-08 10:11:35,179 [foster.py] => Task 1, Epoch 8/34 => Loss 2.385, Loss_clf 0.831, Loss_fe 1.005, Loss_kd 0.321, Train_accy 39.48
2022-10-08 10:11:37,770 [foster.py] => Task 1, Epoch 9/34 => Loss 2.309, Loss_clf 0.785, Loss_fe 0.972, Loss_kd 0.322, Train_accy 38.71
2022-10-08 10:11:40,601 [foster.py] => Task 1, Epoch 10/34 => Loss 2.283, Loss_clf 0.784, Loss_fe 0.948, Loss_kd 0.322, Train_accy 40.34
2022-10-08 10:11:44,246 [foster.py] => Task 1, Epoch 11/34 => Loss 2.155, Loss_clf 0.719, Loss_fe 0.882, Loss_kd 0.323, Train_accy 40.26, Test_accy 59.31
2022-10-08 10:11:46,757 [foster.py] => Task 1, Epoch 12/34 => Loss 2.175, Loss_clf 0.737, Loss_fe 0.898, Loss_kd 0.315, Train_accy 41.97
2022-10-08 10:11:49,412 [foster.py] => Task 1, Epoch 13/34 => Loss 2.126, Loss_clf 0.716, Loss_fe 0.858, Loss_kd 0.321, Train_accy 42.58
2022-10-08 10:11:51,977 [foster.py] => Task 1, Epoch 14/34 => Loss 2.144, Loss_clf 0.728, Loss_fe 0.870, Loss_kd 0.319, Train_accy 40.60
2022-10-08 10:11:54,673 [foster.py] => Task 1, Epoch 15/34 => Loss 2.075, Loss_clf 0.712, Loss_fe 0.820, Loss_kd 0.317, Train_accy 42.92
2022-10-08 10:11:58,149 [foster.py] => Task 1, Epoch 16/34 => Loss 2.033, Loss_clf 0.678, Loss_fe 0.816, Loss_kd 0.315, Train_accy 44.03, Test_accy 59.31
2022-10-08 10:12:00,698 [foster.py] => Task 1, Epoch 17/34 => Loss 2.006, Loss_clf 0.663, Loss_fe 0.802, Loss_kd 0.316, Train_accy 42.83
2022-10-08 10:12:03,272 [foster.py] => Task 1, Epoch 18/34 => Loss 2.016, Loss_clf 0.670, Loss_fe 0.807, Loss_kd 0.314, Train_accy 43.18
2022-10-08 10:12:06,207 [foster.py] => Task 1, Epoch 19/34 => Loss 1.978, Loss_clf 0.663, Loss_fe 0.774, Loss_kd 0.315, Train_accy 44.29
2022-10-08 10:12:09,183 [foster.py] => Task 1, Epoch 20/34 => Loss 1.941, Loss_clf 0.641, Loss_fe 0.761, Loss_kd 0.315, Train_accy 43.95
2022-10-08 10:12:12,919 [foster.py] => Task 1, Epoch 21/34 => Loss 1.915, Loss_clf 0.630, Loss_fe 0.751, Loss_kd 0.312, Train_accy 46.01, Test_accy 60.69
2022-10-08 10:12:15,461 [foster.py] => Task 1, Epoch 22/34 => Loss 1.911, Loss_clf 0.625, Loss_fe 0.742, Loss_kd 0.318, Train_accy 46.09
2022-10-08 10:12:17,989 [foster.py] => Task 1, Epoch 23/34 => Loss 1.911, Loss_clf 0.624, Loss_fe 0.747, Loss_kd 0.315, Train_accy 43.86
2022-10-08 10:12:20,674 [foster.py] => Task 1, Epoch 24/34 => Loss 1.844, Loss_clf 0.595, Loss_fe 0.715, Loss_kd 0.311, Train_accy 45.92
2022-10-08 10:12:23,635 [foster.py] => Task 1, Epoch 25/34 => Loss 1.893, Loss_clf 0.608, Loss_fe 0.731, Loss_kd 0.323, Train_accy 47.55
2022-10-08 10:12:27,375 [foster.py] => Task 1, Epoch 26/34 => Loss 1.852, Loss_clf 0.591, Loss_fe 0.715, Loss_kd 0.319, Train_accy 46.44, Test_accy 60.69
2022-10-08 10:12:29,915 [foster.py] => Task 1, Epoch 27/34 => Loss 1.866, Loss_clf 0.601, Loss_fe 0.719, Loss_kd 0.319, Train_accy 47.04
2022-10-08 10:12:32,476 [foster.py] => Task 1, Epoch 28/34 => Loss 1.814, Loss_clf 0.577, Loss_fe 0.688, Loss_kd 0.321, Train_accy 46.87
2022-10-08 10:12:37,590 [foster.py] => Task 1, Epoch 29/34 => Loss 1.831, Loss_clf 0.583, Loss_fe 0.689, Loss_kd 0.326, Train_accy 47.47
2022-10-08 10:12:41,360 [foster.py] => Task 1, Epoch 30/34 => Loss 1.798, Loss_clf 0.567, Loss_fe 0.686, Loss_kd 0.318, Train_accy 46.61
2022-10-08 10:12:45,196 [foster.py] => Task 1, Epoch 31/34 => Loss 1.816, Loss_clf 0.581, Loss_fe 0.694, Loss_kd 0.315, Train_accy 45.67, Test_accy 60.00
2022-10-08 10:12:47,652 [foster.py] => Task 1, Epoch 32/34 => Loss 1.810, Loss_clf 0.565, Loss_fe 0.694, Loss_kd 0.321, Train_accy 46.52
2022-10-08 10:12:50,043 [foster.py] => Task 1, Epoch 33/34 => Loss 1.827, Loss_clf 0.577, Loss_fe 0.700, Loss_kd 0.321, Train_accy 46.95
2022-10-08 10:12:52,500 [foster.py] => Task 1, Epoch 34/34 => Loss 1.846, Loss_clf 0.589, Loss_fe 0.710, Loss_kd 0.319, Train_accy 45.67
2022-10-08 10:12:52,500 [foster.py] => do not weight align teacher!
2022-10-08 10:12:52,501 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 10:12:56,232 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.911,  Train_accy 11.50, Test_accy 50.00
2022-10-08 10:12:59,013 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.680,  Train_accy 11.76
2022-10-08 10:13:01,893 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.583,  Train_accy 12.36
2022-10-08 10:13:05,435 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.561,  Train_accy 12.36
2022-10-08 10:13:08,742 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.527,  Train_accy 13.22
2022-10-08 10:13:12,507 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.513,  Train_accy 14.16, Test_accy 51.72
2022-10-08 10:13:15,388 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.513,  Train_accy 13.99
2022-10-08 10:13:18,320 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.499,  Train_accy 14.25
2022-10-08 10:13:21,295 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.488,  Train_accy 14.51
2022-10-08 10:13:24,261 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.479,  Train_accy 15.71
2022-10-08 10:13:32,604 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.480,  Train_accy 15.19, Test_accy 53.45
2022-10-08 10:13:35,620 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.484,  Train_accy 15.19
2022-10-08 10:13:38,515 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.473,  Train_accy 15.88
2022-10-08 10:13:41,351 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.468,  Train_accy 15.62
2022-10-08 10:13:44,142 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.468,  Train_accy 15.97
2022-10-08 10:13:47,835 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.465,  Train_accy 15.71, Test_accy 54.14
2022-10-08 10:13:50,725 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.465,  Train_accy 15.88
2022-10-08 10:13:57,307 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.469,  Train_accy 16.65
2022-10-08 10:14:01,111 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.456,  Train_accy 16.48
2022-10-08 10:14:04,358 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.464,  Train_accy 16.48
2022-10-08 10:14:07,884 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.452,  Train_accy 16.39, Test_accy 53.79
2022-10-08 10:14:10,708 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.454,  Train_accy 16.57
2022-10-08 10:14:13,524 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.458,  Train_accy 16.14
2022-10-08 10:14:16,440 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.466,  Train_accy 15.97
2022-10-08 10:14:19,356 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.449,  Train_accy 16.22
2022-10-08 10:14:22,975 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.449,  Train_accy 16.05, Test_accy 53.79
2022-10-08 10:14:22,975 [foster.py] => do not weight align student!
2022-10-08 10:14:23,655 [foster.py] => darknet eval: 
2022-10-08 10:14:23,655 [foster.py] => CNN top1 curve: 53.79
2022-10-08 10:14:23,655 [foster.py] => CNN top5 curve: 97.93
2022-10-08 10:14:23,656 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 10:14:31,486 [foster.py] => Exemplar size: 240
2022-10-08 10:14:31,486 [trainer.py] => CNN: {'total': 60.0, 'old': 84.02, 'new': 26.45, 'base': 84.02, 'compound': 26.45}
2022-10-08 10:14:31,486 [trainer.py] => CNN top1 curve: [89.94, 60.0]
2022-10-08 10:14:31,486 [trainer.py] => CNN base curve: [89.94, 84.02]
2022-10-08 10:14:31,486 [trainer.py] => CNN old curve: [89.94, 84.02]
2022-10-08 10:14:31,486 [trainer.py] => CNN new curve: [0, 26.45]
2022-10-08 10:14:31,486 [trainer.py] => CNN compound curve: [0, 26.45]
2022-10-08 10:14:31,486 [trainer.py] => NME: {'total': 67.24, 'old': 82.84, 'new': 45.45, 'base': 82.84, 'compound': 45.45}
2022-10-08 10:14:31,486 [trainer.py] => NME top1 curve: [89.35, 67.24]
2022-10-08 10:14:31,486 [trainer.py] => NME base curve: [89.35, 82.84]
2022-10-08 10:14:31,486 [trainer.py] => NME old curve: [89.35, 82.84]
2022-10-08 10:14:31,486 [trainer.py] => NME new curve: [0, 45.45]
2022-10-08 10:14:31,486 [trainer.py] => NME compound curve: [0, 45.45]
2022-10-08 10:14:31,711 [foster.py] => Learning on 12-17
2022-10-08 10:14:31,712 [foster.py] => All params: 22385326
2022-10-08 10:14:31,712 [foster.py] => Trainable params: 11202658
2022-10-08 10:14:31,721 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 10:14:35,130 [foster.py] => Task 2, Epoch 1/34 => Loss 5.457, Loss_clf 1.893, Loss_fe 2.150, Loss_kd 0.997, Train_accy 39.36, Test_accy 47.51
2022-10-08 10:14:37,743 [foster.py] => Task 2, Epoch 2/34 => Loss 3.616, Loss_clf 0.854, Loss_fe 1.402, Loss_kd 0.961, Train_accy 37.55
2022-10-08 10:14:40,302 [foster.py] => Task 2, Epoch 3/34 => Loss 3.346, Loss_clf 0.766, Loss_fe 1.213, Loss_kd 0.965, Train_accy 38.49
2022-10-08 10:14:42,900 [foster.py] => Task 2, Epoch 4/34 => Loss 3.183, Loss_clf 0.708, Loss_fe 1.097, Loss_kd 0.972, Train_accy 38.02
2022-10-08 10:14:45,508 [foster.py] => Task 2, Epoch 5/34 => Loss 3.065, Loss_clf 0.680, Loss_fe 1.023, Loss_kd 0.961, Train_accy 39.04
2022-10-08 10:14:48,968 [foster.py] => Task 2, Epoch 6/34 => Loss 2.989, Loss_clf 0.658, Loss_fe 0.952, Loss_kd 0.973, Train_accy 37.39, Test_accy 48.26
2022-10-08 10:14:51,550 [foster.py] => Task 2, Epoch 7/34 => Loss 2.944, Loss_clf 0.653, Loss_fe 0.924, Loss_kd 0.965, Train_accy 37.94
2022-10-08 10:14:57,312 [foster.py] => Task 2, Epoch 8/34 => Loss 2.854, Loss_clf 0.618, Loss_fe 0.855, Loss_kd 0.974, Train_accy 39.12
2022-10-08 10:15:01,009 [foster.py] => Task 2, Epoch 9/34 => Loss 2.830, Loss_clf 0.618, Loss_fe 0.841, Loss_kd 0.967, Train_accy 39.59
2022-10-08 10:15:04,315 [foster.py] => Task 2, Epoch 10/34 => Loss 2.767, Loss_clf 0.596, Loss_fe 0.802, Loss_kd 0.966, Train_accy 41.24
2022-10-08 10:15:08,259 [foster.py] => Task 2, Epoch 11/34 => Loss 2.745, Loss_clf 0.590, Loss_fe 0.783, Loss_kd 0.968, Train_accy 40.22, Test_accy 50.00
2022-10-08 10:15:10,964 [foster.py] => Task 2, Epoch 12/34 => Loss 2.677, Loss_clf 0.569, Loss_fe 0.749, Loss_kd 0.959, Train_accy 40.30
2022-10-08 10:15:13,623 [foster.py] => Task 2, Epoch 13/34 => Loss 2.692, Loss_clf 0.580, Loss_fe 0.742, Loss_kd 0.968, Train_accy 40.61
2022-10-08 10:15:16,230 [foster.py] => Task 2, Epoch 14/34 => Loss 2.665, Loss_clf 0.568, Loss_fe 0.726, Loss_kd 0.968, Train_accy 41.48
2022-10-08 10:15:18,846 [foster.py] => Task 2, Epoch 15/34 => Loss 2.617, Loss_clf 0.551, Loss_fe 0.699, Loss_kd 0.965, Train_accy 41.87
2022-10-08 10:15:22,680 [foster.py] => Task 2, Epoch 16/34 => Loss 2.623, Loss_clf 0.542, Loss_fe 0.692, Loss_kd 0.981, Train_accy 43.21, Test_accy 49.50
2022-10-08 10:15:25,311 [foster.py] => Task 2, Epoch 17/34 => Loss 2.600, Loss_clf 0.538, Loss_fe 0.687, Loss_kd 0.971, Train_accy 42.18
2022-10-08 10:15:27,979 [foster.py] => Task 2, Epoch 18/34 => Loss 2.556, Loss_clf 0.518, Loss_fe 0.660, Loss_kd 0.973, Train_accy 42.03
2022-10-08 10:15:30,723 [foster.py] => Task 2, Epoch 19/34 => Loss 2.547, Loss_clf 0.525, Loss_fe 0.649, Loss_kd 0.970, Train_accy 43.13
2022-10-08 10:15:33,429 [foster.py] => Task 2, Epoch 20/34 => Loss 2.498, Loss_clf 0.508, Loss_fe 0.623, Loss_kd 0.965, Train_accy 41.79
2022-10-08 10:15:37,119 [foster.py] => Task 2, Epoch 21/34 => Loss 2.511, Loss_clf 0.500, Loss_fe 0.631, Loss_kd 0.974, Train_accy 42.89, Test_accy 50.00
2022-10-08 10:15:39,770 [foster.py] => Task 2, Epoch 22/34 => Loss 2.497, Loss_clf 0.501, Loss_fe 0.627, Loss_kd 0.967, Train_accy 41.56
2022-10-08 10:15:42,629 [foster.py] => Task 2, Epoch 23/34 => Loss 2.494, Loss_clf 0.508, Loss_fe 0.620, Loss_kd 0.963, Train_accy 43.05
2022-10-08 10:15:45,484 [foster.py] => Task 2, Epoch 24/34 => Loss 2.467, Loss_clf 0.493, Loss_fe 0.604, Loss_kd 0.967, Train_accy 44.54
2022-10-08 10:15:48,267 [foster.py] => Task 2, Epoch 25/34 => Loss 2.473, Loss_clf 0.495, Loss_fe 0.608, Loss_kd 0.968, Train_accy 42.73
2022-10-08 10:15:51,996 [foster.py] => Task 2, Epoch 26/34 => Loss 2.472, Loss_clf 0.493, Loss_fe 0.601, Loss_kd 0.972, Train_accy 43.99, Test_accy 50.00
2022-10-08 10:15:54,755 [foster.py] => Task 2, Epoch 27/34 => Loss 2.460, Loss_clf 0.493, Loss_fe 0.597, Loss_kd 0.967, Train_accy 42.89
2022-10-08 10:15:57,460 [foster.py] => Task 2, Epoch 28/34 => Loss 2.462, Loss_clf 0.486, Loss_fe 0.605, Loss_kd 0.967, Train_accy 44.30
2022-10-08 10:16:04,526 [foster.py] => Task 2, Epoch 29/34 => Loss 2.431, Loss_clf 0.477, Loss_fe 0.589, Loss_kd 0.963, Train_accy 43.44
2022-10-08 10:16:07,709 [foster.py] => Task 2, Epoch 30/34 => Loss 2.457, Loss_clf 0.483, Loss_fe 0.595, Loss_kd 0.973, Train_accy 44.07
2022-10-08 10:16:11,509 [foster.py] => Task 2, Epoch 31/34 => Loss 2.421, Loss_clf 0.473, Loss_fe 0.584, Loss_kd 0.963, Train_accy 43.28, Test_accy 50.00
2022-10-08 10:16:14,207 [foster.py] => Task 2, Epoch 32/34 => Loss 2.426, Loss_clf 0.468, Loss_fe 0.579, Loss_kd 0.973, Train_accy 44.23
2022-10-08 10:16:16,876 [foster.py] => Task 2, Epoch 33/34 => Loss 2.446, Loss_clf 0.480, Loss_fe 0.594, Loss_kd 0.969, Train_accy 41.87
2022-10-08 10:16:19,489 [foster.py] => Task 2, Epoch 34/34 => Loss 2.445, Loss_clf 0.479, Loss_fe 0.593, Loss_kd 0.969, Train_accy 43.13
2022-10-08 10:16:19,490 [foster.py] => do not weight align teacher!
2022-10-08 10:16:19,490 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 10:16:23,511 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.112,  Train_accy 10.84, Test_accy 38.06
2022-10-08 10:16:26,587 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.969,  Train_accy 11.15
2022-10-08 10:16:33,740 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.944,  Train_accy 11.39
2022-10-08 10:16:37,935 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.926,  Train_accy 11.70
2022-10-08 10:16:41,473 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.905,  Train_accy 11.55
2022-10-08 10:16:45,572 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.889,  Train_accy 11.94, Test_accy 40.30
2022-10-08 10:16:48,511 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.881,  Train_accy 11.63
2022-10-08 10:16:51,513 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.872,  Train_accy 11.63
2022-10-08 10:16:54,973 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.874,  Train_accy 11.70
2022-10-08 10:16:58,241 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.868,  Train_accy 12.33
2022-10-08 10:17:02,102 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.854,  Train_accy 12.18, Test_accy 41.04
2022-10-08 10:17:05,147 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.847,  Train_accy 13.28
2022-10-08 10:17:08,347 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.840,  Train_accy 13.20
2022-10-08 10:17:11,620 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.839,  Train_accy 13.04
2022-10-08 10:17:14,911 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.830,  Train_accy 12.57
2022-10-08 10:17:22,808 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.837,  Train_accy 13.51, Test_accy 40.80
2022-10-08 10:17:26,043 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.829,  Train_accy 12.88
2022-10-08 10:17:29,093 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.826,  Train_accy 13.35
2022-10-08 10:17:32,152 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.842,  Train_accy 13.98
2022-10-08 10:17:35,175 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.830,  Train_accy 13.75
2022-10-08 10:17:39,105 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.830,  Train_accy 14.38, Test_accy 40.80
2022-10-08 10:17:42,183 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.821,  Train_accy 13.59
2022-10-08 10:17:45,358 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.835,  Train_accy 13.35
2022-10-08 10:17:48,591 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.834,  Train_accy 14.22
2022-10-08 10:17:51,997 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.824,  Train_accy 13.75
2022-10-08 10:17:56,298 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.826,  Train_accy 14.22, Test_accy 41.29
2022-10-08 10:17:56,299 [foster.py] => do not weight align student!
2022-10-08 10:17:57,030 [foster.py] => darknet eval: 
2022-10-08 10:17:57,030 [foster.py] => CNN top1 curve: 41.29
2022-10-08 10:17:57,030 [foster.py] => CNN top5 curve: 89.55
2022-10-08 10:17:57,030 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 10:18:06,431 [foster.py] => Exemplar size: 340
2022-10-08 10:18:06,431 [trainer.py] => CNN: {'total': 50.0, 'old': 54.83, 'new': 37.5, 'base': 83.43, 'compound': 25.75}
2022-10-08 10:18:06,431 [trainer.py] => CNN top1 curve: [89.94, 60.0, 50.0]
2022-10-08 10:18:06,431 [trainer.py] => CNN base curve: [89.94, 84.02, 83.43]
2022-10-08 10:18:06,431 [trainer.py] => CNN old curve: [89.94, 84.02, 54.83]
2022-10-08 10:18:06,431 [trainer.py] => CNN new curve: [0, 26.45, 37.5]
2022-10-08 10:18:06,431 [trainer.py] => CNN compound curve: [0, 26.45, 25.75]
2022-10-08 10:18:06,431 [trainer.py] => NME: {'total': 58.46, 'old': 55.86, 'new': 65.18, 'base': 71.6, 'compound': 48.93}
2022-10-08 10:18:06,431 [trainer.py] => NME top1 curve: [89.35, 67.24, 58.46]
2022-10-08 10:18:06,432 [trainer.py] => NME base curve: [89.35, 82.84, 71.6]
2022-10-08 10:18:06,432 [trainer.py] => NME old curve: [89.35, 82.84, 55.86]
2022-10-08 10:18:06,432 [trainer.py] => NME new curve: [0, 45.45, 65.18]
2022-10-08 10:18:06,432 [trainer.py] => NME compound curve: [0, 45.45, 48.93]
2022-10-08 10:18:06,657 [foster.py] => Learning on 17-22
2022-10-08 10:18:06,657 [foster.py] => All params: 22395581
2022-10-08 10:18:06,658 [foster.py] => Trainable params: 11210348
2022-10-08 10:18:06,667 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 10:18:10,408 [foster.py] => Task 3, Epoch 1/34 => Loss 6.852, Loss_clf 2.237, Loss_fe 2.564, Loss_kd 1.585, Train_accy 32.64, Test_accy 37.43
2022-10-08 10:18:13,180 [foster.py] => Task 3, Epoch 2/34 => Loss 5.033, Loss_clf 1.202, Loss_fe 1.811, Loss_kd 1.561, Train_accy 39.35
2022-10-08 10:18:15,921 [foster.py] => Task 3, Epoch 3/34 => Loss 4.673, Loss_clf 1.089, Loss_fe 1.553, Loss_kd 1.569, Train_accy 41.52
2022-10-08 10:18:18,697 [foster.py] => Task 3, Epoch 4/34 => Loss 4.457, Loss_clf 1.018, Loss_fe 1.406, Loss_kd 1.571, Train_accy 41.81
2022-10-08 10:18:21,497 [foster.py] => Task 3, Epoch 5/34 => Loss 4.358, Loss_clf 1.015, Loss_fe 1.327, Loss_kd 1.558, Train_accy 41.81
2022-10-08 10:18:28,825 [foster.py] => Task 3, Epoch 6/34 => Loss 4.213, Loss_clf 0.945, Loss_fe 1.239, Loss_kd 1.568, Train_accy 44.19, Test_accy 42.77
2022-10-08 10:18:31,696 [foster.py] => Task 3, Epoch 7/34 => Loss 4.151, Loss_clf 0.938, Loss_fe 1.189, Loss_kd 1.564, Train_accy 43.83
2022-10-08 10:18:34,544 [foster.py] => Task 3, Epoch 8/34 => Loss 4.055, Loss_clf 0.912, Loss_fe 1.122, Loss_kd 1.561, Train_accy 44.19
2022-10-08 10:18:37,382 [foster.py] => Task 3, Epoch 9/34 => Loss 4.005, Loss_clf 0.895, Loss_fe 1.083, Loss_kd 1.566, Train_accy 45.27
2022-10-08 10:18:40,103 [foster.py] => Task 3, Epoch 10/34 => Loss 3.940, Loss_clf 0.863, Loss_fe 1.048, Loss_kd 1.567, Train_accy 46.06
2022-10-08 10:18:43,823 [foster.py] => Task 3, Epoch 11/34 => Loss 3.856, Loss_clf 0.838, Loss_fe 1.003, Loss_kd 1.557, Train_accy 43.54, Test_accy 45.15
2022-10-08 10:18:46,613 [foster.py] => Task 3, Epoch 12/34 => Loss 3.856, Loss_clf 0.844, Loss_fe 0.984, Loss_kd 1.567, Train_accy 45.92
2022-10-08 10:18:49,409 [foster.py] => Task 3, Epoch 13/34 => Loss 3.794, Loss_clf 0.811, Loss_fe 0.952, Loss_kd 1.569, Train_accy 44.62
2022-10-08 10:18:52,351 [foster.py] => Task 3, Epoch 14/34 => Loss 3.766, Loss_clf 0.801, Loss_fe 0.931, Loss_kd 1.572, Train_accy 46.86
2022-10-08 10:18:55,552 [foster.py] => Task 3, Epoch 15/34 => Loss 3.772, Loss_clf 0.808, Loss_fe 0.931, Loss_kd 1.571, Train_accy 46.50
2022-10-08 10:18:59,528 [foster.py] => Task 3, Epoch 16/34 => Loss 3.727, Loss_clf 0.786, Loss_fe 0.908, Loss_kd 1.571, Train_accy 45.42, Test_accy 46.53
2022-10-08 10:19:02,531 [foster.py] => Task 3, Epoch 17/34 => Loss 3.684, Loss_clf 0.775, Loss_fe 0.879, Loss_kd 1.569, Train_accy 47.94
2022-10-08 10:19:05,697 [foster.py] => Task 3, Epoch 18/34 => Loss 3.667, Loss_clf 0.760, Loss_fe 0.876, Loss_kd 1.569, Train_accy 47.87
2022-10-08 10:19:08,899 [foster.py] => Task 3, Epoch 19/34 => Loss 3.634, Loss_clf 0.756, Loss_fe 0.853, Loss_kd 1.564, Train_accy 46.79
2022-10-08 10:19:12,070 [foster.py] => Task 3, Epoch 20/34 => Loss 3.644, Loss_clf 0.756, Loss_fe 0.855, Loss_kd 1.571, Train_accy 47.87
2022-10-08 10:19:16,262 [foster.py] => Task 3, Epoch 21/34 => Loss 3.642, Loss_clf 0.749, Loss_fe 0.857, Loss_kd 1.574, Train_accy 48.30, Test_accy 46.53
2022-10-08 10:19:19,242 [foster.py] => Task 3, Epoch 22/34 => Loss 3.577, Loss_clf 0.726, Loss_fe 0.816, Loss_kd 1.573, Train_accy 50.18
2022-10-08 10:19:22,548 [foster.py] => Task 3, Epoch 23/34 => Loss 3.568, Loss_clf 0.724, Loss_fe 0.814, Loss_kd 1.568, Train_accy 49.53
2022-10-08 10:19:25,635 [foster.py] => Task 3, Epoch 24/34 => Loss 3.584, Loss_clf 0.733, Loss_fe 0.816, Loss_kd 1.572, Train_accy 49.10
2022-10-08 10:19:28,618 [foster.py] => Task 3, Epoch 25/34 => Loss 3.585, Loss_clf 0.735, Loss_fe 0.820, Loss_kd 1.568, Train_accy 47.94
2022-10-08 10:19:33,032 [foster.py] => Task 3, Epoch 26/34 => Loss 3.558, Loss_clf 0.715, Loss_fe 0.805, Loss_kd 1.575, Train_accy 49.17, Test_accy 46.73
2022-10-08 10:19:36,217 [foster.py] => Task 3, Epoch 27/34 => Loss 3.541, Loss_clf 0.707, Loss_fe 0.799, Loss_kd 1.573, Train_accy 47.87
2022-10-08 10:19:39,337 [foster.py] => Task 3, Epoch 28/34 => Loss 3.526, Loss_clf 0.701, Loss_fe 0.791, Loss_kd 1.572, Train_accy 50.18
2022-10-08 10:19:42,341 [foster.py] => Task 3, Epoch 29/34 => Loss 3.563, Loss_clf 0.715, Loss_fe 0.810, Loss_kd 1.575, Train_accy 50.47
2022-10-08 10:19:45,566 [foster.py] => Task 3, Epoch 30/34 => Loss 3.543, Loss_clf 0.709, Loss_fe 0.793, Loss_kd 1.577, Train_accy 48.45
2022-10-08 10:19:49,782 [foster.py] => Task 3, Epoch 31/34 => Loss 3.534, Loss_clf 0.712, Loss_fe 0.795, Loss_kd 1.566, Train_accy 48.95, Test_accy 46.93
2022-10-08 10:19:52,787 [foster.py] => Task 3, Epoch 32/34 => Loss 3.524, Loss_clf 0.702, Loss_fe 0.788, Loss_kd 1.572, Train_accy 49.46
2022-10-08 10:19:55,790 [foster.py] => Task 3, Epoch 33/34 => Loss 3.528, Loss_clf 0.699, Loss_fe 0.792, Loss_kd 1.573, Train_accy 49.82
2022-10-08 10:19:58,844 [foster.py] => Task 3, Epoch 34/34 => Loss 3.540, Loss_clf 0.705, Loss_fe 0.802, Loss_kd 1.571, Train_accy 49.46
2022-10-08 10:19:58,844 [foster.py] => do not weight align teacher!
2022-10-08 10:19:58,845 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 10:20:03,471 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.510,  Train_accy 11.26, Test_accy 33.07
2022-10-08 10:20:06,848 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.451,  Train_accy 11.55
2022-10-08 10:20:10,457 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.434,  Train_accy 12.42
2022-10-08 10:20:14,110 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.415,  Train_accy 12.27
2022-10-08 10:20:17,696 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.415,  Train_accy 12.42
2022-10-08 10:20:22,160 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.393,  Train_accy 13.07, Test_accy 35.84
2022-10-08 10:20:25,687 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.386,  Train_accy 14.01
2022-10-08 10:20:29,454 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.376,  Train_accy 14.66
2022-10-08 10:20:33,192 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.372,  Train_accy 15.81
2022-10-08 10:20:36,899 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.371,  Train_accy 15.96
2022-10-08 10:20:41,273 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.368,  Train_accy 16.39, Test_accy 36.83
2022-10-08 10:20:44,808 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.365,  Train_accy 17.76
2022-10-08 10:20:48,720 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.363,  Train_accy 16.97
2022-10-08 10:20:52,641 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.370,  Train_accy 19.13
2022-10-08 10:20:56,486 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.356,  Train_accy 17.04
2022-10-08 10:21:00,881 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.356,  Train_accy 18.48, Test_accy 37.43
2022-10-08 10:21:04,298 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.359,  Train_accy 19.71
2022-10-08 10:21:12,196 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.355,  Train_accy 19.57
2022-10-08 10:21:16,491 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.352,  Train_accy 18.48
2022-10-08 10:21:20,225 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.352,  Train_accy 18.99
2022-10-08 10:21:24,389 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.341,  Train_accy 19.42, Test_accy 38.81
2022-10-08 10:21:27,542 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.350,  Train_accy 19.42
2022-10-08 10:21:30,828 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.346,  Train_accy 20.00
2022-10-08 10:21:34,229 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.342,  Train_accy 18.05
2022-10-08 10:21:37,751 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.345,  Train_accy 20.36
2022-10-08 10:21:42,045 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.348,  Train_accy 18.77, Test_accy 37.62
2022-10-08 10:21:42,045 [foster.py] => do not weight align student!
2022-10-08 10:21:42,852 [foster.py] => darknet eval: 
2022-10-08 10:21:42,852 [foster.py] => CNN top1 curve: 37.62
2022-10-08 10:21:42,852 [foster.py] => CNN top5 curve: 85.54
2022-10-08 10:21:42,852 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 10:21:54,146 [foster.py] => Exemplar size: 440
2022-10-08 10:21:54,146 [trainer.py] => CNN: {'total': 47.33, 'old': 51.0, 'new': 33.01, 'base': 81.66, 'compound': 30.06}
2022-10-08 10:21:54,146 [trainer.py] => CNN top1 curve: [89.94, 60.0, 50.0, 47.33]
2022-10-08 10:21:54,146 [trainer.py] => CNN base curve: [89.94, 84.02, 83.43, 81.66]
2022-10-08 10:21:54,146 [trainer.py] => CNN old curve: [89.94, 84.02, 54.83, 51.0]
2022-10-08 10:21:54,146 [trainer.py] => CNN new curve: [0, 26.45, 37.5, 33.01]
2022-10-08 10:21:54,146 [trainer.py] => CNN compound curve: [0, 26.45, 25.75, 30.06]
2022-10-08 10:21:54,146 [trainer.py] => NME: {'total': 55.45, 'old': 56.97, 'new': 49.51, 'base': 71.6, 'compound': 47.32}
2022-10-08 10:21:54,146 [trainer.py] => NME top1 curve: [89.35, 67.24, 58.46, 55.45]
2022-10-08 10:21:54,146 [trainer.py] => NME base curve: [89.35, 82.84, 71.6, 71.6]
2022-10-08 10:21:54,146 [trainer.py] => NME old curve: [89.35, 82.84, 55.86, 56.97]
2022-10-08 10:21:54,146 [trainer.py] => NME new curve: [0, 45.45, 65.18, 49.51]
2022-10-08 10:21:54,146 [trainer.py] => NME compound curve: [0, 45.45, 48.93, 47.32]
2022-10-08 10:21:54,148 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 10:21:54,148 [trainer.py] => prefix: cil
2022-10-08 10:21:54,148 [trainer.py] => dataset: CFEE
2022-10-08 10:21:54,148 [trainer.py] => memory_size: 2000
2022-10-08 10:21:54,148 [trainer.py] => memory_per_class: 20
2022-10-08 10:21:54,148 [trainer.py] => fixed_memory: True
2022-10-08 10:21:54,148 [trainer.py] => shuffle: True
2022-10-08 10:21:54,148 [trainer.py] => init_cls: 7
2022-10-08 10:21:54,148 [trainer.py] => increment: 5
2022-10-08 10:21:54,148 [trainer.py] => model_name: foster
2022-10-08 10:21:54,148 [trainer.py] => convnet_type: resnet18
2022-10-08 10:21:54,148 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 10:21:54,148 [trainer.py] => seed: 1993
2022-10-08 10:21:54,148 [trainer.py] => beta1: 0.96
2022-10-08 10:21:54,148 [trainer.py] => beta2: 0.97
2022-10-08 10:21:54,148 [trainer.py] => oofc: ft
2022-10-08 10:21:54,148 [trainer.py] => is_teacher_wa: False
2022-10-08 10:21:54,148 [trainer.py] => is_student_wa: False
2022-10-08 10:21:54,148 [trainer.py] => lambda_okd: 1
2022-10-08 10:21:54,148 [trainer.py] => wa_value: 1
2022-10-08 10:21:54,148 [trainer.py] => init_epochs: 40
2022-10-08 10:21:54,148 [trainer.py] => init_lr: 0.01
2022-10-08 10:21:54,148 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 10:21:54,148 [trainer.py] => boosting_epochs: 34
2022-10-08 10:21:54,149 [trainer.py] => compression_epochs: 26
2022-10-08 10:21:54,149 [trainer.py] => lr: 0.001
2022-10-08 10:21:54,149 [trainer.py] => batch_size: 32
2022-10-08 10:21:54,149 [trainer.py] => weight_decay: 0.0005
2022-10-08 10:21:54,149 [trainer.py] => num_workers: 8
2022-10-08 10:21:54,149 [trainer.py] => T: 2
2022-10-08 10:21:54,149 [trainer.py] => nb_runs: 3
2022-10-08 10:21:54,149 [trainer.py] => fold: 10
2022-10-08 10:21:54,149 [data.py] => ========== Fold:6 ==========
2022-10-08 10:21:54,154 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 12, 10, 19, 21, 17, 18, 8, 7, 9, 14, 15, 13, 11, 16]
2022-10-08 10:21:54,373 [foster.py] => Learning on 0-7
2022-10-08 10:21:54,373 [foster.py] => All params: 11183694
2022-10-08 10:21:54,373 [foster.py] => Trainable params: 11183694
2022-10-08 10:21:56,714 [foster.py] => Task 0, Epoch 1/40 => Loss 1.361, Train_accy 48.69
2022-10-08 10:21:59,675 [foster.py] => Task 0, Epoch 2/40 => Loss 0.564, Train_accy 80.84, Test_accy 81.99
2022-10-08 10:22:02,707 [foster.py] => Task 0, Epoch 3/40 => Loss 0.387, Train_accy 87.21, Test_accy 83.23
2022-10-08 10:22:05,712 [foster.py] => Task 0, Epoch 4/40 => Loss 0.324, Train_accy 89.49, Test_accy 86.96
2022-10-08 10:22:08,697 [foster.py] => Task 0, Epoch 5/40 => Loss 0.236, Train_accy 92.19, Test_accy 83.85
2022-10-08 10:22:11,077 [foster.py] => Task 0, Epoch 6/40 => Loss 0.197, Train_accy 92.74
2022-10-08 10:22:14,080 [foster.py] => Task 0, Epoch 7/40 => Loss 0.191, Train_accy 93.64, Test_accy 88.20
2022-10-08 10:22:17,081 [foster.py] => Task 0, Epoch 8/40 => Loss 0.157, Train_accy 94.05, Test_accy 87.58
2022-10-08 10:22:20,024 [foster.py] => Task 0, Epoch 9/40 => Loss 0.123, Train_accy 95.50, Test_accy 88.82
2022-10-08 10:22:22,969 [foster.py] => Task 0, Epoch 10/40 => Loss 0.105, Train_accy 96.61, Test_accy 89.44
2022-10-08 10:22:25,394 [foster.py] => Task 0, Epoch 11/40 => Loss 0.080, Train_accy 97.99
2022-10-08 10:22:28,339 [foster.py] => Task 0, Epoch 12/40 => Loss 0.103, Train_accy 96.82, Test_accy 86.96
2022-10-08 10:22:31,305 [foster.py] => Task 0, Epoch 13/40 => Loss 0.085, Train_accy 97.58, Test_accy 89.44
2022-10-08 10:22:34,263 [foster.py] => Task 0, Epoch 14/40 => Loss 0.056, Train_accy 98.48, Test_accy 87.58
2022-10-08 10:22:37,270 [foster.py] => Task 0, Epoch 15/40 => Loss 0.052, Train_accy 98.76, Test_accy 84.47
2022-10-08 10:22:39,667 [foster.py] => Task 0, Epoch 16/40 => Loss 0.050, Train_accy 98.76
2022-10-08 10:22:42,833 [foster.py] => Task 0, Epoch 17/40 => Loss 0.039, Train_accy 98.96, Test_accy 89.44
2022-10-08 10:22:45,977 [foster.py] => Task 0, Epoch 18/40 => Loss 0.041, Train_accy 98.82, Test_accy 89.44
2022-10-08 10:22:49,153 [foster.py] => Task 0, Epoch 19/40 => Loss 0.028, Train_accy 99.59, Test_accy 91.30
2022-10-08 10:22:52,587 [foster.py] => Task 0, Epoch 20/40 => Loss 0.029, Train_accy 99.38, Test_accy 88.20
2022-10-08 10:22:55,156 [foster.py] => Task 0, Epoch 21/40 => Loss 0.037, Train_accy 99.59
2022-10-08 10:22:58,416 [foster.py] => Task 0, Epoch 22/40 => Loss 0.039, Train_accy 99.10, Test_accy 88.20
2022-10-08 10:23:01,636 [foster.py] => Task 0, Epoch 23/40 => Loss 0.029, Train_accy 99.65, Test_accy 86.96
2022-10-08 10:23:04,838 [foster.py] => Task 0, Epoch 24/40 => Loss 0.028, Train_accy 99.31, Test_accy 86.96
2022-10-08 10:23:08,108 [foster.py] => Task 0, Epoch 25/40 => Loss 0.021, Train_accy 99.72, Test_accy 87.58
2022-10-08 10:23:10,605 [foster.py] => Task 0, Epoch 26/40 => Loss 0.024, Train_accy 99.45
2022-10-08 10:23:13,835 [foster.py] => Task 0, Epoch 27/40 => Loss 0.019, Train_accy 99.86, Test_accy 89.44
2022-10-08 10:23:17,022 [foster.py] => Task 0, Epoch 28/40 => Loss 0.019, Train_accy 99.93, Test_accy 89.44
2022-10-08 10:23:20,291 [foster.py] => Task 0, Epoch 29/40 => Loss 0.018, Train_accy 99.86, Test_accy 90.06
2022-10-08 10:23:23,494 [foster.py] => Task 0, Epoch 30/40 => Loss 0.020, Train_accy 99.65, Test_accy 88.20
2022-10-08 10:23:25,985 [foster.py] => Task 0, Epoch 31/40 => Loss 0.018, Train_accy 99.79
2022-10-08 10:23:29,149 [foster.py] => Task 0, Epoch 32/40 => Loss 0.016, Train_accy 99.79, Test_accy 88.82
2022-10-08 10:23:32,353 [foster.py] => Task 0, Epoch 33/40 => Loss 0.012, Train_accy 99.86, Test_accy 88.82
2022-10-08 10:23:35,517 [foster.py] => Task 0, Epoch 34/40 => Loss 0.038, Train_accy 99.86, Test_accy 88.20
2022-10-08 10:23:38,742 [foster.py] => Task 0, Epoch 35/40 => Loss 0.017, Train_accy 99.72, Test_accy 88.82
2022-10-08 10:23:41,327 [foster.py] => Task 0, Epoch 36/40 => Loss 0.015, Train_accy 99.79
2022-10-08 10:23:44,582 [foster.py] => Task 0, Epoch 37/40 => Loss 0.025, Train_accy 99.59, Test_accy 88.20
2022-10-08 10:23:47,812 [foster.py] => Task 0, Epoch 38/40 => Loss 0.012, Train_accy 99.86, Test_accy 88.82
2022-10-08 10:23:51,685 [foster.py] => Task 0, Epoch 39/40 => Loss 0.014, Train_accy 99.86, Test_accy 88.82
2022-10-08 10:23:54,978 [foster.py] => Task 0, Epoch 40/40 => Loss 0.017, Train_accy 99.86, Test_accy 88.20
2022-10-08 10:23:54,979 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 10:24:02,734 [foster.py] => Exemplar size: 140
2022-10-08 10:24:02,734 [trainer.py] => CNN: {'total': 88.2, 'old': 88.2, 'new': 0, 'base': 88.2, 'compound': 0}
2022-10-08 10:24:02,734 [trainer.py] => CNN top1 curve: [88.2]
2022-10-08 10:24:02,734 [trainer.py] => CNN base curve: [88.2]
2022-10-08 10:24:02,734 [trainer.py] => CNN old curve: [88.2]
2022-10-08 10:24:02,734 [trainer.py] => CNN new curve: [0]
2022-10-08 10:24:02,734 [trainer.py] => CNN compound curve: [0]
2022-10-08 10:24:02,734 [trainer.py] => NME: {'total': 88.82, 'old': 88.82, 'new': 0, 'base': 88.82, 'compound': 0}
2022-10-08 10:24:02,734 [trainer.py] => NME top1 curve: [88.82]
2022-10-08 10:24:02,734 [trainer.py] => NME base curve: [88.82]
2022-10-08 10:24:02,734 [trainer.py] => NME old curve: [88.82]
2022-10-08 10:24:02,734 [trainer.py] => NME new curve: [0]
2022-10-08 10:24:02,734 [trainer.py] => NME compound curve: [0]
2022-10-08 10:24:03,017 [foster.py] => Learning on 7-12
2022-10-08 10:24:03,017 [foster.py] => All params: 22375071
2022-10-08 10:24:03,018 [foster.py] => Trainable params: 11194968
2022-10-08 10:24:03,026 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 10:24:06,154 [foster.py] => Task 1, Epoch 1/34 => Loss 5.158, Loss_clf 2.473, Loss_fe 2.062, Loss_kd 0.363, Train_accy 30.46, Test_accy 61.09
2022-10-08 10:24:08,580 [foster.py] => Task 1, Epoch 2/34 => Loss 3.154, Loss_clf 1.079, Loss_fe 1.500, Loss_kd 0.336, Train_accy 45.14
2022-10-08 10:24:11,017 [foster.py] => Task 1, Epoch 3/34 => Loss 2.825, Loss_clf 0.956, Loss_fe 1.324, Loss_kd 0.318, Train_accy 36.35
2022-10-08 10:24:13,449 [foster.py] => Task 1, Epoch 4/34 => Loss 2.716, Loss_clf 0.925, Loss_fe 1.243, Loss_kd 0.320, Train_accy 37.88
2022-10-08 10:24:15,877 [foster.py] => Task 1, Epoch 5/34 => Loss 2.596, Loss_clf 0.892, Loss_fe 1.157, Loss_kd 0.320, Train_accy 37.71
2022-10-08 10:24:19,012 [foster.py] => Task 1, Epoch 6/34 => Loss 2.505, Loss_clf 0.854, Loss_fe 1.109, Loss_kd 0.316, Train_accy 40.27, Test_accy 59.64
2022-10-08 10:24:21,542 [foster.py] => Task 1, Epoch 7/34 => Loss 2.413, Loss_clf 0.834, Loss_fe 1.042, Loss_kd 0.313, Train_accy 39.08
2022-10-08 10:24:27,348 [foster.py] => Task 1, Epoch 8/34 => Loss 2.345, Loss_clf 0.806, Loss_fe 1.003, Loss_kd 0.313, Train_accy 38.82
2022-10-08 10:24:30,764 [foster.py] => Task 1, Epoch 9/34 => Loss 2.294, Loss_clf 0.789, Loss_fe 0.965, Loss_kd 0.315, Train_accy 38.91
2022-10-08 10:24:33,587 [foster.py] => Task 1, Epoch 10/34 => Loss 2.247, Loss_clf 0.771, Loss_fe 0.940, Loss_kd 0.313, Train_accy 40.02
2022-10-08 10:24:36,931 [foster.py] => Task 1, Epoch 11/34 => Loss 2.214, Loss_clf 0.764, Loss_fe 0.919, Loss_kd 0.310, Train_accy 41.81, Test_accy 61.09
2022-10-08 10:24:39,428 [foster.py] => Task 1, Epoch 12/34 => Loss 2.219, Loss_clf 0.759, Loss_fe 0.920, Loss_kd 0.315, Train_accy 42.92
2022-10-08 10:24:41,877 [foster.py] => Task 1, Epoch 13/34 => Loss 2.130, Loss_clf 0.722, Loss_fe 0.866, Loss_kd 0.316, Train_accy 43.09
2022-10-08 10:24:44,357 [foster.py] => Task 1, Epoch 14/34 => Loss 2.120, Loss_clf 0.720, Loss_fe 0.859, Loss_kd 0.316, Train_accy 43.69
2022-10-08 10:24:46,885 [foster.py] => Task 1, Epoch 15/34 => Loss 2.104, Loss_clf 0.719, Loss_fe 0.845, Loss_kd 0.315, Train_accy 43.43
2022-10-08 10:24:50,187 [foster.py] => Task 1, Epoch 16/34 => Loss 2.048, Loss_clf 0.687, Loss_fe 0.823, Loss_kd 0.314, Train_accy 43.60, Test_accy 58.91
2022-10-08 10:24:52,724 [foster.py] => Task 1, Epoch 17/34 => Loss 2.031, Loss_clf 0.682, Loss_fe 0.807, Loss_kd 0.316, Train_accy 44.97
2022-10-08 10:24:55,312 [foster.py] => Task 1, Epoch 18/34 => Loss 2.011, Loss_clf 0.666, Loss_fe 0.802, Loss_kd 0.316, Train_accy 45.31
2022-10-08 10:24:57,995 [foster.py] => Task 1, Epoch 19/34 => Loss 2.009, Loss_clf 0.676, Loss_fe 0.794, Loss_kd 0.314, Train_accy 43.26
2022-10-08 10:25:00,597 [foster.py] => Task 1, Epoch 20/34 => Loss 1.964, Loss_clf 0.648, Loss_fe 0.771, Loss_kd 0.318, Train_accy 45.22
2022-10-08 10:25:03,907 [foster.py] => Task 1, Epoch 21/34 => Loss 1.975, Loss_clf 0.661, Loss_fe 0.781, Loss_kd 0.311, Train_accy 45.22, Test_accy 58.91
2022-10-08 10:25:06,426 [foster.py] => Task 1, Epoch 22/34 => Loss 1.908, Loss_clf 0.626, Loss_fe 0.747, Loss_kd 0.313, Train_accy 46.08
2022-10-08 10:25:08,909 [foster.py] => Task 1, Epoch 23/34 => Loss 1.929, Loss_clf 0.640, Loss_fe 0.753, Loss_kd 0.313, Train_accy 44.37
2022-10-08 10:25:11,623 [foster.py] => Task 1, Epoch 24/34 => Loss 1.903, Loss_clf 0.626, Loss_fe 0.738, Loss_kd 0.315, Train_accy 45.56
2022-10-08 10:25:14,152 [foster.py] => Task 1, Epoch 25/34 => Loss 1.886, Loss_clf 0.612, Loss_fe 0.729, Loss_kd 0.318, Train_accy 45.90
2022-10-08 10:25:17,528 [foster.py] => Task 1, Epoch 26/34 => Loss 1.848, Loss_clf 0.601, Loss_fe 0.710, Loss_kd 0.313, Train_accy 47.01, Test_accy 60.00
2022-10-08 10:25:20,411 [foster.py] => Task 1, Epoch 27/34 => Loss 1.881, Loss_clf 0.612, Loss_fe 0.729, Loss_kd 0.315, Train_accy 45.99
2022-10-08 10:25:23,298 [foster.py] => Task 1, Epoch 28/34 => Loss 1.885, Loss_clf 0.616, Loss_fe 0.734, Loss_kd 0.312, Train_accy 46.84
2022-10-08 10:25:26,152 [foster.py] => Task 1, Epoch 29/34 => Loss 1.862, Loss_clf 0.602, Loss_fe 0.728, Loss_kd 0.310, Train_accy 47.18
2022-10-08 10:25:28,992 [foster.py] => Task 1, Epoch 30/34 => Loss 1.857, Loss_clf 0.600, Loss_fe 0.714, Loss_kd 0.317, Train_accy 46.93
2022-10-08 10:25:32,593 [foster.py] => Task 1, Epoch 31/34 => Loss 1.868, Loss_clf 0.612, Loss_fe 0.727, Loss_kd 0.309, Train_accy 47.18, Test_accy 59.64
2022-10-08 10:25:35,146 [foster.py] => Task 1, Epoch 32/34 => Loss 1.887, Loss_clf 0.620, Loss_fe 0.728, Loss_kd 0.314, Train_accy 47.18
2022-10-08 10:25:37,725 [foster.py] => Task 1, Epoch 33/34 => Loss 1.837, Loss_clf 0.589, Loss_fe 0.712, Loss_kd 0.313, Train_accy 47.44
2022-10-08 10:25:40,467 [foster.py] => Task 1, Epoch 34/34 => Loss 1.844, Loss_clf 0.599, Loss_fe 0.704, Loss_kd 0.315, Train_accy 48.04
2022-10-08 10:25:40,467 [foster.py] => do not weight align teacher!
2022-10-08 10:25:40,468 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 10:25:44,435 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.840,  Train_accy 11.18, Test_accy 50.55
2022-10-08 10:25:47,270 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.652,  Train_accy 12.12
2022-10-08 10:25:50,295 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.568,  Train_accy 12.20
2022-10-08 10:25:53,460 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.544,  Train_accy 12.97
2022-10-08 10:25:56,618 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.530,  Train_accy 13.65
2022-10-08 10:26:00,439 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.511,  Train_accy 13.99, Test_accy 51.27
2022-10-08 10:26:03,456 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.507,  Train_accy 14.16
2022-10-08 10:26:06,498 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.488,  Train_accy 15.19
2022-10-08 10:26:09,443 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.480,  Train_accy 14.93
2022-10-08 10:26:16,640 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.491,  Train_accy 14.42
2022-10-08 10:26:20,819 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.486,  Train_accy 15.19, Test_accy 52.73
2022-10-08 10:26:23,660 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.466,  Train_accy 14.51
2022-10-08 10:26:26,483 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.466,  Train_accy 15.70
2022-10-08 10:26:29,291 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.461,  Train_accy 15.36
2022-10-08 10:26:35,821 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.464,  Train_accy 16.13
2022-10-08 10:26:40,634 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.455,  Train_accy 15.87, Test_accy 51.64
2022-10-08 10:26:43,574 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.452,  Train_accy 16.47
2022-10-08 10:26:46,519 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.453,  Train_accy 17.06
2022-10-08 10:26:49,325 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.443,  Train_accy 15.10
2022-10-08 10:26:52,104 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.453,  Train_accy 16.04
2022-10-08 10:26:55,590 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.453,  Train_accy 17.32, Test_accy 53.09
2022-10-08 10:26:58,446 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.459,  Train_accy 16.30
2022-10-08 10:27:01,319 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.445,  Train_accy 16.89
2022-10-08 10:27:04,439 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.457,  Train_accy 16.89
2022-10-08 10:27:07,559 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.453,  Train_accy 16.47
2022-10-08 10:27:11,334 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.462,  Train_accy 16.47, Test_accy 52.73
2022-10-08 10:27:11,335 [foster.py] => do not weight align student!
2022-10-08 10:27:11,984 [foster.py] => darknet eval: 
2022-10-08 10:27:11,984 [foster.py] => CNN top1 curve: 52.73
2022-10-08 10:27:11,984 [foster.py] => CNN top5 curve: 95.64
2022-10-08 10:27:11,985 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 10:27:19,627 [foster.py] => Exemplar size: 240
2022-10-08 10:27:19,627 [trainer.py] => CNN: {'total': 60.0, 'old': 83.85, 'new': 26.32, 'base': 83.85, 'compound': 26.32}
2022-10-08 10:27:19,627 [trainer.py] => CNN top1 curve: [88.2, 60.0]
2022-10-08 10:27:19,627 [trainer.py] => CNN base curve: [88.2, 83.85]
2022-10-08 10:27:19,627 [trainer.py] => CNN old curve: [88.2, 83.85]
2022-10-08 10:27:19,627 [trainer.py] => CNN new curve: [0, 26.32]
2022-10-08 10:27:19,627 [trainer.py] => CNN compound curve: [0, 26.32]
2022-10-08 10:27:19,627 [trainer.py] => NME: {'total': 68.0, 'old': 81.37, 'new': 49.12, 'base': 81.37, 'compound': 49.12}
2022-10-08 10:27:19,628 [trainer.py] => NME top1 curve: [88.82, 68.0]
2022-10-08 10:27:19,628 [trainer.py] => NME base curve: [88.82, 81.37]
2022-10-08 10:27:19,628 [trainer.py] => NME old curve: [88.82, 81.37]
2022-10-08 10:27:19,628 [trainer.py] => NME new curve: [0, 49.12]
2022-10-08 10:27:19,628 [trainer.py] => NME compound curve: [0, 49.12]
2022-10-08 10:27:19,856 [foster.py] => Learning on 12-17
2022-10-08 10:27:19,857 [foster.py] => All params: 22385326
2022-10-08 10:27:19,857 [foster.py] => Trainable params: 11202658
2022-10-08 10:27:19,866 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 10:27:23,249 [foster.py] => Task 2, Epoch 1/34 => Loss 5.582, Loss_clf 2.021, Loss_fe 2.100, Loss_kd 1.031, Train_accy 39.56, Test_accy 45.41
2022-10-08 10:27:25,804 [foster.py] => Task 2, Epoch 2/34 => Loss 3.698, Loss_clf 0.885, Loss_fe 1.407, Loss_kd 0.993, Train_accy 40.27
2022-10-08 10:27:28,360 [foster.py] => Task 2, Epoch 3/34 => Loss 3.395, Loss_clf 0.766, Loss_fe 1.208, Loss_kd 1.003, Train_accy 42.06
2022-10-08 10:27:30,971 [foster.py] => Task 2, Epoch 4/34 => Loss 3.229, Loss_clf 0.729, Loss_fe 1.092, Loss_kd 0.994, Train_accy 38.08
2022-10-08 10:27:33,586 [foster.py] => Task 2, Epoch 5/34 => Loss 3.126, Loss_clf 0.698, Loss_fe 1.011, Loss_kd 1.000, Train_accy 40.42
2022-10-08 10:27:37,112 [foster.py] => Task 2, Epoch 6/34 => Loss 3.017, Loss_clf 0.662, Loss_fe 0.938, Loss_kd 1.000, Train_accy 39.25, Test_accy 46.46
2022-10-08 10:27:39,728 [foster.py] => Task 2, Epoch 7/34 => Loss 2.991, Loss_clf 0.666, Loss_fe 0.907, Loss_kd 1.002, Train_accy 41.36
2022-10-08 10:27:42,411 [foster.py] => Task 2, Epoch 8/34 => Loss 2.896, Loss_clf 0.632, Loss_fe 0.854, Loss_kd 0.995, Train_accy 40.73
2022-10-08 10:27:45,101 [foster.py] => Task 2, Epoch 9/34 => Loss 2.872, Loss_clf 0.625, Loss_fe 0.831, Loss_kd 1.000, Train_accy 42.61
2022-10-08 10:27:47,939 [foster.py] => Task 2, Epoch 10/34 => Loss 2.807, Loss_clf 0.600, Loss_fe 0.786, Loss_kd 1.003, Train_accy 42.22
2022-10-08 10:27:51,562 [foster.py] => Task 2, Epoch 11/34 => Loss 2.778, Loss_clf 0.590, Loss_fe 0.770, Loss_kd 1.002, Train_accy 42.77, Test_accy 46.98
2022-10-08 10:27:54,219 [foster.py] => Task 2, Epoch 12/34 => Loss 2.729, Loss_clf 0.583, Loss_fe 0.734, Loss_kd 0.997, Train_accy 41.99
2022-10-08 10:27:57,179 [foster.py] => Task 2, Epoch 13/34 => Loss 2.715, Loss_clf 0.580, Loss_fe 0.725, Loss_kd 0.996, Train_accy 44.10
2022-10-08 10:28:00,005 [foster.py] => Task 2, Epoch 14/34 => Loss 2.677, Loss_clf 0.563, Loss_fe 0.703, Loss_kd 0.996, Train_accy 45.04
2022-10-08 10:28:02,834 [foster.py] => Task 2, Epoch 15/34 => Loss 2.674, Loss_clf 0.570, Loss_fe 0.696, Loss_kd 0.994, Train_accy 41.13
2022-10-08 10:28:09,885 [foster.py] => Task 2, Epoch 16/34 => Loss 2.658, Loss_clf 0.559, Loss_fe 0.670, Loss_kd 1.008, Train_accy 45.82, Test_accy 47.51
2022-10-08 10:28:12,792 [foster.py] => Task 2, Epoch 17/34 => Loss 2.633, Loss_clf 0.547, Loss_fe 0.666, Loss_kd 1.002, Train_accy 42.14
2022-10-08 10:28:15,577 [foster.py] => Task 2, Epoch 18/34 => Loss 2.602, Loss_clf 0.534, Loss_fe 0.644, Loss_kd 1.006, Train_accy 44.18
2022-10-08 10:28:18,281 [foster.py] => Task 2, Epoch 19/34 => Loss 2.580, Loss_clf 0.528, Loss_fe 0.641, Loss_kd 0.996, Train_accy 43.08
2022-10-08 10:28:20,970 [foster.py] => Task 2, Epoch 20/34 => Loss 2.555, Loss_clf 0.516, Loss_fe 0.628, Loss_kd 0.996, Train_accy 47.07
2022-10-08 10:28:24,417 [foster.py] => Task 2, Epoch 21/34 => Loss 2.563, Loss_clf 0.527, Loss_fe 0.623, Loss_kd 0.997, Train_accy 43.94, Test_accy 48.03
2022-10-08 10:28:27,029 [foster.py] => Task 2, Epoch 22/34 => Loss 2.549, Loss_clf 0.517, Loss_fe 0.616, Loss_kd 1.000, Train_accy 43.32
2022-10-08 10:28:29,711 [foster.py] => Task 2, Epoch 23/34 => Loss 2.570, Loss_clf 0.525, Loss_fe 0.618, Loss_kd 1.008, Train_accy 44.33
2022-10-08 10:28:36,443 [foster.py] => Task 2, Epoch 24/34 => Loss 2.544, Loss_clf 0.520, Loss_fe 0.608, Loss_kd 1.000, Train_accy 44.18
2022-10-08 10:28:40,157 [foster.py] => Task 2, Epoch 25/34 => Loss 2.529, Loss_clf 0.512, Loss_fe 0.598, Loss_kd 1.001, Train_accy 44.49
2022-10-08 10:28:43,931 [foster.py] => Task 2, Epoch 26/34 => Loss 2.529, Loss_clf 0.503, Loss_fe 0.610, Loss_kd 1.000, Train_accy 45.82, Test_accy 48.03
2022-10-08 10:28:46,547 [foster.py] => Task 2, Epoch 27/34 => Loss 2.518, Loss_clf 0.504, Loss_fe 0.594, Loss_kd 1.003, Train_accy 45.35
2022-10-08 10:28:49,107 [foster.py] => Task 2, Epoch 28/34 => Loss 2.536, Loss_clf 0.513, Loss_fe 0.602, Loss_kd 1.002, Train_accy 43.71
2022-10-08 10:28:51,733 [foster.py] => Task 2, Epoch 29/34 => Loss 2.503, Loss_clf 0.500, Loss_fe 0.592, Loss_kd 0.997, Train_accy 44.25
2022-10-08 10:28:54,392 [foster.py] => Task 2, Epoch 30/34 => Loss 2.534, Loss_clf 0.516, Loss_fe 0.598, Loss_kd 1.002, Train_accy 46.05
2022-10-08 10:28:58,275 [foster.py] => Task 2, Epoch 31/34 => Loss 2.510, Loss_clf 0.502, Loss_fe 0.585, Loss_kd 1.004, Train_accy 45.04, Test_accy 48.29
2022-10-08 10:29:00,976 [foster.py] => Task 2, Epoch 32/34 => Loss 2.496, Loss_clf 0.487, Loss_fe 0.580, Loss_kd 1.008, Train_accy 44.49
2022-10-08 10:29:03,658 [foster.py] => Task 2, Epoch 33/34 => Loss 2.503, Loss_clf 0.500, Loss_fe 0.588, Loss_kd 0.999, Train_accy 44.72
2022-10-08 10:29:06,355 [foster.py] => Task 2, Epoch 34/34 => Loss 2.500, Loss_clf 0.502, Loss_fe 0.588, Loss_kd 0.995, Train_accy 44.57
2022-10-08 10:29:06,356 [foster.py] => do not weight align teacher!
2022-10-08 10:29:06,356 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 10:29:10,432 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.122,  Train_accy 11.18, Test_accy 38.32
2022-10-08 10:29:14,070 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 2.002,  Train_accy 11.02
2022-10-08 10:29:17,530 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.962,  Train_accy 11.10
2022-10-08 10:29:20,892 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.937,  Train_accy 11.49
2022-10-08 10:29:24,194 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.926,  Train_accy 11.42
2022-10-08 10:29:28,311 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.920,  Train_accy 11.81, Test_accy 39.11
2022-10-08 10:29:31,487 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.915,  Train_accy 11.81
2022-10-08 10:29:34,654 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.901,  Train_accy 12.67
2022-10-08 10:29:37,897 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.894,  Train_accy 12.59
2022-10-08 10:29:41,248 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.887,  Train_accy 13.21
2022-10-08 10:29:45,247 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.881,  Train_accy 13.60, Test_accy 39.90
2022-10-08 10:29:48,617 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.873,  Train_accy 14.07
2022-10-08 10:29:51,935 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.865,  Train_accy 14.62
2022-10-08 10:29:55,107 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.863,  Train_accy 14.31
2022-10-08 10:30:03,305 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.861,  Train_accy 14.23
2022-10-08 10:30:08,403 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.860,  Train_accy 15.01, Test_accy 39.90
2022-10-08 10:30:11,469 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.866,  Train_accy 15.32
2022-10-08 10:30:14,460 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.853,  Train_accy 15.09
2022-10-08 10:30:17,454 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.859,  Train_accy 14.93
2022-10-08 10:30:23,937 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.860,  Train_accy 15.25
2022-10-08 10:30:28,623 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.860,  Train_accy 14.46, Test_accy 40.16
2022-10-08 10:30:31,727 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.858,  Train_accy 15.09
2022-10-08 10:30:34,754 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.845,  Train_accy 14.70
2022-10-08 10:30:37,714 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.858,  Train_accy 15.56
2022-10-08 10:30:40,728 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.856,  Train_accy 15.09
2022-10-08 10:30:44,747 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.860,  Train_accy 15.25, Test_accy 40.42
2022-10-08 10:30:44,748 [foster.py] => do not weight align student!
2022-10-08 10:30:45,483 [foster.py] => darknet eval: 
2022-10-08 10:30:45,483 [foster.py] => CNN top1 curve: 40.42
2022-10-08 10:30:45,483 [foster.py] => CNN top5 curve: 88.98
2022-10-08 10:30:45,484 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 10:30:55,041 [foster.py] => Exemplar size: 340
2022-10-08 10:30:55,041 [trainer.py] => CNN: {'total': 48.56, 'old': 54.91, 'new': 32.08, 'base': 80.75, 'compound': 25.0}
2022-10-08 10:30:55,041 [trainer.py] => CNN top1 curve: [88.2, 60.0, 48.56]
2022-10-08 10:30:55,041 [trainer.py] => CNN base curve: [88.2, 83.85, 80.75]
2022-10-08 10:30:55,041 [trainer.py] => CNN old curve: [88.2, 83.85, 54.91]
2022-10-08 10:30:55,041 [trainer.py] => CNN new curve: [0, 26.32, 32.08]
2022-10-08 10:30:55,041 [trainer.py] => CNN compound curve: [0, 26.32, 25.0]
2022-10-08 10:30:55,042 [trainer.py] => NME: {'total': 59.06, 'old': 57.82, 'new': 62.26, 'base': 69.57, 'compound': 51.36}
2022-10-08 10:30:55,042 [trainer.py] => NME top1 curve: [88.82, 68.0, 59.06]
2022-10-08 10:30:55,042 [trainer.py] => NME base curve: [88.82, 81.37, 69.57]
2022-10-08 10:30:55,042 [trainer.py] => NME old curve: [88.82, 81.37, 57.82]
2022-10-08 10:30:55,042 [trainer.py] => NME new curve: [0, 49.12, 62.26]
2022-10-08 10:30:55,042 [trainer.py] => NME compound curve: [0, 49.12, 51.36]
2022-10-08 10:30:55,265 [foster.py] => Learning on 17-22
2022-10-08 10:30:55,265 [foster.py] => All params: 22395581
2022-10-08 10:30:55,266 [foster.py] => Trainable params: 11210348
2022-10-08 10:30:55,275 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 10:30:58,860 [foster.py] => Task 3, Epoch 1/34 => Loss 6.801, Loss_clf 2.194, Loss_fe 2.560, Loss_kd 1.582, Train_accy 31.28, Test_accy 37.50
2022-10-08 10:31:01,585 [foster.py] => Task 3, Epoch 2/34 => Loss 5.060, Loss_clf 1.208, Loss_fe 1.829, Loss_kd 1.563, Train_accy 37.95
2022-10-08 10:31:04,256 [foster.py] => Task 3, Epoch 3/34 => Loss 4.701, Loss_clf 1.093, Loss_fe 1.580, Loss_kd 1.567, Train_accy 39.56
2022-10-08 10:31:06,973 [foster.py] => Task 3, Epoch 4/34 => Loss 4.509, Loss_clf 1.047, Loss_fe 1.440, Loss_kd 1.563, Train_accy 39.27
2022-10-08 10:31:09,649 [foster.py] => Task 3, Epoch 5/34 => Loss 4.355, Loss_clf 0.994, Loss_fe 1.336, Loss_kd 1.564, Train_accy 41.54
2022-10-08 10:31:13,312 [foster.py] => Task 3, Epoch 6/34 => Loss 4.276, Loss_clf 0.979, Loss_fe 1.266, Loss_kd 1.569, Train_accy 42.78, Test_accy 43.85
2022-10-08 10:31:16,071 [foster.py] => Task 3, Epoch 7/34 => Loss 4.165, Loss_clf 0.941, Loss_fe 1.196, Loss_kd 1.567, Train_accy 41.98
2022-10-08 10:31:18,799 [foster.py] => Task 3, Epoch 8/34 => Loss 4.125, Loss_clf 0.933, Loss_fe 1.160, Loss_kd 1.571, Train_accy 43.88
2022-10-08 10:31:23,337 [foster.py] => Task 3, Epoch 9/34 => Loss 4.073, Loss_clf 0.919, Loss_fe 1.122, Loss_kd 1.570, Train_accy 43.22
2022-10-08 10:31:26,905 [foster.py] => Task 3, Epoch 10/34 => Loss 4.008, Loss_clf 0.904, Loss_fe 1.072, Loss_kd 1.571, Train_accy 42.20
2022-10-08 10:31:31,124 [foster.py] => Task 3, Epoch 11/34 => Loss 3.972, Loss_clf 0.889, Loss_fe 1.053, Loss_kd 1.569, Train_accy 44.18, Test_accy 46.03
2022-10-08 10:31:33,963 [foster.py] => Task 3, Epoch 12/34 => Loss 3.925, Loss_clf 0.873, Loss_fe 1.024, Loss_kd 1.567, Train_accy 44.54
2022-10-08 10:31:36,766 [foster.py] => Task 3, Epoch 13/34 => Loss 3.866, Loss_clf 0.847, Loss_fe 0.985, Loss_kd 1.572, Train_accy 44.32
2022-10-08 10:31:39,735 [foster.py] => Task 3, Epoch 14/34 => Loss 3.836, Loss_clf 0.841, Loss_fe 0.976, Loss_kd 1.560, Train_accy 44.40
2022-10-08 10:31:42,609 [foster.py] => Task 3, Epoch 15/34 => Loss 3.798, Loss_clf 0.815, Loss_fe 0.950, Loss_kd 1.570, Train_accy 46.81
2022-10-08 10:31:46,508 [foster.py] => Task 3, Epoch 16/34 => Loss 3.789, Loss_clf 0.814, Loss_fe 0.939, Loss_kd 1.573, Train_accy 44.18, Test_accy 47.02
2022-10-08 10:31:49,397 [foster.py] => Task 3, Epoch 17/34 => Loss 3.796, Loss_clf 0.817, Loss_fe 0.938, Loss_kd 1.576, Train_accy 45.71
2022-10-08 10:31:52,244 [foster.py] => Task 3, Epoch 18/34 => Loss 3.750, Loss_clf 0.804, Loss_fe 0.917, Loss_kd 1.568, Train_accy 44.91
2022-10-08 10:31:55,186 [foster.py] => Task 3, Epoch 19/34 => Loss 3.724, Loss_clf 0.793, Loss_fe 0.897, Loss_kd 1.571, Train_accy 47.18
2022-10-08 10:31:58,175 [foster.py] => Task 3, Epoch 20/34 => Loss 3.702, Loss_clf 0.785, Loss_fe 0.886, Loss_kd 1.570, Train_accy 46.45
2022-10-08 10:32:02,199 [foster.py] => Task 3, Epoch 21/34 => Loss 3.679, Loss_clf 0.773, Loss_fe 0.868, Loss_kd 1.575, Train_accy 45.86, Test_accy 47.82
2022-10-08 10:32:05,222 [foster.py] => Task 3, Epoch 22/34 => Loss 3.649, Loss_clf 0.757, Loss_fe 0.854, Loss_kd 1.574, Train_accy 47.91
2022-10-08 10:32:08,313 [foster.py] => Task 3, Epoch 23/34 => Loss 3.684, Loss_clf 0.777, Loss_fe 0.867, Loss_kd 1.576, Train_accy 47.18
2022-10-08 10:32:11,726 [foster.py] => Task 3, Epoch 24/34 => Loss 3.630, Loss_clf 0.747, Loss_fe 0.845, Loss_kd 1.575, Train_accy 46.37
2022-10-08 10:32:14,896 [foster.py] => Task 3, Epoch 25/34 => Loss 3.646, Loss_clf 0.760, Loss_fe 0.851, Loss_kd 1.573, Train_accy 48.72
2022-10-08 10:32:19,066 [foster.py] => Task 3, Epoch 26/34 => Loss 3.638, Loss_clf 0.746, Loss_fe 0.854, Loss_kd 1.575, Train_accy 47.03, Test_accy 47.62
2022-10-08 10:32:22,085 [foster.py] => Task 3, Epoch 27/34 => Loss 3.636, Loss_clf 0.743, Loss_fe 0.852, Loss_kd 1.577, Train_accy 47.55
2022-10-08 10:32:25,052 [foster.py] => Task 3, Epoch 28/34 => Loss 3.615, Loss_clf 0.746, Loss_fe 0.837, Loss_kd 1.571, Train_accy 47.62
2022-10-08 10:32:28,007 [foster.py] => Task 3, Epoch 29/34 => Loss 3.589, Loss_clf 0.728, Loss_fe 0.822, Loss_kd 1.576, Train_accy 48.35
2022-10-08 10:32:30,958 [foster.py] => Task 3, Epoch 30/34 => Loss 3.603, Loss_clf 0.740, Loss_fe 0.825, Loss_kd 1.574, Train_accy 48.13
2022-10-08 10:32:34,816 [foster.py] => Task 3, Epoch 31/34 => Loss 3.627, Loss_clf 0.755, Loss_fe 0.839, Loss_kd 1.571, Train_accy 46.45, Test_accy 47.82
2022-10-08 10:32:37,737 [foster.py] => Task 3, Epoch 32/34 => Loss 3.607, Loss_clf 0.737, Loss_fe 0.833, Loss_kd 1.574, Train_accy 48.06
2022-10-08 10:32:40,607 [foster.py] => Task 3, Epoch 33/34 => Loss 3.606, Loss_clf 0.748, Loss_fe 0.828, Loss_kd 1.568, Train_accy 47.40
2022-10-08 10:32:43,519 [foster.py] => Task 3, Epoch 34/34 => Loss 3.622, Loss_clf 0.746, Loss_fe 0.838, Loss_kd 1.575, Train_accy 46.81
2022-10-08 10:32:43,519 [foster.py] => do not weight align teacher!
2022-10-08 10:32:43,520 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 10:32:52,164 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.477,  Train_accy 11.43, Test_accy 31.35
2022-10-08 10:32:55,569 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.439,  Train_accy 11.87
2022-10-08 10:32:58,829 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.427,  Train_accy 12.82
2022-10-08 10:33:02,077 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.418,  Train_accy 12.16
2022-10-08 10:33:05,315 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.400,  Train_accy 12.38
2022-10-08 10:33:09,673 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.396,  Train_accy 12.38, Test_accy 31.75
2022-10-08 10:33:12,904 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.392,  Train_accy 12.75
2022-10-08 10:33:16,412 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.381,  Train_accy 13.19
2022-10-08 10:33:19,925 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.383,  Train_accy 13.19
2022-10-08 10:33:23,458 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.378,  Train_accy 13.19
2022-10-08 10:33:27,777 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.380,  Train_accy 13.55, Test_accy 32.54
2022-10-08 10:33:31,165 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.375,  Train_accy 13.63
2022-10-08 10:33:34,843 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.371,  Train_accy 14.14
2022-10-08 10:33:38,290 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.368,  Train_accy 14.73
2022-10-08 10:33:41,889 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.373,  Train_accy 13.99
2022-10-08 10:33:46,515 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.372,  Train_accy 14.43, Test_accy 32.94
2022-10-08 10:33:50,100 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.364,  Train_accy 14.51
2022-10-08 10:33:53,634 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.369,  Train_accy 15.31
2022-10-08 10:33:57,261 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.368,  Train_accy 15.02
2022-10-08 10:34:00,751 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.366,  Train_accy 14.51
2022-10-08 10:34:05,364 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.359,  Train_accy 14.73, Test_accy 33.93
2022-10-08 10:34:09,108 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.368,  Train_accy 14.95
2022-10-08 10:34:13,234 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.358,  Train_accy 15.53
2022-10-08 10:34:17,041 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.360,  Train_accy 15.02
2022-10-08 10:34:20,642 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.366,  Train_accy 15.09
2022-10-08 10:34:25,015 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.369,  Train_accy 14.87, Test_accy 33.73
2022-10-08 10:34:25,015 [foster.py] => do not weight align student!
2022-10-08 10:34:25,828 [foster.py] => darknet eval: 
2022-10-08 10:34:25,828 [foster.py] => CNN top1 curve: 33.73
2022-10-08 10:34:25,828 [foster.py] => CNN top5 curve: 82.14
2022-10-08 10:34:25,828 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 10:34:37,009 [foster.py] => Exemplar size: 440
2022-10-08 10:34:37,009 [trainer.py] => CNN: {'total': 48.02, 'old': 49.87, 'new': 42.28, 'base': 78.88, 'compound': 33.53}
2022-10-08 10:34:37,009 [trainer.py] => CNN top1 curve: [88.2, 60.0, 48.56, 48.02]
2022-10-08 10:34:37,009 [trainer.py] => CNN base curve: [88.2, 83.85, 80.75, 78.88]
2022-10-08 10:34:37,009 [trainer.py] => CNN old curve: [88.2, 83.85, 54.91, 49.87]
2022-10-08 10:34:37,009 [trainer.py] => CNN new curve: [0, 26.32, 32.08, 42.28]
2022-10-08 10:34:37,009 [trainer.py] => CNN compound curve: [0, 26.32, 25.0, 33.53]
2022-10-08 10:34:37,009 [trainer.py] => NME: {'total': 56.75, 'old': 56.96, 'new': 56.1, 'base': 65.84, 'compound': 52.48}
2022-10-08 10:34:37,010 [trainer.py] => NME top1 curve: [88.82, 68.0, 59.06, 56.75]
2022-10-08 10:34:37,010 [trainer.py] => NME base curve: [88.82, 81.37, 69.57, 65.84]
2022-10-08 10:34:37,010 [trainer.py] => NME old curve: [88.82, 81.37, 57.82, 56.96]
2022-10-08 10:34:37,010 [trainer.py] => NME new curve: [0, 49.12, 62.26, 56.1]
2022-10-08 10:34:37,010 [trainer.py] => NME compound curve: [0, 49.12, 51.36, 52.48]
2022-10-08 10:34:37,011 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 10:34:37,011 [trainer.py] => prefix: cil
2022-10-08 10:34:37,011 [trainer.py] => dataset: CFEE
2022-10-08 10:34:37,011 [trainer.py] => memory_size: 2000
2022-10-08 10:34:37,011 [trainer.py] => memory_per_class: 20
2022-10-08 10:34:37,011 [trainer.py] => fixed_memory: True
2022-10-08 10:34:37,011 [trainer.py] => shuffle: True
2022-10-08 10:34:37,011 [trainer.py] => init_cls: 7
2022-10-08 10:34:37,011 [trainer.py] => increment: 5
2022-10-08 10:34:37,011 [trainer.py] => model_name: foster
2022-10-08 10:34:37,011 [trainer.py] => convnet_type: resnet18
2022-10-08 10:34:37,011 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 10:34:37,011 [trainer.py] => seed: 1993
2022-10-08 10:34:37,011 [trainer.py] => beta1: 0.96
2022-10-08 10:34:37,012 [trainer.py] => beta2: 0.97
2022-10-08 10:34:37,012 [trainer.py] => oofc: ft
2022-10-08 10:34:37,012 [trainer.py] => is_teacher_wa: False
2022-10-08 10:34:37,012 [trainer.py] => is_student_wa: False
2022-10-08 10:34:37,012 [trainer.py] => lambda_okd: 1
2022-10-08 10:34:37,012 [trainer.py] => wa_value: 1
2022-10-08 10:34:37,012 [trainer.py] => init_epochs: 40
2022-10-08 10:34:37,012 [trainer.py] => init_lr: 0.01
2022-10-08 10:34:37,012 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 10:34:37,012 [trainer.py] => boosting_epochs: 34
2022-10-08 10:34:37,012 [trainer.py] => compression_epochs: 26
2022-10-08 10:34:37,012 [trainer.py] => lr: 0.001
2022-10-08 10:34:37,012 [trainer.py] => batch_size: 32
2022-10-08 10:34:37,012 [trainer.py] => weight_decay: 0.0005
2022-10-08 10:34:37,012 [trainer.py] => num_workers: 8
2022-10-08 10:34:37,012 [trainer.py] => T: 2
2022-10-08 10:34:37,012 [trainer.py] => nb_runs: 3
2022-10-08 10:34:37,012 [trainer.py] => fold: 10
2022-10-08 10:34:37,012 [data.py] => ========== Fold:7 ==========
2022-10-08 10:34:37,017 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 12, 10, 19, 21, 17, 18, 8, 7, 9, 14, 15, 13, 11, 16]
2022-10-08 10:34:37,237 [foster.py] => Learning on 0-7
2022-10-08 10:34:37,237 [foster.py] => All params: 11183694
2022-10-08 10:34:37,237 [foster.py] => Trainable params: 11183694
2022-10-08 10:34:39,627 [foster.py] => Task 0, Epoch 1/40 => Loss 1.360, Train_accy 49.66
2022-10-08 10:34:42,566 [foster.py] => Task 0, Epoch 2/40 => Loss 0.553, Train_accy 81.48, Test_accy 90.60
2022-10-08 10:34:45,625 [foster.py] => Task 0, Epoch 3/40 => Loss 0.374, Train_accy 87.52, Test_accy 82.55
2022-10-08 10:34:48,650 [foster.py] => Task 0, Epoch 4/40 => Loss 0.301, Train_accy 90.12, Test_accy 85.91
2022-10-08 10:34:51,645 [foster.py] => Task 0, Epoch 5/40 => Loss 0.226, Train_accy 91.50, Test_accy 87.25
2022-10-08 10:34:54,051 [foster.py] => Task 0, Epoch 6/40 => Loss 0.197, Train_accy 93.55
2022-10-08 10:34:56,998 [foster.py] => Task 0, Epoch 7/40 => Loss 0.159, Train_accy 94.99, Test_accy 87.92
2022-10-08 10:34:59,958 [foster.py] => Task 0, Epoch 8/40 => Loss 0.128, Train_accy 95.82, Test_accy 89.26
2022-10-08 10:35:02,887 [foster.py] => Task 0, Epoch 9/40 => Loss 0.128, Train_accy 95.68, Test_accy 85.23
2022-10-08 10:35:06,013 [foster.py] => Task 0, Epoch 10/40 => Loss 0.104, Train_accy 96.50, Test_accy 89.26
2022-10-08 10:35:08,468 [foster.py] => Task 0, Epoch 11/40 => Loss 0.078, Train_accy 97.67
2022-10-08 10:35:11,425 [foster.py] => Task 0, Epoch 12/40 => Loss 0.072, Train_accy 98.08, Test_accy 89.26
2022-10-08 10:35:14,454 [foster.py] => Task 0, Epoch 13/40 => Loss 0.067, Train_accy 97.94, Test_accy 88.59
2022-10-08 10:35:17,450 [foster.py] => Task 0, Epoch 14/40 => Loss 0.047, Train_accy 98.56, Test_accy 88.59
2022-10-08 10:35:20,423 [foster.py] => Task 0, Epoch 15/40 => Loss 0.048, Train_accy 98.63, Test_accy 87.25
2022-10-08 10:35:22,800 [foster.py] => Task 0, Epoch 16/40 => Loss 0.044, Train_accy 98.90
2022-10-08 10:35:25,874 [foster.py] => Task 0, Epoch 17/40 => Loss 0.031, Train_accy 99.25, Test_accy 88.59
2022-10-08 10:35:28,885 [foster.py] => Task 0, Epoch 18/40 => Loss 0.028, Train_accy 99.52, Test_accy 89.26
2022-10-08 10:35:31,863 [foster.py] => Task 0, Epoch 19/40 => Loss 0.029, Train_accy 99.52, Test_accy 89.26
2022-10-08 10:35:35,017 [foster.py] => Task 0, Epoch 20/40 => Loss 0.027, Train_accy 99.31, Test_accy 90.60
2022-10-08 10:35:38,722 [foster.py] => Task 0, Epoch 21/40 => Loss 0.018, Train_accy 99.79
2022-10-08 10:35:42,096 [foster.py] => Task 0, Epoch 22/40 => Loss 0.029, Train_accy 99.31, Test_accy 89.26
2022-10-08 10:35:45,143 [foster.py] => Task 0, Epoch 23/40 => Loss 0.019, Train_accy 99.66, Test_accy 89.93
2022-10-08 10:35:48,174 [foster.py] => Task 0, Epoch 24/40 => Loss 0.020, Train_accy 99.66, Test_accy 89.26
2022-10-08 10:35:51,127 [foster.py] => Task 0, Epoch 25/40 => Loss 0.017, Train_accy 99.86, Test_accy 89.93
2022-10-08 10:35:53,508 [foster.py] => Task 0, Epoch 26/40 => Loss 0.028, Train_accy 99.04
2022-10-08 10:35:56,472 [foster.py] => Task 0, Epoch 27/40 => Loss 0.022, Train_accy 99.45, Test_accy 90.60
2022-10-08 10:35:59,423 [foster.py] => Task 0, Epoch 28/40 => Loss 0.019, Train_accy 99.45, Test_accy 90.60
2022-10-08 10:36:02,399 [foster.py] => Task 0, Epoch 29/40 => Loss 0.019, Train_accy 99.52, Test_accy 90.60
2022-10-08 10:36:05,425 [foster.py] => Task 0, Epoch 30/40 => Loss 0.015, Train_accy 99.79, Test_accy 91.28
2022-10-08 10:36:07,900 [foster.py] => Task 0, Epoch 31/40 => Loss 0.015, Train_accy 99.79
2022-10-08 10:36:10,881 [foster.py] => Task 0, Epoch 32/40 => Loss 0.015, Train_accy 99.86, Test_accy 89.93
2022-10-08 10:36:13,894 [foster.py] => Task 0, Epoch 33/40 => Loss 0.014, Train_accy 99.79, Test_accy 91.28
2022-10-08 10:36:16,922 [foster.py] => Task 0, Epoch 34/40 => Loss 0.016, Train_accy 99.73, Test_accy 91.28
2022-10-08 10:36:19,980 [foster.py] => Task 0, Epoch 35/40 => Loss 0.014, Train_accy 99.86, Test_accy 91.28
2022-10-08 10:36:22,407 [foster.py] => Task 0, Epoch 36/40 => Loss 0.016, Train_accy 99.79
2022-10-08 10:36:25,455 [foster.py] => Task 0, Epoch 37/40 => Loss 0.009, Train_accy 99.93, Test_accy 90.60
2022-10-08 10:36:28,452 [foster.py] => Task 0, Epoch 38/40 => Loss 0.017, Train_accy 99.59, Test_accy 91.28
2022-10-08 10:36:31,454 [foster.py] => Task 0, Epoch 39/40 => Loss 0.015, Train_accy 99.86, Test_accy 90.60
2022-10-08 10:36:34,462 [foster.py] => Task 0, Epoch 40/40 => Loss 0.013, Train_accy 99.86, Test_accy 89.93
2022-10-08 10:36:34,463 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 10:36:41,088 [foster.py] => Exemplar size: 140
2022-10-08 10:36:41,088 [trainer.py] => CNN: {'total': 89.93, 'old': 89.93, 'new': 0, 'base': 89.93, 'compound': 0}
2022-10-08 10:36:41,088 [trainer.py] => CNN top1 curve: [89.93]
2022-10-08 10:36:41,088 [trainer.py] => CNN base curve: [89.93]
2022-10-08 10:36:41,088 [trainer.py] => CNN old curve: [89.93]
2022-10-08 10:36:41,088 [trainer.py] => CNN new curve: [0]
2022-10-08 10:36:41,088 [trainer.py] => CNN compound curve: [0]
2022-10-08 10:36:41,088 [trainer.py] => NME: {'total': 91.28, 'old': 91.28, 'new': 0, 'base': 91.28, 'compound': 0}
2022-10-08 10:36:41,088 [trainer.py] => NME top1 curve: [91.28]
2022-10-08 10:36:41,089 [trainer.py] => NME base curve: [91.28]
2022-10-08 10:36:41,089 [trainer.py] => NME old curve: [91.28]
2022-10-08 10:36:41,089 [trainer.py] => NME new curve: [0]
2022-10-08 10:36:41,089 [trainer.py] => NME compound curve: [0]
2022-10-08 10:36:41,315 [foster.py] => Learning on 7-12
2022-10-08 10:36:41,316 [foster.py] => All params: 22375071
2022-10-08 10:36:41,316 [foster.py] => Trainable params: 11194968
2022-10-08 10:36:41,325 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 10:36:44,503 [foster.py] => Task 1, Epoch 1/34 => Loss 5.049, Loss_clf 2.416, Loss_fe 2.037, Loss_kd 0.348, Train_accy 30.19, Test_accy 56.13
2022-10-08 10:36:46,959 [foster.py] => Task 1, Epoch 2/34 => Loss 3.053, Loss_clf 1.035, Loss_fe 1.455, Loss_kd 0.329, Train_accy 44.51
2022-10-08 10:36:49,383 [foster.py] => Task 1, Epoch 3/34 => Loss 2.736, Loss_clf 0.920, Loss_fe 1.275, Loss_kd 0.315, Train_accy 33.36
2022-10-08 10:36:51,800 [foster.py] => Task 1, Epoch 4/34 => Loss 2.579, Loss_clf 0.862, Loss_fe 1.177, Loss_kd 0.315, Train_accy 34.73
2022-10-08 10:36:54,253 [foster.py] => Task 1, Epoch 5/34 => Loss 2.514, Loss_clf 0.858, Loss_fe 1.123, Loss_kd 0.311, Train_accy 36.11
2022-10-08 10:36:57,440 [foster.py] => Task 1, Epoch 6/34 => Loss 2.477, Loss_clf 0.861, Loss_fe 1.075, Loss_kd 0.316, Train_accy 32.76, Test_accy 55.39
2022-10-08 10:36:59,983 [foster.py] => Task 1, Epoch 7/34 => Loss 2.370, Loss_clf 0.818, Loss_fe 1.013, Loss_kd 0.314, Train_accy 34.31
2022-10-08 10:37:02,590 [foster.py] => Task 1, Epoch 8/34 => Loss 2.309, Loss_clf 0.797, Loss_fe 0.980, Loss_kd 0.310, Train_accy 35.76
2022-10-08 10:37:05,289 [foster.py] => Task 1, Epoch 9/34 => Loss 2.289, Loss_clf 0.799, Loss_fe 0.961, Loss_kd 0.309, Train_accy 37.91
2022-10-08 10:37:07,903 [foster.py] => Task 1, Epoch 10/34 => Loss 2.201, Loss_clf 0.757, Loss_fe 0.910, Loss_kd 0.311, Train_accy 38.94
2022-10-08 10:37:11,253 [foster.py] => Task 1, Epoch 11/34 => Loss 2.140, Loss_clf 0.727, Loss_fe 0.882, Loss_kd 0.310, Train_accy 37.91, Test_accy 56.51
2022-10-08 10:37:13,809 [foster.py] => Task 1, Epoch 12/34 => Loss 2.131, Loss_clf 0.730, Loss_fe 0.867, Loss_kd 0.312, Train_accy 38.85
2022-10-08 10:37:20,435 [foster.py] => Task 1, Epoch 13/34 => Loss 2.086, Loss_clf 0.711, Loss_fe 0.846, Loss_kd 0.309, Train_accy 39.45
2022-10-08 10:37:24,048 [foster.py] => Task 1, Epoch 14/34 => Loss 2.036, Loss_clf 0.673, Loss_fe 0.827, Loss_kd 0.312, Train_accy 40.74
2022-10-08 10:37:26,922 [foster.py] => Task 1, Epoch 15/34 => Loss 2.010, Loss_clf 0.681, Loss_fe 0.801, Loss_kd 0.308, Train_accy 40.14
2022-10-08 10:37:30,321 [foster.py] => Task 1, Epoch 16/34 => Loss 2.018, Loss_clf 0.682, Loss_fe 0.813, Loss_kd 0.305, Train_accy 38.68, Test_accy 56.13
2022-10-08 10:37:32,768 [foster.py] => Task 1, Epoch 17/34 => Loss 1.986, Loss_clf 0.661, Loss_fe 0.797, Loss_kd 0.308, Train_accy 41.42
2022-10-08 10:37:35,197 [foster.py] => Task 1, Epoch 18/34 => Loss 1.941, Loss_clf 0.646, Loss_fe 0.764, Loss_kd 0.309, Train_accy 41.68
2022-10-08 10:37:37,603 [foster.py] => Task 1, Epoch 19/34 => Loss 1.926, Loss_clf 0.636, Loss_fe 0.756, Loss_kd 0.311, Train_accy 42.02
2022-10-08 10:37:40,095 [foster.py] => Task 1, Epoch 20/34 => Loss 1.865, Loss_clf 0.604, Loss_fe 0.736, Loss_kd 0.306, Train_accy 42.62
2022-10-08 10:37:43,489 [foster.py] => Task 1, Epoch 21/34 => Loss 1.898, Loss_clf 0.624, Loss_fe 0.745, Loss_kd 0.308, Train_accy 43.05, Test_accy 56.51
2022-10-08 10:37:45,995 [foster.py] => Task 1, Epoch 22/34 => Loss 1.862, Loss_clf 0.610, Loss_fe 0.724, Loss_kd 0.308, Train_accy 42.28
2022-10-08 10:37:48,415 [foster.py] => Task 1, Epoch 23/34 => Loss 1.871, Loss_clf 0.609, Loss_fe 0.730, Loss_kd 0.310, Train_accy 43.05
2022-10-08 10:37:51,008 [foster.py] => Task 1, Epoch 24/34 => Loss 1.903, Loss_clf 0.627, Loss_fe 0.745, Loss_kd 0.310, Train_accy 42.11
2022-10-08 10:37:53,660 [foster.py] => Task 1, Epoch 25/34 => Loss 1.864, Loss_clf 0.610, Loss_fe 0.720, Loss_kd 0.312, Train_accy 44.25
2022-10-08 10:37:57,089 [foster.py] => Task 1, Epoch 26/34 => Loss 1.824, Loss_clf 0.591, Loss_fe 0.702, Loss_kd 0.310, Train_accy 45.88, Test_accy 56.88
2022-10-08 10:37:59,598 [foster.py] => Task 1, Epoch 27/34 => Loss 1.821, Loss_clf 0.588, Loss_fe 0.700, Loss_kd 0.311, Train_accy 44.77
2022-10-08 10:38:02,252 [foster.py] => Task 1, Epoch 28/34 => Loss 1.841, Loss_clf 0.595, Loss_fe 0.710, Loss_kd 0.313, Train_accy 43.14
2022-10-08 10:38:04,964 [foster.py] => Task 1, Epoch 29/34 => Loss 1.835, Loss_clf 0.592, Loss_fe 0.712, Loss_kd 0.310, Train_accy 42.97
2022-10-08 10:38:07,603 [foster.py] => Task 1, Epoch 30/34 => Loss 1.824, Loss_clf 0.587, Loss_fe 0.703, Loss_kd 0.312, Train_accy 44.77
2022-10-08 10:38:10,991 [foster.py] => Task 1, Epoch 31/34 => Loss 1.825, Loss_clf 0.591, Loss_fe 0.703, Loss_kd 0.310, Train_accy 44.60, Test_accy 57.99
2022-10-08 10:38:13,659 [foster.py] => Task 1, Epoch 32/34 => Loss 1.822, Loss_clf 0.584, Loss_fe 0.706, Loss_kd 0.311, Train_accy 44.43
2022-10-08 10:38:16,213 [foster.py] => Task 1, Epoch 33/34 => Loss 1.782, Loss_clf 0.565, Loss_fe 0.684, Loss_kd 0.311, Train_accy 43.91
2022-10-08 10:38:19,021 [foster.py] => Task 1, Epoch 34/34 => Loss 1.803, Loss_clf 0.579, Loss_fe 0.698, Loss_kd 0.307, Train_accy 43.74
2022-10-08 10:38:19,022 [foster.py] => do not weight align teacher!
2022-10-08 10:38:19,022 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 10:38:22,932 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.842,  Train_accy 11.23, Test_accy 46.84
2022-10-08 10:38:25,921 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.641,  Train_accy 12.18
2022-10-08 10:38:28,986 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.582,  Train_accy 12.18
2022-10-08 10:38:32,017 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.538,  Train_accy 13.46
2022-10-08 10:38:35,066 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.520,  Train_accy 13.12
2022-10-08 10:38:38,742 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.514,  Train_accy 13.72, Test_accy 49.44
2022-10-08 10:38:41,652 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.500,  Train_accy 14.15
2022-10-08 10:38:44,660 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.490,  Train_accy 14.15
2022-10-08 10:38:48,075 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.477,  Train_accy 14.41
2022-10-08 10:38:51,260 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.469,  Train_accy 15.44
2022-10-08 10:38:55,096 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.468,  Train_accy 15.09, Test_accy 49.81
2022-10-08 10:38:58,019 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.467,  Train_accy 14.84
2022-10-08 10:39:01,924 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.458,  Train_accy 14.15
2022-10-08 10:39:05,451 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.456,  Train_accy 14.92
2022-10-08 10:39:08,711 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.454,  Train_accy 15.35
2022-10-08 10:39:12,678 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.447,  Train_accy 15.44, Test_accy 49.81
2022-10-08 10:39:15,535 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.448,  Train_accy 14.24
2022-10-08 10:39:18,388 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.441,  Train_accy 14.49
2022-10-08 10:39:21,507 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.442,  Train_accy 15.61
2022-10-08 10:39:24,581 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.451,  Train_accy 14.92
2022-10-08 10:39:28,325 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.444,  Train_accy 16.04, Test_accy 50.93
2022-10-08 10:39:31,279 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.439,  Train_accy 15.87
2022-10-08 10:39:34,762 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.441,  Train_accy 15.52
2022-10-08 10:39:37,997 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.430,  Train_accy 16.30
2022-10-08 10:39:41,049 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.443,  Train_accy 16.55
2022-10-08 10:39:44,703 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.449,  Train_accy 15.27, Test_accy 50.19
2022-10-08 10:39:44,704 [foster.py] => do not weight align student!
2022-10-08 10:39:45,353 [foster.py] => darknet eval: 
2022-10-08 10:39:45,353 [foster.py] => CNN top1 curve: 50.19
2022-10-08 10:39:45,353 [foster.py] => CNN top5 curve: 97.03
2022-10-08 10:39:45,354 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 10:39:53,076 [foster.py] => Exemplar size: 240
2022-10-08 10:39:53,076 [trainer.py] => CNN: {'total': 57.62, 'old': 83.89, 'new': 25.0, 'base': 83.89, 'compound': 25.0}
2022-10-08 10:39:53,077 [trainer.py] => CNN top1 curve: [89.93, 57.62]
2022-10-08 10:39:53,077 [trainer.py] => CNN base curve: [89.93, 83.89]
2022-10-08 10:39:53,077 [trainer.py] => CNN old curve: [89.93, 83.89]
2022-10-08 10:39:53,077 [trainer.py] => CNN new curve: [0, 25.0]
2022-10-08 10:39:53,077 [trainer.py] => CNN compound curve: [0, 25.0]
2022-10-08 10:39:53,077 [trainer.py] => NME: {'total': 68.4, 'old': 81.21, 'new': 52.5, 'base': 81.21, 'compound': 52.5}
2022-10-08 10:39:53,077 [trainer.py] => NME top1 curve: [91.28, 68.4]
2022-10-08 10:39:53,077 [trainer.py] => NME base curve: [91.28, 81.21]
2022-10-08 10:39:53,077 [trainer.py] => NME old curve: [91.28, 81.21]
2022-10-08 10:39:53,077 [trainer.py] => NME new curve: [0, 52.5]
2022-10-08 10:39:53,077 [trainer.py] => NME compound curve: [0, 52.5]
2022-10-08 10:39:53,302 [foster.py] => Learning on 12-17
2022-10-08 10:39:53,302 [foster.py] => All params: 22385326
2022-10-08 10:39:53,303 [foster.py] => Trainable params: 11202658
2022-10-08 10:39:53,311 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 10:39:56,668 [foster.py] => Task 2, Epoch 1/34 => Loss 5.763, Loss_clf 1.964, Loss_fe 2.355, Loss_kd 1.020, Train_accy 40.85, Test_accy 46.19
2022-10-08 10:39:59,237 [foster.py] => Task 2, Epoch 2/34 => Loss 3.715, Loss_clf 0.880, Loss_fe 1.434, Loss_kd 0.989, Train_accy 41.95
2022-10-08 10:40:01,790 [foster.py] => Task 2, Epoch 3/34 => Loss 3.410, Loss_clf 0.767, Loss_fe 1.231, Loss_kd 0.997, Train_accy 42.03
2022-10-08 10:40:04,366 [foster.py] => Task 2, Epoch 4/34 => Loss 3.233, Loss_clf 0.728, Loss_fe 1.098, Loss_kd 0.993, Train_accy 42.81
2022-10-08 10:40:07,011 [foster.py] => Task 2, Epoch 5/34 => Loss 3.132, Loss_clf 0.691, Loss_fe 1.026, Loss_kd 0.998, Train_accy 41.79
2022-10-08 10:40:10,561 [foster.py] => Task 2, Epoch 6/34 => Loss 3.038, Loss_clf 0.665, Loss_fe 0.962, Loss_kd 0.997, Train_accy 42.50, Test_accy 43.57
2022-10-08 10:40:13,233 [foster.py] => Task 2, Epoch 7/34 => Loss 2.972, Loss_clf 0.645, Loss_fe 0.912, Loss_kd 0.999, Train_accy 43.99
2022-10-08 10:40:15,905 [foster.py] => Task 2, Epoch 8/34 => Loss 2.908, Loss_clf 0.634, Loss_fe 0.860, Loss_kd 0.998, Train_accy 42.97
2022-10-08 10:40:18,721 [foster.py] => Task 2, Epoch 9/34 => Loss 2.859, Loss_clf 0.609, Loss_fe 0.830, Loss_kd 1.002, Train_accy 42.58
2022-10-08 10:40:21,614 [foster.py] => Task 2, Epoch 10/34 => Loss 2.786, Loss_clf 0.593, Loss_fe 0.776, Loss_kd 1.000, Train_accy 43.75
2022-10-08 10:40:25,245 [foster.py] => Task 2, Epoch 11/34 => Loss 2.772, Loss_clf 0.599, Loss_fe 0.766, Loss_kd 0.994, Train_accy 44.54, Test_accy 46.19
2022-10-08 10:40:28,087 [foster.py] => Task 2, Epoch 12/34 => Loss 2.763, Loss_clf 0.587, Loss_fe 0.755, Loss_kd 1.003, Train_accy 43.99
2022-10-08 10:40:30,878 [foster.py] => Task 2, Epoch 13/34 => Loss 2.746, Loss_clf 0.594, Loss_fe 0.741, Loss_kd 0.996, Train_accy 45.17
2022-10-08 10:40:33,692 [foster.py] => Task 2, Epoch 14/34 => Loss 2.693, Loss_clf 0.573, Loss_fe 0.712, Loss_kd 0.994, Train_accy 44.70
2022-10-08 10:40:36,449 [foster.py] => Task 2, Epoch 15/34 => Loss 2.643, Loss_clf 0.542, Loss_fe 0.691, Loss_kd 0.995, Train_accy 44.78
2022-10-08 10:40:40,382 [foster.py] => Task 2, Epoch 16/34 => Loss 2.635, Loss_clf 0.545, Loss_fe 0.678, Loss_kd 0.996, Train_accy 44.93, Test_accy 47.51
2022-10-08 10:40:43,376 [foster.py] => Task 2, Epoch 17/34 => Loss 2.602, Loss_clf 0.531, Loss_fe 0.656, Loss_kd 0.999, Train_accy 46.35
2022-10-08 10:40:46,252 [foster.py] => Task 2, Epoch 18/34 => Loss 2.567, Loss_clf 0.518, Loss_fe 0.637, Loss_kd 0.997, Train_accy 46.50
2022-10-08 10:40:49,114 [foster.py] => Task 2, Epoch 19/34 => Loss 2.575, Loss_clf 0.537, Loss_fe 0.635, Loss_kd 0.991, Train_accy 44.78
2022-10-08 10:40:51,846 [foster.py] => Task 2, Epoch 20/34 => Loss 2.559, Loss_clf 0.519, Loss_fe 0.626, Loss_kd 0.998, Train_accy 46.58
2022-10-08 10:40:55,605 [foster.py] => Task 2, Epoch 21/34 => Loss 2.553, Loss_clf 0.518, Loss_fe 0.621, Loss_kd 0.998, Train_accy 45.95, Test_accy 47.51
2022-10-08 10:40:58,430 [foster.py] => Task 2, Epoch 22/34 => Loss 2.534, Loss_clf 0.515, Loss_fe 0.611, Loss_kd 0.994, Train_accy 46.66
2022-10-08 10:41:01,239 [foster.py] => Task 2, Epoch 23/34 => Loss 2.542, Loss_clf 0.514, Loss_fe 0.608, Loss_kd 1.003, Train_accy 46.66
2022-10-08 10:41:04,140 [foster.py] => Task 2, Epoch 24/34 => Loss 2.523, Loss_clf 0.509, Loss_fe 0.611, Loss_kd 0.990, Train_accy 45.25
2022-10-08 10:41:07,497 [foster.py] => Task 2, Epoch 25/34 => Loss 2.514, Loss_clf 0.503, Loss_fe 0.593, Loss_kd 1.002, Train_accy 46.98
2022-10-08 10:41:11,252 [foster.py] => Task 2, Epoch 26/34 => Loss 2.499, Loss_clf 0.496, Loss_fe 0.583, Loss_kd 1.002, Train_accy 48.15, Test_accy 47.51
2022-10-08 10:41:13,905 [foster.py] => Task 2, Epoch 27/34 => Loss 2.547, Loss_clf 0.512, Loss_fe 0.614, Loss_kd 1.003, Train_accy 47.92
2022-10-08 10:41:16,555 [foster.py] => Task 2, Epoch 28/34 => Loss 2.486, Loss_clf 0.490, Loss_fe 0.578, Loss_kd 1.001, Train_accy 47.84
2022-10-08 10:41:19,353 [foster.py] => Task 2, Epoch 29/34 => Loss 2.500, Loss_clf 0.495, Loss_fe 0.584, Loss_kd 1.003, Train_accy 47.45
2022-10-08 10:41:22,275 [foster.py] => Task 2, Epoch 30/34 => Loss 2.486, Loss_clf 0.492, Loss_fe 0.581, Loss_kd 0.998, Train_accy 46.50
2022-10-08 10:41:26,096 [foster.py] => Task 2, Epoch 31/34 => Loss 2.484, Loss_clf 0.491, Loss_fe 0.579, Loss_kd 0.998, Train_accy 47.13, Test_accy 47.77
2022-10-08 10:41:28,953 [foster.py] => Task 2, Epoch 32/34 => Loss 2.492, Loss_clf 0.491, Loss_fe 0.595, Loss_kd 0.992, Train_accy 45.88
2022-10-08 10:41:31,661 [foster.py] => Task 2, Epoch 33/34 => Loss 2.484, Loss_clf 0.492, Loss_fe 0.580, Loss_kd 0.997, Train_accy 47.92
2022-10-08 10:41:34,699 [foster.py] => Task 2, Epoch 34/34 => Loss 2.480, Loss_clf 0.486, Loss_fe 0.575, Loss_kd 1.002, Train_accy 49.33
2022-10-08 10:41:34,699 [foster.py] => do not weight align teacher!
2022-10-08 10:41:34,700 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 10:41:38,864 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.137,  Train_accy 10.92, Test_accy 32.81
2022-10-08 10:41:42,069 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 2.021,  Train_accy 11.08
2022-10-08 10:41:45,464 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.988,  Train_accy 11.31
2022-10-08 10:41:48,898 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.965,  Train_accy 11.15
2022-10-08 10:41:52,223 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.946,  Train_accy 11.63
2022-10-08 10:41:57,249 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.932,  Train_accy 11.15, Test_accy 35.17
2022-10-08 10:42:00,859 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.932,  Train_accy 11.55
2022-10-08 10:42:04,199 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.926,  Train_accy 11.86
2022-10-08 10:42:07,429 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.907,  Train_accy 11.70
2022-10-08 10:42:11,238 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.901,  Train_accy 12.18
2022-10-08 10:42:15,565 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.906,  Train_accy 12.02, Test_accy 35.70
2022-10-08 10:42:18,725 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.895,  Train_accy 12.65
2022-10-08 10:42:22,050 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.895,  Train_accy 13.28
2022-10-08 10:42:25,431 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.881,  Train_accy 13.04
2022-10-08 10:42:28,835 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.880,  Train_accy 13.12
2022-10-08 10:42:32,726 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.881,  Train_accy 14.06, Test_accy 36.48
2022-10-08 10:42:35,877 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.884,  Train_accy 13.28
2022-10-08 10:42:39,289 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.876,  Train_accy 13.83
2022-10-08 10:42:42,717 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.875,  Train_accy 13.59
2022-10-08 10:42:46,114 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.876,  Train_accy 13.90
2022-10-08 10:42:50,779 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.871,  Train_accy 14.30, Test_accy 37.27
2022-10-08 10:42:53,980 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.879,  Train_accy 14.06
2022-10-08 10:43:01,890 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.872,  Train_accy 13.90
2022-10-08 10:43:06,071 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.867,  Train_accy 13.35
2022-10-08 10:43:09,552 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.870,  Train_accy 14.14
2022-10-08 10:43:13,609 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.876,  Train_accy 14.30, Test_accy 37.27
2022-10-08 10:43:13,610 [foster.py] => do not weight align student!
2022-10-08 10:43:14,336 [foster.py] => darknet eval: 
2022-10-08 10:43:14,336 [foster.py] => CNN top1 curve: 37.27
2022-10-08 10:43:14,336 [foster.py] => CNN top5 curve: 93.7
2022-10-08 10:43:14,337 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 10:43:23,739 [foster.py] => Exemplar size: 340
2022-10-08 10:43:23,739 [trainer.py] => CNN: {'total': 47.51, 'old': 51.3, 'new': 38.39, 'base': 79.19, 'compound': 27.16}
2022-10-08 10:43:23,739 [trainer.py] => CNN top1 curve: [89.93, 57.62, 47.51]
2022-10-08 10:43:23,739 [trainer.py] => CNN base curve: [89.93, 83.89, 79.19]
2022-10-08 10:43:23,739 [trainer.py] => CNN old curve: [89.93, 83.89, 51.3]
2022-10-08 10:43:23,739 [trainer.py] => CNN new curve: [0, 25.0, 38.39]
2022-10-08 10:43:23,739 [trainer.py] => CNN compound curve: [0, 25.0, 27.16]
2022-10-08 10:43:23,739 [trainer.py] => NME: {'total': 59.06, 'old': 57.99, 'new': 61.61, 'base': 68.46, 'compound': 53.02}
2022-10-08 10:43:23,739 [trainer.py] => NME top1 curve: [91.28, 68.4, 59.06]
2022-10-08 10:43:23,739 [trainer.py] => NME base curve: [91.28, 81.21, 68.46]
2022-10-08 10:43:23,739 [trainer.py] => NME old curve: [91.28, 81.21, 57.99]
2022-10-08 10:43:23,739 [trainer.py] => NME new curve: [0, 52.5, 61.61]
2022-10-08 10:43:23,739 [trainer.py] => NME compound curve: [0, 52.5, 53.02]
2022-10-08 10:43:23,963 [foster.py] => Learning on 17-22
2022-10-08 10:43:23,964 [foster.py] => All params: 22395581
2022-10-08 10:43:23,964 [foster.py] => Trainable params: 11210348
2022-10-08 10:43:23,973 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 10:43:27,598 [foster.py] => Task 3, Epoch 1/34 => Loss 6.665, Loss_clf 2.142, Loss_fe 2.473, Loss_kd 1.584, Train_accy 31.06, Test_accy 35.12
2022-10-08 10:43:30,327 [foster.py] => Task 3, Epoch 2/34 => Loss 5.065, Loss_clf 1.199, Loss_fe 1.823, Loss_kd 1.578, Train_accy 40.88
2022-10-08 10:43:33,024 [foster.py] => Task 3, Epoch 3/34 => Loss 4.684, Loss_clf 1.076, Loss_fe 1.581, Loss_kd 1.566, Train_accy 41.83
2022-10-08 10:43:35,755 [foster.py] => Task 3, Epoch 4/34 => Loss 4.492, Loss_clf 1.029, Loss_fe 1.428, Loss_kd 1.573, Train_accy 42.20
2022-10-08 10:43:38,503 [foster.py] => Task 3, Epoch 5/34 => Loss 4.343, Loss_clf 0.986, Loss_fe 1.327, Loss_kd 1.569, Train_accy 41.68
2022-10-08 10:43:42,158 [foster.py] => Task 3, Epoch 6/34 => Loss 4.236, Loss_clf 0.953, Loss_fe 1.258, Loss_kd 1.565, Train_accy 44.40, Test_accy 42.66
2022-10-08 10:43:44,928 [foster.py] => Task 3, Epoch 7/34 => Loss 4.163, Loss_clf 0.940, Loss_fe 1.192, Loss_kd 1.570, Train_accy 45.05
2022-10-08 10:43:47,660 [foster.py] => Task 3, Epoch 8/34 => Loss 4.118, Loss_clf 0.929, Loss_fe 1.154, Loss_kd 1.573, Train_accy 44.62
2022-10-08 10:43:50,538 [foster.py] => Task 3, Epoch 9/34 => Loss 4.043, Loss_clf 0.898, Loss_fe 1.109, Loss_kd 1.573, Train_accy 44.40
2022-10-08 10:43:53,768 [foster.py] => Task 3, Epoch 10/34 => Loss 3.973, Loss_clf 0.879, Loss_fe 1.062, Loss_kd 1.570, Train_accy 44.54
2022-10-08 10:43:57,773 [foster.py] => Task 3, Epoch 11/34 => Loss 3.903, Loss_clf 0.856, Loss_fe 1.014, Loss_kd 1.571, Train_accy 46.96, Test_accy 45.04
2022-10-08 10:44:00,686 [foster.py] => Task 3, Epoch 12/34 => Loss 3.895, Loss_clf 0.856, Loss_fe 1.008, Loss_kd 1.570, Train_accy 45.13
2022-10-08 10:44:03,609 [foster.py] => Task 3, Epoch 13/34 => Loss 3.876, Loss_clf 0.847, Loss_fe 0.986, Loss_kd 1.578, Train_accy 45.93
2022-10-08 10:44:06,826 [foster.py] => Task 3, Epoch 14/34 => Loss 3.812, Loss_clf 0.824, Loss_fe 0.949, Loss_kd 1.575, Train_accy 48.06
2022-10-08 10:44:10,089 [foster.py] => Task 3, Epoch 15/34 => Loss 3.789, Loss_clf 0.815, Loss_fe 0.932, Loss_kd 1.578, Train_accy 45.64
2022-10-08 10:44:14,130 [foster.py] => Task 3, Epoch 16/34 => Loss 3.776, Loss_clf 0.809, Loss_fe 0.928, Loss_kd 1.575, Train_accy 47.11, Test_accy 46.43
2022-10-08 10:44:17,031 [foster.py] => Task 3, Epoch 17/34 => Loss 3.741, Loss_clf 0.798, Loss_fe 0.905, Loss_kd 1.575, Train_accy 46.52
2022-10-08 10:44:20,455 [foster.py] => Task 3, Epoch 18/34 => Loss 3.725, Loss_clf 0.790, Loss_fe 0.892, Loss_kd 1.579, Train_accy 46.74
2022-10-08 10:44:23,763 [foster.py] => Task 3, Epoch 19/34 => Loss 3.654, Loss_clf 0.754, Loss_fe 0.857, Loss_kd 1.579, Train_accy 49.60
2022-10-08 10:44:27,113 [foster.py] => Task 3, Epoch 20/34 => Loss 3.674, Loss_clf 0.763, Loss_fe 0.870, Loss_kd 1.577, Train_accy 49.23
2022-10-08 10:44:31,430 [foster.py] => Task 3, Epoch 21/34 => Loss 3.649, Loss_clf 0.751, Loss_fe 0.858, Loss_kd 1.576, Train_accy 48.79, Test_accy 45.63
2022-10-08 10:44:34,393 [foster.py] => Task 3, Epoch 22/34 => Loss 3.650, Loss_clf 0.760, Loss_fe 0.851, Loss_kd 1.576, Train_accy 48.57
2022-10-08 10:44:37,374 [foster.py] => Task 3, Epoch 23/34 => Loss 3.652, Loss_clf 0.758, Loss_fe 0.849, Loss_kd 1.580, Train_accy 47.99
2022-10-08 10:44:40,336 [foster.py] => Task 3, Epoch 24/34 => Loss 3.605, Loss_clf 0.739, Loss_fe 0.821, Loss_kd 1.581, Train_accy 49.52
2022-10-08 10:44:43,327 [foster.py] => Task 3, Epoch 25/34 => Loss 3.597, Loss_clf 0.734, Loss_fe 0.819, Loss_kd 1.579, Train_accy 48.57
2022-10-08 10:44:47,462 [foster.py] => Task 3, Epoch 26/34 => Loss 3.608, Loss_clf 0.742, Loss_fe 0.825, Loss_kd 1.577, Train_accy 48.86, Test_accy 45.63
2022-10-08 10:44:50,585 [foster.py] => Task 3, Epoch 27/34 => Loss 3.592, Loss_clf 0.736, Loss_fe 0.810, Loss_kd 1.582, Train_accy 49.89
2022-10-08 10:44:53,563 [foster.py] => Task 3, Epoch 28/34 => Loss 3.620, Loss_clf 0.746, Loss_fe 0.828, Loss_kd 1.581, Train_accy 48.86
2022-10-08 10:44:56,524 [foster.py] => Task 3, Epoch 29/34 => Loss 3.588, Loss_clf 0.734, Loss_fe 0.813, Loss_kd 1.577, Train_accy 48.35
2022-10-08 10:44:59,429 [foster.py] => Task 3, Epoch 30/34 => Loss 3.605, Loss_clf 0.730, Loss_fe 0.831, Loss_kd 1.579, Train_accy 48.21
2022-10-08 10:45:03,458 [foster.py] => Task 3, Epoch 31/34 => Loss 3.601, Loss_clf 0.744, Loss_fe 0.821, Loss_kd 1.574, Train_accy 48.72, Test_accy 45.63
2022-10-08 10:45:06,301 [foster.py] => Task 3, Epoch 32/34 => Loss 3.598, Loss_clf 0.738, Loss_fe 0.815, Loss_kd 1.580, Train_accy 48.57
2022-10-08 10:45:09,127 [foster.py] => Task 3, Epoch 33/34 => Loss 3.593, Loss_clf 0.735, Loss_fe 0.815, Loss_kd 1.579, Train_accy 48.86
2022-10-08 10:45:12,156 [foster.py] => Task 3, Epoch 34/34 => Loss 3.562, Loss_clf 0.725, Loss_fe 0.802, Loss_kd 1.572, Train_accy 49.30
2022-10-08 10:45:12,156 [foster.py] => do not weight align teacher!
2022-10-08 10:45:12,157 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 10:45:16,789 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.505,  Train_accy 11.28, Test_accy 29.96
2022-10-08 10:45:20,210 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.461,  Train_accy 11.65
2022-10-08 10:45:23,691 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.441,  Train_accy 12.01
2022-10-08 10:45:27,701 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.424,  Train_accy 12.16
2022-10-08 10:45:31,359 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.420,  Train_accy 12.09
2022-10-08 10:45:35,782 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.407,  Train_accy 12.97, Test_accy 31.35
2022-10-08 10:45:39,239 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.396,  Train_accy 12.67
2022-10-08 10:45:43,376 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.399,  Train_accy 13.41
2022-10-08 10:45:47,571 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.396,  Train_accy 13.55
2022-10-08 10:45:51,422 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.388,  Train_accy 13.11
2022-10-08 10:45:56,052 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.387,  Train_accy 14.07, Test_accy 33.13
2022-10-08 10:45:59,406 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.382,  Train_accy 13.85
2022-10-08 10:46:02,813 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.377,  Train_accy 13.85
2022-10-08 10:46:09,015 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.372,  Train_accy 13.70
2022-10-08 10:46:13,213 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.384,  Train_accy 14.87
2022-10-08 10:46:18,245 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.378,  Train_accy 15.31, Test_accy 33.93
2022-10-08 10:46:21,650 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.376,  Train_accy 15.09
2022-10-08 10:46:24,901 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.369,  Train_accy 15.09
2022-10-08 10:46:28,094 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.375,  Train_accy 14.43
2022-10-08 10:46:31,477 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.369,  Train_accy 15.75
2022-10-08 10:46:35,919 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.370,  Train_accy 15.09, Test_accy 33.53
2022-10-08 10:46:39,230 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.370,  Train_accy 15.31
2022-10-08 10:46:46,507 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.366,  Train_accy 14.51
2022-10-08 10:46:51,625 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.373,  Train_accy 15.60
2022-10-08 10:46:55,753 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.366,  Train_accy 15.97
2022-10-08 10:47:00,382 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.364,  Train_accy 16.48, Test_accy 34.52
2022-10-08 10:47:00,383 [foster.py] => do not weight align student!
2022-10-08 10:47:01,172 [foster.py] => darknet eval: 
2022-10-08 10:47:01,172 [foster.py] => CNN top1 curve: 34.52
2022-10-08 10:47:01,172 [foster.py] => CNN top5 curve: 82.14
2022-10-08 10:47:01,173 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 10:47:12,290 [foster.py] => Exemplar size: 440
2022-10-08 10:47:12,290 [trainer.py] => CNN: {'total': 45.63, 'old': 49.08, 'new': 34.96, 'base': 78.52, 'compound': 31.83}
2022-10-08 10:47:12,290 [trainer.py] => CNN top1 curve: [89.93, 57.62, 47.51, 45.63]
2022-10-08 10:47:12,290 [trainer.py] => CNN base curve: [89.93, 83.89, 79.19, 78.52]
2022-10-08 10:47:12,290 [trainer.py] => CNN old curve: [89.93, 83.89, 51.3, 49.08]
2022-10-08 10:47:12,290 [trainer.py] => CNN new curve: [0, 25.0, 38.39, 34.96]
2022-10-08 10:47:12,290 [trainer.py] => CNN compound curve: [0, 25.0, 27.16, 31.83]
2022-10-08 10:47:12,290 [trainer.py] => NME: {'total': 53.97, 'old': 53.54, 'new': 55.28, 'base': 69.8, 'compound': 47.32}
2022-10-08 10:47:12,290 [trainer.py] => NME top1 curve: [91.28, 68.4, 59.06, 53.97]
2022-10-08 10:47:12,290 [trainer.py] => NME base curve: [91.28, 81.21, 68.46, 69.8]
2022-10-08 10:47:12,291 [trainer.py] => NME old curve: [91.28, 81.21, 57.99, 53.54]
2022-10-08 10:47:12,291 [trainer.py] => NME new curve: [0, 52.5, 61.61, 55.28]
2022-10-08 10:47:12,291 [trainer.py] => NME compound curve: [0, 52.5, 53.02, 47.32]
2022-10-08 10:47:12,292 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 10:47:12,292 [trainer.py] => prefix: cil
2022-10-08 10:47:12,292 [trainer.py] => dataset: CFEE
2022-10-08 10:47:12,292 [trainer.py] => memory_size: 2000
2022-10-08 10:47:12,292 [trainer.py] => memory_per_class: 20
2022-10-08 10:47:12,292 [trainer.py] => fixed_memory: True
2022-10-08 10:47:12,292 [trainer.py] => shuffle: True
2022-10-08 10:47:12,292 [trainer.py] => init_cls: 7
2022-10-08 10:47:12,292 [trainer.py] => increment: 5
2022-10-08 10:47:12,292 [trainer.py] => model_name: foster
2022-10-08 10:47:12,292 [trainer.py] => convnet_type: resnet18
2022-10-08 10:47:12,292 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 10:47:12,292 [trainer.py] => seed: 1993
2022-10-08 10:47:12,292 [trainer.py] => beta1: 0.96
2022-10-08 10:47:12,292 [trainer.py] => beta2: 0.97
2022-10-08 10:47:12,292 [trainer.py] => oofc: ft
2022-10-08 10:47:12,292 [trainer.py] => is_teacher_wa: False
2022-10-08 10:47:12,292 [trainer.py] => is_student_wa: False
2022-10-08 10:47:12,293 [trainer.py] => lambda_okd: 1
2022-10-08 10:47:12,293 [trainer.py] => wa_value: 1
2022-10-08 10:47:12,293 [trainer.py] => init_epochs: 40
2022-10-08 10:47:12,293 [trainer.py] => init_lr: 0.01
2022-10-08 10:47:12,293 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 10:47:12,293 [trainer.py] => boosting_epochs: 34
2022-10-08 10:47:12,293 [trainer.py] => compression_epochs: 26
2022-10-08 10:47:12,293 [trainer.py] => lr: 0.001
2022-10-08 10:47:12,293 [trainer.py] => batch_size: 32
2022-10-08 10:47:12,293 [trainer.py] => weight_decay: 0.0005
2022-10-08 10:47:12,293 [trainer.py] => num_workers: 8
2022-10-08 10:47:12,293 [trainer.py] => T: 2
2022-10-08 10:47:12,293 [trainer.py] => nb_runs: 3
2022-10-08 10:47:12,293 [trainer.py] => fold: 10
2022-10-08 10:47:12,293 [data.py] => ========== Fold:8 ==========
2022-10-08 10:47:12,298 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 12, 10, 19, 21, 17, 18, 8, 7, 9, 14, 15, 13, 11, 16]
2022-10-08 10:47:12,517 [foster.py] => Learning on 0-7
2022-10-08 10:47:12,517 [foster.py] => All params: 11183694
2022-10-08 10:47:12,517 [foster.py] => Trainable params: 11183694
2022-10-08 10:47:14,861 [foster.py] => Task 0, Epoch 1/40 => Loss 1.330, Train_accy 52.52
2022-10-08 10:47:17,778 [foster.py] => Task 0, Epoch 2/40 => Loss 0.563, Train_accy 80.40, Test_accy 85.44
2022-10-08 10:47:20,704 [foster.py] => Task 0, Epoch 3/40 => Loss 0.361, Train_accy 87.78, Test_accy 84.81
2022-10-08 10:47:23,720 [foster.py] => Task 0, Epoch 4/40 => Loss 0.285, Train_accy 89.79, Test_accy 85.44
2022-10-08 10:47:26,617 [foster.py] => Task 0, Epoch 5/40 => Loss 0.216, Train_accy 92.96, Test_accy 84.18
2022-10-08 10:47:28,985 [foster.py] => Task 0, Epoch 6/40 => Loss 0.193, Train_accy 93.03
2022-10-08 10:47:31,931 [foster.py] => Task 0, Epoch 7/40 => Loss 0.160, Train_accy 94.62, Test_accy 87.34
2022-10-08 10:47:34,875 [foster.py] => Task 0, Epoch 8/40 => Loss 0.118, Train_accy 96.48, Test_accy 86.08
2022-10-08 10:47:37,825 [foster.py] => Task 0, Epoch 9/40 => Loss 0.117, Train_accy 95.93, Test_accy 86.71
2022-10-08 10:47:40,782 [foster.py] => Task 0, Epoch 10/40 => Loss 0.094, Train_accy 96.83, Test_accy 84.18
2022-10-08 10:47:43,177 [foster.py] => Task 0, Epoch 11/40 => Loss 0.093, Train_accy 97.31
2022-10-08 10:47:46,184 [foster.py] => Task 0, Epoch 12/40 => Loss 0.068, Train_accy 98.48, Test_accy 87.34
2022-10-08 10:47:49,163 [foster.py] => Task 0, Epoch 13/40 => Loss 0.059, Train_accy 98.14, Test_accy 85.44
2022-10-08 10:47:52,135 [foster.py] => Task 0, Epoch 14/40 => Loss 0.057, Train_accy 98.27, Test_accy 86.08
2022-10-08 10:47:55,113 [foster.py] => Task 0, Epoch 15/40 => Loss 0.046, Train_accy 98.76, Test_accy 84.81
2022-10-08 10:47:57,503 [foster.py] => Task 0, Epoch 16/40 => Loss 0.060, Train_accy 97.86
2022-10-08 10:48:00,463 [foster.py] => Task 0, Epoch 17/40 => Loss 0.051, Train_accy 98.76, Test_accy 83.54
2022-10-08 10:48:03,424 [foster.py] => Task 0, Epoch 18/40 => Loss 0.034, Train_accy 99.24, Test_accy 86.71
2022-10-08 10:48:06,409 [foster.py] => Task 0, Epoch 19/40 => Loss 0.039, Train_accy 98.96, Test_accy 86.08
2022-10-08 10:48:09,364 [foster.py] => Task 0, Epoch 20/40 => Loss 0.030, Train_accy 98.83, Test_accy 86.71
2022-10-08 10:48:11,790 [foster.py] => Task 0, Epoch 21/40 => Loss 0.034, Train_accy 99.52
2022-10-08 10:48:17,418 [foster.py] => Task 0, Epoch 22/40 => Loss 0.025, Train_accy 99.45, Test_accy 87.97
2022-10-08 10:48:20,552 [foster.py] => Task 0, Epoch 23/40 => Loss 0.020, Train_accy 99.72, Test_accy 87.97
2022-10-08 10:48:23,557 [foster.py] => Task 0, Epoch 24/40 => Loss 0.023, Train_accy 99.59, Test_accy 89.24
2022-10-08 10:48:26,544 [foster.py] => Task 0, Epoch 25/40 => Loss 0.023, Train_accy 99.65, Test_accy 87.34
2022-10-08 10:48:28,875 [foster.py] => Task 0, Epoch 26/40 => Loss 0.022, Train_accy 99.72
2022-10-08 10:48:31,854 [foster.py] => Task 0, Epoch 27/40 => Loss 0.015, Train_accy 99.79, Test_accy 86.08
2022-10-08 10:48:34,825 [foster.py] => Task 0, Epoch 28/40 => Loss 0.014, Train_accy 99.93, Test_accy 85.44
2022-10-08 10:48:37,853 [foster.py] => Task 0, Epoch 29/40 => Loss 0.012, Train_accy 99.93, Test_accy 86.08
2022-10-08 10:48:40,930 [foster.py] => Task 0, Epoch 30/40 => Loss 0.017, Train_accy 99.79, Test_accy 87.34
2022-10-08 10:48:43,458 [foster.py] => Task 0, Epoch 31/40 => Loss 0.011, Train_accy 99.93
2022-10-08 10:48:46,460 [foster.py] => Task 0, Epoch 32/40 => Loss 0.018, Train_accy 99.79, Test_accy 86.71
2022-10-08 10:48:49,586 [foster.py] => Task 0, Epoch 33/40 => Loss 0.011, Train_accy 100.00, Test_accy 84.18
2022-10-08 10:48:54,410 [foster.py] => Task 0, Epoch 34/40 => Loss 0.013, Train_accy 99.86, Test_accy 86.71
2022-10-08 10:48:57,614 [foster.py] => Task 0, Epoch 35/40 => Loss 0.012, Train_accy 99.93, Test_accy 86.71
2022-10-08 10:49:00,025 [foster.py] => Task 0, Epoch 36/40 => Loss 0.017, Train_accy 99.52
2022-10-08 10:49:03,045 [foster.py] => Task 0, Epoch 37/40 => Loss 0.009, Train_accy 100.00, Test_accy 84.81
2022-10-08 10:49:05,993 [foster.py] => Task 0, Epoch 38/40 => Loss 0.016, Train_accy 99.72, Test_accy 85.44
2022-10-08 10:49:09,025 [foster.py] => Task 0, Epoch 39/40 => Loss 0.010, Train_accy 100.00, Test_accy 85.44
2022-10-08 10:49:12,004 [foster.py] => Task 0, Epoch 40/40 => Loss 0.015, Train_accy 99.79, Test_accy 86.08
2022-10-08 10:49:12,005 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 10:49:18,409 [foster.py] => Exemplar size: 140
2022-10-08 10:49:18,409 [trainer.py] => CNN: {'total': 86.08, 'old': 86.08, 'new': 0, 'base': 86.08, 'compound': 0}
2022-10-08 10:49:18,409 [trainer.py] => CNN top1 curve: [86.08]
2022-10-08 10:49:18,409 [trainer.py] => CNN base curve: [86.08]
2022-10-08 10:49:18,409 [trainer.py] => CNN old curve: [86.08]
2022-10-08 10:49:18,409 [trainer.py] => CNN new curve: [0]
2022-10-08 10:49:18,409 [trainer.py] => CNN compound curve: [0]
2022-10-08 10:49:18,409 [trainer.py] => NME: {'total': 87.97, 'old': 87.97, 'new': 0, 'base': 87.97, 'compound': 0}
2022-10-08 10:49:18,409 [trainer.py] => NME top1 curve: [87.97]
2022-10-08 10:49:18,409 [trainer.py] => NME base curve: [87.97]
2022-10-08 10:49:18,409 [trainer.py] => NME old curve: [87.97]
2022-10-08 10:49:18,409 [trainer.py] => NME new curve: [0]
2022-10-08 10:49:18,409 [trainer.py] => NME compound curve: [0]
2022-10-08 10:49:18,635 [foster.py] => Learning on 7-12
2022-10-08 10:49:18,635 [foster.py] => All params: 22375071
2022-10-08 10:49:18,635 [foster.py] => Trainable params: 11194968
2022-10-08 10:49:18,644 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 10:49:21,808 [foster.py] => Task 1, Epoch 1/34 => Loss 5.130, Loss_clf 2.431, Loss_fe 2.070, Loss_kd 0.367, Train_accy 31.14, Test_accy 53.28
2022-10-08 10:49:24,275 [foster.py] => Task 1, Epoch 2/34 => Loss 3.188, Loss_clf 1.051, Loss_fe 1.579, Loss_kd 0.326, Train_accy 44.22
2022-10-08 10:49:26,735 [foster.py] => Task 1, Epoch 3/34 => Loss 2.840, Loss_clf 0.946, Loss_fe 1.331, Loss_kd 0.328, Train_accy 34.35
2022-10-08 10:49:29,216 [foster.py] => Task 1, Epoch 4/34 => Loss 2.746, Loss_clf 0.927, Loss_fe 1.285, Loss_kd 0.311, Train_accy 35.78
2022-10-08 10:49:34,587 [foster.py] => Task 1, Epoch 5/34 => Loss 2.574, Loss_clf 0.903, Loss_fe 1.139, Loss_kd 0.311, Train_accy 33.76
2022-10-08 10:49:38,319 [foster.py] => Task 1, Epoch 6/34 => Loss 2.508, Loss_clf 0.858, Loss_fe 1.096, Loss_kd 0.323, Train_accy 40.76, Test_accy 61.00
2022-10-08 10:49:40,885 [foster.py] => Task 1, Epoch 7/34 => Loss 2.446, Loss_clf 0.860, Loss_fe 1.060, Loss_kd 0.307, Train_accy 35.78
2022-10-08 10:49:43,410 [foster.py] => Task 1, Epoch 8/34 => Loss 2.407, Loss_clf 0.835, Loss_fe 1.018, Loss_kd 0.323, Train_accy 40.25
2022-10-08 10:49:45,931 [foster.py] => Task 1, Epoch 9/34 => Loss 2.362, Loss_clf 0.844, Loss_fe 0.984, Loss_kd 0.311, Train_accy 38.23
2022-10-08 10:49:48,467 [foster.py] => Task 1, Epoch 10/34 => Loss 2.286, Loss_clf 0.808, Loss_fe 0.948, Loss_kd 0.310, Train_accy 39.58
2022-10-08 10:49:51,779 [foster.py] => Task 1, Epoch 11/34 => Loss 2.270, Loss_clf 0.789, Loss_fe 0.934, Loss_kd 0.319, Train_accy 41.27, Test_accy 62.16
2022-10-08 10:49:54,509 [foster.py] => Task 1, Epoch 12/34 => Loss 2.199, Loss_clf 0.747, Loss_fe 0.900, Loss_kd 0.322, Train_accy 40.93
2022-10-08 10:49:57,137 [foster.py] => Task 1, Epoch 13/34 => Loss 2.186, Loss_clf 0.726, Loss_fe 0.924, Loss_kd 0.312, Train_accy 42.11
2022-10-08 10:49:59,655 [foster.py] => Task 1, Epoch 14/34 => Loss 2.120, Loss_clf 0.704, Loss_fe 0.859, Loss_kd 0.325, Train_accy 40.76
2022-10-08 10:50:02,224 [foster.py] => Task 1, Epoch 15/34 => Loss 2.139, Loss_clf 0.758, Loss_fe 0.856, Loss_kd 0.307, Train_accy 40.84
2022-10-08 10:50:05,475 [foster.py] => Task 1, Epoch 16/34 => Loss 2.184, Loss_clf 0.754, Loss_fe 0.899, Loss_kd 0.310, Train_accy 43.71, Test_accy 62.55
2022-10-08 10:50:07,945 [foster.py] => Task 1, Epoch 17/34 => Loss 2.092, Loss_clf 0.710, Loss_fe 0.816, Loss_kd 0.330, Train_accy 42.45
2022-10-08 10:50:10,436 [foster.py] => Task 1, Epoch 18/34 => Loss 2.035, Loss_clf 0.706, Loss_fe 0.796, Loss_kd 0.311, Train_accy 41.94
2022-10-08 10:50:16,594 [foster.py] => Task 1, Epoch 19/34 => Loss 2.072, Loss_clf 0.711, Loss_fe 0.794, Loss_kd 0.330, Train_accy 42.95
2022-10-08 10:50:20,227 [foster.py] => Task 1, Epoch 20/34 => Loss 2.001, Loss_clf 0.685, Loss_fe 0.783, Loss_kd 0.311, Train_accy 42.95
2022-10-08 10:50:23,775 [foster.py] => Task 1, Epoch 21/34 => Loss 1.932, Loss_clf 0.647, Loss_fe 0.750, Loss_kd 0.312, Train_accy 45.15, Test_accy 62.55
2022-10-08 10:50:26,320 [foster.py] => Task 1, Epoch 22/34 => Loss 1.966, Loss_clf 0.655, Loss_fe 0.771, Loss_kd 0.315, Train_accy 44.89
2022-10-08 10:50:28,838 [foster.py] => Task 1, Epoch 23/34 => Loss 1.993, Loss_clf 0.625, Loss_fe 0.832, Loss_kd 0.312, Train_accy 47.43
2022-10-08 10:50:31,372 [foster.py] => Task 1, Epoch 24/34 => Loss 1.927, Loss_clf 0.651, Loss_fe 0.750, Loss_kd 0.307, Train_accy 46.41
2022-10-08 10:50:33,808 [foster.py] => Task 1, Epoch 25/34 => Loss 1.946, Loss_clf 0.659, Loss_fe 0.759, Loss_kd 0.308, Train_accy 44.98
2022-10-08 10:50:37,014 [foster.py] => Task 1, Epoch 26/34 => Loss 1.935, Loss_clf 0.658, Loss_fe 0.749, Loss_kd 0.308, Train_accy 47.34, Test_accy 62.16
2022-10-08 10:50:39,410 [foster.py] => Task 1, Epoch 27/34 => Loss 1.892, Loss_clf 0.624, Loss_fe 0.726, Loss_kd 0.316, Train_accy 47.76
2022-10-08 10:50:41,855 [foster.py] => Task 1, Epoch 28/34 => Loss 1.883, Loss_clf 0.613, Loss_fe 0.723, Loss_kd 0.319, Train_accy 48.95
2022-10-08 10:50:44,361 [foster.py] => Task 1, Epoch 29/34 => Loss 1.915, Loss_clf 0.652, Loss_fe 0.735, Loss_kd 0.308, Train_accy 48.10
2022-10-08 10:50:46,906 [foster.py] => Task 1, Epoch 30/34 => Loss 1.892, Loss_clf 0.635, Loss_fe 0.726, Loss_kd 0.310, Train_accy 46.75
2022-10-08 10:50:50,407 [foster.py] => Task 1, Epoch 31/34 => Loss 1.905, Loss_clf 0.626, Loss_fe 0.747, Loss_kd 0.310, Train_accy 47.51, Test_accy 61.39
2022-10-08 10:50:53,045 [foster.py] => Task 1, Epoch 32/34 => Loss 1.844, Loss_clf 0.593, Loss_fe 0.728, Loss_kd 0.305, Train_accy 47.76
2022-10-08 10:50:55,698 [foster.py] => Task 1, Epoch 33/34 => Loss 1.862, Loss_clf 0.595, Loss_fe 0.737, Loss_kd 0.309, Train_accy 46.92
2022-10-08 10:50:58,325 [foster.py] => Task 1, Epoch 34/34 => Loss 1.949, Loss_clf 0.642, Loss_fe 0.781, Loss_kd 0.307, Train_accy 48.02
2022-10-08 10:50:58,326 [foster.py] => do not weight align teacher!
2022-10-08 10:50:58,326 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 10:51:02,350 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.939,  Train_accy 11.05, Test_accy 48.26
2022-10-08 10:51:05,576 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.708,  Train_accy 11.90
2022-10-08 10:51:08,847 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.623,  Train_accy 13.16
2022-10-08 10:51:12,098 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.607,  Train_accy 14.26
2022-10-08 10:51:15,321 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.618,  Train_accy 13.76
2022-10-08 10:51:19,195 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.544,  Train_accy 14.94, Test_accy 53.28
2022-10-08 10:51:22,255 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.544,  Train_accy 15.86
2022-10-08 10:51:25,313 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.556,  Train_accy 15.70
2022-10-08 10:51:28,413 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.529,  Train_accy 16.37
2022-10-08 10:51:31,623 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.523,  Train_accy 17.64
2022-10-08 10:51:35,423 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.512,  Train_accy 17.22, Test_accy 54.05
2022-10-08 10:51:38,423 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.500,  Train_accy 17.30
2022-10-08 10:51:42,389 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.490,  Train_accy 17.89
2022-10-08 10:51:46,030 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.494,  Train_accy 18.99
2022-10-08 10:51:49,162 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.489,  Train_accy 18.31
2022-10-08 10:51:52,917 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.497,  Train_accy 17.97, Test_accy 54.83
2022-10-08 10:51:55,904 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.501,  Train_accy 18.57
2022-10-08 10:51:58,918 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.516,  Train_accy 18.73
2022-10-08 10:52:02,248 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.499,  Train_accy 19.49
2022-10-08 10:52:05,347 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.499,  Train_accy 20.00
2022-10-08 10:52:09,106 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.495,  Train_accy 19.75, Test_accy 55.98
2022-10-08 10:52:12,364 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.507,  Train_accy 20.00
2022-10-08 10:52:16,184 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.490,  Train_accy 19.75
2022-10-08 10:52:19,963 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.492,  Train_accy 19.75
2022-10-08 10:52:23,463 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.477,  Train_accy 18.90
2022-10-08 10:52:27,378 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.522,  Train_accy 18.90, Test_accy 55.60
2022-10-08 10:52:27,379 [foster.py] => do not weight align student!
2022-10-08 10:52:28,049 [foster.py] => darknet eval: 
2022-10-08 10:52:28,049 [foster.py] => CNN top1 curve: 55.6
2022-10-08 10:52:28,049 [foster.py] => CNN top5 curve: 96.53
2022-10-08 10:52:28,049 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 10:52:35,660 [foster.py] => Exemplar size: 240
2022-10-08 10:52:35,660 [trainer.py] => CNN: {'total': 62.16, 'old': 77.85, 'new': 37.62, 'base': 77.85, 'compound': 37.62}
2022-10-08 10:52:35,660 [trainer.py] => CNN top1 curve: [86.08, 62.16]
2022-10-08 10:52:35,660 [trainer.py] => CNN base curve: [86.08, 77.85]
2022-10-08 10:52:35,660 [trainer.py] => CNN old curve: [86.08, 77.85]
2022-10-08 10:52:35,661 [trainer.py] => CNN new curve: [0, 37.62]
2022-10-08 10:52:35,661 [trainer.py] => CNN compound curve: [0, 37.62]
2022-10-08 10:52:35,661 [trainer.py] => NME: {'total': 66.02, 'old': 78.48, 'new': 46.53, 'base': 78.48, 'compound': 46.53}
2022-10-08 10:52:35,661 [trainer.py] => NME top1 curve: [87.97, 66.02]
2022-10-08 10:52:35,661 [trainer.py] => NME base curve: [87.97, 78.48]
2022-10-08 10:52:35,661 [trainer.py] => NME old curve: [87.97, 78.48]
2022-10-08 10:52:35,661 [trainer.py] => NME new curve: [0, 46.53]
2022-10-08 10:52:35,661 [trainer.py] => NME compound curve: [0, 46.53]
2022-10-08 10:52:35,889 [foster.py] => Learning on 12-17
2022-10-08 10:52:35,889 [foster.py] => All params: 22385326
2022-10-08 10:52:35,890 [foster.py] => Trainable params: 11202658
2022-10-08 10:52:35,899 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 10:52:39,212 [foster.py] => Task 2, Epoch 1/34 => Loss 5.639, Loss_clf 2.095, Loss_fe 2.148, Loss_kd 0.985, Train_accy 39.63, Test_accy 48.72
2022-10-08 10:52:41,695 [foster.py] => Task 2, Epoch 2/34 => Loss 3.594, Loss_clf 0.850, Loss_fe 1.398, Loss_kd 0.950, Train_accy 42.11
2022-10-08 10:52:44,300 [foster.py] => Task 2, Epoch 3/34 => Loss 3.278, Loss_clf 0.744, Loss_fe 1.201, Loss_kd 0.941, Train_accy 38.36
2022-10-08 10:52:46,865 [foster.py] => Task 2, Epoch 4/34 => Loss 3.141, Loss_clf 0.702, Loss_fe 1.088, Loss_kd 0.954, Train_accy 40.11
2022-10-08 10:52:49,449 [foster.py] => Task 2, Epoch 5/34 => Loss 3.063, Loss_clf 0.689, Loss_fe 1.038, Loss_kd 0.943, Train_accy 39.63
2022-10-08 10:52:52,886 [foster.py] => Task 2, Epoch 6/34 => Loss 2.906, Loss_clf 0.634, Loss_fe 0.931, Loss_kd 0.947, Train_accy 40.83, Test_accy 50.26
2022-10-08 10:52:55,428 [foster.py] => Task 2, Epoch 7/34 => Loss 2.851, Loss_clf 0.620, Loss_fe 0.895, Loss_kd 0.944, Train_accy 40.91
2022-10-08 10:52:58,055 [foster.py] => Task 2, Epoch 8/34 => Loss 2.845, Loss_clf 0.619, Loss_fe 0.894, Loss_kd 0.940, Train_accy 39.95
2022-10-08 10:53:00,671 [foster.py] => Task 2, Epoch 9/34 => Loss 2.736, Loss_clf 0.594, Loss_fe 0.810, Loss_kd 0.941, Train_accy 43.54
2022-10-08 10:53:03,327 [foster.py] => Task 2, Epoch 10/34 => Loss 2.755, Loss_clf 0.593, Loss_fe 0.819, Loss_kd 0.949, Train_accy 39.95
2022-10-08 10:53:07,012 [foster.py] => Task 2, Epoch 11/34 => Loss 2.679, Loss_clf 0.570, Loss_fe 0.762, Loss_kd 0.950, Train_accy 42.26, Test_accy 51.03
2022-10-08 10:53:09,710 [foster.py] => Task 2, Epoch 12/34 => Loss 2.640, Loss_clf 0.557, Loss_fe 0.745, Loss_kd 0.944, Train_accy 40.99
2022-10-08 10:53:12,626 [foster.py] => Task 2, Epoch 13/34 => Loss 2.622, Loss_clf 0.545, Loss_fe 0.734, Loss_kd 0.948, Train_accy 41.23
2022-10-08 10:53:15,560 [foster.py] => Task 2, Epoch 14/34 => Loss 2.656, Loss_clf 0.570, Loss_fe 0.744, Loss_kd 0.947, Train_accy 42.66
2022-10-08 10:53:18,489 [foster.py] => Task 2, Epoch 15/34 => Loss 2.535, Loss_clf 0.514, Loss_fe 0.676, Loss_kd 0.950, Train_accy 41.47
2022-10-08 10:53:22,228 [foster.py] => Task 2, Epoch 16/34 => Loss 2.509, Loss_clf 0.511, Loss_fe 0.657, Loss_kd 0.947, Train_accy 41.71, Test_accy 51.79
2022-10-08 10:53:24,984 [foster.py] => Task 2, Epoch 17/34 => Loss 2.511, Loss_clf 0.512, Loss_fe 0.663, Loss_kd 0.943, Train_accy 40.67
2022-10-08 10:53:31,994 [foster.py] => Task 2, Epoch 18/34 => Loss 2.502, Loss_clf 0.506, Loss_fe 0.647, Loss_kd 0.952, Train_accy 43.54
2022-10-08 10:53:35,494 [foster.py] => Task 2, Epoch 19/34 => Loss 2.449, Loss_clf 0.486, Loss_fe 0.619, Loss_kd 0.949, Train_accy 44.90
2022-10-08 10:53:38,219 [foster.py] => Task 2, Epoch 20/34 => Loss 2.454, Loss_clf 0.499, Loss_fe 0.621, Loss_kd 0.941, Train_accy 43.30
2022-10-08 10:53:41,743 [foster.py] => Task 2, Epoch 21/34 => Loss 2.479, Loss_clf 0.508, Loss_fe 0.637, Loss_kd 0.941, Train_accy 45.14, Test_accy 51.54
2022-10-08 10:53:44,335 [foster.py] => Task 2, Epoch 22/34 => Loss 2.423, Loss_clf 0.469, Loss_fe 0.606, Loss_kd 0.952, Train_accy 43.70
2022-10-08 10:53:46,902 [foster.py] => Task 2, Epoch 23/34 => Loss 2.461, Loss_clf 0.495, Loss_fe 0.623, Loss_kd 0.948, Train_accy 44.10
2022-10-08 10:53:49,451 [foster.py] => Task 2, Epoch 24/34 => Loss 2.425, Loss_clf 0.479, Loss_fe 0.601, Loss_kd 0.950, Train_accy 44.26
2022-10-08 10:53:52,032 [foster.py] => Task 2, Epoch 25/34 => Loss 2.462, Loss_clf 0.493, Loss_fe 0.615, Loss_kd 0.955, Train_accy 45.14
2022-10-08 10:53:55,979 [foster.py] => Task 2, Epoch 26/34 => Loss 2.393, Loss_clf 0.467, Loss_fe 0.589, Loss_kd 0.943, Train_accy 44.18, Test_accy 50.77
2022-10-08 10:53:58,651 [foster.py] => Task 2, Epoch 27/34 => Loss 2.388, Loss_clf 0.467, Loss_fe 0.579, Loss_kd 0.948, Train_accy 45.37
2022-10-08 10:54:01,299 [foster.py] => Task 2, Epoch 28/34 => Loss 2.375, Loss_clf 0.453, Loss_fe 0.574, Loss_kd 0.951, Train_accy 44.74
2022-10-08 10:54:04,068 [foster.py] => Task 2, Epoch 29/34 => Loss 2.400, Loss_clf 0.463, Loss_fe 0.592, Loss_kd 0.949, Train_accy 45.61
2022-10-08 10:54:06,973 [foster.py] => Task 2, Epoch 30/34 => Loss 2.444, Loss_clf 0.466, Loss_fe 0.618, Loss_kd 0.960, Train_accy 44.26
2022-10-08 10:54:10,532 [foster.py] => Task 2, Epoch 31/34 => Loss 2.394, Loss_clf 0.476, Loss_fe 0.604, Loss_kd 0.928, Train_accy 43.86, Test_accy 51.54
2022-10-08 10:54:13,277 [foster.py] => Task 2, Epoch 32/34 => Loss 2.439, Loss_clf 0.475, Loss_fe 0.613, Loss_kd 0.954, Train_accy 44.90
2022-10-08 10:54:15,974 [foster.py] => Task 2, Epoch 33/34 => Loss 2.385, Loss_clf 0.463, Loss_fe 0.581, Loss_kd 0.947, Train_accy 44.98
2022-10-08 10:54:18,772 [foster.py] => Task 2, Epoch 34/34 => Loss 2.374, Loss_clf 0.455, Loss_fe 0.571, Loss_kd 0.951, Train_accy 44.98
2022-10-08 10:54:18,773 [foster.py] => do not weight align teacher!
2022-10-08 10:54:18,773 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 10:54:23,327 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.089,  Train_accy 11.16, Test_accy 35.38
2022-10-08 10:54:30,640 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.962,  Train_accy 11.72
2022-10-08 10:54:34,639 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.920,  Train_accy 11.96
2022-10-08 10:54:38,103 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.909,  Train_accy 12.04
2022-10-08 10:54:41,287 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.894,  Train_accy 12.36
2022-10-08 10:54:45,060 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.872,  Train_accy 12.36, Test_accy 36.92
2022-10-08 10:54:48,021 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.858,  Train_accy 12.36
2022-10-08 10:54:51,135 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.845,  Train_accy 12.44
2022-10-08 10:54:54,530 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.858,  Train_accy 12.28
2022-10-08 10:54:57,971 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.845,  Train_accy 12.36
2022-10-08 10:55:01,904 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.830,  Train_accy 13.00, Test_accy 37.69
2022-10-08 10:55:05,003 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.823,  Train_accy 12.76
2022-10-08 10:55:08,129 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.830,  Train_accy 12.92
2022-10-08 10:55:11,173 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.821,  Train_accy 13.48
2022-10-08 10:55:14,362 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.820,  Train_accy 13.08
2022-10-08 10:55:18,891 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.807,  Train_accy 13.24, Test_accy 39.49
2022-10-08 10:55:22,210 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.825,  Train_accy 12.92
2022-10-08 10:55:25,568 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.797,  Train_accy 13.56
2022-10-08 10:55:28,933 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.797,  Train_accy 13.88
2022-10-08 10:55:32,102 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.821,  Train_accy 13.48
2022-10-08 10:55:36,053 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.803,  Train_accy 13.40, Test_accy 40.26
2022-10-08 10:55:39,317 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.805,  Train_accy 13.80
2022-10-08 10:55:42,891 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.801,  Train_accy 14.04
2022-10-08 10:55:46,479 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.816,  Train_accy 13.64
2022-10-08 10:55:50,026 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.806,  Train_accy 13.64
2022-10-08 10:55:53,884 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.809,  Train_accy 13.88, Test_accy 38.97
2022-10-08 10:55:53,884 [foster.py] => do not weight align student!
2022-10-08 10:55:54,591 [foster.py] => darknet eval: 
2022-10-08 10:55:54,592 [foster.py] => CNN top1 curve: 38.97
2022-10-08 10:55:54,592 [foster.py] => CNN top5 curve: 90.51
2022-10-08 10:55:54,592 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 10:56:04,003 [foster.py] => Exemplar size: 340
2022-10-08 10:56:04,003 [trainer.py] => CNN: {'total': 51.03, 'old': 56.76, 'new': 39.69, 'base': 77.85, 'compound': 32.76}
2022-10-08 10:56:04,003 [trainer.py] => CNN top1 curve: [86.08, 62.16, 51.03]
2022-10-08 10:56:04,003 [trainer.py] => CNN base curve: [86.08, 77.85, 77.85]
2022-10-08 10:56:04,003 [trainer.py] => CNN old curve: [86.08, 77.85, 56.76]
2022-10-08 10:56:04,003 [trainer.py] => CNN new curve: [0, 37.62, 39.69]
2022-10-08 10:56:04,003 [trainer.py] => CNN compound curve: [0, 37.62, 32.76]
2022-10-08 10:56:04,004 [trainer.py] => NME: {'total': 57.95, 'old': 55.6, 'new': 62.6, 'base': 67.09, 'compound': 51.72}
2022-10-08 10:56:04,004 [trainer.py] => NME top1 curve: [87.97, 66.02, 57.95]
2022-10-08 10:56:04,004 [trainer.py] => NME base curve: [87.97, 78.48, 67.09]
2022-10-08 10:56:04,004 [trainer.py] => NME old curve: [87.97, 78.48, 55.6]
2022-10-08 10:56:04,004 [trainer.py] => NME new curve: [0, 46.53, 62.6]
2022-10-08 10:56:04,004 [trainer.py] => NME compound curve: [0, 46.53, 51.72]
2022-10-08 10:56:04,227 [foster.py] => Learning on 17-22
2022-10-08 10:56:04,227 [foster.py] => All params: 22395581
2022-10-08 10:56:04,228 [foster.py] => Trainable params: 11210348
2022-10-08 10:56:04,236 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 10:56:07,858 [foster.py] => Task 3, Epoch 1/34 => Loss 6.446, Loss_clf 2.021, Loss_fe 2.420, Loss_kd 1.549, Train_accy 33.48, Test_accy 34.92
2022-10-08 10:56:10,534 [foster.py] => Task 3, Epoch 2/34 => Loss 4.949, Loss_clf 1.201, Loss_fe 1.771, Loss_kd 1.528, Train_accy 34.50
2022-10-08 10:56:13,302 [foster.py] => Task 3, Epoch 3/34 => Loss 4.615, Loss_clf 1.086, Loss_fe 1.552, Loss_kd 1.527, Train_accy 38.79
2022-10-08 10:56:16,069 [foster.py] => Task 3, Epoch 4/34 => Loss 4.404, Loss_clf 1.023, Loss_fe 1.400, Loss_kd 1.530, Train_accy 39.81
2022-10-08 10:56:18,834 [foster.py] => Task 3, Epoch 5/34 => Loss 4.297, Loss_clf 0.998, Loss_fe 1.320, Loss_kd 1.529, Train_accy 39.52
2022-10-08 10:56:26,946 [foster.py] => Task 3, Epoch 6/34 => Loss 4.168, Loss_clf 0.962, Loss_fe 1.233, Loss_kd 1.524, Train_accy 40.76, Test_accy 44.64
2022-10-08 10:56:30,071 [foster.py] => Task 3, Epoch 7/34 => Loss 4.076, Loss_clf 0.933, Loss_fe 1.166, Loss_kd 1.528, Train_accy 41.12
2022-10-08 10:56:33,103 [foster.py] => Task 3, Epoch 8/34 => Loss 4.025, Loss_clf 0.911, Loss_fe 1.129, Loss_kd 1.534, Train_accy 40.90
2022-10-08 10:56:35,958 [foster.py] => Task 3, Epoch 9/34 => Loss 3.944, Loss_clf 0.886, Loss_fe 1.075, Loss_kd 1.532, Train_accy 40.90
2022-10-08 10:56:38,744 [foster.py] => Task 3, Epoch 10/34 => Loss 3.910, Loss_clf 0.887, Loss_fe 1.044, Loss_kd 1.530, Train_accy 43.38
2022-10-08 10:56:42,499 [foster.py] => Task 3, Epoch 11/34 => Loss 3.873, Loss_clf 0.874, Loss_fe 1.020, Loss_kd 1.529, Train_accy 43.01, Test_accy 44.84
2022-10-08 10:56:45,249 [foster.py] => Task 3, Epoch 12/34 => Loss 3.808, Loss_clf 0.840, Loss_fe 0.985, Loss_kd 1.532, Train_accy 41.70
2022-10-08 10:56:48,008 [foster.py] => Task 3, Epoch 13/34 => Loss 3.801, Loss_clf 0.856, Loss_fe 0.964, Loss_kd 1.531, Train_accy 43.81
2022-10-08 10:56:50,878 [foster.py] => Task 3, Epoch 14/34 => Loss 3.703, Loss_clf 0.807, Loss_fe 0.920, Loss_kd 1.527, Train_accy 46.00
2022-10-08 10:56:53,730 [foster.py] => Task 3, Epoch 15/34 => Loss 3.701, Loss_clf 0.792, Loss_fe 0.919, Loss_kd 1.538, Train_accy 43.60
2022-10-08 10:56:57,968 [foster.py] => Task 3, Epoch 16/34 => Loss 3.694, Loss_clf 0.807, Loss_fe 0.906, Loss_kd 1.531, Train_accy 46.07, Test_accy 45.44
2022-10-08 10:57:01,061 [foster.py] => Task 3, Epoch 17/34 => Loss 3.658, Loss_clf 0.791, Loss_fe 0.884, Loss_kd 1.532, Train_accy 43.81
2022-10-08 10:57:04,114 [foster.py] => Task 3, Epoch 18/34 => Loss 3.639, Loss_clf 0.777, Loss_fe 0.878, Loss_kd 1.534, Train_accy 44.18
2022-10-08 10:57:07,125 [foster.py] => Task 3, Epoch 19/34 => Loss 3.598, Loss_clf 0.751, Loss_fe 0.861, Loss_kd 1.534, Train_accy 45.71
2022-10-08 10:57:10,024 [foster.py] => Task 3, Epoch 20/34 => Loss 3.589, Loss_clf 0.766, Loss_fe 0.844, Loss_kd 1.529, Train_accy 45.56
2022-10-08 10:57:14,009 [foster.py] => Task 3, Epoch 21/34 => Loss 3.564, Loss_clf 0.745, Loss_fe 0.837, Loss_kd 1.532, Train_accy 45.27, Test_accy 45.83
2022-10-08 10:57:16,978 [foster.py] => Task 3, Epoch 22/34 => Loss 3.565, Loss_clf 0.750, Loss_fe 0.829, Loss_kd 1.535, Train_accy 46.51
2022-10-08 10:57:19,935 [foster.py] => Task 3, Epoch 23/34 => Loss 3.556, Loss_clf 0.741, Loss_fe 0.828, Loss_kd 1.535, Train_accy 46.29
2022-10-08 10:57:22,904 [foster.py] => Task 3, Epoch 24/34 => Loss 3.550, Loss_clf 0.746, Loss_fe 0.825, Loss_kd 1.530, Train_accy 46.43
2022-10-08 10:57:25,974 [foster.py] => Task 3, Epoch 25/34 => Loss 3.524, Loss_clf 0.734, Loss_fe 0.813, Loss_kd 1.528, Train_accy 46.72
2022-10-08 10:57:30,393 [foster.py] => Task 3, Epoch 26/34 => Loss 3.505, Loss_clf 0.722, Loss_fe 0.809, Loss_kd 1.525, Train_accy 47.67, Test_accy 46.03
2022-10-08 10:57:33,352 [foster.py] => Task 3, Epoch 27/34 => Loss 3.527, Loss_clf 0.730, Loss_fe 0.809, Loss_kd 1.536, Train_accy 47.09
2022-10-08 10:57:36,358 [foster.py] => Task 3, Epoch 28/34 => Loss 3.485, Loss_clf 0.711, Loss_fe 0.792, Loss_kd 1.532, Train_accy 46.36
2022-10-08 10:57:39,259 [foster.py] => Task 3, Epoch 29/34 => Loss 3.532, Loss_clf 0.732, Loss_fe 0.814, Loss_kd 1.534, Train_accy 46.51
2022-10-08 10:57:42,397 [foster.py] => Task 3, Epoch 30/34 => Loss 3.486, Loss_clf 0.710, Loss_fe 0.792, Loss_kd 1.532, Train_accy 46.29
2022-10-08 10:57:46,587 [foster.py] => Task 3, Epoch 31/34 => Loss 3.493, Loss_clf 0.713, Loss_fe 0.799, Loss_kd 1.530, Train_accy 46.65, Test_accy 46.03
2022-10-08 10:57:49,770 [foster.py] => Task 3, Epoch 32/34 => Loss 3.489, Loss_clf 0.712, Loss_fe 0.794, Loss_kd 1.532, Train_accy 45.49
2022-10-08 10:57:52,762 [foster.py] => Task 3, Epoch 33/34 => Loss 3.502, Loss_clf 0.714, Loss_fe 0.804, Loss_kd 1.533, Train_accy 47.23
2022-10-08 10:57:55,735 [foster.py] => Task 3, Epoch 34/34 => Loss 3.528, Loss_clf 0.721, Loss_fe 0.817, Loss_kd 1.538, Train_accy 47.31
2022-10-08 10:57:55,736 [foster.py] => do not weight align teacher!
2022-10-08 10:57:55,737 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 10:58:00,651 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.469,  Train_accy 11.72, Test_accy 31.15
2022-10-08 10:58:03,945 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.420,  Train_accy 12.08
2022-10-08 10:58:07,433 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.405,  Train_accy 12.81
2022-10-08 10:58:10,943 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.382,  Train_accy 12.81
2022-10-08 10:58:14,847 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.383,  Train_accy 12.66
2022-10-08 10:58:19,519 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.367,  Train_accy 12.88, Test_accy 33.53
2022-10-08 10:58:22,791 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.362,  Train_accy 13.03
2022-10-08 10:58:26,358 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.360,  Train_accy 13.17
2022-10-08 10:58:29,807 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.349,  Train_accy 13.61
2022-10-08 10:58:33,395 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.345,  Train_accy 14.48
2022-10-08 10:58:38,159 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.342,  Train_accy 14.12, Test_accy 35.32
2022-10-08 10:58:41,648 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.335,  Train_accy 15.21
2022-10-08 10:58:45,170 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.336,  Train_accy 15.43
2022-10-08 10:58:49,307 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.333,  Train_accy 15.57
2022-10-08 10:58:53,461 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.335,  Train_accy 14.92
2022-10-08 10:58:58,396 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.331,  Train_accy 15.28, Test_accy 36.11
2022-10-08 10:59:01,964 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.328,  Train_accy 16.45
2022-10-08 10:59:05,464 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.326,  Train_accy 15.79
2022-10-08 10:59:09,846 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.332,  Train_accy 16.38
2022-10-08 10:59:13,930 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.329,  Train_accy 16.59
2022-10-08 10:59:18,745 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.324,  Train_accy 15.87, Test_accy 36.51
2022-10-08 10:59:22,186 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.321,  Train_accy 15.79
2022-10-08 10:59:26,149 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.321,  Train_accy 16.16
2022-10-08 10:59:30,067 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.326,  Train_accy 15.65
2022-10-08 10:59:34,043 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.321,  Train_accy 16.38
2022-10-08 10:59:38,746 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.328,  Train_accy 16.23, Test_accy 36.90
2022-10-08 10:59:38,747 [foster.py] => do not weight align student!
2022-10-08 10:59:39,549 [foster.py] => darknet eval: 
2022-10-08 10:59:39,549 [foster.py] => CNN top1 curve: 36.9
2022-10-08 10:59:39,549 [foster.py] => CNN top5 curve: 81.75
2022-10-08 10:59:39,549 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 10:59:50,721 [foster.py] => Exemplar size: 440
2022-10-08 10:59:50,721 [trainer.py] => CNN: {'total': 46.03, 'old': 49.74, 'new': 33.33, 'base': 76.58, 'compound': 32.08}
2022-10-08 10:59:50,721 [trainer.py] => CNN top1 curve: [86.08, 62.16, 51.03, 46.03]
2022-10-08 10:59:50,722 [trainer.py] => CNN base curve: [86.08, 77.85, 77.85, 76.58]
2022-10-08 10:59:50,722 [trainer.py] => CNN old curve: [86.08, 77.85, 56.76, 49.74]
2022-10-08 10:59:50,722 [trainer.py] => CNN new curve: [0, 37.62, 39.69, 33.33]
2022-10-08 10:59:50,722 [trainer.py] => CNN compound curve: [0, 37.62, 32.76, 32.08]
2022-10-08 10:59:50,722 [trainer.py] => NME: {'total': 53.97, 'old': 54.62, 'new': 51.75, 'base': 65.19, 'compound': 48.84}
2022-10-08 10:59:50,722 [trainer.py] => NME top1 curve: [87.97, 66.02, 57.95, 53.97]
2022-10-08 10:59:50,722 [trainer.py] => NME base curve: [87.97, 78.48, 67.09, 65.19]
2022-10-08 10:59:50,722 [trainer.py] => NME old curve: [87.97, 78.48, 55.6, 54.62]
2022-10-08 10:59:50,722 [trainer.py] => NME new curve: [0, 46.53, 62.6, 51.75]
2022-10-08 10:59:50,722 [trainer.py] => NME compound curve: [0, 46.53, 51.72, 48.84]
2022-10-08 10:59:50,723 [trainer.py] => config: ./exps/CFEE/foster.json
2022-10-08 10:59:50,723 [trainer.py] => prefix: cil
2022-10-08 10:59:50,723 [trainer.py] => dataset: CFEE
2022-10-08 10:59:50,723 [trainer.py] => memory_size: 2000
2022-10-08 10:59:50,723 [trainer.py] => memory_per_class: 20
2022-10-08 10:59:50,723 [trainer.py] => fixed_memory: True
2022-10-08 10:59:50,723 [trainer.py] => shuffle: True
2022-10-08 10:59:50,723 [trainer.py] => init_cls: 7
2022-10-08 10:59:50,723 [trainer.py] => increment: 5
2022-10-08 10:59:50,723 [trainer.py] => model_name: foster
2022-10-08 10:59:50,724 [trainer.py] => convnet_type: resnet18
2022-10-08 10:59:50,724 [trainer.py] => device: [device(type='cuda', index=0)]
2022-10-08 10:59:50,724 [trainer.py] => seed: 1993
2022-10-08 10:59:50,724 [trainer.py] => beta1: 0.96
2022-10-08 10:59:50,724 [trainer.py] => beta2: 0.97
2022-10-08 10:59:50,724 [trainer.py] => oofc: ft
2022-10-08 10:59:50,724 [trainer.py] => is_teacher_wa: False
2022-10-08 10:59:50,724 [trainer.py] => is_student_wa: False
2022-10-08 10:59:50,724 [trainer.py] => lambda_okd: 1
2022-10-08 10:59:50,724 [trainer.py] => wa_value: 1
2022-10-08 10:59:50,724 [trainer.py] => init_epochs: 40
2022-10-08 10:59:50,724 [trainer.py] => init_lr: 0.01
2022-10-08 10:59:50,724 [trainer.py] => init_weight_decay: 0.0005
2022-10-08 10:59:50,724 [trainer.py] => boosting_epochs: 34
2022-10-08 10:59:50,724 [trainer.py] => compression_epochs: 26
2022-10-08 10:59:50,724 [trainer.py] => lr: 0.001
2022-10-08 10:59:50,724 [trainer.py] => batch_size: 32
2022-10-08 10:59:50,724 [trainer.py] => weight_decay: 0.0005
2022-10-08 10:59:50,724 [trainer.py] => num_workers: 8
2022-10-08 10:59:50,724 [trainer.py] => T: 2
2022-10-08 10:59:50,724 [trainer.py] => nb_runs: 3
2022-10-08 10:59:50,724 [trainer.py] => fold: 10
2022-10-08 10:59:50,724 [data.py] => ========== Fold:9 ==========
2022-10-08 10:59:50,730 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 12, 10, 19, 21, 17, 18, 8, 7, 9, 14, 15, 13, 11, 16]
2022-10-08 10:59:50,947 [foster.py] => Learning on 0-7
2022-10-08 10:59:50,947 [foster.py] => All params: 11183694
2022-10-08 10:59:50,948 [foster.py] => Trainable params: 11183694
2022-10-08 10:59:53,301 [foster.py] => Task 0, Epoch 1/40 => Loss 1.333, Train_accy 51.21
2022-10-08 10:59:56,256 [foster.py] => Task 0, Epoch 2/40 => Loss 0.543, Train_accy 81.91, Test_accy 80.49
2022-10-08 10:59:59,206 [foster.py] => Task 0, Epoch 3/40 => Loss 0.353, Train_accy 88.15, Test_accy 84.15
2022-10-08 11:00:02,216 [foster.py] => Task 0, Epoch 4/40 => Loss 0.272, Train_accy 90.85, Test_accy 85.98
2022-10-08 11:00:05,170 [foster.py] => Task 0, Epoch 5/40 => Loss 0.222, Train_accy 92.38, Test_accy 82.32
2022-10-08 11:00:07,565 [foster.py] => Task 0, Epoch 6/40 => Loss 0.197, Train_accy 93.83
2022-10-08 11:00:10,552 [foster.py] => Task 0, Epoch 7/40 => Loss 0.181, Train_accy 94.39, Test_accy 81.71
2022-10-08 11:00:13,472 [foster.py] => Task 0, Epoch 8/40 => Loss 0.134, Train_accy 95.15, Test_accy 85.98
2022-10-08 11:00:16,432 [foster.py] => Task 0, Epoch 9/40 => Loss 0.116, Train_accy 97.02, Test_accy 86.59
2022-10-08 11:00:19,382 [foster.py] => Task 0, Epoch 10/40 => Loss 0.127, Train_accy 94.80, Test_accy 81.10
2022-10-08 11:00:21,896 [foster.py] => Task 0, Epoch 11/40 => Loss 0.084, Train_accy 97.57
2022-10-08 11:00:24,934 [foster.py] => Task 0, Epoch 12/40 => Loss 0.111, Train_accy 96.74, Test_accy 82.32
2022-10-08 11:00:27,899 [foster.py] => Task 0, Epoch 13/40 => Loss 0.108, Train_accy 97.71, Test_accy 83.54
2022-10-08 11:00:30,969 [foster.py] => Task 0, Epoch 14/40 => Loss 0.119, Train_accy 96.67, Test_accy 84.76
2022-10-08 11:00:34,069 [foster.py] => Task 0, Epoch 15/40 => Loss 0.087, Train_accy 97.37, Test_accy 82.32
2022-10-08 11:00:36,443 [foster.py] => Task 0, Epoch 16/40 => Loss 0.056, Train_accy 98.13
2022-10-08 11:00:39,457 [foster.py] => Task 0, Epoch 17/40 => Loss 0.061, Train_accy 98.75, Test_accy 84.15
2022-10-08 11:00:42,407 [foster.py] => Task 0, Epoch 18/40 => Loss 0.051, Train_accy 98.34, Test_accy 84.76
2022-10-08 11:00:45,469 [foster.py] => Task 0, Epoch 19/40 => Loss 0.101, Train_accy 98.61, Test_accy 85.37
2022-10-08 11:00:48,487 [foster.py] => Task 0, Epoch 20/40 => Loss 0.049, Train_accy 98.68, Test_accy 84.15
2022-10-08 11:00:50,889 [foster.py] => Task 0, Epoch 21/40 => Loss 0.042, Train_accy 98.89
2022-10-08 11:00:53,969 [foster.py] => Task 0, Epoch 22/40 => Loss 0.038, Train_accy 99.31, Test_accy 82.32
2022-10-08 11:00:56,954 [foster.py] => Task 0, Epoch 23/40 => Loss 0.036, Train_accy 99.45, Test_accy 83.54
2022-10-08 11:00:59,941 [foster.py] => Task 0, Epoch 24/40 => Loss 0.028, Train_accy 99.45, Test_accy 82.32
2022-10-08 11:01:02,959 [foster.py] => Task 0, Epoch 25/40 => Loss 0.025, Train_accy 99.86, Test_accy 82.93
2022-10-08 11:01:05,356 [foster.py] => Task 0, Epoch 26/40 => Loss 0.057, Train_accy 99.58
2022-10-08 11:01:08,551 [foster.py] => Task 0, Epoch 27/40 => Loss 0.035, Train_accy 99.31, Test_accy 82.93
2022-10-08 11:01:14,585 [foster.py] => Task 0, Epoch 28/40 => Loss 0.026, Train_accy 99.58, Test_accy 84.15
2022-10-08 11:01:17,834 [foster.py] => Task 0, Epoch 29/40 => Loss 0.066, Train_accy 99.24, Test_accy 84.15
2022-10-08 11:01:20,774 [foster.py] => Task 0, Epoch 30/40 => Loss 0.031, Train_accy 99.24, Test_accy 84.76
2022-10-08 11:01:23,184 [foster.py] => Task 0, Epoch 31/40 => Loss 0.026, Train_accy 99.72
2022-10-08 11:01:26,165 [foster.py] => Task 0, Epoch 32/40 => Loss 0.026, Train_accy 99.72, Test_accy 84.76
2022-10-08 11:01:29,153 [foster.py] => Task 0, Epoch 33/40 => Loss 0.026, Train_accy 99.58, Test_accy 84.76
2022-10-08 11:01:32,117 [foster.py] => Task 0, Epoch 34/40 => Loss 0.017, Train_accy 99.65, Test_accy 84.15
2022-10-08 11:01:35,110 [foster.py] => Task 0, Epoch 35/40 => Loss 0.018, Train_accy 99.79, Test_accy 84.76
2022-10-08 11:01:37,607 [foster.py] => Task 0, Epoch 36/40 => Loss 0.020, Train_accy 99.58
2022-10-08 11:01:40,659 [foster.py] => Task 0, Epoch 37/40 => Loss 0.033, Train_accy 99.65, Test_accy 84.76
2022-10-08 11:01:43,660 [foster.py] => Task 0, Epoch 38/40 => Loss 0.031, Train_accy 99.58, Test_accy 84.76
2022-10-08 11:01:46,672 [foster.py] => Task 0, Epoch 39/40 => Loss 0.016, Train_accy 99.72, Test_accy 84.15
2022-10-08 11:01:50,690 [foster.py] => Task 0, Epoch 40/40 => Loss 0.017, Train_accy 99.86, Test_accy 84.15
2022-10-08 11:01:50,691 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 11:01:57,170 [foster.py] => Exemplar size: 140
2022-10-08 11:01:57,170 [trainer.py] => CNN: {'total': 84.15, 'old': 84.15, 'new': 0, 'base': 84.15, 'compound': 0}
2022-10-08 11:01:57,170 [trainer.py] => CNN top1 curve: [84.15]
2022-10-08 11:01:57,171 [trainer.py] => CNN base curve: [84.15]
2022-10-08 11:01:57,171 [trainer.py] => CNN old curve: [84.15]
2022-10-08 11:01:57,171 [trainer.py] => CNN new curve: [0]
2022-10-08 11:01:57,171 [trainer.py] => CNN compound curve: [0]
2022-10-08 11:01:57,171 [trainer.py] => NME: {'total': 83.54, 'old': 83.54, 'new': 0, 'base': 83.54, 'compound': 0}
2022-10-08 11:01:57,171 [trainer.py] => NME top1 curve: [83.54]
2022-10-08 11:01:57,171 [trainer.py] => NME base curve: [83.54]
2022-10-08 11:01:57,171 [trainer.py] => NME old curve: [83.54]
2022-10-08 11:01:57,171 [trainer.py] => NME new curve: [0]
2022-10-08 11:01:57,171 [trainer.py] => NME compound curve: [0]
2022-10-08 11:01:57,396 [foster.py] => Learning on 7-12
2022-10-08 11:01:57,397 [foster.py] => All params: 22375071
2022-10-08 11:01:57,397 [foster.py] => Trainable params: 11194968
2022-10-08 11:01:57,406 [foster.py] => per cls weights : [1.22574208 1.22574208 1.22574208 1.22574208 1.22574208 1.22574208
 1.22574208 0.68396109 0.68396109 0.68396109 0.68396109 0.68396109]
2022-10-08 11:02:00,516 [foster.py] => Task 1, Epoch 1/34 => Loss 5.326, Loss_clf 2.508, Loss_fe 2.147, Loss_kd 0.392, Train_accy 29.01, Test_accy 50.92
2022-10-08 11:02:02,989 [foster.py] => Task 1, Epoch 2/34 => Loss 3.218, Loss_clf 1.069, Loss_fe 1.509, Loss_kd 0.374, Train_accy 48.52
2022-10-08 11:02:05,468 [foster.py] => Task 1, Epoch 3/34 => Loss 2.889, Loss_clf 0.960, Loss_fe 1.318, Loss_kd 0.356, Train_accy 37.57
2022-10-08 11:02:07,874 [foster.py] => Task 1, Epoch 4/34 => Loss 2.732, Loss_clf 0.915, Loss_fe 1.209, Loss_kd 0.354, Train_accy 38.25
2022-10-08 11:02:10,344 [foster.py] => Task 1, Epoch 5/34 => Loss 2.630, Loss_clf 0.891, Loss_fe 1.134, Loss_kd 0.353, Train_accy 37.91
2022-10-08 11:02:13,586 [foster.py] => Task 1, Epoch 6/34 => Loss 2.526, Loss_clf 0.860, Loss_fe 1.062, Loss_kd 0.352, Train_accy 38.68, Test_accy 58.67
2022-10-08 11:02:16,018 [foster.py] => Task 1, Epoch 7/34 => Loss 2.452, Loss_clf 0.830, Loss_fe 1.021, Loss_kd 0.351, Train_accy 42.75
2022-10-08 11:02:18,443 [foster.py] => Task 1, Epoch 8/34 => Loss 2.420, Loss_clf 0.822, Loss_fe 0.992, Loss_kd 0.353, Train_accy 41.90
2022-10-08 11:02:25,018 [foster.py] => Task 1, Epoch 9/34 => Loss 2.371, Loss_clf 0.811, Loss_fe 0.966, Loss_kd 0.346, Train_accy 40.63
2022-10-08 11:02:28,115 [foster.py] => Task 1, Epoch 10/34 => Loss 2.332, Loss_clf 0.789, Loss_fe 0.934, Loss_kd 0.355, Train_accy 40.12
2022-10-08 11:02:31,936 [foster.py] => Task 1, Epoch 11/34 => Loss 2.266, Loss_clf 0.766, Loss_fe 0.901, Loss_kd 0.349, Train_accy 44.27, Test_accy 61.62
2022-10-08 11:02:34,453 [foster.py] => Task 1, Epoch 12/34 => Loss 2.224, Loss_clf 0.754, Loss_fe 0.878, Loss_kd 0.345, Train_accy 42.83
2022-10-08 11:02:36,974 [foster.py] => Task 1, Epoch 13/34 => Loss 2.228, Loss_clf 0.752, Loss_fe 0.871, Loss_kd 0.353, Train_accy 45.04
2022-10-08 11:02:39,490 [foster.py] => Task 1, Epoch 14/34 => Loss 2.165, Loss_clf 0.728, Loss_fe 0.836, Loss_kd 0.350, Train_accy 44.78
2022-10-08 11:02:42,044 [foster.py] => Task 1, Epoch 15/34 => Loss 2.165, Loss_clf 0.725, Loss_fe 0.838, Loss_kd 0.351, Train_accy 42.75
2022-10-08 11:02:45,347 [foster.py] => Task 1, Epoch 16/34 => Loss 2.122, Loss_clf 0.708, Loss_fe 0.819, Loss_kd 0.347, Train_accy 45.80, Test_accy 61.62
2022-10-08 11:02:47,815 [foster.py] => Task 1, Epoch 17/34 => Loss 2.103, Loss_clf 0.699, Loss_fe 0.802, Loss_kd 0.351, Train_accy 46.40
2022-10-08 11:02:50,347 [foster.py] => Task 1, Epoch 18/34 => Loss 2.100, Loss_clf 0.699, Loss_fe 0.799, Loss_kd 0.351, Train_accy 45.38
2022-10-08 11:02:52,848 [foster.py] => Task 1, Epoch 19/34 => Loss 2.070, Loss_clf 0.688, Loss_fe 0.781, Loss_kd 0.351, Train_accy 45.97
2022-10-08 11:02:55,400 [foster.py] => Task 1, Epoch 20/34 => Loss 2.077, Loss_clf 0.698, Loss_fe 0.787, Loss_kd 0.345, Train_accy 45.21
2022-10-08 11:02:58,697 [foster.py] => Task 1, Epoch 21/34 => Loss 1.994, Loss_clf 0.659, Loss_fe 0.738, Loss_kd 0.348, Train_accy 46.31, Test_accy 61.99
2022-10-08 11:03:01,257 [foster.py] => Task 1, Epoch 22/34 => Loss 2.008, Loss_clf 0.655, Loss_fe 0.753, Loss_kd 0.349, Train_accy 47.24
2022-10-08 11:03:04,066 [foster.py] => Task 1, Epoch 23/34 => Loss 1.964, Loss_clf 0.639, Loss_fe 0.730, Loss_kd 0.347, Train_accy 46.31
2022-10-08 11:03:06,827 [foster.py] => Task 1, Epoch 24/34 => Loss 1.962, Loss_clf 0.634, Loss_fe 0.729, Loss_kd 0.350, Train_accy 47.50
2022-10-08 11:03:09,624 [foster.py] => Task 1, Epoch 25/34 => Loss 1.958, Loss_clf 0.626, Loss_fe 0.724, Loss_kd 0.355, Train_accy 48.94
2022-10-08 11:03:13,166 [foster.py] => Task 1, Epoch 26/34 => Loss 1.964, Loss_clf 0.639, Loss_fe 0.733, Loss_kd 0.346, Train_accy 46.99, Test_accy 61.62
2022-10-08 11:03:15,702 [foster.py] => Task 1, Epoch 27/34 => Loss 1.961, Loss_clf 0.637, Loss_fe 0.722, Loss_kd 0.351, Train_accy 48.77
2022-10-08 11:03:18,250 [foster.py] => Task 1, Epoch 28/34 => Loss 1.940, Loss_clf 0.622, Loss_fe 0.713, Loss_kd 0.353, Train_accy 48.60
2022-10-08 11:03:20,929 [foster.py] => Task 1, Epoch 29/34 => Loss 1.927, Loss_clf 0.621, Loss_fe 0.713, Loss_kd 0.346, Train_accy 48.43
2022-10-08 11:03:23,590 [foster.py] => Task 1, Epoch 30/34 => Loss 1.919, Loss_clf 0.614, Loss_fe 0.706, Loss_kd 0.349, Train_accy 47.92
2022-10-08 11:03:26,916 [foster.py] => Task 1, Epoch 31/34 => Loss 1.944, Loss_clf 0.623, Loss_fe 0.722, Loss_kd 0.349, Train_accy 46.48, Test_accy 61.62
2022-10-08 11:03:29,450 [foster.py] => Task 1, Epoch 32/34 => Loss 1.926, Loss_clf 0.617, Loss_fe 0.709, Loss_kd 0.350, Train_accy 49.11
2022-10-08 11:03:31,998 [foster.py] => Task 1, Epoch 33/34 => Loss 1.905, Loss_clf 0.608, Loss_fe 0.702, Loss_kd 0.347, Train_accy 48.43
2022-10-08 11:03:37,806 [foster.py] => Task 1, Epoch 34/34 => Loss 1.953, Loss_clf 0.624, Loss_fe 0.731, Loss_kd 0.349, Train_accy 47.67
2022-10-08 11:03:37,807 [foster.py] => do not weight align teacher!
2022-10-08 11:03:37,807 [foster.py] => per cls weights : [1.29296018 1.29296018 1.29296018 1.29296018 1.29296018 1.29296018
 1.29296018 0.58985575 0.58985575 0.58985575 0.58985575 0.58985575]
2022-10-08 11:03:42,789 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.953,  Train_accy 11.03, Test_accy 46.86
2022-10-08 11:03:45,745 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.736,  Train_accy 11.70
2022-10-08 11:03:48,626 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.662,  Train_accy 12.64
2022-10-08 11:03:51,542 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.615,  Train_accy 13.15
2022-10-08 11:03:54,497 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.588,  Train_accy 14.16
2022-10-08 11:03:58,552 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.589,  Train_accy 14.08, Test_accy 50.55
2022-10-08 11:04:01,422 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.564,  Train_accy 15.01
2022-10-08 11:04:07,064 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.558,  Train_accy 15.27
2022-10-08 11:04:11,265 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.553,  Train_accy 15.86
2022-10-08 11:04:14,534 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.533,  Train_accy 15.01
2022-10-08 11:04:18,094 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.541,  Train_accy 15.78, Test_accy 52.03
2022-10-08 11:04:20,862 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.531,  Train_accy 16.54
2022-10-08 11:04:23,659 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.535,  Train_accy 16.88
2022-10-08 11:04:26,644 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.527,  Train_accy 17.13
2022-10-08 11:04:29,659 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.517,  Train_accy 16.45
2022-10-08 11:04:33,342 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.524,  Train_accy 17.22, Test_accy 51.29
2022-10-08 11:04:36,551 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.520,  Train_accy 16.45
2022-10-08 11:04:39,743 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.520,  Train_accy 17.05
2022-10-08 11:04:42,738 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.519,  Train_accy 17.22
2022-10-08 11:04:45,802 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.514,  Train_accy 17.64
2022-10-08 11:04:49,549 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.517,  Train_accy 17.13, Test_accy 52.40
2022-10-08 11:04:52,552 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.511,  Train_accy 16.96
2022-10-08 11:04:55,938 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.502,  Train_accy 16.88
2022-10-08 11:04:59,292 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.514,  Train_accy 17.64
2022-10-08 11:05:02,631 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.506,  Train_accy 17.05
2022-10-08 11:05:06,787 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.513,  Train_accy 16.54, Test_accy 52.40
2022-10-08 11:05:06,788 [foster.py] => do not weight align student!
2022-10-08 11:05:07,455 [foster.py] => darknet eval: 
2022-10-08 11:05:07,455 [foster.py] => CNN top1 curve: 52.4
2022-10-08 11:05:07,456 [foster.py] => CNN top5 curve: 95.57
2022-10-08 11:05:07,456 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 11:05:15,204 [foster.py] => Exemplar size: 240
2022-10-08 11:05:15,205 [trainer.py] => CNN: {'total': 62.36, 'old': 76.22, 'new': 41.12, 'base': 76.22, 'compound': 41.12}
2022-10-08 11:05:15,205 [trainer.py] => CNN top1 curve: [84.15, 62.36]
2022-10-08 11:05:15,205 [trainer.py] => CNN base curve: [84.15, 76.22]
2022-10-08 11:05:15,205 [trainer.py] => CNN old curve: [84.15, 76.22]
2022-10-08 11:05:15,205 [trainer.py] => CNN new curve: [0, 41.12]
2022-10-08 11:05:15,205 [trainer.py] => CNN compound curve: [0, 41.12]
2022-10-08 11:05:15,205 [trainer.py] => NME: {'total': 66.42, 'old': 77.44, 'new': 49.53, 'base': 77.44, 'compound': 49.53}
2022-10-08 11:05:15,205 [trainer.py] => NME top1 curve: [83.54, 66.42]
2022-10-08 11:05:15,205 [trainer.py] => NME base curve: [83.54, 77.44]
2022-10-08 11:05:15,205 [trainer.py] => NME old curve: [83.54, 77.44]
2022-10-08 11:05:15,205 [trainer.py] => NME new curve: [0, 49.53]
2022-10-08 11:05:15,205 [trainer.py] => NME compound curve: [0, 49.53]
2022-10-08 11:05:15,434 [foster.py] => Learning on 12-17
2022-10-08 11:05:15,434 [foster.py] => All params: 22385326
2022-10-08 11:05:15,435 [foster.py] => Trainable params: 11202658
2022-10-08 11:05:15,443 [foster.py] => per cls weights : [1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623 1.14942623
 0.64137704 0.64137704 0.64137704 0.64137704 0.64137704]
2022-10-08 11:05:18,803 [foster.py] => Task 2, Epoch 1/34 => Loss 5.878, Loss_clf 2.047, Loss_fe 2.362, Loss_kd 1.036, Train_accy 39.98, Test_accy 43.77
2022-10-08 11:05:21,417 [foster.py] => Task 2, Epoch 2/34 => Loss 3.830, Loss_clf 0.893, Loss_fe 1.511, Loss_kd 1.007, Train_accy 42.20
2022-10-08 11:05:24,067 [foster.py] => Task 2, Epoch 3/34 => Loss 3.475, Loss_clf 0.770, Loss_fe 1.286, Loss_kd 1.002, Train_accy 41.25
2022-10-08 11:05:26,605 [foster.py] => Task 2, Epoch 4/34 => Loss 3.279, Loss_clf 0.718, Loss_fe 1.138, Loss_kd 1.005, Train_accy 40.22
2022-10-08 11:05:29,504 [foster.py] => Task 2, Epoch 5/34 => Loss 3.171, Loss_clf 0.694, Loss_fe 1.053, Loss_kd 1.006, Train_accy 42.20
2022-10-08 11:05:33,297 [foster.py] => Task 2, Epoch 6/34 => Loss 3.069, Loss_clf 0.657, Loss_fe 0.987, Loss_kd 1.005, Train_accy 40.54, Test_accy 45.29
2022-10-08 11:05:35,954 [foster.py] => Task 2, Epoch 7/34 => Loss 3.007, Loss_clf 0.650, Loss_fe 0.933, Loss_kd 1.005, Train_accy 41.41
2022-10-08 11:05:38,607 [foster.py] => Task 2, Epoch 8/34 => Loss 2.968, Loss_clf 0.646, Loss_fe 0.899, Loss_kd 1.005, Train_accy 42.99
2022-10-08 11:05:41,300 [foster.py] => Task 2, Epoch 9/34 => Loss 2.878, Loss_clf 0.611, Loss_fe 0.845, Loss_kd 1.004, Train_accy 42.52
2022-10-08 11:05:43,988 [foster.py] => Task 2, Epoch 10/34 => Loss 2.874, Loss_clf 0.617, Loss_fe 0.825, Loss_kd 1.011, Train_accy 43.47
2022-10-08 11:05:47,937 [foster.py] => Task 2, Epoch 11/34 => Loss 2.808, Loss_clf 0.594, Loss_fe 0.788, Loss_kd 1.006, Train_accy 42.99, Test_accy 46.82
2022-10-08 11:05:50,644 [foster.py] => Task 2, Epoch 12/34 => Loss 2.780, Loss_clf 0.587, Loss_fe 0.763, Loss_kd 1.010, Train_accy 45.61
2022-10-08 11:05:53,485 [foster.py] => Task 2, Epoch 13/34 => Loss 2.716, Loss_clf 0.558, Loss_fe 0.730, Loss_kd 1.007, Train_accy 45.45
2022-10-08 11:05:56,374 [foster.py] => Task 2, Epoch 14/34 => Loss 2.697, Loss_clf 0.552, Loss_fe 0.721, Loss_kd 1.005, Train_accy 43.55
2022-10-08 11:05:59,261 [foster.py] => Task 2, Epoch 15/34 => Loss 2.692, Loss_clf 0.556, Loss_fe 0.703, Loss_kd 1.012, Train_accy 44.73
2022-10-08 11:06:02,996 [foster.py] => Task 2, Epoch 16/34 => Loss 2.665, Loss_clf 0.556, Loss_fe 0.683, Loss_kd 1.006, Train_accy 45.45, Test_accy 49.11
2022-10-08 11:06:05,770 [foster.py] => Task 2, Epoch 17/34 => Loss 2.633, Loss_clf 0.531, Loss_fe 0.671, Loss_kd 1.011, Train_accy 47.59
2022-10-08 11:06:08,514 [foster.py] => Task 2, Epoch 18/34 => Loss 2.627, Loss_clf 0.536, Loss_fe 0.667, Loss_kd 1.005, Train_accy 44.66
2022-10-08 11:06:11,581 [foster.py] => Task 2, Epoch 19/34 => Loss 2.626, Loss_clf 0.532, Loss_fe 0.662, Loss_kd 1.010, Train_accy 45.92
2022-10-08 11:06:14,622 [foster.py] => Task 2, Epoch 20/34 => Loss 2.580, Loss_clf 0.518, Loss_fe 0.635, Loss_kd 1.008, Train_accy 44.89
2022-10-08 11:06:18,518 [foster.py] => Task 2, Epoch 21/34 => Loss 2.600, Loss_clf 0.524, Loss_fe 0.649, Loss_kd 1.007, Train_accy 45.92, Test_accy 49.87
2022-10-08 11:06:21,349 [foster.py] => Task 2, Epoch 22/34 => Loss 2.604, Loss_clf 0.529, Loss_fe 0.642, Loss_kd 1.012, Train_accy 44.73
2022-10-08 11:06:24,187 [foster.py] => Task 2, Epoch 23/34 => Loss 2.568, Loss_clf 0.516, Loss_fe 0.624, Loss_kd 1.008, Train_accy 46.16
2022-10-08 11:06:27,045 [foster.py] => Task 2, Epoch 24/34 => Loss 2.562, Loss_clf 0.509, Loss_fe 0.623, Loss_kd 1.009, Train_accy 47.35
2022-10-08 11:06:29,906 [foster.py] => Task 2, Epoch 25/34 => Loss 2.549, Loss_clf 0.503, Loss_fe 0.611, Loss_kd 1.014, Train_accy 46.32
2022-10-08 11:06:33,625 [foster.py] => Task 2, Epoch 26/34 => Loss 2.534, Loss_clf 0.498, Loss_fe 0.605, Loss_kd 1.010, Train_accy 45.76, Test_accy 50.13
2022-10-08 11:06:36,323 [foster.py] => Task 2, Epoch 27/34 => Loss 2.571, Loss_clf 0.516, Loss_fe 0.621, Loss_kd 1.013, Train_accy 46.71
2022-10-08 11:06:39,024 [foster.py] => Task 2, Epoch 28/34 => Loss 2.503, Loss_clf 0.482, Loss_fe 0.595, Loss_kd 1.006, Train_accy 46.87
2022-10-08 11:06:42,188 [foster.py] => Task 2, Epoch 29/34 => Loss 2.539, Loss_clf 0.494, Loss_fe 0.611, Loss_kd 1.012, Train_accy 46.95
2022-10-08 11:06:45,149 [foster.py] => Task 2, Epoch 30/34 => Loss 2.518, Loss_clf 0.487, Loss_fe 0.594, Loss_kd 1.014, Train_accy 48.46
2022-10-08 11:06:48,899 [foster.py] => Task 2, Epoch 31/34 => Loss 2.510, Loss_clf 0.492, Loss_fe 0.594, Loss_kd 1.005, Train_accy 46.63, Test_accy 50.38
2022-10-08 11:06:51,580 [foster.py] => Task 2, Epoch 32/34 => Loss 2.545, Loss_clf 0.506, Loss_fe 0.610, Loss_kd 1.008, Train_accy 45.53
2022-10-08 11:06:54,439 [foster.py] => Task 2, Epoch 33/34 => Loss 2.541, Loss_clf 0.507, Loss_fe 0.604, Loss_kd 1.009, Train_accy 46.24
2022-10-08 11:06:57,271 [foster.py] => Task 2, Epoch 34/34 => Loss 2.513, Loss_clf 0.491, Loss_fe 0.593, Loss_kd 1.009, Train_accy 47.66
2022-10-08 11:06:57,272 [foster.py] => do not weight align teacher!
2022-10-08 11:06:57,272 [foster.py] => per cls weights : [1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047 1.19039047
 0.54306287 0.54306287 0.54306287 0.54306287 0.54306287]
2022-10-08 11:07:01,623 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 2.134,  Train_accy 11.32, Test_accy 35.88
2022-10-08 11:07:05,088 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 2.019,  Train_accy 11.24
2022-10-08 11:07:08,511 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.972,  Train_accy 11.48
2022-10-08 11:07:11,795 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.951,  Train_accy 11.56
2022-10-08 11:07:15,060 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.948,  Train_accy 11.88
2022-10-08 11:07:19,067 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.930,  Train_accy 12.11, Test_accy 34.86
2022-10-08 11:07:22,306 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.919,  Train_accy 11.56
2022-10-08 11:07:25,836 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.911,  Train_accy 12.51
2022-10-08 11:07:29,396 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.902,  Train_accy 12.91
2022-10-08 11:07:33,010 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.905,  Train_accy 14.01
2022-10-08 11:07:37,253 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.893,  Train_accy 13.62, Test_accy 35.88
2022-10-08 11:07:40,815 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.888,  Train_accy 13.70
2022-10-08 11:07:43,970 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.893,  Train_accy 14.33
2022-10-08 11:07:47,163 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.869,  Train_accy 14.01
2022-10-08 11:07:50,559 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.884,  Train_accy 14.01
2022-10-08 11:07:54,723 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.875,  Train_accy 14.49, Test_accy 35.88
2022-10-08 11:07:57,973 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.868,  Train_accy 13.86
2022-10-08 11:08:01,374 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.884,  Train_accy 15.60
2022-10-08 11:08:04,766 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.872,  Train_accy 15.28
2022-10-08 11:08:08,148 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.860,  Train_accy 15.60
2022-10-08 11:08:12,439 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.871,  Train_accy 15.44, Test_accy 36.39
2022-10-08 11:08:15,699 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.879,  Train_accy 15.76
2022-10-08 11:08:18,946 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.874,  Train_accy 14.96
2022-10-08 11:08:22,434 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.871,  Train_accy 15.60
2022-10-08 11:08:26,349 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.861,  Train_accy 14.89
2022-10-08 11:08:30,734 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.865,  Train_accy 15.28, Test_accy 36.64
2022-10-08 11:08:30,735 [foster.py] => do not weight align student!
2022-10-08 11:08:31,461 [foster.py] => darknet eval: 
2022-10-08 11:08:31,461 [foster.py] => CNN top1 curve: 36.64
2022-10-08 11:08:31,461 [foster.py] => CNN top5 curve: 88.3
2022-10-08 11:08:31,461 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 11:08:40,922 [foster.py] => Exemplar size: 340
2022-10-08 11:08:40,922 [trainer.py] => CNN: {'total': 49.87, 'old': 53.87, 'new': 40.98, 'base': 76.22, 'compound': 31.0}
2022-10-08 11:08:40,922 [trainer.py] => CNN top1 curve: [84.15, 62.36, 49.87]
2022-10-08 11:08:40,922 [trainer.py] => CNN base curve: [84.15, 76.22, 76.22]
2022-10-08 11:08:40,922 [trainer.py] => CNN old curve: [84.15, 76.22, 53.87]
2022-10-08 11:08:40,922 [trainer.py] => CNN new curve: [0, 41.12, 40.98]
2022-10-08 11:08:40,922 [trainer.py] => CNN compound curve: [0, 41.12, 31.0]
2022-10-08 11:08:40,922 [trainer.py] => NME: {'total': 59.8, 'old': 54.61, 'new': 71.31, 'base': 68.9, 'compound': 53.28}
2022-10-08 11:08:40,922 [trainer.py] => NME top1 curve: [83.54, 66.42, 59.8]
2022-10-08 11:08:40,922 [trainer.py] => NME base curve: [83.54, 77.44, 68.9]
2022-10-08 11:08:40,922 [trainer.py] => NME old curve: [83.54, 77.44, 54.61]
2022-10-08 11:08:40,922 [trainer.py] => NME new curve: [0, 49.53, 71.31]
2022-10-08 11:08:40,922 [trainer.py] => NME compound curve: [0, 49.53, 53.28]
2022-10-08 11:08:41,145 [foster.py] => Learning on 17-22
2022-10-08 11:08:41,145 [foster.py] => All params: 22395581
2022-10-08 11:08:41,146 [foster.py] => Trainable params: 11210348
2022-10-08 11:08:41,154 [foster.py] => per cls weights : [1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325
 1.11167325 1.11167325 1.11167325 1.11167325 1.11167325 0.62031097
 0.62031097 0.62031097 0.62031097 0.62031097]
2022-10-08 11:08:44,809 [foster.py] => Task 3, Epoch 1/34 => Loss 6.699, Loss_clf 1.976, Loss_fe 2.689, Loss_kd 1.572, Train_accy 33.55, Test_accy 37.90
2022-10-08 11:08:47,541 [foster.py] => Task 3, Epoch 2/34 => Loss 5.080, Loss_clf 1.186, Loss_fe 1.841, Loss_kd 1.587, Train_accy 40.38
2022-10-08 11:08:50,253 [foster.py] => Task 3, Epoch 3/34 => Loss 4.729, Loss_clf 1.080, Loss_fe 1.607, Loss_kd 1.578, Train_accy 42.19
2022-10-08 11:08:52,963 [foster.py] => Task 3, Epoch 4/34 => Loss 4.614, Loss_clf 1.071, Loss_fe 1.499, Loss_kd 1.579, Train_accy 40.38
2022-10-08 11:08:55,699 [foster.py] => Task 3, Epoch 5/34 => Loss 4.466, Loss_clf 1.054, Loss_fe 1.367, Loss_kd 1.580, Train_accy 42.27
2022-10-08 11:09:00,897 [foster.py] => Task 3, Epoch 6/34 => Loss 4.343, Loss_clf 0.989, Loss_fe 1.314, Loss_kd 1.576, Train_accy 44.30, Test_accy 45.83
2022-10-08 11:09:04,073 [foster.py] => Task 3, Epoch 7/34 => Loss 4.226, Loss_clf 1.000, Loss_fe 1.213, Loss_kd 1.555, Train_accy 42.85
2022-10-08 11:09:07,260 [foster.py] => Task 3, Epoch 8/34 => Loss 4.242, Loss_clf 0.988, Loss_fe 1.209, Loss_kd 1.581, Train_accy 46.11
2022-10-08 11:09:10,385 [foster.py] => Task 3, Epoch 9/34 => Loss 4.122, Loss_clf 0.971, Loss_fe 1.139, Loss_kd 1.554, Train_accy 43.06
2022-10-08 11:09:13,360 [foster.py] => Task 3, Epoch 10/34 => Loss 4.060, Loss_clf 0.914, Loss_fe 1.092, Loss_kd 1.587, Train_accy 48.15
2022-10-08 11:09:17,173 [foster.py] => Task 3, Epoch 11/34 => Loss 3.981, Loss_clf 0.906, Loss_fe 1.066, Loss_kd 1.552, Train_accy 45.61, Test_accy 45.04
2022-10-08 11:09:20,061 [foster.py] => Task 3, Epoch 12/34 => Loss 4.084, Loss_clf 0.947, Loss_fe 1.076, Loss_kd 1.593, Train_accy 48.51
2022-10-08 11:09:22,993 [foster.py] => Task 3, Epoch 13/34 => Loss 3.883, Loss_clf 0.838, Loss_fe 0.995, Loss_kd 1.584, Train_accy 45.10
2022-10-08 11:09:25,860 [foster.py] => Task 3, Epoch 14/34 => Loss 3.918, Loss_clf 0.872, Loss_fe 1.002, Loss_kd 1.579, Train_accy 46.91
2022-10-08 11:09:28,898 [foster.py] => Task 3, Epoch 15/34 => Loss 3.885, Loss_clf 0.849, Loss_fe 0.973, Loss_kd 1.594, Train_accy 47.42
2022-10-08 11:09:33,018 [foster.py] => Task 3, Epoch 16/34 => Loss 3.847, Loss_clf 0.840, Loss_fe 0.958, Loss_kd 1.584, Train_accy 46.04, Test_accy 47.02
2022-10-08 11:09:35,921 [foster.py] => Task 3, Epoch 17/34 => Loss 3.870, Loss_clf 0.878, Loss_fe 0.959, Loss_kd 1.571, Train_accy 47.35
2022-10-08 11:09:43,351 [foster.py] => Task 3, Epoch 18/34 => Loss 3.790, Loss_clf 0.807, Loss_fe 0.917, Loss_kd 1.596, Train_accy 48.66
2022-10-08 11:09:47,450 [foster.py] => Task 3, Epoch 19/34 => Loss 3.737, Loss_clf 0.780, Loss_fe 0.913, Loss_kd 1.579, Train_accy 46.84
2022-10-08 11:09:50,848 [foster.py] => Task 3, Epoch 20/34 => Loss 3.781, Loss_clf 0.835, Loss_fe 0.919, Loss_kd 1.567, Train_accy 48.29
2022-10-08 11:09:54,985 [foster.py] => Task 3, Epoch 21/34 => Loss 3.760, Loss_clf 0.833, Loss_fe 0.892, Loss_kd 1.573, Train_accy 49.24, Test_accy 47.22
2022-10-08 11:09:57,737 [foster.py] => Task 3, Epoch 22/34 => Loss 3.705, Loss_clf 0.804, Loss_fe 0.869, Loss_kd 1.570, Train_accy 48.66
2022-10-08 11:10:00,447 [foster.py] => Task 3, Epoch 23/34 => Loss 3.705, Loss_clf 0.796, Loss_fe 0.886, Loss_kd 1.564, Train_accy 49.53
2022-10-08 11:10:04,807 [foster.py] => Task 3, Epoch 24/34 => Loss 3.714, Loss_clf 0.781, Loss_fe 0.868, Loss_kd 1.596, Train_accy 51.20
2022-10-08 11:10:08,046 [foster.py] => Task 3, Epoch 25/34 => Loss 3.662, Loss_clf 0.760, Loss_fe 0.856, Loss_kd 1.581, Train_accy 49.46
2022-10-08 11:10:12,096 [foster.py] => Task 3, Epoch 26/34 => Loss 3.665, Loss_clf 0.753, Loss_fe 0.859, Loss_kd 1.586, Train_accy 49.60, Test_accy 47.22
2022-10-08 11:10:15,020 [foster.py] => Task 3, Epoch 27/34 => Loss 3.660, Loss_clf 0.759, Loss_fe 0.844, Loss_kd 1.589, Train_accy 48.80
2022-10-08 11:10:17,908 [foster.py] => Task 3, Epoch 28/34 => Loss 3.724, Loss_clf 0.790, Loss_fe 0.882, Loss_kd 1.586, Train_accy 49.38
2022-10-08 11:10:20,746 [foster.py] => Task 3, Epoch 29/34 => Loss 3.644, Loss_clf 0.764, Loss_fe 0.855, Loss_kd 1.565, Train_accy 47.86
2022-10-08 11:10:23,609 [foster.py] => Task 3, Epoch 30/34 => Loss 3.669, Loss_clf 0.758, Loss_fe 0.857, Loss_kd 1.587, Train_accy 48.37
2022-10-08 11:10:27,432 [foster.py] => Task 3, Epoch 31/34 => Loss 3.648, Loss_clf 0.760, Loss_fe 0.843, Loss_kd 1.581, Train_accy 49.67, Test_accy 47.42
2022-10-08 11:10:30,294 [foster.py] => Task 3, Epoch 32/34 => Loss 3.654, Loss_clf 0.748, Loss_fe 0.858, Loss_kd 1.582, Train_accy 48.66
2022-10-08 11:10:33,207 [foster.py] => Task 3, Epoch 33/34 => Loss 3.675, Loss_clf 0.797, Loss_fe 0.849, Loss_kd 1.568, Train_accy 47.86
2022-10-08 11:10:36,152 [foster.py] => Task 3, Epoch 34/34 => Loss 3.666, Loss_clf 0.758, Loss_fe 0.856, Loss_kd 1.586, Train_accy 49.31
2022-10-08 11:10:36,153 [foster.py] => do not weight align teacher!
2022-10-08 11:10:36,154 [foster.py] => per cls weights : [1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798
 1.14101798 1.14101798 1.14101798 1.14101798 1.14101798 0.52053886
 0.52053886 0.52053886 0.52053886 0.52053886]
2022-10-08 11:10:40,588 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.517,  Train_accy 11.55, Test_accy 29.56
2022-10-08 11:10:44,208 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.489,  Train_accy 12.20
2022-10-08 11:10:47,777 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.454,  Train_accy 12.06
2022-10-08 11:10:51,493 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.445,  Train_accy 12.27
2022-10-08 11:10:56,032 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 2.432,  Train_accy 12.42
2022-10-08 11:11:00,676 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 2.426,  Train_accy 13.58, Test_accy 32.54
2022-10-08 11:11:03,960 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 2.417,  Train_accy 14.52
2022-10-08 11:11:07,564 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 2.418,  Train_accy 14.89
2022-10-08 11:11:11,571 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 2.405,  Train_accy 15.83
2022-10-08 11:11:15,636 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 2.401,  Train_accy 17.14
2022-10-08 11:11:20,209 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 2.405,  Train_accy 17.94, Test_accy 33.53
2022-10-08 11:11:23,488 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 2.390,  Train_accy 18.08
2022-10-08 11:11:27,661 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 2.391,  Train_accy 17.65
2022-10-08 11:11:31,490 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 2.388,  Train_accy 19.10
2022-10-08 11:11:35,081 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 2.389,  Train_accy 20.70
2022-10-08 11:11:39,532 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 2.389,  Train_accy 20.48, Test_accy 35.12
2022-10-08 11:11:42,776 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 2.378,  Train_accy 19.61
2022-10-08 11:11:46,415 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 2.417,  Train_accy 21.13
2022-10-08 11:11:50,209 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 2.384,  Train_accy 19.97
2022-10-08 11:11:54,022 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 2.384,  Train_accy 20.33
2022-10-08 11:11:58,634 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 2.386,  Train_accy 20.48, Test_accy 34.92
2022-10-08 11:12:02,033 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 2.377,  Train_accy 20.19
2022-10-08 11:12:05,483 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 2.393,  Train_accy 20.26
2022-10-08 11:12:09,382 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 2.382,  Train_accy 20.33
2022-10-08 11:12:13,240 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 2.380,  Train_accy 21.13
2022-10-08 11:12:17,632 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 2.383,  Train_accy 20.12, Test_accy 35.52
2022-10-08 11:12:17,633 [foster.py] => do not weight align student!
2022-10-08 11:12:18,459 [foster.py] => darknet eval: 
2022-10-08 11:12:18,459 [foster.py] => CNN top1 curve: 35.52
2022-10-08 11:12:18,459 [foster.py] => CNN top5 curve: 83.73
2022-10-08 11:12:18,460 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-10-08 11:12:29,599 [foster.py] => Exemplar size: 440
2022-10-08 11:12:29,599 [trainer.py] => CNN: {'total': 47.42, 'old': 50.13, 'new': 37.84, 'base': 76.22, 'compound': 33.53}
2022-10-08 11:12:29,599 [trainer.py] => CNN top1 curve: [84.15, 62.36, 49.87, 47.42]
2022-10-08 11:12:29,600 [trainer.py] => CNN base curve: [84.15, 76.22, 76.22, 76.22]
2022-10-08 11:12:29,600 [trainer.py] => CNN old curve: [84.15, 76.22, 53.87, 50.13]
2022-10-08 11:12:29,600 [trainer.py] => CNN new curve: [0, 41.12, 40.98, 37.84]
2022-10-08 11:12:29,600 [trainer.py] => CNN compound curve: [0, 41.12, 31.0, 33.53]
2022-10-08 11:12:29,600 [trainer.py] => NME: {'total': 55.56, 'old': 57.0, 'new': 50.45, 'base': 65.85, 'compound': 50.59}
2022-10-08 11:12:29,600 [trainer.py] => NME top1 curve: [83.54, 66.42, 59.8, 55.56]
2022-10-08 11:12:29,600 [trainer.py] => NME base curve: [83.54, 77.44, 68.9, 65.85]
2022-10-08 11:12:29,600 [trainer.py] => NME old curve: [83.54, 77.44, 54.61, 57.0]
2022-10-08 11:12:29,600 [trainer.py] => NME new curve: [0, 49.53, 71.31, 50.45]
2022-10-08 11:12:29,600 [trainer.py] => NME compound curve: [0, 49.53, 53.28, 50.59]
2022-10-08 11:12:29,601 [trainer.py] => top1: CNN:[87.513 64.728 51.396 45.924]+-[0.09004814 3.78317089 1.66641791 0.71892559]
2022-10-08 11:12:29,602 [trainer.py] => top1: NME:[87.606      71.556      61.05466667 54.37433333]+-[0.36097184 4.32130752 1.63112586 0.4492025 ]
2022-10-08 11:12:29,602 [trainer.py] => Last: top1: CNN:62.39+-1.17
2022-10-08 11:12:29,602 [trainer.py] => Last: top1: NME:68.65+-1.30
2022-10-08 11:12:29,602 [trainer.py] => base: CNN:[87.513      82.20866667 79.622      77.51866667]+-[0.09004814 0.98313862 0.50663662 0.45968782]
2022-10-08 11:12:29,602 [trainer.py] => base: NME:[87.606      78.32033333 69.88566667 67.43833333]+-[0.36097184 2.62957035 0.6535872  0.66746902]
2022-10-08 11:12:29,603 [trainer.py] => Last: base: CNN:81.72+-0.47
2022-10-08 11:12:29,603 [trainer.py] => Last: base: NME:75.81+-0.56
2022-10-08 11:12:29,603 [trainer.py] => old: CNN:[87.513      82.20866667 58.83733333 50.61266667]+-[0.09004814 0.98313862 4.06807713 1.10350784]
2022-10-08 11:12:29,603 [trainer.py] => old: NME:[87.606      78.32033333 62.02533333 56.326     ]+-[0.36097184 2.62957035 4.71025734 0.8710618 ]
2022-10-08 11:12:29,603 [trainer.py] => Last: old: CNN:69.79+-1.50
2022-10-08 11:12:29,603 [trainer.py] => Last: old: NME:71.07+-1.38
2022-10-08 11:12:29,604 [trainer.py] => new: CNN:[ 0.         40.40766667 33.59733333 29.95233333]+-[0.         7.77040498 4.52664396 6.77944822]
2022-10-08 11:12:29,604 [trainer.py] => new: NME:[ 0.         62.17366667 58.78233333 47.683     ]+-[ 0.         10.04726432  5.84824101  3.6984029 ]
2022-10-08 11:12:29,604 [trainer.py] => Last: new: CNN:34.65+-1.19
2022-10-08 11:12:29,604 [trainer.py] => Last: new: NME:56.21+-0.53
2022-10-08 11:12:29,604 [trainer.py] => compound: CNN:[ 0.         40.40766667 31.698      31.20933333]+-[0.         7.77040498 2.46150943 1.29333479]
2022-10-08 11:12:29,605 [trainer.py] => compound: NME:[ 0.         62.17366667 54.95       48.309     ]+-[ 0.         10.04726432  2.32931635  0.61007759]
2022-10-08 11:12:29,605 [trainer.py] => Last: compound: CNN:34.44+-2.92
2022-10-08 11:12:29,605 [trainer.py] => Last: compound: NME:55.14+-3.95