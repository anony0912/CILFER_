2022-09-28 00:00:25,372 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 00:00:25,372 [trainer.py] => prefix: cil
2022-09-28 00:00:25,372 [trainer.py] => dataset: CFEE
2022-09-28 00:00:25,372 [trainer.py] => memory_size: 2000
2022-09-28 00:00:25,372 [trainer.py] => memory_per_class: 20
2022-09-28 00:00:25,372 [trainer.py] => fixed_memory: True
2022-09-28 00:00:25,372 [trainer.py] => shuffle: True
2022-09-28 00:00:25,372 [trainer.py] => init_cls: 7
2022-09-28 00:00:25,372 [trainer.py] => increment: 3
2022-09-28 00:00:25,372 [trainer.py] => model_name: foster
2022-09-28 00:00:25,372 [trainer.py] => convnet_type: resnet18
2022-09-28 00:00:25,372 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 00:00:25,372 [trainer.py] => seed: 1993
2022-09-28 00:00:25,372 [trainer.py] => beta1: 0.96
2022-09-28 00:00:25,372 [trainer.py] => beta2: 0.97
2022-09-28 00:00:25,372 [trainer.py] => oofc: ft
2022-09-28 00:00:25,372 [trainer.py] => is_teacher_wa: False
2022-09-28 00:00:25,372 [trainer.py] => is_student_wa: False
2022-09-28 00:00:25,372 [trainer.py] => lambda_okd: 1
2022-09-28 00:00:25,372 [trainer.py] => wa_value: 1
2022-09-28 00:00:25,372 [trainer.py] => init_epochs: 40
2022-09-28 00:00:25,372 [trainer.py] => init_lr: 0.01
2022-09-28 00:00:25,372 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 00:00:25,372 [trainer.py] => boosting_epochs: 34
2022-09-28 00:00:25,372 [trainer.py] => compression_epochs: 26
2022-09-28 00:00:25,372 [trainer.py] => lr: 0.001
2022-09-28 00:00:25,372 [trainer.py] => batch_size: 32
2022-09-28 00:00:25,372 [trainer.py] => weight_decay: 0.0005
2022-09-28 00:00:25,372 [trainer.py] => num_workers: 8
2022-09-28 00:00:25,373 [trainer.py] => T: 2
2022-09-28 00:00:25,373 [trainer.py] => nb_runs: 3
2022-09-28 00:00:25,373 [trainer.py] => fold: 10
2022-09-28 00:00:25,373 [data.py] => ========== Fold:0 ==========
2022-09-28 00:00:25,378 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 13, 17, 15, 9, 11, 20, 18, 12, 14, 7, 10, 19, 21, 16, 8]
2022-09-28 00:00:28,104 [foster.py] => Learning on 0-7
2022-09-28 00:00:28,104 [foster.py] => All params: 11183694
2022-09-28 00:00:28,104 [foster.py] => Trainable params: 11183694
2022-09-28 00:00:33,779 [foster.py] => Task 0, Epoch 1/40 => Loss 1.327, Train_accy 52.17
2022-09-28 00:00:36,960 [foster.py] => Task 0, Epoch 2/40 => Loss 0.541, Train_accy 81.89, Test_accy 84.18
2022-09-28 00:00:39,904 [foster.py] => Task 0, Epoch 3/40 => Loss 0.357, Train_accy 88.11, Test_accy 89.27
2022-09-28 00:00:42,832 [foster.py] => Task 0, Epoch 4/40 => Loss 0.279, Train_accy 90.49, Test_accy 88.70
2022-09-28 00:00:45,739 [foster.py] => Task 0, Epoch 5/40 => Loss 0.248, Train_accy 91.33, Test_accy 88.70
2022-09-28 00:00:48,095 [foster.py] => Task 0, Epoch 6/40 => Loss 0.194, Train_accy 93.99
2022-09-28 00:00:51,086 [foster.py] => Task 0, Epoch 7/40 => Loss 0.157, Train_accy 94.41, Test_accy 89.83
2022-09-28 00:00:53,996 [foster.py] => Task 0, Epoch 8/40 => Loss 0.129, Train_accy 96.50, Test_accy 88.14
2022-09-28 00:00:56,956 [foster.py] => Task 0, Epoch 9/40 => Loss 0.102, Train_accy 97.13, Test_accy 86.44
2022-09-28 00:00:59,884 [foster.py] => Task 0, Epoch 10/40 => Loss 0.096, Train_accy 97.06, Test_accy 89.27
2022-09-28 00:01:02,224 [foster.py] => Task 0, Epoch 11/40 => Loss 0.088, Train_accy 96.78
2022-09-28 00:01:05,204 [foster.py] => Task 0, Epoch 12/40 => Loss 0.069, Train_accy 98.04, Test_accy 87.57
2022-09-28 00:01:08,198 [foster.py] => Task 0, Epoch 13/40 => Loss 0.060, Train_accy 98.25, Test_accy 89.83
2022-09-28 00:01:11,148 [foster.py] => Task 0, Epoch 14/40 => Loss 0.057, Train_accy 98.11, Test_accy 89.83
2022-09-28 00:01:14,064 [foster.py] => Task 0, Epoch 15/40 => Loss 0.046, Train_accy 98.95, Test_accy 90.96
2022-09-28 00:01:16,409 [foster.py] => Task 0, Epoch 16/40 => Loss 0.051, Train_accy 98.25
2022-09-28 00:01:19,318 [foster.py] => Task 0, Epoch 17/40 => Loss 0.032, Train_accy 99.37, Test_accy 90.96
2022-09-28 00:01:22,252 [foster.py] => Task 0, Epoch 18/40 => Loss 0.034, Train_accy 99.16, Test_accy 90.40
2022-09-28 00:01:25,189 [foster.py] => Task 0, Epoch 19/40 => Loss 0.031, Train_accy 99.44, Test_accy 88.70
2022-09-28 00:01:28,140 [foster.py] => Task 0, Epoch 20/40 => Loss 0.022, Train_accy 99.65, Test_accy 89.27
2022-09-28 00:01:30,484 [foster.py] => Task 0, Epoch 21/40 => Loss 0.027, Train_accy 99.23
2022-09-28 00:01:33,439 [foster.py] => Task 0, Epoch 22/40 => Loss 0.029, Train_accy 99.16, Test_accy 88.70
2022-09-28 00:01:36,364 [foster.py] => Task 0, Epoch 23/40 => Loss 0.021, Train_accy 99.65, Test_accy 88.14
2022-09-28 00:01:39,300 [foster.py] => Task 0, Epoch 24/40 => Loss 0.020, Train_accy 99.72, Test_accy 90.40
2022-09-28 00:01:42,203 [foster.py] => Task 0, Epoch 25/40 => Loss 0.016, Train_accy 99.86, Test_accy 90.40
2022-09-28 00:01:44,506 [foster.py] => Task 0, Epoch 26/40 => Loss 0.019, Train_accy 99.51
2022-09-28 00:01:47,438 [foster.py] => Task 0, Epoch 27/40 => Loss 0.020, Train_accy 99.44, Test_accy 89.83
2022-09-28 00:01:50,375 [foster.py] => Task 0, Epoch 28/40 => Loss 0.015, Train_accy 99.65, Test_accy 89.27
2022-09-28 00:01:53,299 [foster.py] => Task 0, Epoch 29/40 => Loss 0.012, Train_accy 100.00, Test_accy 90.96
2022-09-28 00:01:56,339 [foster.py] => Task 0, Epoch 30/40 => Loss 0.018, Train_accy 99.58, Test_accy 90.40
2022-09-28 00:01:58,638 [foster.py] => Task 0, Epoch 31/40 => Loss 0.018, Train_accy 99.72
2022-09-28 00:02:01,617 [foster.py] => Task 0, Epoch 32/40 => Loss 0.015, Train_accy 99.79, Test_accy 90.96
2022-09-28 00:02:04,539 [foster.py] => Task 0, Epoch 33/40 => Loss 0.014, Train_accy 99.79, Test_accy 90.96
2022-09-28 00:02:07,479 [foster.py] => Task 0, Epoch 34/40 => Loss 0.015, Train_accy 99.79, Test_accy 89.83
2022-09-28 00:02:10,397 [foster.py] => Task 0, Epoch 35/40 => Loss 0.014, Train_accy 99.93, Test_accy 90.40
2022-09-28 00:02:12,743 [foster.py] => Task 0, Epoch 36/40 => Loss 0.017, Train_accy 99.51
2022-09-28 00:02:15,667 [foster.py] => Task 0, Epoch 37/40 => Loss 0.011, Train_accy 100.00, Test_accy 90.96
2022-09-28 00:02:18,596 [foster.py] => Task 0, Epoch 38/40 => Loss 0.012, Train_accy 99.86, Test_accy 90.40
2022-09-28 00:02:21,587 [foster.py] => Task 0, Epoch 39/40 => Loss 0.012, Train_accy 99.93, Test_accy 90.96
2022-09-28 00:02:24,573 [foster.py] => Task 0, Epoch 40/40 => Loss 0.012, Train_accy 99.86, Test_accy 90.40
2022-09-28 00:02:24,573 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 00:02:31,274 [foster.py] => Exemplar size: 140
2022-09-28 00:02:31,274 [trainer.py] => CNN: {'total': 90.4, 'old': 90.4, 'new': 0, 'base': 90.4, 'compound': 0}
2022-09-28 00:02:31,274 [trainer.py] => CNN top1 curve: [90.4]
2022-09-28 00:02:31,275 [trainer.py] => CNN base curve: [90.4]
2022-09-28 00:02:31,275 [trainer.py] => CNN old curve: [90.4]
2022-09-28 00:02:31,275 [trainer.py] => CNN new curve: [0]
2022-09-28 00:02:31,275 [trainer.py] => CNN compound curve: [0]
2022-09-28 00:02:31,275 [trainer.py] => NME: {'total': 89.27, 'old': 89.27, 'new': 0, 'base': 89.27, 'compound': 0}
2022-09-28 00:02:31,275 [trainer.py] => NME top1 curve: [89.27]
2022-09-28 00:02:31,275 [trainer.py] => NME base curve: [89.27]
2022-09-28 00:02:31,275 [trainer.py] => NME old curve: [89.27]
2022-09-28 00:02:31,275 [trainer.py] => NME new curve: [0]
2022-09-28 00:02:31,275 [trainer.py] => NME compound curve: [0]
2022-09-28 00:02:31,504 [foster.py] => Learning on 7-10
2022-09-28 00:02:31,505 [foster.py] => All params: 22371995
2022-09-28 00:02:31,505 [foster.py] => Trainable params: 11191892
2022-09-28 00:02:31,525 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 00:02:34,019 [foster.py] => Task 1, Epoch 1/34 => Loss 4.608, Loss_clf 2.073, Loss_fe 1.849, Loss_kd 0.480, Train_accy 41.48, Test_accy 73.79
2022-09-28 00:02:35,771 [foster.py] => Task 1, Epoch 2/34 => Loss 2.455, Loss_clf 0.607, Loss_fe 1.159, Loss_kd 0.482, Train_accy 74.24
2022-09-28 00:02:37,479 [foster.py] => Task 1, Epoch 3/34 => Loss 2.008, Loss_clf 0.386, Loss_fe 0.955, Loss_kd 0.467, Train_accy 56.27
2022-09-28 00:02:39,242 [foster.py] => Task 1, Epoch 4/34 => Loss 1.823, Loss_clf 0.353, Loss_fe 0.806, Loss_kd 0.465, Train_accy 53.90
2022-09-28 00:02:41,023 [foster.py] => Task 1, Epoch 5/34 => Loss 1.704, Loss_clf 0.327, Loss_fe 0.719, Loss_kd 0.461, Train_accy 55.22
2022-09-28 00:02:43,502 [foster.py] => Task 1, Epoch 6/34 => Loss 1.696, Loss_clf 0.345, Loss_fe 0.690, Loss_kd 0.463, Train_accy 55.61, Test_accy 75.00
2022-09-28 00:02:45,236 [foster.py] => Task 1, Epoch 7/34 => Loss 1.585, Loss_clf 0.311, Loss_fe 0.611, Loss_kd 0.464, Train_accy 55.09
2022-09-28 00:02:46,955 [foster.py] => Task 1, Epoch 8/34 => Loss 1.534, Loss_clf 0.300, Loss_fe 0.574, Loss_kd 0.462, Train_accy 59.58
2022-09-28 00:02:48,658 [foster.py] => Task 1, Epoch 9/34 => Loss 1.514, Loss_clf 0.297, Loss_fe 0.553, Loss_kd 0.465, Train_accy 57.33
2022-09-28 00:02:50,392 [foster.py] => Task 1, Epoch 10/34 => Loss 1.462, Loss_clf 0.282, Loss_fe 0.524, Loss_kd 0.459, Train_accy 57.60
2022-09-28 00:02:52,954 [foster.py] => Task 1, Epoch 11/34 => Loss 1.408, Loss_clf 0.265, Loss_fe 0.487, Loss_kd 0.459, Train_accy 57.73, Test_accy 75.00
2022-09-28 00:02:54,711 [foster.py] => Task 1, Epoch 12/34 => Loss 1.388, Loss_clf 0.270, Loss_fe 0.470, Loss_kd 0.454, Train_accy 56.27
2022-09-28 00:02:56,403 [foster.py] => Task 1, Epoch 13/34 => Loss 1.359, Loss_clf 0.257, Loss_fe 0.440, Loss_kd 0.464, Train_accy 56.94
2022-09-28 00:02:58,150 [foster.py] => Task 1, Epoch 14/34 => Loss 1.311, Loss_clf 0.235, Loss_fe 0.417, Loss_kd 0.461, Train_accy 59.18
2022-09-28 00:02:59,890 [foster.py] => Task 1, Epoch 15/34 => Loss 1.323, Loss_clf 0.248, Loss_fe 0.412, Loss_kd 0.465, Train_accy 60.24
2022-09-28 00:03:02,348 [foster.py] => Task 1, Epoch 16/34 => Loss 1.287, Loss_clf 0.232, Loss_fe 0.398, Loss_kd 0.460, Train_accy 57.20, Test_accy 75.81
2022-09-28 00:03:04,084 [foster.py] => Task 1, Epoch 17/34 => Loss 1.260, Loss_clf 0.218, Loss_fe 0.384, Loss_kd 0.461, Train_accy 60.24
2022-09-28 00:03:05,801 [foster.py] => Task 1, Epoch 18/34 => Loss 1.240, Loss_clf 0.221, Loss_fe 0.365, Loss_kd 0.457, Train_accy 59.45
2022-09-28 00:03:07,546 [foster.py] => Task 1, Epoch 19/34 => Loss 1.224, Loss_clf 0.215, Loss_fe 0.362, Loss_kd 0.453, Train_accy 60.37
2022-09-28 00:03:09,278 [foster.py] => Task 1, Epoch 20/34 => Loss 1.235, Loss_clf 0.214, Loss_fe 0.364, Loss_kd 0.460, Train_accy 60.63
2022-09-28 00:03:11,759 [foster.py] => Task 1, Epoch 21/34 => Loss 1.225, Loss_clf 0.216, Loss_fe 0.345, Loss_kd 0.465, Train_accy 60.50, Test_accy 76.21
2022-09-28 00:03:13,504 [foster.py] => Task 1, Epoch 22/34 => Loss 1.213, Loss_clf 0.204, Loss_fe 0.346, Loss_kd 0.464, Train_accy 59.18
2022-09-28 00:03:15,201 [foster.py] => Task 1, Epoch 23/34 => Loss 1.220, Loss_clf 0.208, Loss_fe 0.351, Loss_kd 0.463, Train_accy 59.97
2022-09-28 00:03:16,934 [foster.py] => Task 1, Epoch 24/34 => Loss 1.230, Loss_clf 0.218, Loss_fe 0.352, Loss_kd 0.462, Train_accy 57.99
2022-09-28 00:03:18,639 [foster.py] => Task 1, Epoch 25/34 => Loss 1.209, Loss_clf 0.207, Loss_fe 0.336, Loss_kd 0.467, Train_accy 60.77
2022-09-28 00:03:21,142 [foster.py] => Task 1, Epoch 26/34 => Loss 1.206, Loss_clf 0.204, Loss_fe 0.343, Loss_kd 0.462, Train_accy 58.78, Test_accy 76.61
2022-09-28 00:03:22,844 [foster.py] => Task 1, Epoch 27/34 => Loss 1.181, Loss_clf 0.195, Loss_fe 0.332, Loss_kd 0.457, Train_accy 60.37
2022-09-28 00:03:24,540 [foster.py] => Task 1, Epoch 28/34 => Loss 1.175, Loss_clf 0.195, Loss_fe 0.327, Loss_kd 0.457, Train_accy 60.11
2022-09-28 00:03:26,271 [foster.py] => Task 1, Epoch 29/34 => Loss 1.203, Loss_clf 0.210, Loss_fe 0.341, Loss_kd 0.456, Train_accy 60.77
2022-09-28 00:03:27,982 [foster.py] => Task 1, Epoch 30/34 => Loss 1.170, Loss_clf 0.193, Loss_fe 0.323, Loss_kd 0.458, Train_accy 61.03
2022-09-28 00:03:30,460 [foster.py] => Task 1, Epoch 31/34 => Loss 1.196, Loss_clf 0.206, Loss_fe 0.330, Loss_kd 0.462, Train_accy 59.31, Test_accy 76.61
2022-09-28 00:03:32,165 [foster.py] => Task 1, Epoch 32/34 => Loss 1.178, Loss_clf 0.193, Loss_fe 0.327, Loss_kd 0.460, Train_accy 59.71
2022-09-28 00:03:33,882 [foster.py] => Task 1, Epoch 33/34 => Loss 1.180, Loss_clf 0.196, Loss_fe 0.324, Loss_kd 0.462, Train_accy 60.50
2022-09-28 00:03:35,630 [foster.py] => Task 1, Epoch 34/34 => Loss 1.199, Loss_clf 0.205, Loss_fe 0.332, Loss_kd 0.463, Train_accy 60.11
2022-09-28 00:03:35,631 [foster.py] => do not weight align teacher!
2022-09-28 00:03:35,631 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 00:03:38,444 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.572,  Train_accy 18.23, Test_accy 63.31
2022-09-28 00:03:40,363 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.416,  Train_accy 18.49
2022-09-28 00:03:42,281 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.327,  Train_accy 19.95
2022-09-28 00:03:44,255 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.276,  Train_accy 23.51
2022-09-28 00:03:46,214 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.253,  Train_accy 27.48
2022-09-28 00:03:48,817 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.239,  Train_accy 28.80, Test_accy 66.13
2022-09-28 00:03:50,752 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.226,  Train_accy 32.10
2022-09-28 00:03:52,697 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.204,  Train_accy 33.42
2022-09-28 00:03:54,651 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.205,  Train_accy 34.74
2022-09-28 00:03:56,593 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.193,  Train_accy 34.74
2022-09-28 00:03:59,249 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.205,  Train_accy 35.14, Test_accy 66.94
2022-09-28 00:04:01,195 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.162,  Train_accy 36.20
2022-09-28 00:04:03,096 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.184,  Train_accy 35.93
2022-09-28 00:04:05,029 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.171,  Train_accy 35.80
2022-09-28 00:04:06,938 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.184,  Train_accy 37.65
2022-09-28 00:04:09,576 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.177,  Train_accy 36.59, Test_accy 69.76
2022-09-28 00:04:11,527 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.173,  Train_accy 37.38
2022-09-28 00:04:13,488 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.176,  Train_accy 38.44
2022-09-28 00:04:15,440 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.159,  Train_accy 37.91
2022-09-28 00:04:17,432 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.174,  Train_accy 36.99
2022-09-28 00:04:20,051 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.174,  Train_accy 37.65, Test_accy 68.55
2022-09-28 00:04:22,003 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.163,  Train_accy 39.23
2022-09-28 00:04:23,913 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.173,  Train_accy 37.12
2022-09-28 00:04:25,812 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.167,  Train_accy 36.86
2022-09-28 00:04:27,766 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.163,  Train_accy 37.65
2022-09-28 00:04:30,392 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.167,  Train_accy 37.91, Test_accy 68.95
2022-09-28 00:04:30,392 [foster.py] => do not weight align student!
2022-09-28 00:04:31,084 [foster.py] => darknet eval: 
2022-09-28 00:04:31,084 [foster.py] => CNN top1 curve: 68.95
2022-09-28 00:04:31,084 [foster.py] => CNN top5 curve: 99.6
2022-09-28 00:04:31,084 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 00:04:37,400 [foster.py] => Exemplar size: 200
2022-09-28 00:04:37,400 [trainer.py] => CNN: {'total': 76.61, 'old': 88.14, 'new': 47.89, 'base': 88.14, 'compound': 47.89}
2022-09-28 00:04:37,400 [trainer.py] => CNN top1 curve: [90.4, 76.61]
2022-09-28 00:04:37,400 [trainer.py] => CNN base curve: [90.4, 88.14]
2022-09-28 00:04:37,400 [trainer.py] => CNN old curve: [90.4, 88.14]
2022-09-28 00:04:37,400 [trainer.py] => CNN new curve: [0, 47.89]
2022-09-28 00:04:37,400 [trainer.py] => CNN compound curve: [0, 47.89]
2022-09-28 00:04:37,400 [trainer.py] => NME: {'total': 83.47, 'old': 86.44, 'new': 76.06, 'base': 86.44, 'compound': 76.06}
2022-09-28 00:04:37,400 [trainer.py] => NME top1 curve: [89.27, 83.47]
2022-09-28 00:04:37,400 [trainer.py] => NME base curve: [89.27, 86.44]
2022-09-28 00:04:37,400 [trainer.py] => NME old curve: [89.27, 86.44]
2022-09-28 00:04:37,400 [trainer.py] => NME new curve: [0, 76.06]
2022-09-28 00:04:37,400 [trainer.py] => NME compound curve: [0, 76.06]
2022-09-28 00:04:37,628 [foster.py] => Learning on 10-13
2022-09-28 00:04:37,629 [foster.py] => All params: 22378148
2022-09-28 00:04:37,629 [foster.py] => Trainable params: 11196506
2022-09-28 00:04:37,649 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 00:04:40,288 [foster.py] => Task 2, Epoch 1/34 => Loss 5.404, Loss_clf 2.231, Loss_fe 2.094, Loss_kd 0.830, Train_accy 39.61, Test_accy 49.03
2022-09-28 00:04:42,113 [foster.py] => Task 2, Epoch 2/34 => Loss 3.334, Loss_clf 0.880, Loss_fe 1.400, Loss_kd 0.811, Train_accy 48.55
2022-09-28 00:04:43,935 [foster.py] => Task 2, Epoch 3/34 => Loss 2.913, Loss_clf 0.704, Loss_fe 1.177, Loss_kd 0.794, Train_accy 37.56
2022-09-28 00:04:45,771 [foster.py] => Task 2, Epoch 4/34 => Loss 2.724, Loss_clf 0.638, Loss_fe 1.047, Loss_kd 0.799, Train_accy 39.49
2022-09-28 00:04:47,598 [foster.py] => Task 2, Epoch 5/34 => Loss 2.636, Loss_clf 0.614, Loss_fe 0.978, Loss_kd 0.803, Train_accy 40.70
2022-09-28 00:04:50,201 [foster.py] => Task 2, Epoch 6/34 => Loss 2.564, Loss_clf 0.603, Loss_fe 0.926, Loss_kd 0.796, Train_accy 41.43, Test_accy 62.66
2022-09-28 00:04:52,003 [foster.py] => Task 2, Epoch 7/34 => Loss 2.451, Loss_clf 0.562, Loss_fe 0.856, Loss_kd 0.794, Train_accy 42.03
2022-09-28 00:04:53,824 [foster.py] => Task 2, Epoch 8/34 => Loss 2.450, Loss_clf 0.575, Loss_fe 0.839, Loss_kd 0.797, Train_accy 40.82
2022-09-28 00:04:55,698 [foster.py] => Task 2, Epoch 9/34 => Loss 2.351, Loss_clf 0.534, Loss_fe 0.771, Loss_kd 0.805, Train_accy 43.84
2022-09-28 00:04:57,520 [foster.py] => Task 2, Epoch 10/34 => Loss 2.327, Loss_clf 0.539, Loss_fe 0.752, Loss_kd 0.797, Train_accy 41.43
2022-09-28 00:05:00,170 [foster.py] => Task 2, Epoch 11/34 => Loss 2.304, Loss_clf 0.522, Loss_fe 0.744, Loss_kd 0.799, Train_accy 43.72, Test_accy 64.29
2022-09-28 00:05:01,976 [foster.py] => Task 2, Epoch 12/34 => Loss 2.206, Loss_clf 0.487, Loss_fe 0.685, Loss_kd 0.795, Train_accy 46.38
2022-09-28 00:05:03,781 [foster.py] => Task 2, Epoch 13/34 => Loss 2.145, Loss_clf 0.453, Loss_fe 0.660, Loss_kd 0.794, Train_accy 44.57
2022-09-28 00:05:05,667 [foster.py] => Task 2, Epoch 14/34 => Loss 2.151, Loss_clf 0.463, Loss_fe 0.650, Loss_kd 0.799, Train_accy 46.14
2022-09-28 00:05:07,511 [foster.py] => Task 2, Epoch 15/34 => Loss 2.159, Loss_clf 0.471, Loss_fe 0.636, Loss_kd 0.809, Train_accy 44.81
2022-09-28 00:05:10,125 [foster.py] => Task 2, Epoch 16/34 => Loss 2.117, Loss_clf 0.462, Loss_fe 0.618, Loss_kd 0.798, Train_accy 43.84, Test_accy 64.61
2022-09-28 00:05:11,929 [foster.py] => Task 2, Epoch 17/34 => Loss 2.119, Loss_clf 0.461, Loss_fe 0.617, Loss_kd 0.801, Train_accy 44.32
2022-09-28 00:05:13,739 [foster.py] => Task 2, Epoch 18/34 => Loss 2.065, Loss_clf 0.440, Loss_fe 0.580, Loss_kd 0.804, Train_accy 46.26
2022-09-28 00:05:15,568 [foster.py] => Task 2, Epoch 19/34 => Loss 2.038, Loss_clf 0.431, Loss_fe 0.575, Loss_kd 0.794, Train_accy 45.05
2022-09-28 00:05:17,411 [foster.py] => Task 2, Epoch 20/34 => Loss 2.057, Loss_clf 0.435, Loss_fe 0.581, Loss_kd 0.801, Train_accy 45.89
2022-09-28 00:05:20,026 [foster.py] => Task 2, Epoch 21/34 => Loss 2.042, Loss_clf 0.437, Loss_fe 0.570, Loss_kd 0.797, Train_accy 45.29, Test_accy 64.94
2022-09-28 00:05:21,829 [foster.py] => Task 2, Epoch 22/34 => Loss 2.017, Loss_clf 0.419, Loss_fe 0.560, Loss_kd 0.799, Train_accy 46.26
2022-09-28 00:05:23,642 [foster.py] => Task 2, Epoch 23/34 => Loss 1.991, Loss_clf 0.403, Loss_fe 0.537, Loss_kd 0.808, Train_accy 49.28
2022-09-28 00:05:25,488 [foster.py] => Task 2, Epoch 24/34 => Loss 1.982, Loss_clf 0.413, Loss_fe 0.543, Loss_kd 0.789, Train_accy 47.83
2022-09-28 00:05:27,332 [foster.py] => Task 2, Epoch 25/34 => Loss 1.974, Loss_clf 0.403, Loss_fe 0.533, Loss_kd 0.799, Train_accy 46.50
2022-09-28 00:05:29,997 [foster.py] => Task 2, Epoch 26/34 => Loss 1.981, Loss_clf 0.412, Loss_fe 0.537, Loss_kd 0.794, Train_accy 46.38, Test_accy 65.58
2022-09-28 00:05:31,806 [foster.py] => Task 2, Epoch 27/34 => Loss 1.968, Loss_clf 0.389, Loss_fe 0.531, Loss_kd 0.806, Train_accy 48.55
2022-09-28 00:05:33,616 [foster.py] => Task 2, Epoch 28/34 => Loss 2.010, Loss_clf 0.415, Loss_fe 0.548, Loss_kd 0.806, Train_accy 47.58
2022-09-28 00:05:35,439 [foster.py] => Task 2, Epoch 29/34 => Loss 1.966, Loss_clf 0.393, Loss_fe 0.527, Loss_kd 0.804, Train_accy 48.07
2022-09-28 00:05:37,288 [foster.py] => Task 2, Epoch 30/34 => Loss 1.966, Loss_clf 0.399, Loss_fe 0.534, Loss_kd 0.794, Train_accy 47.83
2022-09-28 00:05:39,920 [foster.py] => Task 2, Epoch 31/34 => Loss 1.941, Loss_clf 0.388, Loss_fe 0.513, Loss_kd 0.799, Train_accy 48.67, Test_accy 66.23
2022-09-28 00:05:41,761 [foster.py] => Task 2, Epoch 32/34 => Loss 1.967, Loss_clf 0.387, Loss_fe 0.531, Loss_kd 0.807, Train_accy 48.43
2022-09-28 00:05:43,636 [foster.py] => Task 2, Epoch 33/34 => Loss 1.991, Loss_clf 0.409, Loss_fe 0.534, Loss_kd 0.806, Train_accy 49.28
2022-09-28 00:05:45,446 [foster.py] => Task 2, Epoch 34/34 => Loss 1.987, Loss_clf 0.410, Loss_fe 0.536, Loss_kd 0.801, Train_accy 47.83
2022-09-28 00:05:45,447 [foster.py] => do not weight align teacher!
2022-09-28 00:05:45,447 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 00:05:48,459 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.819,  Train_accy 16.55, Test_accy 53.90
2022-09-28 00:05:50,509 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.667,  Train_accy 17.75
2022-09-28 00:05:52,554 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.623,  Train_accy 18.72
2022-09-28 00:05:54,629 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.586,  Train_accy 18.84
2022-09-28 00:05:56,648 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.567,  Train_accy 19.69
2022-09-28 00:05:59,424 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.545,  Train_accy 18.96, Test_accy 57.79
2022-09-28 00:06:01,466 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.551,  Train_accy 20.05
2022-09-28 00:06:03,540 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.537,  Train_accy 19.69
2022-09-28 00:06:05,587 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.537,  Train_accy 20.53
2022-09-28 00:06:07,624 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.522,  Train_accy 20.17
2022-09-28 00:06:10,406 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.526,  Train_accy 20.17, Test_accy 57.47
2022-09-28 00:06:12,438 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.526,  Train_accy 20.89
2022-09-28 00:06:14,478 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.521,  Train_accy 20.53
2022-09-28 00:06:16,554 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.513,  Train_accy 21.26
2022-09-28 00:06:18,570 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.511,  Train_accy 21.01
2022-09-28 00:06:21,358 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.526,  Train_accy 20.41, Test_accy 57.47
2022-09-28 00:06:23,438 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.505,  Train_accy 20.89
2022-09-28 00:06:25,483 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.508,  Train_accy 21.50
2022-09-28 00:06:27,580 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.519,  Train_accy 21.50
2022-09-28 00:06:29,651 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.494,  Train_accy 21.62
2022-09-28 00:06:32,404 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.507,  Train_accy 21.38, Test_accy 58.77
2022-09-28 00:06:34,442 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.517,  Train_accy 21.86
2022-09-28 00:06:36,487 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.506,  Train_accy 22.46
2022-09-28 00:06:38,561 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.514,  Train_accy 20.17
2022-09-28 00:06:40,606 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.506,  Train_accy 21.74
2022-09-28 00:06:43,412 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.525,  Train_accy 21.62, Test_accy 58.12
2022-09-28 00:06:43,412 [foster.py] => do not weight align student!
2022-09-28 00:06:44,180 [foster.py] => darknet eval: 
2022-09-28 00:06:44,180 [foster.py] => CNN top1 curve: 58.12
2022-09-28 00:06:44,180 [foster.py] => CNN top5 curve: 97.73
2022-09-28 00:06:44,180 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 00:06:51,593 [foster.py] => Exemplar size: 260
2022-09-28 00:06:51,593 [trainer.py] => CNN: {'total': 65.58, 'old': 73.79, 'new': 31.67, 'base': 80.79, 'compound': 45.04}
2022-09-28 00:06:51,593 [trainer.py] => CNN top1 curve: [90.4, 76.61, 65.58]
2022-09-28 00:06:51,593 [trainer.py] => CNN base curve: [90.4, 88.14, 80.79]
2022-09-28 00:06:51,593 [trainer.py] => CNN old curve: [90.4, 88.14, 73.79]
2022-09-28 00:06:51,593 [trainer.py] => CNN new curve: [0, 47.89, 31.67]
2022-09-28 00:06:51,593 [trainer.py] => CNN compound curve: [0, 47.89, 45.04]
2022-09-28 00:06:51,593 [trainer.py] => NME: {'total': 72.08, 'old': 74.6, 'new': 61.67, 'base': 74.58, 'compound': 68.7}
2022-09-28 00:06:51,593 [trainer.py] => NME top1 curve: [89.27, 83.47, 72.08]
2022-09-28 00:06:51,593 [trainer.py] => NME base curve: [89.27, 86.44, 74.58]
2022-09-28 00:06:51,593 [trainer.py] => NME old curve: [89.27, 86.44, 74.6]
2022-09-28 00:06:51,593 [trainer.py] => NME new curve: [0, 76.06, 61.67]
2022-09-28 00:06:51,593 [trainer.py] => NME compound curve: [0, 76.06, 68.7]
2022-09-28 00:06:51,821 [foster.py] => Learning on 13-16
2022-09-28 00:06:51,821 [foster.py] => All params: 22384301
2022-09-28 00:06:51,821 [foster.py] => Trainable params: 11201120
2022-09-28 00:06:51,841 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 00:06:54,597 [foster.py] => Task 3, Epoch 1/34 => Loss 5.815, Loss_clf 1.887, Loss_fe 2.297, Loss_kd 1.325, Train_accy 41.67, Test_accy 47.43
2022-09-28 00:06:56,545 [foster.py] => Task 3, Epoch 2/34 => Loss 4.210, Loss_clf 1.006, Loss_fe 1.588, Loss_kd 1.313, Train_accy 38.51
2022-09-28 00:06:58,528 [foster.py] => Task 3, Epoch 3/34 => Loss 3.898, Loss_clf 0.874, Loss_fe 1.404, Loss_kd 1.316, Train_accy 41.44
2022-09-28 00:07:00,431 [foster.py] => Task 3, Epoch 4/34 => Loss 3.767, Loss_clf 0.856, Loss_fe 1.294, Loss_kd 1.314, Train_accy 38.18
2022-09-28 00:07:02,333 [foster.py] => Task 3, Epoch 5/34 => Loss 3.670, Loss_clf 0.854, Loss_fe 1.207, Loss_kd 1.308, Train_accy 39.19
2022-09-28 00:07:05,166 [foster.py] => Task 3, Epoch 6/34 => Loss 3.592, Loss_clf 0.835, Loss_fe 1.152, Loss_kd 1.304, Train_accy 37.84, Test_accy 56.64
2022-09-28 00:07:07,066 [foster.py] => Task 3, Epoch 7/34 => Loss 3.504, Loss_clf 0.790, Loss_fe 1.100, Loss_kd 1.312, Train_accy 41.10
2022-09-28 00:07:09,026 [foster.py] => Task 3, Epoch 8/34 => Loss 3.461, Loss_clf 0.791, Loss_fe 1.059, Loss_kd 1.309, Train_accy 41.22
2022-09-28 00:07:10,940 [foster.py] => Task 3, Epoch 9/34 => Loss 3.396, Loss_clf 0.773, Loss_fe 1.012, Loss_kd 1.309, Train_accy 37.05
2022-09-28 00:07:12,838 [foster.py] => Task 3, Epoch 10/34 => Loss 3.341, Loss_clf 0.756, Loss_fe 0.966, Loss_kd 1.316, Train_accy 45.16
2022-09-28 00:07:15,694 [foster.py] => Task 3, Epoch 11/34 => Loss 3.299, Loss_clf 0.742, Loss_fe 0.941, Loss_kd 1.313, Train_accy 40.77, Test_accy 57.72
2022-09-28 00:07:17,669 [foster.py] => Task 3, Epoch 12/34 => Loss 3.264, Loss_clf 0.734, Loss_fe 0.921, Loss_kd 1.308, Train_accy 39.30
2022-09-28 00:07:19,571 [foster.py] => Task 3, Epoch 13/34 => Loss 3.204, Loss_clf 0.708, Loss_fe 0.881, Loss_kd 1.312, Train_accy 42.00
2022-09-28 00:07:21,528 [foster.py] => Task 3, Epoch 14/34 => Loss 3.178, Loss_clf 0.699, Loss_fe 0.862, Loss_kd 1.314, Train_accy 40.43
2022-09-28 00:07:23,434 [foster.py] => Task 3, Epoch 15/34 => Loss 3.153, Loss_clf 0.688, Loss_fe 0.851, Loss_kd 1.311, Train_accy 41.44
2022-09-28 00:07:26,203 [foster.py] => Task 3, Epoch 16/34 => Loss 3.118, Loss_clf 0.664, Loss_fe 0.834, Loss_kd 1.316, Train_accy 41.67, Test_accy 57.99
2022-09-28 00:07:28,116 [foster.py] => Task 3, Epoch 17/34 => Loss 3.128, Loss_clf 0.679, Loss_fe 0.824, Loss_kd 1.320, Train_accy 44.14
2022-09-28 00:07:30,018 [foster.py] => Task 3, Epoch 18/34 => Loss 3.078, Loss_clf 0.662, Loss_fe 0.802, Loss_kd 1.311, Train_accy 40.77
2022-09-28 00:07:31,942 [foster.py] => Task 3, Epoch 19/34 => Loss 3.055, Loss_clf 0.652, Loss_fe 0.793, Loss_kd 1.308, Train_accy 45.27
2022-09-28 00:07:33,837 [foster.py] => Task 3, Epoch 20/34 => Loss 3.020, Loss_clf 0.637, Loss_fe 0.765, Loss_kd 1.314, Train_accy 44.37
2022-09-28 00:07:36,633 [foster.py] => Task 3, Epoch 21/34 => Loss 3.020, Loss_clf 0.633, Loss_fe 0.773, Loss_kd 1.311, Train_accy 43.36, Test_accy 58.27
2022-09-28 00:07:38,613 [foster.py] => Task 3, Epoch 22/34 => Loss 3.025, Loss_clf 0.630, Loss_fe 0.762, Loss_kd 1.326, Train_accy 44.14
2022-09-28 00:07:40,583 [foster.py] => Task 3, Epoch 23/34 => Loss 2.939, Loss_clf 0.601, Loss_fe 0.726, Loss_kd 1.310, Train_accy 46.06
2022-09-28 00:07:42,545 [foster.py] => Task 3, Epoch 24/34 => Loss 2.975, Loss_clf 0.620, Loss_fe 0.743, Loss_kd 1.310, Train_accy 43.58
2022-09-28 00:07:44,463 [foster.py] => Task 3, Epoch 25/34 => Loss 2.990, Loss_clf 0.627, Loss_fe 0.740, Loss_kd 1.319, Train_accy 44.93
2022-09-28 00:07:47,298 [foster.py] => Task 3, Epoch 26/34 => Loss 2.981, Loss_clf 0.623, Loss_fe 0.742, Loss_kd 1.313, Train_accy 44.37, Test_accy 58.54
2022-09-28 00:07:49,230 [foster.py] => Task 3, Epoch 27/34 => Loss 2.985, Loss_clf 0.617, Loss_fe 0.740, Loss_kd 1.323, Train_accy 44.71
2022-09-28 00:07:51,191 [foster.py] => Task 3, Epoch 28/34 => Loss 2.964, Loss_clf 0.608, Loss_fe 0.733, Loss_kd 1.318, Train_accy 44.59
2022-09-28 00:07:53,134 [foster.py] => Task 3, Epoch 29/34 => Loss 2.940, Loss_clf 0.602, Loss_fe 0.728, Loss_kd 1.309, Train_accy 44.59
2022-09-28 00:07:55,086 [foster.py] => Task 3, Epoch 30/34 => Loss 2.960, Loss_clf 0.614, Loss_fe 0.730, Loss_kd 1.314, Train_accy 45.38
2022-09-28 00:07:57,866 [foster.py] => Task 3, Epoch 31/34 => Loss 2.955, Loss_clf 0.611, Loss_fe 0.725, Loss_kd 1.316, Train_accy 46.40, Test_accy 59.08
2022-09-28 00:07:59,817 [foster.py] => Task 3, Epoch 32/34 => Loss 2.981, Loss_clf 0.613, Loss_fe 0.740, Loss_kd 1.324, Train_accy 44.26
2022-09-28 00:08:01,777 [foster.py] => Task 3, Epoch 33/34 => Loss 2.947, Loss_clf 0.608, Loss_fe 0.721, Loss_kd 1.315, Train_accy 45.50
2022-09-28 00:08:03,731 [foster.py] => Task 3, Epoch 34/34 => Loss 2.950, Loss_clf 0.610, Loss_fe 0.727, Loss_kd 1.311, Train_accy 45.16
2022-09-28 00:08:03,731 [foster.py] => do not weight align teacher!
2022-09-28 00:08:03,732 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 00:08:06,912 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.096,  Train_accy 18.13, Test_accy 47.97
2022-09-28 00:08:09,061 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.012,  Train_accy 18.92
2022-09-28 00:08:11,238 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 1.986,  Train_accy 18.92
2022-09-28 00:08:13,374 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 1.980,  Train_accy 19.03
2022-09-28 00:08:15,548 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.965,  Train_accy 19.03
2022-09-28 00:08:18,474 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.967,  Train_accy 19.48, Test_accy 52.03
2022-09-28 00:08:20,667 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.957,  Train_accy 19.71
2022-09-28 00:08:22,803 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.953,  Train_accy 19.03
2022-09-28 00:08:24,956 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.952,  Train_accy 19.14
2022-09-28 00:08:27,174 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.946,  Train_accy 19.48
2022-09-28 00:08:30,144 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.949,  Train_accy 19.82, Test_accy 51.76
2022-09-28 00:08:32,348 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.940,  Train_accy 20.50
2022-09-28 00:08:34,506 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.934,  Train_accy 20.16
2022-09-28 00:08:36,742 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.944,  Train_accy 20.16
2022-09-28 00:08:38,905 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.946,  Train_accy 19.82
2022-09-28 00:08:41,780 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.939,  Train_accy 19.37, Test_accy 51.22
2022-09-28 00:08:43,929 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.939,  Train_accy 19.48
2022-09-28 00:08:46,074 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.939,  Train_accy 19.03
2022-09-28 00:08:48,192 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.931,  Train_accy 19.71
2022-09-28 00:08:50,351 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.933,  Train_accy 20.05
2022-09-28 00:08:53,290 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.945,  Train_accy 19.59, Test_accy 52.57
2022-09-28 00:08:55,474 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.928,  Train_accy 20.05
2022-09-28 00:08:57,625 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.929,  Train_accy 19.03
2022-09-28 00:08:59,774 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.924,  Train_accy 21.17
2022-09-28 00:09:01,966 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.939,  Train_accy 20.05
2022-09-28 00:09:04,874 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.936,  Train_accy 19.93, Test_accy 52.57
2022-09-28 00:09:04,875 [foster.py] => do not weight align student!
2022-09-28 00:09:05,632 [foster.py] => darknet eval: 
2022-09-28 00:09:05,632 [foster.py] => CNN top1 curve: 52.57
2022-09-28 00:09:05,632 [foster.py] => CNN top5 curve: 90.79
2022-09-28 00:09:05,632 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 00:09:14,088 [foster.py] => Exemplar size: 320
2022-09-28 00:09:14,088 [trainer.py] => CNN: {'total': 59.08, 'old': 62.99, 'new': 39.34, 'base': 80.79, 'compound': 39.06}
2022-09-28 00:09:14,088 [trainer.py] => CNN top1 curve: [90.4, 76.61, 65.58, 59.08]
2022-09-28 00:09:14,088 [trainer.py] => CNN base curve: [90.4, 88.14, 80.79, 80.79]
2022-09-28 00:09:14,088 [trainer.py] => CNN old curve: [90.4, 88.14, 73.79, 62.99]
2022-09-28 00:09:14,089 [trainer.py] => CNN new curve: [0, 47.89, 31.67, 39.34]
2022-09-28 00:09:14,089 [trainer.py] => CNN compound curve: [0, 47.89, 45.04, 39.06]
2022-09-28 00:09:14,089 [trainer.py] => NME: {'total': 61.25, 'old': 63.31, 'new': 50.82, 'base': 70.06, 'compound': 53.12}
2022-09-28 00:09:14,089 [trainer.py] => NME top1 curve: [89.27, 83.47, 72.08, 61.25]
2022-09-28 00:09:14,089 [trainer.py] => NME base curve: [89.27, 86.44, 74.58, 70.06]
2022-09-28 00:09:14,089 [trainer.py] => NME old curve: [89.27, 86.44, 74.6, 63.31]
2022-09-28 00:09:14,089 [trainer.py] => NME new curve: [0, 76.06, 61.67, 50.82]
2022-09-28 00:09:14,089 [trainer.py] => NME compound curve: [0, 76.06, 68.7, 53.12]
2022-09-28 00:09:14,316 [foster.py] => Learning on 16-19
2022-09-28 00:09:14,317 [foster.py] => All params: 22390454
2022-09-28 00:09:14,317 [foster.py] => Trainable params: 11205734
2022-09-28 00:09:14,337 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 00:09:17,267 [foster.py] => Task 4, Epoch 1/34 => Loss 6.580, Loss_clf 2.114, Loss_fe 2.501, Loss_kd 1.655, Train_accy 42.83, Test_accy 49.53
2022-09-28 00:09:19,284 [foster.py] => Task 4, Epoch 2/34 => Loss 4.620, Loss_clf 0.959, Loss_fe 1.698, Loss_kd 1.653, Train_accy 41.03
2022-09-28 00:09:21,326 [foster.py] => Task 4, Epoch 3/34 => Loss 4.302, Loss_clf 0.869, Loss_fe 1.479, Loss_kd 1.647, Train_accy 47.89
2022-09-28 00:09:23,386 [foster.py] => Task 4, Epoch 4/34 => Loss 4.139, Loss_clf 0.838, Loss_fe 1.347, Loss_kd 1.645, Train_accy 45.78
2022-09-28 00:09:25,381 [foster.py] => Task 4, Epoch 5/34 => Loss 3.990, Loss_clf 0.791, Loss_fe 1.240, Loss_kd 1.650, Train_accy 47.15
2022-09-28 00:09:28,370 [foster.py] => Task 4, Epoch 6/34 => Loss 3.902, Loss_clf 0.781, Loss_fe 1.179, Loss_kd 1.636, Train_accy 46.41, Test_accy 53.04
2022-09-28 00:09:30,405 [foster.py] => Task 4, Epoch 7/34 => Loss 3.823, Loss_clf 0.766, Loss_fe 1.102, Loss_kd 1.647, Train_accy 49.68
2022-09-28 00:09:32,461 [foster.py] => Task 4, Epoch 8/34 => Loss 3.742, Loss_clf 0.746, Loss_fe 1.052, Loss_kd 1.637, Train_accy 45.57
2022-09-28 00:09:34,557 [foster.py] => Task 4, Epoch 9/34 => Loss 3.739, Loss_clf 0.758, Loss_fe 1.026, Loss_kd 1.647, Train_accy 49.16
2022-09-28 00:09:36,562 [foster.py] => Task 4, Epoch 10/34 => Loss 3.669, Loss_clf 0.733, Loss_fe 0.980, Loss_kd 1.647, Train_accy 48.63
2022-09-28 00:09:39,490 [foster.py] => Task 4, Epoch 11/34 => Loss 3.607, Loss_clf 0.709, Loss_fe 0.949, Loss_kd 1.641, Train_accy 50.84, Test_accy 55.14
2022-09-28 00:09:41,515 [foster.py] => Task 4, Epoch 12/34 => Loss 3.546, Loss_clf 0.683, Loss_fe 0.911, Loss_kd 1.644, Train_accy 49.68
2022-09-28 00:09:43,512 [foster.py] => Task 4, Epoch 13/34 => Loss 3.542, Loss_clf 0.697, Loss_fe 0.890, Loss_kd 1.647, Train_accy 47.78
2022-09-28 00:09:45,553 [foster.py] => Task 4, Epoch 14/34 => Loss 3.505, Loss_clf 0.685, Loss_fe 0.863, Loss_kd 1.648, Train_accy 49.47
2022-09-28 00:09:47,535 [foster.py] => Task 4, Epoch 15/34 => Loss 3.500, Loss_clf 0.679, Loss_fe 0.856, Loss_kd 1.656, Train_accy 50.84
2022-09-28 00:09:50,475 [foster.py] => Task 4, Epoch 16/34 => Loss 3.475, Loss_clf 0.679, Loss_fe 0.843, Loss_kd 1.644, Train_accy 51.79, Test_accy 56.78
2022-09-28 00:09:52,512 [foster.py] => Task 4, Epoch 17/34 => Loss 3.463, Loss_clf 0.677, Loss_fe 0.831, Loss_kd 1.646, Train_accy 49.37
2022-09-28 00:09:54,519 [foster.py] => Task 4, Epoch 18/34 => Loss 3.412, Loss_clf 0.649, Loss_fe 0.799, Loss_kd 1.654, Train_accy 49.89
2022-09-28 00:09:56,613 [foster.py] => Task 4, Epoch 19/34 => Loss 3.398, Loss_clf 0.646, Loss_fe 0.792, Loss_kd 1.650, Train_accy 51.69
2022-09-28 00:09:58,670 [foster.py] => Task 4, Epoch 20/34 => Loss 3.398, Loss_clf 0.639, Loss_fe 0.788, Loss_kd 1.660, Train_accy 51.37
2022-09-28 00:10:01,631 [foster.py] => Task 4, Epoch 21/34 => Loss 3.368, Loss_clf 0.638, Loss_fe 0.775, Loss_kd 1.647, Train_accy 50.95, Test_accy 57.01
2022-09-28 00:10:03,647 [foster.py] => Task 4, Epoch 22/34 => Loss 3.370, Loss_clf 0.638, Loss_fe 0.768, Loss_kd 1.654, Train_accy 50.74
2022-09-28 00:10:05,698 [foster.py] => Task 4, Epoch 23/34 => Loss 3.328, Loss_clf 0.619, Loss_fe 0.745, Loss_kd 1.654, Train_accy 51.69
2022-09-28 00:10:07,721 [foster.py] => Task 4, Epoch 24/34 => Loss 3.329, Loss_clf 0.630, Loss_fe 0.750, Loss_kd 1.641, Train_accy 50.11
2022-09-28 00:10:09,754 [foster.py] => Task 4, Epoch 25/34 => Loss 3.347, Loss_clf 0.631, Loss_fe 0.755, Loss_kd 1.652, Train_accy 51.05
2022-09-28 00:10:12,673 [foster.py] => Task 4, Epoch 26/34 => Loss 3.321, Loss_clf 0.628, Loss_fe 0.733, Loss_kd 1.650, Train_accy 51.69, Test_accy 57.24
2022-09-28 00:10:14,748 [foster.py] => Task 4, Epoch 27/34 => Loss 3.299, Loss_clf 0.606, Loss_fe 0.733, Loss_kd 1.651, Train_accy 50.84
2022-09-28 00:10:16,752 [foster.py] => Task 4, Epoch 28/34 => Loss 3.325, Loss_clf 0.613, Loss_fe 0.740, Loss_kd 1.661, Train_accy 51.79
2022-09-28 00:10:18,781 [foster.py] => Task 4, Epoch 29/34 => Loss 3.313, Loss_clf 0.616, Loss_fe 0.738, Loss_kd 1.649, Train_accy 50.53
2022-09-28 00:10:20,789 [foster.py] => Task 4, Epoch 30/34 => Loss 3.309, Loss_clf 0.612, Loss_fe 0.738, Loss_kd 1.650, Train_accy 50.74
2022-09-28 00:10:23,734 [foster.py] => Task 4, Epoch 31/34 => Loss 3.308, Loss_clf 0.617, Loss_fe 0.727, Loss_kd 1.653, Train_accy 51.48, Test_accy 57.94
2022-09-28 00:10:25,730 [foster.py] => Task 4, Epoch 32/34 => Loss 3.299, Loss_clf 0.605, Loss_fe 0.730, Loss_kd 1.654, Train_accy 52.95
2022-09-28 00:10:27,732 [foster.py] => Task 4, Epoch 33/34 => Loss 3.324, Loss_clf 0.621, Loss_fe 0.751, Loss_kd 1.643, Train_accy 51.37
2022-09-28 00:10:29,767 [foster.py] => Task 4, Epoch 34/34 => Loss 3.299, Loss_clf 0.612, Loss_fe 0.737, Loss_kd 1.642, Train_accy 51.05
2022-09-28 00:10:29,768 [foster.py] => do not weight align teacher!
2022-09-28 00:10:29,768 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 00:10:33,120 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.324,  Train_accy 18.67, Test_accy 45.33
2022-09-28 00:10:35,382 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.269,  Train_accy 18.14
2022-09-28 00:10:37,624 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.237,  Train_accy 18.99
2022-09-28 00:10:39,882 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.229,  Train_accy 19.09
2022-09-28 00:10:42,178 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.223,  Train_accy 19.51
2022-09-28 00:10:45,218 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.217,  Train_accy 19.73, Test_accy 46.73
2022-09-28 00:10:47,472 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.204,  Train_accy 19.51
2022-09-28 00:10:49,710 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.197,  Train_accy 20.15
2022-09-28 00:10:52,030 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.183,  Train_accy 20.15
2022-09-28 00:10:54,331 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.188,  Train_accy 20.04
2022-09-28 00:10:57,418 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.192,  Train_accy 20.25, Test_accy 46.50
2022-09-28 00:10:59,681 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.192,  Train_accy 21.41
2022-09-28 00:11:02,035 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.181,  Train_accy 19.83
2022-09-28 00:11:04,272 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.184,  Train_accy 20.78
2022-09-28 00:11:06,566 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.179,  Train_accy 20.89
2022-09-28 00:11:09,609 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.178,  Train_accy 19.94, Test_accy 46.26
2022-09-28 00:11:11,860 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.169,  Train_accy 20.78
2022-09-28 00:11:14,108 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.172,  Train_accy 21.10
2022-09-28 00:11:16,358 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.164,  Train_accy 21.10
2022-09-28 00:11:18,643 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.171,  Train_accy 21.10
2022-09-28 00:11:21,751 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.173,  Train_accy 20.99, Test_accy 47.90
2022-09-28 00:11:23,999 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.175,  Train_accy 20.57
2022-09-28 00:11:26,297 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.170,  Train_accy 21.20
2022-09-28 00:11:28,575 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.170,  Train_accy 20.46
2022-09-28 00:11:30,817 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.173,  Train_accy 21.52
2022-09-28 00:11:33,887 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.168,  Train_accy 20.99, Test_accy 47.90
2022-09-28 00:11:33,887 [foster.py] => do not weight align student!
2022-09-28 00:11:34,695 [foster.py] => darknet eval: 
2022-09-28 00:11:34,695 [foster.py] => CNN top1 curve: 47.9
2022-09-28 00:11:34,695 [foster.py] => CNN top5 curve: 88.08
2022-09-28 00:11:34,696 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 00:11:44,282 [foster.py] => Exemplar size: 380
2022-09-28 00:11:44,282 [trainer.py] => CNN: {'total': 57.48, 'old': 57.72, 'new': 55.93, 'base': 78.53, 'compound': 42.63}
2022-09-28 00:11:44,282 [trainer.py] => CNN top1 curve: [90.4, 76.61, 65.58, 59.08, 57.48]
2022-09-28 00:11:44,282 [trainer.py] => CNN base curve: [90.4, 88.14, 80.79, 80.79, 78.53]
2022-09-28 00:11:44,282 [trainer.py] => CNN old curve: [90.4, 88.14, 73.79, 62.99, 57.72]
2022-09-28 00:11:44,282 [trainer.py] => CNN new curve: [0, 47.89, 31.67, 39.34, 55.93]
2022-09-28 00:11:44,282 [trainer.py] => CNN compound curve: [0, 47.89, 45.04, 39.06, 42.63]
2022-09-28 00:11:44,283 [trainer.py] => NME: {'total': 61.68, 'old': 60.7, 'new': 67.8, 'base': 71.19, 'compound': 54.98}
2022-09-28 00:11:44,283 [trainer.py] => NME top1 curve: [89.27, 83.47, 72.08, 61.25, 61.68]
2022-09-28 00:11:44,283 [trainer.py] => NME base curve: [89.27, 86.44, 74.58, 70.06, 71.19]
2022-09-28 00:11:44,283 [trainer.py] => NME old curve: [89.27, 86.44, 74.6, 63.31, 60.7]
2022-09-28 00:11:44,283 [trainer.py] => NME new curve: [0, 76.06, 61.67, 50.82, 67.8]
2022-09-28 00:11:44,283 [trainer.py] => NME compound curve: [0, 76.06, 68.7, 53.12, 54.98]
2022-09-28 00:11:44,511 [foster.py] => Learning on 19-22
2022-09-28 00:11:44,511 [foster.py] => All params: 22396607
2022-09-28 00:11:44,511 [foster.py] => Trainable params: 11210348
2022-09-28 00:11:44,532 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 00:11:47,592 [foster.py] => Task 5, Epoch 1/34 => Loss 6.960, Loss_clf 2.101, Loss_fe 2.614, Loss_kd 1.939, Train_accy 39.39, Test_accy 46.73
2022-09-28 00:11:49,695 [foster.py] => Task 5, Epoch 2/34 => Loss 5.320, Loss_clf 1.136, Loss_fe 1.927, Loss_kd 1.949, Train_accy 36.06
2022-09-28 00:11:51,812 [foster.py] => Task 5, Epoch 3/34 => Loss 5.016, Loss_clf 1.053, Loss_fe 1.708, Loss_kd 1.947, Train_accy 40.30
2022-09-28 00:11:53,916 [foster.py] => Task 5, Epoch 4/34 => Loss 4.826, Loss_clf 1.012, Loss_fe 1.576, Loss_kd 1.932, Train_accy 40.71
2022-09-28 00:11:56,052 [foster.py] => Task 5, Epoch 5/34 => Loss 4.710, Loss_clf 0.973, Loss_fe 1.491, Loss_kd 1.940, Train_accy 41.11
2022-09-28 00:11:59,126 [foster.py] => Task 5, Epoch 6/34 => Loss 4.598, Loss_clf 0.958, Loss_fe 1.395, Loss_kd 1.939, Train_accy 41.52, Test_accy 50.89
2022-09-28 00:12:01,184 [foster.py] => Task 5, Epoch 7/34 => Loss 4.504, Loss_clf 0.926, Loss_fe 1.326, Loss_kd 1.944, Train_accy 42.53
2022-09-28 00:12:03,287 [foster.py] => Task 5, Epoch 8/34 => Loss 4.462, Loss_clf 0.913, Loss_fe 1.296, Loss_kd 1.945, Train_accy 45.56
2022-09-28 00:12:05,365 [foster.py] => Task 5, Epoch 9/34 => Loss 4.346, Loss_clf 0.879, Loss_fe 1.221, Loss_kd 1.939, Train_accy 42.02
2022-09-28 00:12:07,436 [foster.py] => Task 5, Epoch 10/34 => Loss 4.320, Loss_clf 0.870, Loss_fe 1.191, Loss_kd 1.951, Train_accy 45.56
2022-09-28 00:12:10,493 [foster.py] => Task 5, Epoch 11/34 => Loss 4.251, Loss_clf 0.856, Loss_fe 1.142, Loss_kd 1.946, Train_accy 44.85, Test_accy 50.69
2022-09-28 00:12:12,627 [foster.py] => Task 5, Epoch 12/34 => Loss 4.212, Loss_clf 0.839, Loss_fe 1.118, Loss_kd 1.947, Train_accy 45.15
2022-09-28 00:12:14,725 [foster.py] => Task 5, Epoch 13/34 => Loss 4.152, Loss_clf 0.824, Loss_fe 1.079, Loss_kd 1.943, Train_accy 45.25
2022-09-28 00:12:16,829 [foster.py] => Task 5, Epoch 14/34 => Loss 4.117, Loss_clf 0.807, Loss_fe 1.055, Loss_kd 1.948, Train_accy 46.46
2022-09-28 00:12:18,873 [foster.py] => Task 5, Epoch 15/34 => Loss 4.098, Loss_clf 0.800, Loss_fe 1.042, Loss_kd 1.948, Train_accy 46.26
2022-09-28 00:12:21,986 [foster.py] => Task 5, Epoch 16/34 => Loss 4.062, Loss_clf 0.799, Loss_fe 1.008, Loss_kd 1.947, Train_accy 46.26, Test_accy 51.49
2022-09-28 00:12:24,074 [foster.py] => Task 5, Epoch 17/34 => Loss 4.016, Loss_clf 0.782, Loss_fe 0.977, Loss_kd 1.949, Train_accy 46.87
2022-09-28 00:12:26,167 [foster.py] => Task 5, Epoch 18/34 => Loss 4.020, Loss_clf 0.778, Loss_fe 0.981, Loss_kd 1.952, Train_accy 48.28
2022-09-28 00:12:28,255 [foster.py] => Task 5, Epoch 19/34 => Loss 3.982, Loss_clf 0.774, Loss_fe 0.950, Loss_kd 1.950, Train_accy 46.97
2022-09-28 00:12:30,354 [foster.py] => Task 5, Epoch 20/34 => Loss 3.974, Loss_clf 0.766, Loss_fe 0.958, Loss_kd 1.943, Train_accy 46.77
2022-09-28 00:12:33,396 [foster.py] => Task 5, Epoch 21/34 => Loss 3.944, Loss_clf 0.757, Loss_fe 0.932, Loss_kd 1.948, Train_accy 48.08, Test_accy 51.88
2022-09-28 00:12:35,503 [foster.py] => Task 5, Epoch 22/34 => Loss 3.989, Loss_clf 0.776, Loss_fe 0.951, Loss_kd 1.954, Train_accy 46.16
2022-09-28 00:12:37,591 [foster.py] => Task 5, Epoch 23/34 => Loss 3.924, Loss_clf 0.746, Loss_fe 0.915, Loss_kd 1.954, Train_accy 47.47
2022-09-28 00:12:39,696 [foster.py] => Task 5, Epoch 24/34 => Loss 3.908, Loss_clf 0.736, Loss_fe 0.914, Loss_kd 1.951, Train_accy 48.59
2022-09-28 00:12:41,764 [foster.py] => Task 5, Epoch 25/34 => Loss 3.889, Loss_clf 0.735, Loss_fe 0.896, Loss_kd 1.950, Train_accy 48.48
2022-09-28 00:12:44,858 [foster.py] => Task 5, Epoch 26/34 => Loss 3.874, Loss_clf 0.724, Loss_fe 0.891, Loss_kd 1.951, Train_accy 48.18, Test_accy 52.28
2022-09-28 00:12:46,913 [foster.py] => Task 5, Epoch 27/34 => Loss 3.889, Loss_clf 0.741, Loss_fe 0.898, Loss_kd 1.943, Train_accy 47.98
2022-09-28 00:12:48,985 [foster.py] => Task 5, Epoch 28/34 => Loss 3.884, Loss_clf 0.723, Loss_fe 0.890, Loss_kd 1.961, Train_accy 49.09
2022-09-28 00:12:51,044 [foster.py] => Task 5, Epoch 29/34 => Loss 3.873, Loss_clf 0.721, Loss_fe 0.897, Loss_kd 1.947, Train_accy 48.79
2022-09-28 00:12:53,154 [foster.py] => Task 5, Epoch 30/34 => Loss 3.870, Loss_clf 0.722, Loss_fe 0.890, Loss_kd 1.950, Train_accy 48.99
2022-09-28 00:12:56,211 [foster.py] => Task 5, Epoch 31/34 => Loss 3.853, Loss_clf 0.718, Loss_fe 0.871, Loss_kd 1.955, Train_accy 49.39, Test_accy 52.28
2022-09-28 00:12:58,339 [foster.py] => Task 5, Epoch 32/34 => Loss 3.864, Loss_clf 0.722, Loss_fe 0.877, Loss_kd 1.956, Train_accy 49.60
2022-09-28 00:13:00,437 [foster.py] => Task 5, Epoch 33/34 => Loss 3.860, Loss_clf 0.721, Loss_fe 0.882, Loss_kd 1.949, Train_accy 49.09
2022-09-28 00:13:02,534 [foster.py] => Task 5, Epoch 34/34 => Loss 3.874, Loss_clf 0.730, Loss_fe 0.886, Loss_kd 1.951, Train_accy 48.69
2022-09-28 00:13:02,535 [foster.py] => do not weight align teacher!
2022-09-28 00:13:02,535 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 00:13:06,016 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.446,  Train_accy 19.09, Test_accy 41.19
2022-09-28 00:13:08,345 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.430,  Train_accy 20.10
2022-09-28 00:13:10,660 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.429,  Train_accy 20.10
2022-09-28 00:13:12,994 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.418,  Train_accy 20.51
2022-09-28 00:13:15,328 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.415,  Train_accy 20.40
2022-09-28 00:13:18,523 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.404,  Train_accy 20.20, Test_accy 42.18
2022-09-28 00:13:20,884 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.409,  Train_accy 21.01
2022-09-28 00:13:23,233 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.407,  Train_accy 21.41
2022-09-28 00:13:25,556 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.407,  Train_accy 19.60
2022-09-28 00:13:27,868 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.404,  Train_accy 21.31
2022-09-28 00:13:31,056 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.400,  Train_accy 22.02, Test_accy 42.77
2022-09-28 00:13:33,417 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.399,  Train_accy 20.81
2022-09-28 00:13:35,771 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.389,  Train_accy 21.62
2022-09-28 00:13:38,103 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.394,  Train_accy 21.31
2022-09-28 00:13:40,455 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.396,  Train_accy 21.92
2022-09-28 00:13:43,689 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.386,  Train_accy 21.41, Test_accy 41.98
2022-09-28 00:13:46,018 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.388,  Train_accy 21.21
2022-09-28 00:13:48,422 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.392,  Train_accy 21.92
2022-09-28 00:13:50,737 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.385,  Train_accy 20.10
2022-09-28 00:13:53,082 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.392,  Train_accy 22.02
2022-09-28 00:13:56,279 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.396,  Train_accy 21.41, Test_accy 42.18
2022-09-28 00:13:58,656 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.386,  Train_accy 21.82
2022-09-28 00:14:00,980 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.384,  Train_accy 21.72
2022-09-28 00:14:03,287 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.394,  Train_accy 21.92
2022-09-28 00:14:05,588 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.393,  Train_accy 21.41
2022-09-28 00:14:08,755 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.388,  Train_accy 21.11, Test_accy 42.38
2022-09-28 00:14:08,756 [foster.py] => do not weight align student!
2022-09-28 00:14:09,598 [foster.py] => darknet eval: 
2022-09-28 00:14:09,598 [foster.py] => CNN top1 curve: 42.38
2022-09-28 00:14:09,598 [foster.py] => CNN top5 curve: 82.57
2022-09-28 00:14:09,598 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 00:14:20,344 [foster.py] => Exemplar size: 440
2022-09-28 00:14:20,344 [trainer.py] => CNN: {'total': 52.28, 'old': 54.21, 'new': 41.56, 'base': 71.75, 'compound': 41.77}
2022-09-28 00:14:20,344 [trainer.py] => CNN top1 curve: [90.4, 76.61, 65.58, 59.08, 57.48, 52.28]
2022-09-28 00:14:20,344 [trainer.py] => CNN base curve: [90.4, 88.14, 80.79, 80.79, 78.53, 71.75]
2022-09-28 00:14:20,344 [trainer.py] => CNN old curve: [90.4, 88.14, 73.79, 62.99, 57.72, 54.21]
2022-09-28 00:14:20,344 [trainer.py] => CNN new curve: [0, 47.89, 31.67, 39.34, 55.93, 41.56]
2022-09-28 00:14:20,344 [trainer.py] => CNN compound curve: [0, 47.89, 45.04, 39.06, 42.63, 41.77]
2022-09-28 00:14:20,344 [trainer.py] => NME: {'total': 57.03, 'old': 57.24, 'new': 55.84, 'base': 68.93, 'compound': 50.61}
2022-09-28 00:14:20,344 [trainer.py] => NME top1 curve: [89.27, 83.47, 72.08, 61.25, 61.68, 57.03]
2022-09-28 00:14:20,344 [trainer.py] => NME base curve: [89.27, 86.44, 74.58, 70.06, 71.19, 68.93]
2022-09-28 00:14:20,344 [trainer.py] => NME old curve: [89.27, 86.44, 74.6, 63.31, 60.7, 57.24]
2022-09-28 00:14:20,344 [trainer.py] => NME new curve: [0, 76.06, 61.67, 50.82, 67.8, 55.84]
2022-09-28 00:14:20,344 [trainer.py] => NME compound curve: [0, 76.06, 68.7, 53.12, 54.98, 50.61]
2022-09-28 00:14:20,346 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 00:14:20,346 [trainer.py] => prefix: cil
2022-09-28 00:14:20,346 [trainer.py] => dataset: CFEE
2022-09-28 00:14:20,346 [trainer.py] => memory_size: 2000
2022-09-28 00:14:20,346 [trainer.py] => memory_per_class: 20
2022-09-28 00:14:20,346 [trainer.py] => fixed_memory: True
2022-09-28 00:14:20,346 [trainer.py] => shuffle: True
2022-09-28 00:14:20,346 [trainer.py] => init_cls: 7
2022-09-28 00:14:20,346 [trainer.py] => increment: 3
2022-09-28 00:14:20,346 [trainer.py] => model_name: foster
2022-09-28 00:14:20,346 [trainer.py] => convnet_type: resnet18
2022-09-28 00:14:20,346 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 00:14:20,346 [trainer.py] => seed: 1993
2022-09-28 00:14:20,346 [trainer.py] => beta1: 0.96
2022-09-28 00:14:20,346 [trainer.py] => beta2: 0.97
2022-09-28 00:14:20,346 [trainer.py] => oofc: ft
2022-09-28 00:14:20,346 [trainer.py] => is_teacher_wa: False
2022-09-28 00:14:20,346 [trainer.py] => is_student_wa: False
2022-09-28 00:14:20,346 [trainer.py] => lambda_okd: 1
2022-09-28 00:14:20,346 [trainer.py] => wa_value: 1
2022-09-28 00:14:20,346 [trainer.py] => init_epochs: 40
2022-09-28 00:14:20,346 [trainer.py] => init_lr: 0.01
2022-09-28 00:14:20,346 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 00:14:20,346 [trainer.py] => boosting_epochs: 34
2022-09-28 00:14:20,346 [trainer.py] => compression_epochs: 26
2022-09-28 00:14:20,346 [trainer.py] => lr: 0.001
2022-09-28 00:14:20,346 [trainer.py] => batch_size: 32
2022-09-28 00:14:20,347 [trainer.py] => weight_decay: 0.0005
2022-09-28 00:14:20,347 [trainer.py] => num_workers: 8
2022-09-28 00:14:20,347 [trainer.py] => T: 2
2022-09-28 00:14:20,347 [trainer.py] => nb_runs: 3
2022-09-28 00:14:20,347 [trainer.py] => fold: 10
2022-09-28 00:14:20,347 [data.py] => ========== Fold:1 ==========
2022-09-28 00:14:20,352 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 13, 17, 15, 9, 11, 20, 18, 12, 14, 7, 10, 19, 21, 16, 8]
2022-09-28 00:14:20,561 [foster.py] => Learning on 0-7
2022-09-28 00:14:20,561 [foster.py] => All params: 11183694
2022-09-28 00:14:20,562 [foster.py] => Trainable params: 11183694
2022-09-28 00:14:22,946 [foster.py] => Task 0, Epoch 1/40 => Loss 1.331, Train_accy 51.54
2022-09-28 00:14:25,967 [foster.py] => Task 0, Epoch 2/40 => Loss 0.525, Train_accy 82.04, Test_accy 84.46
2022-09-28 00:14:28,976 [foster.py] => Task 0, Epoch 3/40 => Loss 0.347, Train_accy 87.59, Test_accy 83.11
2022-09-28 00:14:31,966 [foster.py] => Task 0, Epoch 4/40 => Loss 0.282, Train_accy 90.13, Test_accy 86.49
2022-09-28 00:14:34,916 [foster.py] => Task 0, Epoch 5/40 => Loss 0.227, Train_accy 92.25, Test_accy 83.78
2022-09-28 00:14:37,318 [foster.py] => Task 0, Epoch 6/40 => Loss 0.185, Train_accy 93.69
2022-09-28 00:14:40,346 [foster.py] => Task 0, Epoch 7/40 => Loss 0.145, Train_accy 95.68, Test_accy 89.19
2022-09-28 00:14:43,318 [foster.py] => Task 0, Epoch 8/40 => Loss 0.129, Train_accy 95.89, Test_accy 87.84
2022-09-28 00:14:46,393 [foster.py] => Task 0, Epoch 9/40 => Loss 0.110, Train_accy 96.44, Test_accy 88.51
2022-09-28 00:14:49,462 [foster.py] => Task 0, Epoch 10/40 => Loss 0.087, Train_accy 97.46, Test_accy 87.16
2022-09-28 00:14:51,880 [foster.py] => Task 0, Epoch 11/40 => Loss 0.082, Train_accy 97.53
2022-09-28 00:14:54,908 [foster.py] => Task 0, Epoch 12/40 => Loss 0.080, Train_accy 97.88, Test_accy 87.16
2022-09-28 00:14:57,928 [foster.py] => Task 0, Epoch 13/40 => Loss 0.071, Train_accy 98.08, Test_accy 85.81
2022-09-28 00:15:00,910 [foster.py] => Task 0, Epoch 14/40 => Loss 0.058, Train_accy 98.08, Test_accy 86.49
2022-09-28 00:15:03,900 [foster.py] => Task 0, Epoch 15/40 => Loss 0.045, Train_accy 98.77, Test_accy 87.84
2022-09-28 00:15:06,306 [foster.py] => Task 0, Epoch 16/40 => Loss 0.047, Train_accy 98.49
2022-09-28 00:15:09,290 [foster.py] => Task 0, Epoch 17/40 => Loss 0.038, Train_accy 99.04, Test_accy 87.84
2022-09-28 00:15:12,281 [foster.py] => Task 0, Epoch 18/40 => Loss 0.035, Train_accy 99.18, Test_accy 88.51
2022-09-28 00:15:15,324 [foster.py] => Task 0, Epoch 19/40 => Loss 0.028, Train_accy 99.59, Test_accy 85.14
2022-09-28 00:15:18,277 [foster.py] => Task 0, Epoch 20/40 => Loss 0.027, Train_accy 99.31, Test_accy 87.84
2022-09-28 00:15:20,677 [foster.py] => Task 0, Epoch 21/40 => Loss 0.027, Train_accy 99.59
2022-09-28 00:15:23,648 [foster.py] => Task 0, Epoch 22/40 => Loss 0.022, Train_accy 99.66, Test_accy 87.16
2022-09-28 00:15:26,617 [foster.py] => Task 0, Epoch 23/40 => Loss 0.019, Train_accy 99.73, Test_accy 87.84
2022-09-28 00:15:29,598 [foster.py] => Task 0, Epoch 24/40 => Loss 0.023, Train_accy 99.45, Test_accy 88.51
2022-09-28 00:15:32,573 [foster.py] => Task 0, Epoch 25/40 => Loss 0.015, Train_accy 99.93, Test_accy 87.84
2022-09-28 00:15:34,979 [foster.py] => Task 0, Epoch 26/40 => Loss 0.017, Train_accy 99.73
2022-09-28 00:15:37,978 [foster.py] => Task 0, Epoch 27/40 => Loss 0.019, Train_accy 99.73, Test_accy 87.16
2022-09-28 00:15:41,034 [foster.py] => Task 0, Epoch 28/40 => Loss 0.017, Train_accy 99.79, Test_accy 87.84
2022-09-28 00:15:44,077 [foster.py] => Task 0, Epoch 29/40 => Loss 0.015, Train_accy 99.79, Test_accy 87.84
2022-09-28 00:15:47,139 [foster.py] => Task 0, Epoch 30/40 => Loss 0.012, Train_accy 99.93, Test_accy 87.84
2022-09-28 00:15:49,524 [foster.py] => Task 0, Epoch 31/40 => Loss 0.015, Train_accy 99.93
2022-09-28 00:15:52,512 [foster.py] => Task 0, Epoch 32/40 => Loss 0.014, Train_accy 99.86, Test_accy 87.84
2022-09-28 00:15:55,547 [foster.py] => Task 0, Epoch 33/40 => Loss 0.018, Train_accy 99.66, Test_accy 88.51
2022-09-28 00:15:58,538 [foster.py] => Task 0, Epoch 34/40 => Loss 0.012, Train_accy 99.86, Test_accy 88.51
2022-09-28 00:16:01,548 [foster.py] => Task 0, Epoch 35/40 => Loss 0.013, Train_accy 100.00, Test_accy 88.51
2022-09-28 00:16:03,895 [foster.py] => Task 0, Epoch 36/40 => Loss 0.016, Train_accy 99.79
2022-09-28 00:16:06,891 [foster.py] => Task 0, Epoch 37/40 => Loss 0.012, Train_accy 99.93, Test_accy 87.84
2022-09-28 00:16:09,888 [foster.py] => Task 0, Epoch 38/40 => Loss 0.014, Train_accy 99.73, Test_accy 87.84
2022-09-28 00:16:12,855 [foster.py] => Task 0, Epoch 39/40 => Loss 0.015, Train_accy 99.79, Test_accy 88.51
2022-09-28 00:16:15,884 [foster.py] => Task 0, Epoch 40/40 => Loss 0.010, Train_accy 99.93, Test_accy 87.16
2022-09-28 00:16:15,884 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 00:16:22,757 [foster.py] => Exemplar size: 140
2022-09-28 00:16:22,757 [trainer.py] => CNN: {'total': 87.16, 'old': 87.16, 'new': 0, 'base': 87.16, 'compound': 0}
2022-09-28 00:16:22,757 [trainer.py] => CNN top1 curve: [87.16]
2022-09-28 00:16:22,757 [trainer.py] => CNN base curve: [87.16]
2022-09-28 00:16:22,757 [trainer.py] => CNN old curve: [87.16]
2022-09-28 00:16:22,757 [trainer.py] => CNN new curve: [0]
2022-09-28 00:16:22,757 [trainer.py] => CNN compound curve: [0]
2022-09-28 00:16:22,757 [trainer.py] => NME: {'total': 88.51, 'old': 88.51, 'new': 0, 'base': 88.51, 'compound': 0}
2022-09-28 00:16:22,757 [trainer.py] => NME top1 curve: [88.51]
2022-09-28 00:16:22,757 [trainer.py] => NME base curve: [88.51]
2022-09-28 00:16:22,757 [trainer.py] => NME old curve: [88.51]
2022-09-28 00:16:22,757 [trainer.py] => NME new curve: [0]
2022-09-28 00:16:22,757 [trainer.py] => NME compound curve: [0]
2022-09-28 00:16:22,984 [foster.py] => Learning on 7-10
2022-09-28 00:16:22,985 [foster.py] => All params: 22371995
2022-09-28 00:16:22,985 [foster.py] => Trainable params: 11191892
2022-09-28 00:16:23,005 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 00:16:25,498 [foster.py] => Task 1, Epoch 1/34 => Loss 4.860, Loss_clf 2.165, Loss_fe 1.987, Loss_kd 0.496, Train_accy 40.32, Test_accy 66.22
2022-09-28 00:16:27,224 [foster.py] => Task 1, Epoch 2/34 => Loss 2.458, Loss_clf 0.577, Loss_fe 1.160, Loss_kd 0.504, Train_accy 79.71
2022-09-28 00:16:28,961 [foster.py] => Task 1, Epoch 3/34 => Loss 1.980, Loss_clf 0.383, Loss_fe 0.902, Loss_kd 0.487, Train_accy 55.17
2022-09-28 00:16:30,659 [foster.py] => Task 1, Epoch 4/34 => Loss 1.809, Loss_clf 0.337, Loss_fe 0.779, Loss_kd 0.484, Train_accy 58.62
2022-09-28 00:16:32,405 [foster.py] => Task 1, Epoch 5/34 => Loss 1.693, Loss_clf 0.311, Loss_fe 0.692, Loss_kd 0.483, Train_accy 57.96
2022-09-28 00:16:34,853 [foster.py] => Task 1, Epoch 6/34 => Loss 1.593, Loss_clf 0.289, Loss_fe 0.624, Loss_kd 0.476, Train_accy 58.49, Test_accy 70.27
2022-09-28 00:16:36,615 [foster.py] => Task 1, Epoch 7/34 => Loss 1.547, Loss_clf 0.291, Loss_fe 0.574, Loss_kd 0.477, Train_accy 60.34
2022-09-28 00:16:38,307 [foster.py] => Task 1, Epoch 8/34 => Loss 1.520, Loss_clf 0.280, Loss_fe 0.551, Loss_kd 0.483, Train_accy 61.54
2022-09-28 00:16:40,052 [foster.py] => Task 1, Epoch 9/34 => Loss 1.470, Loss_clf 0.274, Loss_fe 0.510, Loss_kd 0.480, Train_accy 58.09
2022-09-28 00:16:41,795 [foster.py] => Task 1, Epoch 10/34 => Loss 1.423, Loss_clf 0.254, Loss_fe 0.483, Loss_kd 0.480, Train_accy 61.14
2022-09-28 00:16:44,224 [foster.py] => Task 1, Epoch 11/34 => Loss 1.381, Loss_clf 0.246, Loss_fe 0.455, Loss_kd 0.476, Train_accy 58.75, Test_accy 70.27
2022-09-28 00:16:45,951 [foster.py] => Task 1, Epoch 12/34 => Loss 1.370, Loss_clf 0.249, Loss_fe 0.435, Loss_kd 0.480, Train_accy 61.01
2022-09-28 00:16:47,654 [foster.py] => Task 1, Epoch 13/34 => Loss 1.322, Loss_clf 0.228, Loss_fe 0.407, Loss_kd 0.481, Train_accy 60.74
2022-09-28 00:16:49,369 [foster.py] => Task 1, Epoch 14/34 => Loss 1.326, Loss_clf 0.230, Loss_fe 0.408, Loss_kd 0.482, Train_accy 62.60
2022-09-28 00:16:51,067 [foster.py] => Task 1, Epoch 15/34 => Loss 1.300, Loss_clf 0.232, Loss_fe 0.389, Loss_kd 0.475, Train_accy 60.61
2022-09-28 00:16:53,548 [foster.py] => Task 1, Epoch 16/34 => Loss 1.317, Loss_clf 0.229, Loss_fe 0.401, Loss_kd 0.481, Train_accy 62.07, Test_accy 70.72
2022-09-28 00:16:55,256 [foster.py] => Task 1, Epoch 17/34 => Loss 1.277, Loss_clf 0.224, Loss_fe 0.370, Loss_kd 0.478, Train_accy 59.42
2022-09-28 00:16:56,966 [foster.py] => Task 1, Epoch 18/34 => Loss 1.242, Loss_clf 0.210, Loss_fe 0.358, Loss_kd 0.472, Train_accy 61.80
2022-09-28 00:16:58,681 [foster.py] => Task 1, Epoch 19/34 => Loss 1.250, Loss_clf 0.212, Loss_fe 0.358, Loss_kd 0.475, Train_accy 61.27
2022-09-28 00:17:00,401 [foster.py] => Task 1, Epoch 20/34 => Loss 1.235, Loss_clf 0.207, Loss_fe 0.343, Loss_kd 0.479, Train_accy 63.13
2022-09-28 00:17:03,006 [foster.py] => Task 1, Epoch 21/34 => Loss 1.233, Loss_clf 0.206, Loss_fe 0.343, Loss_kd 0.479, Train_accy 61.54, Test_accy 72.07
2022-09-28 00:17:04,703 [foster.py] => Task 1, Epoch 22/34 => Loss 1.235, Loss_clf 0.208, Loss_fe 0.340, Loss_kd 0.481, Train_accy 62.07
2022-09-28 00:17:06,445 [foster.py] => Task 1, Epoch 23/34 => Loss 1.220, Loss_clf 0.197, Loss_fe 0.333, Loss_kd 0.483, Train_accy 62.47
2022-09-28 00:17:08,244 [foster.py] => Task 1, Epoch 24/34 => Loss 1.195, Loss_clf 0.197, Loss_fe 0.319, Loss_kd 0.475, Train_accy 61.67
2022-09-28 00:17:09,986 [foster.py] => Task 1, Epoch 25/34 => Loss 1.231, Loss_clf 0.214, Loss_fe 0.335, Loss_kd 0.478, Train_accy 62.47
2022-09-28 00:17:12,418 [foster.py] => Task 1, Epoch 26/34 => Loss 1.210, Loss_clf 0.193, Loss_fe 0.331, Loss_kd 0.480, Train_accy 62.20, Test_accy 72.52
2022-09-28 00:17:14,146 [foster.py] => Task 1, Epoch 27/34 => Loss 1.187, Loss_clf 0.191, Loss_fe 0.306, Loss_kd 0.482, Train_accy 63.53
2022-09-28 00:17:15,886 [foster.py] => Task 1, Epoch 28/34 => Loss 1.182, Loss_clf 0.188, Loss_fe 0.322, Loss_kd 0.470, Train_accy 60.88
2022-09-28 00:17:17,617 [foster.py] => Task 1, Epoch 29/34 => Loss 1.158, Loss_clf 0.179, Loss_fe 0.301, Loss_kd 0.475, Train_accy 63.26
2022-09-28 00:17:19,370 [foster.py] => Task 1, Epoch 30/34 => Loss 1.163, Loss_clf 0.177, Loss_fe 0.303, Loss_kd 0.478, Train_accy 62.47
2022-09-28 00:17:21,803 [foster.py] => Task 1, Epoch 31/34 => Loss 1.179, Loss_clf 0.181, Loss_fe 0.314, Loss_kd 0.479, Train_accy 63.40, Test_accy 72.52
2022-09-28 00:17:23,506 [foster.py] => Task 1, Epoch 32/34 => Loss 1.180, Loss_clf 0.181, Loss_fe 0.307, Loss_kd 0.485, Train_accy 63.66
2022-09-28 00:17:25,223 [foster.py] => Task 1, Epoch 33/34 => Loss 1.169, Loss_clf 0.181, Loss_fe 0.304, Loss_kd 0.479, Train_accy 63.40
2022-09-28 00:17:26,910 [foster.py] => Task 1, Epoch 34/34 => Loss 1.175, Loss_clf 0.185, Loss_fe 0.308, Loss_kd 0.477, Train_accy 62.60
2022-09-28 00:17:26,911 [foster.py] => do not weight align teacher!
2022-09-28 00:17:26,911 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 00:17:29,744 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.630,  Train_accy 18.04, Test_accy 55.86
2022-09-28 00:17:31,643 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.477,  Train_accy 18.44
2022-09-28 00:17:33,594 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.402,  Train_accy 18.30
2022-09-28 00:17:35,496 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.328,  Train_accy 19.63
2022-09-28 00:17:37,419 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.309,  Train_accy 22.02
2022-09-28 00:17:39,990 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.282,  Train_accy 24.93, Test_accy 59.46
2022-09-28 00:17:41,895 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.259,  Train_accy 26.92
2022-09-28 00:17:43,805 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.247,  Train_accy 27.32
2022-09-28 00:17:45,773 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.232,  Train_accy 29.58
2022-09-28 00:17:47,703 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.227,  Train_accy 30.77
2022-09-28 00:17:50,303 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.234,  Train_accy 31.70, Test_accy 61.71
2022-09-28 00:17:52,271 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.218,  Train_accy 32.36
2022-09-28 00:17:54,190 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.215,  Train_accy 32.10
2022-09-28 00:17:56,133 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.216,  Train_accy 34.08
2022-09-28 00:17:58,018 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.204,  Train_accy 34.75
2022-09-28 00:18:00,573 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.194,  Train_accy 33.69, Test_accy 62.61
2022-09-28 00:18:02,485 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.201,  Train_accy 35.41
2022-09-28 00:18:04,407 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.198,  Train_accy 37.40
2022-09-28 00:18:06,310 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.187,  Train_accy 34.08
2022-09-28 00:18:08,204 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.197,  Train_accy 34.08
2022-09-28 00:18:10,808 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.188,  Train_accy 36.07, Test_accy 62.16
2022-09-28 00:18:12,752 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.189,  Train_accy 35.01
2022-09-28 00:18:14,722 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.209,  Train_accy 35.28
2022-09-28 00:18:16,654 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.201,  Train_accy 35.94
2022-09-28 00:18:18,599 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.193,  Train_accy 34.48
2022-09-28 00:18:21,169 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.198,  Train_accy 35.28, Test_accy 62.61
2022-09-28 00:18:21,170 [foster.py] => do not weight align student!
2022-09-28 00:18:21,824 [foster.py] => darknet eval: 
2022-09-28 00:18:21,825 [foster.py] => CNN top1 curve: 62.61
2022-09-28 00:18:21,825 [foster.py] => CNN top5 curve: 98.65
2022-09-28 00:18:21,825 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 00:18:28,098 [foster.py] => Exemplar size: 200
2022-09-28 00:18:28,098 [trainer.py] => CNN: {'total': 72.97, 'old': 86.49, 'new': 45.95, 'base': 86.49, 'compound': 45.95}
2022-09-28 00:18:28,098 [trainer.py] => CNN top1 curve: [87.16, 72.97]
2022-09-28 00:18:28,098 [trainer.py] => CNN base curve: [87.16, 86.49]
2022-09-28 00:18:28,098 [trainer.py] => CNN old curve: [87.16, 86.49]
2022-09-28 00:18:28,098 [trainer.py] => CNN new curve: [0, 45.95]
2022-09-28 00:18:28,099 [trainer.py] => CNN compound curve: [0, 45.95]
2022-09-28 00:18:28,099 [trainer.py] => NME: {'total': 76.13, 'old': 81.08, 'new': 66.22, 'base': 81.08, 'compound': 66.22}
2022-09-28 00:18:28,099 [trainer.py] => NME top1 curve: [88.51, 76.13]
2022-09-28 00:18:28,099 [trainer.py] => NME base curve: [88.51, 81.08]
2022-09-28 00:18:28,099 [trainer.py] => NME old curve: [88.51, 81.08]
2022-09-28 00:18:28,099 [trainer.py] => NME new curve: [0, 66.22]
2022-09-28 00:18:28,099 [trainer.py] => NME compound curve: [0, 66.22]
2022-09-28 00:18:28,327 [foster.py] => Learning on 10-13
2022-09-28 00:18:28,328 [foster.py] => All params: 22378148
2022-09-28 00:18:28,328 [foster.py] => Trainable params: 11196506
2022-09-28 00:18:28,348 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 00:18:30,961 [foster.py] => Task 2, Epoch 1/34 => Loss 5.330, Loss_clf 2.163, Loss_fe 2.124, Loss_kd 0.803, Train_accy 38.00, Test_accy 45.67
2022-09-28 00:18:32,763 [foster.py] => Task 2, Epoch 2/34 => Loss 3.332, Loss_clf 0.885, Loss_fe 1.389, Loss_kd 0.814, Train_accy 48.23
2022-09-28 00:18:34,647 [foster.py] => Task 2, Epoch 3/34 => Loss 2.845, Loss_clf 0.665, Loss_fe 1.163, Loss_kd 0.782, Train_accy 39.10
2022-09-28 00:18:36,448 [foster.py] => Task 2, Epoch 4/34 => Loss 2.689, Loss_clf 0.617, Loss_fe 1.047, Loss_kd 0.789, Train_accy 43.97
2022-09-28 00:18:38,286 [foster.py] => Task 2, Epoch 5/34 => Loss 2.557, Loss_clf 0.586, Loss_fe 0.951, Loss_kd 0.785, Train_accy 43.36
2022-09-28 00:18:40,947 [foster.py] => Task 2, Epoch 6/34 => Loss 2.467, Loss_clf 0.560, Loss_fe 0.896, Loss_kd 0.778, Train_accy 43.36, Test_accy 56.06
2022-09-28 00:18:42,753 [foster.py] => Task 2, Epoch 7/34 => Loss 2.371, Loss_clf 0.527, Loss_fe 0.822, Loss_kd 0.786, Train_accy 44.82
2022-09-28 00:18:44,548 [foster.py] => Task 2, Epoch 8/34 => Loss 2.360, Loss_clf 0.542, Loss_fe 0.808, Loss_kd 0.777, Train_accy 45.80
2022-09-28 00:18:46,391 [foster.py] => Task 2, Epoch 9/34 => Loss 2.303, Loss_clf 0.519, Loss_fe 0.775, Loss_kd 0.776, Train_accy 46.04
2022-09-28 00:18:48,213 [foster.py] => Task 2, Epoch 10/34 => Loss 2.272, Loss_clf 0.519, Loss_fe 0.740, Loss_kd 0.780, Train_accy 44.82
2022-09-28 00:18:50,885 [foster.py] => Task 2, Epoch 11/34 => Loss 2.250, Loss_clf 0.507, Loss_fe 0.723, Loss_kd 0.785, Train_accy 44.09, Test_accy 57.79
2022-09-28 00:18:52,700 [foster.py] => Task 2, Epoch 12/34 => Loss 2.206, Loss_clf 0.490, Loss_fe 0.695, Loss_kd 0.785, Train_accy 43.48
2022-09-28 00:18:54,503 [foster.py] => Task 2, Epoch 13/34 => Loss 2.132, Loss_clf 0.452, Loss_fe 0.656, Loss_kd 0.787, Train_accy 45.43
2022-09-28 00:18:56,384 [foster.py] => Task 2, Epoch 14/34 => Loss 2.089, Loss_clf 0.445, Loss_fe 0.623, Loss_kd 0.786, Train_accy 45.92
2022-09-28 00:18:58,173 [foster.py] => Task 2, Epoch 15/34 => Loss 2.092, Loss_clf 0.453, Loss_fe 0.624, Loss_kd 0.780, Train_accy 47.50
2022-09-28 00:19:00,775 [foster.py] => Task 2, Epoch 16/34 => Loss 2.050, Loss_clf 0.438, Loss_fe 0.596, Loss_kd 0.782, Train_accy 46.04, Test_accy 58.82
2022-09-28 00:19:02,590 [foster.py] => Task 2, Epoch 17/34 => Loss 2.011, Loss_clf 0.416, Loss_fe 0.579, Loss_kd 0.782, Train_accy 46.89
2022-09-28 00:19:04,440 [foster.py] => Task 2, Epoch 18/34 => Loss 2.011, Loss_clf 0.416, Loss_fe 0.578, Loss_kd 0.782, Train_accy 47.14
2022-09-28 00:19:06,292 [foster.py] => Task 2, Epoch 19/34 => Loss 1.989, Loss_clf 0.412, Loss_fe 0.565, Loss_kd 0.778, Train_accy 49.09
2022-09-28 00:19:08,101 [foster.py] => Task 2, Epoch 20/34 => Loss 1.974, Loss_clf 0.405, Loss_fe 0.548, Loss_kd 0.786, Train_accy 48.60
2022-09-28 00:19:10,721 [foster.py] => Task 2, Epoch 21/34 => Loss 1.988, Loss_clf 0.405, Loss_fe 0.557, Loss_kd 0.789, Train_accy 49.82, Test_accy 59.17
2022-09-28 00:19:12,605 [foster.py] => Task 2, Epoch 22/34 => Loss 1.939, Loss_clf 0.384, Loss_fe 0.542, Loss_kd 0.779, Train_accy 46.89
2022-09-28 00:19:14,452 [foster.py] => Task 2, Epoch 23/34 => Loss 1.944, Loss_clf 0.392, Loss_fe 0.542, Loss_kd 0.776, Train_accy 48.11
2022-09-28 00:19:16,297 [foster.py] => Task 2, Epoch 24/34 => Loss 1.959, Loss_clf 0.402, Loss_fe 0.533, Loss_kd 0.788, Train_accy 50.67
2022-09-28 00:19:18,107 [foster.py] => Task 2, Epoch 25/34 => Loss 1.933, Loss_clf 0.398, Loss_fe 0.525, Loss_kd 0.777, Train_accy 47.87
2022-09-28 00:19:20,731 [foster.py] => Task 2, Epoch 26/34 => Loss 1.994, Loss_clf 0.403, Loss_fe 0.558, Loss_kd 0.795, Train_accy 49.70, Test_accy 60.21
2022-09-28 00:19:22,563 [foster.py] => Task 2, Epoch 27/34 => Loss 1.940, Loss_clf 0.393, Loss_fe 0.521, Loss_kd 0.790, Train_accy 49.45
2022-09-28 00:19:24,369 [foster.py] => Task 2, Epoch 28/34 => Loss 1.939, Loss_clf 0.391, Loss_fe 0.527, Loss_kd 0.785, Train_accy 47.75
2022-09-28 00:19:26,216 [foster.py] => Task 2, Epoch 29/34 => Loss 1.912, Loss_clf 0.380, Loss_fe 0.512, Loss_kd 0.785, Train_accy 49.09
2022-09-28 00:19:28,051 [foster.py] => Task 2, Epoch 30/34 => Loss 1.893, Loss_clf 0.362, Loss_fe 0.512, Loss_kd 0.784, Train_accy 51.52
2022-09-28 00:19:30,626 [foster.py] => Task 2, Epoch 31/34 => Loss 1.936, Loss_clf 0.388, Loss_fe 0.521, Loss_kd 0.790, Train_accy 50.06, Test_accy 60.21
2022-09-28 00:19:32,441 [foster.py] => Task 2, Epoch 32/34 => Loss 1.885, Loss_clf 0.363, Loss_fe 0.503, Loss_kd 0.784, Train_accy 49.70
2022-09-28 00:19:34,254 [foster.py] => Task 2, Epoch 33/34 => Loss 1.896, Loss_clf 0.371, Loss_fe 0.501, Loss_kd 0.787, Train_accy 49.21
2022-09-28 00:19:36,058 [foster.py] => Task 2, Epoch 34/34 => Loss 1.901, Loss_clf 0.371, Loss_fe 0.508, Loss_kd 0.786, Train_accy 50.43
2022-09-28 00:19:36,058 [foster.py] => do not weight align teacher!
2022-09-28 00:19:36,059 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 00:19:39,051 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.826,  Train_accy 16.93, Test_accy 47.40
2022-09-28 00:19:41,166 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.674,  Train_accy 18.15
2022-09-28 00:19:43,201 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.604,  Train_accy 18.03
2022-09-28 00:19:45,265 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.564,  Train_accy 18.64
2022-09-28 00:19:47,287 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.548,  Train_accy 18.88
2022-09-28 00:19:50,116 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.535,  Train_accy 18.88, Test_accy 49.48
2022-09-28 00:19:52,178 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.518,  Train_accy 20.10
2022-09-28 00:19:54,240 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.498,  Train_accy 20.34
2022-09-28 00:19:56,313 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.501,  Train_accy 21.07
2022-09-28 00:19:58,391 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.501,  Train_accy 21.32
2022-09-28 00:20:01,121 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.489,  Train_accy 21.56, Test_accy 49.83
2022-09-28 00:20:03,128 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.493,  Train_accy 21.68
2022-09-28 00:20:05,156 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.489,  Train_accy 21.56
2022-09-28 00:20:07,202 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.503,  Train_accy 22.53
2022-09-28 00:20:09,281 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.485,  Train_accy 21.92
2022-09-28 00:20:12,049 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.490,  Train_accy 22.05, Test_accy 49.83
2022-09-28 00:20:14,110 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.481,  Train_accy 21.68
2022-09-28 00:20:16,110 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.492,  Train_accy 23.63
2022-09-28 00:20:18,207 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.472,  Train_accy 23.26
2022-09-28 00:20:20,251 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.483,  Train_accy 22.90
2022-09-28 00:20:23,030 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.488,  Train_accy 22.05, Test_accy 50.87
2022-09-28 00:20:25,055 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.500,  Train_accy 22.41
2022-09-28 00:20:27,120 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.481,  Train_accy 22.29
2022-09-28 00:20:29,178 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.466,  Train_accy 21.56
2022-09-28 00:20:31,187 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.466,  Train_accy 22.53
2022-09-28 00:20:33,947 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.477,  Train_accy 23.02, Test_accy 50.87
2022-09-28 00:20:33,947 [foster.py] => do not weight align student!
2022-09-28 00:20:34,671 [foster.py] => darknet eval: 
2022-09-28 00:20:34,671 [foster.py] => CNN top1 curve: 50.87
2022-09-28 00:20:34,672 [foster.py] => CNN top5 curve: 96.54
2022-09-28 00:20:34,672 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 00:20:42,100 [foster.py] => Exemplar size: 260
2022-09-28 00:20:42,100 [trainer.py] => CNN: {'total': 60.21, 'old': 68.47, 'new': 32.84, 'base': 81.76, 'compound': 37.59}
2022-09-28 00:20:42,101 [trainer.py] => CNN top1 curve: [87.16, 72.97, 60.21]
2022-09-28 00:20:42,101 [trainer.py] => CNN base curve: [87.16, 86.49, 81.76]
2022-09-28 00:20:42,101 [trainer.py] => CNN old curve: [87.16, 86.49, 68.47]
2022-09-28 00:20:42,101 [trainer.py] => CNN new curve: [0, 45.95, 32.84]
2022-09-28 00:20:42,101 [trainer.py] => CNN compound curve: [0, 45.95, 37.59]
2022-09-28 00:20:42,101 [trainer.py] => NME: {'total': 62.98, 'old': 66.67, 'new': 50.75, 'base': 70.27, 'compound': 55.32}
2022-09-28 00:20:42,101 [trainer.py] => NME top1 curve: [88.51, 76.13, 62.98]
2022-09-28 00:20:42,101 [trainer.py] => NME base curve: [88.51, 81.08, 70.27]
2022-09-28 00:20:42,101 [trainer.py] => NME old curve: [88.51, 81.08, 66.67]
2022-09-28 00:20:42,101 [trainer.py] => NME new curve: [0, 66.22, 50.75]
2022-09-28 00:20:42,101 [trainer.py] => NME compound curve: [0, 66.22, 55.32]
2022-09-28 00:20:42,328 [foster.py] => Learning on 13-16
2022-09-28 00:20:42,328 [foster.py] => All params: 22384301
2022-09-28 00:20:42,329 [foster.py] => Trainable params: 11201120
2022-09-28 00:20:42,349 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 00:20:45,134 [foster.py] => Task 3, Epoch 1/34 => Loss 6.153, Loss_clf 2.174, Loss_fe 2.338, Loss_kd 1.333, Train_accy 40.14, Test_accy 40.72
2022-09-28 00:20:47,058 [foster.py] => Task 3, Epoch 2/34 => Loss 4.298, Loss_clf 1.021, Loss_fe 1.647, Loss_kd 1.325, Train_accy 44.24
2022-09-28 00:20:49,010 [foster.py] => Task 3, Epoch 3/34 => Loss 4.000, Loss_clf 0.904, Loss_fe 1.460, Loss_kd 1.329, Train_accy 41.39
2022-09-28 00:20:50,911 [foster.py] => Task 3, Epoch 4/34 => Loss 3.873, Loss_clf 0.859, Loss_fe 1.356, Loss_kd 1.347, Train_accy 40.48
2022-09-28 00:20:52,832 [foster.py] => Task 3, Epoch 5/34 => Loss 3.719, Loss_clf 0.830, Loss_fe 1.251, Loss_kd 1.331, Train_accy 42.42
2022-09-28 00:20:55,620 [foster.py] => Task 3, Epoch 6/34 => Loss 3.693, Loss_clf 0.843, Loss_fe 1.207, Loss_kd 1.334, Train_accy 41.39, Test_accy 48.75
2022-09-28 00:20:57,586 [foster.py] => Task 3, Epoch 7/34 => Loss 3.571, Loss_clf 0.793, Loss_fe 1.132, Loss_kd 1.338, Train_accy 42.30
2022-09-28 00:20:59,519 [foster.py] => Task 3, Epoch 8/34 => Loss 3.467, Loss_clf 0.762, Loss_fe 1.062, Loss_kd 1.334, Train_accy 41.85
2022-09-28 00:21:01,424 [foster.py] => Task 3, Epoch 9/34 => Loss 3.414, Loss_clf 0.760, Loss_fe 1.027, Loss_kd 1.322, Train_accy 43.67
2022-09-28 00:21:03,357 [foster.py] => Task 3, Epoch 10/34 => Loss 3.372, Loss_clf 0.737, Loss_fe 0.999, Loss_kd 1.329, Train_accy 43.22
2022-09-28 00:21:06,099 [foster.py] => Task 3, Epoch 11/34 => Loss 3.341, Loss_clf 0.731, Loss_fe 0.967, Loss_kd 1.335, Train_accy 44.47, Test_accy 49.58
2022-09-28 00:21:07,979 [foster.py] => Task 3, Epoch 12/34 => Loss 3.291, Loss_clf 0.711, Loss_fe 0.944, Loss_kd 1.329, Train_accy 45.72
2022-09-28 00:21:09,872 [foster.py] => Task 3, Epoch 13/34 => Loss 3.228, Loss_clf 0.692, Loss_fe 0.895, Loss_kd 1.333, Train_accy 44.01
2022-09-28 00:21:11,806 [foster.py] => Task 3, Epoch 14/34 => Loss 3.219, Loss_clf 0.686, Loss_fe 0.889, Loss_kd 1.336, Train_accy 45.04
2022-09-28 00:21:13,722 [foster.py] => Task 3, Epoch 15/34 => Loss 3.156, Loss_clf 0.674, Loss_fe 0.849, Loss_kd 1.326, Train_accy 46.18
2022-09-28 00:21:16,542 [foster.py] => Task 3, Epoch 16/34 => Loss 3.143, Loss_clf 0.658, Loss_fe 0.829, Loss_kd 1.345, Train_accy 46.18, Test_accy 49.86
2022-09-28 00:21:18,532 [foster.py] => Task 3, Epoch 17/34 => Loss 3.112, Loss_clf 0.649, Loss_fe 0.809, Loss_kd 1.344, Train_accy 46.75
2022-09-28 00:21:20,452 [foster.py] => Task 3, Epoch 18/34 => Loss 3.116, Loss_clf 0.650, Loss_fe 0.819, Loss_kd 1.338, Train_accy 47.32
2022-09-28 00:21:22,384 [foster.py] => Task 3, Epoch 19/34 => Loss 3.088, Loss_clf 0.647, Loss_fe 0.804, Loss_kd 1.330, Train_accy 44.36
2022-09-28 00:21:24,315 [foster.py] => Task 3, Epoch 20/34 => Loss 3.063, Loss_clf 0.634, Loss_fe 0.790, Loss_kd 1.331, Train_accy 47.09
2022-09-28 00:21:27,131 [foster.py] => Task 3, Epoch 21/34 => Loss 3.056, Loss_clf 0.621, Loss_fe 0.783, Loss_kd 1.342, Train_accy 47.89, Test_accy 51.25
2022-09-28 00:21:29,031 [foster.py] => Task 3, Epoch 22/34 => Loss 3.037, Loss_clf 0.622, Loss_fe 0.771, Loss_kd 1.336, Train_accy 48.00
2022-09-28 00:21:30,905 [foster.py] => Task 3, Epoch 23/34 => Loss 3.048, Loss_clf 0.625, Loss_fe 0.775, Loss_kd 1.339, Train_accy 46.18
2022-09-28 00:21:32,816 [foster.py] => Task 3, Epoch 24/34 => Loss 3.008, Loss_clf 0.613, Loss_fe 0.756, Loss_kd 1.332, Train_accy 47.43
2022-09-28 00:21:34,707 [foster.py] => Task 3, Epoch 25/34 => Loss 3.005, Loss_clf 0.621, Loss_fe 0.744, Loss_kd 1.333, Train_accy 49.83
2022-09-28 00:21:37,484 [foster.py] => Task 3, Epoch 26/34 => Loss 2.969, Loss_clf 0.601, Loss_fe 0.734, Loss_kd 1.327, Train_accy 47.55, Test_accy 50.69
2022-09-28 00:21:39,383 [foster.py] => Task 3, Epoch 27/34 => Loss 2.972, Loss_clf 0.602, Loss_fe 0.736, Loss_kd 1.327, Train_accy 47.32
2022-09-28 00:21:41,279 [foster.py] => Task 3, Epoch 28/34 => Loss 3.015, Loss_clf 0.606, Loss_fe 0.745, Loss_kd 1.351, Train_accy 49.03
2022-09-28 00:21:43,211 [foster.py] => Task 3, Epoch 29/34 => Loss 2.943, Loss_clf 0.584, Loss_fe 0.713, Loss_kd 1.337, Train_accy 46.86
2022-09-28 00:21:45,133 [foster.py] => Task 3, Epoch 30/34 => Loss 2.967, Loss_clf 0.587, Loss_fe 0.734, Loss_kd 1.338, Train_accy 46.29
2022-09-28 00:21:47,916 [foster.py] => Task 3, Epoch 31/34 => Loss 2.990, Loss_clf 0.611, Loss_fe 0.745, Loss_kd 1.327, Train_accy 46.86, Test_accy 50.97
2022-09-28 00:21:49,807 [foster.py] => Task 3, Epoch 32/34 => Loss 2.965, Loss_clf 0.596, Loss_fe 0.733, Loss_kd 1.330, Train_accy 48.57
2022-09-28 00:21:51,716 [foster.py] => Task 3, Epoch 33/34 => Loss 2.975, Loss_clf 0.604, Loss_fe 0.723, Loss_kd 1.339, Train_accy 48.57
2022-09-28 00:21:53,634 [foster.py] => Task 3, Epoch 34/34 => Loss 2.977, Loss_clf 0.602, Loss_fe 0.733, Loss_kd 1.334, Train_accy 47.78
2022-09-28 00:21:53,635 [foster.py] => do not weight align teacher!
2022-09-28 00:21:53,635 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 00:21:56,825 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.115,  Train_accy 19.04, Test_accy 40.72
2022-09-28 00:21:58,981 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.036,  Train_accy 19.61
2022-09-28 00:22:01,122 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 1.999,  Train_accy 20.18
2022-09-28 00:22:03,278 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 1.992,  Train_accy 19.38
2022-09-28 00:22:05,441 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.979,  Train_accy 19.84
2022-09-28 00:22:08,395 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.973,  Train_accy 20.52, Test_accy 43.21
2022-09-28 00:22:10,556 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.969,  Train_accy 19.95
2022-09-28 00:22:12,745 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.952,  Train_accy 19.95
2022-09-28 00:22:14,897 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.946,  Train_accy 20.18
2022-09-28 00:22:17,027 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.960,  Train_accy 20.30
2022-09-28 00:22:19,992 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.963,  Train_accy 21.21, Test_accy 42.94
2022-09-28 00:22:22,160 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.941,  Train_accy 20.52
2022-09-28 00:22:24,311 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.937,  Train_accy 20.64
2022-09-28 00:22:26,473 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.945,  Train_accy 20.30
2022-09-28 00:22:28,689 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.945,  Train_accy 21.09
2022-09-28 00:22:31,601 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.950,  Train_accy 20.64, Test_accy 43.49
2022-09-28 00:22:33,807 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.952,  Train_accy 20.64
2022-09-28 00:22:35,988 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.940,  Train_accy 20.87
2022-09-28 00:22:38,146 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.926,  Train_accy 20.52
2022-09-28 00:22:40,257 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.939,  Train_accy 20.98
2022-09-28 00:22:43,182 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.937,  Train_accy 21.09, Test_accy 43.77
2022-09-28 00:22:45,344 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.945,  Train_accy 19.95
2022-09-28 00:22:47,496 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.939,  Train_accy 21.09
2022-09-28 00:22:49,619 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.937,  Train_accy 20.41
2022-09-28 00:22:51,773 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.930,  Train_accy 21.66
2022-09-28 00:22:54,639 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.929,  Train_accy 20.52, Test_accy 43.77
2022-09-28 00:22:54,639 [foster.py] => do not weight align student!
2022-09-28 00:22:55,389 [foster.py] => darknet eval: 
2022-09-28 00:22:55,389 [foster.py] => CNN top1 curve: 43.77
2022-09-28 00:22:55,389 [foster.py] => CNN top5 curve: 90.58
2022-09-28 00:22:55,390 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 00:23:03,869 [foster.py] => Exemplar size: 320
2022-09-28 00:23:03,869 [trainer.py] => CNN: {'total': 50.69, 'old': 54.67, 'new': 34.72, 'base': 76.35, 'compound': 32.86}
2022-09-28 00:23:03,870 [trainer.py] => CNN top1 curve: [87.16, 72.97, 60.21, 50.69]
2022-09-28 00:23:03,870 [trainer.py] => CNN base curve: [87.16, 86.49, 81.76, 76.35]
2022-09-28 00:23:03,870 [trainer.py] => CNN old curve: [87.16, 86.49, 68.47, 54.67]
2022-09-28 00:23:03,870 [trainer.py] => CNN new curve: [0, 45.95, 32.84, 34.72]
2022-09-28 00:23:03,870 [trainer.py] => CNN compound curve: [0, 45.95, 37.59, 32.86]
2022-09-28 00:23:03,870 [trainer.py] => NME: {'total': 55.96, 'old': 58.48, 'new': 45.83, 'base': 66.22, 'compound': 48.83}
2022-09-28 00:23:03,870 [trainer.py] => NME top1 curve: [88.51, 76.13, 62.98, 55.96]
2022-09-28 00:23:03,870 [trainer.py] => NME base curve: [88.51, 81.08, 70.27, 66.22]
2022-09-28 00:23:03,870 [trainer.py] => NME old curve: [88.51, 81.08, 66.67, 58.48]
2022-09-28 00:23:03,870 [trainer.py] => NME new curve: [0, 66.22, 50.75, 45.83]
2022-09-28 00:23:03,870 [trainer.py] => NME compound curve: [0, 66.22, 55.32, 48.83]
2022-09-28 00:23:04,099 [foster.py] => Learning on 16-19
2022-09-28 00:23:04,100 [foster.py] => All params: 22390454
2022-09-28 00:23:04,100 [foster.py] => Trainable params: 11205734
2022-09-28 00:23:04,120 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 00:23:07,026 [foster.py] => Task 4, Epoch 1/34 => Loss 6.169, Loss_clf 1.977, Loss_fe 2.282, Loss_kd 1.609, Train_accy 40.30, Test_accy 39.55
2022-09-28 00:23:09,022 [foster.py] => Task 4, Epoch 2/34 => Loss 4.512, Loss_clf 0.946, Loss_fe 1.663, Loss_kd 1.603, Train_accy 40.30
2022-09-28 00:23:11,010 [foster.py] => Task 4, Epoch 3/34 => Loss 4.234, Loss_clf 0.848, Loss_fe 1.482, Loss_kd 1.603, Train_accy 44.40
2022-09-28 00:23:13,011 [foster.py] => Task 4, Epoch 4/34 => Loss 4.051, Loss_clf 0.808, Loss_fe 1.346, Loss_kd 1.597, Train_accy 43.86
2022-09-28 00:23:15,014 [foster.py] => Task 4, Epoch 5/34 => Loss 3.926, Loss_clf 0.779, Loss_fe 1.250, Loss_kd 1.598, Train_accy 48.38
2022-09-28 00:23:17,912 [foster.py] => Task 4, Epoch 6/34 => Loss 3.852, Loss_clf 0.773, Loss_fe 1.188, Loss_kd 1.592, Train_accy 44.72, Test_accy 44.55
2022-09-28 00:23:19,881 [foster.py] => Task 4, Epoch 7/34 => Loss 3.803, Loss_clf 0.771, Loss_fe 1.137, Loss_kd 1.595, Train_accy 45.15
2022-09-28 00:23:21,846 [foster.py] => Task 4, Epoch 8/34 => Loss 3.682, Loss_clf 0.718, Loss_fe 1.066, Loss_kd 1.598, Train_accy 48.38
2022-09-28 00:23:23,802 [foster.py] => Task 4, Epoch 9/34 => Loss 3.644, Loss_clf 0.728, Loss_fe 1.015, Loss_kd 1.601, Train_accy 46.88
2022-09-28 00:23:25,783 [foster.py] => Task 4, Epoch 10/34 => Loss 3.596, Loss_clf 0.702, Loss_fe 0.988, Loss_kd 1.604, Train_accy 48.71
2022-09-28 00:23:28,678 [foster.py] => Task 4, Epoch 11/34 => Loss 3.549, Loss_clf 0.692, Loss_fe 0.950, Loss_kd 1.606, Train_accy 47.74, Test_accy 45.68
2022-09-28 00:23:30,691 [foster.py] => Task 4, Epoch 12/34 => Loss 3.525, Loss_clf 0.687, Loss_fe 0.937, Loss_kd 1.601, Train_accy 48.60
2022-09-28 00:23:32,679 [foster.py] => Task 4, Epoch 13/34 => Loss 3.488, Loss_clf 0.688, Loss_fe 0.894, Loss_kd 1.605, Train_accy 51.51
2022-09-28 00:23:34,681 [foster.py] => Task 4, Epoch 14/34 => Loss 3.429, Loss_clf 0.658, Loss_fe 0.872, Loss_kd 1.600, Train_accy 49.35
2022-09-28 00:23:36,659 [foster.py] => Task 4, Epoch 15/34 => Loss 3.466, Loss_clf 0.682, Loss_fe 0.870, Loss_kd 1.612, Train_accy 51.51
2022-09-28 00:23:39,620 [foster.py] => Task 4, Epoch 16/34 => Loss 3.380, Loss_clf 0.647, Loss_fe 0.832, Loss_kd 1.601, Train_accy 47.20, Test_accy 46.14
2022-09-28 00:23:41,604 [foster.py] => Task 4, Epoch 17/34 => Loss 3.418, Loss_clf 0.667, Loss_fe 0.837, Loss_kd 1.611, Train_accy 49.14
2022-09-28 00:23:43,553 [foster.py] => Task 4, Epoch 18/34 => Loss 3.346, Loss_clf 0.645, Loss_fe 0.801, Loss_kd 1.600, Train_accy 47.63
2022-09-28 00:23:45,524 [foster.py] => Task 4, Epoch 19/34 => Loss 3.350, Loss_clf 0.646, Loss_fe 0.796, Loss_kd 1.606, Train_accy 49.14
2022-09-28 00:23:47,496 [foster.py] => Task 4, Epoch 20/34 => Loss 3.342, Loss_clf 0.639, Loss_fe 0.796, Loss_kd 1.606, Train_accy 47.20
2022-09-28 00:23:50,454 [foster.py] => Task 4, Epoch 21/34 => Loss 3.331, Loss_clf 0.642, Loss_fe 0.793, Loss_kd 1.597, Train_accy 49.89, Test_accy 46.59
2022-09-28 00:23:52,458 [foster.py] => Task 4, Epoch 22/34 => Loss 3.320, Loss_clf 0.632, Loss_fe 0.776, Loss_kd 1.610, Train_accy 51.29
2022-09-28 00:23:54,466 [foster.py] => Task 4, Epoch 23/34 => Loss 3.300, Loss_clf 0.626, Loss_fe 0.764, Loss_kd 1.609, Train_accy 51.51
2022-09-28 00:23:56,423 [foster.py] => Task 4, Epoch 24/34 => Loss 3.287, Loss_clf 0.623, Loss_fe 0.759, Loss_kd 1.604, Train_accy 50.43
2022-09-28 00:23:58,407 [foster.py] => Task 4, Epoch 25/34 => Loss 3.239, Loss_clf 0.596, Loss_fe 0.735, Loss_kd 1.607, Train_accy 50.00
2022-09-28 00:24:01,308 [foster.py] => Task 4, Epoch 26/34 => Loss 3.254, Loss_clf 0.608, Loss_fe 0.744, Loss_kd 1.602, Train_accy 51.19, Test_accy 47.50
2022-09-28 00:24:03,312 [foster.py] => Task 4, Epoch 27/34 => Loss 3.280, Loss_clf 0.625, Loss_fe 0.755, Loss_kd 1.599, Train_accy 49.68
2022-09-28 00:24:05,269 [foster.py] => Task 4, Epoch 28/34 => Loss 3.286, Loss_clf 0.624, Loss_fe 0.757, Loss_kd 1.604, Train_accy 50.32
2022-09-28 00:24:07,244 [foster.py] => Task 4, Epoch 29/34 => Loss 3.289, Loss_clf 0.623, Loss_fe 0.758, Loss_kd 1.606, Train_accy 51.29
2022-09-28 00:24:09,237 [foster.py] => Task 4, Epoch 30/34 => Loss 3.278, Loss_clf 0.618, Loss_fe 0.754, Loss_kd 1.605, Train_accy 51.94
2022-09-28 00:24:12,181 [foster.py] => Task 4, Epoch 31/34 => Loss 3.254, Loss_clf 0.620, Loss_fe 0.742, Loss_kd 1.593, Train_accy 48.92, Test_accy 47.73
2022-09-28 00:24:14,177 [foster.py] => Task 4, Epoch 32/34 => Loss 3.273, Loss_clf 0.615, Loss_fe 0.745, Loss_kd 1.611, Train_accy 51.08
2022-09-28 00:24:16,141 [foster.py] => Task 4, Epoch 33/34 => Loss 3.241, Loss_clf 0.605, Loss_fe 0.737, Loss_kd 1.599, Train_accy 50.75
2022-09-28 00:24:18,144 [foster.py] => Task 4, Epoch 34/34 => Loss 3.267, Loss_clf 0.617, Loss_fe 0.743, Loss_kd 1.606, Train_accy 50.65
2022-09-28 00:24:18,145 [foster.py] => do not weight align teacher!
2022-09-28 00:24:18,145 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 00:24:21,411 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.282,  Train_accy 18.64, Test_accy 35.45
2022-09-28 00:24:23,624 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.234,  Train_accy 19.40
2022-09-28 00:24:25,825 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.212,  Train_accy 20.15
2022-09-28 00:24:28,038 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.197,  Train_accy 20.26
2022-09-28 00:24:30,270 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.181,  Train_accy 20.37
2022-09-28 00:24:33,316 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.178,  Train_accy 19.94, Test_accy 35.23
2022-09-28 00:24:35,566 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.161,  Train_accy 21.44
2022-09-28 00:24:37,800 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.157,  Train_accy 19.50
2022-09-28 00:24:40,036 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.155,  Train_accy 20.69
2022-09-28 00:24:42,271 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.144,  Train_accy 21.01
2022-09-28 00:24:45,352 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.145,  Train_accy 21.44, Test_accy 36.59
2022-09-28 00:24:47,671 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.133,  Train_accy 21.88
2022-09-28 00:24:49,871 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.130,  Train_accy 21.12
2022-09-28 00:24:52,093 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.131,  Train_accy 21.98
2022-09-28 00:24:54,301 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.145,  Train_accy 21.77
2022-09-28 00:24:57,335 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.132,  Train_accy 22.09, Test_accy 37.05
2022-09-28 00:24:59,581 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.129,  Train_accy 21.77
2022-09-28 00:25:01,810 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.127,  Train_accy 21.88
2022-09-28 00:25:04,061 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.124,  Train_accy 22.95
2022-09-28 00:25:06,331 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.129,  Train_accy 22.31
2022-09-28 00:25:09,374 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.129,  Train_accy 21.77, Test_accy 37.50
2022-09-28 00:25:11,607 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.129,  Train_accy 22.09
2022-09-28 00:25:13,808 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.124,  Train_accy 22.84
2022-09-28 00:25:16,043 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.126,  Train_accy 22.41
2022-09-28 00:25:18,299 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.117,  Train_accy 21.98
2022-09-28 00:25:21,440 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.130,  Train_accy 22.41, Test_accy 37.73
2022-09-28 00:25:21,441 [foster.py] => do not weight align student!
2022-09-28 00:25:22,242 [foster.py] => darknet eval: 
2022-09-28 00:25:22,242 [foster.py] => CNN top1 curve: 37.73
2022-09-28 00:25:22,242 [foster.py] => CNN top5 curve: 83.41
2022-09-28 00:25:22,242 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 00:25:31,737 [foster.py] => Exemplar size: 380
2022-09-28 00:25:31,737 [trainer.py] => CNN: {'total': 47.73, 'old': 49.86, 'new': 37.97, 'base': 72.97, 'compound': 34.93}
2022-09-28 00:25:31,737 [trainer.py] => CNN top1 curve: [87.16, 72.97, 60.21, 50.69, 47.73]
2022-09-28 00:25:31,738 [trainer.py] => CNN base curve: [87.16, 86.49, 81.76, 76.35, 72.97]
2022-09-28 00:25:31,738 [trainer.py] => CNN old curve: [87.16, 86.49, 68.47, 54.67, 49.86]
2022-09-28 00:25:31,738 [trainer.py] => CNN new curve: [0, 45.95, 32.84, 34.72, 37.97]
2022-09-28 00:25:31,738 [trainer.py] => CNN compound curve: [0, 45.95, 37.59, 32.86, 34.93]
2022-09-28 00:25:31,738 [trainer.py] => NME: {'total': 52.95, 'old': 52.35, 'new': 55.7, 'base': 64.19, 'compound': 47.26}
2022-09-28 00:25:31,738 [trainer.py] => NME top1 curve: [88.51, 76.13, 62.98, 55.96, 52.95]
2022-09-28 00:25:31,738 [trainer.py] => NME base curve: [88.51, 81.08, 70.27, 66.22, 64.19]
2022-09-28 00:25:31,738 [trainer.py] => NME old curve: [88.51, 81.08, 66.67, 58.48, 52.35]
2022-09-28 00:25:31,738 [trainer.py] => NME new curve: [0, 66.22, 50.75, 45.83, 55.7]
2022-09-28 00:25:31,738 [trainer.py] => NME compound curve: [0, 66.22, 55.32, 48.83, 47.26]
2022-09-28 00:25:31,965 [foster.py] => Learning on 19-22
2022-09-28 00:25:31,965 [foster.py] => All params: 22396607
2022-09-28 00:25:31,966 [foster.py] => Trainable params: 11210348
2022-09-28 00:25:31,986 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 00:25:35,089 [foster.py] => Task 5, Epoch 1/34 => Loss 6.979, Loss_clf 2.046, Loss_fe 2.714, Loss_kd 1.916, Train_accy 37.52, Test_accy 36.83
2022-09-28 00:25:37,203 [foster.py] => Task 5, Epoch 2/34 => Loss 5.190, Loss_clf 1.086, Loss_fe 1.882, Loss_kd 1.919, Train_accy 38.62
2022-09-28 00:25:39,313 [foster.py] => Task 5, Epoch 3/34 => Loss 4.951, Loss_clf 1.034, Loss_fe 1.697, Loss_kd 1.917, Train_accy 42.42
2022-09-28 00:25:41,390 [foster.py] => Task 5, Epoch 4/34 => Loss 4.757, Loss_clf 0.979, Loss_fe 1.556, Loss_kd 1.919, Train_accy 40.02
2022-09-28 00:25:43,483 [foster.py] => Task 5, Epoch 5/34 => Loss 4.653, Loss_clf 0.950, Loss_fe 1.480, Loss_kd 1.919, Train_accy 44.81
2022-09-28 00:25:46,587 [foster.py] => Task 5, Epoch 6/34 => Loss 4.545, Loss_clf 0.935, Loss_fe 1.394, Loss_kd 1.914, Train_accy 41.72, Test_accy 40.40
2022-09-28 00:25:48,693 [foster.py] => Task 5, Epoch 7/34 => Loss 4.435, Loss_clf 0.892, Loss_fe 1.327, Loss_kd 1.915, Train_accy 42.81
2022-09-28 00:25:50,790 [foster.py] => Task 5, Epoch 8/34 => Loss 4.394, Loss_clf 0.904, Loss_fe 1.266, Loss_kd 1.921, Train_accy 45.01
2022-09-28 00:25:52,900 [foster.py] => Task 5, Epoch 9/34 => Loss 4.315, Loss_clf 0.876, Loss_fe 1.216, Loss_kd 1.920, Train_accy 45.01
2022-09-28 00:25:54,985 [foster.py] => Task 5, Epoch 10/34 => Loss 4.246, Loss_clf 0.850, Loss_fe 1.166, Loss_kd 1.926, Train_accy 47.31
2022-09-28 00:25:58,070 [foster.py] => Task 5, Epoch 11/34 => Loss 4.235, Loss_clf 0.869, Loss_fe 1.148, Loss_kd 1.916, Train_accy 44.11, Test_accy 41.19
2022-09-28 00:26:00,136 [foster.py] => Task 5, Epoch 12/34 => Loss 4.162, Loss_clf 0.828, Loss_fe 1.107, Loss_kd 1.923, Train_accy 47.41
2022-09-28 00:26:02,251 [foster.py] => Task 5, Epoch 13/34 => Loss 4.101, Loss_clf 0.813, Loss_fe 1.058, Loss_kd 1.926, Train_accy 47.21
2022-09-28 00:26:04,356 [foster.py] => Task 5, Epoch 14/34 => Loss 4.058, Loss_clf 0.796, Loss_fe 1.042, Loss_kd 1.918, Train_accy 47.01
2022-09-28 00:26:06,441 [foster.py] => Task 5, Epoch 15/34 => Loss 4.009, Loss_clf 0.775, Loss_fe 1.019, Loss_kd 1.913, Train_accy 47.11
2022-09-28 00:26:09,463 [foster.py] => Task 5, Epoch 16/34 => Loss 3.996, Loss_clf 0.775, Loss_fe 0.995, Loss_kd 1.923, Train_accy 48.30, Test_accy 40.99
2022-09-28 00:26:11,561 [foster.py] => Task 5, Epoch 17/34 => Loss 3.983, Loss_clf 0.771, Loss_fe 0.983, Loss_kd 1.925, Train_accy 46.21
2022-09-28 00:26:13,668 [foster.py] => Task 5, Epoch 18/34 => Loss 3.938, Loss_clf 0.750, Loss_fe 0.959, Loss_kd 1.925, Train_accy 48.90
2022-09-28 00:26:15,783 [foster.py] => Task 5, Epoch 19/34 => Loss 3.970, Loss_clf 0.765, Loss_fe 0.972, Loss_kd 1.929, Train_accy 48.60
2022-09-28 00:26:17,906 [foster.py] => Task 5, Epoch 20/34 => Loss 3.892, Loss_clf 0.735, Loss_fe 0.924, Loss_kd 1.929, Train_accy 49.60
2022-09-28 00:26:20,986 [foster.py] => Task 5, Epoch 21/34 => Loss 3.903, Loss_clf 0.752, Loss_fe 0.926, Loss_kd 1.921, Train_accy 49.00, Test_accy 42.57
2022-09-28 00:26:23,107 [foster.py] => Task 5, Epoch 22/34 => Loss 3.887, Loss_clf 0.733, Loss_fe 0.922, Loss_kd 1.928, Train_accy 49.10
2022-09-28 00:26:25,206 [foster.py] => Task 5, Epoch 23/34 => Loss 3.850, Loss_clf 0.725, Loss_fe 0.891, Loss_kd 1.930, Train_accy 48.60
2022-09-28 00:26:27,281 [foster.py] => Task 5, Epoch 24/34 => Loss 3.818, Loss_clf 0.713, Loss_fe 0.879, Loss_kd 1.923, Train_accy 50.60
2022-09-28 00:26:29,381 [foster.py] => Task 5, Epoch 25/34 => Loss 3.850, Loss_clf 0.732, Loss_fe 0.890, Loss_kd 1.924, Train_accy 49.50
2022-09-28 00:26:32,469 [foster.py] => Task 5, Epoch 26/34 => Loss 3.820, Loss_clf 0.717, Loss_fe 0.879, Loss_kd 1.920, Train_accy 50.90, Test_accy 41.78
2022-09-28 00:26:34,570 [foster.py] => Task 5, Epoch 27/34 => Loss 3.830, Loss_clf 0.725, Loss_fe 0.878, Loss_kd 1.923, Train_accy 48.80
2022-09-28 00:26:36,645 [foster.py] => Task 5, Epoch 28/34 => Loss 3.806, Loss_clf 0.709, Loss_fe 0.870, Loss_kd 1.924, Train_accy 50.60
2022-09-28 00:26:38,722 [foster.py] => Task 5, Epoch 29/34 => Loss 3.838, Loss_clf 0.719, Loss_fe 0.893, Loss_kd 1.922, Train_accy 49.90
2022-09-28 00:26:40,866 [foster.py] => Task 5, Epoch 30/34 => Loss 3.792, Loss_clf 0.697, Loss_fe 0.862, Loss_kd 1.928, Train_accy 51.50
2022-09-28 00:26:43,925 [foster.py] => Task 5, Epoch 31/34 => Loss 3.806, Loss_clf 0.706, Loss_fe 0.865, Loss_kd 1.930, Train_accy 50.00, Test_accy 42.18
2022-09-28 00:26:46,027 [foster.py] => Task 5, Epoch 32/34 => Loss 3.845, Loss_clf 0.728, Loss_fe 0.887, Loss_kd 1.926, Train_accy 49.20
2022-09-28 00:26:48,145 [foster.py] => Task 5, Epoch 33/34 => Loss 3.805, Loss_clf 0.714, Loss_fe 0.862, Loss_kd 1.925, Train_accy 51.40
2022-09-28 00:26:50,261 [foster.py] => Task 5, Epoch 34/34 => Loss 3.827, Loss_clf 0.712, Loss_fe 0.873, Loss_kd 1.936, Train_accy 52.20
2022-09-28 00:26:50,261 [foster.py] => do not weight align teacher!
2022-09-28 00:26:50,262 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 00:26:53,745 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.450,  Train_accy 19.26, Test_accy 33.27
2022-09-28 00:26:56,083 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.425,  Train_accy 20.36
2022-09-28 00:26:58,447 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.420,  Train_accy 20.36
2022-09-28 00:27:00,795 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.415,  Train_accy 21.06
2022-09-28 00:27:03,142 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.404,  Train_accy 21.56
2022-09-28 00:27:06,338 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.395,  Train_accy 21.26, Test_accy 35.45
2022-09-28 00:27:08,698 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.407,  Train_accy 21.26
2022-09-28 00:27:11,035 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.386,  Train_accy 21.36
2022-09-28 00:27:13,384 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.391,  Train_accy 21.36
2022-09-28 00:27:15,721 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.376,  Train_accy 21.06
2022-09-28 00:27:18,980 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.379,  Train_accy 21.66, Test_accy 37.03
2022-09-28 00:27:21,342 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.384,  Train_accy 21.36
2022-09-28 00:27:23,679 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.384,  Train_accy 22.85
2022-09-28 00:27:26,030 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.381,  Train_accy 22.26
2022-09-28 00:27:28,354 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.378,  Train_accy 20.66
2022-09-28 00:27:31,547 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.377,  Train_accy 22.26, Test_accy 37.23
2022-09-28 00:27:33,930 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.366,  Train_accy 21.96
2022-09-28 00:27:36,302 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.377,  Train_accy 20.56
2022-09-28 00:27:38,652 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.358,  Train_accy 20.96
2022-09-28 00:27:40,981 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.374,  Train_accy 21.16
2022-09-28 00:27:44,221 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.366,  Train_accy 21.96, Test_accy 37.43
2022-09-28 00:27:46,594 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.379,  Train_accy 21.96
2022-09-28 00:27:48,928 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.373,  Train_accy 22.06
2022-09-28 00:27:51,287 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.377,  Train_accy 21.46
2022-09-28 00:27:53,635 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.362,  Train_accy 21.46
2022-09-28 00:27:56,807 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.364,  Train_accy 21.66, Test_accy 37.62
2022-09-28 00:27:56,808 [foster.py] => do not weight align student!
2022-09-28 00:27:57,734 [foster.py] => darknet eval: 
2022-09-28 00:27:57,734 [foster.py] => CNN top1 curve: 37.62
2022-09-28 00:27:57,734 [foster.py] => CNN top5 curve: 82.18
2022-09-28 00:27:57,734 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 00:28:08,315 [foster.py] => Exemplar size: 440
2022-09-28 00:28:08,315 [trainer.py] => CNN: {'total': 42.18, 'old': 43.86, 'new': 30.77, 'base': 66.89, 'compound': 31.93}
2022-09-28 00:28:08,315 [trainer.py] => CNN top1 curve: [87.16, 72.97, 60.21, 50.69, 47.73, 42.18]
2022-09-28 00:28:08,315 [trainer.py] => CNN base curve: [87.16, 86.49, 81.76, 76.35, 72.97, 66.89]
2022-09-28 00:28:08,315 [trainer.py] => CNN old curve: [87.16, 86.49, 68.47, 54.67, 49.86, 43.86]
2022-09-28 00:28:08,315 [trainer.py] => CNN new curve: [0, 45.95, 32.84, 34.72, 37.97, 30.77]
2022-09-28 00:28:08,315 [trainer.py] => CNN compound curve: [0, 45.95, 37.59, 32.86, 34.93, 31.93]
2022-09-28 00:28:08,315 [trainer.py] => NME: {'total': 47.13, 'old': 47.05, 'new': 47.69, 'base': 63.51, 'compound': 40.34}
2022-09-28 00:28:08,315 [trainer.py] => NME top1 curve: [88.51, 76.13, 62.98, 55.96, 52.95, 47.13]
2022-09-28 00:28:08,315 [trainer.py] => NME base curve: [88.51, 81.08, 70.27, 66.22, 64.19, 63.51]
2022-09-28 00:28:08,315 [trainer.py] => NME old curve: [88.51, 81.08, 66.67, 58.48, 52.35, 47.05]
2022-09-28 00:28:08,315 [trainer.py] => NME new curve: [0, 66.22, 50.75, 45.83, 55.7, 47.69]
2022-09-28 00:28:08,315 [trainer.py] => NME compound curve: [0, 66.22, 55.32, 48.83, 47.26, 40.34]
2022-09-28 00:28:08,316 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 00:28:08,316 [trainer.py] => prefix: cil
2022-09-28 00:28:08,316 [trainer.py] => dataset: CFEE
2022-09-28 00:28:08,316 [trainer.py] => memory_size: 2000
2022-09-28 00:28:08,316 [trainer.py] => memory_per_class: 20
2022-09-28 00:28:08,316 [trainer.py] => fixed_memory: True
2022-09-28 00:28:08,317 [trainer.py] => shuffle: True
2022-09-28 00:28:08,317 [trainer.py] => init_cls: 7
2022-09-28 00:28:08,317 [trainer.py] => increment: 3
2022-09-28 00:28:08,317 [trainer.py] => model_name: foster
2022-09-28 00:28:08,317 [trainer.py] => convnet_type: resnet18
2022-09-28 00:28:08,317 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 00:28:08,317 [trainer.py] => seed: 1993
2022-09-28 00:28:08,317 [trainer.py] => beta1: 0.96
2022-09-28 00:28:08,317 [trainer.py] => beta2: 0.97
2022-09-28 00:28:08,317 [trainer.py] => oofc: ft
2022-09-28 00:28:08,317 [trainer.py] => is_teacher_wa: False
2022-09-28 00:28:08,317 [trainer.py] => is_student_wa: False
2022-09-28 00:28:08,317 [trainer.py] => lambda_okd: 1
2022-09-28 00:28:08,317 [trainer.py] => wa_value: 1
2022-09-28 00:28:08,317 [trainer.py] => init_epochs: 40
2022-09-28 00:28:08,317 [trainer.py] => init_lr: 0.01
2022-09-28 00:28:08,317 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 00:28:08,317 [trainer.py] => boosting_epochs: 34
2022-09-28 00:28:08,317 [trainer.py] => compression_epochs: 26
2022-09-28 00:28:08,317 [trainer.py] => lr: 0.001
2022-09-28 00:28:08,317 [trainer.py] => batch_size: 32
2022-09-28 00:28:08,317 [trainer.py] => weight_decay: 0.0005
2022-09-28 00:28:08,317 [trainer.py] => num_workers: 8
2022-09-28 00:28:08,317 [trainer.py] => T: 2
2022-09-28 00:28:08,317 [trainer.py] => nb_runs: 3
2022-09-28 00:28:08,317 [trainer.py] => fold: 10
2022-09-28 00:28:08,317 [data.py] => ========== Fold:2 ==========
2022-09-28 00:28:08,323 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 13, 17, 15, 9, 11, 20, 18, 12, 14, 7, 10, 19, 21, 16, 8]
2022-09-28 00:28:08,534 [foster.py] => Learning on 0-7
2022-09-28 00:28:08,534 [foster.py] => All params: 11183694
2022-09-28 00:28:08,534 [foster.py] => Trainable params: 11183694
2022-09-28 00:28:10,901 [foster.py] => Task 0, Epoch 1/40 => Loss 1.417, Train_accy 45.96
2022-09-28 00:28:13,927 [foster.py] => Task 0, Epoch 2/40 => Loss 0.569, Train_accy 80.95, Test_accy 79.75
2022-09-28 00:28:16,934 [foster.py] => Task 0, Epoch 3/40 => Loss 0.353, Train_accy 88.47, Test_accy 82.28
2022-09-28 00:28:19,934 [foster.py] => Task 0, Epoch 4/40 => Loss 0.277, Train_accy 90.48, Test_accy 81.65
2022-09-28 00:28:22,935 [foster.py] => Task 0, Epoch 5/40 => Loss 0.240, Train_accy 91.51, Test_accy 85.44
2022-09-28 00:28:25,320 [foster.py] => Task 0, Epoch 6/40 => Loss 0.189, Train_accy 93.58
2022-09-28 00:28:28,279 [foster.py] => Task 0, Epoch 7/40 => Loss 0.155, Train_accy 95.51, Test_accy 85.44
2022-09-28 00:28:31,263 [foster.py] => Task 0, Epoch 8/40 => Loss 0.139, Train_accy 94.82, Test_accy 86.71
2022-09-28 00:28:34,256 [foster.py] => Task 0, Epoch 9/40 => Loss 0.102, Train_accy 96.27, Test_accy 82.91
2022-09-28 00:28:37,245 [foster.py] => Task 0, Epoch 10/40 => Loss 0.092, Train_accy 97.31, Test_accy 82.28
2022-09-28 00:28:39,602 [foster.py] => Task 0, Epoch 11/40 => Loss 0.095, Train_accy 96.76
2022-09-28 00:28:42,615 [foster.py] => Task 0, Epoch 12/40 => Loss 0.077, Train_accy 97.24, Test_accy 84.18
2022-09-28 00:28:45,618 [foster.py] => Task 0, Epoch 13/40 => Loss 0.082, Train_accy 97.86, Test_accy 84.81
2022-09-28 00:28:48,590 [foster.py] => Task 0, Epoch 14/40 => Loss 0.066, Train_accy 97.86, Test_accy 84.81
2022-09-28 00:28:51,548 [foster.py] => Task 0, Epoch 15/40 => Loss 0.053, Train_accy 98.27, Test_accy 84.81
2022-09-28 00:28:53,886 [foster.py] => Task 0, Epoch 16/40 => Loss 0.046, Train_accy 98.62
2022-09-28 00:28:56,867 [foster.py] => Task 0, Epoch 17/40 => Loss 0.048, Train_accy 98.48, Test_accy 84.18
2022-09-28 00:28:59,903 [foster.py] => Task 0, Epoch 18/40 => Loss 0.037, Train_accy 99.10, Test_accy 86.08
2022-09-28 00:29:02,887 [foster.py] => Task 0, Epoch 19/40 => Loss 0.038, Train_accy 98.76, Test_accy 86.08
2022-09-28 00:29:05,838 [foster.py] => Task 0, Epoch 20/40 => Loss 0.028, Train_accy 99.31, Test_accy 85.44
2022-09-28 00:29:08,234 [foster.py] => Task 0, Epoch 21/40 => Loss 0.026, Train_accy 99.45
2022-09-28 00:29:11,252 [foster.py] => Task 0, Epoch 22/40 => Loss 0.023, Train_accy 99.52, Test_accy 86.71
2022-09-28 00:29:14,256 [foster.py] => Task 0, Epoch 23/40 => Loss 0.021, Train_accy 99.59, Test_accy 86.08
2022-09-28 00:29:17,262 [foster.py] => Task 0, Epoch 24/40 => Loss 0.033, Train_accy 99.38, Test_accy 85.44
2022-09-28 00:29:20,265 [foster.py] => Task 0, Epoch 25/40 => Loss 0.025, Train_accy 99.72, Test_accy 86.08
2022-09-28 00:29:22,646 [foster.py] => Task 0, Epoch 26/40 => Loss 0.022, Train_accy 99.65
2022-09-28 00:29:25,612 [foster.py] => Task 0, Epoch 27/40 => Loss 0.026, Train_accy 99.52, Test_accy 84.81
2022-09-28 00:29:28,595 [foster.py] => Task 0, Epoch 28/40 => Loss 0.020, Train_accy 99.72, Test_accy 83.54
2022-09-28 00:29:31,587 [foster.py] => Task 0, Epoch 29/40 => Loss 0.018, Train_accy 99.72, Test_accy 84.18
2022-09-28 00:29:34,535 [foster.py] => Task 0, Epoch 30/40 => Loss 0.020, Train_accy 99.52, Test_accy 84.81
2022-09-28 00:29:36,975 [foster.py] => Task 0, Epoch 31/40 => Loss 0.015, Train_accy 99.93
2022-09-28 00:29:39,919 [foster.py] => Task 0, Epoch 32/40 => Loss 0.018, Train_accy 99.79, Test_accy 84.18
2022-09-28 00:29:42,904 [foster.py] => Task 0, Epoch 33/40 => Loss 0.016, Train_accy 99.72, Test_accy 84.18
2022-09-28 00:29:45,880 [foster.py] => Task 0, Epoch 34/40 => Loss 0.016, Train_accy 99.86, Test_accy 84.18
2022-09-28 00:29:48,921 [foster.py] => Task 0, Epoch 35/40 => Loss 0.012, Train_accy 99.86, Test_accy 84.18
2022-09-28 00:29:51,356 [foster.py] => Task 0, Epoch 36/40 => Loss 0.017, Train_accy 99.65
2022-09-28 00:29:54,367 [foster.py] => Task 0, Epoch 37/40 => Loss 0.013, Train_accy 99.72, Test_accy 85.44
2022-09-28 00:29:57,348 [foster.py] => Task 0, Epoch 38/40 => Loss 0.013, Train_accy 99.79, Test_accy 84.81
2022-09-28 00:30:00,319 [foster.py] => Task 0, Epoch 39/40 => Loss 0.014, Train_accy 99.93, Test_accy 83.54
2022-09-28 00:30:03,373 [foster.py] => Task 0, Epoch 40/40 => Loss 0.015, Train_accy 99.79, Test_accy 84.81
2022-09-28 00:30:03,374 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 00:30:10,194 [foster.py] => Exemplar size: 140
2022-09-28 00:30:10,194 [trainer.py] => CNN: {'total': 84.81, 'old': 84.81, 'new': 0, 'base': 84.81, 'compound': 0}
2022-09-28 00:30:10,194 [trainer.py] => CNN top1 curve: [84.81]
2022-09-28 00:30:10,194 [trainer.py] => CNN base curve: [84.81]
2022-09-28 00:30:10,195 [trainer.py] => CNN old curve: [84.81]
2022-09-28 00:30:10,195 [trainer.py] => CNN new curve: [0]
2022-09-28 00:30:10,195 [trainer.py] => CNN compound curve: [0]
2022-09-28 00:30:10,195 [trainer.py] => NME: {'total': 85.44, 'old': 85.44, 'new': 0, 'base': 85.44, 'compound': 0}
2022-09-28 00:30:10,195 [trainer.py] => NME top1 curve: [85.44]
2022-09-28 00:30:10,195 [trainer.py] => NME base curve: [85.44]
2022-09-28 00:30:10,195 [trainer.py] => NME old curve: [85.44]
2022-09-28 00:30:10,195 [trainer.py] => NME new curve: [0]
2022-09-28 00:30:10,195 [trainer.py] => NME compound curve: [0]
2022-09-28 00:30:10,422 [foster.py] => Learning on 7-10
2022-09-28 00:30:10,423 [foster.py] => All params: 22371995
2022-09-28 00:30:10,423 [foster.py] => Trainable params: 11191892
2022-09-28 00:30:10,443 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 00:30:12,890 [foster.py] => Task 1, Epoch 1/34 => Loss 4.729, Loss_clf 2.156, Loss_fe 1.876, Loss_kd 0.488, Train_accy 39.16, Test_accy 71.11
2022-09-28 00:30:14,601 [foster.py] => Task 1, Epoch 2/34 => Loss 2.424, Loss_clf 0.603, Loss_fe 1.114, Loss_kd 0.495, Train_accy 75.43
2022-09-28 00:30:16,366 [foster.py] => Task 1, Epoch 3/34 => Loss 1.955, Loss_clf 0.370, Loss_fe 0.902, Loss_kd 0.479, Train_accy 55.06
2022-09-28 00:30:18,129 [foster.py] => Task 1, Epoch 4/34 => Loss 1.821, Loss_clf 0.343, Loss_fe 0.788, Loss_kd 0.483, Train_accy 55.19
2022-09-28 00:30:19,877 [foster.py] => Task 1, Epoch 5/34 => Loss 1.700, Loss_clf 0.327, Loss_fe 0.697, Loss_kd 0.473, Train_accy 57.29
2022-09-28 00:30:22,384 [foster.py] => Task 1, Epoch 6/34 => Loss 1.616, Loss_clf 0.308, Loss_fe 0.634, Loss_kd 0.472, Train_accy 54.93, Test_accy 68.00
2022-09-28 00:30:24,138 [foster.py] => Task 1, Epoch 7/34 => Loss 1.552, Loss_clf 0.289, Loss_fe 0.582, Loss_kd 0.477, Train_accy 56.37
2022-09-28 00:30:25,888 [foster.py] => Task 1, Epoch 8/34 => Loss 1.519, Loss_clf 0.289, Loss_fe 0.547, Loss_kd 0.478, Train_accy 56.90
2022-09-28 00:30:27,643 [foster.py] => Task 1, Epoch 9/34 => Loss 1.459, Loss_clf 0.268, Loss_fe 0.511, Loss_kd 0.476, Train_accy 57.03
2022-09-28 00:30:29,456 [foster.py] => Task 1, Epoch 10/34 => Loss 1.441, Loss_clf 0.273, Loss_fe 0.490, Loss_kd 0.475, Train_accy 56.50
2022-09-28 00:30:31,999 [foster.py] => Task 1, Epoch 11/34 => Loss 1.387, Loss_clf 0.259, Loss_fe 0.456, Loss_kd 0.470, Train_accy 56.24, Test_accy 67.56
2022-09-28 00:30:33,729 [foster.py] => Task 1, Epoch 12/34 => Loss 1.402, Loss_clf 0.269, Loss_fe 0.456, Loss_kd 0.474, Train_accy 58.61
2022-09-28 00:30:35,459 [foster.py] => Task 1, Epoch 13/34 => Loss 1.341, Loss_clf 0.247, Loss_fe 0.423, Loss_kd 0.470, Train_accy 56.64
2022-09-28 00:30:37,162 [foster.py] => Task 1, Epoch 14/34 => Loss 1.292, Loss_clf 0.225, Loss_fe 0.398, Loss_kd 0.468, Train_accy 57.29
2022-09-28 00:30:38,893 [foster.py] => Task 1, Epoch 15/34 => Loss 1.311, Loss_clf 0.238, Loss_fe 0.401, Loss_kd 0.470, Train_accy 57.16
2022-09-28 00:30:41,411 [foster.py] => Task 1, Epoch 16/34 => Loss 1.283, Loss_clf 0.221, Loss_fe 0.381, Loss_kd 0.477, Train_accy 58.74, Test_accy 67.11
2022-09-28 00:30:43,160 [foster.py] => Task 1, Epoch 17/34 => Loss 1.259, Loss_clf 0.218, Loss_fe 0.366, Loss_kd 0.472, Train_accy 57.82
2022-09-28 00:30:44,905 [foster.py] => Task 1, Epoch 18/34 => Loss 1.251, Loss_clf 0.221, Loss_fe 0.361, Loss_kd 0.468, Train_accy 58.21
2022-09-28 00:30:46,634 [foster.py] => Task 1, Epoch 19/34 => Loss 1.223, Loss_clf 0.209, Loss_fe 0.344, Loss_kd 0.469, Train_accy 58.08
2022-09-28 00:30:48,426 [foster.py] => Task 1, Epoch 20/34 => Loss 1.222, Loss_clf 0.207, Loss_fe 0.343, Loss_kd 0.470, Train_accy 58.48
2022-09-28 00:30:50,928 [foster.py] => Task 1, Epoch 21/34 => Loss 1.223, Loss_clf 0.209, Loss_fe 0.337, Loss_kd 0.474, Train_accy 60.84, Test_accy 68.00
2022-09-28 00:30:52,690 [foster.py] => Task 1, Epoch 22/34 => Loss 1.217, Loss_clf 0.210, Loss_fe 0.342, Loss_kd 0.466, Train_accy 57.03
2022-09-28 00:30:54,420 [foster.py] => Task 1, Epoch 23/34 => Loss 1.188, Loss_clf 0.191, Loss_fe 0.323, Loss_kd 0.472, Train_accy 60.18
2022-09-28 00:30:56,122 [foster.py] => Task 1, Epoch 24/34 => Loss 1.219, Loss_clf 0.207, Loss_fe 0.331, Loss_kd 0.477, Train_accy 59.26
2022-09-28 00:30:57,825 [foster.py] => Task 1, Epoch 25/34 => Loss 1.194, Loss_clf 0.197, Loss_fe 0.322, Loss_kd 0.473, Train_accy 59.79
2022-09-28 00:31:00,358 [foster.py] => Task 1, Epoch 26/34 => Loss 1.200, Loss_clf 0.204, Loss_fe 0.326, Loss_kd 0.469, Train_accy 57.95, Test_accy 67.56
2022-09-28 00:31:02,115 [foster.py] => Task 1, Epoch 27/34 => Loss 1.195, Loss_clf 0.198, Loss_fe 0.329, Loss_kd 0.468, Train_accy 57.82
2022-09-28 00:31:03,867 [foster.py] => Task 1, Epoch 28/34 => Loss 1.201, Loss_clf 0.198, Loss_fe 0.315, Loss_kd 0.481, Train_accy 59.40
2022-09-28 00:31:05,628 [foster.py] => Task 1, Epoch 29/34 => Loss 1.164, Loss_clf 0.185, Loss_fe 0.312, Loss_kd 0.468, Train_accy 58.21
2022-09-28 00:31:07,396 [foster.py] => Task 1, Epoch 30/34 => Loss 1.160, Loss_clf 0.181, Loss_fe 0.308, Loss_kd 0.470, Train_accy 60.84
2022-09-28 00:31:09,911 [foster.py] => Task 1, Epoch 31/34 => Loss 1.193, Loss_clf 0.196, Loss_fe 0.318, Loss_kd 0.475, Train_accy 60.71, Test_accy 68.00
2022-09-28 00:31:11,609 [foster.py] => Task 1, Epoch 32/34 => Loss 1.190, Loss_clf 0.197, Loss_fe 0.314, Loss_kd 0.475, Train_accy 59.79
2022-09-28 00:31:13,347 [foster.py] => Task 1, Epoch 33/34 => Loss 1.167, Loss_clf 0.183, Loss_fe 0.313, Loss_kd 0.469, Train_accy 59.66
2022-09-28 00:31:15,098 [foster.py] => Task 1, Epoch 34/34 => Loss 1.191, Loss_clf 0.199, Loss_fe 0.316, Loss_kd 0.473, Train_accy 60.58
2022-09-28 00:31:15,098 [foster.py] => do not weight align teacher!
2022-09-28 00:31:15,099 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 00:31:17,968 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.543,  Train_accy 17.61, Test_accy 59.56
2022-09-28 00:31:19,914 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.420,  Train_accy 18.00
2022-09-28 00:31:21,848 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.344,  Train_accy 18.53
2022-09-28 00:31:23,812 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.301,  Train_accy 19.45
2022-09-28 00:31:25,747 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.271,  Train_accy 21.16
2022-09-28 00:31:28,328 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.256,  Train_accy 23.00, Test_accy 60.89
2022-09-28 00:31:30,252 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.242,  Train_accy 24.44
2022-09-28 00:31:32,156 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.228,  Train_accy 26.15
2022-09-28 00:31:34,069 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.229,  Train_accy 26.54
2022-09-28 00:31:36,089 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.219,  Train_accy 26.68
2022-09-28 00:31:38,700 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.216,  Train_accy 28.38, Test_accy 61.33
2022-09-28 00:31:40,595 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.207,  Train_accy 29.83
2022-09-28 00:31:42,578 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.196,  Train_accy 30.49
2022-09-28 00:31:44,487 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.210,  Train_accy 30.75
2022-09-28 00:31:46,417 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.197,  Train_accy 30.49
2022-09-28 00:31:49,098 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.198,  Train_accy 30.88, Test_accy 62.22
2022-09-28 00:31:51,023 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.195,  Train_accy 31.80
2022-09-28 00:31:52,977 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.178,  Train_accy 30.49
2022-09-28 00:31:54,950 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.211,  Train_accy 32.46
2022-09-28 00:31:56,877 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.184,  Train_accy 32.19
2022-09-28 00:31:59,479 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.185,  Train_accy 32.19, Test_accy 62.67
2022-09-28 00:32:01,421 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.188,  Train_accy 31.80
2022-09-28 00:32:03,401 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.198,  Train_accy 32.85
2022-09-28 00:32:05,372 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.180,  Train_accy 32.06
2022-09-28 00:32:07,312 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.191,  Train_accy 31.14
2022-09-28 00:32:09,938 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.178,  Train_accy 32.46, Test_accy 61.78
2022-09-28 00:32:09,938 [foster.py] => do not weight align student!
2022-09-28 00:32:10,609 [foster.py] => darknet eval: 
2022-09-28 00:32:10,609 [foster.py] => CNN top1 curve: 61.78
2022-09-28 00:32:10,609 [foster.py] => CNN top5 curve: 98.67
2022-09-28 00:32:10,609 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 00:32:16,869 [foster.py] => Exemplar size: 200
2022-09-28 00:32:16,870 [trainer.py] => CNN: {'total': 68.0, 'old': 78.48, 'new': 43.28, 'base': 78.48, 'compound': 43.28}
2022-09-28 00:32:16,870 [trainer.py] => CNN top1 curve: [84.81, 68.0]
2022-09-28 00:32:16,870 [trainer.py] => CNN base curve: [84.81, 78.48]
2022-09-28 00:32:16,870 [trainer.py] => CNN old curve: [84.81, 78.48]
2022-09-28 00:32:16,870 [trainer.py] => CNN new curve: [0, 43.28]
2022-09-28 00:32:16,870 [trainer.py] => CNN compound curve: [0, 43.28]
2022-09-28 00:32:16,870 [trainer.py] => NME: {'total': 78.67, 'old': 82.91, 'new': 68.66, 'base': 82.91, 'compound': 68.66}
2022-09-28 00:32:16,870 [trainer.py] => NME top1 curve: [85.44, 78.67]
2022-09-28 00:32:16,870 [trainer.py] => NME base curve: [85.44, 82.91]
2022-09-28 00:32:16,870 [trainer.py] => NME old curve: [85.44, 82.91]
2022-09-28 00:32:16,870 [trainer.py] => NME new curve: [0, 68.66]
2022-09-28 00:32:16,870 [trainer.py] => NME compound curve: [0, 68.66]
2022-09-28 00:32:17,099 [foster.py] => Learning on 10-13
2022-09-28 00:32:17,100 [foster.py] => All params: 22378148
2022-09-28 00:32:17,100 [foster.py] => Trainable params: 11196506
2022-09-28 00:32:17,120 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 00:32:19,720 [foster.py] => Task 2, Epoch 1/34 => Loss 5.320, Loss_clf 2.141, Loss_fe 2.115, Loss_kd 0.818, Train_accy 37.33, Test_accy 49.32
2022-09-28 00:32:21,558 [foster.py] => Task 2, Epoch 2/34 => Loss 3.418, Loss_clf 0.914, Loss_fe 1.441, Loss_kd 0.818, Train_accy 48.35
2022-09-28 00:32:23,424 [foster.py] => Task 2, Epoch 3/34 => Loss 2.969, Loss_clf 0.706, Loss_fe 1.227, Loss_kd 0.797, Train_accy 37.82
2022-09-28 00:32:25,262 [foster.py] => Task 2, Epoch 4/34 => Loss 2.848, Loss_clf 0.686, Loss_fe 1.115, Loss_kd 0.806, Train_accy 41.98
2022-09-28 00:32:27,096 [foster.py] => Task 2, Epoch 5/34 => Loss 2.660, Loss_clf 0.633, Loss_fe 0.996, Loss_kd 0.793, Train_accy 37.45
2022-09-28 00:32:29,715 [foster.py] => Task 2, Epoch 6/34 => Loss 2.551, Loss_clf 0.575, Loss_fe 0.935, Loss_kd 0.801, Train_accy 41.25, Test_accy 56.42
2022-09-28 00:32:31,506 [foster.py] => Task 2, Epoch 7/34 => Loss 2.465, Loss_clf 0.560, Loss_fe 0.873, Loss_kd 0.794, Train_accy 42.35
2022-09-28 00:32:33,353 [foster.py] => Task 2, Epoch 8/34 => Loss 2.412, Loss_clf 0.549, Loss_fe 0.830, Loss_kd 0.795, Train_accy 42.23
2022-09-28 00:32:35,187 [foster.py] => Task 2, Epoch 9/34 => Loss 2.354, Loss_clf 0.532, Loss_fe 0.795, Loss_kd 0.790, Train_accy 41.13
2022-09-28 00:32:37,020 [foster.py] => Task 2, Epoch 10/34 => Loss 2.298, Loss_clf 0.526, Loss_fe 0.746, Loss_kd 0.789, Train_accy 43.21
2022-09-28 00:32:39,632 [foster.py] => Task 2, Epoch 11/34 => Loss 2.263, Loss_clf 0.502, Loss_fe 0.732, Loss_kd 0.791, Train_accy 41.37, Test_accy 58.11
2022-09-28 00:32:41,419 [foster.py] => Task 2, Epoch 12/34 => Loss 2.259, Loss_clf 0.507, Loss_fe 0.719, Loss_kd 0.795, Train_accy 44.31
2022-09-28 00:32:43,261 [foster.py] => Task 2, Epoch 13/34 => Loss 2.222, Loss_clf 0.498, Loss_fe 0.695, Loss_kd 0.792, Train_accy 43.33
2022-09-28 00:32:45,077 [foster.py] => Task 2, Epoch 14/34 => Loss 2.176, Loss_clf 0.491, Loss_fe 0.662, Loss_kd 0.787, Train_accy 41.13
2022-09-28 00:32:46,911 [foster.py] => Task 2, Epoch 15/34 => Loss 2.186, Loss_clf 0.491, Loss_fe 0.655, Loss_kd 0.800, Train_accy 47.49
2022-09-28 00:32:49,599 [foster.py] => Task 2, Epoch 16/34 => Loss 2.149, Loss_clf 0.470, Loss_fe 0.641, Loss_kd 0.799, Train_accy 43.21, Test_accy 58.78
2022-09-28 00:32:51,443 [foster.py] => Task 2, Epoch 17/34 => Loss 2.093, Loss_clf 0.442, Loss_fe 0.614, Loss_kd 0.798, Train_accy 43.70
2022-09-28 00:32:53,285 [foster.py] => Task 2, Epoch 18/34 => Loss 2.086, Loss_clf 0.449, Loss_fe 0.609, Loss_kd 0.791, Train_accy 43.33
2022-09-28 00:32:55,120 [foster.py] => Task 2, Epoch 19/34 => Loss 2.055, Loss_clf 0.436, Loss_fe 0.585, Loss_kd 0.795, Train_accy 43.57
2022-09-28 00:32:56,971 [foster.py] => Task 2, Epoch 20/34 => Loss 2.032, Loss_clf 0.427, Loss_fe 0.580, Loss_kd 0.789, Train_accy 45.53
2022-09-28 00:32:59,652 [foster.py] => Task 2, Epoch 21/34 => Loss 2.029, Loss_clf 0.425, Loss_fe 0.571, Loss_kd 0.794, Train_accy 44.68, Test_accy 59.80
2022-09-28 00:33:01,483 [foster.py] => Task 2, Epoch 22/34 => Loss 2.046, Loss_clf 0.428, Loss_fe 0.584, Loss_kd 0.794, Train_accy 46.14
2022-09-28 00:33:03,340 [foster.py] => Task 2, Epoch 23/34 => Loss 2.014, Loss_clf 0.415, Loss_fe 0.564, Loss_kd 0.796, Train_accy 46.63
2022-09-28 00:33:05,149 [foster.py] => Task 2, Epoch 24/34 => Loss 2.007, Loss_clf 0.417, Loss_fe 0.557, Loss_kd 0.795, Train_accy 45.53
2022-09-28 00:33:07,000 [foster.py] => Task 2, Epoch 25/34 => Loss 2.036, Loss_clf 0.432, Loss_fe 0.571, Loss_kd 0.795, Train_accy 44.92
2022-09-28 00:33:09,564 [foster.py] => Task 2, Epoch 26/34 => Loss 1.982, Loss_clf 0.399, Loss_fe 0.548, Loss_kd 0.796, Train_accy 45.65, Test_accy 60.47
2022-09-28 00:33:11,386 [foster.py] => Task 2, Epoch 27/34 => Loss 1.961, Loss_clf 0.390, Loss_fe 0.533, Loss_kd 0.798, Train_accy 46.88
2022-09-28 00:33:13,190 [foster.py] => Task 2, Epoch 28/34 => Loss 1.974, Loss_clf 0.404, Loss_fe 0.530, Loss_kd 0.800, Train_accy 45.41
2022-09-28 00:33:14,998 [foster.py] => Task 2, Epoch 29/34 => Loss 1.996, Loss_clf 0.412, Loss_fe 0.547, Loss_kd 0.797, Train_accy 45.65
2022-09-28 00:33:16,789 [foster.py] => Task 2, Epoch 30/34 => Loss 1.981, Loss_clf 0.410, Loss_fe 0.539, Loss_kd 0.793, Train_accy 45.53
2022-09-28 00:33:19,447 [foster.py] => Task 2, Epoch 31/34 => Loss 1.969, Loss_clf 0.399, Loss_fe 0.535, Loss_kd 0.796, Train_accy 46.63, Test_accy 59.46
2022-09-28 00:33:21,239 [foster.py] => Task 2, Epoch 32/34 => Loss 1.993, Loss_clf 0.411, Loss_fe 0.545, Loss_kd 0.798, Train_accy 46.02
2022-09-28 00:33:23,085 [foster.py] => Task 2, Epoch 33/34 => Loss 1.960, Loss_clf 0.397, Loss_fe 0.535, Loss_kd 0.790, Train_accy 46.27
2022-09-28 00:33:24,902 [foster.py] => Task 2, Epoch 34/34 => Loss 1.972, Loss_clf 0.398, Loss_fe 0.540, Loss_kd 0.796, Train_accy 44.43
2022-09-28 00:33:24,902 [foster.py] => do not weight align teacher!
2022-09-28 00:33:24,903 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 00:33:27,888 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.816,  Train_accy 17.26, Test_accy 44.93
2022-09-28 00:33:29,900 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.694,  Train_accy 17.87
2022-09-28 00:33:31,903 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.611,  Train_accy 17.75
2022-09-28 00:33:33,925 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.585,  Train_accy 18.60
2022-09-28 00:33:35,916 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.565,  Train_accy 19.22
2022-09-28 00:33:38,635 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.547,  Train_accy 19.46, Test_accy 50.00
2022-09-28 00:33:40,681 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.546,  Train_accy 19.46
2022-09-28 00:33:42,747 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.526,  Train_accy 19.46
2022-09-28 00:33:44,759 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.521,  Train_accy 19.58
2022-09-28 00:33:46,858 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.524,  Train_accy 19.71
2022-09-28 00:33:49,579 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.513,  Train_accy 19.22, Test_accy 51.01
2022-09-28 00:33:51,618 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.513,  Train_accy 20.32
2022-09-28 00:33:53,618 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.506,  Train_accy 20.56
2022-09-28 00:33:55,615 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.504,  Train_accy 19.46
2022-09-28 00:33:57,674 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.504,  Train_accy 20.81
2022-09-28 00:34:00,474 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.508,  Train_accy 20.93, Test_accy 51.69
2022-09-28 00:34:02,466 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.509,  Train_accy 20.56
2022-09-28 00:34:04,540 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.496,  Train_accy 20.07
2022-09-28 00:34:06,585 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.496,  Train_accy 20.44
2022-09-28 00:34:08,622 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.502,  Train_accy 20.93
2022-09-28 00:34:11,383 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.495,  Train_accy 20.20, Test_accy 52.03
2022-09-28 00:34:13,444 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.497,  Train_accy 20.32
2022-09-28 00:34:15,491 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.497,  Train_accy 20.20
2022-09-28 00:34:17,519 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.500,  Train_accy 19.71
2022-09-28 00:34:19,542 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.495,  Train_accy 21.05
2022-09-28 00:34:22,330 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.491,  Train_accy 20.81, Test_accy 51.69
2022-09-28 00:34:22,330 [foster.py] => do not weight align student!
2022-09-28 00:34:23,055 [foster.py] => darknet eval: 
2022-09-28 00:34:23,055 [foster.py] => CNN top1 curve: 51.69
2022-09-28 00:34:23,055 [foster.py] => CNN top5 curve: 95.61
2022-09-28 00:34:23,055 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 00:34:30,527 [foster.py] => Exemplar size: 260
2022-09-28 00:34:30,527 [trainer.py] => CNN: {'total': 59.12, 'old': 69.33, 'new': 26.76, 'base': 75.32, 'compound': 40.58}
2022-09-28 00:34:30,527 [trainer.py] => CNN top1 curve: [84.81, 68.0, 59.12]
2022-09-28 00:34:30,527 [trainer.py] => CNN base curve: [84.81, 78.48, 75.32]
2022-09-28 00:34:30,527 [trainer.py] => CNN old curve: [84.81, 78.48, 69.33]
2022-09-28 00:34:30,527 [trainer.py] => CNN new curve: [0, 43.28, 26.76]
2022-09-28 00:34:30,527 [trainer.py] => CNN compound curve: [0, 43.28, 40.58]
2022-09-28 00:34:30,527 [trainer.py] => NME: {'total': 66.22, 'old': 70.67, 'new': 52.11, 'base': 71.52, 'compound': 60.14}
2022-09-28 00:34:30,527 [trainer.py] => NME top1 curve: [85.44, 78.67, 66.22]
2022-09-28 00:34:30,527 [trainer.py] => NME base curve: [85.44, 82.91, 71.52]
2022-09-28 00:34:30,527 [trainer.py] => NME old curve: [85.44, 82.91, 70.67]
2022-09-28 00:34:30,527 [trainer.py] => NME new curve: [0, 68.66, 52.11]
2022-09-28 00:34:30,527 [trainer.py] => NME compound curve: [0, 68.66, 60.14]
2022-09-28 00:34:30,759 [foster.py] => Learning on 13-16
2022-09-28 00:34:30,759 [foster.py] => All params: 22384301
2022-09-28 00:34:30,759 [foster.py] => Trainable params: 11201120
2022-09-28 00:34:30,779 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 00:34:33,549 [foster.py] => Task 3, Epoch 1/34 => Loss 5.926, Loss_clf 2.099, Loss_fe 2.184, Loss_kd 1.335, Train_accy 36.94, Test_accy 42.82
2022-09-28 00:34:35,463 [foster.py] => Task 3, Epoch 2/34 => Loss 4.327, Loss_clf 1.024, Loss_fe 1.651, Loss_kd 1.342, Train_accy 42.46
2022-09-28 00:34:37,332 [foster.py] => Task 3, Epoch 3/34 => Loss 4.031, Loss_clf 0.924, Loss_fe 1.488, Loss_kd 1.316, Train_accy 42.00
2022-09-28 00:34:39,290 [foster.py] => Task 3, Epoch 4/34 => Loss 3.905, Loss_clf 0.905, Loss_fe 1.365, Loss_kd 1.329, Train_accy 41.31
2022-09-28 00:34:41,189 [foster.py] => Task 3, Epoch 5/34 => Loss 3.716, Loss_clf 0.827, Loss_fe 1.246, Loss_kd 1.334, Train_accy 41.08
2022-09-28 00:34:43,933 [foster.py] => Task 3, Epoch 6/34 => Loss 3.653, Loss_clf 0.829, Loss_fe 1.191, Loss_kd 1.327, Train_accy 40.74, Test_accy 48.14
2022-09-28 00:34:45,856 [foster.py] => Task 3, Epoch 7/34 => Loss 3.535, Loss_clf 0.795, Loss_fe 1.110, Loss_kd 1.325, Train_accy 41.20
2022-09-28 00:34:47,722 [foster.py] => Task 3, Epoch 8/34 => Loss 3.509, Loss_clf 0.804, Loss_fe 1.074, Loss_kd 1.326, Train_accy 40.62
2022-09-28 00:34:49,646 [foster.py] => Task 3, Epoch 9/34 => Loss 3.406, Loss_clf 0.746, Loss_fe 1.014, Loss_kd 1.338, Train_accy 42.00
2022-09-28 00:34:51,589 [foster.py] => Task 3, Epoch 10/34 => Loss 3.357, Loss_clf 0.741, Loss_fe 0.982, Loss_kd 1.328, Train_accy 43.27
2022-09-28 00:34:54,336 [foster.py] => Task 3, Epoch 11/34 => Loss 3.295, Loss_clf 0.708, Loss_fe 0.947, Loss_kd 1.333, Train_accy 43.84, Test_accy 48.94
2022-09-28 00:34:56,250 [foster.py] => Task 3, Epoch 12/34 => Loss 3.274, Loss_clf 0.713, Loss_fe 0.921, Loss_kd 1.332, Train_accy 44.42
2022-09-28 00:34:58,179 [foster.py] => Task 3, Epoch 13/34 => Loss 3.274, Loss_clf 0.720, Loss_fe 0.913, Loss_kd 1.333, Train_accy 43.27
2022-09-28 00:35:00,058 [foster.py] => Task 3, Epoch 14/34 => Loss 3.237, Loss_clf 0.702, Loss_fe 0.881, Loss_kd 1.344, Train_accy 42.58
2022-09-28 00:35:01,976 [foster.py] => Task 3, Epoch 15/34 => Loss 3.243, Loss_clf 0.722, Loss_fe 0.885, Loss_kd 1.330, Train_accy 45.45
2022-09-28 00:35:04,760 [foster.py] => Task 3, Epoch 16/34 => Loss 3.176, Loss_clf 0.682, Loss_fe 0.852, Loss_kd 1.334, Train_accy 43.50, Test_accy 50.80
2022-09-28 00:35:06,638 [foster.py] => Task 3, Epoch 17/34 => Loss 3.137, Loss_clf 0.665, Loss_fe 0.833, Loss_kd 1.332, Train_accy 45.57
2022-09-28 00:35:08,522 [foster.py] => Task 3, Epoch 18/34 => Loss 3.125, Loss_clf 0.658, Loss_fe 0.823, Loss_kd 1.336, Train_accy 45.80
2022-09-28 00:35:10,419 [foster.py] => Task 3, Epoch 19/34 => Loss 3.136, Loss_clf 0.680, Loss_fe 0.813, Loss_kd 1.335, Train_accy 41.08
2022-09-28 00:35:12,351 [foster.py] => Task 3, Epoch 20/34 => Loss 3.135, Loss_clf 0.667, Loss_fe 0.821, Loss_kd 1.339, Train_accy 46.95
2022-09-28 00:35:15,071 [foster.py] => Task 3, Epoch 21/34 => Loss 3.155, Loss_clf 0.695, Loss_fe 0.824, Loss_kd 1.330, Train_accy 43.96, Test_accy 51.06
2022-09-28 00:35:16,997 [foster.py] => Task 3, Epoch 22/34 => Loss 3.098, Loss_clf 0.659, Loss_fe 0.786, Loss_kd 1.343, Train_accy 47.07
2022-09-28 00:35:18,907 [foster.py] => Task 3, Epoch 23/34 => Loss 3.064, Loss_clf 0.638, Loss_fe 0.766, Loss_kd 1.349, Train_accy 46.38
2022-09-28 00:35:20,887 [foster.py] => Task 3, Epoch 24/34 => Loss 3.081, Loss_clf 0.644, Loss_fe 0.789, Loss_kd 1.339, Train_accy 44.76
2022-09-28 00:35:22,763 [foster.py] => Task 3, Epoch 25/34 => Loss 3.051, Loss_clf 0.630, Loss_fe 0.791, Loss_kd 1.324, Train_accy 43.96
2022-09-28 00:35:25,509 [foster.py] => Task 3, Epoch 26/34 => Loss 3.006, Loss_clf 0.621, Loss_fe 0.748, Loss_kd 1.330, Train_accy 44.19, Test_accy 51.33
2022-09-28 00:35:27,380 [foster.py] => Task 3, Epoch 27/34 => Loss 3.079, Loss_clf 0.652, Loss_fe 0.769, Loss_kd 1.347, Train_accy 47.64
2022-09-28 00:35:29,242 [foster.py] => Task 3, Epoch 28/34 => Loss 3.031, Loss_clf 0.632, Loss_fe 0.741, Loss_kd 1.347, Train_accy 47.87
2022-09-28 00:35:31,155 [foster.py] => Task 3, Epoch 29/34 => Loss 2.994, Loss_clf 0.605, Loss_fe 0.742, Loss_kd 1.338, Train_accy 45.11
2022-09-28 00:35:33,084 [foster.py] => Task 3, Epoch 30/34 => Loss 3.023, Loss_clf 0.622, Loss_fe 0.745, Loss_kd 1.346, Train_accy 46.38
2022-09-28 00:35:35,855 [foster.py] => Task 3, Epoch 31/34 => Loss 3.005, Loss_clf 0.612, Loss_fe 0.741, Loss_kd 1.342, Train_accy 47.30, Test_accy 51.60
2022-09-28 00:35:37,771 [foster.py] => Task 3, Epoch 32/34 => Loss 3.002, Loss_clf 0.622, Loss_fe 0.740, Loss_kd 1.332, Train_accy 46.26
2022-09-28 00:35:39,669 [foster.py] => Task 3, Epoch 33/34 => Loss 3.017, Loss_clf 0.604, Loss_fe 0.749, Loss_kd 1.352, Train_accy 47.41
2022-09-28 00:35:41,608 [foster.py] => Task 3, Epoch 34/34 => Loss 3.021, Loss_clf 0.628, Loss_fe 0.760, Loss_kd 1.327, Train_accy 44.53
2022-09-28 00:35:41,608 [foster.py] => do not weight align teacher!
2022-09-28 00:35:41,609 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 00:35:44,714 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.116,  Train_accy 17.95, Test_accy 39.36
2022-09-28 00:35:46,856 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.060,  Train_accy 18.41
2022-09-28 00:35:48,971 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.008,  Train_accy 18.53
2022-09-28 00:35:51,098 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 1.999,  Train_accy 19.68
2022-09-28 00:35:53,269 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.991,  Train_accy 19.68
2022-09-28 00:35:56,188 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.998,  Train_accy 19.10, Test_accy 42.29
2022-09-28 00:35:58,299 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.987,  Train_accy 19.79
2022-09-28 00:36:00,435 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.993,  Train_accy 19.79
2022-09-28 00:36:02,528 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.975,  Train_accy 19.45
2022-09-28 00:36:04,652 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.965,  Train_accy 19.33
2022-09-28 00:36:07,592 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.973,  Train_accy 19.91, Test_accy 42.55
2022-09-28 00:36:09,724 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.978,  Train_accy 19.79
2022-09-28 00:36:11,856 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.969,  Train_accy 20.02
2022-09-28 00:36:14,008 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.970,  Train_accy 19.45
2022-09-28 00:36:16,107 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.979,  Train_accy 20.83
2022-09-28 00:36:19,003 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.964,  Train_accy 19.91, Test_accy 43.88
2022-09-28 00:36:21,128 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.967,  Train_accy 20.60
2022-09-28 00:36:23,287 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.959,  Train_accy 19.56
2022-09-28 00:36:25,424 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.959,  Train_accy 19.79
2022-09-28 00:36:27,603 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.952,  Train_accy 20.02
2022-09-28 00:36:30,520 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.974,  Train_accy 19.91, Test_accy 44.15
2022-09-28 00:36:32,644 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.961,  Train_accy 19.22
2022-09-28 00:36:34,774 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.967,  Train_accy 19.68
2022-09-28 00:36:36,886 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.958,  Train_accy 19.45
2022-09-28 00:36:39,034 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.961,  Train_accy 19.68
2022-09-28 00:36:41,921 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.958,  Train_accy 20.14, Test_accy 44.15
2022-09-28 00:36:41,921 [foster.py] => do not weight align student!
2022-09-28 00:36:42,693 [foster.py] => darknet eval: 
2022-09-28 00:36:42,694 [foster.py] => CNN top1 curve: 44.15
2022-09-28 00:36:42,694 [foster.py] => CNN top5 curve: 85.37
2022-09-28 00:36:42,694 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 00:36:51,196 [foster.py] => Exemplar size: 320
2022-09-28 00:36:51,197 [trainer.py] => CNN: {'total': 51.6, 'old': 58.45, 'new': 26.25, 'base': 75.95, 'compound': 33.94}
2022-09-28 00:36:51,197 [trainer.py] => CNN top1 curve: [84.81, 68.0, 59.12, 51.6]
2022-09-28 00:36:51,197 [trainer.py] => CNN base curve: [84.81, 78.48, 75.32, 75.95]
2022-09-28 00:36:51,197 [trainer.py] => CNN old curve: [84.81, 78.48, 69.33, 58.45]
2022-09-28 00:36:51,197 [trainer.py] => CNN new curve: [0, 43.28, 26.76, 26.25]
2022-09-28 00:36:51,197 [trainer.py] => CNN compound curve: [0, 43.28, 40.58, 33.94]
2022-09-28 00:36:51,197 [trainer.py] => NME: {'total': 58.24, 'old': 61.49, 'new': 46.25, 'base': 67.72, 'compound': 51.38}
2022-09-28 00:36:51,197 [trainer.py] => NME top1 curve: [85.44, 78.67, 66.22, 58.24]
2022-09-28 00:36:51,197 [trainer.py] => NME base curve: [85.44, 82.91, 71.52, 67.72]
2022-09-28 00:36:51,197 [trainer.py] => NME old curve: [85.44, 82.91, 70.67, 61.49]
2022-09-28 00:36:51,197 [trainer.py] => NME new curve: [0, 68.66, 52.11, 46.25]
2022-09-28 00:36:51,197 [trainer.py] => NME compound curve: [0, 68.66, 60.14, 51.38]
2022-09-28 00:36:51,426 [foster.py] => Learning on 16-19
2022-09-28 00:36:51,426 [foster.py] => All params: 22390454
2022-09-28 00:36:51,426 [foster.py] => Trainable params: 11205734
2022-09-28 00:36:51,447 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 00:36:54,371 [foster.py] => Task 4, Epoch 1/34 => Loss 6.198, Loss_clf 1.878, Loss_fe 2.362, Loss_kd 1.649, Train_accy 41.00, Test_accy 40.77
2022-09-28 00:36:56,404 [foster.py] => Task 4, Epoch 2/34 => Loss 4.578, Loss_clf 0.955, Loss_fe 1.669, Loss_kd 1.645, Train_accy 40.04
2022-09-28 00:36:58,398 [foster.py] => Task 4, Epoch 3/34 => Loss 4.273, Loss_clf 0.854, Loss_fe 1.464, Loss_kd 1.646, Train_accy 46.86
2022-09-28 00:37:00,397 [foster.py] => Task 4, Epoch 4/34 => Loss 4.134, Loss_clf 0.837, Loss_fe 1.338, Loss_kd 1.650, Train_accy 46.96
2022-09-28 00:37:02,390 [foster.py] => Task 4, Epoch 5/34 => Loss 4.011, Loss_clf 0.806, Loss_fe 1.253, Loss_kd 1.644, Train_accy 47.39
2022-09-28 00:37:05,397 [foster.py] => Task 4, Epoch 6/34 => Loss 3.919, Loss_clf 0.777, Loss_fe 1.182, Loss_kd 1.651, Train_accy 47.07, Test_accy 46.17
2022-09-28 00:37:07,429 [foster.py] => Task 4, Epoch 7/34 => Loss 3.859, Loss_clf 0.777, Loss_fe 1.132, Loss_kd 1.642, Train_accy 49.95
2022-09-28 00:37:09,439 [foster.py] => Task 4, Epoch 8/34 => Loss 3.793, Loss_clf 0.747, Loss_fe 1.089, Loss_kd 1.647, Train_accy 49.20
2022-09-28 00:37:11,465 [foster.py] => Task 4, Epoch 9/34 => Loss 3.736, Loss_clf 0.745, Loss_fe 1.044, Loss_kd 1.639, Train_accy 46.43
2022-09-28 00:37:13,443 [foster.py] => Task 4, Epoch 10/34 => Loss 3.671, Loss_clf 0.722, Loss_fe 0.999, Loss_kd 1.642, Train_accy 49.31
2022-09-28 00:37:16,374 [foster.py] => Task 4, Epoch 11/34 => Loss 3.585, Loss_clf 0.681, Loss_fe 0.949, Loss_kd 1.647, Train_accy 50.37, Test_accy 47.07
2022-09-28 00:37:18,406 [foster.py] => Task 4, Epoch 12/34 => Loss 3.601, Loss_clf 0.695, Loss_fe 0.941, Loss_kd 1.655, Train_accy 49.95
2022-09-28 00:37:20,395 [foster.py] => Task 4, Epoch 13/34 => Loss 3.575, Loss_clf 0.695, Loss_fe 0.915, Loss_kd 1.654, Train_accy 48.67
2022-09-28 00:37:22,368 [foster.py] => Task 4, Epoch 14/34 => Loss 3.546, Loss_clf 0.676, Loss_fe 0.911, Loss_kd 1.650, Train_accy 50.27
2022-09-28 00:37:24,353 [foster.py] => Task 4, Epoch 15/34 => Loss 3.478, Loss_clf 0.661, Loss_fe 0.853, Loss_kd 1.653, Train_accy 50.59
2022-09-28 00:37:27,366 [foster.py] => Task 4, Epoch 16/34 => Loss 3.479, Loss_clf 0.657, Loss_fe 0.849, Loss_kd 1.662, Train_accy 50.27, Test_accy 47.97
2022-09-28 00:37:29,383 [foster.py] => Task 4, Epoch 17/34 => Loss 3.437, Loss_clf 0.652, Loss_fe 0.831, Loss_kd 1.645, Train_accy 51.12
2022-09-28 00:37:31,391 [foster.py] => Task 4, Epoch 18/34 => Loss 3.417, Loss_clf 0.651, Loss_fe 0.809, Loss_kd 1.648, Train_accy 49.95
2022-09-28 00:37:33,369 [foster.py] => Task 4, Epoch 19/34 => Loss 3.434, Loss_clf 0.653, Loss_fe 0.816, Loss_kd 1.654, Train_accy 50.27
2022-09-28 00:37:35,357 [foster.py] => Task 4, Epoch 20/34 => Loss 3.433, Loss_clf 0.653, Loss_fe 0.819, Loss_kd 1.651, Train_accy 52.08
2022-09-28 00:37:38,300 [foster.py] => Task 4, Epoch 21/34 => Loss 3.399, Loss_clf 0.643, Loss_fe 0.795, Loss_kd 1.652, Train_accy 51.22, Test_accy 47.07
2022-09-28 00:37:40,298 [foster.py] => Task 4, Epoch 22/34 => Loss 3.402, Loss_clf 0.642, Loss_fe 0.797, Loss_kd 1.653, Train_accy 51.22
2022-09-28 00:37:42,333 [foster.py] => Task 4, Epoch 23/34 => Loss 3.384, Loss_clf 0.634, Loss_fe 0.789, Loss_kd 1.651, Train_accy 50.48
2022-09-28 00:37:44,314 [foster.py] => Task 4, Epoch 24/34 => Loss 3.401, Loss_clf 0.646, Loss_fe 0.790, Loss_kd 1.654, Train_accy 50.48
2022-09-28 00:37:46,344 [foster.py] => Task 4, Epoch 25/34 => Loss 3.392, Loss_clf 0.642, Loss_fe 0.796, Loss_kd 1.646, Train_accy 50.59
2022-09-28 00:37:49,248 [foster.py] => Task 4, Epoch 26/34 => Loss 3.338, Loss_clf 0.616, Loss_fe 0.760, Loss_kd 1.653, Train_accy 52.08, Test_accy 48.42
2022-09-28 00:37:51,271 [foster.py] => Task 4, Epoch 27/34 => Loss 3.317, Loss_clf 0.614, Loss_fe 0.754, Loss_kd 1.642, Train_accy 51.65
2022-09-28 00:37:53,278 [foster.py] => Task 4, Epoch 28/34 => Loss 3.337, Loss_clf 0.611, Loss_fe 0.758, Loss_kd 1.658, Train_accy 53.67
2022-09-28 00:37:55,303 [foster.py] => Task 4, Epoch 29/34 => Loss 3.317, Loss_clf 0.604, Loss_fe 0.749, Loss_kd 1.654, Train_accy 52.82
2022-09-28 00:37:57,329 [foster.py] => Task 4, Epoch 30/34 => Loss 3.337, Loss_clf 0.612, Loss_fe 0.760, Loss_kd 1.655, Train_accy 52.72
2022-09-28 00:38:00,262 [foster.py] => Task 4, Epoch 31/34 => Loss 3.337, Loss_clf 0.625, Loss_fe 0.757, Loss_kd 1.647, Train_accy 51.86, Test_accy 46.85
2022-09-28 00:38:02,323 [foster.py] => Task 4, Epoch 32/34 => Loss 3.296, Loss_clf 0.593, Loss_fe 0.737, Loss_kd 1.656, Train_accy 52.18
2022-09-28 00:38:04,408 [foster.py] => Task 4, Epoch 33/34 => Loss 3.315, Loss_clf 0.607, Loss_fe 0.756, Loss_kd 1.644, Train_accy 53.99
2022-09-28 00:38:06,382 [foster.py] => Task 4, Epoch 34/34 => Loss 3.322, Loss_clf 0.606, Loss_fe 0.754, Loss_kd 1.652, Train_accy 50.91
2022-09-28 00:38:06,382 [foster.py] => do not weight align teacher!
2022-09-28 00:38:06,383 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 00:38:09,664 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.341,  Train_accy 17.57, Test_accy 37.39
2022-09-28 00:38:11,903 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.291,  Train_accy 18.85
2022-09-28 00:38:14,162 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.259,  Train_accy 19.17
2022-09-28 00:38:16,446 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.252,  Train_accy 19.91
2022-09-28 00:38:18,723 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.246,  Train_accy 19.91
2022-09-28 00:38:21,810 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.217,  Train_accy 19.17, Test_accy 39.41
2022-09-28 00:38:24,047 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.219,  Train_accy 19.06
2022-09-28 00:38:26,347 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.208,  Train_accy 20.34
2022-09-28 00:38:28,603 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.206,  Train_accy 19.49
2022-09-28 00:38:30,879 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.204,  Train_accy 20.34
2022-09-28 00:38:33,960 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.198,  Train_accy 20.13, Test_accy 39.64
2022-09-28 00:38:36,231 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.189,  Train_accy 18.85
2022-09-28 00:38:38,481 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.185,  Train_accy 20.55
2022-09-28 00:38:40,749 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.182,  Train_accy 19.49
2022-09-28 00:38:43,061 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.189,  Train_accy 20.87
2022-09-28 00:38:46,150 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.179,  Train_accy 20.77, Test_accy 40.99
2022-09-28 00:38:48,432 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.199,  Train_accy 20.87
2022-09-28 00:38:50,698 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.179,  Train_accy 21.41
2022-09-28 00:38:52,972 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.184,  Train_accy 20.66
2022-09-28 00:38:55,237 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.182,  Train_accy 21.51
2022-09-28 00:38:58,381 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.182,  Train_accy 21.41, Test_accy 40.99
2022-09-28 00:39:00,600 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.170,  Train_accy 21.51
2022-09-28 00:39:02,897 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.179,  Train_accy 21.30
2022-09-28 00:39:05,168 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.181,  Train_accy 21.19
2022-09-28 00:39:07,462 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.167,  Train_accy 20.87
2022-09-28 00:39:10,591 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.179,  Train_accy 21.73, Test_accy 41.89
2022-09-28 00:39:10,592 [foster.py] => do not weight align student!
2022-09-28 00:39:11,385 [foster.py] => darknet eval: 
2022-09-28 00:39:11,385 [foster.py] => CNN top1 curve: 41.89
2022-09-28 00:39:11,385 [foster.py] => CNN top5 curve: 83.56
2022-09-28 00:39:11,386 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 00:39:20,861 [foster.py] => Exemplar size: 380
2022-09-28 00:39:20,861 [trainer.py] => CNN: {'total': 47.07, 'old': 48.67, 'new': 38.24, 'base': 73.42, 'compound': 32.52}
2022-09-28 00:39:20,861 [trainer.py] => CNN top1 curve: [84.81, 68.0, 59.12, 51.6, 47.07]
2022-09-28 00:39:20,861 [trainer.py] => CNN base curve: [84.81, 78.48, 75.32, 75.95, 73.42]
2022-09-28 00:39:20,861 [trainer.py] => CNN old curve: [84.81, 78.48, 69.33, 58.45, 48.67]
2022-09-28 00:39:20,861 [trainer.py] => CNN new curve: [0, 43.28, 26.76, 26.25, 38.24]
2022-09-28 00:39:20,861 [trainer.py] => CNN compound curve: [0, 43.28, 40.58, 33.94, 32.52]
2022-09-28 00:39:20,861 [trainer.py] => NME: {'total': 56.98, 'old': 55.85, 'new': 63.24, 'base': 68.35, 'compound': 50.7}
2022-09-28 00:39:20,861 [trainer.py] => NME top1 curve: [85.44, 78.67, 66.22, 58.24, 56.98]
2022-09-28 00:39:20,861 [trainer.py] => NME base curve: [85.44, 82.91, 71.52, 67.72, 68.35]
2022-09-28 00:39:20,862 [trainer.py] => NME old curve: [85.44, 82.91, 70.67, 61.49, 55.85]
2022-09-28 00:39:20,862 [trainer.py] => NME new curve: [0, 68.66, 52.11, 46.25, 63.24]
2022-09-28 00:39:20,862 [trainer.py] => NME compound curve: [0, 68.66, 60.14, 51.38, 50.7]
2022-09-28 00:39:21,089 [foster.py] => Learning on 19-22
2022-09-28 00:39:21,089 [foster.py] => All params: 22396607
2022-09-28 00:39:21,090 [foster.py] => Trainable params: 11210348
2022-09-28 00:39:21,110 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 00:39:24,169 [foster.py] => Task 5, Epoch 1/34 => Loss 6.998, Loss_clf 2.058, Loss_fe 2.678, Loss_kd 1.954, Train_accy 37.87, Test_accy 40.59
2022-09-28 00:39:26,264 [foster.py] => Task 5, Epoch 2/34 => Loss 5.341, Loss_clf 1.136, Loss_fe 1.930, Loss_kd 1.965, Train_accy 37.87
2022-09-28 00:39:28,399 [foster.py] => Task 5, Epoch 3/34 => Loss 5.052, Loss_clf 1.059, Loss_fe 1.732, Loss_kd 1.952, Train_accy 39.26
2022-09-28 00:39:30,535 [foster.py] => Task 5, Epoch 4/34 => Loss 4.856, Loss_clf 1.008, Loss_fe 1.581, Loss_kd 1.958, Train_accy 42.54
2022-09-28 00:39:32,641 [foster.py] => Task 5, Epoch 5/34 => Loss 4.755, Loss_clf 0.984, Loss_fe 1.510, Loss_kd 1.953, Train_accy 43.44
2022-09-28 00:39:35,833 [foster.py] => Task 5, Epoch 6/34 => Loss 4.635, Loss_clf 0.959, Loss_fe 1.414, Loss_kd 1.954, Train_accy 43.04, Test_accy 45.35
2022-09-28 00:39:37,931 [foster.py] => Task 5, Epoch 7/34 => Loss 4.532, Loss_clf 0.929, Loss_fe 1.337, Loss_kd 1.957, Train_accy 44.23
2022-09-28 00:39:40,014 [foster.py] => Task 5, Epoch 8/34 => Loss 4.481, Loss_clf 0.920, Loss_fe 1.294, Loss_kd 1.958, Train_accy 45.73
2022-09-28 00:39:42,092 [foster.py] => Task 5, Epoch 9/34 => Loss 4.365, Loss_clf 0.883, Loss_fe 1.219, Loss_kd 1.955, Train_accy 43.74
2022-09-28 00:39:44,223 [foster.py] => Task 5, Epoch 10/34 => Loss 4.313, Loss_clf 0.876, Loss_fe 1.171, Loss_kd 1.957, Train_accy 45.23
2022-09-28 00:39:47,304 [foster.py] => Task 5, Epoch 11/34 => Loss 4.280, Loss_clf 0.862, Loss_fe 1.141, Loss_kd 1.966, Train_accy 45.63, Test_accy 45.54
2022-09-28 00:39:49,420 [foster.py] => Task 5, Epoch 12/34 => Loss 4.242, Loss_clf 0.857, Loss_fe 1.114, Loss_kd 1.962, Train_accy 48.31
2022-09-28 00:39:51,504 [foster.py] => Task 5, Epoch 13/34 => Loss 4.189, Loss_clf 0.832, Loss_fe 1.084, Loss_kd 1.963, Train_accy 45.63
2022-09-28 00:39:53,609 [foster.py] => Task 5, Epoch 14/34 => Loss 4.145, Loss_clf 0.820, Loss_fe 1.049, Loss_kd 1.965, Train_accy 46.92
2022-09-28 00:39:55,791 [foster.py] => Task 5, Epoch 15/34 => Loss 4.073, Loss_clf 0.789, Loss_fe 1.012, Loss_kd 1.962, Train_accy 47.71
2022-09-28 00:39:58,889 [foster.py] => Task 5, Epoch 16/34 => Loss 4.063, Loss_clf 0.789, Loss_fe 0.998, Loss_kd 1.965, Train_accy 48.61, Test_accy 46.53
2022-09-28 00:40:00,996 [foster.py] => Task 5, Epoch 17/34 => Loss 4.040, Loss_clf 0.785, Loss_fe 0.980, Loss_kd 1.965, Train_accy 48.71
2022-09-28 00:40:03,130 [foster.py] => Task 5, Epoch 18/34 => Loss 4.004, Loss_clf 0.774, Loss_fe 0.956, Loss_kd 1.964, Train_accy 48.11
2022-09-28 00:40:05,203 [foster.py] => Task 5, Epoch 19/34 => Loss 4.028, Loss_clf 0.776, Loss_fe 0.969, Loss_kd 1.971, Train_accy 47.81
2022-09-28 00:40:07,343 [foster.py] => Task 5, Epoch 20/34 => Loss 3.975, Loss_clf 0.766, Loss_fe 0.935, Loss_kd 1.964, Train_accy 48.61
2022-09-28 00:40:10,486 [foster.py] => Task 5, Epoch 21/34 => Loss 3.975, Loss_clf 0.762, Loss_fe 0.931, Loss_kd 1.971, Train_accy 49.60, Test_accy 46.14
2022-09-28 00:40:12,586 [foster.py] => Task 5, Epoch 22/34 => Loss 3.913, Loss_clf 0.734, Loss_fe 0.899, Loss_kd 1.969, Train_accy 51.69
2022-09-28 00:40:14,677 [foster.py] => Task 5, Epoch 23/34 => Loss 3.938, Loss_clf 0.748, Loss_fe 0.917, Loss_kd 1.964, Train_accy 48.21
2022-09-28 00:40:16,795 [foster.py] => Task 5, Epoch 24/34 => Loss 3.941, Loss_clf 0.747, Loss_fe 0.909, Loss_kd 1.973, Train_accy 51.49
2022-09-28 00:40:18,907 [foster.py] => Task 5, Epoch 25/34 => Loss 3.868, Loss_clf 0.717, Loss_fe 0.879, Loss_kd 1.962, Train_accy 50.40
2022-09-28 00:40:21,945 [foster.py] => Task 5, Epoch 26/34 => Loss 3.876, Loss_clf 0.721, Loss_fe 0.880, Loss_kd 1.964, Train_accy 50.60, Test_accy 46.93
2022-09-28 00:40:24,022 [foster.py] => Task 5, Epoch 27/34 => Loss 3.872, Loss_clf 0.725, Loss_fe 0.868, Loss_kd 1.967, Train_accy 51.39
2022-09-28 00:40:26,099 [foster.py] => Task 5, Epoch 28/34 => Loss 3.861, Loss_clf 0.721, Loss_fe 0.867, Loss_kd 1.963, Train_accy 51.39
2022-09-28 00:40:28,180 [foster.py] => Task 5, Epoch 29/34 => Loss 3.884, Loss_clf 0.732, Loss_fe 0.881, Loss_kd 1.962, Train_accy 50.80
2022-09-28 00:40:30,308 [foster.py] => Task 5, Epoch 30/34 => Loss 3.863, Loss_clf 0.726, Loss_fe 0.863, Loss_kd 1.964, Train_accy 51.59
2022-09-28 00:40:33,410 [foster.py] => Task 5, Epoch 31/34 => Loss 3.870, Loss_clf 0.724, Loss_fe 0.865, Loss_kd 1.969, Train_accy 50.60, Test_accy 46.53
2022-09-28 00:40:35,534 [foster.py] => Task 5, Epoch 32/34 => Loss 3.896, Loss_clf 0.730, Loss_fe 0.886, Loss_kd 1.969, Train_accy 50.89
2022-09-28 00:40:37,654 [foster.py] => Task 5, Epoch 33/34 => Loss 3.877, Loss_clf 0.719, Loss_fe 0.872, Loss_kd 1.974, Train_accy 52.29
2022-09-28 00:40:39,743 [foster.py] => Task 5, Epoch 34/34 => Loss 3.892, Loss_clf 0.727, Loss_fe 0.882, Loss_kd 1.971, Train_accy 49.80
2022-09-28 00:40:39,744 [foster.py] => do not weight align teacher!
2022-09-28 00:40:39,744 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 00:40:43,201 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.474,  Train_accy 19.88, Test_accy 36.24
2022-09-28 00:40:45,611 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.463,  Train_accy 19.38
2022-09-28 00:40:47,994 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.452,  Train_accy 19.98
2022-09-28 00:40:50,343 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.441,  Train_accy 19.88
2022-09-28 00:40:52,730 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.441,  Train_accy 19.28
2022-09-28 00:40:55,996 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.442,  Train_accy 19.58, Test_accy 38.22
2022-09-28 00:40:58,354 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.438,  Train_accy 20.28
2022-09-28 00:41:00,715 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.425,  Train_accy 19.88
2022-09-28 00:41:03,075 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.422,  Train_accy 20.38
2022-09-28 00:41:05,444 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.421,  Train_accy 20.78
2022-09-28 00:41:08,687 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.418,  Train_accy 19.98, Test_accy 39.21
2022-09-28 00:41:11,129 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.408,  Train_accy 20.28
2022-09-28 00:41:13,500 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.412,  Train_accy 21.37
2022-09-28 00:41:15,893 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.409,  Train_accy 20.38
2022-09-28 00:41:18,274 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.412,  Train_accy 20.97
2022-09-28 00:41:21,459 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.417,  Train_accy 19.58, Test_accy 39.80
2022-09-28 00:41:23,846 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.420,  Train_accy 21.17
2022-09-28 00:41:26,232 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.409,  Train_accy 20.48
2022-09-28 00:41:28,598 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.414,  Train_accy 19.98
2022-09-28 00:41:30,944 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.407,  Train_accy 20.68
2022-09-28 00:41:34,123 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.415,  Train_accy 20.68, Test_accy 40.20
2022-09-28 00:41:36,457 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.408,  Train_accy 20.18
2022-09-28 00:41:38,815 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.415,  Train_accy 21.07
2022-09-28 00:41:41,205 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.406,  Train_accy 20.78
2022-09-28 00:41:43,546 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.413,  Train_accy 21.17
2022-09-28 00:41:46,780 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.410,  Train_accy 20.38, Test_accy 39.80
2022-09-28 00:41:46,780 [foster.py] => do not weight align student!
2022-09-28 00:41:47,640 [foster.py] => darknet eval: 
2022-09-28 00:41:47,641 [foster.py] => CNN top1 curve: 39.8
2022-09-28 00:41:47,641 [foster.py] => CNN top5 curve: 82.77
2022-09-28 00:41:47,641 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 00:41:58,314 [foster.py] => Exemplar size: 440
2022-09-28 00:41:58,315 [trainer.py] => CNN: {'total': 47.13, 'old': 47.75, 'new': 42.62, 'base': 70.25, 'compound': 36.6}
2022-09-28 00:41:58,315 [trainer.py] => CNN top1 curve: [84.81, 68.0, 59.12, 51.6, 47.07, 47.13]
2022-09-28 00:41:58,315 [trainer.py] => CNN base curve: [84.81, 78.48, 75.32, 75.95, 73.42, 70.25]
2022-09-28 00:41:58,315 [trainer.py] => CNN old curve: [84.81, 78.48, 69.33, 58.45, 48.67, 47.75]
2022-09-28 00:41:58,315 [trainer.py] => CNN new curve: [0, 43.28, 26.76, 26.25, 38.24, 42.62]
2022-09-28 00:41:58,315 [trainer.py] => CNN compound curve: [0, 43.28, 40.58, 33.94, 32.52, 36.6]
2022-09-28 00:41:58,315 [trainer.py] => NME: {'total': 53.86, 'old': 54.05, 'new': 52.46, 'base': 67.72, 'compound': 47.55}
2022-09-28 00:41:58,315 [trainer.py] => NME top1 curve: [85.44, 78.67, 66.22, 58.24, 56.98, 53.86]
2022-09-28 00:41:58,315 [trainer.py] => NME base curve: [85.44, 82.91, 71.52, 67.72, 68.35, 67.72]
2022-09-28 00:41:58,315 [trainer.py] => NME old curve: [85.44, 82.91, 70.67, 61.49, 55.85, 54.05]
2022-09-28 00:41:58,315 [trainer.py] => NME new curve: [0, 68.66, 52.11, 46.25, 63.24, 52.46]
2022-09-28 00:41:58,315 [trainer.py] => NME compound curve: [0, 68.66, 60.14, 51.38, 50.7, 47.55]
2022-09-28 00:41:58,316 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 00:41:58,316 [trainer.py] => prefix: cil
2022-09-28 00:41:58,316 [trainer.py] => dataset: CFEE
2022-09-28 00:41:58,316 [trainer.py] => memory_size: 2000
2022-09-28 00:41:58,316 [trainer.py] => memory_per_class: 20
2022-09-28 00:41:58,316 [trainer.py] => fixed_memory: True
2022-09-28 00:41:58,316 [trainer.py] => shuffle: True
2022-09-28 00:41:58,317 [trainer.py] => init_cls: 7
2022-09-28 00:41:58,317 [trainer.py] => increment: 3
2022-09-28 00:41:58,317 [trainer.py] => model_name: foster
2022-09-28 00:41:58,317 [trainer.py] => convnet_type: resnet18
2022-09-28 00:41:58,317 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 00:41:58,317 [trainer.py] => seed: 1993
2022-09-28 00:41:58,317 [trainer.py] => beta1: 0.96
2022-09-28 00:41:58,317 [trainer.py] => beta2: 0.97
2022-09-28 00:41:58,317 [trainer.py] => oofc: ft
2022-09-28 00:41:58,317 [trainer.py] => is_teacher_wa: False
2022-09-28 00:41:58,317 [trainer.py] => is_student_wa: False
2022-09-28 00:41:58,317 [trainer.py] => lambda_okd: 1
2022-09-28 00:41:58,317 [trainer.py] => wa_value: 1
2022-09-28 00:41:58,317 [trainer.py] => init_epochs: 40
2022-09-28 00:41:58,317 [trainer.py] => init_lr: 0.01
2022-09-28 00:41:58,317 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 00:41:58,317 [trainer.py] => boosting_epochs: 34
2022-09-28 00:41:58,317 [trainer.py] => compression_epochs: 26
2022-09-28 00:41:58,317 [trainer.py] => lr: 0.001
2022-09-28 00:41:58,317 [trainer.py] => batch_size: 32
2022-09-28 00:41:58,317 [trainer.py] => weight_decay: 0.0005
2022-09-28 00:41:58,317 [trainer.py] => num_workers: 8
2022-09-28 00:41:58,317 [trainer.py] => T: 2
2022-09-28 00:41:58,317 [trainer.py] => nb_runs: 3
2022-09-28 00:41:58,317 [trainer.py] => fold: 10
2022-09-28 00:41:58,318 [data.py] => ========== Fold:3 ==========
2022-09-28 00:41:58,323 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 13, 17, 15, 9, 11, 20, 18, 12, 14, 7, 10, 19, 21, 16, 8]
2022-09-28 00:41:58,535 [foster.py] => Learning on 0-7
2022-09-28 00:41:58,535 [foster.py] => All params: 11183694
2022-09-28 00:41:58,535 [foster.py] => Trainable params: 11183694
2022-09-28 00:42:00,909 [foster.py] => Task 0, Epoch 1/40 => Loss 1.372, Train_accy 49.16
2022-09-28 00:42:03,887 [foster.py] => Task 0, Epoch 2/40 => Loss 0.552, Train_accy 80.46, Test_accy 83.24
2022-09-28 00:42:06,894 [foster.py] => Task 0, Epoch 3/40 => Loss 0.344, Train_accy 88.66, Test_accy 84.92
2022-09-28 00:42:09,919 [foster.py] => Task 0, Epoch 4/40 => Loss 0.286, Train_accy 91.04, Test_accy 86.59
2022-09-28 00:42:12,964 [foster.py] => Task 0, Epoch 5/40 => Loss 0.236, Train_accy 91.46, Test_accy 84.36
2022-09-28 00:42:15,341 [foster.py] => Task 0, Epoch 6/40 => Loss 0.183, Train_accy 93.70
2022-09-28 00:42:18,347 [foster.py] => Task 0, Epoch 7/40 => Loss 0.176, Train_accy 93.91, Test_accy 87.15
2022-09-28 00:42:21,298 [foster.py] => Task 0, Epoch 8/40 => Loss 0.119, Train_accy 96.57, Test_accy 86.59
2022-09-28 00:42:24,281 [foster.py] => Task 0, Epoch 9/40 => Loss 0.101, Train_accy 96.71, Test_accy 84.92
2022-09-28 00:42:27,289 [foster.py] => Task 0, Epoch 10/40 => Loss 0.102, Train_accy 96.64, Test_accy 86.03
2022-09-28 00:42:29,621 [foster.py] => Task 0, Epoch 11/40 => Loss 0.082, Train_accy 97.55
2022-09-28 00:42:32,574 [foster.py] => Task 0, Epoch 12/40 => Loss 0.098, Train_accy 96.78, Test_accy 86.59
2022-09-28 00:42:35,557 [foster.py] => Task 0, Epoch 13/40 => Loss 0.065, Train_accy 98.25, Test_accy 85.47
2022-09-28 00:42:38,558 [foster.py] => Task 0, Epoch 14/40 => Loss 0.062, Train_accy 98.25, Test_accy 87.71
2022-09-28 00:42:41,536 [foster.py] => Task 0, Epoch 15/40 => Loss 0.041, Train_accy 98.95, Test_accy 86.03
2022-09-28 00:42:43,886 [foster.py] => Task 0, Epoch 16/40 => Loss 0.053, Train_accy 98.81
2022-09-28 00:42:46,972 [foster.py] => Task 0, Epoch 17/40 => Loss 0.047, Train_accy 98.81, Test_accy 88.27
2022-09-28 00:42:49,936 [foster.py] => Task 0, Epoch 18/40 => Loss 0.039, Train_accy 99.02, Test_accy 87.15
2022-09-28 00:42:52,981 [foster.py] => Task 0, Epoch 19/40 => Loss 0.030, Train_accy 99.44, Test_accy 87.15
2022-09-28 00:42:55,966 [foster.py] => Task 0, Epoch 20/40 => Loss 0.031, Train_accy 99.58, Test_accy 87.15
2022-09-28 00:42:58,323 [foster.py] => Task 0, Epoch 21/40 => Loss 0.030, Train_accy 99.23
2022-09-28 00:43:01,339 [foster.py] => Task 0, Epoch 22/40 => Loss 0.027, Train_accy 99.30, Test_accy 88.83
2022-09-28 00:43:04,304 [foster.py] => Task 0, Epoch 23/40 => Loss 0.031, Train_accy 99.02, Test_accy 86.59
2022-09-28 00:43:07,327 [foster.py] => Task 0, Epoch 24/40 => Loss 0.021, Train_accy 99.65, Test_accy 87.71
2022-09-28 00:43:10,429 [foster.py] => Task 0, Epoch 25/40 => Loss 0.019, Train_accy 99.72, Test_accy 87.71
2022-09-28 00:43:12,763 [foster.py] => Task 0, Epoch 26/40 => Loss 0.018, Train_accy 99.79
2022-09-28 00:43:15,729 [foster.py] => Task 0, Epoch 27/40 => Loss 0.017, Train_accy 99.93, Test_accy 87.15
2022-09-28 00:43:18,693 [foster.py] => Task 0, Epoch 28/40 => Loss 0.019, Train_accy 99.79, Test_accy 87.71
2022-09-28 00:43:21,694 [foster.py] => Task 0, Epoch 29/40 => Loss 0.019, Train_accy 99.51, Test_accy 88.83
2022-09-28 00:43:24,650 [foster.py] => Task 0, Epoch 30/40 => Loss 0.015, Train_accy 99.86, Test_accy 87.71
2022-09-28 00:43:27,005 [foster.py] => Task 0, Epoch 31/40 => Loss 0.013, Train_accy 99.93
2022-09-28 00:43:29,974 [foster.py] => Task 0, Epoch 32/40 => Loss 0.012, Train_accy 99.93, Test_accy 87.71
2022-09-28 00:43:32,948 [foster.py] => Task 0, Epoch 33/40 => Loss 0.016, Train_accy 99.93, Test_accy 87.71
2022-09-28 00:43:35,970 [foster.py] => Task 0, Epoch 34/40 => Loss 0.015, Train_accy 99.79, Test_accy 88.27
2022-09-28 00:43:38,955 [foster.py] => Task 0, Epoch 35/40 => Loss 0.014, Train_accy 99.93, Test_accy 88.27
2022-09-28 00:43:41,313 [foster.py] => Task 0, Epoch 36/40 => Loss 0.015, Train_accy 99.79
2022-09-28 00:43:44,270 [foster.py] => Task 0, Epoch 37/40 => Loss 0.016, Train_accy 99.86, Test_accy 87.71
2022-09-28 00:43:47,244 [foster.py] => Task 0, Epoch 38/40 => Loss 0.018, Train_accy 99.72, Test_accy 88.27
2022-09-28 00:43:50,239 [foster.py] => Task 0, Epoch 39/40 => Loss 0.016, Train_accy 99.58, Test_accy 88.83
2022-09-28 00:43:53,232 [foster.py] => Task 0, Epoch 40/40 => Loss 0.018, Train_accy 99.65, Test_accy 86.59
2022-09-28 00:43:53,233 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 00:44:00,096 [foster.py] => Exemplar size: 140
2022-09-28 00:44:00,096 [trainer.py] => CNN: {'total': 86.59, 'old': 86.59, 'new': 0, 'base': 86.59, 'compound': 0}
2022-09-28 00:44:00,096 [trainer.py] => CNN top1 curve: [86.59]
2022-09-28 00:44:00,096 [trainer.py] => CNN base curve: [86.59]
2022-09-28 00:44:00,096 [trainer.py] => CNN old curve: [86.59]
2022-09-28 00:44:00,096 [trainer.py] => CNN new curve: [0]
2022-09-28 00:44:00,096 [trainer.py] => CNN compound curve: [0]
2022-09-28 00:44:00,096 [trainer.py] => NME: {'total': 87.15, 'old': 87.15, 'new': 0, 'base': 87.15, 'compound': 0}
2022-09-28 00:44:00,096 [trainer.py] => NME top1 curve: [87.15]
2022-09-28 00:44:00,096 [trainer.py] => NME base curve: [87.15]
2022-09-28 00:44:00,096 [trainer.py] => NME old curve: [87.15]
2022-09-28 00:44:00,096 [trainer.py] => NME new curve: [0]
2022-09-28 00:44:00,096 [trainer.py] => NME compound curve: [0]
2022-09-28 00:44:00,325 [foster.py] => Learning on 7-10
2022-09-28 00:44:00,325 [foster.py] => All params: 22371995
2022-09-28 00:44:00,326 [foster.py] => Trainable params: 11191892
2022-09-28 00:44:00,346 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 00:44:02,857 [foster.py] => Task 1, Epoch 1/34 => Loss 4.642, Loss_clf 1.951, Loss_fe 1.977, Loss_kd 0.500, Train_accy 41.64, Test_accy 68.46
2022-09-28 00:44:04,627 [foster.py] => Task 1, Epoch 2/34 => Loss 2.500, Loss_clf 0.641, Loss_fe 1.145, Loss_kd 0.500, Train_accy 78.46
2022-09-28 00:44:06,340 [foster.py] => Task 1, Epoch 3/34 => Loss 2.029, Loss_clf 0.404, Loss_fe 0.921, Loss_kd 0.493, Train_accy 53.66
2022-09-28 00:44:08,050 [foster.py] => Task 1, Epoch 4/34 => Loss 1.817, Loss_clf 0.341, Loss_fe 0.780, Loss_kd 0.487, Train_accy 55.74
2022-09-28 00:44:09,822 [foster.py] => Task 1, Epoch 5/34 => Loss 1.711, Loss_clf 0.317, Loss_fe 0.695, Loss_kd 0.489, Train_accy 58.09
2022-09-28 00:44:12,302 [foster.py] => Task 1, Epoch 6/34 => Loss 1.668, Loss_clf 0.325, Loss_fe 0.654, Loss_kd 0.483, Train_accy 57.70, Test_accy 73.44
2022-09-28 00:44:14,092 [foster.py] => Task 1, Epoch 7/34 => Loss 1.592, Loss_clf 0.293, Loss_fe 0.594, Loss_kd 0.494, Train_accy 58.36
2022-09-28 00:44:15,816 [foster.py] => Task 1, Epoch 8/34 => Loss 1.540, Loss_clf 0.292, Loss_fe 0.554, Loss_kd 0.486, Train_accy 57.44
2022-09-28 00:44:17,571 [foster.py] => Task 1, Epoch 9/34 => Loss 1.491, Loss_clf 0.281, Loss_fe 0.518, Loss_kd 0.484, Train_accy 59.14
2022-09-28 00:44:19,327 [foster.py] => Task 1, Epoch 10/34 => Loss 1.475, Loss_clf 0.276, Loss_fe 0.501, Loss_kd 0.488, Train_accy 60.70
2022-09-28 00:44:21,804 [foster.py] => Task 1, Epoch 11/34 => Loss 1.421, Loss_clf 0.269, Loss_fe 0.468, Loss_kd 0.479, Train_accy 56.66, Test_accy 75.52
2022-09-28 00:44:23,555 [foster.py] => Task 1, Epoch 12/34 => Loss 1.389, Loss_clf 0.253, Loss_fe 0.440, Loss_kd 0.487, Train_accy 58.75
2022-09-28 00:44:25,307 [foster.py] => Task 1, Epoch 13/34 => Loss 1.378, Loss_clf 0.249, Loss_fe 0.429, Loss_kd 0.490, Train_accy 62.14
2022-09-28 00:44:27,033 [foster.py] => Task 1, Epoch 14/34 => Loss 1.368, Loss_clf 0.252, Loss_fe 0.422, Loss_kd 0.486, Train_accy 59.79
2022-09-28 00:44:28,738 [foster.py] => Task 1, Epoch 15/34 => Loss 1.335, Loss_clf 0.230, Loss_fe 0.404, Loss_kd 0.491, Train_accy 59.53
2022-09-28 00:44:31,242 [foster.py] => Task 1, Epoch 16/34 => Loss 1.332, Loss_clf 0.239, Loss_fe 0.400, Loss_kd 0.486, Train_accy 60.70, Test_accy 75.93
2022-09-28 00:44:32,997 [foster.py] => Task 1, Epoch 17/34 => Loss 1.323, Loss_clf 0.241, Loss_fe 0.386, Loss_kd 0.488, Train_accy 58.62
2022-09-28 00:44:34,753 [foster.py] => Task 1, Epoch 18/34 => Loss 1.297, Loss_clf 0.228, Loss_fe 0.376, Loss_kd 0.485, Train_accy 61.36
2022-09-28 00:44:36,453 [foster.py] => Task 1, Epoch 19/34 => Loss 1.285, Loss_clf 0.225, Loss_fe 0.362, Loss_kd 0.489, Train_accy 60.44
2022-09-28 00:44:38,213 [foster.py] => Task 1, Epoch 20/34 => Loss 1.295, Loss_clf 0.229, Loss_fe 0.372, Loss_kd 0.486, Train_accy 60.97
2022-09-28 00:44:40,647 [foster.py] => Task 1, Epoch 21/34 => Loss 1.261, Loss_clf 0.220, Loss_fe 0.341, Loss_kd 0.490, Train_accy 62.27, Test_accy 76.35
2022-09-28 00:44:42,450 [foster.py] => Task 1, Epoch 22/34 => Loss 1.288, Loss_clf 0.234, Loss_fe 0.358, Loss_kd 0.487, Train_accy 60.31
2022-09-28 00:44:44,168 [foster.py] => Task 1, Epoch 23/34 => Loss 1.253, Loss_clf 0.211, Loss_fe 0.343, Loss_kd 0.489, Train_accy 60.97
2022-09-28 00:44:45,907 [foster.py] => Task 1, Epoch 24/34 => Loss 1.218, Loss_clf 0.200, Loss_fe 0.331, Loss_kd 0.481, Train_accy 61.36
2022-09-28 00:44:47,633 [foster.py] => Task 1, Epoch 25/34 => Loss 1.258, Loss_clf 0.222, Loss_fe 0.344, Loss_kd 0.485, Train_accy 59.92
2022-09-28 00:44:50,157 [foster.py] => Task 1, Epoch 26/34 => Loss 1.221, Loss_clf 0.202, Loss_fe 0.328, Loss_kd 0.483, Train_accy 60.97, Test_accy 76.35
2022-09-28 00:44:51,907 [foster.py] => Task 1, Epoch 27/34 => Loss 1.249, Loss_clf 0.216, Loss_fe 0.333, Loss_kd 0.490, Train_accy 62.01
2022-09-28 00:44:53,658 [foster.py] => Task 1, Epoch 28/34 => Loss 1.237, Loss_clf 0.211, Loss_fe 0.339, Loss_kd 0.481, Train_accy 60.57
2022-09-28 00:44:55,408 [foster.py] => Task 1, Epoch 29/34 => Loss 1.223, Loss_clf 0.209, Loss_fe 0.323, Loss_kd 0.484, Train_accy 62.01
2022-09-28 00:44:57,129 [foster.py] => Task 1, Epoch 30/34 => Loss 1.220, Loss_clf 0.199, Loss_fe 0.322, Loss_kd 0.489, Train_accy 61.49
2022-09-28 00:44:59,608 [foster.py] => Task 1, Epoch 31/34 => Loss 1.225, Loss_clf 0.201, Loss_fe 0.332, Loss_kd 0.485, Train_accy 59.66, Test_accy 76.35
2022-09-28 00:45:01,313 [foster.py] => Task 1, Epoch 32/34 => Loss 1.205, Loss_clf 0.200, Loss_fe 0.317, Loss_kd 0.482, Train_accy 61.75
2022-09-28 00:45:03,058 [foster.py] => Task 1, Epoch 33/34 => Loss 1.244, Loss_clf 0.219, Loss_fe 0.334, Loss_kd 0.484, Train_accy 61.49
2022-09-28 00:45:04,765 [foster.py] => Task 1, Epoch 34/34 => Loss 1.243, Loss_clf 0.214, Loss_fe 0.338, Loss_kd 0.484, Train_accy 60.44
2022-09-28 00:45:04,766 [foster.py] => do not weight align teacher!
2022-09-28 00:45:04,766 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 00:45:07,622 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.615,  Train_accy 18.02, Test_accy 63.07
2022-09-28 00:45:09,578 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.467,  Train_accy 18.02
2022-09-28 00:45:11,526 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.360,  Train_accy 18.28
2022-09-28 00:45:13,485 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.316,  Train_accy 20.63
2022-09-28 00:45:15,450 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.280,  Train_accy 23.37
2022-09-28 00:45:18,046 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.259,  Train_accy 26.50, Test_accy 66.39
2022-09-28 00:45:20,024 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.261,  Train_accy 29.50
2022-09-28 00:45:21,977 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.240,  Train_accy 30.42
2022-09-28 00:45:23,983 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.229,  Train_accy 31.98
2022-09-28 00:45:25,948 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.216,  Train_accy 31.59
2022-09-28 00:45:28,640 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.219,  Train_accy 32.77, Test_accy 70.54
2022-09-28 00:45:30,548 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.209,  Train_accy 34.46
2022-09-28 00:45:32,503 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.210,  Train_accy 34.73
2022-09-28 00:45:34,445 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.207,  Train_accy 35.51
2022-09-28 00:45:36,396 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.218,  Train_accy 35.90
2022-09-28 00:45:39,044 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.201,  Train_accy 36.81, Test_accy 71.37
2022-09-28 00:45:41,008 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.205,  Train_accy 36.55
2022-09-28 00:45:42,941 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.188,  Train_accy 36.16
2022-09-28 00:45:44,849 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.199,  Train_accy 37.99
2022-09-28 00:45:46,771 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.204,  Train_accy 38.51
2022-09-28 00:45:49,367 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.205,  Train_accy 36.42, Test_accy 71.37
2022-09-28 00:45:51,335 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.202,  Train_accy 36.16
2022-09-28 00:45:53,303 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.196,  Train_accy 36.16
2022-09-28 00:45:55,224 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.198,  Train_accy 37.21
2022-09-28 00:45:57,185 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.200,  Train_accy 35.77
2022-09-28 00:45:59,775 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.187,  Train_accy 37.86, Test_accy 71.37
2022-09-28 00:45:59,775 [foster.py] => do not weight align student!
2022-09-28 00:46:00,449 [foster.py] => darknet eval: 
2022-09-28 00:46:00,449 [foster.py] => CNN top1 curve: 71.37
2022-09-28 00:46:00,449 [foster.py] => CNN top5 curve: 97.93
2022-09-28 00:46:00,449 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 00:46:06,774 [foster.py] => Exemplar size: 200
2022-09-28 00:46:06,774 [trainer.py] => CNN: {'total': 76.35, 'old': 84.92, 'new': 51.61, 'base': 84.92, 'compound': 51.61}
2022-09-28 00:46:06,774 [trainer.py] => CNN top1 curve: [86.59, 76.35]
2022-09-28 00:46:06,774 [trainer.py] => CNN base curve: [86.59, 84.92]
2022-09-28 00:46:06,774 [trainer.py] => CNN old curve: [86.59, 84.92]
2022-09-28 00:46:06,774 [trainer.py] => CNN new curve: [0, 51.61]
2022-09-28 00:46:06,774 [trainer.py] => CNN compound curve: [0, 51.61]
2022-09-28 00:46:06,774 [trainer.py] => NME: {'total': 75.93, 'old': 78.21, 'new': 69.35, 'base': 78.21, 'compound': 69.35}
2022-09-28 00:46:06,774 [trainer.py] => NME top1 curve: [87.15, 75.93]
2022-09-28 00:46:06,774 [trainer.py] => NME base curve: [87.15, 78.21]
2022-09-28 00:46:06,774 [trainer.py] => NME old curve: [87.15, 78.21]
2022-09-28 00:46:06,774 [trainer.py] => NME new curve: [0, 69.35]
2022-09-28 00:46:06,774 [trainer.py] => NME compound curve: [0, 69.35]
2022-09-28 00:46:07,001 [foster.py] => Learning on 10-13
2022-09-28 00:46:07,001 [foster.py] => All params: 22378148
2022-09-28 00:46:07,002 [foster.py] => Trainable params: 11196506
2022-09-28 00:46:07,022 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 00:46:09,675 [foster.py] => Task 2, Epoch 1/34 => Loss 5.400, Loss_clf 2.161, Loss_fe 2.210, Loss_kd 0.792, Train_accy 37.18, Test_accy 50.00
2022-09-28 00:46:11,461 [foster.py] => Task 2, Epoch 2/34 => Loss 3.365, Loss_clf 0.903, Loss_fe 1.422, Loss_kd 0.800, Train_accy 47.12
2022-09-28 00:46:13,242 [foster.py] => Task 2, Epoch 3/34 => Loss 2.963, Loss_clf 0.740, Loss_fe 1.215, Loss_kd 0.775, Train_accy 38.53
2022-09-28 00:46:15,059 [foster.py] => Task 2, Epoch 4/34 => Loss 2.775, Loss_clf 0.673, Loss_fe 1.090, Loss_kd 0.778, Train_accy 36.32
2022-09-28 00:46:16,858 [foster.py] => Task 2, Epoch 5/34 => Loss 2.648, Loss_clf 0.626, Loss_fe 1.014, Loss_kd 0.776, Train_accy 39.51
2022-09-28 00:46:19,468 [foster.py] => Task 2, Epoch 6/34 => Loss 2.552, Loss_clf 0.601, Loss_fe 0.943, Loss_kd 0.775, Train_accy 40.37, Test_accy 61.78
2022-09-28 00:46:21,279 [foster.py] => Task 2, Epoch 7/34 => Loss 2.503, Loss_clf 0.600, Loss_fe 0.895, Loss_kd 0.775, Train_accy 39.26
2022-09-28 00:46:23,078 [foster.py] => Task 2, Epoch 8/34 => Loss 2.368, Loss_clf 0.534, Loss_fe 0.820, Loss_kd 0.780, Train_accy 42.33
2022-09-28 00:46:24,914 [foster.py] => Task 2, Epoch 9/34 => Loss 2.381, Loss_clf 0.551, Loss_fe 0.805, Loss_kd 0.788, Train_accy 42.21
2022-09-28 00:46:26,742 [foster.py] => Task 2, Epoch 10/34 => Loss 2.359, Loss_clf 0.550, Loss_fe 0.794, Loss_kd 0.781, Train_accy 42.09
2022-09-28 00:46:29,404 [foster.py] => Task 2, Epoch 11/34 => Loss 2.277, Loss_clf 0.529, Loss_fe 0.745, Loss_kd 0.771, Train_accy 41.60, Test_accy 61.46
2022-09-28 00:46:31,276 [foster.py] => Task 2, Epoch 12/34 => Loss 2.274, Loss_clf 0.536, Loss_fe 0.726, Loss_kd 0.778, Train_accy 42.21
2022-09-28 00:46:33,106 [foster.py] => Task 2, Epoch 13/34 => Loss 2.220, Loss_clf 0.505, Loss_fe 0.713, Loss_kd 0.771, Train_accy 43.56
2022-09-28 00:46:34,905 [foster.py] => Task 2, Epoch 14/34 => Loss 2.198, Loss_clf 0.497, Loss_fe 0.690, Loss_kd 0.778, Train_accy 41.47
2022-09-28 00:46:36,729 [foster.py] => Task 2, Epoch 15/34 => Loss 2.140, Loss_clf 0.481, Loss_fe 0.653, Loss_kd 0.773, Train_accy 40.86
2022-09-28 00:46:39,400 [foster.py] => Task 2, Epoch 16/34 => Loss 2.134, Loss_clf 0.469, Loss_fe 0.655, Loss_kd 0.777, Train_accy 43.19, Test_accy 62.10
2022-09-28 00:46:41,240 [foster.py] => Task 2, Epoch 17/34 => Loss 2.138, Loss_clf 0.479, Loss_fe 0.651, Loss_kd 0.776, Train_accy 42.33
2022-09-28 00:46:43,064 [foster.py] => Task 2, Epoch 18/34 => Loss 2.108, Loss_clf 0.475, Loss_fe 0.624, Loss_kd 0.776, Train_accy 44.66
2022-09-28 00:46:44,910 [foster.py] => Task 2, Epoch 19/34 => Loss 2.056, Loss_clf 0.440, Loss_fe 0.609, Loss_kd 0.775, Train_accy 41.47
2022-09-28 00:46:46,705 [foster.py] => Task 2, Epoch 20/34 => Loss 2.061, Loss_clf 0.439, Loss_fe 0.598, Loss_kd 0.787, Train_accy 46.01
2022-09-28 00:46:49,342 [foster.py] => Task 2, Epoch 21/34 => Loss 2.057, Loss_clf 0.449, Loss_fe 0.594, Loss_kd 0.780, Train_accy 42.58, Test_accy 62.74
2022-09-28 00:46:51,160 [foster.py] => Task 2, Epoch 22/34 => Loss 1.998, Loss_clf 0.414, Loss_fe 0.578, Loss_kd 0.774, Train_accy 43.56
2022-09-28 00:46:52,965 [foster.py] => Task 2, Epoch 23/34 => Loss 2.048, Loss_clf 0.441, Loss_fe 0.592, Loss_kd 0.780, Train_accy 45.28
2022-09-28 00:46:54,765 [foster.py] => Task 2, Epoch 24/34 => Loss 1.974, Loss_clf 0.412, Loss_fe 0.555, Loss_kd 0.775, Train_accy 44.66
2022-09-28 00:46:56,586 [foster.py] => Task 2, Epoch 25/34 => Loss 2.010, Loss_clf 0.425, Loss_fe 0.569, Loss_kd 0.781, Train_accy 43.07
2022-09-28 00:46:59,201 [foster.py] => Task 2, Epoch 26/34 => Loss 1.964, Loss_clf 0.399, Loss_fe 0.551, Loss_kd 0.780, Train_accy 46.01, Test_accy 63.38
2022-09-28 00:47:01,014 [foster.py] => Task 2, Epoch 27/34 => Loss 1.953, Loss_clf 0.408, Loss_fe 0.546, Loss_kd 0.769, Train_accy 44.54
2022-09-28 00:47:02,808 [foster.py] => Task 2, Epoch 28/34 => Loss 1.996, Loss_clf 0.415, Loss_fe 0.563, Loss_kd 0.783, Train_accy 45.77
2022-09-28 00:47:04,594 [foster.py] => Task 2, Epoch 29/34 => Loss 1.949, Loss_clf 0.396, Loss_fe 0.547, Loss_kd 0.773, Train_accy 44.66
2022-09-28 00:47:06,436 [foster.py] => Task 2, Epoch 30/34 => Loss 1.975, Loss_clf 0.419, Loss_fe 0.558, Loss_kd 0.768, Train_accy 45.40
2022-09-28 00:47:09,077 [foster.py] => Task 2, Epoch 31/34 => Loss 1.997, Loss_clf 0.410, Loss_fe 0.567, Loss_kd 0.784, Train_accy 47.12, Test_accy 63.06
2022-09-28 00:47:10,864 [foster.py] => Task 2, Epoch 32/34 => Loss 1.991, Loss_clf 0.421, Loss_fe 0.563, Loss_kd 0.775, Train_accy 45.52
2022-09-28 00:47:12,678 [foster.py] => Task 2, Epoch 33/34 => Loss 1.976, Loss_clf 0.412, Loss_fe 0.555, Loss_kd 0.776, Train_accy 46.26
2022-09-28 00:47:14,468 [foster.py] => Task 2, Epoch 34/34 => Loss 1.978, Loss_clf 0.410, Loss_fe 0.552, Loss_kd 0.781, Train_accy 46.63
2022-09-28 00:47:14,468 [foster.py] => do not weight align teacher!
2022-09-28 00:47:14,469 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 00:47:17,415 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.802,  Train_accy 17.79, Test_accy 51.27
2022-09-28 00:47:19,423 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.685,  Train_accy 18.53
2022-09-28 00:47:21,485 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.605,  Train_accy 19.14
2022-09-28 00:47:23,514 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.560,  Train_accy 19.75
2022-09-28 00:47:25,515 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.531,  Train_accy 19.88
2022-09-28 00:47:28,233 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.527,  Train_accy 20.37, Test_accy 55.41
2022-09-28 00:47:30,279 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.510,  Train_accy 21.10
2022-09-28 00:47:32,315 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.494,  Train_accy 20.61
2022-09-28 00:47:34,347 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.499,  Train_accy 21.23
2022-09-28 00:47:36,367 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.488,  Train_accy 21.23
2022-09-28 00:47:39,117 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.484,  Train_accy 20.98, Test_accy 55.10
2022-09-28 00:47:41,197 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.468,  Train_accy 21.10
2022-09-28 00:47:43,248 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.476,  Train_accy 21.60
2022-09-28 00:47:45,244 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.478,  Train_accy 22.09
2022-09-28 00:47:47,273 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.470,  Train_accy 21.47
2022-09-28 00:47:50,028 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.476,  Train_accy 21.60, Test_accy 55.41
2022-09-28 00:47:52,077 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.474,  Train_accy 21.72
2022-09-28 00:47:54,088 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.461,  Train_accy 22.58
2022-09-28 00:47:56,085 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.463,  Train_accy 23.07
2022-09-28 00:47:58,112 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.469,  Train_accy 22.21
2022-09-28 00:48:00,893 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.465,  Train_accy 22.45, Test_accy 56.05
2022-09-28 00:48:02,909 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.463,  Train_accy 22.33
2022-09-28 00:48:04,961 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.455,  Train_accy 21.72
2022-09-28 00:48:06,980 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.467,  Train_accy 22.21
2022-09-28 00:48:09,050 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.466,  Train_accy 22.21
2022-09-28 00:48:11,768 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.472,  Train_accy 23.44, Test_accy 55.73
2022-09-28 00:48:11,768 [foster.py] => do not weight align student!
2022-09-28 00:48:12,475 [foster.py] => darknet eval: 
2022-09-28 00:48:12,475 [foster.py] => CNN top1 curve: 55.73
2022-09-28 00:48:12,475 [foster.py] => CNN top5 curve: 96.5
2022-09-28 00:48:12,475 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 00:48:19,992 [foster.py] => Exemplar size: 260
2022-09-28 00:48:19,992 [trainer.py] => CNN: {'total': 63.06, 'old': 73.03, 'new': 30.14, 'base': 79.33, 'compound': 41.48}
2022-09-28 00:48:19,992 [trainer.py] => CNN top1 curve: [86.59, 76.35, 63.06]
2022-09-28 00:48:19,992 [trainer.py] => CNN base curve: [86.59, 84.92, 79.33]
2022-09-28 00:48:19,992 [trainer.py] => CNN old curve: [86.59, 84.92, 73.03]
2022-09-28 00:48:19,992 [trainer.py] => CNN new curve: [0, 51.61, 30.14]
2022-09-28 00:48:19,992 [trainer.py] => CNN compound curve: [0, 51.61, 41.48]
2022-09-28 00:48:19,992 [trainer.py] => NME: {'total': 66.88, 'old': 68.05, 'new': 63.01, 'base': 68.16, 'compound': 65.19}
2022-09-28 00:48:19,992 [trainer.py] => NME top1 curve: [87.15, 75.93, 66.88]
2022-09-28 00:48:19,992 [trainer.py] => NME base curve: [87.15, 78.21, 68.16]
2022-09-28 00:48:19,993 [trainer.py] => NME old curve: [87.15, 78.21, 68.05]
2022-09-28 00:48:19,993 [trainer.py] => NME new curve: [0, 69.35, 63.01]
2022-09-28 00:48:19,993 [trainer.py] => NME compound curve: [0, 69.35, 65.19]
2022-09-28 00:48:20,221 [foster.py] => Learning on 13-16
2022-09-28 00:48:20,221 [foster.py] => All params: 22384301
2022-09-28 00:48:20,222 [foster.py] => Trainable params: 11201120
2022-09-28 00:48:20,242 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 00:48:23,071 [foster.py] => Task 3, Epoch 1/34 => Loss 5.655, Loss_clf 1.737, Loss_fe 2.298, Loss_kd 1.316, Train_accy 41.32, Test_accy 44.32
2022-09-28 00:48:24,968 [foster.py] => Task 3, Epoch 2/34 => Loss 4.218, Loss_clf 0.984, Loss_fe 1.627, Loss_kd 1.305, Train_accy 43.00
2022-09-28 00:48:26,899 [foster.py] => Task 3, Epoch 3/34 => Loss 3.925, Loss_clf 0.895, Loss_fe 1.412, Loss_kd 1.315, Train_accy 38.86
2022-09-28 00:48:28,920 [foster.py] => Task 3, Epoch 4/34 => Loss 3.783, Loss_clf 0.855, Loss_fe 1.311, Loss_kd 1.313, Train_accy 39.87
2022-09-28 00:48:30,903 [foster.py] => Task 3, Epoch 5/34 => Loss 3.676, Loss_clf 0.835, Loss_fe 1.236, Loss_kd 1.304, Train_accy 41.32
2022-09-28 00:48:33,702 [foster.py] => Task 3, Epoch 6/34 => Loss 3.548, Loss_clf 0.793, Loss_fe 1.143, Loss_kd 1.310, Train_accy 40.43, Test_accy 53.78
2022-09-28 00:48:35,663 [foster.py] => Task 3, Epoch 7/34 => Loss 3.501, Loss_clf 0.791, Loss_fe 1.102, Loss_kd 1.307, Train_accy 38.19
2022-09-28 00:48:37,582 [foster.py] => Task 3, Epoch 8/34 => Loss 3.438, Loss_clf 0.779, Loss_fe 1.048, Loss_kd 1.309, Train_accy 41.99
2022-09-28 00:48:39,539 [foster.py] => Task 3, Epoch 9/34 => Loss 3.414, Loss_clf 0.767, Loss_fe 1.023, Loss_kd 1.319, Train_accy 42.22
2022-09-28 00:48:41,466 [foster.py] => Task 3, Epoch 10/34 => Loss 3.378, Loss_clf 0.770, Loss_fe 0.994, Loss_kd 1.311, Train_accy 40.76
2022-09-28 00:48:44,271 [foster.py] => Task 3, Epoch 11/34 => Loss 3.263, Loss_clf 0.722, Loss_fe 0.930, Loss_kd 1.309, Train_accy 41.10, Test_accy 54.32
2022-09-28 00:48:46,253 [foster.py] => Task 3, Epoch 12/34 => Loss 3.254, Loss_clf 0.721, Loss_fe 0.910, Loss_kd 1.319, Train_accy 41.55
2022-09-28 00:48:48,170 [foster.py] => Task 3, Epoch 13/34 => Loss 3.197, Loss_clf 0.699, Loss_fe 0.883, Loss_kd 1.313, Train_accy 44.12
2022-09-28 00:48:50,154 [foster.py] => Task 3, Epoch 14/34 => Loss 3.167, Loss_clf 0.683, Loss_fe 0.858, Loss_kd 1.322, Train_accy 44.57
2022-09-28 00:48:52,146 [foster.py] => Task 3, Epoch 15/34 => Loss 3.171, Loss_clf 0.697, Loss_fe 0.855, Loss_kd 1.315, Train_accy 43.56
2022-09-28 00:48:55,073 [foster.py] => Task 3, Epoch 16/34 => Loss 3.110, Loss_clf 0.662, Loss_fe 0.830, Loss_kd 1.314, Train_accy 41.99, Test_accy 52.43
2022-09-28 00:48:57,044 [foster.py] => Task 3, Epoch 17/34 => Loss 3.129, Loss_clf 0.681, Loss_fe 0.831, Loss_kd 1.314, Train_accy 44.57
2022-09-28 00:48:59,075 [foster.py] => Task 3, Epoch 18/34 => Loss 3.047, Loss_clf 0.643, Loss_fe 0.791, Loss_kd 1.311, Train_accy 43.23
2022-09-28 00:49:01,114 [foster.py] => Task 3, Epoch 19/34 => Loss 3.067, Loss_clf 0.652, Loss_fe 0.794, Loss_kd 1.317, Train_accy 44.46
2022-09-28 00:49:03,219 [foster.py] => Task 3, Epoch 20/34 => Loss 3.056, Loss_clf 0.652, Loss_fe 0.782, Loss_kd 1.318, Train_accy 44.46
2022-09-28 00:49:06,273 [foster.py] => Task 3, Epoch 21/34 => Loss 3.028, Loss_clf 0.649, Loss_fe 0.769, Loss_kd 1.309, Train_accy 44.68, Test_accy 53.24
2022-09-28 00:49:08,316 [foster.py] => Task 3, Epoch 22/34 => Loss 3.018, Loss_clf 0.631, Loss_fe 0.761, Loss_kd 1.321, Train_accy 44.90
2022-09-28 00:49:10,349 [foster.py] => Task 3, Epoch 23/34 => Loss 2.985, Loss_clf 0.621, Loss_fe 0.760, Loss_kd 1.303, Train_accy 44.34
2022-09-28 00:49:12,454 [foster.py] => Task 3, Epoch 24/34 => Loss 2.993, Loss_clf 0.620, Loss_fe 0.746, Loss_kd 1.322, Train_accy 45.69
2022-09-28 00:49:14,523 [foster.py] => Task 3, Epoch 25/34 => Loss 2.941, Loss_clf 0.591, Loss_fe 0.730, Loss_kd 1.316, Train_accy 46.81
2022-09-28 00:49:17,536 [foster.py] => Task 3, Epoch 26/34 => Loss 2.982, Loss_clf 0.616, Loss_fe 0.739, Loss_kd 1.322, Train_accy 46.70, Test_accy 53.78
2022-09-28 00:49:19,558 [foster.py] => Task 3, Epoch 27/34 => Loss 2.982, Loss_clf 0.613, Loss_fe 0.751, Loss_kd 1.314, Train_accy 44.12
2022-09-28 00:49:21,611 [foster.py] => Task 3, Epoch 28/34 => Loss 2.971, Loss_clf 0.617, Loss_fe 0.741, Loss_kd 1.311, Train_accy 46.81
2022-09-28 00:49:23,656 [foster.py] => Task 3, Epoch 29/34 => Loss 2.941, Loss_clf 0.605, Loss_fe 0.724, Loss_kd 1.309, Train_accy 46.14
2022-09-28 00:49:25,695 [foster.py] => Task 3, Epoch 30/34 => Loss 2.980, Loss_clf 0.619, Loss_fe 0.741, Loss_kd 1.316, Train_accy 46.36
2022-09-28 00:49:28,730 [foster.py] => Task 3, Epoch 31/34 => Loss 2.952, Loss_clf 0.597, Loss_fe 0.728, Loss_kd 1.321, Train_accy 46.47, Test_accy 52.43
2022-09-28 00:49:30,815 [foster.py] => Task 3, Epoch 32/34 => Loss 2.970, Loss_clf 0.607, Loss_fe 0.739, Loss_kd 1.319, Train_accy 44.79
2022-09-28 00:49:32,898 [foster.py] => Task 3, Epoch 33/34 => Loss 2.952, Loss_clf 0.603, Loss_fe 0.729, Loss_kd 1.316, Train_accy 48.49
2022-09-28 00:49:34,917 [foster.py] => Task 3, Epoch 34/34 => Loss 2.918, Loss_clf 0.587, Loss_fe 0.715, Loss_kd 1.313, Train_accy 46.58
2022-09-28 00:49:34,917 [foster.py] => do not weight align teacher!
2022-09-28 00:49:34,918 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 00:49:38,163 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.092,  Train_accy 17.47, Test_accy 48.92
2022-09-28 00:49:40,319 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.024,  Train_accy 19.15
2022-09-28 00:49:42,481 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 1.991,  Train_accy 18.92
2022-09-28 00:49:44,653 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 1.980,  Train_accy 19.37
2022-09-28 00:49:46,835 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.956,  Train_accy 19.15
2022-09-28 00:49:49,863 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.967,  Train_accy 19.37, Test_accy 49.73
2022-09-28 00:49:52,043 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.953,  Train_accy 18.92
2022-09-28 00:49:54,247 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.936,  Train_accy 19.82
2022-09-28 00:49:56,471 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.937,  Train_accy 19.71
2022-09-28 00:49:58,624 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.938,  Train_accy 20.49
2022-09-28 00:50:01,658 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.944,  Train_accy 18.70, Test_accy 49.73
2022-09-28 00:50:03,831 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.941,  Train_accy 19.93
2022-09-28 00:50:05,985 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.936,  Train_accy 19.93
2022-09-28 00:50:08,159 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.923,  Train_accy 20.49
2022-09-28 00:50:10,322 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.927,  Train_accy 18.70
2022-09-28 00:50:13,256 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.933,  Train_accy 19.60, Test_accy 50.54
2022-09-28 00:50:15,486 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.926,  Train_accy 19.71
2022-09-28 00:50:17,645 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.929,  Train_accy 19.93
2022-09-28 00:50:19,839 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.924,  Train_accy 19.26
2022-09-28 00:50:21,988 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.924,  Train_accy 20.04
2022-09-28 00:50:24,911 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.925,  Train_accy 19.60, Test_accy 50.54
2022-09-28 00:50:27,110 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.921,  Train_accy 19.48
2022-09-28 00:50:29,290 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.929,  Train_accy 20.16
2022-09-28 00:50:31,454 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.930,  Train_accy 20.04
2022-09-28 00:50:33,646 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.923,  Train_accy 20.04
2022-09-28 00:50:36,557 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.924,  Train_accy 20.38, Test_accy 50.54
2022-09-28 00:50:36,558 [foster.py] => do not weight align student!
2022-09-28 00:50:37,324 [foster.py] => darknet eval: 
2022-09-28 00:50:37,324 [foster.py] => CNN top1 curve: 50.54
2022-09-28 00:50:37,324 [foster.py] => CNN top5 curve: 91.35
2022-09-28 00:50:37,325 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 00:50:45,830 [foster.py] => Exemplar size: 320
2022-09-28 00:50:45,830 [trainer.py] => CNN: {'total': 52.43, 'old': 57.01, 'new': 26.79, 'base': 76.54, 'compound': 29.84}
2022-09-28 00:50:45,830 [trainer.py] => CNN top1 curve: [86.59, 76.35, 63.06, 52.43]
2022-09-28 00:50:45,830 [trainer.py] => CNN base curve: [86.59, 84.92, 79.33, 76.54]
2022-09-28 00:50:45,830 [trainer.py] => CNN old curve: [86.59, 84.92, 73.03, 57.01]
2022-09-28 00:50:45,830 [trainer.py] => CNN new curve: [0, 51.61, 30.14, 26.79]
2022-09-28 00:50:45,830 [trainer.py] => CNN compound curve: [0, 51.61, 41.48, 29.84]
2022-09-28 00:50:45,830 [trainer.py] => NME: {'total': 60.0, 'old': 62.1, 'new': 48.21, 'base': 68.16, 'compound': 52.36}
2022-09-28 00:50:45,830 [trainer.py] => NME top1 curve: [87.15, 75.93, 66.88, 60.0]
2022-09-28 00:50:45,830 [trainer.py] => NME base curve: [87.15, 78.21, 68.16, 68.16]
2022-09-28 00:50:45,830 [trainer.py] => NME old curve: [87.15, 78.21, 68.05, 62.1]
2022-09-28 00:50:45,830 [trainer.py] => NME new curve: [0, 69.35, 63.01, 48.21]
2022-09-28 00:50:45,830 [trainer.py] => NME compound curve: [0, 69.35, 65.19, 52.36]
2022-09-28 00:50:46,061 [foster.py] => Learning on 16-19
2022-09-28 00:50:46,062 [foster.py] => All params: 22390454
2022-09-28 00:50:46,062 [foster.py] => Trainable params: 11205734
2022-09-28 00:50:46,082 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 00:50:49,041 [foster.py] => Task 4, Epoch 1/34 => Loss 6.307, Loss_clf 1.928, Loss_fe 2.443, Loss_kd 1.630, Train_accy 41.03, Test_accy 47.85
2022-09-28 00:50:51,059 [foster.py] => Task 4, Epoch 2/34 => Loss 4.567, Loss_clf 0.954, Loss_fe 1.665, Loss_kd 1.641, Train_accy 42.20
2022-09-28 00:50:53,120 [foster.py] => Task 4, Epoch 3/34 => Loss 4.292, Loss_clf 0.872, Loss_fe 1.467, Loss_kd 1.645, Train_accy 45.09
2022-09-28 00:50:55,118 [foster.py] => Task 4, Epoch 4/34 => Loss 4.139, Loss_clf 0.848, Loss_fe 1.344, Loss_kd 1.640, Train_accy 47.01
2022-09-28 00:50:57,156 [foster.py] => Task 4, Epoch 5/34 => Loss 3.964, Loss_clf 0.785, Loss_fe 1.231, Loss_kd 1.640, Train_accy 45.51
2022-09-28 00:51:00,055 [foster.py] => Task 4, Epoch 6/34 => Loss 3.867, Loss_clf 0.767, Loss_fe 1.155, Loss_kd 1.638, Train_accy 50.00, Test_accy 49.66
2022-09-28 00:51:02,039 [foster.py] => Task 4, Epoch 7/34 => Loss 3.829, Loss_clf 0.769, Loss_fe 1.113, Loss_kd 1.639, Train_accy 48.18
2022-09-28 00:51:04,056 [foster.py] => Task 4, Epoch 8/34 => Loss 3.757, Loss_clf 0.745, Loss_fe 1.063, Loss_kd 1.641, Train_accy 48.50
2022-09-28 00:51:06,072 [foster.py] => Task 4, Epoch 9/34 => Loss 3.682, Loss_clf 0.710, Loss_fe 1.011, Loss_kd 1.651, Train_accy 49.15
2022-09-28 00:51:08,063 [foster.py] => Task 4, Epoch 10/34 => Loss 3.654, Loss_clf 0.714, Loss_fe 0.986, Loss_kd 1.646, Train_accy 50.00
2022-09-28 00:51:11,030 [foster.py] => Task 4, Epoch 11/34 => Loss 3.587, Loss_clf 0.691, Loss_fe 0.935, Loss_kd 1.651, Train_accy 51.39, Test_accy 51.70
2022-09-28 00:51:13,051 [foster.py] => Task 4, Epoch 12/34 => Loss 3.546, Loss_clf 0.690, Loss_fe 0.911, Loss_kd 1.638, Train_accy 51.18
2022-09-28 00:51:15,085 [foster.py] => Task 4, Epoch 13/34 => Loss 3.502, Loss_clf 0.672, Loss_fe 0.886, Loss_kd 1.637, Train_accy 50.96
2022-09-28 00:51:17,089 [foster.py] => Task 4, Epoch 14/34 => Loss 3.495, Loss_clf 0.668, Loss_fe 0.872, Loss_kd 1.647, Train_accy 53.31
2022-09-28 00:51:19,130 [foster.py] => Task 4, Epoch 15/34 => Loss 3.508, Loss_clf 0.688, Loss_fe 0.869, Loss_kd 1.643, Train_accy 50.11
2022-09-28 00:51:22,074 [foster.py] => Task 4, Epoch 16/34 => Loss 3.432, Loss_clf 0.659, Loss_fe 0.822, Loss_kd 1.643, Train_accy 51.82, Test_accy 51.93
2022-09-28 00:51:24,091 [foster.py] => Task 4, Epoch 17/34 => Loss 3.420, Loss_clf 0.642, Loss_fe 0.822, Loss_kd 1.647, Train_accy 51.92
2022-09-28 00:51:26,090 [foster.py] => Task 4, Epoch 18/34 => Loss 3.384, Loss_clf 0.629, Loss_fe 0.805, Loss_kd 1.643, Train_accy 50.96
2022-09-28 00:51:28,080 [foster.py] => Task 4, Epoch 19/34 => Loss 3.381, Loss_clf 0.643, Loss_fe 0.787, Loss_kd 1.643, Train_accy 53.85
2022-09-28 00:51:30,162 [foster.py] => Task 4, Epoch 20/34 => Loss 3.338, Loss_clf 0.626, Loss_fe 0.772, Loss_kd 1.634, Train_accy 50.11
2022-09-28 00:51:33,171 [foster.py] => Task 4, Epoch 21/34 => Loss 3.419, Loss_clf 0.656, Loss_fe 0.804, Loss_kd 1.650, Train_accy 51.60, Test_accy 53.51
2022-09-28 00:51:35,204 [foster.py] => Task 4, Epoch 22/34 => Loss 3.325, Loss_clf 0.620, Loss_fe 0.756, Loss_kd 1.641, Train_accy 51.18
2022-09-28 00:51:37,237 [foster.py] => Task 4, Epoch 23/34 => Loss 3.351, Loss_clf 0.621, Loss_fe 0.761, Loss_kd 1.658, Train_accy 53.10
2022-09-28 00:51:39,255 [foster.py] => Task 4, Epoch 24/34 => Loss 3.340, Loss_clf 0.617, Loss_fe 0.756, Loss_kd 1.656, Train_accy 50.75
2022-09-28 00:51:41,234 [foster.py] => Task 4, Epoch 25/34 => Loss 3.345, Loss_clf 0.625, Loss_fe 0.757, Loss_kd 1.653, Train_accy 53.53
2022-09-28 00:51:44,149 [foster.py] => Task 4, Epoch 26/34 => Loss 3.298, Loss_clf 0.595, Loss_fe 0.746, Loss_kd 1.648, Train_accy 54.17, Test_accy 53.74
2022-09-28 00:51:46,135 [foster.py] => Task 4, Epoch 27/34 => Loss 3.309, Loss_clf 0.617, Loss_fe 0.750, Loss_kd 1.635, Train_accy 51.50
2022-09-28 00:51:48,117 [foster.py] => Task 4, Epoch 28/34 => Loss 3.348, Loss_clf 0.635, Loss_fe 0.759, Loss_kd 1.646, Train_accy 53.31
2022-09-28 00:51:50,095 [foster.py] => Task 4, Epoch 29/34 => Loss 3.334, Loss_clf 0.620, Loss_fe 0.759, Loss_kd 1.646, Train_accy 51.82
2022-09-28 00:51:52,110 [foster.py] => Task 4, Epoch 30/34 => Loss 3.339, Loss_clf 0.621, Loss_fe 0.768, Loss_kd 1.642, Train_accy 52.67
2022-09-28 00:51:55,069 [foster.py] => Task 4, Epoch 31/34 => Loss 3.272, Loss_clf 0.597, Loss_fe 0.729, Loss_kd 1.638, Train_accy 52.03, Test_accy 53.29
2022-09-28 00:51:57,031 [foster.py] => Task 4, Epoch 32/34 => Loss 3.251, Loss_clf 0.590, Loss_fe 0.725, Loss_kd 1.631, Train_accy 52.46
2022-09-28 00:51:59,048 [foster.py] => Task 4, Epoch 33/34 => Loss 3.279, Loss_clf 0.592, Loss_fe 0.727, Loss_kd 1.650, Train_accy 52.67
2022-09-28 00:52:01,060 [foster.py] => Task 4, Epoch 34/34 => Loss 3.252, Loss_clf 0.589, Loss_fe 0.719, Loss_kd 1.637, Train_accy 53.21
2022-09-28 00:52:01,061 [foster.py] => do not weight align teacher!
2022-09-28 00:52:01,061 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 00:52:04,385 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.295,  Train_accy 18.59, Test_accy 42.63
2022-09-28 00:52:06,656 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.241,  Train_accy 19.23
2022-09-28 00:52:08,912 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.223,  Train_accy 19.12
2022-09-28 00:52:11,147 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.222,  Train_accy 19.87
2022-09-28 00:52:13,370 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.197,  Train_accy 18.80
2022-09-28 00:52:16,426 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.200,  Train_accy 19.44, Test_accy 43.76
2022-09-28 00:52:18,741 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.194,  Train_accy 20.73
2022-09-28 00:52:20,956 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.183,  Train_accy 20.51
2022-09-28 00:52:23,227 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.178,  Train_accy 21.15
2022-09-28 00:52:25,479 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.169,  Train_accy 21.47
2022-09-28 00:52:28,550 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.175,  Train_accy 20.83, Test_accy 44.90
2022-09-28 00:52:30,803 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.177,  Train_accy 21.58
2022-09-28 00:52:33,032 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.184,  Train_accy 23.18
2022-09-28 00:52:35,254 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.170,  Train_accy 22.01
2022-09-28 00:52:37,524 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.161,  Train_accy 22.22
2022-09-28 00:52:40,540 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.157,  Train_accy 23.08, Test_accy 45.35
2022-09-28 00:52:42,802 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.165,  Train_accy 22.33
2022-09-28 00:52:45,030 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.159,  Train_accy 22.33
2022-09-28 00:52:47,273 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.162,  Train_accy 22.86
2022-09-28 00:52:49,538 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.159,  Train_accy 24.25
2022-09-28 00:52:52,634 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.158,  Train_accy 22.54, Test_accy 45.35
2022-09-28 00:52:54,893 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.161,  Train_accy 23.93
2022-09-28 00:52:57,124 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.156,  Train_accy 22.86
2022-09-28 00:52:59,350 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.166,  Train_accy 22.44
2022-09-28 00:53:01,595 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.149,  Train_accy 23.29
2022-09-28 00:53:04,701 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.159,  Train_accy 22.01, Test_accy 45.35
2022-09-28 00:53:04,702 [foster.py] => do not weight align student!
2022-09-28 00:53:05,522 [foster.py] => darknet eval: 
2022-09-28 00:53:05,523 [foster.py] => CNN top1 curve: 45.35
2022-09-28 00:53:05,523 [foster.py] => CNN top5 curve: 85.71
2022-09-28 00:53:05,523 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 00:53:15,199 [foster.py] => Exemplar size: 380
2022-09-28 00:53:15,199 [trainer.py] => CNN: {'total': 53.51, 'old': 55.14, 'new': 45.07, 'base': 73.74, 'compound': 39.69}
2022-09-28 00:53:15,199 [trainer.py] => CNN top1 curve: [86.59, 76.35, 63.06, 52.43, 53.51]
2022-09-28 00:53:15,199 [trainer.py] => CNN base curve: [86.59, 84.92, 79.33, 76.54, 73.74]
2022-09-28 00:53:15,199 [trainer.py] => CNN old curve: [86.59, 84.92, 73.03, 57.01, 55.14]
2022-09-28 00:53:15,199 [trainer.py] => CNN new curve: [0, 51.61, 30.14, 26.79, 45.07]
2022-09-28 00:53:15,199 [trainer.py] => CNN compound curve: [0, 51.61, 41.48, 29.84, 39.69]
2022-09-28 00:53:15,199 [trainer.py] => NME: {'total': 56.69, 'old': 57.03, 'new': 54.93, 'base': 68.72, 'compound': 48.47}
2022-09-28 00:53:15,199 [trainer.py] => NME top1 curve: [87.15, 75.93, 66.88, 60.0, 56.69]
2022-09-28 00:53:15,199 [trainer.py] => NME base curve: [87.15, 78.21, 68.16, 68.16, 68.72]
2022-09-28 00:53:15,199 [trainer.py] => NME old curve: [87.15, 78.21, 68.05, 62.1, 57.03]
2022-09-28 00:53:15,199 [trainer.py] => NME new curve: [0, 69.35, 63.01, 48.21, 54.93]
2022-09-28 00:53:15,199 [trainer.py] => NME compound curve: [0, 69.35, 65.19, 52.36, 48.47]
2022-09-28 00:53:15,427 [foster.py] => Learning on 19-22
2022-09-28 00:53:15,428 [foster.py] => All params: 22396607
2022-09-28 00:53:15,428 [foster.py] => Trainable params: 11210348
2022-09-28 00:53:15,448 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 00:53:18,510 [foster.py] => Task 5, Epoch 1/34 => Loss 6.688, Loss_clf 1.772, Loss_fe 2.679, Loss_kd 1.932, Train_accy 40.08, Test_accy 44.75
2022-09-28 00:53:20,603 [foster.py] => Task 5, Epoch 2/34 => Loss 5.229, Loss_clf 1.086, Loss_fe 1.893, Loss_kd 1.943, Train_accy 36.29
2022-09-28 00:53:22,682 [foster.py] => Task 5, Epoch 3/34 => Loss 4.959, Loss_clf 1.021, Loss_fe 1.705, Loss_kd 1.929, Train_accy 39.48
2022-09-28 00:53:24,800 [foster.py] => Task 5, Epoch 4/34 => Loss 4.798, Loss_clf 0.975, Loss_fe 1.579, Loss_kd 1.938, Train_accy 38.98
2022-09-28 00:53:26,883 [foster.py] => Task 5, Epoch 5/34 => Loss 4.684, Loss_clf 0.952, Loss_fe 1.480, Loss_kd 1.945, Train_accy 39.58
2022-09-28 00:53:29,975 [foster.py] => Task 5, Epoch 6/34 => Loss 4.558, Loss_clf 0.926, Loss_fe 1.390, Loss_kd 1.936, Train_accy 40.68, Test_accy 47.13
2022-09-28 00:53:32,040 [foster.py] => Task 5, Epoch 7/34 => Loss 4.459, Loss_clf 0.894, Loss_fe 1.314, Loss_kd 1.944, Train_accy 44.07
2022-09-28 00:53:34,148 [foster.py] => Task 5, Epoch 8/34 => Loss 4.432, Loss_clf 0.909, Loss_fe 1.280, Loss_kd 1.938, Train_accy 41.77
2022-09-28 00:53:36,264 [foster.py] => Task 5, Epoch 9/34 => Loss 4.322, Loss_clf 0.864, Loss_fe 1.203, Loss_kd 1.947, Train_accy 43.37
2022-09-28 00:53:38,363 [foster.py] => Task 5, Epoch 10/34 => Loss 4.267, Loss_clf 0.852, Loss_fe 1.170, Loss_kd 1.939, Train_accy 43.87
2022-09-28 00:53:41,430 [foster.py] => Task 5, Epoch 11/34 => Loss 4.208, Loss_clf 0.836, Loss_fe 1.127, Loss_kd 1.939, Train_accy 44.37, Test_accy 49.31
2022-09-28 00:53:43,542 [foster.py] => Task 5, Epoch 12/34 => Loss 4.172, Loss_clf 0.822, Loss_fe 1.091, Loss_kd 1.951, Train_accy 45.36
2022-09-28 00:53:45,605 [foster.py] => Task 5, Epoch 13/34 => Loss 4.145, Loss_clf 0.828, Loss_fe 1.063, Loss_kd 1.947, Train_accy 43.57
2022-09-28 00:53:47,684 [foster.py] => Task 5, Epoch 14/34 => Loss 4.129, Loss_clf 0.823, Loss_fe 1.056, Loss_kd 1.943, Train_accy 45.36
2022-09-28 00:53:49,798 [foster.py] => Task 5, Epoch 15/34 => Loss 4.067, Loss_clf 0.803, Loss_fe 1.016, Loss_kd 1.942, Train_accy 45.96
2022-09-28 00:53:52,857 [foster.py] => Task 5, Epoch 16/34 => Loss 4.032, Loss_clf 0.785, Loss_fe 0.990, Loss_kd 1.949, Train_accy 45.56, Test_accy 50.30
2022-09-28 00:53:54,939 [foster.py] => Task 5, Epoch 17/34 => Loss 3.991, Loss_clf 0.769, Loss_fe 0.967, Loss_kd 1.948, Train_accy 46.86
2022-09-28 00:53:57,064 [foster.py] => Task 5, Epoch 18/34 => Loss 4.004, Loss_clf 0.780, Loss_fe 0.967, Loss_kd 1.950, Train_accy 45.56
2022-09-28 00:53:59,140 [foster.py] => Task 5, Epoch 19/34 => Loss 3.968, Loss_clf 0.773, Loss_fe 0.941, Loss_kd 1.947, Train_accy 48.26
2022-09-28 00:54:01,260 [foster.py] => Task 5, Epoch 20/34 => Loss 3.954, Loss_clf 0.757, Loss_fe 0.934, Loss_kd 1.954, Train_accy 46.76
2022-09-28 00:54:04,334 [foster.py] => Task 5, Epoch 21/34 => Loss 3.912, Loss_clf 0.742, Loss_fe 0.916, Loss_kd 1.946, Train_accy 47.66, Test_accy 50.50
2022-09-28 00:54:06,414 [foster.py] => Task 5, Epoch 22/34 => Loss 3.916, Loss_clf 0.755, Loss_fe 0.911, Loss_kd 1.943, Train_accy 46.26
2022-09-28 00:54:08,531 [foster.py] => Task 5, Epoch 23/34 => Loss 3.957, Loss_clf 0.773, Loss_fe 0.922, Loss_kd 1.953, Train_accy 47.26
2022-09-28 00:54:10,641 [foster.py] => Task 5, Epoch 24/34 => Loss 3.885, Loss_clf 0.740, Loss_fe 0.893, Loss_kd 1.945, Train_accy 49.55
2022-09-28 00:54:12,730 [foster.py] => Task 5, Epoch 25/34 => Loss 3.889, Loss_clf 0.734, Loss_fe 0.900, Loss_kd 1.948, Train_accy 47.06
2022-09-28 00:54:15,765 [foster.py] => Task 5, Epoch 26/34 => Loss 3.896, Loss_clf 0.747, Loss_fe 0.896, Loss_kd 1.945, Train_accy 47.66, Test_accy 50.50
2022-09-28 00:54:17,891 [foster.py] => Task 5, Epoch 27/34 => Loss 3.885, Loss_clf 0.739, Loss_fe 0.887, Loss_kd 1.950, Train_accy 49.75
2022-09-28 00:54:19,982 [foster.py] => Task 5, Epoch 28/34 => Loss 3.828, Loss_clf 0.714, Loss_fe 0.854, Loss_kd 1.952, Train_accy 49.35
2022-09-28 00:54:22,052 [foster.py] => Task 5, Epoch 29/34 => Loss 3.847, Loss_clf 0.724, Loss_fe 0.863, Loss_kd 1.951, Train_accy 48.45
2022-09-28 00:54:24,151 [foster.py] => Task 5, Epoch 30/34 => Loss 3.893, Loss_clf 0.748, Loss_fe 0.893, Loss_kd 1.945, Train_accy 47.16
2022-09-28 00:54:27,223 [foster.py] => Task 5, Epoch 31/34 => Loss 3.835, Loss_clf 0.718, Loss_fe 0.857, Loss_kd 1.951, Train_accy 49.05, Test_accy 51.09
2022-09-28 00:54:29,299 [foster.py] => Task 5, Epoch 32/34 => Loss 3.864, Loss_clf 0.735, Loss_fe 0.873, Loss_kd 1.948, Train_accy 48.95
2022-09-28 00:54:31,379 [foster.py] => Task 5, Epoch 33/34 => Loss 3.887, Loss_clf 0.735, Loss_fe 0.882, Loss_kd 1.961, Train_accy 50.05
2022-09-28 00:54:33,446 [foster.py] => Task 5, Epoch 34/34 => Loss 3.830, Loss_clf 0.707, Loss_fe 0.866, Loss_kd 1.949, Train_accy 48.65
2022-09-28 00:54:33,446 [foster.py] => do not weight align teacher!
2022-09-28 00:54:33,447 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 00:54:36,909 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.430,  Train_accy 19.44, Test_accy 40.40
2022-09-28 00:54:39,242 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.421,  Train_accy 19.54
2022-09-28 00:54:41,619 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.419,  Train_accy 18.25
2022-09-28 00:54:43,953 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.411,  Train_accy 19.84
2022-09-28 00:54:46,293 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.409,  Train_accy 19.14
2022-09-28 00:54:49,544 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.397,  Train_accy 20.74, Test_accy 43.56
2022-09-28 00:54:51,892 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.391,  Train_accy 20.24
2022-09-28 00:54:54,267 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.388,  Train_accy 19.64
2022-09-28 00:54:56,585 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.388,  Train_accy 21.44
2022-09-28 00:54:58,930 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.395,  Train_accy 21.34
2022-09-28 00:55:02,157 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.386,  Train_accy 20.54, Test_accy 42.77
2022-09-28 00:55:04,562 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.385,  Train_accy 21.04
2022-09-28 00:55:06,962 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.375,  Train_accy 20.44
2022-09-28 00:55:09,295 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.382,  Train_accy 21.24
2022-09-28 00:55:11,639 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.374,  Train_accy 20.44
2022-09-28 00:55:14,868 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.382,  Train_accy 20.94, Test_accy 43.76
2022-09-28 00:55:17,319 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.376,  Train_accy 20.64
2022-09-28 00:55:19,712 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.375,  Train_accy 21.04
2022-09-28 00:55:22,077 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.375,  Train_accy 20.54
2022-09-28 00:55:24,515 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.385,  Train_accy 21.14
2022-09-28 00:55:27,745 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.375,  Train_accy 21.54, Test_accy 43.76
2022-09-28 00:55:30,072 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.376,  Train_accy 21.14
2022-09-28 00:55:32,445 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.372,  Train_accy 20.34
2022-09-28 00:55:34,848 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.371,  Train_accy 21.93
2022-09-28 00:55:37,187 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.374,  Train_accy 20.74
2022-09-28 00:55:40,370 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.369,  Train_accy 20.94, Test_accy 45.15
2022-09-28 00:55:40,370 [foster.py] => do not weight align student!
2022-09-28 00:55:41,206 [foster.py] => darknet eval: 
2022-09-28 00:55:41,206 [foster.py] => CNN top1 curve: 45.15
2022-09-28 00:55:41,206 [foster.py] => CNN top5 curve: 83.37
2022-09-28 00:55:41,206 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 00:55:51,784 [foster.py] => Exemplar size: 440
2022-09-28 00:55:51,784 [trainer.py] => CNN: {'total': 50.89, 'old': 53.51, 'new': 32.81, 'base': 70.39, 'compound': 40.18}
2022-09-28 00:55:51,785 [trainer.py] => CNN top1 curve: [86.59, 76.35, 63.06, 52.43, 53.51, 50.89]
2022-09-28 00:55:51,785 [trainer.py] => CNN base curve: [86.59, 84.92, 79.33, 76.54, 73.74, 70.39]
2022-09-28 00:55:51,785 [trainer.py] => CNN old curve: [86.59, 84.92, 73.03, 57.01, 55.14, 53.51]
2022-09-28 00:55:51,785 [trainer.py] => CNN new curve: [0, 51.61, 30.14, 26.79, 45.07, 32.81]
2022-09-28 00:55:51,785 [trainer.py] => CNN compound curve: [0, 51.61, 41.48, 29.84, 39.69, 40.18]
2022-09-28 00:55:51,785 [trainer.py] => NME: {'total': 54.85, 'old': 55.56, 'new': 50.0, 'base': 65.36, 'compound': 49.08}
2022-09-28 00:55:51,785 [trainer.py] => NME top1 curve: [87.15, 75.93, 66.88, 60.0, 56.69, 54.85]
2022-09-28 00:55:51,785 [trainer.py] => NME base curve: [87.15, 78.21, 68.16, 68.16, 68.72, 65.36]
2022-09-28 00:55:51,785 [trainer.py] => NME old curve: [87.15, 78.21, 68.05, 62.1, 57.03, 55.56]
2022-09-28 00:55:51,785 [trainer.py] => NME new curve: [0, 69.35, 63.01, 48.21, 54.93, 50.0]
2022-09-28 00:55:51,785 [trainer.py] => NME compound curve: [0, 69.35, 65.19, 52.36, 48.47, 49.08]
2022-09-28 00:55:51,786 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 00:55:51,786 [trainer.py] => prefix: cil
2022-09-28 00:55:51,786 [trainer.py] => dataset: CFEE
2022-09-28 00:55:51,786 [trainer.py] => memory_size: 2000
2022-09-28 00:55:51,786 [trainer.py] => memory_per_class: 20
2022-09-28 00:55:51,786 [trainer.py] => fixed_memory: True
2022-09-28 00:55:51,786 [trainer.py] => shuffle: True
2022-09-28 00:55:51,786 [trainer.py] => init_cls: 7
2022-09-28 00:55:51,786 [trainer.py] => increment: 3
2022-09-28 00:55:51,786 [trainer.py] => model_name: foster
2022-09-28 00:55:51,786 [trainer.py] => convnet_type: resnet18
2022-09-28 00:55:51,787 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 00:55:51,787 [trainer.py] => seed: 1993
2022-09-28 00:55:51,787 [trainer.py] => beta1: 0.96
2022-09-28 00:55:51,787 [trainer.py] => beta2: 0.97
2022-09-28 00:55:51,787 [trainer.py] => oofc: ft
2022-09-28 00:55:51,787 [trainer.py] => is_teacher_wa: False
2022-09-28 00:55:51,787 [trainer.py] => is_student_wa: False
2022-09-28 00:55:51,787 [trainer.py] => lambda_okd: 1
2022-09-28 00:55:51,787 [trainer.py] => wa_value: 1
2022-09-28 00:55:51,787 [trainer.py] => init_epochs: 40
2022-09-28 00:55:51,787 [trainer.py] => init_lr: 0.01
2022-09-28 00:55:51,787 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 00:55:51,787 [trainer.py] => boosting_epochs: 34
2022-09-28 00:55:51,787 [trainer.py] => compression_epochs: 26
2022-09-28 00:55:51,787 [trainer.py] => lr: 0.001
2022-09-28 00:55:51,787 [trainer.py] => batch_size: 32
2022-09-28 00:55:51,787 [trainer.py] => weight_decay: 0.0005
2022-09-28 00:55:51,787 [trainer.py] => num_workers: 8
2022-09-28 00:55:51,787 [trainer.py] => T: 2
2022-09-28 00:55:51,787 [trainer.py] => nb_runs: 3
2022-09-28 00:55:51,787 [trainer.py] => fold: 10
2022-09-28 00:55:51,787 [data.py] => ========== Fold:4 ==========
2022-09-28 00:55:51,792 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 13, 17, 15, 9, 11, 20, 18, 12, 14, 7, 10, 19, 21, 16, 8]
2022-09-28 00:55:52,004 [foster.py] => Learning on 0-7
2022-09-28 00:55:52,004 [foster.py] => All params: 11183694
2022-09-28 00:55:52,005 [foster.py] => Trainable params: 11183694
2022-09-28 00:55:54,410 [foster.py] => Task 0, Epoch 1/40 => Loss 1.336, Train_accy 49.49
2022-09-28 00:55:57,386 [foster.py] => Task 0, Epoch 2/40 => Loss 0.525, Train_accy 81.75, Test_accy 80.56
2022-09-28 00:56:00,378 [foster.py] => Task 0, Epoch 3/40 => Loss 0.341, Train_accy 88.59, Test_accy 84.72
2022-09-28 00:56:03,384 [foster.py] => Task 0, Epoch 4/40 => Loss 0.285, Train_accy 90.23, Test_accy 81.25
2022-09-28 00:56:06,345 [foster.py] => Task 0, Epoch 5/40 => Loss 0.231, Train_accy 91.80, Test_accy 86.11
2022-09-28 00:56:08,740 [foster.py] => Task 0, Epoch 6/40 => Loss 0.164, Train_accy 94.94
2022-09-28 00:56:11,700 [foster.py] => Task 0, Epoch 7/40 => Loss 0.159, Train_accy 94.46, Test_accy 86.11
2022-09-28 00:56:14,723 [foster.py] => Task 0, Epoch 8/40 => Loss 0.124, Train_accy 95.63, Test_accy 86.81
2022-09-28 00:56:17,747 [foster.py] => Task 0, Epoch 9/40 => Loss 0.109, Train_accy 96.17, Test_accy 87.50
2022-09-28 00:56:20,823 [foster.py] => Task 0, Epoch 10/40 => Loss 0.104, Train_accy 96.86, Test_accy 84.72
2022-09-28 00:56:23,266 [foster.py] => Task 0, Epoch 11/40 => Loss 0.103, Train_accy 96.38
2022-09-28 00:56:26,277 [foster.py] => Task 0, Epoch 12/40 => Loss 0.066, Train_accy 97.81, Test_accy 86.81
2022-09-28 00:56:29,249 [foster.py] => Task 0, Epoch 13/40 => Loss 0.060, Train_accy 98.15, Test_accy 87.50
2022-09-28 00:56:32,292 [foster.py] => Task 0, Epoch 14/40 => Loss 0.048, Train_accy 98.97, Test_accy 87.50
2022-09-28 00:56:35,249 [foster.py] => Task 0, Epoch 15/40 => Loss 0.054, Train_accy 98.29, Test_accy 86.81
2022-09-28 00:56:37,629 [foster.py] => Task 0, Epoch 16/40 => Loss 0.036, Train_accy 99.25
2022-09-28 00:56:40,606 [foster.py] => Task 0, Epoch 17/40 => Loss 0.037, Train_accy 99.25, Test_accy 89.58
2022-09-28 00:56:43,575 [foster.py] => Task 0, Epoch 18/40 => Loss 0.028, Train_accy 99.45, Test_accy 89.58
2022-09-28 00:56:46,552 [foster.py] => Task 0, Epoch 19/40 => Loss 0.032, Train_accy 98.97, Test_accy 87.50
2022-09-28 00:56:49,534 [foster.py] => Task 0, Epoch 20/40 => Loss 0.028, Train_accy 99.38, Test_accy 89.58
2022-09-28 00:56:51,908 [foster.py] => Task 0, Epoch 21/40 => Loss 0.023, Train_accy 99.66
2022-09-28 00:56:54,881 [foster.py] => Task 0, Epoch 22/40 => Loss 0.028, Train_accy 99.45, Test_accy 85.42
2022-09-28 00:56:57,892 [foster.py] => Task 0, Epoch 23/40 => Loss 0.024, Train_accy 99.52, Test_accy 88.19
2022-09-28 00:57:00,899 [foster.py] => Task 0, Epoch 24/40 => Loss 0.016, Train_accy 99.79, Test_accy 88.19
2022-09-28 00:57:03,900 [foster.py] => Task 0, Epoch 25/40 => Loss 0.015, Train_accy 100.00, Test_accy 88.19
2022-09-28 00:57:06,284 [foster.py] => Task 0, Epoch 26/40 => Loss 0.015, Train_accy 99.79
2022-09-28 00:57:09,260 [foster.py] => Task 0, Epoch 27/40 => Loss 0.019, Train_accy 99.79, Test_accy 88.89
2022-09-28 00:57:12,278 [foster.py] => Task 0, Epoch 28/40 => Loss 0.015, Train_accy 99.73, Test_accy 88.19
2022-09-28 00:57:15,252 [foster.py] => Task 0, Epoch 29/40 => Loss 0.018, Train_accy 99.59, Test_accy 88.19
2022-09-28 00:57:18,302 [foster.py] => Task 0, Epoch 30/40 => Loss 0.013, Train_accy 99.86, Test_accy 88.19
2022-09-28 00:57:20,673 [foster.py] => Task 0, Epoch 31/40 => Loss 0.018, Train_accy 99.52
2022-09-28 00:57:23,686 [foster.py] => Task 0, Epoch 32/40 => Loss 0.012, Train_accy 99.79, Test_accy 88.19
2022-09-28 00:57:26,698 [foster.py] => Task 0, Epoch 33/40 => Loss 0.018, Train_accy 99.59, Test_accy 88.89
2022-09-28 00:57:29,653 [foster.py] => Task 0, Epoch 34/40 => Loss 0.016, Train_accy 99.73, Test_accy 88.19
2022-09-28 00:57:32,667 [foster.py] => Task 0, Epoch 35/40 => Loss 0.013, Train_accy 99.86, Test_accy 88.89
2022-09-28 00:57:35,093 [foster.py] => Task 0, Epoch 36/40 => Loss 0.012, Train_accy 99.86
2022-09-28 00:57:38,113 [foster.py] => Task 0, Epoch 37/40 => Loss 0.014, Train_accy 99.79, Test_accy 88.89
2022-09-28 00:57:41,207 [foster.py] => Task 0, Epoch 38/40 => Loss 0.015, Train_accy 99.86, Test_accy 88.19
2022-09-28 00:57:44,178 [foster.py] => Task 0, Epoch 39/40 => Loss 0.015, Train_accy 99.52, Test_accy 88.19
2022-09-28 00:57:47,148 [foster.py] => Task 0, Epoch 40/40 => Loss 0.018, Train_accy 99.52, Test_accy 88.19
2022-09-28 00:57:47,148 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 00:57:53,984 [foster.py] => Exemplar size: 140
2022-09-28 00:57:53,984 [trainer.py] => CNN: {'total': 88.19, 'old': 88.19, 'new': 0, 'base': 88.19, 'compound': 0}
2022-09-28 00:57:53,984 [trainer.py] => CNN top1 curve: [88.19]
2022-09-28 00:57:53,984 [trainer.py] => CNN base curve: [88.19]
2022-09-28 00:57:53,984 [trainer.py] => CNN old curve: [88.19]
2022-09-28 00:57:53,984 [trainer.py] => CNN new curve: [0]
2022-09-28 00:57:53,984 [trainer.py] => CNN compound curve: [0]
2022-09-28 00:57:53,984 [trainer.py] => NME: {'total': 90.28, 'old': 90.28, 'new': 0, 'base': 90.28, 'compound': 0}
2022-09-28 00:57:53,984 [trainer.py] => NME top1 curve: [90.28]
2022-09-28 00:57:53,984 [trainer.py] => NME base curve: [90.28]
2022-09-28 00:57:53,984 [trainer.py] => NME old curve: [90.28]
2022-09-28 00:57:53,984 [trainer.py] => NME new curve: [0]
2022-09-28 00:57:53,984 [trainer.py] => NME compound curve: [0]
2022-09-28 00:57:54,213 [foster.py] => Learning on 7-10
2022-09-28 00:57:54,214 [foster.py] => All params: 22371995
2022-09-28 00:57:54,214 [foster.py] => Trainable params: 11191892
2022-09-28 00:57:54,234 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 00:57:56,697 [foster.py] => Task 1, Epoch 1/34 => Loss 4.381, Loss_clf 2.027, Loss_fe 1.676, Loss_kd 0.474, Train_accy 42.93, Test_accy 71.14
2022-09-28 00:57:58,443 [foster.py] => Task 1, Epoch 2/34 => Loss 2.363, Loss_clf 0.602, Loss_fe 1.088, Loss_kd 0.471, Train_accy 77.82
2022-09-28 00:58:00,201 [foster.py] => Task 1, Epoch 3/34 => Loss 1.879, Loss_clf 0.358, Loss_fe 0.877, Loss_kd 0.450, Train_accy 55.25
2022-09-28 00:58:01,952 [foster.py] => Task 1, Epoch 4/34 => Loss 1.774, Loss_clf 0.337, Loss_fe 0.765, Loss_kd 0.471, Train_accy 55.77
2022-09-28 00:58:03,712 [foster.py] => Task 1, Epoch 5/34 => Loss 1.676, Loss_clf 0.333, Loss_fe 0.710, Loss_kd 0.442, Train_accy 54.99
2022-09-28 00:58:06,244 [foster.py] => Task 1, Epoch 6/34 => Loss 1.618, Loss_clf 0.326, Loss_fe 0.646, Loss_kd 0.452, Train_accy 54.60, Test_accy 76.12
2022-09-28 00:58:08,016 [foster.py] => Task 1, Epoch 7/34 => Loss 1.546, Loss_clf 0.293, Loss_fe 0.620, Loss_kd 0.443, Train_accy 57.46
2022-09-28 00:58:09,785 [foster.py] => Task 1, Epoch 8/34 => Loss 1.485, Loss_clf 0.284, Loss_fe 0.539, Loss_kd 0.463, Train_accy 56.03
2022-09-28 00:58:11,519 [foster.py] => Task 1, Epoch 9/34 => Loss 1.455, Loss_clf 0.294, Loss_fe 0.525, Loss_kd 0.445, Train_accy 57.85
2022-09-28 00:58:13,268 [foster.py] => Task 1, Epoch 10/34 => Loss 1.401, Loss_clf 0.273, Loss_fe 0.480, Loss_kd 0.453, Train_accy 56.94
2022-09-28 00:58:15,712 [foster.py] => Task 1, Epoch 11/34 => Loss 1.410, Loss_clf 0.280, Loss_fe 0.474, Loss_kd 0.459, Train_accy 57.59, Test_accy 76.62
2022-09-28 00:58:17,471 [foster.py] => Task 1, Epoch 12/34 => Loss 1.327, Loss_clf 0.251, Loss_fe 0.440, Loss_kd 0.445, Train_accy 55.77
2022-09-28 00:58:19,251 [foster.py] => Task 1, Epoch 13/34 => Loss 1.308, Loss_clf 0.239, Loss_fe 0.418, Loss_kd 0.456, Train_accy 56.16
2022-09-28 00:58:20,982 [foster.py] => Task 1, Epoch 14/34 => Loss 1.309, Loss_clf 0.259, Loss_fe 0.416, Loss_kd 0.444, Train_accy 58.11
2022-09-28 00:58:22,708 [foster.py] => Task 1, Epoch 15/34 => Loss 1.323, Loss_clf 0.265, Loss_fe 0.427, Loss_kd 0.442, Train_accy 55.90
2022-09-28 00:58:25,186 [foster.py] => Task 1, Epoch 16/34 => Loss 1.284, Loss_clf 0.248, Loss_fe 0.414, Loss_kd 0.436, Train_accy 58.75, Test_accy 78.11
2022-09-28 00:58:26,911 [foster.py] => Task 1, Epoch 17/34 => Loss 1.313, Loss_clf 0.255, Loss_fe 0.419, Loss_kd 0.447, Train_accy 56.81
2022-09-28 00:58:28,682 [foster.py] => Task 1, Epoch 18/34 => Loss 1.316, Loss_clf 0.275, Loss_fe 0.410, Loss_kd 0.441, Train_accy 56.03
2022-09-28 00:58:30,435 [foster.py] => Task 1, Epoch 19/34 => Loss 1.241, Loss_clf 0.241, Loss_fe 0.356, Loss_kd 0.450, Train_accy 60.83
2022-09-28 00:58:32,183 [foster.py] => Task 1, Epoch 20/34 => Loss 1.278, Loss_clf 0.248, Loss_fe 0.389, Loss_kd 0.449, Train_accy 59.79
2022-09-28 00:58:34,647 [foster.py] => Task 1, Epoch 21/34 => Loss 1.234, Loss_clf 0.229, Loss_fe 0.364, Loss_kd 0.449, Train_accy 58.50, Test_accy 76.62
2022-09-28 00:58:36,396 [foster.py] => Task 1, Epoch 22/34 => Loss 1.210, Loss_clf 0.241, Loss_fe 0.336, Loss_kd 0.443, Train_accy 57.20
2022-09-28 00:58:38,122 [foster.py] => Task 1, Epoch 23/34 => Loss 1.217, Loss_clf 0.212, Loss_fe 0.337, Loss_kd 0.468, Train_accy 58.63
2022-09-28 00:58:39,892 [foster.py] => Task 1, Epoch 24/34 => Loss 1.182, Loss_clf 0.194, Loss_fe 0.342, Loss_kd 0.452, Train_accy 58.75
2022-09-28 00:58:41,623 [foster.py] => Task 1, Epoch 25/34 => Loss 1.274, Loss_clf 0.243, Loss_fe 0.388, Loss_kd 0.450, Train_accy 58.24
2022-09-28 00:58:44,057 [foster.py] => Task 1, Epoch 26/34 => Loss 1.198, Loss_clf 0.224, Loss_fe 0.334, Loss_kd 0.449, Train_accy 58.24, Test_accy 77.11
2022-09-28 00:58:45,784 [foster.py] => Task 1, Epoch 27/34 => Loss 1.260, Loss_clf 0.216, Loss_fe 0.409, Loss_kd 0.444, Train_accy 58.37
2022-09-28 00:58:47,625 [foster.py] => Task 1, Epoch 28/34 => Loss 1.185, Loss_clf 0.204, Loss_fe 0.348, Loss_kd 0.443, Train_accy 60.57
2022-09-28 00:58:49,409 [foster.py] => Task 1, Epoch 29/34 => Loss 1.234, Loss_clf 0.214, Loss_fe 0.367, Loss_kd 0.457, Train_accy 58.88
2022-09-28 00:58:51,148 [foster.py] => Task 1, Epoch 30/34 => Loss 1.204, Loss_clf 0.221, Loss_fe 0.354, Loss_kd 0.441, Train_accy 59.14
2022-09-28 00:58:53,595 [foster.py] => Task 1, Epoch 31/34 => Loss 1.198, Loss_clf 0.207, Loss_fe 0.333, Loss_kd 0.461, Train_accy 59.01, Test_accy 77.11
2022-09-28 00:58:55,366 [foster.py] => Task 1, Epoch 32/34 => Loss 1.209, Loss_clf 0.214, Loss_fe 0.345, Loss_kd 0.455, Train_accy 60.70
2022-09-28 00:58:57,128 [foster.py] => Task 1, Epoch 33/34 => Loss 1.189, Loss_clf 0.208, Loss_fe 0.327, Loss_kd 0.458, Train_accy 58.11
2022-09-28 00:58:58,935 [foster.py] => Task 1, Epoch 34/34 => Loss 1.206, Loss_clf 0.216, Loss_fe 0.332, Loss_kd 0.461, Train_accy 58.50
2022-09-28 00:58:58,936 [foster.py] => do not weight align teacher!
2022-09-28 00:58:58,936 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 00:59:01,833 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.554,  Train_accy 17.90, Test_accy 62.69
2022-09-28 00:59:03,811 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.417,  Train_accy 18.16
2022-09-28 00:59:05,831 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.339,  Train_accy 19.33
2022-09-28 00:59:07,866 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.273,  Train_accy 23.61
2022-09-28 00:59:09,804 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.254,  Train_accy 26.46
2022-09-28 00:59:12,427 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.202,  Train_accy 30.87, Test_accy 66.17
2022-09-28 00:59:14,413 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.207,  Train_accy 30.87
2022-09-28 00:59:16,357 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.203,  Train_accy 33.33
2022-09-28 00:59:18,303 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.192,  Train_accy 33.98
2022-09-28 00:59:20,228 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.195,  Train_accy 36.06
2022-09-28 00:59:22,801 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.205,  Train_accy 35.28, Test_accy 68.66
2022-09-28 00:59:24,734 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.155,  Train_accy 35.93
2022-09-28 00:59:26,708 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.126,  Train_accy 36.71
2022-09-28 00:59:28,705 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.141,  Train_accy 35.67
2022-09-28 00:59:30,647 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.208,  Train_accy 37.74
2022-09-28 00:59:33,263 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.146,  Train_accy 37.87, Test_accy 70.15
2022-09-28 00:59:35,203 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.166,  Train_accy 38.91
2022-09-28 00:59:37,177 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.135,  Train_accy 38.91
2022-09-28 00:59:39,145 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.170,  Train_accy 39.69
2022-09-28 00:59:41,117 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.152,  Train_accy 38.26
2022-09-28 00:59:43,778 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.147,  Train_accy 39.17, Test_accy 71.14
2022-09-28 00:59:45,762 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.175,  Train_accy 38.26
2022-09-28 00:59:47,719 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.148,  Train_accy 38.39
2022-09-28 00:59:49,672 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.159,  Train_accy 38.91
2022-09-28 00:59:51,605 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.150,  Train_accy 38.65
2022-09-28 00:59:54,219 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.186,  Train_accy 39.82, Test_accy 70.15
2022-09-28 00:59:54,219 [foster.py] => do not weight align student!
2022-09-28 00:59:54,854 [foster.py] => darknet eval: 
2022-09-28 00:59:54,855 [foster.py] => CNN top1 curve: 70.15
2022-09-28 00:59:54,855 [foster.py] => CNN top5 curve: 98.01
2022-09-28 00:59:54,855 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 01:00:01,133 [foster.py] => Exemplar size: 200
2022-09-28 01:00:01,133 [trainer.py] => CNN: {'total': 77.61, 'old': 86.11, 'new': 56.14, 'base': 86.11, 'compound': 56.14}
2022-09-28 01:00:01,133 [trainer.py] => CNN top1 curve: [88.19, 77.61]
2022-09-28 01:00:01,133 [trainer.py] => CNN base curve: [88.19, 86.11]
2022-09-28 01:00:01,133 [trainer.py] => CNN old curve: [88.19, 86.11]
2022-09-28 01:00:01,133 [trainer.py] => CNN new curve: [0, 56.14]
2022-09-28 01:00:01,133 [trainer.py] => CNN compound curve: [0, 56.14]
2022-09-28 01:00:01,133 [trainer.py] => NME: {'total': 85.57, 'old': 85.42, 'new': 85.96, 'base': 85.42, 'compound': 85.96}
2022-09-28 01:00:01,133 [trainer.py] => NME top1 curve: [90.28, 85.57]
2022-09-28 01:00:01,133 [trainer.py] => NME base curve: [90.28, 85.42]
2022-09-28 01:00:01,133 [trainer.py] => NME old curve: [90.28, 85.42]
2022-09-28 01:00:01,133 [trainer.py] => NME new curve: [0, 85.96]
2022-09-28 01:00:01,133 [trainer.py] => NME compound curve: [0, 85.96]
2022-09-28 01:00:01,361 [foster.py] => Learning on 10-13
2022-09-28 01:00:01,362 [foster.py] => All params: 22378148
2022-09-28 01:00:01,362 [foster.py] => Trainable params: 11196506
2022-09-28 01:00:01,382 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 01:00:04,014 [foster.py] => Task 2, Epoch 1/34 => Loss 5.353, Loss_clf 2.361, Loss_fe 1.946, Loss_kd 0.805, Train_accy 37.00, Test_accy 49.82
2022-09-28 01:00:05,839 [foster.py] => Task 2, Epoch 2/34 => Loss 3.199, Loss_clf 0.850, Loss_fe 1.304, Loss_kd 0.804, Train_accy 48.64
2022-09-28 01:00:07,658 [foster.py] => Task 2, Epoch 3/34 => Loss 2.830, Loss_clf 0.681, Loss_fe 1.134, Loss_kd 0.782, Train_accy 43.07
2022-09-28 01:00:09,505 [foster.py] => Task 2, Epoch 4/34 => Loss 2.707, Loss_clf 0.648, Loss_fe 1.058, Loss_kd 0.770, Train_accy 42.20
2022-09-28 01:00:11,313 [foster.py] => Task 2, Epoch 5/34 => Loss 2.566, Loss_clf 0.576, Loss_fe 0.973, Loss_kd 0.782, Train_accy 42.95
2022-09-28 01:00:13,862 [foster.py] => Task 2, Epoch 6/34 => Loss 2.471, Loss_clf 0.566, Loss_fe 0.897, Loss_kd 0.775, Train_accy 43.94, Test_accy 62.28
2022-09-28 01:00:15,674 [foster.py] => Task 2, Epoch 7/34 => Loss 2.367, Loss_clf 0.523, Loss_fe 0.825, Loss_kd 0.784, Train_accy 44.43
2022-09-28 01:00:17,474 [foster.py] => Task 2, Epoch 8/34 => Loss 2.335, Loss_clf 0.524, Loss_fe 0.795, Loss_kd 0.781, Train_accy 42.95
2022-09-28 01:00:19,287 [foster.py] => Task 2, Epoch 9/34 => Loss 2.283, Loss_clf 0.519, Loss_fe 0.747, Loss_kd 0.782, Train_accy 46.53
2022-09-28 01:00:21,127 [foster.py] => Task 2, Epoch 10/34 => Loss 2.246, Loss_clf 0.509, Loss_fe 0.736, Loss_kd 0.770, Train_accy 42.82
2022-09-28 01:00:23,696 [foster.py] => Task 2, Epoch 11/34 => Loss 2.208, Loss_clf 0.494, Loss_fe 0.699, Loss_kd 0.780, Train_accy 45.42, Test_accy 61.57
2022-09-28 01:00:25,473 [foster.py] => Task 2, Epoch 12/34 => Loss 2.196, Loss_clf 0.489, Loss_fe 0.700, Loss_kd 0.774, Train_accy 43.19
2022-09-28 01:00:27,301 [foster.py] => Task 2, Epoch 13/34 => Loss 2.117, Loss_clf 0.458, Loss_fe 0.649, Loss_kd 0.777, Train_accy 46.78
2022-09-28 01:00:29,142 [foster.py] => Task 2, Epoch 14/34 => Loss 2.154, Loss_clf 0.480, Loss_fe 0.655, Loss_kd 0.783, Train_accy 47.40
2022-09-28 01:00:30,997 [foster.py] => Task 2, Epoch 15/34 => Loss 2.143, Loss_clf 0.469, Loss_fe 0.650, Loss_kd 0.788, Train_accy 46.04
2022-09-28 01:00:33,599 [foster.py] => Task 2, Epoch 16/34 => Loss 2.067, Loss_clf 0.447, Loss_fe 0.602, Loss_kd 0.783, Train_accy 46.04, Test_accy 62.28
2022-09-28 01:00:35,418 [foster.py] => Task 2, Epoch 17/34 => Loss 2.043, Loss_clf 0.426, Loss_fe 0.601, Loss_kd 0.782, Train_accy 47.40
2022-09-28 01:00:37,284 [foster.py] => Task 2, Epoch 18/34 => Loss 2.001, Loss_clf 0.412, Loss_fe 0.574, Loss_kd 0.781, Train_accy 47.28
2022-09-28 01:00:39,153 [foster.py] => Task 2, Epoch 19/34 => Loss 1.990, Loss_clf 0.419, Loss_fe 0.567, Loss_kd 0.772, Train_accy 48.27
2022-09-28 01:00:40,929 [foster.py] => Task 2, Epoch 20/34 => Loss 1.979, Loss_clf 0.415, Loss_fe 0.551, Loss_kd 0.779, Train_accy 48.64
2022-09-28 01:00:43,538 [foster.py] => Task 2, Epoch 21/34 => Loss 1.949, Loss_clf 0.398, Loss_fe 0.540, Loss_kd 0.777, Train_accy 49.13, Test_accy 62.28
2022-09-28 01:00:45,310 [foster.py] => Task 2, Epoch 22/34 => Loss 1.945, Loss_clf 0.398, Loss_fe 0.532, Loss_kd 0.781, Train_accy 47.15
2022-09-28 01:00:47,121 [foster.py] => Task 2, Epoch 23/34 => Loss 1.938, Loss_clf 0.385, Loss_fe 0.527, Loss_kd 0.790, Train_accy 50.25
2022-09-28 01:00:48,915 [foster.py] => Task 2, Epoch 24/34 => Loss 1.933, Loss_clf 0.390, Loss_fe 0.531, Loss_kd 0.778, Train_accy 48.39
2022-09-28 01:00:50,723 [foster.py] => Task 2, Epoch 25/34 => Loss 1.904, Loss_clf 0.384, Loss_fe 0.513, Loss_kd 0.775, Train_accy 47.03
2022-09-28 01:00:53,288 [foster.py] => Task 2, Epoch 26/34 => Loss 1.910, Loss_clf 0.394, Loss_fe 0.526, Loss_kd 0.762, Train_accy 46.66, Test_accy 62.63
2022-09-28 01:00:55,117 [foster.py] => Task 2, Epoch 27/34 => Loss 1.917, Loss_clf 0.379, Loss_fe 0.512, Loss_kd 0.789, Train_accy 47.77
2022-09-28 01:00:56,969 [foster.py] => Task 2, Epoch 28/34 => Loss 1.906, Loss_clf 0.373, Loss_fe 0.528, Loss_kd 0.773, Train_accy 49.01
2022-09-28 01:00:58,808 [foster.py] => Task 2, Epoch 29/34 => Loss 1.881, Loss_clf 0.370, Loss_fe 0.506, Loss_kd 0.773, Train_accy 48.14
2022-09-28 01:01:00,634 [foster.py] => Task 2, Epoch 30/34 => Loss 1.890, Loss_clf 0.381, Loss_fe 0.504, Loss_kd 0.774, Train_accy 49.50
2022-09-28 01:01:03,232 [foster.py] => Task 2, Epoch 31/34 => Loss 1.906, Loss_clf 0.384, Loss_fe 0.510, Loss_kd 0.779, Train_accy 49.38, Test_accy 62.28
2022-09-28 01:01:05,093 [foster.py] => Task 2, Epoch 32/34 => Loss 1.879, Loss_clf 0.369, Loss_fe 0.501, Loss_kd 0.776, Train_accy 47.90
2022-09-28 01:01:06,902 [foster.py] => Task 2, Epoch 33/34 => Loss 1.877, Loss_clf 0.364, Loss_fe 0.504, Loss_kd 0.776, Train_accy 49.01
2022-09-28 01:01:08,717 [foster.py] => Task 2, Epoch 34/34 => Loss 1.974, Loss_clf 0.396, Loss_fe 0.553, Loss_kd 0.788, Train_accy 48.76
2022-09-28 01:01:08,717 [foster.py] => do not weight align teacher!
2022-09-28 01:01:08,717 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 01:01:11,655 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.811,  Train_accy 17.57, Test_accy 48.04
2022-09-28 01:01:13,706 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.671,  Train_accy 18.69
2022-09-28 01:01:15,731 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.591,  Train_accy 19.31
2022-09-28 01:01:17,768 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.553,  Train_accy 19.31
2022-09-28 01:01:19,799 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.543,  Train_accy 19.93
2022-09-28 01:01:22,503 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.503,  Train_accy 20.30, Test_accy 51.25
2022-09-28 01:01:24,501 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.519,  Train_accy 21.29
2022-09-28 01:01:26,484 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.500,  Train_accy 22.03
2022-09-28 01:01:28,477 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.488,  Train_accy 21.66
2022-09-28 01:01:30,518 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.488,  Train_accy 22.52
2022-09-28 01:01:33,296 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.514,  Train_accy 23.14, Test_accy 51.96
2022-09-28 01:01:35,321 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.497,  Train_accy 23.02
2022-09-28 01:01:37,320 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.481,  Train_accy 22.90
2022-09-28 01:01:39,366 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.492,  Train_accy 23.51
2022-09-28 01:01:41,360 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.454,  Train_accy 22.77
2022-09-28 01:01:44,097 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.482,  Train_accy 23.76, Test_accy 53.74
2022-09-28 01:01:46,151 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.479,  Train_accy 23.14
2022-09-28 01:01:48,153 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.474,  Train_accy 23.51
2022-09-28 01:01:50,160 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.478,  Train_accy 24.01
2022-09-28 01:01:52,200 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.480,  Train_accy 24.13
2022-09-28 01:01:55,028 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.478,  Train_accy 23.27, Test_accy 53.38
2022-09-28 01:01:57,014 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.465,  Train_accy 22.52
2022-09-28 01:01:59,054 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.475,  Train_accy 24.38
2022-09-28 01:02:01,058 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.465,  Train_accy 23.64
2022-09-28 01:02:03,073 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.474,  Train_accy 23.51
2022-09-28 01:02:05,757 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.467,  Train_accy 24.38, Test_accy 52.31
2022-09-28 01:02:05,757 [foster.py] => do not weight align student!
2022-09-28 01:02:06,450 [foster.py] => darknet eval: 
2022-09-28 01:02:06,450 [foster.py] => CNN top1 curve: 52.31
2022-09-28 01:02:06,450 [foster.py] => CNN top5 curve: 96.44
2022-09-28 01:02:06,450 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 01:02:13,762 [foster.py] => Exemplar size: 260
2022-09-28 01:02:13,762 [trainer.py] => CNN: {'total': 61.92, 'old': 74.63, 'new': 30.0, 'base': 79.17, 'compound': 43.8}
2022-09-28 01:02:13,762 [trainer.py] => CNN top1 curve: [88.19, 77.61, 61.92]
2022-09-28 01:02:13,762 [trainer.py] => CNN base curve: [88.19, 86.11, 79.17]
2022-09-28 01:02:13,762 [trainer.py] => CNN old curve: [88.19, 86.11, 74.63]
2022-09-28 01:02:13,762 [trainer.py] => CNN new curve: [0, 56.14, 30.0]
2022-09-28 01:02:13,762 [trainer.py] => CNN compound curve: [0, 56.14, 43.8]
2022-09-28 01:02:13,762 [trainer.py] => NME: {'total': 72.24, 'old': 79.1, 'new': 55.0, 'base': 78.47, 'compound': 65.69}
2022-09-28 01:02:13,762 [trainer.py] => NME top1 curve: [90.28, 85.57, 72.24]
2022-09-28 01:02:13,762 [trainer.py] => NME base curve: [90.28, 85.42, 78.47]
2022-09-28 01:02:13,762 [trainer.py] => NME old curve: [90.28, 85.42, 79.1]
2022-09-28 01:02:13,762 [trainer.py] => NME new curve: [0, 85.96, 55.0]
2022-09-28 01:02:13,762 [trainer.py] => NME compound curve: [0, 85.96, 65.69]
2022-09-28 01:02:13,992 [foster.py] => Learning on 13-16
2022-09-28 01:02:13,993 [foster.py] => All params: 22384301
2022-09-28 01:02:13,993 [foster.py] => Trainable params: 11201120
2022-09-28 01:02:14,013 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 01:02:16,795 [foster.py] => Task 3, Epoch 1/34 => Loss 5.765, Loss_clf 1.858, Loss_fe 2.311, Loss_kd 1.298, Train_accy 38.93, Test_accy 41.53
2022-09-28 01:02:18,671 [foster.py] => Task 3, Epoch 2/34 => Loss 4.219, Loss_clf 0.999, Loss_fe 1.619, Loss_kd 1.300, Train_accy 39.27
2022-09-28 01:02:20,563 [foster.py] => Task 3, Epoch 3/34 => Loss 3.903, Loss_clf 0.890, Loss_fe 1.420, Loss_kd 1.295, Train_accy 40.64
2022-09-28 01:02:22,498 [foster.py] => Task 3, Epoch 4/34 => Loss 3.792, Loss_clf 0.864, Loss_fe 1.330, Loss_kd 1.298, Train_accy 38.58
2022-09-28 01:02:24,395 [foster.py] => Task 3, Epoch 5/34 => Loss 3.623, Loss_clf 0.813, Loss_fe 1.206, Loss_kd 1.304, Train_accy 38.58
2022-09-28 01:02:27,183 [foster.py] => Task 3, Epoch 6/34 => Loss 3.549, Loss_clf 0.796, Loss_fe 1.153, Loss_kd 1.300, Train_accy 42.01, Test_accy 51.41
2022-09-28 01:02:29,151 [foster.py] => Task 3, Epoch 7/34 => Loss 3.496, Loss_clf 0.793, Loss_fe 1.109, Loss_kd 1.295, Train_accy 41.32
2022-09-28 01:02:31,065 [foster.py] => Task 3, Epoch 8/34 => Loss 3.430, Loss_clf 0.765, Loss_fe 1.066, Loss_kd 1.299, Train_accy 39.61
2022-09-28 01:02:33,001 [foster.py] => Task 3, Epoch 9/34 => Loss 3.370, Loss_clf 0.754, Loss_fe 1.017, Loss_kd 1.298, Train_accy 41.78
2022-09-28 01:02:34,940 [foster.py] => Task 3, Epoch 10/34 => Loss 3.322, Loss_clf 0.767, Loss_fe 0.971, Loss_kd 1.287, Train_accy 40.98
2022-09-28 01:02:37,756 [foster.py] => Task 3, Epoch 11/34 => Loss 3.250, Loss_clf 0.713, Loss_fe 0.940, Loss_kd 1.297, Train_accy 41.10, Test_accy 53.11
2022-09-28 01:02:39,687 [foster.py] => Task 3, Epoch 12/34 => Loss 3.169, Loss_clf 0.688, Loss_fe 0.884, Loss_kd 1.298, Train_accy 41.21
2022-09-28 01:02:41,613 [foster.py] => Task 3, Epoch 13/34 => Loss 3.165, Loss_clf 0.697, Loss_fe 0.870, Loss_kd 1.298, Train_accy 43.84
2022-09-28 01:02:43,497 [foster.py] => Task 3, Epoch 14/34 => Loss 3.132, Loss_clf 0.688, Loss_fe 0.842, Loss_kd 1.301, Train_accy 44.06
2022-09-28 01:02:45,390 [foster.py] => Task 3, Epoch 15/34 => Loss 3.140, Loss_clf 0.699, Loss_fe 0.842, Loss_kd 1.300, Train_accy 42.58
2022-09-28 01:02:48,210 [foster.py] => Task 3, Epoch 16/34 => Loss 3.087, Loss_clf 0.662, Loss_fe 0.824, Loss_kd 1.301, Train_accy 43.38, Test_accy 53.39
2022-09-28 01:02:50,121 [foster.py] => Task 3, Epoch 17/34 => Loss 3.034, Loss_clf 0.641, Loss_fe 0.787, Loss_kd 1.305, Train_accy 44.75
2022-09-28 01:02:52,037 [foster.py] => Task 3, Epoch 18/34 => Loss 3.056, Loss_clf 0.653, Loss_fe 0.796, Loss_kd 1.306, Train_accy 45.32
2022-09-28 01:02:53,992 [foster.py] => Task 3, Epoch 19/34 => Loss 3.019, Loss_clf 0.658, Loss_fe 0.772, Loss_kd 1.290, Train_accy 44.75
2022-09-28 01:02:55,906 [foster.py] => Task 3, Epoch 20/34 => Loss 3.033, Loss_clf 0.654, Loss_fe 0.772, Loss_kd 1.306, Train_accy 45.89
2022-09-28 01:02:58,671 [foster.py] => Task 3, Epoch 21/34 => Loss 2.953, Loss_clf 0.610, Loss_fe 0.751, Loss_kd 1.293, Train_accy 44.18, Test_accy 53.11
2022-09-28 01:03:00,617 [foster.py] => Task 3, Epoch 22/34 => Loss 2.948, Loss_clf 0.616, Loss_fe 0.730, Loss_kd 1.303, Train_accy 47.03
2022-09-28 01:03:02,541 [foster.py] => Task 3, Epoch 23/34 => Loss 2.973, Loss_clf 0.628, Loss_fe 0.745, Loss_kd 1.300, Train_accy 43.26
2022-09-28 01:03:04,432 [foster.py] => Task 3, Epoch 24/34 => Loss 2.944, Loss_clf 0.613, Loss_fe 0.729, Loss_kd 1.302, Train_accy 46.46
2022-09-28 01:03:06,321 [foster.py] => Task 3, Epoch 25/34 => Loss 2.940, Loss_clf 0.623, Loss_fe 0.726, Loss_kd 1.293, Train_accy 46.00
2022-09-28 01:03:09,155 [foster.py] => Task 3, Epoch 26/34 => Loss 2.904, Loss_clf 0.599, Loss_fe 0.710, Loss_kd 1.296, Train_accy 45.66, Test_accy 53.11
2022-09-28 01:03:11,080 [foster.py] => Task 3, Epoch 27/34 => Loss 2.899, Loss_clf 0.596, Loss_fe 0.707, Loss_kd 1.297, Train_accy 47.26
2022-09-28 01:03:13,022 [foster.py] => Task 3, Epoch 28/34 => Loss 2.915, Loss_clf 0.596, Loss_fe 0.715, Loss_kd 1.304, Train_accy 47.15
2022-09-28 01:03:14,935 [foster.py] => Task 3, Epoch 29/34 => Loss 2.898, Loss_clf 0.586, Loss_fe 0.703, Loss_kd 1.307, Train_accy 44.75
2022-09-28 01:03:16,889 [foster.py] => Task 3, Epoch 30/34 => Loss 2.888, Loss_clf 0.578, Loss_fe 0.711, Loss_kd 1.299, Train_accy 45.32
2022-09-28 01:03:19,638 [foster.py] => Task 3, Epoch 31/34 => Loss 2.896, Loss_clf 0.598, Loss_fe 0.698, Loss_kd 1.300, Train_accy 45.55, Test_accy 53.39
2022-09-28 01:03:21,513 [foster.py] => Task 3, Epoch 32/34 => Loss 2.881, Loss_clf 0.586, Loss_fe 0.698, Loss_kd 1.297, Train_accy 46.69
2022-09-28 01:03:23,448 [foster.py] => Task 3, Epoch 33/34 => Loss 2.878, Loss_clf 0.586, Loss_fe 0.698, Loss_kd 1.294, Train_accy 45.78
2022-09-28 01:03:25,390 [foster.py] => Task 3, Epoch 34/34 => Loss 2.935, Loss_clf 0.600, Loss_fe 0.720, Loss_kd 1.311, Train_accy 46.92
2022-09-28 01:03:25,390 [foster.py] => do not weight align teacher!
2022-09-28 01:03:25,391 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 01:03:28,535 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.052,  Train_accy 19.29, Test_accy 41.24
2022-09-28 01:03:30,698 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 1.967,  Train_accy 19.98
2022-09-28 01:03:32,809 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 1.955,  Train_accy 19.86
2022-09-28 01:03:34,993 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 1.927,  Train_accy 20.09
2022-09-28 01:03:37,131 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.927,  Train_accy 20.89
2022-09-28 01:03:40,039 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.921,  Train_accy 20.78, Test_accy 46.05
2022-09-28 01:03:42,229 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.913,  Train_accy 19.98
2022-09-28 01:03:44,353 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.909,  Train_accy 20.32
2022-09-28 01:03:46,509 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.907,  Train_accy 21.00
2022-09-28 01:03:48,636 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.911,  Train_accy 19.98
2022-09-28 01:03:51,546 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.896,  Train_accy 21.12, Test_accy 47.18
2022-09-28 01:03:53,710 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.894,  Train_accy 21.00
2022-09-28 01:03:55,876 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.904,  Train_accy 20.66
2022-09-28 01:03:58,000 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.892,  Train_accy 20.89
2022-09-28 01:04:00,151 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.900,  Train_accy 21.46
2022-09-28 01:04:03,046 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.886,  Train_accy 21.35, Test_accy 47.74
2022-09-28 01:04:05,156 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.902,  Train_accy 22.03
2022-09-28 01:04:07,312 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.888,  Train_accy 20.55
2022-09-28 01:04:09,468 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.896,  Train_accy 21.23
2022-09-28 01:04:11,628 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.893,  Train_accy 21.12
2022-09-28 01:04:14,506 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.891,  Train_accy 21.69, Test_accy 47.46
2022-09-28 01:04:16,615 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.890,  Train_accy 20.89
2022-09-28 01:04:18,762 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.885,  Train_accy 21.00
2022-09-28 01:04:20,874 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.887,  Train_accy 21.58
2022-09-28 01:04:22,998 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.890,  Train_accy 20.66
2022-09-28 01:04:25,900 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.885,  Train_accy 21.00, Test_accy 48.02
2022-09-28 01:04:25,901 [foster.py] => do not weight align student!
2022-09-28 01:04:26,637 [foster.py] => darknet eval: 
2022-09-28 01:04:26,637 [foster.py] => CNN top1 curve: 48.02
2022-09-28 01:04:26,637 [foster.py] => CNN top5 curve: 90.68
2022-09-28 01:04:26,638 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 01:04:35,141 [foster.py] => Exemplar size: 320
2022-09-28 01:04:35,141 [trainer.py] => CNN: {'total': 53.11, 'old': 59.43, 'new': 28.77, 'base': 76.39, 'compound': 37.14}
2022-09-28 01:04:35,141 [trainer.py] => CNN top1 curve: [88.19, 77.61, 61.92, 53.11]
2022-09-28 01:04:35,141 [trainer.py] => CNN base curve: [88.19, 86.11, 79.17, 76.39]
2022-09-28 01:04:35,141 [trainer.py] => CNN old curve: [88.19, 86.11, 74.63, 59.43]
2022-09-28 01:04:35,141 [trainer.py] => CNN new curve: [0, 56.14, 30.0, 28.77]
2022-09-28 01:04:35,141 [trainer.py] => CNN compound curve: [0, 56.14, 43.8, 37.14]
2022-09-28 01:04:35,141 [trainer.py] => NME: {'total': 60.73, 'old': 65.48, 'new': 42.47, 'base': 72.22, 'compound': 52.86}
2022-09-28 01:04:35,141 [trainer.py] => NME top1 curve: [90.28, 85.57, 72.24, 60.73]
2022-09-28 01:04:35,141 [trainer.py] => NME base curve: [90.28, 85.42, 78.47, 72.22]
2022-09-28 01:04:35,141 [trainer.py] => NME old curve: [90.28, 85.42, 79.1, 65.48]
2022-09-28 01:04:35,141 [trainer.py] => NME new curve: [0, 85.96, 55.0, 42.47]
2022-09-28 01:04:35,141 [trainer.py] => NME compound curve: [0, 85.96, 65.69, 52.86]
2022-09-28 01:04:35,371 [foster.py] => Learning on 16-19
2022-09-28 01:04:35,371 [foster.py] => All params: 22390454
2022-09-28 01:04:35,371 [foster.py] => Trainable params: 11205734
2022-09-28 01:04:35,392 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 01:04:38,298 [foster.py] => Task 4, Epoch 1/34 => Loss 6.434, Loss_clf 1.862, Loss_fe 2.680, Loss_kd 1.593, Train_accy 41.41, Test_accy 45.05
2022-09-28 01:04:40,311 [foster.py] => Task 4, Epoch 2/34 => Loss 4.505, Loss_clf 0.923, Loss_fe 1.681, Loss_kd 1.601, Train_accy 38.63
2022-09-28 01:04:42,319 [foster.py] => Task 4, Epoch 3/34 => Loss 4.154, Loss_clf 0.819, Loss_fe 1.439, Loss_kd 1.597, Train_accy 45.78
2022-09-28 01:04:44,353 [foster.py] => Task 4, Epoch 4/34 => Loss 4.063, Loss_clf 0.831, Loss_fe 1.346, Loss_kd 1.588, Train_accy 46.21
2022-09-28 01:04:46,403 [foster.py] => Task 4, Epoch 5/34 => Loss 3.894, Loss_clf 0.785, Loss_fe 1.223, Loss_kd 1.588, Train_accy 43.65
2022-09-28 01:04:49,393 [foster.py] => Task 4, Epoch 6/34 => Loss 3.837, Loss_clf 0.771, Loss_fe 1.170, Loss_kd 1.596, Train_accy 47.60, Test_accy 47.88
2022-09-28 01:04:51,399 [foster.py] => Task 4, Epoch 7/34 => Loss 3.726, Loss_clf 0.753, Loss_fe 1.096, Loss_kd 1.581, Train_accy 46.21
2022-09-28 01:04:53,393 [foster.py] => Task 4, Epoch 8/34 => Loss 3.693, Loss_clf 0.738, Loss_fe 1.057, Loss_kd 1.598, Train_accy 45.57
2022-09-28 01:04:55,464 [foster.py] => Task 4, Epoch 9/34 => Loss 3.583, Loss_clf 0.703, Loss_fe 0.994, Loss_kd 1.588, Train_accy 49.52
2022-09-28 01:04:57,454 [foster.py] => Task 4, Epoch 10/34 => Loss 3.622, Loss_clf 0.728, Loss_fe 1.002, Loss_kd 1.593, Train_accy 46.32
2022-09-28 01:05:00,369 [foster.py] => Task 4, Epoch 11/34 => Loss 3.489, Loss_clf 0.686, Loss_fe 0.910, Loss_kd 1.594, Train_accy 48.35, Test_accy 50.94
2022-09-28 01:05:02,372 [foster.py] => Task 4, Epoch 12/34 => Loss 3.470, Loss_clf 0.680, Loss_fe 0.894, Loss_kd 1.597, Train_accy 46.64
2022-09-28 01:05:04,351 [foster.py] => Task 4, Epoch 13/34 => Loss 3.407, Loss_clf 0.660, Loss_fe 0.860, Loss_kd 1.589, Train_accy 48.67
2022-09-28 01:05:06,399 [foster.py] => Task 4, Epoch 14/34 => Loss 3.387, Loss_clf 0.653, Loss_fe 0.851, Loss_kd 1.585, Train_accy 48.24
2022-09-28 01:05:08,405 [foster.py] => Task 4, Epoch 15/34 => Loss 3.414, Loss_clf 0.663, Loss_fe 0.855, Loss_kd 1.596, Train_accy 48.67
2022-09-28 01:05:11,302 [foster.py] => Task 4, Epoch 16/34 => Loss 3.392, Loss_clf 0.659, Loss_fe 0.845, Loss_kd 1.590, Train_accy 48.56, Test_accy 51.18
2022-09-28 01:05:13,299 [foster.py] => Task 4, Epoch 17/34 => Loss 3.317, Loss_clf 0.632, Loss_fe 0.800, Loss_kd 1.587, Train_accy 49.31
2022-09-28 01:05:15,282 [foster.py] => Task 4, Epoch 18/34 => Loss 3.300, Loss_clf 0.615, Loss_fe 0.789, Loss_kd 1.596, Train_accy 48.77
2022-09-28 01:05:17,313 [foster.py] => Task 4, Epoch 19/34 => Loss 3.298, Loss_clf 0.626, Loss_fe 0.774, Loss_kd 1.598, Train_accy 49.31
2022-09-28 01:05:19,326 [foster.py] => Task 4, Epoch 20/34 => Loss 3.246, Loss_clf 0.609, Loss_fe 0.753, Loss_kd 1.587, Train_accy 50.59
2022-09-28 01:05:22,241 [foster.py] => Task 4, Epoch 21/34 => Loss 3.287, Loss_clf 0.612, Loss_fe 0.788, Loss_kd 1.589, Train_accy 50.91, Test_accy 51.65
2022-09-28 01:05:24,270 [foster.py] => Task 4, Epoch 22/34 => Loss 3.278, Loss_clf 0.621, Loss_fe 0.763, Loss_kd 1.595, Train_accy 49.63
2022-09-28 01:05:26,257 [foster.py] => Task 4, Epoch 23/34 => Loss 3.286, Loss_clf 0.623, Loss_fe 0.766, Loss_kd 1.598, Train_accy 48.99
2022-09-28 01:05:28,244 [foster.py] => Task 4, Epoch 24/34 => Loss 3.240, Loss_clf 0.609, Loss_fe 0.746, Loss_kd 1.587, Train_accy 49.52
2022-09-28 01:05:30,258 [foster.py] => Task 4, Epoch 25/34 => Loss 3.206, Loss_clf 0.587, Loss_fe 0.726, Loss_kd 1.594, Train_accy 50.37
2022-09-28 01:05:33,164 [foster.py] => Task 4, Epoch 26/34 => Loss 3.215, Loss_clf 0.593, Loss_fe 0.734, Loss_kd 1.590, Train_accy 50.59, Test_accy 51.65
2022-09-28 01:05:35,143 [foster.py] => Task 4, Epoch 27/34 => Loss 3.224, Loss_clf 0.602, Loss_fe 0.735, Loss_kd 1.589, Train_accy 50.37
2022-09-28 01:05:37,131 [foster.py] => Task 4, Epoch 28/34 => Loss 3.260, Loss_clf 0.615, Loss_fe 0.748, Loss_kd 1.597, Train_accy 51.12
2022-09-28 01:05:39,155 [foster.py] => Task 4, Epoch 29/34 => Loss 3.176, Loss_clf 0.584, Loss_fe 0.716, Loss_kd 1.580, Train_accy 50.48
2022-09-28 01:05:41,203 [foster.py] => Task 4, Epoch 30/34 => Loss 3.221, Loss_clf 0.589, Loss_fe 0.726, Loss_kd 1.605, Train_accy 51.76
2022-09-28 01:05:44,113 [foster.py] => Task 4, Epoch 31/34 => Loss 3.200, Loss_clf 0.593, Loss_fe 0.723, Loss_kd 1.586, Train_accy 49.41, Test_accy 51.18
2022-09-28 01:05:46,085 [foster.py] => Task 4, Epoch 32/34 => Loss 3.243, Loss_clf 0.612, Loss_fe 0.738, Loss_kd 1.594, Train_accy 50.48
2022-09-28 01:05:48,068 [foster.py] => Task 4, Epoch 33/34 => Loss 3.189, Loss_clf 0.581, Loss_fe 0.704, Loss_kd 1.604, Train_accy 50.27
2022-09-28 01:05:50,097 [foster.py] => Task 4, Epoch 34/34 => Loss 3.251, Loss_clf 0.614, Loss_fe 0.742, Loss_kd 1.596, Train_accy 50.80
2022-09-28 01:05:50,097 [foster.py] => do not weight align teacher!
2022-09-28 01:05:50,098 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 01:05:53,402 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.259,  Train_accy 19.10, Test_accy 40.33
2022-09-28 01:05:55,654 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.205,  Train_accy 19.64
2022-09-28 01:05:57,915 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.190,  Train_accy 19.96
2022-09-28 01:06:00,173 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.172,  Train_accy 20.17
2022-09-28 01:06:02,446 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.171,  Train_accy 20.17
2022-09-28 01:06:05,559 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.158,  Train_accy 20.92, Test_accy 41.04
2022-09-28 01:06:07,792 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.140,  Train_accy 19.96
2022-09-28 01:06:10,076 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.139,  Train_accy 21.24
2022-09-28 01:06:12,298 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.137,  Train_accy 21.02
2022-09-28 01:06:14,539 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.142,  Train_accy 21.02
2022-09-28 01:06:17,665 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.122,  Train_accy 21.34, Test_accy 42.22
2022-09-28 01:06:19,919 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.132,  Train_accy 20.92
2022-09-28 01:06:22,128 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.127,  Train_accy 20.38
2022-09-28 01:06:24,406 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.113,  Train_accy 21.24
2022-09-28 01:06:26,650 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.115,  Train_accy 21.66
2022-09-28 01:06:29,679 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.104,  Train_accy 21.99, Test_accy 42.45
2022-09-28 01:06:31,908 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.115,  Train_accy 21.24
2022-09-28 01:06:34,159 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.117,  Train_accy 20.81
2022-09-28 01:06:36,423 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.123,  Train_accy 22.20
2022-09-28 01:06:38,659 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.106,  Train_accy 23.05
2022-09-28 01:06:41,706 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.109,  Train_accy 22.41, Test_accy 42.69
2022-09-28 01:06:43,935 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.103,  Train_accy 21.02
2022-09-28 01:06:46,148 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.122,  Train_accy 22.84
2022-09-28 01:06:48,397 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.106,  Train_accy 22.09
2022-09-28 01:06:50,614 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.117,  Train_accy 21.88
2022-09-28 01:06:53,695 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.109,  Train_accy 22.31, Test_accy 43.16
2022-09-28 01:06:53,696 [foster.py] => do not weight align student!
2022-09-28 01:06:54,495 [foster.py] => darknet eval: 
2022-09-28 01:06:54,495 [foster.py] => CNN top1 curve: 43.16
2022-09-28 01:06:54,495 [foster.py] => CNN top5 curve: 86.56
2022-09-28 01:06:54,495 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 01:07:04,029 [foster.py] => Exemplar size: 380
2022-09-28 01:07:04,029 [trainer.py] => CNN: {'total': 51.18, 'old': 55.37, 'new': 30.0, 'base': 72.92, 'compound': 40.0}
2022-09-28 01:07:04,029 [trainer.py] => CNN top1 curve: [88.19, 77.61, 61.92, 53.11, 51.18]
2022-09-28 01:07:04,029 [trainer.py] => CNN base curve: [88.19, 86.11, 79.17, 76.39, 72.92]
2022-09-28 01:07:04,029 [trainer.py] => CNN old curve: [88.19, 86.11, 74.63, 59.43, 55.37]
2022-09-28 01:07:04,029 [trainer.py] => CNN new curve: [0, 56.14, 30.0, 28.77, 30.0]
2022-09-28 01:07:04,029 [trainer.py] => CNN compound curve: [0, 56.14, 43.8, 37.14, 40.0]
2022-09-28 01:07:04,029 [trainer.py] => NME: {'total': 55.9, 'old': 57.63, 'new': 47.14, 'base': 71.53, 'compound': 47.86}
2022-09-28 01:07:04,029 [trainer.py] => NME top1 curve: [90.28, 85.57, 72.24, 60.73, 55.9]
2022-09-28 01:07:04,030 [trainer.py] => NME base curve: [90.28, 85.42, 78.47, 72.22, 71.53]
2022-09-28 01:07:04,030 [trainer.py] => NME old curve: [90.28, 85.42, 79.1, 65.48, 57.63]
2022-09-28 01:07:04,030 [trainer.py] => NME new curve: [0, 85.96, 55.0, 42.47, 47.14]
2022-09-28 01:07:04,030 [trainer.py] => NME compound curve: [0, 85.96, 65.69, 52.86, 47.86]
2022-09-28 01:07:04,257 [foster.py] => Learning on 19-22
2022-09-28 01:07:04,257 [foster.py] => All params: 22396607
2022-09-28 01:07:04,258 [foster.py] => Trainable params: 11210348
2022-09-28 01:07:04,278 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 01:07:07,285 [foster.py] => Task 5, Epoch 1/34 => Loss 6.775, Loss_clf 1.941, Loss_fe 2.647, Loss_kd 1.889, Train_accy 36.31, Test_accy 41.78
2022-09-28 01:07:09,391 [foster.py] => Task 5, Epoch 2/34 => Loss 5.191, Loss_clf 1.103, Loss_fe 1.894, Loss_kd 1.894, Train_accy 34.69
2022-09-28 01:07:11,434 [foster.py] => Task 5, Epoch 3/34 => Loss 4.912, Loss_clf 1.017, Loss_fe 1.697, Loss_kd 1.899, Train_accy 39.15
2022-09-28 01:07:13,548 [foster.py] => Task 5, Epoch 4/34 => Loss 4.725, Loss_clf 0.966, Loss_fe 1.560, Loss_kd 1.899, Train_accy 39.45
2022-09-28 01:07:15,609 [foster.py] => Task 5, Epoch 5/34 => Loss 4.640, Loss_clf 0.964, Loss_fe 1.476, Loss_kd 1.900, Train_accy 40.87
2022-09-28 01:07:18,708 [foster.py] => Task 5, Epoch 6/34 => Loss 4.484, Loss_clf 0.911, Loss_fe 1.377, Loss_kd 1.896, Train_accy 38.64, Test_accy 46.53
2022-09-28 01:07:20,805 [foster.py] => Task 5, Epoch 7/34 => Loss 4.406, Loss_clf 0.893, Loss_fe 1.316, Loss_kd 1.897, Train_accy 40.37
2022-09-28 01:07:22,886 [foster.py] => Task 5, Epoch 8/34 => Loss 4.325, Loss_clf 0.872, Loss_fe 1.250, Loss_kd 1.903, Train_accy 42.29
2022-09-28 01:07:25,020 [foster.py] => Task 5, Epoch 9/34 => Loss 4.284, Loss_clf 0.858, Loss_fe 1.214, Loss_kd 1.910, Train_accy 42.90
2022-09-28 01:07:27,075 [foster.py] => Task 5, Epoch 10/34 => Loss 4.242, Loss_clf 0.859, Loss_fe 1.177, Loss_kd 1.904, Train_accy 44.73
2022-09-28 01:07:30,091 [foster.py] => Task 5, Epoch 11/34 => Loss 4.156, Loss_clf 0.827, Loss_fe 1.120, Loss_kd 1.907, Train_accy 45.03, Test_accy 46.14
2022-09-28 01:07:32,182 [foster.py] => Task 5, Epoch 12/34 => Loss 4.124, Loss_clf 0.819, Loss_fe 1.102, Loss_kd 1.902, Train_accy 44.93
2022-09-28 01:07:34,266 [foster.py] => Task 5, Epoch 13/34 => Loss 4.109, Loss_clf 0.823, Loss_fe 1.084, Loss_kd 1.902, Train_accy 44.83
2022-09-28 01:07:36,316 [foster.py] => Task 5, Epoch 14/34 => Loss 4.084, Loss_clf 0.812, Loss_fe 1.066, Loss_kd 1.906, Train_accy 44.22
2022-09-28 01:07:38,375 [foster.py] => Task 5, Epoch 15/34 => Loss 4.014, Loss_clf 0.787, Loss_fe 1.014, Loss_kd 1.911, Train_accy 46.45
2022-09-28 01:07:41,446 [foster.py] => Task 5, Epoch 16/34 => Loss 3.976, Loss_clf 0.784, Loss_fe 0.995, Loss_kd 1.898, Train_accy 43.71, Test_accy 46.73
2022-09-28 01:07:43,537 [foster.py] => Task 5, Epoch 17/34 => Loss 3.939, Loss_clf 0.753, Loss_fe 0.970, Loss_kd 1.914, Train_accy 47.67
2022-09-28 01:07:45,605 [foster.py] => Task 5, Epoch 18/34 => Loss 3.937, Loss_clf 0.764, Loss_fe 0.965, Loss_kd 1.906, Train_accy 47.87
2022-09-28 01:07:47,669 [foster.py] => Task 5, Epoch 19/34 => Loss 3.930, Loss_clf 0.765, Loss_fe 0.955, Loss_kd 1.908, Train_accy 46.55
2022-09-28 01:07:49,747 [foster.py] => Task 5, Epoch 20/34 => Loss 3.914, Loss_clf 0.750, Loss_fe 0.953, Loss_kd 1.910, Train_accy 46.35
2022-09-28 01:07:52,847 [foster.py] => Task 5, Epoch 21/34 => Loss 3.886, Loss_clf 0.746, Loss_fe 0.930, Loss_kd 1.909, Train_accy 45.33, Test_accy 47.13
2022-09-28 01:07:54,890 [foster.py] => Task 5, Epoch 22/34 => Loss 3.871, Loss_clf 0.749, Loss_fe 0.917, Loss_kd 1.905, Train_accy 46.96
2022-09-28 01:07:56,995 [foster.py] => Task 5, Epoch 23/34 => Loss 3.872, Loss_clf 0.739, Loss_fe 0.921, Loss_kd 1.910, Train_accy 46.65
2022-09-28 01:07:59,051 [foster.py] => Task 5, Epoch 24/34 => Loss 3.850, Loss_clf 0.734, Loss_fe 0.907, Loss_kd 1.907, Train_accy 46.75
2022-09-28 01:08:01,109 [foster.py] => Task 5, Epoch 25/34 => Loss 3.816, Loss_clf 0.720, Loss_fe 0.883, Loss_kd 1.911, Train_accy 47.26
2022-09-28 01:08:04,157 [foster.py] => Task 5, Epoch 26/34 => Loss 3.858, Loss_clf 0.740, Loss_fe 0.911, Loss_kd 1.906, Train_accy 46.45, Test_accy 47.52
2022-09-28 01:08:06,256 [foster.py] => Task 5, Epoch 27/34 => Loss 3.824, Loss_clf 0.725, Loss_fe 0.887, Loss_kd 1.910, Train_accy 48.99
2022-09-28 01:08:08,381 [foster.py] => Task 5, Epoch 28/34 => Loss 3.844, Loss_clf 0.738, Loss_fe 0.894, Loss_kd 1.911, Train_accy 46.75
2022-09-28 01:08:10,441 [foster.py] => Task 5, Epoch 29/34 => Loss 3.839, Loss_clf 0.732, Loss_fe 0.893, Loss_kd 1.912, Train_accy 46.75
2022-09-28 01:08:12,495 [foster.py] => Task 5, Epoch 30/34 => Loss 3.805, Loss_clf 0.722, Loss_fe 0.872, Loss_kd 1.909, Train_accy 48.38
2022-09-28 01:08:15,564 [foster.py] => Task 5, Epoch 31/34 => Loss 3.780, Loss_clf 0.705, Loss_fe 0.864, Loss_kd 1.910, Train_accy 49.80, Test_accy 47.92
2022-09-28 01:08:17,685 [foster.py] => Task 5, Epoch 32/34 => Loss 3.819, Loss_clf 0.723, Loss_fe 0.887, Loss_kd 1.907, Train_accy 47.46
2022-09-28 01:08:19,755 [foster.py] => Task 5, Epoch 33/34 => Loss 3.814, Loss_clf 0.720, Loss_fe 0.879, Loss_kd 1.913, Train_accy 47.87
2022-09-28 01:08:21,869 [foster.py] => Task 5, Epoch 34/34 => Loss 3.793, Loss_clf 0.710, Loss_fe 0.872, Loss_kd 1.910, Train_accy 49.09
2022-09-28 01:08:21,869 [foster.py] => do not weight align teacher!
2022-09-28 01:08:21,870 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 01:08:25,321 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.423,  Train_accy 20.18, Test_accy 36.24
2022-09-28 01:08:27,625 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.403,  Train_accy 20.08
2022-09-28 01:08:29,940 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.390,  Train_accy 21.50
2022-09-28 01:08:32,334 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.386,  Train_accy 20.08
2022-09-28 01:08:34,683 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.376,  Train_accy 20.99
2022-09-28 01:08:37,824 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.382,  Train_accy 21.81, Test_accy 39.41
2022-09-28 01:08:40,172 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.373,  Train_accy 21.10
2022-09-28 01:08:42,478 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.365,  Train_accy 21.60
2022-09-28 01:08:44,806 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.368,  Train_accy 20.89
2022-09-28 01:08:47,145 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.357,  Train_accy 20.59
2022-09-28 01:08:50,309 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.368,  Train_accy 21.10, Test_accy 39.01
2022-09-28 01:08:52,655 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.358,  Train_accy 21.40
2022-09-28 01:08:55,018 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.349,  Train_accy 20.69
2022-09-28 01:08:57,362 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.351,  Train_accy 21.30
2022-09-28 01:08:59,661 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.344,  Train_accy 21.60
2022-09-28 01:09:02,861 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.349,  Train_accy 21.30, Test_accy 39.41
2022-09-28 01:09:05,216 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.342,  Train_accy 20.79
2022-09-28 01:09:07,516 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.347,  Train_accy 21.60
2022-09-28 01:09:09,841 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.352,  Train_accy 21.91
2022-09-28 01:09:12,166 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.356,  Train_accy 21.40
2022-09-28 01:09:15,389 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.350,  Train_accy 21.81, Test_accy 39.80
2022-09-28 01:09:17,731 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.357,  Train_accy 21.60
2022-09-28 01:09:20,042 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.347,  Train_accy 21.10
2022-09-28 01:09:22,457 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.348,  Train_accy 21.30
2022-09-28 01:09:24,761 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.348,  Train_accy 21.40
2022-09-28 01:09:27,946 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.353,  Train_accy 21.70, Test_accy 39.41
2022-09-28 01:09:27,946 [foster.py] => do not weight align student!
2022-09-28 01:09:28,782 [foster.py] => darknet eval: 
2022-09-28 01:09:28,782 [foster.py] => CNN top1 curve: 39.41
2022-09-28 01:09:28,782 [foster.py] => CNN top5 curve: 81.78
2022-09-28 01:09:28,782 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 01:09:39,356 [foster.py] => Exemplar size: 440
2022-09-28 01:09:39,356 [trainer.py] => CNN: {'total': 47.52, 'old': 49.53, 'new': 37.04, 'base': 68.75, 'compound': 39.06}
2022-09-28 01:09:39,356 [trainer.py] => CNN top1 curve: [88.19, 77.61, 61.92, 53.11, 51.18, 47.52]
2022-09-28 01:09:39,356 [trainer.py] => CNN base curve: [88.19, 86.11, 79.17, 76.39, 72.92, 68.75]
2022-09-28 01:09:39,356 [trainer.py] => CNN old curve: [88.19, 86.11, 74.63, 59.43, 55.37, 49.53]
2022-09-28 01:09:39,357 [trainer.py] => CNN new curve: [0, 56.14, 30.0, 28.77, 30.0, 37.04]
2022-09-28 01:09:39,357 [trainer.py] => CNN compound curve: [0, 56.14, 43.8, 37.14, 40.0, 39.06]
2022-09-28 01:09:39,357 [trainer.py] => NME: {'total': 55.25, 'old': 56.37, 'new': 49.38, 'base': 75.0, 'compound': 47.37}
2022-09-28 01:09:39,357 [trainer.py] => NME top1 curve: [90.28, 85.57, 72.24, 60.73, 55.9, 55.25]
2022-09-28 01:09:39,357 [trainer.py] => NME base curve: [90.28, 85.42, 78.47, 72.22, 71.53, 75.0]
2022-09-28 01:09:39,357 [trainer.py] => NME old curve: [90.28, 85.42, 79.1, 65.48, 57.63, 56.37]
2022-09-28 01:09:39,357 [trainer.py] => NME new curve: [0, 85.96, 55.0, 42.47, 47.14, 49.38]
2022-09-28 01:09:39,357 [trainer.py] => NME compound curve: [0, 85.96, 65.69, 52.86, 47.86, 47.37]
2022-09-28 01:09:39,358 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 01:09:39,358 [trainer.py] => prefix: cil
2022-09-28 01:09:39,358 [trainer.py] => dataset: CFEE
2022-09-28 01:09:39,358 [trainer.py] => memory_size: 2000
2022-09-28 01:09:39,358 [trainer.py] => memory_per_class: 20
2022-09-28 01:09:39,358 [trainer.py] => fixed_memory: True
2022-09-28 01:09:39,358 [trainer.py] => shuffle: True
2022-09-28 01:09:39,358 [trainer.py] => init_cls: 7
2022-09-28 01:09:39,358 [trainer.py] => increment: 3
2022-09-28 01:09:39,358 [trainer.py] => model_name: foster
2022-09-28 01:09:39,358 [trainer.py] => convnet_type: resnet18
2022-09-28 01:09:39,358 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 01:09:39,358 [trainer.py] => seed: 1993
2022-09-28 01:09:39,358 [trainer.py] => beta1: 0.96
2022-09-28 01:09:39,358 [trainer.py] => beta2: 0.97
2022-09-28 01:09:39,358 [trainer.py] => oofc: ft
2022-09-28 01:09:39,358 [trainer.py] => is_teacher_wa: False
2022-09-28 01:09:39,359 [trainer.py] => is_student_wa: False
2022-09-28 01:09:39,359 [trainer.py] => lambda_okd: 1
2022-09-28 01:09:39,359 [trainer.py] => wa_value: 1
2022-09-28 01:09:39,359 [trainer.py] => init_epochs: 40
2022-09-28 01:09:39,359 [trainer.py] => init_lr: 0.01
2022-09-28 01:09:39,359 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 01:09:39,359 [trainer.py] => boosting_epochs: 34
2022-09-28 01:09:39,359 [trainer.py] => compression_epochs: 26
2022-09-28 01:09:39,359 [trainer.py] => lr: 0.001
2022-09-28 01:09:39,359 [trainer.py] => batch_size: 32
2022-09-28 01:09:39,359 [trainer.py] => weight_decay: 0.0005
2022-09-28 01:09:39,359 [trainer.py] => num_workers: 8
2022-09-28 01:09:39,359 [trainer.py] => T: 2
2022-09-28 01:09:39,359 [trainer.py] => nb_runs: 3
2022-09-28 01:09:39,359 [trainer.py] => fold: 10
2022-09-28 01:09:39,359 [data.py] => ========== Fold:5 ==========
2022-09-28 01:09:39,364 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 13, 17, 15, 9, 11, 20, 18, 12, 14, 7, 10, 19, 21, 16, 8]
2022-09-28 01:09:39,578 [foster.py] => Learning on 0-7
2022-09-28 01:09:39,578 [foster.py] => All params: 11183694
2022-09-28 01:09:39,578 [foster.py] => Trainable params: 11183694
2022-09-28 01:09:41,948 [foster.py] => Task 0, Epoch 1/40 => Loss 1.388, Train_accy 48.54
2022-09-28 01:09:44,933 [foster.py] => Task 0, Epoch 2/40 => Loss 0.554, Train_accy 81.43, Test_accy 84.62
2022-09-28 01:09:47,891 [foster.py] => Task 0, Epoch 3/40 => Loss 0.380, Train_accy 86.58, Test_accy 86.39
2022-09-28 01:09:50,833 [foster.py] => Task 0, Epoch 4/40 => Loss 0.286, Train_accy 89.57, Test_accy 86.98
2022-09-28 01:09:53,853 [foster.py] => Task 0, Epoch 5/40 => Loss 0.230, Train_accy 92.14, Test_accy 89.35
2022-09-28 01:09:56,173 [foster.py] => Task 0, Epoch 6/40 => Loss 0.169, Train_accy 94.51
2022-09-28 01:09:59,188 [foster.py] => Task 0, Epoch 7/40 => Loss 0.146, Train_accy 95.13, Test_accy 89.94
2022-09-28 01:10:02,191 [foster.py] => Task 0, Epoch 8/40 => Loss 0.133, Train_accy 95.20, Test_accy 88.17
2022-09-28 01:10:05,178 [foster.py] => Task 0, Epoch 9/40 => Loss 0.101, Train_accy 97.15, Test_accy 85.21
2022-09-28 01:10:08,179 [foster.py] => Task 0, Epoch 10/40 => Loss 0.107, Train_accy 96.59, Test_accy 86.98
2022-09-28 01:10:10,503 [foster.py] => Task 0, Epoch 11/40 => Loss 0.091, Train_accy 97.08
2022-09-28 01:10:13,528 [foster.py] => Task 0, Epoch 12/40 => Loss 0.073, Train_accy 97.84, Test_accy 89.94
2022-09-28 01:10:16,516 [foster.py] => Task 0, Epoch 13/40 => Loss 0.065, Train_accy 98.19, Test_accy 88.17
2022-09-28 01:10:19,476 [foster.py] => Task 0, Epoch 14/40 => Loss 0.050, Train_accy 98.61, Test_accy 88.76
2022-09-28 01:10:22,460 [foster.py] => Task 0, Epoch 15/40 => Loss 0.048, Train_accy 98.82, Test_accy 87.57
2022-09-28 01:10:24,805 [foster.py] => Task 0, Epoch 16/40 => Loss 0.036, Train_accy 99.17
2022-09-28 01:10:27,758 [foster.py] => Task 0, Epoch 17/40 => Loss 0.039, Train_accy 99.10, Test_accy 86.39
2022-09-28 01:10:30,787 [foster.py] => Task 0, Epoch 18/40 => Loss 0.037, Train_accy 99.03, Test_accy 87.57
2022-09-28 01:10:33,785 [foster.py] => Task 0, Epoch 19/40 => Loss 0.034, Train_accy 99.03, Test_accy 88.17
2022-09-28 01:10:36,788 [foster.py] => Task 0, Epoch 20/40 => Loss 0.035, Train_accy 99.03, Test_accy 88.17
2022-09-28 01:10:39,189 [foster.py] => Task 0, Epoch 21/40 => Loss 0.027, Train_accy 99.44
2022-09-28 01:10:42,153 [foster.py] => Task 0, Epoch 22/40 => Loss 0.023, Train_accy 99.58, Test_accy 88.76
2022-09-28 01:10:45,138 [foster.py] => Task 0, Epoch 23/40 => Loss 0.023, Train_accy 99.37, Test_accy 87.57
2022-09-28 01:10:48,107 [foster.py] => Task 0, Epoch 24/40 => Loss 0.021, Train_accy 99.58, Test_accy 88.76
2022-09-28 01:10:51,154 [foster.py] => Task 0, Epoch 25/40 => Loss 0.018, Train_accy 99.86, Test_accy 89.35
2022-09-28 01:10:53,564 [foster.py] => Task 0, Epoch 26/40 => Loss 0.016, Train_accy 99.58
2022-09-28 01:10:56,533 [foster.py] => Task 0, Epoch 27/40 => Loss 0.018, Train_accy 99.79, Test_accy 89.35
2022-09-28 01:10:59,519 [foster.py] => Task 0, Epoch 28/40 => Loss 0.016, Train_accy 99.79, Test_accy 89.35
2022-09-28 01:11:02,457 [foster.py] => Task 0, Epoch 29/40 => Loss 0.019, Train_accy 99.58, Test_accy 89.35
2022-09-28 01:11:05,448 [foster.py] => Task 0, Epoch 30/40 => Loss 0.016, Train_accy 99.72, Test_accy 89.35
2022-09-28 01:11:07,803 [foster.py] => Task 0, Epoch 31/40 => Loss 0.012, Train_accy 99.86
2022-09-28 01:11:10,795 [foster.py] => Task 0, Epoch 32/40 => Loss 0.014, Train_accy 99.86, Test_accy 88.76
2022-09-28 01:11:13,745 [foster.py] => Task 0, Epoch 33/40 => Loss 0.015, Train_accy 99.93, Test_accy 88.76
2022-09-28 01:11:16,767 [foster.py] => Task 0, Epoch 34/40 => Loss 0.014, Train_accy 99.65, Test_accy 89.94
2022-09-28 01:11:19,848 [foster.py] => Task 0, Epoch 35/40 => Loss 0.014, Train_accy 99.79, Test_accy 89.94
2022-09-28 01:11:22,209 [foster.py] => Task 0, Epoch 36/40 => Loss 0.015, Train_accy 99.93
2022-09-28 01:11:25,169 [foster.py] => Task 0, Epoch 37/40 => Loss 0.013, Train_accy 99.86, Test_accy 90.53
2022-09-28 01:11:28,166 [foster.py] => Task 0, Epoch 38/40 => Loss 0.013, Train_accy 99.93, Test_accy 89.35
2022-09-28 01:11:31,155 [foster.py] => Task 0, Epoch 39/40 => Loss 0.011, Train_accy 99.93, Test_accy 89.94
2022-09-28 01:11:34,111 [foster.py] => Task 0, Epoch 40/40 => Loss 0.011, Train_accy 99.93, Test_accy 88.76
2022-09-28 01:11:34,112 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 01:11:40,984 [foster.py] => Exemplar size: 140
2022-09-28 01:11:40,984 [trainer.py] => CNN: {'total': 88.76, 'old': 88.76, 'new': 0, 'base': 88.76, 'compound': 0}
2022-09-28 01:11:40,984 [trainer.py] => CNN top1 curve: [88.76]
2022-09-28 01:11:40,984 [trainer.py] => CNN base curve: [88.76]
2022-09-28 01:11:40,984 [trainer.py] => CNN old curve: [88.76]
2022-09-28 01:11:40,984 [trainer.py] => CNN new curve: [0]
2022-09-28 01:11:40,984 [trainer.py] => CNN compound curve: [0]
2022-09-28 01:11:40,984 [trainer.py] => NME: {'total': 87.57, 'old': 87.57, 'new': 0, 'base': 87.57, 'compound': 0}
2022-09-28 01:11:40,985 [trainer.py] => NME top1 curve: [87.57]
2022-09-28 01:11:40,985 [trainer.py] => NME base curve: [87.57]
2022-09-28 01:11:40,985 [trainer.py] => NME old curve: [87.57]
2022-09-28 01:11:40,985 [trainer.py] => NME new curve: [0]
2022-09-28 01:11:40,985 [trainer.py] => NME compound curve: [0]
2022-09-28 01:11:41,211 [foster.py] => Learning on 7-10
2022-09-28 01:11:41,211 [foster.py] => All params: 22371995
2022-09-28 01:11:41,212 [foster.py] => Trainable params: 11191892
2022-09-28 01:11:41,232 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 01:11:43,727 [foster.py] => Task 1, Epoch 1/34 => Loss 4.599, Loss_clf 2.000, Loss_fe 1.890, Loss_kd 0.497, Train_accy 40.39, Test_accy 73.00
2022-09-28 01:11:45,496 [foster.py] => Task 1, Epoch 2/34 => Loss 2.461, Loss_clf 0.616, Loss_fe 1.131, Loss_kd 0.500, Train_accy 76.45
2022-09-28 01:11:47,216 [foster.py] => Task 1, Epoch 3/34 => Loss 1.969, Loss_clf 0.374, Loss_fe 0.908, Loss_kd 0.481, Train_accy 56.58
2022-09-28 01:11:48,975 [foster.py] => Task 1, Epoch 4/34 => Loss 1.848, Loss_clf 0.370, Loss_fe 0.791, Loss_kd 0.480, Train_accy 56.84
2022-09-28 01:11:50,734 [foster.py] => Task 1, Epoch 5/34 => Loss 1.709, Loss_clf 0.328, Loss_fe 0.693, Loss_kd 0.481, Train_accy 58.95
2022-09-28 01:11:53,251 [foster.py] => Task 1, Epoch 6/34 => Loss 1.612, Loss_clf 0.306, Loss_fe 0.627, Loss_kd 0.476, Train_accy 58.03, Test_accy 73.42
2022-09-28 01:11:55,039 [foster.py] => Task 1, Epoch 7/34 => Loss 1.563, Loss_clf 0.302, Loss_fe 0.581, Loss_kd 0.476, Train_accy 58.42
2022-09-28 01:11:56,782 [foster.py] => Task 1, Epoch 8/34 => Loss 1.471, Loss_clf 0.273, Loss_fe 0.518, Loss_kd 0.476, Train_accy 59.21
2022-09-28 01:11:58,542 [foster.py] => Task 1, Epoch 9/34 => Loss 1.471, Loss_clf 0.285, Loss_fe 0.505, Loss_kd 0.477, Train_accy 58.42
2022-09-28 01:12:00,237 [foster.py] => Task 1, Epoch 10/34 => Loss 1.448, Loss_clf 0.281, Loss_fe 0.483, Loss_kd 0.479, Train_accy 58.55
2022-09-28 01:12:02,741 [foster.py] => Task 1, Epoch 11/34 => Loss 1.419, Loss_clf 0.270, Loss_fe 0.458, Loss_kd 0.484, Train_accy 59.08, Test_accy 75.11
2022-09-28 01:12:04,473 [foster.py] => Task 1, Epoch 12/34 => Loss 1.382, Loss_clf 0.265, Loss_fe 0.440, Loss_kd 0.474, Train_accy 60.13
2022-09-28 01:12:06,219 [foster.py] => Task 1, Epoch 13/34 => Loss 1.357, Loss_clf 0.261, Loss_fe 0.422, Loss_kd 0.472, Train_accy 59.74
2022-09-28 01:12:07,974 [foster.py] => Task 1, Epoch 14/34 => Loss 1.328, Loss_clf 0.250, Loss_fe 0.405, Loss_kd 0.471, Train_accy 59.87
2022-09-28 01:12:09,720 [foster.py] => Task 1, Epoch 15/34 => Loss 1.337, Loss_clf 0.244, Loss_fe 0.402, Loss_kd 0.484, Train_accy 62.11
2022-09-28 01:12:12,189 [foster.py] => Task 1, Epoch 16/34 => Loss 1.296, Loss_clf 0.236, Loss_fe 0.382, Loss_kd 0.475, Train_accy 62.50, Test_accy 74.26
2022-09-28 01:12:13,908 [foster.py] => Task 1, Epoch 17/34 => Loss 1.299, Loss_clf 0.241, Loss_fe 0.383, Loss_kd 0.473, Train_accy 60.53
2022-09-28 01:12:15,634 [foster.py] => Task 1, Epoch 18/34 => Loss 1.259, Loss_clf 0.223, Loss_fe 0.353, Loss_kd 0.478, Train_accy 61.97
2022-09-28 01:12:17,355 [foster.py] => Task 1, Epoch 19/34 => Loss 1.250, Loss_clf 0.225, Loss_fe 0.351, Loss_kd 0.472, Train_accy 60.66
2022-09-28 01:12:19,106 [foster.py] => Task 1, Epoch 20/34 => Loss 1.222, Loss_clf 0.207, Loss_fe 0.340, Loss_kd 0.472, Train_accy 59.47
2022-09-28 01:12:21,548 [foster.py] => Task 1, Epoch 21/34 => Loss 1.235, Loss_clf 0.218, Loss_fe 0.335, Loss_kd 0.477, Train_accy 61.97, Test_accy 75.53
2022-09-28 01:12:23,255 [foster.py] => Task 1, Epoch 22/34 => Loss 1.258, Loss_clf 0.222, Loss_fe 0.348, Loss_kd 0.482, Train_accy 61.32
2022-09-28 01:12:24,968 [foster.py] => Task 1, Epoch 23/34 => Loss 1.211, Loss_clf 0.205, Loss_fe 0.326, Loss_kd 0.476, Train_accy 62.24
2022-09-28 01:12:26,713 [foster.py] => Task 1, Epoch 24/34 => Loss 1.210, Loss_clf 0.216, Loss_fe 0.321, Loss_kd 0.471, Train_accy 61.32
2022-09-28 01:12:28,480 [foster.py] => Task 1, Epoch 25/34 => Loss 1.192, Loss_clf 0.199, Loss_fe 0.321, Loss_kd 0.470, Train_accy 62.37
2022-09-28 01:12:30,942 [foster.py] => Task 1, Epoch 26/34 => Loss 1.206, Loss_clf 0.212, Loss_fe 0.324, Loss_kd 0.469, Train_accy 59.34, Test_accy 75.95
2022-09-28 01:12:32,692 [foster.py] => Task 1, Epoch 27/34 => Loss 1.206, Loss_clf 0.203, Loss_fe 0.321, Loss_kd 0.477, Train_accy 61.45
2022-09-28 01:12:34,444 [foster.py] => Task 1, Epoch 28/34 => Loss 1.215, Loss_clf 0.201, Loss_fe 0.326, Loss_kd 0.482, Train_accy 63.03
2022-09-28 01:12:36,192 [foster.py] => Task 1, Epoch 29/34 => Loss 1.200, Loss_clf 0.207, Loss_fe 0.313, Loss_kd 0.476, Train_accy 62.50
2022-09-28 01:12:37,901 [foster.py] => Task 1, Epoch 30/34 => Loss 1.198, Loss_clf 0.209, Loss_fe 0.308, Loss_kd 0.477, Train_accy 60.92
2022-09-28 01:12:40,359 [foster.py] => Task 1, Epoch 31/34 => Loss 1.202, Loss_clf 0.202, Loss_fe 0.317, Loss_kd 0.478, Train_accy 61.05, Test_accy 74.68
2022-09-28 01:12:42,071 [foster.py] => Task 1, Epoch 32/34 => Loss 1.237, Loss_clf 0.225, Loss_fe 0.336, Loss_kd 0.472, Train_accy 60.53
2022-09-28 01:12:43,825 [foster.py] => Task 1, Epoch 33/34 => Loss 1.167, Loss_clf 0.192, Loss_fe 0.300, Loss_kd 0.472, Train_accy 62.11
2022-09-28 01:12:45,526 [foster.py] => Task 1, Epoch 34/34 => Loss 1.180, Loss_clf 0.195, Loss_fe 0.306, Loss_kd 0.476, Train_accy 61.05
2022-09-28 01:12:45,527 [foster.py] => do not weight align teacher!
2022-09-28 01:12:45,527 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 01:12:48,348 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.525,  Train_accy 18.03, Test_accy 62.45
2022-09-28 01:12:50,282 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.395,  Train_accy 18.82
2022-09-28 01:12:52,207 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.322,  Train_accy 20.66
2022-09-28 01:12:54,157 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.288,  Train_accy 22.89
2022-09-28 01:12:56,066 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.261,  Train_accy 25.79
2022-09-28 01:12:58,692 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.250,  Train_accy 27.89, Test_accy 65.82
2022-09-28 01:13:00,627 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.240,  Train_accy 30.92
2022-09-28 01:13:02,543 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.229,  Train_accy 31.97
2022-09-28 01:13:04,485 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.209,  Train_accy 32.89
2022-09-28 01:13:06,424 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.224,  Train_accy 32.50
2022-09-28 01:13:09,040 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.204,  Train_accy 33.03, Test_accy 67.93
2022-09-28 01:13:10,995 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.206,  Train_accy 33.82
2022-09-28 01:13:12,969 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.199,  Train_accy 34.74
2022-09-28 01:13:14,871 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.199,  Train_accy 34.47
2022-09-28 01:13:16,812 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.195,  Train_accy 36.84
2022-09-28 01:13:19,449 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.187,  Train_accy 36.71, Test_accy 68.78
2022-09-28 01:13:21,343 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.202,  Train_accy 37.11
2022-09-28 01:13:23,305 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.176,  Train_accy 35.79
2022-09-28 01:13:25,209 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.190,  Train_accy 36.58
2022-09-28 01:13:27,167 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.187,  Train_accy 36.18
2022-09-28 01:13:29,843 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.187,  Train_accy 36.05, Test_accy 67.93
2022-09-28 01:13:31,791 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.187,  Train_accy 37.24
2022-09-28 01:13:33,738 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.184,  Train_accy 36.97
2022-09-28 01:13:35,689 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.186,  Train_accy 35.00
2022-09-28 01:13:37,680 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.188,  Train_accy 34.47
2022-09-28 01:13:40,307 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.181,  Train_accy 36.18, Test_accy 68.35
2022-09-28 01:13:40,308 [foster.py] => do not weight align student!
2022-09-28 01:13:40,979 [foster.py] => darknet eval: 
2022-09-28 01:13:40,979 [foster.py] => CNN top1 curve: 68.35
2022-09-28 01:13:40,979 [foster.py] => CNN top5 curve: 98.73
2022-09-28 01:13:40,979 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 01:13:47,332 [foster.py] => Exemplar size: 200
2022-09-28 01:13:47,332 [trainer.py] => CNN: {'total': 74.68, 'old': 87.57, 'new': 42.65, 'base': 87.57, 'compound': 42.65}
2022-09-28 01:13:47,332 [trainer.py] => CNN top1 curve: [88.76, 74.68]
2022-09-28 01:13:47,332 [trainer.py] => CNN base curve: [88.76, 87.57]
2022-09-28 01:13:47,332 [trainer.py] => CNN old curve: [88.76, 87.57]
2022-09-28 01:13:47,332 [trainer.py] => CNN new curve: [0, 42.65]
2022-09-28 01:13:47,332 [trainer.py] => CNN compound curve: [0, 42.65]
2022-09-28 01:13:47,332 [trainer.py] => NME: {'total': 78.9, 'old': 82.84, 'new': 69.12, 'base': 82.84, 'compound': 69.12}
2022-09-28 01:13:47,332 [trainer.py] => NME top1 curve: [87.57, 78.9]
2022-09-28 01:13:47,332 [trainer.py] => NME base curve: [87.57, 82.84]
2022-09-28 01:13:47,332 [trainer.py] => NME old curve: [87.57, 82.84]
2022-09-28 01:13:47,332 [trainer.py] => NME new curve: [0, 69.12]
2022-09-28 01:13:47,332 [trainer.py] => NME compound curve: [0, 69.12]
2022-09-28 01:13:47,561 [foster.py] => Learning on 10-13
2022-09-28 01:13:47,561 [foster.py] => All params: 22378148
2022-09-28 01:13:47,562 [foster.py] => Trainable params: 11196506
2022-09-28 01:13:47,582 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 01:13:50,197 [foster.py] => Task 2, Epoch 1/34 => Loss 5.474, Loss_clf 2.338, Loss_fe 2.069, Loss_kd 0.821, Train_accy 39.39, Test_accy 49.03
2022-09-28 01:13:52,007 [foster.py] => Task 2, Epoch 2/34 => Loss 3.367, Loss_clf 0.925, Loss_fe 1.397, Loss_kd 0.804, Train_accy 48.34
2022-09-28 01:13:53,848 [foster.py] => Task 2, Epoch 3/34 => Loss 2.868, Loss_clf 0.662, Loss_fe 1.173, Loss_kd 0.794, Train_accy 38.53
2022-09-28 01:13:55,643 [foster.py] => Task 2, Epoch 4/34 => Loss 2.691, Loss_clf 0.619, Loss_fe 1.031, Loss_kd 0.800, Train_accy 41.10
2022-09-28 01:13:57,473 [foster.py] => Task 2, Epoch 5/34 => Loss 2.634, Loss_clf 0.608, Loss_fe 0.989, Loss_kd 0.798, Train_accy 39.14
2022-09-28 01:14:00,057 [foster.py] => Task 2, Epoch 6/34 => Loss 2.518, Loss_clf 0.581, Loss_fe 0.906, Loss_kd 0.794, Train_accy 41.23, Test_accy 60.65
2022-09-28 01:14:01,878 [foster.py] => Task 2, Epoch 7/34 => Loss 2.429, Loss_clf 0.563, Loss_fe 0.848, Loss_kd 0.783, Train_accy 39.88
2022-09-28 01:14:03,663 [foster.py] => Task 2, Epoch 8/34 => Loss 2.397, Loss_clf 0.549, Loss_fe 0.824, Loss_kd 0.788, Train_accy 43.44
2022-09-28 01:14:05,512 [foster.py] => Task 2, Epoch 9/34 => Loss 2.332, Loss_clf 0.527, Loss_fe 0.781, Loss_kd 0.788, Train_accy 41.23
2022-09-28 01:14:07,306 [foster.py] => Task 2, Epoch 10/34 => Loss 2.299, Loss_clf 0.507, Loss_fe 0.768, Loss_kd 0.788, Train_accy 42.82
2022-09-28 01:14:09,949 [foster.py] => Task 2, Epoch 11/34 => Loss 2.275, Loss_clf 0.516, Loss_fe 0.731, Loss_kd 0.790, Train_accy 43.07, Test_accy 60.65
2022-09-28 01:14:11,779 [foster.py] => Task 2, Epoch 12/34 => Loss 2.225, Loss_clf 0.503, Loss_fe 0.705, Loss_kd 0.782, Train_accy 44.05
2022-09-28 01:14:13,589 [foster.py] => Task 2, Epoch 13/34 => Loss 2.215, Loss_clf 0.502, Loss_fe 0.686, Loss_kd 0.790, Train_accy 44.91
2022-09-28 01:14:15,399 [foster.py] => Task 2, Epoch 14/34 => Loss 2.119, Loss_clf 0.463, Loss_fe 0.634, Loss_kd 0.787, Train_accy 45.03
2022-09-28 01:14:17,228 [foster.py] => Task 2, Epoch 15/34 => Loss 2.147, Loss_clf 0.472, Loss_fe 0.645, Loss_kd 0.792, Train_accy 45.89
2022-09-28 01:14:19,862 [foster.py] => Task 2, Epoch 16/34 => Loss 2.123, Loss_clf 0.460, Loss_fe 0.642, Loss_kd 0.785, Train_accy 45.28, Test_accy 61.61
2022-09-28 01:14:21,700 [foster.py] => Task 2, Epoch 17/34 => Loss 2.070, Loss_clf 0.451, Loss_fe 0.605, Loss_kd 0.780, Train_accy 43.31
2022-09-28 01:14:23,491 [foster.py] => Task 2, Epoch 18/34 => Loss 2.056, Loss_clf 0.429, Loss_fe 0.592, Loss_kd 0.796, Train_accy 46.63
2022-09-28 01:14:25,305 [foster.py] => Task 2, Epoch 19/34 => Loss 2.080, Loss_clf 0.452, Loss_fe 0.587, Loss_kd 0.801, Train_accy 45.52
2022-09-28 01:14:27,123 [foster.py] => Task 2, Epoch 20/34 => Loss 2.048, Loss_clf 0.437, Loss_fe 0.574, Loss_kd 0.797, Train_accy 46.38
2022-09-28 01:14:29,775 [foster.py] => Task 2, Epoch 21/34 => Loss 2.004, Loss_clf 0.416, Loss_fe 0.563, Loss_kd 0.788, Train_accy 47.12, Test_accy 61.29
2022-09-28 01:14:31,599 [foster.py] => Task 2, Epoch 22/34 => Loss 2.050, Loss_clf 0.436, Loss_fe 0.572, Loss_kd 0.802, Train_accy 47.61
2022-09-28 01:14:33,418 [foster.py] => Task 2, Epoch 23/34 => Loss 1.991, Loss_clf 0.416, Loss_fe 0.562, Loss_kd 0.780, Train_accy 46.38
2022-09-28 01:14:35,211 [foster.py] => Task 2, Epoch 24/34 => Loss 2.017, Loss_clf 0.426, Loss_fe 0.570, Loss_kd 0.785, Train_accy 47.73
2022-09-28 01:14:37,045 [foster.py] => Task 2, Epoch 25/34 => Loss 1.989, Loss_clf 0.415, Loss_fe 0.546, Loss_kd 0.791, Train_accy 47.24
2022-09-28 01:14:39,637 [foster.py] => Task 2, Epoch 26/34 => Loss 1.991, Loss_clf 0.410, Loss_fe 0.546, Loss_kd 0.796, Train_accy 46.99, Test_accy 62.26
2022-09-28 01:14:41,427 [foster.py] => Task 2, Epoch 27/34 => Loss 1.947, Loss_clf 0.392, Loss_fe 0.526, Loss_kd 0.792, Train_accy 47.98
2022-09-28 01:14:43,279 [foster.py] => Task 2, Epoch 28/34 => Loss 1.953, Loss_clf 0.401, Loss_fe 0.529, Loss_kd 0.787, Train_accy 46.63
2022-09-28 01:14:45,080 [foster.py] => Task 2, Epoch 29/34 => Loss 1.947, Loss_clf 0.405, Loss_fe 0.529, Loss_kd 0.779, Train_accy 48.47
2022-09-28 01:14:46,885 [foster.py] => Task 2, Epoch 30/34 => Loss 1.968, Loss_clf 0.407, Loss_fe 0.532, Loss_kd 0.791, Train_accy 46.13
2022-09-28 01:14:49,527 [foster.py] => Task 2, Epoch 31/34 => Loss 1.960, Loss_clf 0.405, Loss_fe 0.526, Loss_kd 0.792, Train_accy 47.73, Test_accy 61.94
2022-09-28 01:14:51,318 [foster.py] => Task 2, Epoch 32/34 => Loss 1.991, Loss_clf 0.415, Loss_fe 0.544, Loss_kd 0.794, Train_accy 45.89
2022-09-28 01:14:53,130 [foster.py] => Task 2, Epoch 33/34 => Loss 1.968, Loss_clf 0.394, Loss_fe 0.540, Loss_kd 0.796, Train_accy 47.48
2022-09-28 01:14:54,927 [foster.py] => Task 2, Epoch 34/34 => Loss 1.947, Loss_clf 0.389, Loss_fe 0.518, Loss_kd 0.800, Train_accy 48.34
2022-09-28 01:14:54,927 [foster.py] => do not weight align teacher!
2022-09-28 01:14:54,927 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 01:14:57,912 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.772,  Train_accy 17.55, Test_accy 47.42
2022-09-28 01:14:59,941 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.657,  Train_accy 17.79
2022-09-28 01:15:01,992 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.599,  Train_accy 18.40
2022-09-28 01:15:04,012 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.560,  Train_accy 19.63
2022-09-28 01:15:06,011 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.542,  Train_accy 19.63
2022-09-28 01:15:08,720 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.516,  Train_accy 19.88, Test_accy 51.94
2022-09-28 01:15:10,718 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.510,  Train_accy 19.63
2022-09-28 01:15:12,748 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.525,  Train_accy 20.12
2022-09-28 01:15:14,773 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.516,  Train_accy 20.74
2022-09-28 01:15:16,830 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.495,  Train_accy 20.12
2022-09-28 01:15:19,606 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.490,  Train_accy 21.47, Test_accy 53.55
2022-09-28 01:15:21,624 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.497,  Train_accy 21.23
2022-09-28 01:15:23,672 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.490,  Train_accy 21.96
2022-09-28 01:15:25,684 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.481,  Train_accy 21.96
2022-09-28 01:15:27,729 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.491,  Train_accy 22.94
2022-09-28 01:15:30,471 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.477,  Train_accy 21.96, Test_accy 53.55
2022-09-28 01:15:32,491 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.488,  Train_accy 22.09
2022-09-28 01:15:34,525 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.473,  Train_accy 22.21
2022-09-28 01:15:36,594 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.472,  Train_accy 21.47
2022-09-28 01:15:38,661 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.476,  Train_accy 23.19
2022-09-28 01:15:41,432 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.484,  Train_accy 23.19, Test_accy 53.87
2022-09-28 01:15:43,486 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.490,  Train_accy 22.45
2022-09-28 01:15:45,534 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.484,  Train_accy 22.45
2022-09-28 01:15:47,591 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.475,  Train_accy 22.09
2022-09-28 01:15:49,632 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.470,  Train_accy 23.56
2022-09-28 01:15:52,394 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.474,  Train_accy 22.33, Test_accy 54.19
2022-09-28 01:15:52,395 [foster.py] => do not weight align student!
2022-09-28 01:15:53,110 [foster.py] => darknet eval: 
2022-09-28 01:15:53,110 [foster.py] => CNN top1 curve: 54.19
2022-09-28 01:15:53,110 [foster.py] => CNN top5 curve: 97.1
2022-09-28 01:15:53,111 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 01:16:00,483 [foster.py] => Exemplar size: 260
2022-09-28 01:16:00,483 [trainer.py] => CNN: {'total': 61.94, 'old': 72.15, 'new': 28.77, 'base': 82.84, 'compound': 36.88}
2022-09-28 01:16:00,483 [trainer.py] => CNN top1 curve: [88.76, 74.68, 61.94]
2022-09-28 01:16:00,483 [trainer.py] => CNN base curve: [88.76, 87.57, 82.84]
2022-09-28 01:16:00,483 [trainer.py] => CNN old curve: [88.76, 87.57, 72.15]
2022-09-28 01:16:00,483 [trainer.py] => CNN new curve: [0, 42.65, 28.77]
2022-09-28 01:16:00,483 [trainer.py] => CNN compound curve: [0, 42.65, 36.88]
2022-09-28 01:16:00,483 [trainer.py] => NME: {'total': 72.9, 'old': 74.26, 'new': 68.49, 'base': 78.11, 'compound': 66.67}
2022-09-28 01:16:00,483 [trainer.py] => NME top1 curve: [87.57, 78.9, 72.9]
2022-09-28 01:16:00,483 [trainer.py] => NME base curve: [87.57, 82.84, 78.11]
2022-09-28 01:16:00,483 [trainer.py] => NME old curve: [87.57, 82.84, 74.26]
2022-09-28 01:16:00,483 [trainer.py] => NME new curve: [0, 69.12, 68.49]
2022-09-28 01:16:00,483 [trainer.py] => NME compound curve: [0, 69.12, 66.67]
2022-09-28 01:16:00,714 [foster.py] => Learning on 13-16
2022-09-28 01:16:00,714 [foster.py] => All params: 22384301
2022-09-28 01:16:00,714 [foster.py] => Trainable params: 11201120
2022-09-28 01:16:00,735 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 01:16:03,591 [foster.py] => Task 3, Epoch 1/34 => Loss 5.804, Loss_clf 1.979, Loss_fe 2.190, Loss_kd 1.328, Train_accy 42.76, Test_accy 42.13
2022-09-28 01:16:05,519 [foster.py] => Task 3, Epoch 2/34 => Loss 4.275, Loss_clf 1.052, Loss_fe 1.595, Loss_kd 1.323, Train_accy 37.78
2022-09-28 01:16:07,425 [foster.py] => Task 3, Epoch 3/34 => Loss 3.905, Loss_clf 0.879, Loss_fe 1.407, Loss_kd 1.315, Train_accy 40.50
2022-09-28 01:16:09,379 [foster.py] => Task 3, Epoch 4/34 => Loss 3.766, Loss_clf 0.844, Loss_fe 1.293, Loss_kd 1.324, Train_accy 38.91
2022-09-28 01:16:11,322 [foster.py] => Task 3, Epoch 5/34 => Loss 3.663, Loss_clf 0.840, Loss_fe 1.213, Loss_kd 1.309, Train_accy 36.65
2022-09-28 01:16:14,084 [foster.py] => Task 3, Epoch 6/34 => Loss 3.548, Loss_clf 0.794, Loss_fe 1.137, Loss_kd 1.314, Train_accy 38.69, Test_accy 50.67
2022-09-28 01:16:16,041 [foster.py] => Task 3, Epoch 7/34 => Loss 3.483, Loss_clf 0.777, Loss_fe 1.085, Loss_kd 1.317, Train_accy 38.80
2022-09-28 01:16:17,930 [foster.py] => Task 3, Epoch 8/34 => Loss 3.431, Loss_clf 0.767, Loss_fe 1.040, Loss_kd 1.320, Train_accy 37.67
2022-09-28 01:16:19,825 [foster.py] => Task 3, Epoch 9/34 => Loss 3.368, Loss_clf 0.744, Loss_fe 0.997, Loss_kd 1.322, Train_accy 40.27
2022-09-28 01:16:21,749 [foster.py] => Task 3, Epoch 10/34 => Loss 3.292, Loss_clf 0.731, Loss_fe 0.946, Loss_kd 1.312, Train_accy 40.72
2022-09-28 01:16:24,537 [foster.py] => Task 3, Epoch 11/34 => Loss 3.290, Loss_clf 0.737, Loss_fe 0.930, Loss_kd 1.318, Train_accy 38.91, Test_accy 51.20
2022-09-28 01:16:26,429 [foster.py] => Task 3, Epoch 12/34 => Loss 3.240, Loss_clf 0.717, Loss_fe 0.901, Loss_kd 1.318, Train_accy 40.84
2022-09-28 01:16:28,370 [foster.py] => Task 3, Epoch 13/34 => Loss 3.226, Loss_clf 0.718, Loss_fe 0.886, Loss_kd 1.317, Train_accy 37.67
2022-09-28 01:16:30,308 [foster.py] => Task 3, Epoch 14/34 => Loss 3.199, Loss_clf 0.716, Loss_fe 0.862, Loss_kd 1.316, Train_accy 40.38
2022-09-28 01:16:32,249 [foster.py] => Task 3, Epoch 15/34 => Loss 3.151, Loss_clf 0.686, Loss_fe 0.833, Loss_kd 1.326, Train_accy 40.72
2022-09-28 01:16:35,007 [foster.py] => Task 3, Epoch 16/34 => Loss 3.101, Loss_clf 0.666, Loss_fe 0.813, Loss_kd 1.318, Train_accy 41.29, Test_accy 50.40
2022-09-28 01:16:36,924 [foster.py] => Task 3, Epoch 17/34 => Loss 3.107, Loss_clf 0.671, Loss_fe 0.820, Loss_kd 1.313, Train_accy 40.95
2022-09-28 01:16:38,825 [foster.py] => Task 3, Epoch 18/34 => Loss 3.065, Loss_clf 0.656, Loss_fe 0.782, Loss_kd 1.322, Train_accy 40.16
2022-09-28 01:16:40,751 [foster.py] => Task 3, Epoch 19/34 => Loss 3.023, Loss_clf 0.641, Loss_fe 0.761, Loss_kd 1.316, Train_accy 41.29
2022-09-28 01:16:42,661 [foster.py] => Task 3, Epoch 20/34 => Loss 3.055, Loss_clf 0.651, Loss_fe 0.779, Loss_kd 1.320, Train_accy 43.10
2022-09-28 01:16:45,458 [foster.py] => Task 3, Epoch 21/34 => Loss 3.017, Loss_clf 0.632, Loss_fe 0.750, Loss_kd 1.328, Train_accy 41.86, Test_accy 52.27
2022-09-28 01:16:47,374 [foster.py] => Task 3, Epoch 22/34 => Loss 3.014, Loss_clf 0.632, Loss_fe 0.742, Loss_kd 1.332, Train_accy 41.97
2022-09-28 01:16:49,346 [foster.py] => Task 3, Epoch 23/34 => Loss 3.019, Loss_clf 0.638, Loss_fe 0.747, Loss_kd 1.327, Train_accy 43.89
2022-09-28 01:16:51,255 [foster.py] => Task 3, Epoch 24/34 => Loss 2.982, Loss_clf 0.621, Loss_fe 0.738, Loss_kd 1.319, Train_accy 41.52
2022-09-28 01:16:53,179 [foster.py] => Task 3, Epoch 25/34 => Loss 3.002, Loss_clf 0.630, Loss_fe 0.748, Loss_kd 1.320, Train_accy 42.31
2022-09-28 01:16:55,995 [foster.py] => Task 3, Epoch 26/34 => Loss 2.990, Loss_clf 0.619, Loss_fe 0.740, Loss_kd 1.324, Train_accy 44.23, Test_accy 51.47
2022-09-28 01:16:57,902 [foster.py] => Task 3, Epoch 27/34 => Loss 2.935, Loss_clf 0.606, Loss_fe 0.704, Loss_kd 1.320, Train_accy 44.91
2022-09-28 01:16:59,817 [foster.py] => Task 3, Epoch 28/34 => Loss 2.974, Loss_clf 0.621, Loss_fe 0.727, Loss_kd 1.321, Train_accy 41.86
2022-09-28 01:17:01,725 [foster.py] => Task 3, Epoch 29/34 => Loss 2.989, Loss_clf 0.626, Loss_fe 0.724, Loss_kd 1.332, Train_accy 42.53
2022-09-28 01:17:03,618 [foster.py] => Task 3, Epoch 30/34 => Loss 2.949, Loss_clf 0.601, Loss_fe 0.712, Loss_kd 1.330, Train_accy 43.89
2022-09-28 01:17:06,365 [foster.py] => Task 3, Epoch 31/34 => Loss 2.940, Loss_clf 0.608, Loss_fe 0.705, Loss_kd 1.321, Train_accy 42.08, Test_accy 51.47
2022-09-28 01:17:08,299 [foster.py] => Task 3, Epoch 32/34 => Loss 2.929, Loss_clf 0.603, Loss_fe 0.699, Loss_kd 1.322, Train_accy 43.33
2022-09-28 01:17:10,191 [foster.py] => Task 3, Epoch 33/34 => Loss 2.971, Loss_clf 0.617, Loss_fe 0.715, Loss_kd 1.331, Train_accy 43.78
2022-09-28 01:17:12,119 [foster.py] => Task 3, Epoch 34/34 => Loss 2.946, Loss_clf 0.607, Loss_fe 0.714, Loss_kd 1.321, Train_accy 42.42
2022-09-28 01:17:12,120 [foster.py] => do not weight align teacher!
2022-09-28 01:17:12,120 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 01:17:15,240 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.086,  Train_accy 18.21, Test_accy 46.13
2022-09-28 01:17:17,409 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.022,  Train_accy 18.33
2022-09-28 01:17:19,590 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 1.983,  Train_accy 19.34
2022-09-28 01:17:21,718 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 1.974,  Train_accy 19.23
2022-09-28 01:17:23,845 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.958,  Train_accy 19.80
2022-09-28 01:17:26,773 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.954,  Train_accy 19.68, Test_accy 46.40
2022-09-28 01:17:28,895 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.942,  Train_accy 19.68
2022-09-28 01:17:31,031 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.939,  Train_accy 20.02
2022-09-28 01:17:33,197 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.928,  Train_accy 20.48
2022-09-28 01:17:35,368 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.940,  Train_accy 20.48
2022-09-28 01:17:38,253 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.928,  Train_accy 20.02, Test_accy 46.40
2022-09-28 01:17:40,372 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.924,  Train_accy 20.14
2022-09-28 01:17:42,493 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.922,  Train_accy 20.25
2022-09-28 01:17:44,667 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.913,  Train_accy 19.80
2022-09-28 01:17:46,792 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.915,  Train_accy 20.81
2022-09-28 01:17:49,711 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.920,  Train_accy 20.02, Test_accy 46.67
2022-09-28 01:17:51,872 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.915,  Train_accy 20.25
2022-09-28 01:17:54,058 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.921,  Train_accy 20.48
2022-09-28 01:17:56,199 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.918,  Train_accy 19.80
2022-09-28 01:17:58,338 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.917,  Train_accy 20.36
2022-09-28 01:18:01,222 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.913,  Train_accy 20.25, Test_accy 46.40
2022-09-28 01:18:03,378 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.929,  Train_accy 20.14
2022-09-28 01:18:05,563 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.914,  Train_accy 19.91
2022-09-28 01:18:07,697 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.923,  Train_accy 20.36
2022-09-28 01:18:09,851 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.913,  Train_accy 19.91
2022-09-28 01:18:12,720 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.913,  Train_accy 20.02, Test_accy 46.40
2022-09-28 01:18:12,721 [foster.py] => do not weight align student!
2022-09-28 01:18:13,470 [foster.py] => darknet eval: 
2022-09-28 01:18:13,470 [foster.py] => CNN top1 curve: 46.4
2022-09-28 01:18:13,470 [foster.py] => CNN top5 curve: 88.27
2022-09-28 01:18:13,470 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 01:18:22,031 [foster.py] => Exemplar size: 320
2022-09-28 01:18:22,031 [trainer.py] => CNN: {'total': 51.73, 'old': 58.06, 'new': 21.54, 'base': 77.51, 'compound': 30.58}
2022-09-28 01:18:22,031 [trainer.py] => CNN top1 curve: [88.76, 74.68, 61.94, 51.73]
2022-09-28 01:18:22,031 [trainer.py] => CNN base curve: [88.76, 87.57, 82.84, 77.51]
2022-09-28 01:18:22,032 [trainer.py] => CNN old curve: [88.76, 87.57, 72.15, 58.06]
2022-09-28 01:18:22,032 [trainer.py] => CNN new curve: [0, 42.65, 28.77, 21.54]
2022-09-28 01:18:22,032 [trainer.py] => CNN compound curve: [0, 42.65, 36.88, 30.58]
2022-09-28 01:18:22,032 [trainer.py] => NME: {'total': 59.2, 'old': 62.58, 'new': 43.08, 'base': 70.41, 'compound': 50.0}
2022-09-28 01:18:22,032 [trainer.py] => NME top1 curve: [87.57, 78.9, 72.9, 59.2]
2022-09-28 01:18:22,032 [trainer.py] => NME base curve: [87.57, 82.84, 78.11, 70.41]
2022-09-28 01:18:22,032 [trainer.py] => NME old curve: [87.57, 82.84, 74.26, 62.58]
2022-09-28 01:18:22,032 [trainer.py] => NME new curve: [0, 69.12, 68.49, 43.08]
2022-09-28 01:18:22,032 [trainer.py] => NME compound curve: [0, 69.12, 66.67, 50.0]
2022-09-28 01:18:22,260 [foster.py] => Learning on 16-19
2022-09-28 01:18:22,261 [foster.py] => All params: 22390454
2022-09-28 01:18:22,261 [foster.py] => Trainable params: 11205734
2022-09-28 01:18:22,281 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 01:18:25,201 [foster.py] => Task 4, Epoch 1/34 => Loss 6.178, Loss_clf 1.850, Loss_fe 2.392, Loss_kd 1.630, Train_accy 42.08, Test_accy 44.67
2022-09-28 01:18:27,262 [foster.py] => Task 4, Epoch 2/34 => Loss 4.532, Loss_clf 0.916, Loss_fe 1.669, Loss_kd 1.640, Train_accy 42.93
2022-09-28 01:18:29,280 [foster.py] => Task 4, Epoch 3/34 => Loss 4.260, Loss_clf 0.851, Loss_fe 1.474, Loss_kd 1.630, Train_accy 45.48
2022-09-28 01:18:31,287 [foster.py] => Task 4, Epoch 4/34 => Loss 4.045, Loss_clf 0.784, Loss_fe 1.341, Loss_kd 1.617, Train_accy 47.72
2022-09-28 01:18:33,327 [foster.py] => Task 4, Epoch 5/34 => Loss 3.944, Loss_clf 0.774, Loss_fe 1.239, Loss_kd 1.626, Train_accy 46.33
2022-09-28 01:18:36,356 [foster.py] => Task 4, Epoch 6/34 => Loss 3.855, Loss_clf 0.746, Loss_fe 1.168, Loss_kd 1.634, Train_accy 47.18, Test_accy 46.03
2022-09-28 01:18:38,348 [foster.py] => Task 4, Epoch 7/34 => Loss 3.761, Loss_clf 0.738, Loss_fe 1.099, Loss_kd 1.620, Train_accy 48.57
2022-09-28 01:18:40,340 [foster.py] => Task 4, Epoch 8/34 => Loss 3.667, Loss_clf 0.706, Loss_fe 1.033, Loss_kd 1.623, Train_accy 49.73
2022-09-28 01:18:42,335 [foster.py] => Task 4, Epoch 9/34 => Loss 3.644, Loss_clf 0.710, Loss_fe 1.009, Loss_kd 1.621, Train_accy 49.31
2022-09-28 01:18:44,327 [foster.py] => Task 4, Epoch 10/34 => Loss 3.634, Loss_clf 0.720, Loss_fe 0.982, Loss_kd 1.627, Train_accy 48.99
2022-09-28 01:18:47,278 [foster.py] => Task 4, Epoch 11/34 => Loss 3.526, Loss_clf 0.660, Loss_fe 0.924, Loss_kd 1.636, Train_accy 51.22, Test_accy 47.85
2022-09-28 01:18:49,283 [foster.py] => Task 4, Epoch 12/34 => Loss 3.549, Loss_clf 0.688, Loss_fe 0.915, Loss_kd 1.638, Train_accy 49.42
2022-09-28 01:18:51,314 [foster.py] => Task 4, Epoch 13/34 => Loss 3.499, Loss_clf 0.673, Loss_fe 0.887, Loss_kd 1.633, Train_accy 47.50
2022-09-28 01:18:53,319 [foster.py] => Task 4, Epoch 14/34 => Loss 3.444, Loss_clf 0.665, Loss_fe 0.855, Loss_kd 1.620, Train_accy 51.01
2022-09-28 01:18:55,306 [foster.py] => Task 4, Epoch 15/34 => Loss 3.453, Loss_clf 0.670, Loss_fe 0.851, Loss_kd 1.627, Train_accy 49.63
2022-09-28 01:18:58,248 [foster.py] => Task 4, Epoch 16/34 => Loss 3.390, Loss_clf 0.633, Loss_fe 0.816, Loss_kd 1.634, Train_accy 51.01, Test_accy 49.66
2022-09-28 01:19:00,277 [foster.py] => Task 4, Epoch 17/34 => Loss 3.385, Loss_clf 0.648, Loss_fe 0.809, Loss_kd 1.623, Train_accy 50.90
2022-09-28 01:19:02,263 [foster.py] => Task 4, Epoch 18/34 => Loss 3.382, Loss_clf 0.646, Loss_fe 0.814, Loss_kd 1.619, Train_accy 51.22
2022-09-28 01:19:04,251 [foster.py] => Task 4, Epoch 19/34 => Loss 3.339, Loss_clf 0.625, Loss_fe 0.782, Loss_kd 1.627, Train_accy 50.90
2022-09-28 01:19:06,327 [foster.py] => Task 4, Epoch 20/34 => Loss 3.352, Loss_clf 0.632, Loss_fe 0.777, Loss_kd 1.636, Train_accy 51.97
2022-09-28 01:19:09,284 [foster.py] => Task 4, Epoch 21/34 => Loss 3.307, Loss_clf 0.615, Loss_fe 0.758, Loss_kd 1.629, Train_accy 51.43, Test_accy 49.21
2022-09-28 01:19:11,343 [foster.py] => Task 4, Epoch 22/34 => Loss 3.296, Loss_clf 0.605, Loss_fe 0.753, Loss_kd 1.632, Train_accy 51.86
2022-09-28 01:19:13,364 [foster.py] => Task 4, Epoch 23/34 => Loss 3.292, Loss_clf 0.610, Loss_fe 0.746, Loss_kd 1.630, Train_accy 52.50
2022-09-28 01:19:15,359 [foster.py] => Task 4, Epoch 24/34 => Loss 3.282, Loss_clf 0.600, Loss_fe 0.737, Loss_kd 1.638, Train_accy 51.12
2022-09-28 01:19:17,395 [foster.py] => Task 4, Epoch 25/34 => Loss 3.265, Loss_clf 0.600, Loss_fe 0.732, Loss_kd 1.628, Train_accy 51.43
2022-09-28 01:19:20,324 [foster.py] => Task 4, Epoch 26/34 => Loss 3.251, Loss_clf 0.594, Loss_fe 0.721, Loss_kd 1.631, Train_accy 52.71, Test_accy 48.75
2022-09-28 01:19:22,354 [foster.py] => Task 4, Epoch 27/34 => Loss 3.278, Loss_clf 0.604, Loss_fe 0.736, Loss_kd 1.633, Train_accy 51.01
2022-09-28 01:19:24,402 [foster.py] => Task 4, Epoch 28/34 => Loss 3.254, Loss_clf 0.598, Loss_fe 0.726, Loss_kd 1.626, Train_accy 51.43
2022-09-28 01:19:26,390 [foster.py] => Task 4, Epoch 29/34 => Loss 3.275, Loss_clf 0.598, Loss_fe 0.737, Loss_kd 1.634, Train_accy 52.18
2022-09-28 01:19:28,369 [foster.py] => Task 4, Epoch 30/34 => Loss 3.272, Loss_clf 0.614, Loss_fe 0.720, Loss_kd 1.632, Train_accy 51.12
2022-09-28 01:19:31,304 [foster.py] => Task 4, Epoch 31/34 => Loss 3.285, Loss_clf 0.604, Loss_fe 0.736, Loss_kd 1.638, Train_accy 51.01, Test_accy 48.98
2022-09-28 01:19:33,336 [foster.py] => Task 4, Epoch 32/34 => Loss 3.247, Loss_clf 0.590, Loss_fe 0.723, Loss_kd 1.629, Train_accy 52.50
2022-09-28 01:19:35,354 [foster.py] => Task 4, Epoch 33/34 => Loss 3.275, Loss_clf 0.609, Loss_fe 0.724, Loss_kd 1.635, Train_accy 52.71
2022-09-28 01:19:37,391 [foster.py] => Task 4, Epoch 34/34 => Loss 3.278, Loss_clf 0.601, Loss_fe 0.729, Loss_kd 1.641, Train_accy 51.75
2022-09-28 01:19:37,391 [foster.py] => do not weight align teacher!
2022-09-28 01:19:37,392 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 01:19:40,635 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.289,  Train_accy 18.92, Test_accy 40.36
2022-09-28 01:19:42,909 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.245,  Train_accy 19.13
2022-09-28 01:19:45,209 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.219,  Train_accy 19.13
2022-09-28 01:19:47,476 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.211,  Train_accy 20.19
2022-09-28 01:19:49,704 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.185,  Train_accy 20.19
2022-09-28 01:19:52,760 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.183,  Train_accy 19.66, Test_accy 42.63
2022-09-28 01:19:55,035 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.172,  Train_accy 20.51
2022-09-28 01:19:57,283 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.164,  Train_accy 20.94
2022-09-28 01:19:59,511 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.174,  Train_accy 21.36
2022-09-28 01:20:01,763 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.164,  Train_accy 20.83
2022-09-28 01:20:04,807 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.155,  Train_accy 22.00, Test_accy 42.86
2022-09-28 01:20:07,064 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.155,  Train_accy 21.79
2022-09-28 01:20:09,355 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.146,  Train_accy 21.89
2022-09-28 01:20:11,621 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.155,  Train_accy 22.64
2022-09-28 01:20:13,951 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.152,  Train_accy 22.42
2022-09-28 01:20:17,122 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.140,  Train_accy 22.32, Test_accy 43.54
2022-09-28 01:20:19,383 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.143,  Train_accy 22.00
2022-09-28 01:20:21,694 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.141,  Train_accy 23.38
2022-09-28 01:20:23,977 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.140,  Train_accy 22.64
2022-09-28 01:20:26,232 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.149,  Train_accy 23.80
2022-09-28 01:20:29,320 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.143,  Train_accy 22.00, Test_accy 43.54
2022-09-28 01:20:31,551 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.146,  Train_accy 24.65
2022-09-28 01:20:33,823 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.140,  Train_accy 23.38
2022-09-28 01:20:36,076 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.135,  Train_accy 22.10
2022-09-28 01:20:38,394 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.136,  Train_accy 23.17
2022-09-28 01:20:41,443 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.144,  Train_accy 22.10, Test_accy 43.31
2022-09-28 01:20:41,443 [foster.py] => do not weight align student!
2022-09-28 01:20:42,272 [foster.py] => darknet eval: 
2022-09-28 01:20:42,272 [foster.py] => CNN top1 curve: 43.31
2022-09-28 01:20:42,272 [foster.py] => CNN top5 curve: 88.44
2022-09-28 01:20:42,273 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 01:20:51,850 [foster.py] => Exemplar size: 380
2022-09-28 01:20:51,850 [trainer.py] => CNN: {'total': 48.53, 'old': 51.47, 'new': 31.82, 'base': 77.51, 'compound': 30.51}
2022-09-28 01:20:51,850 [trainer.py] => CNN top1 curve: [88.76, 74.68, 61.94, 51.73, 48.53]
2022-09-28 01:20:51,851 [trainer.py] => CNN base curve: [88.76, 87.57, 82.84, 77.51, 77.51]
2022-09-28 01:20:51,851 [trainer.py] => CNN old curve: [88.76, 87.57, 72.15, 58.06, 51.47]
2022-09-28 01:20:51,851 [trainer.py] => CNN new curve: [0, 42.65, 28.77, 21.54, 31.82]
2022-09-28 01:20:51,851 [trainer.py] => CNN compound curve: [0, 42.65, 36.88, 30.58, 30.51]
2022-09-28 01:20:51,851 [trainer.py] => NME: {'total': 54.65, 'old': 54.93, 'new': 53.03, 'base': 69.23, 'compound': 45.59}
2022-09-28 01:20:51,851 [trainer.py] => NME top1 curve: [87.57, 78.9, 72.9, 59.2, 54.65]
2022-09-28 01:20:51,851 [trainer.py] => NME base curve: [87.57, 82.84, 78.11, 70.41, 69.23]
2022-09-28 01:20:51,851 [trainer.py] => NME old curve: [87.57, 82.84, 74.26, 62.58, 54.93]
2022-09-28 01:20:51,851 [trainer.py] => NME new curve: [0, 69.12, 68.49, 43.08, 53.03]
2022-09-28 01:20:51,851 [trainer.py] => NME compound curve: [0, 69.12, 66.67, 50.0, 45.59]
2022-09-28 01:20:52,081 [foster.py] => Learning on 19-22
2022-09-28 01:20:52,081 [foster.py] => All params: 22396607
2022-09-28 01:20:52,081 [foster.py] => Trainable params: 11210348
2022-09-28 01:20:52,102 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 01:20:55,159 [foster.py] => Task 5, Epoch 1/34 => Loss 6.626, Loss_clf 1.875, Loss_fe 2.552, Loss_kd 1.900, Train_accy 37.59, Test_accy 44.16
2022-09-28 01:20:57,269 [foster.py] => Task 5, Epoch 2/34 => Loss 5.209, Loss_clf 1.134, Loss_fe 1.863, Loss_kd 1.910, Train_accy 35.00
2022-09-28 01:20:59,356 [foster.py] => Task 5, Epoch 3/34 => Loss 4.860, Loss_clf 1.012, Loss_fe 1.636, Loss_kd 1.910, Train_accy 39.68
2022-09-28 01:21:01,450 [foster.py] => Task 5, Epoch 4/34 => Loss 4.696, Loss_clf 0.973, Loss_fe 1.527, Loss_kd 1.897, Train_accy 40.18
2022-09-28 01:21:03,529 [foster.py] => Task 5, Epoch 5/34 => Loss 4.577, Loss_clf 0.949, Loss_fe 1.430, Loss_kd 1.898, Train_accy 41.28
2022-09-28 01:21:06,647 [foster.py] => Task 5, Epoch 6/34 => Loss 4.512, Loss_clf 0.935, Loss_fe 1.371, Loss_kd 1.905, Train_accy 43.07, Test_accy 46.93
2022-09-28 01:21:08,762 [foster.py] => Task 5, Epoch 7/34 => Loss 4.408, Loss_clf 0.912, Loss_fe 1.289, Loss_kd 1.906, Train_accy 42.07
2022-09-28 01:21:10,869 [foster.py] => Task 5, Epoch 8/34 => Loss 4.338, Loss_clf 0.891, Loss_fe 1.232, Loss_kd 1.912, Train_accy 44.17
2022-09-28 01:21:12,995 [foster.py] => Task 5, Epoch 9/34 => Loss 4.266, Loss_clf 0.879, Loss_fe 1.184, Loss_kd 1.903, Train_accy 44.77
2022-09-28 01:21:15,123 [foster.py] => Task 5, Epoch 10/34 => Loss 4.220, Loss_clf 0.865, Loss_fe 1.143, Loss_kd 1.911, Train_accy 44.07
2022-09-28 01:21:18,255 [foster.py] => Task 5, Epoch 11/34 => Loss 4.146, Loss_clf 0.843, Loss_fe 1.099, Loss_kd 1.903, Train_accy 41.77, Test_accy 47.72
2022-09-28 01:21:20,376 [foster.py] => Task 5, Epoch 12/34 => Loss 4.103, Loss_clf 0.822, Loss_fe 1.068, Loss_kd 1.911, Train_accy 44.27
2022-09-28 01:21:22,453 [foster.py] => Task 5, Epoch 13/34 => Loss 4.019, Loss_clf 0.791, Loss_fe 1.015, Loss_kd 1.911, Train_accy 45.86
2022-09-28 01:21:24,588 [foster.py] => Task 5, Epoch 14/34 => Loss 4.056, Loss_clf 0.819, Loss_fe 1.024, Loss_kd 1.911, Train_accy 43.47
2022-09-28 01:21:26,679 [foster.py] => Task 5, Epoch 15/34 => Loss 4.011, Loss_clf 0.797, Loss_fe 1.005, Loss_kd 1.908, Train_accy 45.56
2022-09-28 01:21:29,820 [foster.py] => Task 5, Epoch 16/34 => Loss 3.997, Loss_clf 0.794, Loss_fe 0.985, Loss_kd 1.915, Train_accy 45.76, Test_accy 47.52
2022-09-28 01:21:31,910 [foster.py] => Task 5, Epoch 17/34 => Loss 3.941, Loss_clf 0.772, Loss_fe 0.958, Loss_kd 1.910, Train_accy 47.46
2022-09-28 01:21:34,076 [foster.py] => Task 5, Epoch 18/34 => Loss 3.931, Loss_clf 0.761, Loss_fe 0.952, Loss_kd 1.915, Train_accy 46.96
2022-09-28 01:21:36,212 [foster.py] => Task 5, Epoch 19/34 => Loss 3.922, Loss_clf 0.771, Loss_fe 0.933, Loss_kd 1.915, Train_accy 47.06
2022-09-28 01:21:38,301 [foster.py] => Task 5, Epoch 20/34 => Loss 3.883, Loss_clf 0.763, Loss_fe 0.911, Loss_kd 1.908, Train_accy 46.46
2022-09-28 01:21:41,447 [foster.py] => Task 5, Epoch 21/34 => Loss 3.863, Loss_clf 0.748, Loss_fe 0.901, Loss_kd 1.912, Train_accy 47.76, Test_accy 47.92
2022-09-28 01:21:43,568 [foster.py] => Task 5, Epoch 22/34 => Loss 3.871, Loss_clf 0.748, Loss_fe 0.897, Loss_kd 1.922, Train_accy 46.56
2022-09-28 01:21:45,729 [foster.py] => Task 5, Epoch 23/34 => Loss 3.817, Loss_clf 0.725, Loss_fe 0.873, Loss_kd 1.916, Train_accy 48.85
2022-09-28 01:21:47,844 [foster.py] => Task 5, Epoch 24/34 => Loss 3.844, Loss_clf 0.744, Loss_fe 0.892, Loss_kd 1.906, Train_accy 46.36
2022-09-28 01:21:49,974 [foster.py] => Task 5, Epoch 25/34 => Loss 3.835, Loss_clf 0.733, Loss_fe 0.890, Loss_kd 1.910, Train_accy 47.76
2022-09-28 01:21:53,066 [foster.py] => Task 5, Epoch 26/34 => Loss 3.816, Loss_clf 0.731, Loss_fe 0.877, Loss_kd 1.907, Train_accy 48.35, Test_accy 47.92
2022-09-28 01:21:55,167 [foster.py] => Task 5, Epoch 27/34 => Loss 3.785, Loss_clf 0.713, Loss_fe 0.854, Loss_kd 1.916, Train_accy 48.45
2022-09-28 01:21:57,251 [foster.py] => Task 5, Epoch 28/34 => Loss 3.826, Loss_clf 0.739, Loss_fe 0.871, Loss_kd 1.913, Train_accy 47.36
2022-09-28 01:21:59,329 [foster.py] => Task 5, Epoch 29/34 => Loss 3.770, Loss_clf 0.708, Loss_fe 0.852, Loss_kd 1.909, Train_accy 47.36
2022-09-28 01:22:01,431 [foster.py] => Task 5, Epoch 30/34 => Loss 3.773, Loss_clf 0.713, Loss_fe 0.849, Loss_kd 1.910, Train_accy 48.85
2022-09-28 01:22:04,504 [foster.py] => Task 5, Epoch 31/34 => Loss 3.822, Loss_clf 0.734, Loss_fe 0.870, Loss_kd 1.916, Train_accy 49.05, Test_accy 48.51
2022-09-28 01:22:06,671 [foster.py] => Task 5, Epoch 32/34 => Loss 3.791, Loss_clf 0.714, Loss_fe 0.855, Loss_kd 1.919, Train_accy 48.06
2022-09-28 01:22:08,763 [foster.py] => Task 5, Epoch 33/34 => Loss 3.808, Loss_clf 0.723, Loss_fe 0.859, Loss_kd 1.923, Train_accy 47.96
2022-09-28 01:22:10,931 [foster.py] => Task 5, Epoch 34/34 => Loss 3.783, Loss_clf 0.718, Loss_fe 0.856, Loss_kd 1.908, Train_accy 50.05
2022-09-28 01:22:10,931 [foster.py] => do not weight align teacher!
2022-09-28 01:22:10,931 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 01:22:14,356 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.418,  Train_accy 19.94, Test_accy 39.01
2022-09-28 01:22:16,751 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.408,  Train_accy 19.74
2022-09-28 01:22:19,146 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.410,  Train_accy 20.94
2022-09-28 01:22:21,490 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.390,  Train_accy 20.04
2022-09-28 01:22:23,837 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.383,  Train_accy 20.44
2022-09-28 01:22:27,010 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.380,  Train_accy 21.14, Test_accy 40.79
2022-09-28 01:22:29,340 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.377,  Train_accy 21.24
2022-09-28 01:22:31,705 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.371,  Train_accy 20.64
2022-09-28 01:22:34,129 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.371,  Train_accy 21.04
2022-09-28 01:22:36,524 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.356,  Train_accy 22.73
2022-09-28 01:22:39,781 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.359,  Train_accy 22.13, Test_accy 40.79
2022-09-28 01:22:42,135 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.355,  Train_accy 21.93
2022-09-28 01:22:44,503 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.356,  Train_accy 21.64
2022-09-28 01:22:46,848 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.365,  Train_accy 21.54
2022-09-28 01:22:49,251 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.355,  Train_accy 21.54
2022-09-28 01:22:52,494 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.355,  Train_accy 21.93, Test_accy 41.78
2022-09-28 01:22:54,888 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.355,  Train_accy 22.03
2022-09-28 01:22:57,280 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.361,  Train_accy 21.93
2022-09-28 01:22:59,675 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.354,  Train_accy 22.03
2022-09-28 01:23:02,053 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.353,  Train_accy 21.93
2022-09-28 01:23:05,303 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.353,  Train_accy 21.44, Test_accy 41.98
2022-09-28 01:23:07,641 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.350,  Train_accy 22.23
2022-09-28 01:23:10,047 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.353,  Train_accy 21.54
2022-09-28 01:23:12,409 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.349,  Train_accy 22.13
2022-09-28 01:23:14,747 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.357,  Train_accy 22.33
2022-09-28 01:23:17,924 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.351,  Train_accy 21.54, Test_accy 42.18
2022-09-28 01:23:17,924 [foster.py] => do not weight align student!
2022-09-28 01:23:18,778 [foster.py] => darknet eval: 
2022-09-28 01:23:18,778 [foster.py] => CNN top1 curve: 42.18
2022-09-28 01:23:18,778 [foster.py] => CNN top5 curve: 83.76
2022-09-28 01:23:18,778 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 01:23:29,419 [foster.py] => Exemplar size: 440
2022-09-28 01:23:29,419 [trainer.py] => CNN: {'total': 48.12, 'old': 50.57, 'new': 31.25, 'base': 71.01, 'compound': 36.61}
2022-09-28 01:23:29,419 [trainer.py] => CNN top1 curve: [88.76, 74.68, 61.94, 51.73, 48.53, 48.12]
2022-09-28 01:23:29,419 [trainer.py] => CNN base curve: [88.76, 87.57, 82.84, 77.51, 77.51, 71.01]
2022-09-28 01:23:29,419 [trainer.py] => CNN old curve: [88.76, 87.57, 72.15, 58.06, 51.47, 50.57]
2022-09-28 01:23:29,419 [trainer.py] => CNN new curve: [0, 42.65, 28.77, 21.54, 31.82, 31.25]
2022-09-28 01:23:29,419 [trainer.py] => CNN compound curve: [0, 42.65, 36.88, 30.58, 30.51, 36.61]
2022-09-28 01:23:29,419 [trainer.py] => NME: {'total': 53.27, 'old': 53.97, 'new': 48.44, 'base': 66.86, 'compound': 46.43}
2022-09-28 01:23:29,419 [trainer.py] => NME top1 curve: [87.57, 78.9, 72.9, 59.2, 54.65, 53.27]
2022-09-28 01:23:29,419 [trainer.py] => NME base curve: [87.57, 82.84, 78.11, 70.41, 69.23, 66.86]
2022-09-28 01:23:29,420 [trainer.py] => NME old curve: [87.57, 82.84, 74.26, 62.58, 54.93, 53.97]
2022-09-28 01:23:29,420 [trainer.py] => NME new curve: [0, 69.12, 68.49, 43.08, 53.03, 48.44]
2022-09-28 01:23:29,420 [trainer.py] => NME compound curve: [0, 69.12, 66.67, 50.0, 45.59, 46.43]
2022-09-28 01:23:29,421 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 01:23:29,421 [trainer.py] => prefix: cil
2022-09-28 01:23:29,421 [trainer.py] => dataset: CFEE
2022-09-28 01:23:29,421 [trainer.py] => memory_size: 2000
2022-09-28 01:23:29,421 [trainer.py] => memory_per_class: 20
2022-09-28 01:23:29,421 [trainer.py] => fixed_memory: True
2022-09-28 01:23:29,421 [trainer.py] => shuffle: True
2022-09-28 01:23:29,421 [trainer.py] => init_cls: 7
2022-09-28 01:23:29,421 [trainer.py] => increment: 3
2022-09-28 01:23:29,421 [trainer.py] => model_name: foster
2022-09-28 01:23:29,421 [trainer.py] => convnet_type: resnet18
2022-09-28 01:23:29,421 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 01:23:29,421 [trainer.py] => seed: 1993
2022-09-28 01:23:29,421 [trainer.py] => beta1: 0.96
2022-09-28 01:23:29,421 [trainer.py] => beta2: 0.97
2022-09-28 01:23:29,421 [trainer.py] => oofc: ft
2022-09-28 01:23:29,421 [trainer.py] => is_teacher_wa: False
2022-09-28 01:23:29,421 [trainer.py] => is_student_wa: False
2022-09-28 01:23:29,421 [trainer.py] => lambda_okd: 1
2022-09-28 01:23:29,421 [trainer.py] => wa_value: 1
2022-09-28 01:23:29,421 [trainer.py] => init_epochs: 40
2022-09-28 01:23:29,421 [trainer.py] => init_lr: 0.01
2022-09-28 01:23:29,421 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 01:23:29,421 [trainer.py] => boosting_epochs: 34
2022-09-28 01:23:29,422 [trainer.py] => compression_epochs: 26
2022-09-28 01:23:29,422 [trainer.py] => lr: 0.001
2022-09-28 01:23:29,422 [trainer.py] => batch_size: 32
2022-09-28 01:23:29,422 [trainer.py] => weight_decay: 0.0005
2022-09-28 01:23:29,422 [trainer.py] => num_workers: 8
2022-09-28 01:23:29,422 [trainer.py] => T: 2
2022-09-28 01:23:29,422 [trainer.py] => nb_runs: 3
2022-09-28 01:23:29,422 [trainer.py] => fold: 10
2022-09-28 01:23:29,422 [data.py] => ========== Fold:6 ==========
2022-09-28 01:23:29,427 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 13, 17, 15, 9, 11, 20, 18, 12, 14, 7, 10, 19, 21, 16, 8]
2022-09-28 01:23:29,639 [foster.py] => Learning on 0-7
2022-09-28 01:23:29,639 [foster.py] => All params: 11183694
2022-09-28 01:23:29,639 [foster.py] => Trainable params: 11183694
2022-09-28 01:23:32,038 [foster.py] => Task 0, Epoch 1/40 => Loss 1.389, Train_accy 48.06
2022-09-28 01:23:35,023 [foster.py] => Task 0, Epoch 2/40 => Loss 0.570, Train_accy 78.77, Test_accy 81.99
2022-09-28 01:23:38,035 [foster.py] => Task 0, Epoch 3/40 => Loss 0.375, Train_accy 87.28, Test_accy 85.71
2022-09-28 01:23:41,063 [foster.py] => Task 0, Epoch 4/40 => Loss 0.307, Train_accy 89.83, Test_accy 88.82
2022-09-28 01:23:44,078 [foster.py] => Task 0, Epoch 5/40 => Loss 0.250, Train_accy 91.01, Test_accy 89.44
2022-09-28 01:23:46,477 [foster.py] => Task 0, Epoch 6/40 => Loss 0.209, Train_accy 93.02
2022-09-28 01:23:49,506 [foster.py] => Task 0, Epoch 7/40 => Loss 0.182, Train_accy 94.12, Test_accy 89.44
2022-09-28 01:23:52,484 [foster.py] => Task 0, Epoch 8/40 => Loss 0.151, Train_accy 94.61, Test_accy 86.34
2022-09-28 01:23:55,461 [foster.py] => Task 0, Epoch 9/40 => Loss 0.151, Train_accy 95.99, Test_accy 86.96
2022-09-28 01:23:58,459 [foster.py] => Task 0, Epoch 10/40 => Loss 0.134, Train_accy 96.13, Test_accy 91.30
2022-09-28 01:24:00,832 [foster.py] => Task 0, Epoch 11/40 => Loss 0.103, Train_accy 96.54
2022-09-28 01:24:03,834 [foster.py] => Task 0, Epoch 12/40 => Loss 0.103, Train_accy 97.51, Test_accy 90.68
2022-09-28 01:24:06,832 [foster.py] => Task 0, Epoch 13/40 => Loss 0.106, Train_accy 97.65, Test_accy 87.58
2022-09-28 01:24:09,853 [foster.py] => Task 0, Epoch 14/40 => Loss 0.082, Train_accy 97.30, Test_accy 88.82
2022-09-28 01:24:12,854 [foster.py] => Task 0, Epoch 15/40 => Loss 0.072, Train_accy 98.06, Test_accy 88.20
2022-09-28 01:24:15,198 [foster.py] => Task 0, Epoch 16/40 => Loss 0.059, Train_accy 98.69
2022-09-28 01:24:18,196 [foster.py] => Task 0, Epoch 17/40 => Loss 0.073, Train_accy 98.06, Test_accy 90.06
2022-09-28 01:24:21,181 [foster.py] => Task 0, Epoch 18/40 => Loss 0.078, Train_accy 98.27, Test_accy 89.44
2022-09-28 01:24:24,181 [foster.py] => Task 0, Epoch 19/40 => Loss 0.055, Train_accy 98.55, Test_accy 90.68
2022-09-28 01:24:27,190 [foster.py] => Task 0, Epoch 20/40 => Loss 0.040, Train_accy 98.89, Test_accy 90.06
2022-09-28 01:24:29,573 [foster.py] => Task 0, Epoch 21/40 => Loss 0.037, Train_accy 99.17
2022-09-28 01:24:32,647 [foster.py] => Task 0, Epoch 22/40 => Loss 0.027, Train_accy 99.45, Test_accy 90.06
2022-09-28 01:24:35,637 [foster.py] => Task 0, Epoch 23/40 => Loss 0.026, Train_accy 99.45, Test_accy 88.82
2022-09-28 01:24:38,651 [foster.py] => Task 0, Epoch 24/40 => Loss 0.027, Train_accy 99.38, Test_accy 88.82
2022-09-28 01:24:41,682 [foster.py] => Task 0, Epoch 25/40 => Loss 0.020, Train_accy 99.65, Test_accy 88.20
2022-09-28 01:24:44,067 [foster.py] => Task 0, Epoch 26/40 => Loss 0.020, Train_accy 99.79
2022-09-28 01:24:47,054 [foster.py] => Task 0, Epoch 27/40 => Loss 0.018, Train_accy 99.65, Test_accy 90.06
2022-09-28 01:24:50,024 [foster.py] => Task 0, Epoch 28/40 => Loss 0.017, Train_accy 99.72, Test_accy 89.44
2022-09-28 01:24:53,012 [foster.py] => Task 0, Epoch 29/40 => Loss 0.018, Train_accy 99.86, Test_accy 89.44
2022-09-28 01:24:56,027 [foster.py] => Task 0, Epoch 30/40 => Loss 0.016, Train_accy 99.86, Test_accy 90.06
2022-09-28 01:24:58,400 [foster.py] => Task 0, Epoch 31/40 => Loss 0.021, Train_accy 99.79
2022-09-28 01:25:01,396 [foster.py] => Task 0, Epoch 32/40 => Loss 0.026, Train_accy 99.79, Test_accy 89.44
2022-09-28 01:25:04,398 [foster.py] => Task 0, Epoch 33/40 => Loss 0.015, Train_accy 99.93, Test_accy 88.82
2022-09-28 01:25:07,420 [foster.py] => Task 0, Epoch 34/40 => Loss 0.022, Train_accy 99.86, Test_accy 88.20
2022-09-28 01:25:10,459 [foster.py] => Task 0, Epoch 35/40 => Loss 0.013, Train_accy 99.86, Test_accy 88.82
2022-09-28 01:25:12,819 [foster.py] => Task 0, Epoch 36/40 => Loss 0.013, Train_accy 99.86
2022-09-28 01:25:15,829 [foster.py] => Task 0, Epoch 37/40 => Loss 0.019, Train_accy 99.72, Test_accy 90.06
2022-09-28 01:25:18,798 [foster.py] => Task 0, Epoch 38/40 => Loss 0.012, Train_accy 99.93, Test_accy 89.44
2022-09-28 01:25:21,797 [foster.py] => Task 0, Epoch 39/40 => Loss 0.014, Train_accy 99.93, Test_accy 91.30
2022-09-28 01:25:24,801 [foster.py] => Task 0, Epoch 40/40 => Loss 0.020, Train_accy 99.86, Test_accy 89.44
2022-09-28 01:25:24,802 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 01:25:31,648 [foster.py] => Exemplar size: 140
2022-09-28 01:25:31,648 [trainer.py] => CNN: {'total': 89.44, 'old': 89.44, 'new': 0, 'base': 89.44, 'compound': 0}
2022-09-28 01:25:31,648 [trainer.py] => CNN top1 curve: [89.44]
2022-09-28 01:25:31,648 [trainer.py] => CNN base curve: [89.44]
2022-09-28 01:25:31,648 [trainer.py] => CNN old curve: [89.44]
2022-09-28 01:25:31,648 [trainer.py] => CNN new curve: [0]
2022-09-28 01:25:31,649 [trainer.py] => CNN compound curve: [0]
2022-09-28 01:25:31,649 [trainer.py] => NME: {'total': 88.82, 'old': 88.82, 'new': 0, 'base': 88.82, 'compound': 0}
2022-09-28 01:25:31,649 [trainer.py] => NME top1 curve: [88.82]
2022-09-28 01:25:31,649 [trainer.py] => NME base curve: [88.82]
2022-09-28 01:25:31,649 [trainer.py] => NME old curve: [88.82]
2022-09-28 01:25:31,649 [trainer.py] => NME new curve: [0]
2022-09-28 01:25:31,649 [trainer.py] => NME compound curve: [0]
2022-09-28 01:25:31,878 [foster.py] => Learning on 7-10
2022-09-28 01:25:31,878 [foster.py] => All params: 22371995
2022-09-28 01:25:31,879 [foster.py] => Trainable params: 11191892
2022-09-28 01:25:31,899 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 01:25:34,374 [foster.py] => Task 1, Epoch 1/34 => Loss 4.751, Loss_clf 2.255, Loss_fe 1.827, Loss_kd 0.469, Train_accy 39.97, Test_accy 70.12
2022-09-28 01:25:36,110 [foster.py] => Task 1, Epoch 2/34 => Loss 2.418, Loss_clf 0.624, Loss_fe 1.118, Loss_kd 0.473, Train_accy 80.21
2022-09-28 01:25:37,860 [foster.py] => Task 1, Epoch 3/34 => Loss 1.940, Loss_clf 0.391, Loss_fe 0.889, Loss_kd 0.462, Train_accy 54.81
2022-09-28 01:25:39,585 [foster.py] => Task 1, Epoch 4/34 => Loss 1.785, Loss_clf 0.350, Loss_fe 0.786, Loss_kd 0.455, Train_accy 56.42
2022-09-28 01:25:41,348 [foster.py] => Task 1, Epoch 5/34 => Loss 1.682, Loss_clf 0.335, Loss_fe 0.699, Loss_kd 0.453, Train_accy 53.74
2022-09-28 01:25:43,802 [foster.py] => Task 1, Epoch 6/34 => Loss 1.595, Loss_clf 0.316, Loss_fe 0.628, Loss_kd 0.455, Train_accy 55.08, Test_accy 73.86
2022-09-28 01:25:45,546 [foster.py] => Task 1, Epoch 7/34 => Loss 1.542, Loss_clf 0.310, Loss_fe 0.572, Loss_kd 0.462, Train_accy 57.22
2022-09-28 01:25:47,324 [foster.py] => Task 1, Epoch 8/34 => Loss 1.445, Loss_clf 0.268, Loss_fe 0.527, Loss_kd 0.455, Train_accy 54.28
2022-09-28 01:25:49,053 [foster.py] => Task 1, Epoch 9/34 => Loss 1.431, Loss_clf 0.285, Loss_fe 0.497, Loss_kd 0.454, Train_accy 54.28
2022-09-28 01:25:50,792 [foster.py] => Task 1, Epoch 10/34 => Loss 1.425, Loss_clf 0.278, Loss_fe 0.501, Loss_kd 0.452, Train_accy 53.61
2022-09-28 01:25:53,228 [foster.py] => Task 1, Epoch 11/34 => Loss 1.424, Loss_clf 0.286, Loss_fe 0.497, Loss_kd 0.448, Train_accy 54.28, Test_accy 75.52
2022-09-28 01:25:54,922 [foster.py] => Task 1, Epoch 12/34 => Loss 1.355, Loss_clf 0.267, Loss_fe 0.445, Loss_kd 0.450, Train_accy 56.15
2022-09-28 01:25:56,656 [foster.py] => Task 1, Epoch 13/34 => Loss 1.300, Loss_clf 0.248, Loss_fe 0.416, Loss_kd 0.446, Train_accy 55.61
2022-09-28 01:25:58,371 [foster.py] => Task 1, Epoch 14/34 => Loss 1.353, Loss_clf 0.274, Loss_fe 0.436, Loss_kd 0.450, Train_accy 55.08
2022-09-28 01:26:00,107 [foster.py] => Task 1, Epoch 15/34 => Loss 1.260, Loss_clf 0.231, Loss_fe 0.393, Loss_kd 0.446, Train_accy 54.41
2022-09-28 01:26:02,618 [foster.py] => Task 1, Epoch 16/34 => Loss 1.245, Loss_clf 0.228, Loss_fe 0.372, Loss_kd 0.452, Train_accy 53.88, Test_accy 75.52
2022-09-28 01:26:04,349 [foster.py] => Task 1, Epoch 17/34 => Loss 1.258, Loss_clf 0.230, Loss_fe 0.382, Loss_kd 0.452, Train_accy 56.15
2022-09-28 01:26:06,077 [foster.py] => Task 1, Epoch 18/34 => Loss 1.268, Loss_clf 0.245, Loss_fe 0.369, Loss_kd 0.458, Train_accy 54.81
2022-09-28 01:26:07,782 [foster.py] => Task 1, Epoch 19/34 => Loss 1.230, Loss_clf 0.223, Loss_fe 0.359, Loss_kd 0.454, Train_accy 58.96
2022-09-28 01:26:09,532 [foster.py] => Task 1, Epoch 20/34 => Loss 1.225, Loss_clf 0.226, Loss_fe 0.355, Loss_kd 0.451, Train_accy 58.16
2022-09-28 01:26:12,000 [foster.py] => Task 1, Epoch 21/34 => Loss 1.251, Loss_clf 0.239, Loss_fe 0.370, Loss_kd 0.449, Train_accy 57.35, Test_accy 76.35
2022-09-28 01:26:13,742 [foster.py] => Task 1, Epoch 22/34 => Loss 1.199, Loss_clf 0.216, Loss_fe 0.330, Loss_kd 0.457, Train_accy 58.82
2022-09-28 01:26:15,452 [foster.py] => Task 1, Epoch 23/34 => Loss 1.223, Loss_clf 0.228, Loss_fe 0.347, Loss_kd 0.454, Train_accy 55.21
2022-09-28 01:26:17,238 [foster.py] => Task 1, Epoch 24/34 => Loss 1.228, Loss_clf 0.227, Loss_fe 0.349, Loss_kd 0.456, Train_accy 58.02
2022-09-28 01:26:18,948 [foster.py] => Task 1, Epoch 25/34 => Loss 1.183, Loss_clf 0.213, Loss_fe 0.329, Loss_kd 0.449, Train_accy 56.42
2022-09-28 01:26:21,457 [foster.py] => Task 1, Epoch 26/34 => Loss 1.215, Loss_clf 0.222, Loss_fe 0.353, Loss_kd 0.448, Train_accy 56.28, Test_accy 76.76
2022-09-28 01:26:23,203 [foster.py] => Task 1, Epoch 27/34 => Loss 1.217, Loss_clf 0.225, Loss_fe 0.344, Loss_kd 0.453, Train_accy 55.08
2022-09-28 01:26:24,961 [foster.py] => Task 1, Epoch 28/34 => Loss 1.162, Loss_clf 0.206, Loss_fe 0.316, Loss_kd 0.449, Train_accy 54.55
2022-09-28 01:26:26,736 [foster.py] => Task 1, Epoch 29/34 => Loss 1.190, Loss_clf 0.217, Loss_fe 0.324, Loss_kd 0.455, Train_accy 57.89
2022-09-28 01:26:28,435 [foster.py] => Task 1, Epoch 30/34 => Loss 1.140, Loss_clf 0.197, Loss_fe 0.308, Loss_kd 0.445, Train_accy 57.09
2022-09-28 01:26:30,868 [foster.py] => Task 1, Epoch 31/34 => Loss 1.204, Loss_clf 0.215, Loss_fe 0.331, Loss_kd 0.461, Train_accy 57.22, Test_accy 76.76
2022-09-28 01:26:32,583 [foster.py] => Task 1, Epoch 32/34 => Loss 1.196, Loss_clf 0.218, Loss_fe 0.334, Loss_kd 0.451, Train_accy 56.28
2022-09-28 01:26:34,277 [foster.py] => Task 1, Epoch 33/34 => Loss 1.212, Loss_clf 0.227, Loss_fe 0.338, Loss_kd 0.453, Train_accy 55.75
2022-09-28 01:26:36,028 [foster.py] => Task 1, Epoch 34/34 => Loss 1.200, Loss_clf 0.213, Loss_fe 0.333, Loss_kd 0.458, Train_accy 56.82
2022-09-28 01:26:36,029 [foster.py] => do not weight align teacher!
2022-09-28 01:26:36,029 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 01:26:38,891 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.498,  Train_accy 18.32, Test_accy 60.17
2022-09-28 01:26:40,806 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.404,  Train_accy 19.12
2022-09-28 01:26:42,770 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.337,  Train_accy 19.52
2022-09-28 01:26:44,673 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.276,  Train_accy 22.06
2022-09-28 01:26:46,608 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.278,  Train_accy 23.53
2022-09-28 01:26:49,174 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.247,  Train_accy 26.07, Test_accy 63.07
2022-09-28 01:26:51,099 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.226,  Train_accy 26.07
2022-09-28 01:26:52,992 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.228,  Train_accy 28.61
2022-09-28 01:26:54,883 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.214,  Train_accy 29.14
2022-09-28 01:26:56,846 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.216,  Train_accy 30.75
2022-09-28 01:26:59,434 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.199,  Train_accy 31.02, Test_accy 65.15
2022-09-28 01:27:01,346 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.209,  Train_accy 31.02
2022-09-28 01:27:03,290 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.190,  Train_accy 31.28
2022-09-28 01:27:05,252 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.199,  Train_accy 31.82
2022-09-28 01:27:07,196 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.180,  Train_accy 31.82
2022-09-28 01:27:09,871 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.187,  Train_accy 31.15, Test_accy 65.56
2022-09-28 01:27:11,832 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.188,  Train_accy 33.56
2022-09-28 01:27:13,756 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.174,  Train_accy 33.82
2022-09-28 01:27:15,687 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.173,  Train_accy 33.16
2022-09-28 01:27:17,609 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.174,  Train_accy 33.02
2022-09-28 01:27:20,186 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.170,  Train_accy 32.62, Test_accy 66.80
2022-09-28 01:27:22,117 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.181,  Train_accy 33.82
2022-09-28 01:27:24,065 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.179,  Train_accy 33.42
2022-09-28 01:27:25,948 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.174,  Train_accy 32.89
2022-09-28 01:27:27,852 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.180,  Train_accy 34.63
2022-09-28 01:27:30,409 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.182,  Train_accy 32.75, Test_accy 67.22
2022-09-28 01:27:30,410 [foster.py] => do not weight align student!
2022-09-28 01:27:31,074 [foster.py] => darknet eval: 
2022-09-28 01:27:31,075 [foster.py] => CNN top1 curve: 67.22
2022-09-28 01:27:31,075 [foster.py] => CNN top5 curve: 98.34
2022-09-28 01:27:31,075 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 01:27:37,342 [foster.py] => Exemplar size: 200
2022-09-28 01:27:37,342 [trainer.py] => CNN: {'total': 76.76, 'old': 85.71, 'new': 58.75, 'base': 85.71, 'compound': 58.75}
2022-09-28 01:27:37,342 [trainer.py] => CNN top1 curve: [89.44, 76.76]
2022-09-28 01:27:37,342 [trainer.py] => CNN base curve: [89.44, 85.71]
2022-09-28 01:27:37,342 [trainer.py] => CNN old curve: [89.44, 85.71]
2022-09-28 01:27:37,342 [trainer.py] => CNN new curve: [0, 58.75]
2022-09-28 01:27:37,342 [trainer.py] => CNN compound curve: [0, 58.75]
2022-09-28 01:27:37,342 [trainer.py] => NME: {'total': 80.91, 'old': 83.85, 'new': 75.0, 'base': 83.85, 'compound': 75.0}
2022-09-28 01:27:37,342 [trainer.py] => NME top1 curve: [88.82, 80.91]
2022-09-28 01:27:37,342 [trainer.py] => NME base curve: [88.82, 83.85]
2022-09-28 01:27:37,342 [trainer.py] => NME old curve: [88.82, 83.85]
2022-09-28 01:27:37,342 [trainer.py] => NME new curve: [0, 75.0]
2022-09-28 01:27:37,342 [trainer.py] => NME compound curve: [0, 75.0]
2022-09-28 01:27:37,572 [foster.py] => Learning on 10-13
2022-09-28 01:27:37,573 [foster.py] => All params: 22378148
2022-09-28 01:27:37,573 [foster.py] => Trainable params: 11196506
2022-09-28 01:27:37,593 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 01:27:40,201 [foster.py] => Task 2, Epoch 1/34 => Loss 5.594, Loss_clf 2.514, Loss_fe 2.052, Loss_kd 0.791, Train_accy 38.91, Test_accy 49.34
2022-09-28 01:27:41,992 [foster.py] => Task 2, Epoch 2/34 => Loss 3.355, Loss_clf 0.931, Loss_fe 1.391, Loss_kd 0.795, Train_accy 51.52
2022-09-28 01:27:43,887 [foster.py] => Task 2, Epoch 3/34 => Loss 2.905, Loss_clf 0.713, Loss_fe 1.199, Loss_kd 0.764, Train_accy 34.67
2022-09-28 01:27:45,696 [foster.py] => Task 2, Epoch 4/34 => Loss 2.761, Loss_clf 0.678, Loss_fe 1.093, Loss_kd 0.762, Train_accy 37.45
2022-09-28 01:27:47,518 [foster.py] => Task 2, Epoch 5/34 => Loss 2.653, Loss_clf 0.645, Loss_fe 1.009, Loss_kd 0.769, Train_accy 39.76
2022-09-28 01:27:50,188 [foster.py] => Task 2, Epoch 6/34 => Loss 2.540, Loss_clf 0.596, Loss_fe 0.954, Loss_kd 0.761, Train_accy 39.64, Test_accy 58.55
2022-09-28 01:27:52,013 [foster.py] => Task 2, Epoch 7/34 => Loss 2.459, Loss_clf 0.571, Loss_fe 0.896, Loss_kd 0.763, Train_accy 38.91
2022-09-28 01:27:53,825 [foster.py] => Task 2, Epoch 8/34 => Loss 2.420, Loss_clf 0.572, Loss_fe 0.856, Loss_kd 0.763, Train_accy 37.33
2022-09-28 01:27:55,638 [foster.py] => Task 2, Epoch 9/34 => Loss 2.346, Loss_clf 0.549, Loss_fe 0.799, Loss_kd 0.768, Train_accy 40.48
2022-09-28 01:27:57,468 [foster.py] => Task 2, Epoch 10/34 => Loss 2.288, Loss_clf 0.528, Loss_fe 0.769, Loss_kd 0.762, Train_accy 40.12
2022-09-28 01:28:00,083 [foster.py] => Task 2, Epoch 11/34 => Loss 2.265, Loss_clf 0.523, Loss_fe 0.756, Loss_kd 0.759, Train_accy 39.64, Test_accy 61.51
2022-09-28 01:28:01,893 [foster.py] => Task 2, Epoch 12/34 => Loss 2.208, Loss_clf 0.505, Loss_fe 0.712, Loss_kd 0.762, Train_accy 41.94
2022-09-28 01:28:03,744 [foster.py] => Task 2, Epoch 13/34 => Loss 2.148, Loss_clf 0.481, Loss_fe 0.680, Loss_kd 0.759, Train_accy 41.58
2022-09-28 01:28:05,597 [foster.py] => Task 2, Epoch 14/34 => Loss 2.129, Loss_clf 0.479, Loss_fe 0.670, Loss_kd 0.754, Train_accy 41.33
2022-09-28 01:28:07,408 [foster.py] => Task 2, Epoch 15/34 => Loss 2.114, Loss_clf 0.463, Loss_fe 0.662, Loss_kd 0.761, Train_accy 40.36
2022-09-28 01:28:10,054 [foster.py] => Task 2, Epoch 16/34 => Loss 2.083, Loss_clf 0.455, Loss_fe 0.635, Loss_kd 0.764, Train_accy 42.06, Test_accy 61.18
2022-09-28 01:28:11,878 [foster.py] => Task 2, Epoch 17/34 => Loss 2.094, Loss_clf 0.468, Loss_fe 0.639, Loss_kd 0.759, Train_accy 42.18
2022-09-28 01:28:13,690 [foster.py] => Task 2, Epoch 18/34 => Loss 2.061, Loss_clf 0.453, Loss_fe 0.615, Loss_kd 0.763, Train_accy 42.67
2022-09-28 01:28:15,534 [foster.py] => Task 2, Epoch 19/34 => Loss 2.053, Loss_clf 0.457, Loss_fe 0.609, Loss_kd 0.759, Train_accy 42.79
2022-09-28 01:28:17,344 [foster.py] => Task 2, Epoch 20/34 => Loss 2.029, Loss_clf 0.447, Loss_fe 0.607, Loss_kd 0.750, Train_accy 44.97
2022-09-28 01:28:19,940 [foster.py] => Task 2, Epoch 21/34 => Loss 2.022, Loss_clf 0.436, Loss_fe 0.602, Loss_kd 0.757, Train_accy 44.12, Test_accy 62.50
2022-09-28 01:28:21,768 [foster.py] => Task 2, Epoch 22/34 => Loss 1.987, Loss_clf 0.416, Loss_fe 0.574, Loss_kd 0.767, Train_accy 43.88
2022-09-28 01:28:23,657 [foster.py] => Task 2, Epoch 23/34 => Loss 1.996, Loss_clf 0.424, Loss_fe 0.579, Loss_kd 0.764, Train_accy 43.52
2022-09-28 01:28:25,491 [foster.py] => Task 2, Epoch 24/34 => Loss 1.999, Loss_clf 0.425, Loss_fe 0.580, Loss_kd 0.765, Train_accy 42.91
2022-09-28 01:28:27,314 [foster.py] => Task 2, Epoch 25/34 => Loss 1.962, Loss_clf 0.418, Loss_fe 0.564, Loss_kd 0.754, Train_accy 44.12
2022-09-28 01:28:29,933 [foster.py] => Task 2, Epoch 26/34 => Loss 1.951, Loss_clf 0.411, Loss_fe 0.555, Loss_kd 0.758, Train_accy 42.55, Test_accy 62.50
2022-09-28 01:28:31,781 [foster.py] => Task 2, Epoch 27/34 => Loss 1.935, Loss_clf 0.407, Loss_fe 0.552, Loss_kd 0.750, Train_accy 42.06
2022-09-28 01:28:33,594 [foster.py] => Task 2, Epoch 28/34 => Loss 1.940, Loss_clf 0.408, Loss_fe 0.544, Loss_kd 0.760, Train_accy 42.79
2022-09-28 01:28:35,419 [foster.py] => Task 2, Epoch 29/34 => Loss 1.960, Loss_clf 0.405, Loss_fe 0.559, Loss_kd 0.766, Train_accy 43.88
2022-09-28 01:28:37,261 [foster.py] => Task 2, Epoch 30/34 => Loss 1.923, Loss_clf 0.402, Loss_fe 0.532, Loss_kd 0.761, Train_accy 43.15
2022-09-28 01:28:39,881 [foster.py] => Task 2, Epoch 31/34 => Loss 1.928, Loss_clf 0.397, Loss_fe 0.542, Loss_kd 0.761, Train_accy 44.36, Test_accy 62.50
2022-09-28 01:28:41,703 [foster.py] => Task 2, Epoch 32/34 => Loss 1.927, Loss_clf 0.394, Loss_fe 0.544, Loss_kd 0.761, Train_accy 43.52
2022-09-28 01:28:43,525 [foster.py] => Task 2, Epoch 33/34 => Loss 1.955, Loss_clf 0.408, Loss_fe 0.562, Loss_kd 0.758, Train_accy 44.00
2022-09-28 01:28:45,354 [foster.py] => Task 2, Epoch 34/34 => Loss 1.919, Loss_clf 0.392, Loss_fe 0.534, Loss_kd 0.764, Train_accy 44.97
2022-09-28 01:28:45,355 [foster.py] => do not weight align teacher!
2022-09-28 01:28:45,355 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 01:28:48,366 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.732,  Train_accy 16.97, Test_accy 48.03
2022-09-28 01:28:50,391 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.633,  Train_accy 18.55
2022-09-28 01:28:52,399 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.557,  Train_accy 19.03
2022-09-28 01:28:54,435 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.531,  Train_accy 18.55
2022-09-28 01:28:56,515 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.531,  Train_accy 18.18
2022-09-28 01:28:59,299 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.528,  Train_accy 19.15, Test_accy 52.63
2022-09-28 01:29:01,391 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.498,  Train_accy 18.67
2022-09-28 01:29:03,417 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.502,  Train_accy 19.15
2022-09-28 01:29:05,507 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.493,  Train_accy 19.52
2022-09-28 01:29:07,531 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.481,  Train_accy 20.00
2022-09-28 01:29:10,254 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.480,  Train_accy 20.36, Test_accy 52.63
2022-09-28 01:29:12,341 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.471,  Train_accy 19.64
2022-09-28 01:29:14,446 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.475,  Train_accy 20.73
2022-09-28 01:29:16,486 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.482,  Train_accy 20.48
2022-09-28 01:29:18,544 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.467,  Train_accy 19.88
2022-09-28 01:29:21,293 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.468,  Train_accy 20.48, Test_accy 53.29
2022-09-28 01:29:23,327 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.469,  Train_accy 20.36
2022-09-28 01:29:25,344 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.474,  Train_accy 19.39
2022-09-28 01:29:27,378 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.459,  Train_accy 20.48
2022-09-28 01:29:29,396 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.463,  Train_accy 20.85
2022-09-28 01:29:32,186 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.455,  Train_accy 19.88, Test_accy 54.28
2022-09-28 01:29:34,219 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.458,  Train_accy 20.85
2022-09-28 01:29:36,241 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.462,  Train_accy 20.85
2022-09-28 01:29:38,269 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.460,  Train_accy 20.61
2022-09-28 01:29:40,308 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.463,  Train_accy 20.36
2022-09-28 01:29:43,080 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.468,  Train_accy 20.48, Test_accy 53.62
2022-09-28 01:29:43,080 [foster.py] => do not weight align student!
2022-09-28 01:29:43,817 [foster.py] => darknet eval: 
2022-09-28 01:29:43,817 [foster.py] => CNN top1 curve: 53.62
2022-09-28 01:29:43,817 [foster.py] => CNN top5 curve: 97.04
2022-09-28 01:29:43,818 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 01:29:51,243 [foster.py] => Exemplar size: 260
2022-09-28 01:29:51,243 [trainer.py] => CNN: {'total': 62.5, 'old': 71.78, 'new': 26.98, 'base': 80.75, 'compound': 41.96}
2022-09-28 01:29:51,243 [trainer.py] => CNN top1 curve: [89.44, 76.76, 62.5]
2022-09-28 01:29:51,243 [trainer.py] => CNN base curve: [89.44, 85.71, 80.75]
2022-09-28 01:29:51,243 [trainer.py] => CNN old curve: [89.44, 85.71, 71.78]
2022-09-28 01:29:51,243 [trainer.py] => CNN new curve: [0, 58.75, 26.98]
2022-09-28 01:29:51,243 [trainer.py] => CNN compound curve: [0, 58.75, 41.96]
2022-09-28 01:29:51,243 [trainer.py] => NME: {'total': 71.05, 'old': 74.27, 'new': 58.73, 'base': 76.4, 'compound': 65.03}
2022-09-28 01:29:51,243 [trainer.py] => NME top1 curve: [88.82, 80.91, 71.05]
2022-09-28 01:29:51,243 [trainer.py] => NME base curve: [88.82, 83.85, 76.4]
2022-09-28 01:29:51,243 [trainer.py] => NME old curve: [88.82, 83.85, 74.27]
2022-09-28 01:29:51,243 [trainer.py] => NME new curve: [0, 75.0, 58.73]
2022-09-28 01:29:51,243 [trainer.py] => NME compound curve: [0, 75.0, 65.03]
2022-09-28 01:29:51,474 [foster.py] => Learning on 13-16
2022-09-28 01:29:51,474 [foster.py] => All params: 22384301
2022-09-28 01:29:51,474 [foster.py] => Trainable params: 11201120
2022-09-28 01:29:51,495 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 01:29:54,299 [foster.py] => Task 3, Epoch 1/34 => Loss 6.230, Loss_clf 2.264, Loss_fe 2.322, Loss_kd 1.336, Train_accy 40.16, Test_accy 42.86
2022-09-28 01:29:56,290 [foster.py] => Task 3, Epoch 2/34 => Loss 4.392, Loss_clf 1.102, Loss_fe 1.664, Loss_kd 1.322, Train_accy 40.94
2022-09-28 01:29:58,238 [foster.py] => Task 3, Epoch 3/34 => Loss 4.018, Loss_clf 0.921, Loss_fe 1.476, Loss_kd 1.317, Train_accy 40.83
2022-09-28 01:30:00,169 [foster.py] => Task 3, Epoch 4/34 => Loss 3.869, Loss_clf 0.901, Loss_fe 1.349, Loss_kd 1.316, Train_accy 41.17
2022-09-28 01:30:02,131 [foster.py] => Task 3, Epoch 5/34 => Loss 3.692, Loss_clf 0.836, Loss_fe 1.235, Loss_kd 1.318, Train_accy 38.02
2022-09-28 01:30:04,921 [foster.py] => Task 3, Epoch 6/34 => Loss 3.661, Loss_clf 0.836, Loss_fe 1.197, Loss_kd 1.323, Train_accy 39.60, Test_accy 52.20
2022-09-28 01:30:06,875 [foster.py] => Task 3, Epoch 7/34 => Loss 3.571, Loss_clf 0.823, Loss_fe 1.132, Loss_kd 1.314, Train_accy 41.39
2022-09-28 01:30:08,804 [foster.py] => Task 3, Epoch 8/34 => Loss 3.462, Loss_clf 0.783, Loss_fe 1.067, Loss_kd 1.310, Train_accy 40.38
2022-09-28 01:30:10,727 [foster.py] => Task 3, Epoch 9/34 => Loss 3.384, Loss_clf 0.751, Loss_fe 1.019, Loss_kd 1.312, Train_accy 40.27
2022-09-28 01:30:12,649 [foster.py] => Task 3, Epoch 10/34 => Loss 3.400, Loss_clf 0.774, Loss_fe 1.003, Loss_kd 1.319, Train_accy 43.08
2022-09-28 01:30:15,436 [foster.py] => Task 3, Epoch 11/34 => Loss 3.356, Loss_clf 0.760, Loss_fe 0.967, Loss_kd 1.324, Train_accy 39.48, Test_accy 52.47
2022-09-28 01:30:17,381 [foster.py] => Task 3, Epoch 12/34 => Loss 3.311, Loss_clf 0.750, Loss_fe 0.938, Loss_kd 1.319, Train_accy 42.07
2022-09-28 01:30:19,336 [foster.py] => Task 3, Epoch 13/34 => Loss 3.297, Loss_clf 0.738, Loss_fe 0.925, Loss_kd 1.328, Train_accy 39.48
2022-09-28 01:30:21,275 [foster.py] => Task 3, Epoch 14/34 => Loss 3.227, Loss_clf 0.721, Loss_fe 0.888, Loss_kd 1.315, Train_accy 40.94
2022-09-28 01:30:23,227 [foster.py] => Task 3, Epoch 15/34 => Loss 3.195, Loss_clf 0.695, Loss_fe 0.876, Loss_kd 1.319, Train_accy 41.84
2022-09-28 01:30:26,010 [foster.py] => Task 3, Epoch 16/34 => Loss 3.187, Loss_clf 0.696, Loss_fe 0.867, Loss_kd 1.320, Train_accy 40.72, Test_accy 53.85
2022-09-28 01:30:27,905 [foster.py] => Task 3, Epoch 17/34 => Loss 3.112, Loss_clf 0.671, Loss_fe 0.821, Loss_kd 1.316, Train_accy 42.52
2022-09-28 01:30:29,863 [foster.py] => Task 3, Epoch 18/34 => Loss 3.105, Loss_clf 0.662, Loss_fe 0.810, Loss_kd 1.327, Train_accy 41.84
2022-09-28 01:30:31,788 [foster.py] => Task 3, Epoch 19/34 => Loss 3.090, Loss_clf 0.664, Loss_fe 0.803, Loss_kd 1.319, Train_accy 44.09
2022-09-28 01:30:33,693 [foster.py] => Task 3, Epoch 20/34 => Loss 3.081, Loss_clf 0.657, Loss_fe 0.803, Loss_kd 1.317, Train_accy 42.63
2022-09-28 01:30:36,520 [foster.py] => Task 3, Epoch 21/34 => Loss 3.059, Loss_clf 0.640, Loss_fe 0.782, Loss_kd 1.330, Train_accy 44.32, Test_accy 54.12
2022-09-28 01:30:38,489 [foster.py] => Task 3, Epoch 22/34 => Loss 3.075, Loss_clf 0.659, Loss_fe 0.790, Loss_kd 1.322, Train_accy 42.86
2022-09-28 01:30:40,431 [foster.py] => Task 3, Epoch 23/34 => Loss 3.064, Loss_clf 0.653, Loss_fe 0.784, Loss_kd 1.323, Train_accy 42.86
2022-09-28 01:30:42,379 [foster.py] => Task 3, Epoch 24/34 => Loss 3.033, Loss_clf 0.636, Loss_fe 0.769, Loss_kd 1.322, Train_accy 43.64
2022-09-28 01:30:44,334 [foster.py] => Task 3, Epoch 25/34 => Loss 3.037, Loss_clf 0.641, Loss_fe 0.760, Loss_kd 1.330, Train_accy 44.88
2022-09-28 01:30:47,117 [foster.py] => Task 3, Epoch 26/34 => Loss 3.041, Loss_clf 0.641, Loss_fe 0.770, Loss_kd 1.324, Train_accy 43.64, Test_accy 54.12
2022-09-28 01:30:49,063 [foster.py] => Task 3, Epoch 27/34 => Loss 3.018, Loss_clf 0.629, Loss_fe 0.757, Loss_kd 1.326, Train_accy 44.54
2022-09-28 01:30:50,998 [foster.py] => Task 3, Epoch 28/34 => Loss 3.012, Loss_clf 0.625, Loss_fe 0.757, Loss_kd 1.325, Train_accy 43.19
2022-09-28 01:30:52,928 [foster.py] => Task 3, Epoch 29/34 => Loss 3.002, Loss_clf 0.630, Loss_fe 0.742, Loss_kd 1.325, Train_accy 44.43
2022-09-28 01:30:54,855 [foster.py] => Task 3, Epoch 30/34 => Loss 3.027, Loss_clf 0.631, Loss_fe 0.754, Loss_kd 1.333, Train_accy 44.77
2022-09-28 01:30:57,623 [foster.py] => Task 3, Epoch 31/34 => Loss 2.991, Loss_clf 0.617, Loss_fe 0.746, Loss_kd 1.322, Train_accy 43.76, Test_accy 54.12
2022-09-28 01:30:59,514 [foster.py] => Task 3, Epoch 32/34 => Loss 3.035, Loss_clf 0.643, Loss_fe 0.761, Loss_kd 1.325, Train_accy 45.11
2022-09-28 01:31:01,469 [foster.py] => Task 3, Epoch 33/34 => Loss 2.979, Loss_clf 0.614, Loss_fe 0.737, Loss_kd 1.323, Train_accy 44.88
2022-09-28 01:31:03,388 [foster.py] => Task 3, Epoch 34/34 => Loss 3.024, Loss_clf 0.633, Loss_fe 0.753, Loss_kd 1.331, Train_accy 44.88
2022-09-28 01:31:03,389 [foster.py] => do not weight align teacher!
2022-09-28 01:31:03,389 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 01:31:06,564 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.087,  Train_accy 17.55, Test_accy 45.88
2022-09-28 01:31:08,698 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.028,  Train_accy 18.00
2022-09-28 01:31:10,867 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.004,  Train_accy 18.00
2022-09-28 01:31:13,007 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 1.985,  Train_accy 18.90
2022-09-28 01:31:15,188 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.976,  Train_accy 19.01
2022-09-28 01:31:18,115 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.963,  Train_accy 19.57, Test_accy 48.35
2022-09-28 01:31:20,299 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.966,  Train_accy 19.35
2022-09-28 01:31:22,511 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.972,  Train_accy 19.69
2022-09-28 01:31:24,670 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.960,  Train_accy 19.46
2022-09-28 01:31:26,870 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.958,  Train_accy 19.35
2022-09-28 01:31:29,796 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.943,  Train_accy 19.12, Test_accy 48.90
2022-09-28 01:31:31,949 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.948,  Train_accy 19.80
2022-09-28 01:31:34,098 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.942,  Train_accy 19.35
2022-09-28 01:31:36,307 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.937,  Train_accy 19.46
2022-09-28 01:31:38,489 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.947,  Train_accy 19.24
2022-09-28 01:31:41,429 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.945,  Train_accy 19.80, Test_accy 49.18
2022-09-28 01:31:43,621 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.946,  Train_accy 19.80
2022-09-28 01:31:45,788 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.949,  Train_accy 19.35
2022-09-28 01:31:47,965 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.937,  Train_accy 19.91
2022-09-28 01:31:50,128 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.935,  Train_accy 19.91
2022-09-28 01:31:53,089 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.944,  Train_accy 19.80, Test_accy 49.45
2022-09-28 01:31:55,283 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.935,  Train_accy 20.25
2022-09-28 01:31:57,473 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.937,  Train_accy 19.80
2022-09-28 01:31:59,625 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.937,  Train_accy 19.80
2022-09-28 01:32:01,785 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.933,  Train_accy 19.35
2022-09-28 01:32:04,703 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.942,  Train_accy 19.69, Test_accy 50.27
2022-09-28 01:32:04,704 [foster.py] => do not weight align student!
2022-09-28 01:32:05,451 [foster.py] => darknet eval: 
2022-09-28 01:32:05,451 [foster.py] => CNN top1 curve: 50.27
2022-09-28 01:32:05,451 [foster.py] => CNN top5 curve: 92.58
2022-09-28 01:32:05,452 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 01:32:13,901 [foster.py] => Exemplar size: 320
2022-09-28 01:32:13,901 [trainer.py] => CNN: {'total': 54.12, 'old': 59.54, 'new': 26.67, 'base': 79.5, 'compound': 33.99}
2022-09-28 01:32:13,901 [trainer.py] => CNN top1 curve: [89.44, 76.76, 62.5, 54.12]
2022-09-28 01:32:13,901 [trainer.py] => CNN base curve: [89.44, 85.71, 80.75, 79.5]
2022-09-28 01:32:13,901 [trainer.py] => CNN old curve: [89.44, 85.71, 71.78, 59.54]
2022-09-28 01:32:13,901 [trainer.py] => CNN new curve: [0, 58.75, 26.98, 26.67]
2022-09-28 01:32:13,901 [trainer.py] => CNN compound curve: [0, 58.75, 41.96, 33.99]
2022-09-28 01:32:13,901 [trainer.py] => NME: {'total': 63.46, 'old': 64.14, 'new': 60.0, 'base': 72.67, 'compound': 56.16}
2022-09-28 01:32:13,901 [trainer.py] => NME top1 curve: [88.82, 80.91, 71.05, 63.46]
2022-09-28 01:32:13,901 [trainer.py] => NME base curve: [88.82, 83.85, 76.4, 72.67]
2022-09-28 01:32:13,901 [trainer.py] => NME old curve: [88.82, 83.85, 74.27, 64.14]
2022-09-28 01:32:13,901 [trainer.py] => NME new curve: [0, 75.0, 58.73, 60.0]
2022-09-28 01:32:13,901 [trainer.py] => NME compound curve: [0, 75.0, 65.03, 56.16]
2022-09-28 01:32:14,129 [foster.py] => Learning on 16-19
2022-09-28 01:32:14,130 [foster.py] => All params: 22390454
2022-09-28 01:32:14,130 [foster.py] => Trainable params: 11205734
2022-09-28 01:32:14,150 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 01:32:17,126 [foster.py] => Task 4, Epoch 1/34 => Loss 6.218, Loss_clf 1.945, Loss_fe 2.333, Loss_kd 1.634, Train_accy 40.13, Test_accy 47.93
2022-09-28 01:32:19,141 [foster.py] => Task 4, Epoch 2/34 => Loss 4.592, Loss_clf 0.956, Loss_fe 1.672, Loss_kd 1.654, Train_accy 43.22
2022-09-28 01:32:21,130 [foster.py] => Task 4, Epoch 3/34 => Loss 4.323, Loss_clf 0.899, Loss_fe 1.476, Loss_kd 1.640, Train_accy 46.74
2022-09-28 01:32:23,142 [foster.py] => Task 4, Epoch 4/34 => Loss 4.170, Loss_clf 0.860, Loss_fe 1.367, Loss_kd 1.636, Train_accy 44.93
2022-09-28 01:32:25,145 [foster.py] => Task 4, Epoch 5/34 => Loss 4.018, Loss_clf 0.820, Loss_fe 1.255, Loss_kd 1.637, Train_accy 46.21
2022-09-28 01:32:28,049 [foster.py] => Task 4, Epoch 6/34 => Loss 3.921, Loss_clf 0.799, Loss_fe 1.175, Loss_kd 1.639, Train_accy 48.03, Test_accy 51.38
2022-09-28 01:32:30,056 [foster.py] => Task 4, Epoch 7/34 => Loss 3.856, Loss_clf 0.783, Loss_fe 1.128, Loss_kd 1.638, Train_accy 46.42
2022-09-28 01:32:32,091 [foster.py] => Task 4, Epoch 8/34 => Loss 3.798, Loss_clf 0.770, Loss_fe 1.080, Loss_kd 1.640, Train_accy 48.03
2022-09-28 01:32:34,103 [foster.py] => Task 4, Epoch 9/34 => Loss 3.730, Loss_clf 0.743, Loss_fe 1.037, Loss_kd 1.642, Train_accy 47.07
2022-09-28 01:32:36,090 [foster.py] => Task 4, Epoch 10/34 => Loss 3.692, Loss_clf 0.750, Loss_fe 0.990, Loss_kd 1.644, Train_accy 48.88
2022-09-28 01:32:39,020 [foster.py] => Task 4, Epoch 11/34 => Loss 3.657, Loss_clf 0.739, Loss_fe 0.962, Loss_kd 1.646, Train_accy 47.28, Test_accy 51.61
2022-09-28 01:32:41,020 [foster.py] => Task 4, Epoch 12/34 => Loss 3.651, Loss_clf 0.750, Loss_fe 0.945, Loss_kd 1.647, Train_accy 50.05
2022-09-28 01:32:43,036 [foster.py] => Task 4, Epoch 13/34 => Loss 3.596, Loss_clf 0.728, Loss_fe 0.922, Loss_kd 1.639, Train_accy 49.31
2022-09-28 01:32:45,033 [foster.py] => Task 4, Epoch 14/34 => Loss 3.539, Loss_clf 0.700, Loss_fe 0.882, Loss_kd 1.647, Train_accy 48.45
2022-09-28 01:32:47,064 [foster.py] => Task 4, Epoch 15/34 => Loss 3.530, Loss_clf 0.706, Loss_fe 0.864, Loss_kd 1.651, Train_accy 51.33
2022-09-28 01:32:50,016 [foster.py] => Task 4, Epoch 16/34 => Loss 3.485, Loss_clf 0.691, Loss_fe 0.851, Loss_kd 1.636, Train_accy 49.31, Test_accy 52.07
2022-09-28 01:32:52,012 [foster.py] => Task 4, Epoch 17/34 => Loss 3.454, Loss_clf 0.677, Loss_fe 0.841, Loss_kd 1.630, Train_accy 49.84
2022-09-28 01:32:53,996 [foster.py] => Task 4, Epoch 18/34 => Loss 3.447, Loss_clf 0.666, Loss_fe 0.821, Loss_kd 1.651, Train_accy 51.23
2022-09-28 01:32:56,019 [foster.py] => Task 4, Epoch 19/34 => Loss 3.404, Loss_clf 0.654, Loss_fe 0.802, Loss_kd 1.640, Train_accy 49.09
2022-09-28 01:32:58,030 [foster.py] => Task 4, Epoch 20/34 => Loss 3.423, Loss_clf 0.654, Loss_fe 0.800, Loss_kd 1.658, Train_accy 51.97
2022-09-28 01:33:00,956 [foster.py] => Task 4, Epoch 21/34 => Loss 3.404, Loss_clf 0.658, Loss_fe 0.784, Loss_kd 1.653, Train_accy 51.44, Test_accy 53.00
2022-09-28 01:33:02,934 [foster.py] => Task 4, Epoch 22/34 => Loss 3.376, Loss_clf 0.646, Loss_fe 0.773, Loss_kd 1.648, Train_accy 49.31
2022-09-28 01:33:04,971 [foster.py] => Task 4, Epoch 23/34 => Loss 3.387, Loss_clf 0.655, Loss_fe 0.780, Loss_kd 1.644, Train_accy 49.73
2022-09-28 01:33:06,998 [foster.py] => Task 4, Epoch 24/34 => Loss 3.378, Loss_clf 0.647, Loss_fe 0.772, Loss_kd 1.649, Train_accy 50.48
2022-09-28 01:33:08,984 [foster.py] => Task 4, Epoch 25/34 => Loss 3.383, Loss_clf 0.658, Loss_fe 0.774, Loss_kd 1.643, Train_accy 49.73
2022-09-28 01:33:11,957 [foster.py] => Task 4, Epoch 26/34 => Loss 3.371, Loss_clf 0.648, Loss_fe 0.767, Loss_kd 1.647, Train_accy 50.69, Test_accy 52.76
2022-09-28 01:33:13,926 [foster.py] => Task 4, Epoch 27/34 => Loss 3.316, Loss_clf 0.628, Loss_fe 0.743, Loss_kd 1.638, Train_accy 52.19
2022-09-28 01:33:15,989 [foster.py] => Task 4, Epoch 28/34 => Loss 3.364, Loss_clf 0.655, Loss_fe 0.758, Loss_kd 1.643, Train_accy 52.08
2022-09-28 01:33:18,025 [foster.py] => Task 4, Epoch 29/34 => Loss 3.327, Loss_clf 0.620, Loss_fe 0.751, Loss_kd 1.647, Train_accy 52.93
2022-09-28 01:33:20,053 [foster.py] => Task 4, Epoch 30/34 => Loss 3.341, Loss_clf 0.638, Loss_fe 0.750, Loss_kd 1.645, Train_accy 52.29
2022-09-28 01:33:23,037 [foster.py] => Task 4, Epoch 31/34 => Loss 3.356, Loss_clf 0.642, Loss_fe 0.761, Loss_kd 1.644, Train_accy 50.59, Test_accy 52.76
2022-09-28 01:33:25,030 [foster.py] => Task 4, Epoch 32/34 => Loss 3.365, Loss_clf 0.651, Loss_fe 0.760, Loss_kd 1.645, Train_accy 50.37
2022-09-28 01:33:27,038 [foster.py] => Task 4, Epoch 33/34 => Loss 3.380, Loss_clf 0.655, Loss_fe 0.770, Loss_kd 1.646, Train_accy 51.44
2022-09-28 01:33:29,067 [foster.py] => Task 4, Epoch 34/34 => Loss 3.355, Loss_clf 0.640, Loss_fe 0.762, Loss_kd 1.644, Train_accy 51.65
2022-09-28 01:33:29,067 [foster.py] => do not weight align teacher!
2022-09-28 01:33:29,068 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 01:33:32,336 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.299,  Train_accy 18.68, Test_accy 40.55
2022-09-28 01:33:34,587 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.251,  Train_accy 18.89
2022-09-28 01:33:36,852 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.217,  Train_accy 19.00
2022-09-28 01:33:39,141 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.219,  Train_accy 19.10
2022-09-28 01:33:41,377 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.204,  Train_accy 19.42
2022-09-28 01:33:44,478 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.194,  Train_accy 20.38, Test_accy 43.32
2022-09-28 01:33:46,751 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.195,  Train_accy 21.24
2022-09-28 01:33:49,021 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.192,  Train_accy 21.66
2022-09-28 01:33:51,363 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.184,  Train_accy 20.92
2022-09-28 01:33:53,634 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.179,  Train_accy 22.20
2022-09-28 01:33:56,697 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.191,  Train_accy 23.16, Test_accy 43.09
2022-09-28 01:33:58,957 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.162,  Train_accy 23.27
2022-09-28 01:34:01,203 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.169,  Train_accy 22.31
2022-09-28 01:34:03,433 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.177,  Train_accy 22.31
2022-09-28 01:34:05,710 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.167,  Train_accy 24.44
2022-09-28 01:34:08,838 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.172,  Train_accy 23.59, Test_accy 44.93
2022-09-28 01:34:11,067 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.165,  Train_accy 24.01
2022-09-28 01:34:13,288 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.155,  Train_accy 24.33
2022-09-28 01:34:15,522 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.162,  Train_accy 23.80
2022-09-28 01:34:17,794 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.170,  Train_accy 24.55
2022-09-28 01:34:20,870 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.153,  Train_accy 23.80, Test_accy 44.01
2022-09-28 01:34:23,124 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.170,  Train_accy 24.33
2022-09-28 01:34:25,376 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.162,  Train_accy 25.19
2022-09-28 01:34:27,648 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.157,  Train_accy 24.97
2022-09-28 01:34:29,884 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.162,  Train_accy 24.76
2022-09-28 01:34:32,919 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.166,  Train_accy 23.91, Test_accy 44.93
2022-09-28 01:34:32,920 [foster.py] => do not weight align student!
2022-09-28 01:34:33,721 [foster.py] => darknet eval: 
2022-09-28 01:34:33,721 [foster.py] => CNN top1 curve: 44.93
2022-09-28 01:34:33,721 [foster.py] => CNN top5 curve: 85.71
2022-09-28 01:34:33,721 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 01:34:43,234 [foster.py] => Exemplar size: 380
2022-09-28 01:34:43,234 [trainer.py] => CNN: {'total': 52.76, 'old': 54.95, 'new': 41.43, 'base': 77.02, 'compound': 38.46}
2022-09-28 01:34:43,234 [trainer.py] => CNN top1 curve: [89.44, 76.76, 62.5, 54.12, 52.76]
2022-09-28 01:34:43,234 [trainer.py] => CNN base curve: [89.44, 85.71, 80.75, 79.5, 77.02]
2022-09-28 01:34:43,234 [trainer.py] => CNN old curve: [89.44, 85.71, 71.78, 59.54, 54.95]
2022-09-28 01:34:43,234 [trainer.py] => CNN new curve: [0, 58.75, 26.98, 26.67, 41.43]
2022-09-28 01:34:43,234 [trainer.py] => CNN compound curve: [0, 58.75, 41.96, 33.99, 38.46]
2022-09-28 01:34:43,234 [trainer.py] => NME: {'total': 60.6, 'old': 60.44, 'new': 61.43, 'base': 70.19, 'compound': 54.95}
2022-09-28 01:34:43,234 [trainer.py] => NME top1 curve: [88.82, 80.91, 71.05, 63.46, 60.6]
2022-09-28 01:34:43,234 [trainer.py] => NME base curve: [88.82, 83.85, 76.4, 72.67, 70.19]
2022-09-28 01:34:43,234 [trainer.py] => NME old curve: [88.82, 83.85, 74.27, 64.14, 60.44]
2022-09-28 01:34:43,234 [trainer.py] => NME new curve: [0, 75.0, 58.73, 60.0, 61.43]
2022-09-28 01:34:43,235 [trainer.py] => NME compound curve: [0, 75.0, 65.03, 56.16, 54.95]
2022-09-28 01:34:43,461 [foster.py] => Learning on 19-22
2022-09-28 01:34:43,461 [foster.py] => All params: 22396607
2022-09-28 01:34:43,462 [foster.py] => Trainable params: 11210348
2022-09-28 01:34:43,482 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 01:34:46,544 [foster.py] => Task 5, Epoch 1/34 => Loss 6.891, Loss_clf 1.993, Loss_fe 2.706, Loss_kd 1.893, Train_accy 36.71, Test_accy 43.65
2022-09-28 01:34:48,635 [foster.py] => Task 5, Epoch 2/34 => Loss 5.281, Loss_clf 1.159, Loss_fe 1.916, Loss_kd 1.905, Train_accy 33.60
2022-09-28 01:34:50,797 [foster.py] => Task 5, Epoch 3/34 => Loss 4.958, Loss_clf 1.076, Loss_fe 1.693, Loss_kd 1.891, Train_accy 34.90
2022-09-28 01:34:52,893 [foster.py] => Task 5, Epoch 4/34 => Loss 4.750, Loss_clf 1.017, Loss_fe 1.551, Loss_kd 1.885, Train_accy 35.91
2022-09-28 01:34:55,018 [foster.py] => Task 5, Epoch 5/34 => Loss 4.651, Loss_clf 0.991, Loss_fe 1.484, Loss_kd 1.879, Train_accy 38.01
2022-09-28 01:34:58,124 [foster.py] => Task 5, Epoch 6/34 => Loss 4.597, Loss_clf 1.002, Loss_fe 1.413, Loss_kd 1.884, Train_accy 37.91, Test_accy 47.42
2022-09-28 01:35:00,203 [foster.py] => Task 5, Epoch 7/34 => Loss 4.427, Loss_clf 0.937, Loss_fe 1.307, Loss_kd 1.885, Train_accy 39.32
2022-09-28 01:35:02,277 [foster.py] => Task 5, Epoch 8/34 => Loss 4.404, Loss_clf 0.926, Loss_fe 1.286, Loss_kd 1.892, Train_accy 40.22
2022-09-28 01:35:04,344 [foster.py] => Task 5, Epoch 9/34 => Loss 4.298, Loss_clf 0.895, Loss_fe 1.220, Loss_kd 1.886, Train_accy 40.72
2022-09-28 01:35:06,457 [foster.py] => Task 5, Epoch 10/34 => Loss 4.310, Loss_clf 0.904, Loss_fe 1.214, Loss_kd 1.893, Train_accy 41.12
2022-09-28 01:35:09,528 [foster.py] => Task 5, Epoch 11/34 => Loss 4.206, Loss_clf 0.886, Loss_fe 1.133, Loss_kd 1.889, Train_accy 41.22, Test_accy 48.41
2022-09-28 01:35:11,623 [foster.py] => Task 5, Epoch 12/34 => Loss 4.155, Loss_clf 0.852, Loss_fe 1.103, Loss_kd 1.900, Train_accy 42.03
2022-09-28 01:35:13,748 [foster.py] => Task 5, Epoch 13/34 => Loss 4.163, Loss_clf 0.855, Loss_fe 1.121, Loss_kd 1.888, Train_accy 39.82
2022-09-28 01:35:15,842 [foster.py] => Task 5, Epoch 14/34 => Loss 4.161, Loss_clf 0.893, Loss_fe 1.084, Loss_kd 1.887, Train_accy 43.23
2022-09-28 01:35:17,950 [foster.py] => Task 5, Epoch 15/34 => Loss 4.119, Loss_clf 0.847, Loss_fe 1.059, Loss_kd 1.911, Train_accy 43.73
2022-09-28 01:35:21,040 [foster.py] => Task 5, Epoch 16/34 => Loss 4.058, Loss_clf 0.822, Loss_fe 1.031, Loss_kd 1.905, Train_accy 43.73, Test_accy 50.00
2022-09-28 01:35:23,146 [foster.py] => Task 5, Epoch 17/34 => Loss 4.023, Loss_clf 0.834, Loss_fe 1.000, Loss_kd 1.891, Train_accy 43.13
2022-09-28 01:35:25,213 [foster.py] => Task 5, Epoch 18/34 => Loss 3.958, Loss_clf 0.793, Loss_fe 0.971, Loss_kd 1.894, Train_accy 42.53
2022-09-28 01:35:27,299 [foster.py] => Task 5, Epoch 19/34 => Loss 3.954, Loss_clf 0.802, Loss_fe 0.959, Loss_kd 1.894, Train_accy 43.13
2022-09-28 01:35:29,448 [foster.py] => Task 5, Epoch 20/34 => Loss 3.988, Loss_clf 0.808, Loss_fe 0.967, Loss_kd 1.911, Train_accy 42.53
2022-09-28 01:35:32,487 [foster.py] => Task 5, Epoch 21/34 => Loss 3.948, Loss_clf 0.792, Loss_fe 0.952, Loss_kd 1.904, Train_accy 43.93, Test_accy 50.20
2022-09-28 01:35:34,590 [foster.py] => Task 5, Epoch 22/34 => Loss 3.911, Loss_clf 0.778, Loss_fe 0.934, Loss_kd 1.899, Train_accy 45.14
2022-09-28 01:35:36,717 [foster.py] => Task 5, Epoch 23/34 => Loss 3.905, Loss_clf 0.783, Loss_fe 0.919, Loss_kd 1.902, Train_accy 43.63
2022-09-28 01:35:38,842 [foster.py] => Task 5, Epoch 24/34 => Loss 3.887, Loss_clf 0.772, Loss_fe 0.908, Loss_kd 1.907, Train_accy 45.74
2022-09-28 01:35:40,943 [foster.py] => Task 5, Epoch 25/34 => Loss 3.894, Loss_clf 0.770, Loss_fe 0.923, Loss_kd 1.901, Train_accy 43.63
2022-09-28 01:35:44,075 [foster.py] => Task 5, Epoch 26/34 => Loss 3.892, Loss_clf 0.776, Loss_fe 0.918, Loss_kd 1.898, Train_accy 42.73, Test_accy 50.99
2022-09-28 01:35:46,187 [foster.py] => Task 5, Epoch 27/34 => Loss 3.866, Loss_clf 0.762, Loss_fe 0.906, Loss_kd 1.898, Train_accy 43.93
2022-09-28 01:35:48,282 [foster.py] => Task 5, Epoch 28/34 => Loss 3.833, Loss_clf 0.745, Loss_fe 0.885, Loss_kd 1.903, Train_accy 45.74
2022-09-28 01:35:50,382 [foster.py] => Task 5, Epoch 29/34 => Loss 3.846, Loss_clf 0.749, Loss_fe 0.898, Loss_kd 1.899, Train_accy 45.74
2022-09-28 01:35:52,540 [foster.py] => Task 5, Epoch 30/34 => Loss 3.832, Loss_clf 0.747, Loss_fe 0.894, Loss_kd 1.893, Train_accy 45.04
2022-09-28 01:35:55,663 [foster.py] => Task 5, Epoch 31/34 => Loss 3.840, Loss_clf 0.743, Loss_fe 0.885, Loss_kd 1.911, Train_accy 44.93, Test_accy 50.79
2022-09-28 01:35:57,757 [foster.py] => Task 5, Epoch 32/34 => Loss 3.827, Loss_clf 0.745, Loss_fe 0.882, Loss_kd 1.900, Train_accy 44.83
2022-09-28 01:35:59,877 [foster.py] => Task 5, Epoch 33/34 => Loss 3.859, Loss_clf 0.754, Loss_fe 0.897, Loss_kd 1.907, Train_accy 44.63
2022-09-28 01:36:02,014 [foster.py] => Task 5, Epoch 34/34 => Loss 3.836, Loss_clf 0.743, Loss_fe 0.888, Loss_kd 1.905, Train_accy 46.84
2022-09-28 01:36:02,015 [foster.py] => do not weight align teacher!
2022-09-28 01:36:02,015 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 01:36:05,504 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.408,  Train_accy 19.16, Test_accy 39.48
2022-09-28 01:36:07,838 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.404,  Train_accy 18.66
2022-09-28 01:36:10,203 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.395,  Train_accy 19.76
2022-09-28 01:36:12,552 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.386,  Train_accy 19.86
2022-09-28 01:36:14,920 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.370,  Train_accy 20.16
2022-09-28 01:36:18,149 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.381,  Train_accy 20.06, Test_accy 41.87
2022-09-28 01:36:20,499 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.383,  Train_accy 20.36
2022-09-28 01:36:22,901 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.367,  Train_accy 21.16
2022-09-28 01:36:25,295 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.369,  Train_accy 20.16
2022-09-28 01:36:27,632 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.360,  Train_accy 20.66
2022-09-28 01:36:30,836 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.371,  Train_accy 20.06, Test_accy 41.47
2022-09-28 01:36:33,209 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.357,  Train_accy 20.76
2022-09-28 01:36:35,589 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.359,  Train_accy 20.96
2022-09-28 01:36:37,916 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.345,  Train_accy 21.26
2022-09-28 01:36:40,265 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.357,  Train_accy 20.86
2022-09-28 01:36:43,518 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.346,  Train_accy 21.46, Test_accy 42.66
2022-09-28 01:36:45,909 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.360,  Train_accy 19.96
2022-09-28 01:36:48,285 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.356,  Train_accy 20.16
2022-09-28 01:36:50,636 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.343,  Train_accy 21.36
2022-09-28 01:36:53,019 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.337,  Train_accy 21.16
2022-09-28 01:36:56,231 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.339,  Train_accy 19.76, Test_accy 43.06
2022-09-28 01:36:58,626 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.348,  Train_accy 20.26
2022-09-28 01:37:00,993 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.366,  Train_accy 20.66
2022-09-28 01:37:03,335 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.344,  Train_accy 20.76
2022-09-28 01:37:05,671 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.342,  Train_accy 20.76
2022-09-28 01:37:08,927 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.343,  Train_accy 21.26, Test_accy 41.47
2022-09-28 01:37:08,927 [foster.py] => do not weight align student!
2022-09-28 01:37:09,813 [foster.py] => darknet eval: 
2022-09-28 01:37:09,813 [foster.py] => CNN top1 curve: 41.47
2022-09-28 01:37:09,813 [foster.py] => CNN top5 curve: 81.35
2022-09-28 01:37:09,814 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 01:37:20,481 [foster.py] => Exemplar size: 440
2022-09-28 01:37:20,481 [trainer.py] => CNN: {'total': 50.2, 'old': 53.46, 'new': 30.0, 'base': 75.16, 'compound': 38.48}
2022-09-28 01:37:20,481 [trainer.py] => CNN top1 curve: [89.44, 76.76, 62.5, 54.12, 52.76, 50.2]
2022-09-28 01:37:20,481 [trainer.py] => CNN base curve: [89.44, 85.71, 80.75, 79.5, 77.02, 75.16]
2022-09-28 01:37:20,481 [trainer.py] => CNN old curve: [89.44, 85.71, 71.78, 59.54, 54.95, 53.46]
2022-09-28 01:37:20,481 [trainer.py] => CNN new curve: [0, 58.75, 26.98, 26.67, 41.43, 30.0]
2022-09-28 01:37:20,481 [trainer.py] => CNN compound curve: [0, 58.75, 41.96, 33.99, 38.46, 38.48]
2022-09-28 01:37:20,481 [trainer.py] => NME: {'total': 56.35, 'old': 58.53, 'new': 42.86, 'base': 69.57, 'compound': 50.15}
2022-09-28 01:37:20,481 [trainer.py] => NME top1 curve: [88.82, 80.91, 71.05, 63.46, 60.6, 56.35]
2022-09-28 01:37:20,481 [trainer.py] => NME base curve: [88.82, 83.85, 76.4, 72.67, 70.19, 69.57]
2022-09-28 01:37:20,481 [trainer.py] => NME old curve: [88.82, 83.85, 74.27, 64.14, 60.44, 58.53]
2022-09-28 01:37:20,481 [trainer.py] => NME new curve: [0, 75.0, 58.73, 60.0, 61.43, 42.86]
2022-09-28 01:37:20,481 [trainer.py] => NME compound curve: [0, 75.0, 65.03, 56.16, 54.95, 50.15]
2022-09-28 01:37:20,483 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 01:37:20,483 [trainer.py] => prefix: cil
2022-09-28 01:37:20,483 [trainer.py] => dataset: CFEE
2022-09-28 01:37:20,483 [trainer.py] => memory_size: 2000
2022-09-28 01:37:20,483 [trainer.py] => memory_per_class: 20
2022-09-28 01:37:20,483 [trainer.py] => fixed_memory: True
2022-09-28 01:37:20,483 [trainer.py] => shuffle: True
2022-09-28 01:37:20,483 [trainer.py] => init_cls: 7
2022-09-28 01:37:20,483 [trainer.py] => increment: 3
2022-09-28 01:37:20,483 [trainer.py] => model_name: foster
2022-09-28 01:37:20,483 [trainer.py] => convnet_type: resnet18
2022-09-28 01:37:20,483 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 01:37:20,483 [trainer.py] => seed: 1993
2022-09-28 01:37:20,483 [trainer.py] => beta1: 0.96
2022-09-28 01:37:20,483 [trainer.py] => beta2: 0.97
2022-09-28 01:37:20,483 [trainer.py] => oofc: ft
2022-09-28 01:37:20,483 [trainer.py] => is_teacher_wa: False
2022-09-28 01:37:20,483 [trainer.py] => is_student_wa: False
2022-09-28 01:37:20,483 [trainer.py] => lambda_okd: 1
2022-09-28 01:37:20,483 [trainer.py] => wa_value: 1
2022-09-28 01:37:20,483 [trainer.py] => init_epochs: 40
2022-09-28 01:37:20,483 [trainer.py] => init_lr: 0.01
2022-09-28 01:37:20,483 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 01:37:20,483 [trainer.py] => boosting_epochs: 34
2022-09-28 01:37:20,483 [trainer.py] => compression_epochs: 26
2022-09-28 01:37:20,483 [trainer.py] => lr: 0.001
2022-09-28 01:37:20,483 [trainer.py] => batch_size: 32
2022-09-28 01:37:20,483 [trainer.py] => weight_decay: 0.0005
2022-09-28 01:37:20,483 [trainer.py] => num_workers: 8
2022-09-28 01:37:20,483 [trainer.py] => T: 2
2022-09-28 01:37:20,483 [trainer.py] => nb_runs: 3
2022-09-28 01:37:20,484 [trainer.py] => fold: 10
2022-09-28 01:37:20,484 [data.py] => ========== Fold:7 ==========
2022-09-28 01:37:20,489 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 13, 17, 15, 9, 11, 20, 18, 12, 14, 7, 10, 19, 21, 16, 8]
2022-09-28 01:37:20,702 [foster.py] => Learning on 0-7
2022-09-28 01:37:20,703 [foster.py] => All params: 11183694
2022-09-28 01:37:20,703 [foster.py] => Trainable params: 11183694
2022-09-28 01:37:23,096 [foster.py] => Task 0, Epoch 1/40 => Loss 1.362, Train_accy 48.01
2022-09-28 01:37:26,118 [foster.py] => Task 0, Epoch 2/40 => Loss 0.541, Train_accy 81.07, Test_accy 87.25
2022-09-28 01:37:29,075 [foster.py] => Task 0, Epoch 3/40 => Loss 0.366, Train_accy 87.79, Test_accy 87.25
2022-09-28 01:37:32,032 [foster.py] => Task 0, Epoch 4/40 => Loss 0.275, Train_accy 90.60, Test_accy 89.93
2022-09-28 01:37:34,994 [foster.py] => Task 0, Epoch 5/40 => Loss 0.255, Train_accy 90.81, Test_accy 85.91
2022-09-28 01:37:37,368 [foster.py] => Task 0, Epoch 6/40 => Loss 0.180, Train_accy 94.38
2022-09-28 01:37:40,345 [foster.py] => Task 0, Epoch 7/40 => Loss 0.178, Train_accy 93.21, Test_accy 86.58
2022-09-28 01:37:43,324 [foster.py] => Task 0, Epoch 8/40 => Loss 0.132, Train_accy 95.61, Test_accy 88.59
2022-09-28 01:37:46,315 [foster.py] => Task 0, Epoch 9/40 => Loss 0.116, Train_accy 96.43, Test_accy 83.22
2022-09-28 01:37:49,347 [foster.py] => Task 0, Epoch 10/40 => Loss 0.083, Train_accy 97.81, Test_accy 87.25
2022-09-28 01:37:51,767 [foster.py] => Task 0, Epoch 11/40 => Loss 0.079, Train_accy 97.46
2022-09-28 01:37:54,729 [foster.py] => Task 0, Epoch 12/40 => Loss 0.070, Train_accy 97.94, Test_accy 87.92
2022-09-28 01:37:57,738 [foster.py] => Task 0, Epoch 13/40 => Loss 0.057, Train_accy 98.42, Test_accy 85.91
2022-09-28 01:38:00,736 [foster.py] => Task 0, Epoch 14/40 => Loss 0.057, Train_accy 98.56, Test_accy 85.23
2022-09-28 01:38:03,724 [foster.py] => Task 0, Epoch 15/40 => Loss 0.045, Train_accy 99.04, Test_accy 83.89
2022-09-28 01:38:06,100 [foster.py] => Task 0, Epoch 16/40 => Loss 0.038, Train_accy 99.04
2022-09-28 01:38:09,084 [foster.py] => Task 0, Epoch 17/40 => Loss 0.042, Train_accy 98.35, Test_accy 83.89
2022-09-28 01:38:12,096 [foster.py] => Task 0, Epoch 18/40 => Loss 0.031, Train_accy 99.25, Test_accy 84.56
2022-09-28 01:38:15,150 [foster.py] => Task 0, Epoch 19/40 => Loss 0.028, Train_accy 99.52, Test_accy 84.56
2022-09-28 01:38:18,108 [foster.py] => Task 0, Epoch 20/40 => Loss 0.025, Train_accy 99.31, Test_accy 83.89
2022-09-28 01:38:20,553 [foster.py] => Task 0, Epoch 21/40 => Loss 0.026, Train_accy 99.45
2022-09-28 01:38:23,540 [foster.py] => Task 0, Epoch 22/40 => Loss 0.024, Train_accy 99.38, Test_accy 83.89
2022-09-28 01:38:26,518 [foster.py] => Task 0, Epoch 23/40 => Loss 0.026, Train_accy 99.38, Test_accy 84.56
2022-09-28 01:38:29,496 [foster.py] => Task 0, Epoch 24/40 => Loss 0.016, Train_accy 99.86, Test_accy 85.23
2022-09-28 01:38:32,576 [foster.py] => Task 0, Epoch 25/40 => Loss 0.018, Train_accy 99.66, Test_accy 86.58
2022-09-28 01:38:35,001 [foster.py] => Task 0, Epoch 26/40 => Loss 0.018, Train_accy 99.66
2022-09-28 01:38:38,008 [foster.py] => Task 0, Epoch 27/40 => Loss 0.022, Train_accy 99.59, Test_accy 84.56
2022-09-28 01:38:41,047 [foster.py] => Task 0, Epoch 28/40 => Loss 0.012, Train_accy 99.86, Test_accy 85.23
2022-09-28 01:38:44,115 [foster.py] => Task 0, Epoch 29/40 => Loss 0.017, Train_accy 99.86, Test_accy 84.56
2022-09-28 01:38:47,088 [foster.py] => Task 0, Epoch 30/40 => Loss 0.013, Train_accy 99.93, Test_accy 85.91
2022-09-28 01:38:49,465 [foster.py] => Task 0, Epoch 31/40 => Loss 0.013, Train_accy 99.79
2022-09-28 01:38:52,472 [foster.py] => Task 0, Epoch 32/40 => Loss 0.012, Train_accy 99.86, Test_accy 84.56
2022-09-28 01:38:55,490 [foster.py] => Task 0, Epoch 33/40 => Loss 0.017, Train_accy 99.52, Test_accy 85.23
2022-09-28 01:38:58,463 [foster.py] => Task 0, Epoch 34/40 => Loss 0.013, Train_accy 99.86, Test_accy 85.91
2022-09-28 01:39:01,441 [foster.py] => Task 0, Epoch 35/40 => Loss 0.009, Train_accy 99.93, Test_accy 86.58
2022-09-28 01:39:03,853 [foster.py] => Task 0, Epoch 36/40 => Loss 0.012, Train_accy 99.93
2022-09-28 01:39:06,872 [foster.py] => Task 0, Epoch 37/40 => Loss 0.011, Train_accy 99.93, Test_accy 84.56
2022-09-28 01:39:09,888 [foster.py] => Task 0, Epoch 38/40 => Loss 0.011, Train_accy 100.00, Test_accy 88.59
2022-09-28 01:39:12,886 [foster.py] => Task 0, Epoch 39/40 => Loss 0.014, Train_accy 99.73, Test_accy 85.23
2022-09-28 01:39:15,916 [foster.py] => Task 0, Epoch 40/40 => Loss 0.014, Train_accy 99.79, Test_accy 85.23
2022-09-28 01:39:15,916 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 01:39:22,740 [foster.py] => Exemplar size: 140
2022-09-28 01:39:22,740 [trainer.py] => CNN: {'total': 85.23, 'old': 85.23, 'new': 0, 'base': 85.23, 'compound': 0}
2022-09-28 01:39:22,740 [trainer.py] => CNN top1 curve: [85.23]
2022-09-28 01:39:22,740 [trainer.py] => CNN base curve: [85.23]
2022-09-28 01:39:22,740 [trainer.py] => CNN old curve: [85.23]
2022-09-28 01:39:22,740 [trainer.py] => CNN new curve: [0]
2022-09-28 01:39:22,740 [trainer.py] => CNN compound curve: [0]
2022-09-28 01:39:22,740 [trainer.py] => NME: {'total': 85.23, 'old': 85.23, 'new': 0, 'base': 85.23, 'compound': 0}
2022-09-28 01:39:22,740 [trainer.py] => NME top1 curve: [85.23]
2022-09-28 01:39:22,740 [trainer.py] => NME base curve: [85.23]
2022-09-28 01:39:22,740 [trainer.py] => NME old curve: [85.23]
2022-09-28 01:39:22,740 [trainer.py] => NME new curve: [0]
2022-09-28 01:39:22,740 [trainer.py] => NME compound curve: [0]
2022-09-28 01:39:22,969 [foster.py] => Learning on 7-10
2022-09-28 01:39:22,970 [foster.py] => All params: 22371995
2022-09-28 01:39:22,970 [foster.py] => Trainable params: 11191892
2022-09-28 01:39:22,990 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 01:39:25,446 [foster.py] => Task 1, Epoch 1/34 => Loss 4.736, Loss_clf 2.081, Loss_fe 1.985, Loss_kd 0.469, Train_accy 38.75, Test_accy 69.91
2022-09-28 01:39:27,160 [foster.py] => Task 1, Epoch 2/34 => Loss 2.441, Loss_clf 0.614, Loss_fe 1.146, Loss_kd 0.477, Train_accy 80.56
2022-09-28 01:39:28,887 [foster.py] => Task 1, Epoch 3/34 => Loss 1.922, Loss_clf 0.365, Loss_fe 0.911, Loss_kd 0.452, Train_accy 56.46
2022-09-28 01:39:30,577 [foster.py] => Task 1, Epoch 4/34 => Loss 1.777, Loss_clf 0.346, Loss_fe 0.777, Loss_kd 0.458, Train_accy 57.66
2022-09-28 01:39:32,321 [foster.py] => Task 1, Epoch 5/34 => Loss 1.674, Loss_clf 0.327, Loss_fe 0.696, Loss_kd 0.456, Train_accy 60.59
2022-09-28 01:39:34,789 [foster.py] => Task 1, Epoch 6/34 => Loss 1.591, Loss_clf 0.305, Loss_fe 0.639, Loss_kd 0.453, Train_accy 55.53, Test_accy 73.01
2022-09-28 01:39:36,517 [foster.py] => Task 1, Epoch 7/34 => Loss 1.532, Loss_clf 0.305, Loss_fe 0.578, Loss_kd 0.454, Train_accy 56.06
2022-09-28 01:39:38,251 [foster.py] => Task 1, Epoch 8/34 => Loss 1.468, Loss_clf 0.283, Loss_fe 0.532, Loss_kd 0.457, Train_accy 59.52
2022-09-28 01:39:39,987 [foster.py] => Task 1, Epoch 9/34 => Loss 1.450, Loss_clf 0.290, Loss_fe 0.514, Loss_kd 0.452, Train_accy 56.46
2022-09-28 01:39:41,698 [foster.py] => Task 1, Epoch 10/34 => Loss 1.387, Loss_clf 0.275, Loss_fe 0.481, Loss_kd 0.441, Train_accy 58.19
2022-09-28 01:39:44,138 [foster.py] => Task 1, Epoch 11/34 => Loss 1.361, Loss_clf 0.261, Loss_fe 0.452, Loss_kd 0.454, Train_accy 58.99, Test_accy 72.12
2022-09-28 01:39:45,854 [foster.py] => Task 1, Epoch 12/34 => Loss 1.318, Loss_clf 0.252, Loss_fe 0.428, Loss_kd 0.447, Train_accy 57.79
2022-09-28 01:39:47,552 [foster.py] => Task 1, Epoch 13/34 => Loss 1.304, Loss_clf 0.248, Loss_fe 0.417, Loss_kd 0.448, Train_accy 59.25
2022-09-28 01:39:49,310 [foster.py] => Task 1, Epoch 14/34 => Loss 1.337, Loss_clf 0.266, Loss_fe 0.428, Loss_kd 0.450, Train_accy 60.99
2022-09-28 01:39:51,002 [foster.py] => Task 1, Epoch 15/34 => Loss 1.288, Loss_clf 0.251, Loss_fe 0.400, Loss_kd 0.446, Train_accy 59.25
2022-09-28 01:39:53,523 [foster.py] => Task 1, Epoch 16/34 => Loss 1.280, Loss_clf 0.249, Loss_fe 0.388, Loss_kd 0.450, Train_accy 59.25, Test_accy 72.57
2022-09-28 01:39:55,236 [foster.py] => Task 1, Epoch 17/34 => Loss 1.276, Loss_clf 0.244, Loss_fe 0.389, Loss_kd 0.449, Train_accy 61.52
2022-09-28 01:39:56,959 [foster.py] => Task 1, Epoch 18/34 => Loss 1.245, Loss_clf 0.231, Loss_fe 0.368, Loss_kd 0.452, Train_accy 60.32
2022-09-28 01:39:58,705 [foster.py] => Task 1, Epoch 19/34 => Loss 1.233, Loss_clf 0.237, Loss_fe 0.356, Loss_kd 0.449, Train_accy 59.92
2022-09-28 01:40:00,402 [foster.py] => Task 1, Epoch 20/34 => Loss 1.204, Loss_clf 0.213, Loss_fe 0.337, Loss_kd 0.457, Train_accy 60.59
2022-09-28 01:40:02,892 [foster.py] => Task 1, Epoch 21/34 => Loss 1.174, Loss_clf 0.201, Loss_fe 0.327, Loss_kd 0.452, Train_accy 59.92, Test_accy 72.57
2022-09-28 01:40:04,588 [foster.py] => Task 1, Epoch 22/34 => Loss 1.197, Loss_clf 0.212, Loss_fe 0.331, Loss_kd 0.457, Train_accy 61.25
2022-09-28 01:40:06,301 [foster.py] => Task 1, Epoch 23/34 => Loss 1.173, Loss_clf 0.202, Loss_fe 0.327, Loss_kd 0.451, Train_accy 60.85
2022-09-28 01:40:08,067 [foster.py] => Task 1, Epoch 24/34 => Loss 1.201, Loss_clf 0.212, Loss_fe 0.341, Loss_kd 0.454, Train_accy 60.85
2022-09-28 01:40:09,781 [foster.py] => Task 1, Epoch 25/34 => Loss 1.195, Loss_clf 0.212, Loss_fe 0.331, Loss_kd 0.457, Train_accy 60.99
2022-09-28 01:40:12,263 [foster.py] => Task 1, Epoch 26/34 => Loss 1.205, Loss_clf 0.228, Loss_fe 0.331, Loss_kd 0.452, Train_accy 60.99, Test_accy 72.57
2022-09-28 01:40:13,990 [foster.py] => Task 1, Epoch 27/34 => Loss 1.176, Loss_clf 0.206, Loss_fe 0.320, Loss_kd 0.455, Train_accy 61.12
2022-09-28 01:40:15,705 [foster.py] => Task 1, Epoch 28/34 => Loss 1.136, Loss_clf 0.191, Loss_fe 0.306, Loss_kd 0.447, Train_accy 60.59
2022-09-28 01:40:17,456 [foster.py] => Task 1, Epoch 29/34 => Loss 1.143, Loss_clf 0.194, Loss_fe 0.306, Loss_kd 0.450, Train_accy 60.32
2022-09-28 01:40:19,210 [foster.py] => Task 1, Epoch 30/34 => Loss 1.168, Loss_clf 0.208, Loss_fe 0.320, Loss_kd 0.448, Train_accy 60.45
2022-09-28 01:40:21,623 [foster.py] => Task 1, Epoch 31/34 => Loss 1.175, Loss_clf 0.209, Loss_fe 0.314, Loss_kd 0.456, Train_accy 62.58, Test_accy 72.57
2022-09-28 01:40:23,329 [foster.py] => Task 1, Epoch 32/34 => Loss 1.140, Loss_clf 0.188, Loss_fe 0.302, Loss_kd 0.455, Train_accy 62.85
2022-09-28 01:40:25,057 [foster.py] => Task 1, Epoch 33/34 => Loss 1.170, Loss_clf 0.206, Loss_fe 0.316, Loss_kd 0.453, Train_accy 61.12
2022-09-28 01:40:26,766 [foster.py] => Task 1, Epoch 34/34 => Loss 1.194, Loss_clf 0.215, Loss_fe 0.330, Loss_kd 0.455, Train_accy 62.45
2022-09-28 01:40:26,766 [foster.py] => do not weight align teacher!
2022-09-28 01:40:26,767 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 01:40:29,564 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.537,  Train_accy 18.24, Test_accy 55.31
2022-09-28 01:40:31,472 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.387,  Train_accy 18.24
2022-09-28 01:40:33,406 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.301,  Train_accy 19.57
2022-09-28 01:40:35,352 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.261,  Train_accy 23.57
2022-09-28 01:40:37,283 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.234,  Train_accy 29.03
2022-09-28 01:40:39,891 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.214,  Train_accy 31.42, Test_accy 61.50
2022-09-28 01:40:41,859 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.210,  Train_accy 33.02
2022-09-28 01:40:43,817 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.197,  Train_accy 34.09
2022-09-28 01:40:45,782 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.188,  Train_accy 33.82
2022-09-28 01:40:47,669 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.174,  Train_accy 35.15
2022-09-28 01:40:50,259 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.172,  Train_accy 35.69, Test_accy 64.16
2022-09-28 01:40:52,199 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.172,  Train_accy 35.82
2022-09-28 01:40:54,160 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.158,  Train_accy 38.48
2022-09-28 01:40:56,137 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.167,  Train_accy 35.42
2022-09-28 01:40:58,028 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.171,  Train_accy 37.68
2022-09-28 01:41:00,655 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.168,  Train_accy 39.15, Test_accy 65.49
2022-09-28 01:41:02,549 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.162,  Train_accy 36.09
2022-09-28 01:41:04,512 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.159,  Train_accy 38.35
2022-09-28 01:41:06,446 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.156,  Train_accy 37.55
2022-09-28 01:41:08,383 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.162,  Train_accy 38.35
2022-09-28 01:41:11,019 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.153,  Train_accy 36.88, Test_accy 65.49
2022-09-28 01:41:12,947 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.152,  Train_accy 38.75
2022-09-28 01:41:14,872 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.153,  Train_accy 38.35
2022-09-28 01:41:16,796 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.154,  Train_accy 38.75
2022-09-28 01:41:18,690 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.150,  Train_accy 38.62
2022-09-28 01:41:21,258 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.151,  Train_accy 39.68, Test_accy 65.04
2022-09-28 01:41:21,258 [foster.py] => do not weight align student!
2022-09-28 01:41:21,925 [foster.py] => darknet eval: 
2022-09-28 01:41:21,925 [foster.py] => CNN top1 curve: 65.04
2022-09-28 01:41:21,925 [foster.py] => CNN top5 curve: 98.67
2022-09-28 01:41:21,926 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 01:41:28,288 [foster.py] => Exemplar size: 200
2022-09-28 01:41:28,288 [trainer.py] => CNN: {'total': 72.57, 'old': 84.56, 'new': 49.35, 'base': 84.56, 'compound': 49.35}
2022-09-28 01:41:28,288 [trainer.py] => CNN top1 curve: [85.23, 72.57]
2022-09-28 01:41:28,288 [trainer.py] => CNN base curve: [85.23, 84.56]
2022-09-28 01:41:28,288 [trainer.py] => CNN old curve: [85.23, 84.56]
2022-09-28 01:41:28,288 [trainer.py] => CNN new curve: [0, 49.35]
2022-09-28 01:41:28,288 [trainer.py] => CNN compound curve: [0, 49.35]
2022-09-28 01:41:28,288 [trainer.py] => NME: {'total': 76.11, 'old': 81.21, 'new': 66.23, 'base': 81.21, 'compound': 66.23}
2022-09-28 01:41:28,288 [trainer.py] => NME top1 curve: [85.23, 76.11]
2022-09-28 01:41:28,288 [trainer.py] => NME base curve: [85.23, 81.21]
2022-09-28 01:41:28,288 [trainer.py] => NME old curve: [85.23, 81.21]
2022-09-28 01:41:28,289 [trainer.py] => NME new curve: [0, 66.23]
2022-09-28 01:41:28,289 [trainer.py] => NME compound curve: [0, 66.23]
2022-09-28 01:41:28,517 [foster.py] => Learning on 10-13
2022-09-28 01:41:28,517 [foster.py] => All params: 22378148
2022-09-28 01:41:28,518 [foster.py] => Trainable params: 11196506
2022-09-28 01:41:28,538 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 01:41:31,215 [foster.py] => Task 2, Epoch 1/34 => Loss 5.375, Loss_clf 2.329, Loss_fe 1.998, Loss_kd 0.807, Train_accy 40.19, Test_accy 48.12
2022-09-28 01:41:33,067 [foster.py] => Task 2, Epoch 2/34 => Loss 3.307, Loss_clf 0.913, Loss_fe 1.349, Loss_kd 0.804, Train_accy 51.52
2022-09-28 01:41:34,875 [foster.py] => Task 2, Epoch 3/34 => Loss 2.878, Loss_clf 0.693, Loss_fe 1.159, Loss_kd 0.789, Train_accy 39.34
2022-09-28 01:41:36,755 [foster.py] => Task 2, Epoch 4/34 => Loss 2.763, Loss_clf 0.679, Loss_fe 1.068, Loss_kd 0.781, Train_accy 38.98
2022-09-28 01:41:38,553 [foster.py] => Task 2, Epoch 5/34 => Loss 2.611, Loss_clf 0.622, Loss_fe 0.963, Loss_kd 0.790, Train_accy 42.14
2022-09-28 01:41:41,243 [foster.py] => Task 2, Epoch 6/34 => Loss 2.507, Loss_clf 0.579, Loss_fe 0.908, Loss_kd 0.784, Train_accy 44.34, Test_accy 57.00
2022-09-28 01:41:43,102 [foster.py] => Task 2, Epoch 7/34 => Loss 2.479, Loss_clf 0.579, Loss_fe 0.866, Loss_kd 0.795, Train_accy 41.90
2022-09-28 01:41:44,910 [foster.py] => Task 2, Epoch 8/34 => Loss 2.367, Loss_clf 0.537, Loss_fe 0.811, Loss_kd 0.784, Train_accy 43.00
2022-09-28 01:41:46,726 [foster.py] => Task 2, Epoch 9/34 => Loss 2.314, Loss_clf 0.519, Loss_fe 0.774, Loss_kd 0.786, Train_accy 44.09
2022-09-28 01:41:48,558 [foster.py] => Task 2, Epoch 10/34 => Loss 2.268, Loss_clf 0.511, Loss_fe 0.749, Loss_kd 0.776, Train_accy 42.51
2022-09-28 01:41:51,178 [foster.py] => Task 2, Epoch 11/34 => Loss 2.274, Loss_clf 0.526, Loss_fe 0.737, Loss_kd 0.777, Train_accy 43.36, Test_accy 58.36
2022-09-28 01:41:53,013 [foster.py] => Task 2, Epoch 12/34 => Loss 2.260, Loss_clf 0.521, Loss_fe 0.719, Loss_kd 0.784, Train_accy 42.14
2022-09-28 01:41:54,842 [foster.py] => Task 2, Epoch 13/34 => Loss 2.197, Loss_clf 0.488, Loss_fe 0.696, Loss_kd 0.780, Train_accy 44.70
2022-09-28 01:41:56,690 [foster.py] => Task 2, Epoch 14/34 => Loss 2.148, Loss_clf 0.475, Loss_fe 0.653, Loss_kd 0.785, Train_accy 44.95
2022-09-28 01:41:58,500 [foster.py] => Task 2, Epoch 15/34 => Loss 2.160, Loss_clf 0.476, Loss_fe 0.653, Loss_kd 0.793, Train_accy 45.80
2022-09-28 01:42:01,184 [foster.py] => Task 2, Epoch 16/34 => Loss 2.114, Loss_clf 0.461, Loss_fe 0.630, Loss_kd 0.787, Train_accy 45.07, Test_accy 59.04
2022-09-28 01:42:03,026 [foster.py] => Task 2, Epoch 17/34 => Loss 2.072, Loss_clf 0.444, Loss_fe 0.605, Loss_kd 0.787, Train_accy 44.09
2022-09-28 01:42:04,824 [foster.py] => Task 2, Epoch 18/34 => Loss 2.043, Loss_clf 0.438, Loss_fe 0.587, Loss_kd 0.783, Train_accy 48.11
2022-09-28 01:42:06,673 [foster.py] => Task 2, Epoch 19/34 => Loss 2.027, Loss_clf 0.425, Loss_fe 0.573, Loss_kd 0.792, Train_accy 44.70
2022-09-28 01:42:08,519 [foster.py] => Task 2, Epoch 20/34 => Loss 2.036, Loss_clf 0.434, Loss_fe 0.580, Loss_kd 0.786, Train_accy 46.04
2022-09-28 01:42:11,247 [foster.py] => Task 2, Epoch 21/34 => Loss 2.013, Loss_clf 0.429, Loss_fe 0.570, Loss_kd 0.780, Train_accy 47.14, Test_accy 59.73
2022-09-28 01:42:13,082 [foster.py] => Task 2, Epoch 22/34 => Loss 1.989, Loss_clf 0.408, Loss_fe 0.559, Loss_kd 0.786, Train_accy 47.99
2022-09-28 01:42:14,925 [foster.py] => Task 2, Epoch 23/34 => Loss 1.998, Loss_clf 0.421, Loss_fe 0.557, Loss_kd 0.785, Train_accy 46.16
2022-09-28 01:42:16,763 [foster.py] => Task 2, Epoch 24/34 => Loss 1.980, Loss_clf 0.408, Loss_fe 0.548, Loss_kd 0.787, Train_accy 46.16
2022-09-28 01:42:18,631 [foster.py] => Task 2, Epoch 25/34 => Loss 1.980, Loss_clf 0.417, Loss_fe 0.544, Loss_kd 0.784, Train_accy 48.60
2022-09-28 01:42:21,313 [foster.py] => Task 2, Epoch 26/34 => Loss 1.963, Loss_clf 0.408, Loss_fe 0.536, Loss_kd 0.784, Train_accy 45.55, Test_accy 59.73
2022-09-28 01:42:23,145 [foster.py] => Task 2, Epoch 27/34 => Loss 2.024, Loss_clf 0.436, Loss_fe 0.572, Loss_kd 0.782, Train_accy 46.77
2022-09-28 01:42:24,992 [foster.py] => Task 2, Epoch 28/34 => Loss 1.987, Loss_clf 0.408, Loss_fe 0.554, Loss_kd 0.788, Train_accy 46.16
2022-09-28 01:42:26,847 [foster.py] => Task 2, Epoch 29/34 => Loss 1.964, Loss_clf 0.406, Loss_fe 0.539, Loss_kd 0.784, Train_accy 48.60
2022-09-28 01:42:28,652 [foster.py] => Task 2, Epoch 30/34 => Loss 1.954, Loss_clf 0.394, Loss_fe 0.536, Loss_kd 0.787, Train_accy 47.99
2022-09-28 01:42:31,334 [foster.py] => Task 2, Epoch 31/34 => Loss 1.919, Loss_clf 0.377, Loss_fe 0.517, Loss_kd 0.788, Train_accy 47.50, Test_accy 59.73
2022-09-28 01:42:33,139 [foster.py] => Task 2, Epoch 32/34 => Loss 1.983, Loss_clf 0.412, Loss_fe 0.559, Loss_kd 0.778, Train_accy 47.62
2022-09-28 01:42:34,979 [foster.py] => Task 2, Epoch 33/34 => Loss 1.964, Loss_clf 0.401, Loss_fe 0.539, Loss_kd 0.787, Train_accy 46.77
2022-09-28 01:42:36,861 [foster.py] => Task 2, Epoch 34/34 => Loss 1.953, Loss_clf 0.398, Loss_fe 0.538, Loss_kd 0.783, Train_accy 47.99
2022-09-28 01:42:36,862 [foster.py] => do not weight align teacher!
2022-09-28 01:42:36,862 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 01:42:39,881 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.763,  Train_accy 17.90, Test_accy 47.44
2022-09-28 01:42:41,907 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.650,  Train_accy 18.03
2022-09-28 01:42:43,939 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.589,  Train_accy 18.51
2022-09-28 01:42:45,992 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.563,  Train_accy 18.88
2022-09-28 01:42:48,041 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.546,  Train_accy 19.24
2022-09-28 01:42:50,774 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.532,  Train_accy 19.73, Test_accy 51.54
2022-09-28 01:42:52,822 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.526,  Train_accy 19.98
2022-09-28 01:42:54,891 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.508,  Train_accy 21.32
2022-09-28 01:42:56,955 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.513,  Train_accy 21.07
2022-09-28 01:42:59,014 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.501,  Train_accy 20.95
2022-09-28 01:43:01,829 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.515,  Train_accy 21.92, Test_accy 51.88
2022-09-28 01:43:03,863 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.491,  Train_accy 21.44
2022-09-28 01:43:05,874 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.496,  Train_accy 22.05
2022-09-28 01:43:07,943 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.498,  Train_accy 21.32
2022-09-28 01:43:10,083 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.499,  Train_accy 22.53
2022-09-28 01:43:12,808 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.487,  Train_accy 22.53, Test_accy 52.22
2022-09-28 01:43:14,832 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.482,  Train_accy 21.68
2022-09-28 01:43:16,861 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.495,  Train_accy 23.14
2022-09-28 01:43:18,933 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.485,  Train_accy 22.53
2022-09-28 01:43:20,965 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.480,  Train_accy 22.05
2022-09-28 01:43:23,766 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.482,  Train_accy 23.02, Test_accy 54.27
2022-09-28 01:43:25,861 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.502,  Train_accy 22.17
2022-09-28 01:43:27,890 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.495,  Train_accy 22.90
2022-09-28 01:43:29,918 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.483,  Train_accy 23.02
2022-09-28 01:43:31,973 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.485,  Train_accy 22.90
2022-09-28 01:43:34,697 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.494,  Train_accy 23.39, Test_accy 52.90
2022-09-28 01:43:34,697 [foster.py] => do not weight align student!
2022-09-28 01:43:35,423 [foster.py] => darknet eval: 
2022-09-28 01:43:35,424 [foster.py] => CNN top1 curve: 52.9
2022-09-28 01:43:35,424 [foster.py] => CNN top5 curve: 96.25
2022-09-28 01:43:35,424 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 01:43:42,855 [foster.py] => Exemplar size: 260
2022-09-28 01:43:42,855 [trainer.py] => CNN: {'total': 59.39, 'old': 69.03, 'new': 26.87, 'base': 77.85, 'compound': 40.28}
2022-09-28 01:43:42,855 [trainer.py] => CNN top1 curve: [85.23, 72.57, 59.39]
2022-09-28 01:43:42,855 [trainer.py] => CNN base curve: [85.23, 84.56, 77.85]
2022-09-28 01:43:42,855 [trainer.py] => CNN old curve: [85.23, 84.56, 69.03]
2022-09-28 01:43:42,855 [trainer.py] => CNN new curve: [0, 49.35, 26.87]
2022-09-28 01:43:42,855 [trainer.py] => CNN compound curve: [0, 49.35, 40.28]
2022-09-28 01:43:42,855 [trainer.py] => NME: {'total': 66.89, 'old': 68.58, 'new': 61.19, 'base': 73.15, 'compound': 60.42}
2022-09-28 01:43:42,855 [trainer.py] => NME top1 curve: [85.23, 76.11, 66.89]
2022-09-28 01:43:42,855 [trainer.py] => NME base curve: [85.23, 81.21, 73.15]
2022-09-28 01:43:42,855 [trainer.py] => NME old curve: [85.23, 81.21, 68.58]
2022-09-28 01:43:42,855 [trainer.py] => NME new curve: [0, 66.23, 61.19]
2022-09-28 01:43:42,855 [trainer.py] => NME compound curve: [0, 66.23, 60.42]
2022-09-28 01:43:43,084 [foster.py] => Learning on 13-16
2022-09-28 01:43:43,085 [foster.py] => All params: 22384301
2022-09-28 01:43:43,085 [foster.py] => Trainable params: 11201120
2022-09-28 01:43:43,105 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 01:43:45,889 [foster.py] => Task 3, Epoch 1/34 => Loss 6.104, Loss_clf 2.236, Loss_fe 2.274, Loss_kd 1.296, Train_accy 39.07, Test_accy 43.73
2022-09-28 01:43:47,865 [foster.py] => Task 3, Epoch 2/34 => Loss 4.257, Loss_clf 1.036, Loss_fe 1.636, Loss_kd 1.288, Train_accy 39.41
2022-09-28 01:43:49,782 [foster.py] => Task 3, Epoch 3/34 => Loss 3.902, Loss_clf 0.886, Loss_fe 1.430, Loss_kd 1.288, Train_accy 39.41
2022-09-28 01:43:51,682 [foster.py] => Task 3, Epoch 4/34 => Loss 3.762, Loss_clf 0.855, Loss_fe 1.322, Loss_kd 1.288, Train_accy 39.52
2022-09-28 01:43:53,624 [foster.py] => Task 3, Epoch 5/34 => Loss 3.652, Loss_clf 0.857, Loss_fe 1.224, Loss_kd 1.277, Train_accy 38.05
2022-09-28 01:43:56,399 [foster.py] => Task 3, Epoch 6/34 => Loss 3.553, Loss_clf 0.814, Loss_fe 1.149, Loss_kd 1.291, Train_accy 39.30, Test_accy 49.30
2022-09-28 01:43:58,376 [foster.py] => Task 3, Epoch 7/34 => Loss 3.478, Loss_clf 0.803, Loss_fe 1.087, Loss_kd 1.290, Train_accy 38.84
2022-09-28 01:44:00,330 [foster.py] => Task 3, Epoch 8/34 => Loss 3.407, Loss_clf 0.786, Loss_fe 1.038, Loss_kd 1.286, Train_accy 38.73
2022-09-28 01:44:02,221 [foster.py] => Task 3, Epoch 9/34 => Loss 3.334, Loss_clf 0.754, Loss_fe 0.998, Loss_kd 1.285, Train_accy 39.98
2022-09-28 01:44:04,132 [foster.py] => Task 3, Epoch 10/34 => Loss 3.325, Loss_clf 0.775, Loss_fe 0.975, Loss_kd 1.280, Train_accy 41.90
2022-09-28 01:44:06,889 [foster.py] => Task 3, Epoch 11/34 => Loss 3.239, Loss_clf 0.731, Loss_fe 0.921, Loss_kd 1.289, Train_accy 41.34, Test_accy 50.14
2022-09-28 01:44:08,863 [foster.py] => Task 3, Epoch 12/34 => Loss 3.230, Loss_clf 0.736, Loss_fe 0.903, Loss_kd 1.293, Train_accy 40.43
2022-09-28 01:44:10,745 [foster.py] => Task 3, Epoch 13/34 => Loss 3.149, Loss_clf 0.712, Loss_fe 0.863, Loss_kd 1.279, Train_accy 41.90
2022-09-28 01:44:12,647 [foster.py] => Task 3, Epoch 14/34 => Loss 3.130, Loss_clf 0.700, Loss_fe 0.843, Loss_kd 1.290, Train_accy 40.32
2022-09-28 01:44:14,601 [foster.py] => Task 3, Epoch 15/34 => Loss 3.118, Loss_clf 0.692, Loss_fe 0.838, Loss_kd 1.290, Train_accy 43.37
2022-09-28 01:44:17,391 [foster.py] => Task 3, Epoch 16/34 => Loss 3.075, Loss_clf 0.667, Loss_fe 0.823, Loss_kd 1.288, Train_accy 41.56, Test_accy 50.70
2022-09-28 01:44:19,277 [foster.py] => Task 3, Epoch 17/34 => Loss 3.064, Loss_clf 0.668, Loss_fe 0.811, Loss_kd 1.288, Train_accy 44.51
2022-09-28 01:44:21,230 [foster.py] => Task 3, Epoch 18/34 => Loss 3.087, Loss_clf 0.688, Loss_fe 0.810, Loss_kd 1.291, Train_accy 42.47
2022-09-28 01:44:23,135 [foster.py] => Task 3, Epoch 19/34 => Loss 3.005, Loss_clf 0.653, Loss_fe 0.770, Loss_kd 1.286, Train_accy 44.73
2022-09-28 01:44:25,065 [foster.py] => Task 3, Epoch 20/34 => Loss 3.047, Loss_clf 0.669, Loss_fe 0.783, Loss_kd 1.296, Train_accy 43.60
2022-09-28 01:44:27,835 [foster.py] => Task 3, Epoch 21/34 => Loss 2.954, Loss_clf 0.634, Loss_fe 0.737, Loss_kd 1.286, Train_accy 43.71, Test_accy 50.42
2022-09-28 01:44:29,765 [foster.py] => Task 3, Epoch 22/34 => Loss 2.937, Loss_clf 0.621, Loss_fe 0.730, Loss_kd 1.288, Train_accy 44.85
2022-09-28 01:44:31,725 [foster.py] => Task 3, Epoch 23/34 => Loss 2.966, Loss_clf 0.634, Loss_fe 0.747, Loss_kd 1.288, Train_accy 43.71
2022-09-28 01:44:33,637 [foster.py] => Task 3, Epoch 24/34 => Loss 2.939, Loss_clf 0.618, Loss_fe 0.732, Loss_kd 1.291, Train_accy 44.28
2022-09-28 01:44:35,551 [foster.py] => Task 3, Epoch 25/34 => Loss 2.939, Loss_clf 0.625, Loss_fe 0.727, Loss_kd 1.289, Train_accy 43.15
2022-09-28 01:44:38,351 [foster.py] => Task 3, Epoch 26/34 => Loss 2.916, Loss_clf 0.615, Loss_fe 0.715, Loss_kd 1.288, Train_accy 45.53, Test_accy 51.25
2022-09-28 01:44:40,253 [foster.py] => Task 3, Epoch 27/34 => Loss 2.922, Loss_clf 0.620, Loss_fe 0.716, Loss_kd 1.289, Train_accy 42.70
2022-09-28 01:44:42,145 [foster.py] => Task 3, Epoch 28/34 => Loss 2.944, Loss_clf 0.631, Loss_fe 0.718, Loss_kd 1.296, Train_accy 46.32
2022-09-28 01:44:44,047 [foster.py] => Task 3, Epoch 29/34 => Loss 2.904, Loss_clf 0.604, Loss_fe 0.700, Loss_kd 1.300, Train_accy 45.98
2022-09-28 01:44:45,948 [foster.py] => Task 3, Epoch 30/34 => Loss 2.937, Loss_clf 0.621, Loss_fe 0.718, Loss_kd 1.298, Train_accy 45.07
2022-09-28 01:44:48,778 [foster.py] => Task 3, Epoch 31/34 => Loss 2.881, Loss_clf 0.602, Loss_fe 0.698, Loss_kd 1.285, Train_accy 45.19, Test_accy 51.81
2022-09-28 01:44:50,723 [foster.py] => Task 3, Epoch 32/34 => Loss 2.899, Loss_clf 0.608, Loss_fe 0.706, Loss_kd 1.288, Train_accy 44.28
2022-09-28 01:44:52,647 [foster.py] => Task 3, Epoch 33/34 => Loss 2.899, Loss_clf 0.611, Loss_fe 0.701, Loss_kd 1.290, Train_accy 45.64
2022-09-28 01:44:54,589 [foster.py] => Task 3, Epoch 34/34 => Loss 2.894, Loss_clf 0.614, Loss_fe 0.700, Loss_kd 1.284, Train_accy 44.96
2022-09-28 01:44:54,589 [foster.py] => do not weight align teacher!
2022-09-28 01:44:54,590 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 01:44:57,702 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.067,  Train_accy 18.69, Test_accy 42.62
2022-09-28 01:44:59,921 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.021,  Train_accy 19.14
2022-09-28 01:45:02,050 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 1.974,  Train_accy 19.71
2022-09-28 01:45:04,220 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 1.948,  Train_accy 19.14
2022-09-28 01:45:06,388 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.958,  Train_accy 19.93
2022-09-28 01:45:09,286 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.945,  Train_accy 19.48, Test_accy 43.73
2022-09-28 01:45:11,411 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.942,  Train_accy 19.82
2022-09-28 01:45:13,559 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.926,  Train_accy 19.82
2022-09-28 01:45:15,721 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.926,  Train_accy 19.93
2022-09-28 01:45:17,878 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.933,  Train_accy 20.39
2022-09-28 01:45:20,795 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.918,  Train_accy 19.71, Test_accy 44.85
2022-09-28 01:45:22,949 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.918,  Train_accy 20.16
2022-09-28 01:45:25,106 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.919,  Train_accy 20.27
2022-09-28 01:45:27,232 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.923,  Train_accy 20.27
2022-09-28 01:45:29,435 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.916,  Train_accy 20.39
2022-09-28 01:45:32,369 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.913,  Train_accy 20.05, Test_accy 44.57
2022-09-28 01:45:34,482 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.913,  Train_accy 20.84
2022-09-28 01:45:36,650 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.903,  Train_accy 19.93
2022-09-28 01:45:38,880 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.907,  Train_accy 20.61
2022-09-28 01:45:41,019 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.914,  Train_accy 19.71
2022-09-28 01:45:43,978 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.904,  Train_accy 19.48, Test_accy 44.85
2022-09-28 01:45:46,092 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.905,  Train_accy 20.27
2022-09-28 01:45:48,248 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.899,  Train_accy 20.50
2022-09-28 01:45:50,425 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.911,  Train_accy 20.50
2022-09-28 01:45:52,595 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.904,  Train_accy 20.27
2022-09-28 01:45:55,515 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.903,  Train_accy 19.37, Test_accy 44.85
2022-09-28 01:45:55,516 [foster.py] => do not weight align student!
2022-09-28 01:45:56,282 [foster.py] => darknet eval: 
2022-09-28 01:45:56,282 [foster.py] => CNN top1 curve: 44.85
2022-09-28 01:45:56,282 [foster.py] => CNN top5 curve: 89.69
2022-09-28 01:45:56,282 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 01:46:04,760 [foster.py] => Exemplar size: 320
2022-09-28 01:46:04,760 [trainer.py] => CNN: {'total': 50.97, 'old': 55.97, 'new': 28.79, 'base': 73.15, 'compound': 35.24}
2022-09-28 01:46:04,760 [trainer.py] => CNN top1 curve: [85.23, 72.57, 59.39, 50.97]
2022-09-28 01:46:04,760 [trainer.py] => CNN base curve: [85.23, 84.56, 77.85, 73.15]
2022-09-28 01:46:04,760 [trainer.py] => CNN old curve: [85.23, 84.56, 69.03, 55.97]
2022-09-28 01:46:04,760 [trainer.py] => CNN new curve: [0, 49.35, 26.87, 28.79]
2022-09-28 01:46:04,760 [trainer.py] => CNN compound curve: [0, 49.35, 40.28, 35.24]
2022-09-28 01:46:04,760 [trainer.py] => NME: {'total': 59.33, 'old': 60.41, 'new': 54.55, 'base': 65.77, 'compound': 54.76}
2022-09-28 01:46:04,760 [trainer.py] => NME top1 curve: [85.23, 76.11, 66.89, 59.33]
2022-09-28 01:46:04,760 [trainer.py] => NME base curve: [85.23, 81.21, 73.15, 65.77]
2022-09-28 01:46:04,760 [trainer.py] => NME old curve: [85.23, 81.21, 68.58, 60.41]
2022-09-28 01:46:04,760 [trainer.py] => NME new curve: [0, 66.23, 61.19, 54.55]
2022-09-28 01:46:04,760 [trainer.py] => NME compound curve: [0, 66.23, 60.42, 54.76]
2022-09-28 01:46:04,988 [foster.py] => Learning on 16-19
2022-09-28 01:46:04,989 [foster.py] => All params: 22390454
2022-09-28 01:46:04,989 [foster.py] => Trainable params: 11205734
2022-09-28 01:46:05,009 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 01:46:07,979 [foster.py] => Task 4, Epoch 1/34 => Loss 6.274, Loss_clf 2.040, Loss_fe 2.314, Loss_kd 1.617, Train_accy 44.85, Test_accy 44.24
2022-09-28 01:46:09,981 [foster.py] => Task 4, Epoch 2/34 => Loss 4.552, Loss_clf 0.957, Loss_fe 1.687, Loss_kd 1.607, Train_accy 40.28
2022-09-28 01:46:11,953 [foster.py] => Task 4, Epoch 3/34 => Loss 4.245, Loss_clf 0.862, Loss_fe 1.480, Loss_kd 1.603, Train_accy 46.33
2022-09-28 01:46:13,977 [foster.py] => Task 4, Epoch 4/34 => Loss 4.088, Loss_clf 0.833, Loss_fe 1.360, Loss_kd 1.596, Train_accy 47.82
2022-09-28 01:46:15,994 [foster.py] => Task 4, Epoch 5/34 => Loss 3.986, Loss_clf 0.810, Loss_fe 1.266, Loss_kd 1.609, Train_accy 46.76
2022-09-28 01:46:18,933 [foster.py] => Task 4, Epoch 6/34 => Loss 3.888, Loss_clf 0.788, Loss_fe 1.184, Loss_kd 1.613, Train_accy 47.72, Test_accy 46.12
2022-09-28 01:46:20,953 [foster.py] => Task 4, Epoch 7/34 => Loss 3.815, Loss_clf 0.765, Loss_fe 1.139, Loss_kd 1.609, Train_accy 44.74
2022-09-28 01:46:22,934 [foster.py] => Task 4, Epoch 8/34 => Loss 3.705, Loss_clf 0.734, Loss_fe 1.061, Loss_kd 1.609, Train_accy 47.72
2022-09-28 01:46:24,941 [foster.py] => Task 4, Epoch 9/34 => Loss 3.656, Loss_clf 0.721, Loss_fe 1.033, Loss_kd 1.601, Train_accy 45.70
2022-09-28 01:46:26,935 [foster.py] => Task 4, Epoch 10/34 => Loss 3.597, Loss_clf 0.713, Loss_fe 0.976, Loss_kd 1.607, Train_accy 50.69
2022-09-28 01:46:29,943 [foster.py] => Task 4, Epoch 11/34 => Loss 3.614, Loss_clf 0.719, Loss_fe 0.986, Loss_kd 1.607, Train_accy 48.99, Test_accy 48.00
2022-09-28 01:46:31,933 [foster.py] => Task 4, Epoch 12/34 => Loss 3.546, Loss_clf 0.706, Loss_fe 0.931, Loss_kd 1.608, Train_accy 47.72
2022-09-28 01:46:33,936 [foster.py] => Task 4, Epoch 13/34 => Loss 3.526, Loss_clf 0.692, Loss_fe 0.912, Loss_kd 1.618, Train_accy 51.54
2022-09-28 01:46:35,953 [foster.py] => Task 4, Epoch 14/34 => Loss 3.457, Loss_clf 0.669, Loss_fe 0.881, Loss_kd 1.606, Train_accy 51.01
2022-09-28 01:46:37,974 [foster.py] => Task 4, Epoch 15/34 => Loss 3.466, Loss_clf 0.677, Loss_fe 0.880, Loss_kd 1.608, Train_accy 50.80
2022-09-28 01:46:40,920 [foster.py] => Task 4, Epoch 16/34 => Loss 3.421, Loss_clf 0.663, Loss_fe 0.847, Loss_kd 1.609, Train_accy 51.65, Test_accy 49.18
2022-09-28 01:46:42,902 [foster.py] => Task 4, Epoch 17/34 => Loss 3.384, Loss_clf 0.654, Loss_fe 0.818, Loss_kd 1.610, Train_accy 48.46
2022-09-28 01:46:44,895 [foster.py] => Task 4, Epoch 18/34 => Loss 3.390, Loss_clf 0.653, Loss_fe 0.824, Loss_kd 1.611, Train_accy 52.39
2022-09-28 01:46:46,888 [foster.py] => Task 4, Epoch 19/34 => Loss 3.328, Loss_clf 0.632, Loss_fe 0.788, Loss_kd 1.608, Train_accy 51.75
2022-09-28 01:46:48,871 [foster.py] => Task 4, Epoch 20/34 => Loss 3.349, Loss_clf 0.641, Loss_fe 0.796, Loss_kd 1.610, Train_accy 49.20
2022-09-28 01:46:51,788 [foster.py] => Task 4, Epoch 21/34 => Loss 3.317, Loss_clf 0.626, Loss_fe 0.779, Loss_kd 1.610, Train_accy 51.75, Test_accy 50.59
2022-09-28 01:46:53,796 [foster.py] => Task 4, Epoch 22/34 => Loss 3.298, Loss_clf 0.627, Loss_fe 0.767, Loss_kd 1.603, Train_accy 52.71
2022-09-28 01:46:55,839 [foster.py] => Task 4, Epoch 23/34 => Loss 3.300, Loss_clf 0.623, Loss_fe 0.760, Loss_kd 1.614, Train_accy 53.99
2022-09-28 01:46:57,816 [foster.py] => Task 4, Epoch 24/34 => Loss 3.312, Loss_clf 0.625, Loss_fe 0.774, Loss_kd 1.610, Train_accy 54.52
2022-09-28 01:46:59,811 [foster.py] => Task 4, Epoch 25/34 => Loss 3.272, Loss_clf 0.614, Loss_fe 0.745, Loss_kd 1.611, Train_accy 51.22
2022-09-28 01:47:02,793 [foster.py] => Task 4, Epoch 26/34 => Loss 3.249, Loss_clf 0.602, Loss_fe 0.736, Loss_kd 1.609, Train_accy 53.24, Test_accy 50.59
2022-09-28 01:47:04,790 [foster.py] => Task 4, Epoch 27/34 => Loss 3.277, Loss_clf 0.620, Loss_fe 0.749, Loss_kd 1.606, Train_accy 52.82
2022-09-28 01:47:06,826 [foster.py] => Task 4, Epoch 28/34 => Loss 3.264, Loss_clf 0.610, Loss_fe 0.741, Loss_kd 1.612, Train_accy 52.50
2022-09-28 01:47:08,865 [foster.py] => Task 4, Epoch 29/34 => Loss 3.261, Loss_clf 0.613, Loss_fe 0.736, Loss_kd 1.610, Train_accy 52.50
2022-09-28 01:47:10,851 [foster.py] => Task 4, Epoch 30/34 => Loss 3.269, Loss_clf 0.616, Loss_fe 0.742, Loss_kd 1.610, Train_accy 54.30
2022-09-28 01:47:13,772 [foster.py] => Task 4, Epoch 31/34 => Loss 3.263, Loss_clf 0.611, Loss_fe 0.749, Loss_kd 1.602, Train_accy 52.18, Test_accy 50.35
2022-09-28 01:47:15,790 [foster.py] => Task 4, Epoch 32/34 => Loss 3.264, Loss_clf 0.606, Loss_fe 0.740, Loss_kd 1.616, Train_accy 50.69
2022-09-28 01:47:17,830 [foster.py] => Task 4, Epoch 33/34 => Loss 3.282, Loss_clf 0.626, Loss_fe 0.745, Loss_kd 1.609, Train_accy 51.65
2022-09-28 01:47:19,848 [foster.py] => Task 4, Epoch 34/34 => Loss 3.287, Loss_clf 0.621, Loss_fe 0.757, Loss_kd 1.608, Train_accy 52.39
2022-09-28 01:47:19,848 [foster.py] => do not weight align teacher!
2022-09-28 01:47:19,849 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 01:47:23,100 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.282,  Train_accy 19.23, Test_accy 37.18
2022-09-28 01:47:25,379 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.234,  Train_accy 19.34
2022-09-28 01:47:27,607 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.206,  Train_accy 19.13
2022-09-28 01:47:29,852 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.202,  Train_accy 19.87
2022-09-28 01:47:32,115 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.188,  Train_accy 19.55
2022-09-28 01:47:35,181 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.178,  Train_accy 19.13, Test_accy 40.00
2022-09-28 01:47:37,448 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.169,  Train_accy 20.19
2022-09-28 01:47:39,693 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.160,  Train_accy 19.98
2022-09-28 01:47:41,955 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.152,  Train_accy 19.98
2022-09-28 01:47:44,221 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.163,  Train_accy 20.09
2022-09-28 01:47:47,323 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.146,  Train_accy 20.19, Test_accy 39.06
2022-09-28 01:47:49,592 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.159,  Train_accy 19.34
2022-09-28 01:47:51,881 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.149,  Train_accy 19.98
2022-09-28 01:47:54,133 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.145,  Train_accy 19.77
2022-09-28 01:47:56,358 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.148,  Train_accy 20.51
2022-09-28 01:47:59,421 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.151,  Train_accy 20.40, Test_accy 39.53
2022-09-28 01:48:01,689 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.154,  Train_accy 19.87
2022-09-28 01:48:03,955 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.142,  Train_accy 21.25
2022-09-28 01:48:06,180 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.146,  Train_accy 20.72
2022-09-28 01:48:08,434 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.149,  Train_accy 20.94
2022-09-28 01:48:11,477 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.135,  Train_accy 20.72, Test_accy 39.76
2022-09-28 01:48:13,754 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.139,  Train_accy 20.51
2022-09-28 01:48:16,016 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.149,  Train_accy 20.30
2022-09-28 01:48:18,293 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.135,  Train_accy 20.19
2022-09-28 01:48:20,566 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.143,  Train_accy 20.94
2022-09-28 01:48:23,620 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.148,  Train_accy 21.04, Test_accy 40.00
2022-09-28 01:48:23,620 [foster.py] => do not weight align student!
2022-09-28 01:48:24,419 [foster.py] => darknet eval: 
2022-09-28 01:48:24,419 [foster.py] => CNN top1 curve: 40.0
2022-09-28 01:48:24,419 [foster.py] => CNN top5 curve: 88.0
2022-09-28 01:48:24,420 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 01:48:33,939 [foster.py] => Exemplar size: 380
2022-09-28 01:48:33,940 [trainer.py] => CNN: {'total': 50.12, 'old': 52.37, 'new': 37.88, 'base': 68.46, 'compound': 40.22}
2022-09-28 01:48:33,940 [trainer.py] => CNN top1 curve: [85.23, 72.57, 59.39, 50.97, 50.12]
2022-09-28 01:48:33,940 [trainer.py] => CNN base curve: [85.23, 84.56, 77.85, 73.15, 68.46]
2022-09-28 01:48:33,940 [trainer.py] => CNN old curve: [85.23, 84.56, 69.03, 55.97, 52.37]
2022-09-28 01:48:33,940 [trainer.py] => CNN new curve: [0, 49.35, 26.87, 28.79, 37.88]
2022-09-28 01:48:33,940 [trainer.py] => CNN compound curve: [0, 49.35, 40.28, 35.24, 40.22]
2022-09-28 01:48:33,940 [trainer.py] => NME: {'total': 56.94, 'old': 56.27, 'new': 60.61, 'base': 63.09, 'compound': 53.62}
2022-09-28 01:48:33,940 [trainer.py] => NME top1 curve: [85.23, 76.11, 66.89, 59.33, 56.94]
2022-09-28 01:48:33,940 [trainer.py] => NME base curve: [85.23, 81.21, 73.15, 65.77, 63.09]
2022-09-28 01:48:33,940 [trainer.py] => NME old curve: [85.23, 81.21, 68.58, 60.41, 56.27]
2022-09-28 01:48:33,940 [trainer.py] => NME new curve: [0, 66.23, 61.19, 54.55, 60.61]
2022-09-28 01:48:33,940 [trainer.py] => NME compound curve: [0, 66.23, 60.42, 54.76, 53.62]
2022-09-28 01:48:34,171 [foster.py] => Learning on 19-22
2022-09-28 01:48:34,172 [foster.py] => All params: 22396607
2022-09-28 01:48:34,172 [foster.py] => Trainable params: 11210348
2022-09-28 01:48:34,192 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 01:48:37,304 [foster.py] => Task 5, Epoch 1/34 => Loss 6.808, Loss_clf 1.973, Loss_fe 2.597, Loss_kd 1.933, Train_accy 37.55, Test_accy 41.47
2022-09-28 01:48:39,390 [foster.py] => Task 5, Epoch 2/34 => Loss 5.251, Loss_clf 1.111, Loss_fe 1.895, Loss_kd 1.939, Train_accy 38.06
2022-09-28 01:48:41,486 [foster.py] => Task 5, Epoch 3/34 => Loss 4.949, Loss_clf 1.022, Loss_fe 1.699, Loss_kd 1.925, Train_accy 41.60
2022-09-28 01:48:43,594 [foster.py] => Task 5, Epoch 4/34 => Loss 4.765, Loss_clf 0.982, Loss_fe 1.559, Loss_kd 1.921, Train_accy 41.90
2022-09-28 01:48:45,670 [foster.py] => Task 5, Epoch 5/34 => Loss 4.667, Loss_clf 0.957, Loss_fe 1.472, Loss_kd 1.932, Train_accy 44.13
2022-09-28 01:48:48,770 [foster.py] => Task 5, Epoch 6/34 => Loss 4.563, Loss_clf 0.928, Loss_fe 1.410, Loss_kd 1.922, Train_accy 43.32, Test_accy 46.63
2022-09-28 01:48:50,947 [foster.py] => Task 5, Epoch 7/34 => Loss 4.490, Loss_clf 0.923, Loss_fe 1.328, Loss_kd 1.934, Train_accy 46.86
2022-09-28 01:48:53,009 [foster.py] => Task 5, Epoch 8/34 => Loss 4.426, Loss_clf 0.910, Loss_fe 1.281, Loss_kd 1.930, Train_accy 44.03
2022-09-28 01:48:55,112 [foster.py] => Task 5, Epoch 9/34 => Loss 4.340, Loss_clf 0.879, Loss_fe 1.225, Loss_kd 1.931, Train_accy 46.76
2022-09-28 01:48:57,228 [foster.py] => Task 5, Epoch 10/34 => Loss 4.293, Loss_clf 0.872, Loss_fe 1.188, Loss_kd 1.928, Train_accy 44.94
2022-09-28 01:49:00,390 [foster.py] => Task 5, Epoch 11/34 => Loss 4.233, Loss_clf 0.843, Loss_fe 1.148, Loss_kd 1.936, Train_accy 47.37, Test_accy 47.42
2022-09-28 01:49:02,478 [foster.py] => Task 5, Epoch 12/34 => Loss 4.149, Loss_clf 0.821, Loss_fe 1.088, Loss_kd 1.935, Train_accy 45.45
2022-09-28 01:49:04,579 [foster.py] => Task 5, Epoch 13/34 => Loss 4.152, Loss_clf 0.822, Loss_fe 1.081, Loss_kd 1.943, Train_accy 48.08
2022-09-28 01:49:06,704 [foster.py] => Task 5, Epoch 14/34 => Loss 4.074, Loss_clf 0.798, Loss_fe 1.040, Loss_kd 1.931, Train_accy 46.66
2022-09-28 01:49:08,792 [foster.py] => Task 5, Epoch 15/34 => Loss 4.064, Loss_clf 0.800, Loss_fe 1.029, Loss_kd 1.930, Train_accy 46.96
2022-09-28 01:49:12,001 [foster.py] => Task 5, Epoch 16/34 => Loss 4.046, Loss_clf 0.786, Loss_fe 1.020, Loss_kd 1.935, Train_accy 47.98, Test_accy 47.82
2022-09-28 01:49:14,092 [foster.py] => Task 5, Epoch 17/34 => Loss 3.999, Loss_clf 0.773, Loss_fe 0.989, Loss_kd 1.933, Train_accy 48.08
2022-09-28 01:49:16,259 [foster.py] => Task 5, Epoch 18/34 => Loss 3.986, Loss_clf 0.775, Loss_fe 0.973, Loss_kd 1.933, Train_accy 47.77
2022-09-28 01:49:18,467 [foster.py] => Task 5, Epoch 19/34 => Loss 3.959, Loss_clf 0.758, Loss_fe 0.953, Loss_kd 1.941, Train_accy 50.51
2022-09-28 01:49:20,671 [foster.py] => Task 5, Epoch 20/34 => Loss 3.921, Loss_clf 0.747, Loss_fe 0.934, Loss_kd 1.934, Train_accy 49.29
2022-09-28 01:49:23,990 [foster.py] => Task 5, Epoch 21/34 => Loss 3.925, Loss_clf 0.750, Loss_fe 0.930, Loss_kd 1.938, Train_accy 48.68, Test_accy 48.81
2022-09-28 01:49:26,217 [foster.py] => Task 5, Epoch 22/34 => Loss 3.872, Loss_clf 0.730, Loss_fe 0.908, Loss_kd 1.930, Train_accy 50.30
2022-09-28 01:49:28,390 [foster.py] => Task 5, Epoch 23/34 => Loss 3.918, Loss_clf 0.744, Loss_fe 0.924, Loss_kd 1.943, Train_accy 48.28
2022-09-28 01:49:30,563 [foster.py] => Task 5, Epoch 24/34 => Loss 3.896, Loss_clf 0.733, Loss_fe 0.916, Loss_kd 1.941, Train_accy 48.89
2022-09-28 01:49:32,764 [foster.py] => Task 5, Epoch 25/34 => Loss 3.859, Loss_clf 0.723, Loss_fe 0.890, Loss_kd 1.939, Train_accy 50.20
2022-09-28 01:49:36,027 [foster.py] => Task 5, Epoch 26/34 => Loss 3.838, Loss_clf 0.716, Loss_fe 0.887, Loss_kd 1.930, Train_accy 51.21, Test_accy 49.21
2022-09-28 01:49:38,197 [foster.py] => Task 5, Epoch 27/34 => Loss 3.828, Loss_clf 0.714, Loss_fe 0.883, Loss_kd 1.927, Train_accy 49.39
2022-09-28 01:49:40,415 [foster.py] => Task 5, Epoch 28/34 => Loss 3.835, Loss_clf 0.712, Loss_fe 0.875, Loss_kd 1.942, Train_accy 50.10
2022-09-28 01:49:42,636 [foster.py] => Task 5, Epoch 29/34 => Loss 3.852, Loss_clf 0.722, Loss_fe 0.885, Loss_kd 1.939, Train_accy 50.00
2022-09-28 01:49:44,836 [foster.py] => Task 5, Epoch 30/34 => Loss 3.841, Loss_clf 0.716, Loss_fe 0.879, Loss_kd 1.940, Train_accy 50.20
2022-09-28 01:49:48,172 [foster.py] => Task 5, Epoch 31/34 => Loss 3.830, Loss_clf 0.708, Loss_fe 0.873, Loss_kd 1.942, Train_accy 51.42, Test_accy 48.81
2022-09-28 01:49:50,365 [foster.py] => Task 5, Epoch 32/34 => Loss 3.855, Loss_clf 0.706, Loss_fe 0.891, Loss_kd 1.950, Train_accy 51.32
2022-09-28 01:49:52,543 [foster.py] => Task 5, Epoch 33/34 => Loss 3.865, Loss_clf 0.731, Loss_fe 0.885, Loss_kd 1.942, Train_accy 52.02
2022-09-28 01:49:54,763 [foster.py] => Task 5, Epoch 34/34 => Loss 3.860, Loss_clf 0.723, Loss_fe 0.891, Loss_kd 1.939, Train_accy 50.51
2022-09-28 01:49:54,764 [foster.py] => do not weight align teacher!
2022-09-28 01:49:54,764 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 01:49:58,230 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.441,  Train_accy 19.43, Test_accy 34.52
2022-09-28 01:50:00,545 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.422,  Train_accy 19.23
2022-09-28 01:50:02,888 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.423,  Train_accy 20.34
2022-09-28 01:50:05,243 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.404,  Train_accy 20.85
2022-09-28 01:50:07,619 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.404,  Train_accy 20.45
2022-09-28 01:50:10,835 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.403,  Train_accy 20.04, Test_accy 36.71
2022-09-28 01:50:13,142 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.401,  Train_accy 20.45
2022-09-28 01:50:15,482 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.395,  Train_accy 20.75
2022-09-28 01:50:17,826 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.393,  Train_accy 20.24
2022-09-28 01:50:20,177 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.390,  Train_accy 20.55
2022-09-28 01:50:23,344 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.386,  Train_accy 21.76, Test_accy 36.71
2022-09-28 01:50:25,711 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.389,  Train_accy 20.04
2022-09-28 01:50:28,018 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.387,  Train_accy 20.75
2022-09-28 01:50:30,409 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.378,  Train_accy 20.65
2022-09-28 01:50:32,724 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.384,  Train_accy 20.34
2022-09-28 01:50:35,936 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.377,  Train_accy 21.56, Test_accy 37.50
2022-09-28 01:50:38,249 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.377,  Train_accy 21.66
2022-09-28 01:50:40,611 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.378,  Train_accy 21.66
2022-09-28 01:50:43,005 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.378,  Train_accy 21.46
2022-09-28 01:50:45,412 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.373,  Train_accy 20.95
2022-09-28 01:50:48,607 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.389,  Train_accy 21.46, Test_accy 37.70
2022-09-28 01:50:50,933 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.381,  Train_accy 21.76
2022-09-28 01:50:53,285 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.380,  Train_accy 21.96
2022-09-28 01:50:55,609 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.387,  Train_accy 21.66
2022-09-28 01:50:57,947 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.374,  Train_accy 21.26
2022-09-28 01:51:01,158 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.380,  Train_accy 21.05, Test_accy 38.69
2022-09-28 01:51:01,158 [foster.py] => do not weight align student!
2022-09-28 01:51:01,997 [foster.py] => darknet eval: 
2022-09-28 01:51:01,997 [foster.py] => CNN top1 curve: 38.69
2022-09-28 01:51:01,998 [foster.py] => CNN top5 curve: 82.54
2022-09-28 01:51:01,998 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 01:51:12,706 [foster.py] => Exemplar size: 440
2022-09-28 01:51:12,706 [trainer.py] => CNN: {'total': 49.01, 'old': 48.94, 'new': 49.37, 'base': 65.1, 'compound': 42.25}
2022-09-28 01:51:12,706 [trainer.py] => CNN top1 curve: [85.23, 72.57, 59.39, 50.97, 50.12, 49.01]
2022-09-28 01:51:12,706 [trainer.py] => CNN base curve: [85.23, 84.56, 77.85, 73.15, 68.46, 65.1]
2022-09-28 01:51:12,706 [trainer.py] => CNN old curve: [85.23, 84.56, 69.03, 55.97, 52.37, 48.94]
2022-09-28 01:51:12,706 [trainer.py] => CNN new curve: [0, 49.35, 26.87, 28.79, 37.88, 49.37]
2022-09-28 01:51:12,706 [trainer.py] => CNN compound curve: [0, 49.35, 40.28, 35.24, 40.22, 42.25]
2022-09-28 01:51:12,706 [trainer.py] => NME: {'total': 54.37, 'old': 55.76, 'new': 46.84, 'base': 65.1, 'compound': 49.86}
2022-09-28 01:51:12,706 [trainer.py] => NME top1 curve: [85.23, 76.11, 66.89, 59.33, 56.94, 54.37]
2022-09-28 01:51:12,706 [trainer.py] => NME base curve: [85.23, 81.21, 73.15, 65.77, 63.09, 65.1]
2022-09-28 01:51:12,706 [trainer.py] => NME old curve: [85.23, 81.21, 68.58, 60.41, 56.27, 55.76]
2022-09-28 01:51:12,706 [trainer.py] => NME new curve: [0, 66.23, 61.19, 54.55, 60.61, 46.84]
2022-09-28 01:51:12,706 [trainer.py] => NME compound curve: [0, 66.23, 60.42, 54.76, 53.62, 49.86]
2022-09-28 01:51:12,707 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 01:51:12,707 [trainer.py] => prefix: cil
2022-09-28 01:51:12,708 [trainer.py] => dataset: CFEE
2022-09-28 01:51:12,708 [trainer.py] => memory_size: 2000
2022-09-28 01:51:12,708 [trainer.py] => memory_per_class: 20
2022-09-28 01:51:12,708 [trainer.py] => fixed_memory: True
2022-09-28 01:51:12,708 [trainer.py] => shuffle: True
2022-09-28 01:51:12,708 [trainer.py] => init_cls: 7
2022-09-28 01:51:12,708 [trainer.py] => increment: 3
2022-09-28 01:51:12,708 [trainer.py] => model_name: foster
2022-09-28 01:51:12,708 [trainer.py] => convnet_type: resnet18
2022-09-28 01:51:12,708 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 01:51:12,708 [trainer.py] => seed: 1993
2022-09-28 01:51:12,708 [trainer.py] => beta1: 0.96
2022-09-28 01:51:12,708 [trainer.py] => beta2: 0.97
2022-09-28 01:51:12,708 [trainer.py] => oofc: ft
2022-09-28 01:51:12,708 [trainer.py] => is_teacher_wa: False
2022-09-28 01:51:12,708 [trainer.py] => is_student_wa: False
2022-09-28 01:51:12,708 [trainer.py] => lambda_okd: 1
2022-09-28 01:51:12,708 [trainer.py] => wa_value: 1
2022-09-28 01:51:12,708 [trainer.py] => init_epochs: 40
2022-09-28 01:51:12,708 [trainer.py] => init_lr: 0.01
2022-09-28 01:51:12,708 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 01:51:12,708 [trainer.py] => boosting_epochs: 34
2022-09-28 01:51:12,708 [trainer.py] => compression_epochs: 26
2022-09-28 01:51:12,708 [trainer.py] => lr: 0.001
2022-09-28 01:51:12,708 [trainer.py] => batch_size: 32
2022-09-28 01:51:12,708 [trainer.py] => weight_decay: 0.0005
2022-09-28 01:51:12,708 [trainer.py] => num_workers: 8
2022-09-28 01:51:12,708 [trainer.py] => T: 2
2022-09-28 01:51:12,708 [trainer.py] => nb_runs: 3
2022-09-28 01:51:12,708 [trainer.py] => fold: 10
2022-09-28 01:51:12,709 [data.py] => ========== Fold:8 ==========
2022-09-28 01:51:12,713 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 13, 17, 15, 9, 11, 20, 18, 12, 14, 7, 10, 19, 21, 16, 8]
2022-09-28 01:51:12,926 [foster.py] => Learning on 0-7
2022-09-28 01:51:12,926 [foster.py] => All params: 11183694
2022-09-28 01:51:12,926 [foster.py] => Trainable params: 11183694
2022-09-28 01:51:15,353 [foster.py] => Task 0, Epoch 1/40 => Loss 1.371, Train_accy 48.93
2022-09-28 01:51:18,333 [foster.py] => Task 0, Epoch 2/40 => Loss 0.537, Train_accy 82.06, Test_accy 82.28
2022-09-28 01:51:21,309 [foster.py] => Task 0, Epoch 3/40 => Loss 0.366, Train_accy 87.44, Test_accy 87.34
2022-09-28 01:51:24,301 [foster.py] => Task 0, Epoch 4/40 => Loss 0.291, Train_accy 89.51, Test_accy 87.34
2022-09-28 01:51:27,259 [foster.py] => Task 0, Epoch 5/40 => Loss 0.233, Train_accy 92.27, Test_accy 88.61
2022-09-28 01:51:29,675 [foster.py] => Task 0, Epoch 6/40 => Loss 0.227, Train_accy 91.65
2022-09-28 01:51:32,708 [foster.py] => Task 0, Epoch 7/40 => Loss 0.180, Train_accy 94.27, Test_accy 89.87
2022-09-28 01:51:35,671 [foster.py] => Task 0, Epoch 8/40 => Loss 0.144, Train_accy 95.58, Test_accy 86.08
2022-09-28 01:51:38,675 [foster.py] => Task 0, Epoch 9/40 => Loss 0.110, Train_accy 96.48, Test_accy 87.34
2022-09-28 01:51:41,685 [foster.py] => Task 0, Epoch 10/40 => Loss 0.086, Train_accy 98.07, Test_accy 88.61
2022-09-28 01:51:44,064 [foster.py] => Task 0, Epoch 11/40 => Loss 0.095, Train_accy 97.10
2022-09-28 01:51:47,092 [foster.py] => Task 0, Epoch 12/40 => Loss 0.084, Train_accy 97.45, Test_accy 87.97
2022-09-28 01:51:50,084 [foster.py] => Task 0, Epoch 13/40 => Loss 0.067, Train_accy 97.58, Test_accy 86.08
2022-09-28 01:51:53,087 [foster.py] => Task 0, Epoch 14/40 => Loss 0.051, Train_accy 98.76, Test_accy 87.97
2022-09-28 01:51:56,080 [foster.py] => Task 0, Epoch 15/40 => Loss 0.054, Train_accy 98.14, Test_accy 88.61
2022-09-28 01:51:58,418 [foster.py] => Task 0, Epoch 16/40 => Loss 0.039, Train_accy 98.96
2022-09-28 01:52:01,379 [foster.py] => Task 0, Epoch 17/40 => Loss 0.030, Train_accy 99.52, Test_accy 87.97
2022-09-28 01:52:04,407 [foster.py] => Task 0, Epoch 18/40 => Loss 0.040, Train_accy 99.03, Test_accy 87.97
2022-09-28 01:52:07,408 [foster.py] => Task 0, Epoch 19/40 => Loss 0.037, Train_accy 98.55, Test_accy 89.24
2022-09-28 01:52:10,395 [foster.py] => Task 0, Epoch 20/40 => Loss 0.033, Train_accy 98.90, Test_accy 87.97
2022-09-28 01:52:12,744 [foster.py] => Task 0, Epoch 21/40 => Loss 0.030, Train_accy 99.38
2022-09-28 01:52:15,731 [foster.py] => Task 0, Epoch 22/40 => Loss 0.024, Train_accy 99.65, Test_accy 89.24
2022-09-28 01:52:18,747 [foster.py] => Task 0, Epoch 23/40 => Loss 0.017, Train_accy 99.72, Test_accy 89.24
2022-09-28 01:52:21,779 [foster.py] => Task 0, Epoch 24/40 => Loss 0.020, Train_accy 99.65, Test_accy 89.24
2022-09-28 01:52:24,740 [foster.py] => Task 0, Epoch 25/40 => Loss 0.021, Train_accy 99.31, Test_accy 88.61
2022-09-28 01:52:27,099 [foster.py] => Task 0, Epoch 26/40 => Loss 0.015, Train_accy 99.72
2022-09-28 01:52:30,084 [foster.py] => Task 0, Epoch 27/40 => Loss 0.024, Train_accy 99.59, Test_accy 89.24
2022-09-28 01:52:33,080 [foster.py] => Task 0, Epoch 28/40 => Loss 0.015, Train_accy 99.79, Test_accy 88.61
2022-09-28 01:52:36,105 [foster.py] => Task 0, Epoch 29/40 => Loss 0.014, Train_accy 100.00, Test_accy 88.61
2022-09-28 01:52:39,066 [foster.py] => Task 0, Epoch 30/40 => Loss 0.024, Train_accy 99.59, Test_accy 89.87
2022-09-28 01:52:41,450 [foster.py] => Task 0, Epoch 31/40 => Loss 0.016, Train_accy 99.86
2022-09-28 01:52:44,416 [foster.py] => Task 0, Epoch 32/40 => Loss 0.011, Train_accy 99.79, Test_accy 89.24
2022-09-28 01:52:47,386 [foster.py] => Task 0, Epoch 33/40 => Loss 0.021, Train_accy 99.59, Test_accy 89.24
2022-09-28 01:52:50,394 [foster.py] => Task 0, Epoch 34/40 => Loss 0.013, Train_accy 99.86, Test_accy 89.24
2022-09-28 01:52:53,385 [foster.py] => Task 0, Epoch 35/40 => Loss 0.015, Train_accy 99.93, Test_accy 89.24
2022-09-28 01:52:55,742 [foster.py] => Task 0, Epoch 36/40 => Loss 0.011, Train_accy 99.93
2022-09-28 01:52:58,740 [foster.py] => Task 0, Epoch 37/40 => Loss 0.015, Train_accy 99.93, Test_accy 89.24
2022-09-28 01:53:01,735 [foster.py] => Task 0, Epoch 38/40 => Loss 0.015, Train_accy 99.86, Test_accy 89.87
2022-09-28 01:53:04,738 [foster.py] => Task 0, Epoch 39/40 => Loss 0.012, Train_accy 99.72, Test_accy 89.24
2022-09-28 01:53:07,725 [foster.py] => Task 0, Epoch 40/40 => Loss 0.014, Train_accy 99.79, Test_accy 88.61
2022-09-28 01:53:07,725 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 01:53:14,557 [foster.py] => Exemplar size: 140
2022-09-28 01:53:14,557 [trainer.py] => CNN: {'total': 88.61, 'old': 88.61, 'new': 0, 'base': 88.61, 'compound': 0}
2022-09-28 01:53:14,557 [trainer.py] => CNN top1 curve: [88.61]
2022-09-28 01:53:14,557 [trainer.py] => CNN base curve: [88.61]
2022-09-28 01:53:14,557 [trainer.py] => CNN old curve: [88.61]
2022-09-28 01:53:14,557 [trainer.py] => CNN new curve: [0]
2022-09-28 01:53:14,557 [trainer.py] => CNN compound curve: [0]
2022-09-28 01:53:14,557 [trainer.py] => NME: {'total': 89.87, 'old': 89.87, 'new': 0, 'base': 89.87, 'compound': 0}
2022-09-28 01:53:14,557 [trainer.py] => NME top1 curve: [89.87]
2022-09-28 01:53:14,557 [trainer.py] => NME base curve: [89.87]
2022-09-28 01:53:14,557 [trainer.py] => NME old curve: [89.87]
2022-09-28 01:53:14,557 [trainer.py] => NME new curve: [0]
2022-09-28 01:53:14,557 [trainer.py] => NME compound curve: [0]
2022-09-28 01:53:14,784 [foster.py] => Learning on 7-10
2022-09-28 01:53:14,784 [foster.py] => All params: 22371995
2022-09-28 01:53:14,784 [foster.py] => Trainable params: 11191892
2022-09-28 01:53:14,804 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 01:53:17,245 [foster.py] => Task 1, Epoch 1/34 => Loss 4.836, Loss_clf 2.358, Loss_fe 1.835, Loss_kd 0.450, Train_accy 41.25, Test_accy 67.67
2022-09-28 01:53:18,964 [foster.py] => Task 1, Epoch 2/34 => Loss 2.448, Loss_clf 0.686, Loss_fe 1.115, Loss_kd 0.453, Train_accy 79.18
2022-09-28 01:53:20,719 [foster.py] => Task 1, Epoch 3/34 => Loss 1.943, Loss_clf 0.408, Loss_fe 0.913, Loss_kd 0.436, Train_accy 53.32
2022-09-28 01:53:22,444 [foster.py] => Task 1, Epoch 4/34 => Loss 1.798, Loss_clf 0.371, Loss_fe 0.812, Loss_kd 0.431, Train_accy 51.86
2022-09-28 01:53:24,145 [foster.py] => Task 1, Epoch 5/34 => Loss 1.661, Loss_clf 0.334, Loss_fe 0.718, Loss_kd 0.426, Train_accy 55.04
2022-09-28 01:53:26,622 [foster.py] => Task 1, Epoch 6/34 => Loss 1.607, Loss_clf 0.327, Loss_fe 0.667, Loss_kd 0.429, Train_accy 54.24, Test_accy 70.26
2022-09-28 01:53:28,312 [foster.py] => Task 1, Epoch 7/34 => Loss 1.562, Loss_clf 0.324, Loss_fe 0.626, Loss_kd 0.429, Train_accy 54.24
2022-09-28 01:53:30,057 [foster.py] => Task 1, Epoch 8/34 => Loss 1.483, Loss_clf 0.302, Loss_fe 0.563, Loss_kd 0.432, Train_accy 55.31
2022-09-28 01:53:31,786 [foster.py] => Task 1, Epoch 9/34 => Loss 1.436, Loss_clf 0.287, Loss_fe 0.535, Loss_kd 0.430, Train_accy 54.11
2022-09-28 01:53:33,527 [foster.py] => Task 1, Epoch 10/34 => Loss 1.406, Loss_clf 0.281, Loss_fe 0.517, Loss_kd 0.426, Train_accy 55.17
2022-09-28 01:53:35,995 [foster.py] => Task 1, Epoch 11/34 => Loss 1.368, Loss_clf 0.271, Loss_fe 0.483, Loss_kd 0.430, Train_accy 55.84, Test_accy 69.40
2022-09-28 01:53:37,734 [foster.py] => Task 1, Epoch 12/34 => Loss 1.357, Loss_clf 0.273, Loss_fe 0.462, Loss_kd 0.435, Train_accy 54.91
2022-09-28 01:53:39,466 [foster.py] => Task 1, Epoch 13/34 => Loss 1.300, Loss_clf 0.255, Loss_fe 0.428, Loss_kd 0.432, Train_accy 56.76
2022-09-28 01:53:41,161 [foster.py] => Task 1, Epoch 14/34 => Loss 1.312, Loss_clf 0.257, Loss_fe 0.433, Loss_kd 0.435, Train_accy 55.70
2022-09-28 01:53:42,901 [foster.py] => Task 1, Epoch 15/34 => Loss 1.267, Loss_clf 0.245, Loss_fe 0.418, Loss_kd 0.423, Train_accy 57.16
2022-09-28 01:53:45,380 [foster.py] => Task 1, Epoch 16/34 => Loss 1.248, Loss_clf 0.228, Loss_fe 0.401, Loss_kd 0.433, Train_accy 57.56, Test_accy 69.83
2022-09-28 01:53:47,086 [foster.py] => Task 1, Epoch 17/34 => Loss 1.253, Loss_clf 0.233, Loss_fe 0.402, Loss_kd 0.433, Train_accy 55.44
2022-09-28 01:53:48,819 [foster.py] => Task 1, Epoch 18/34 => Loss 1.217, Loss_clf 0.223, Loss_fe 0.374, Loss_kd 0.434, Train_accy 57.03
2022-09-28 01:53:50,530 [foster.py] => Task 1, Epoch 19/34 => Loss 1.225, Loss_clf 0.228, Loss_fe 0.377, Loss_kd 0.434, Train_accy 57.16
2022-09-28 01:53:52,279 [foster.py] => Task 1, Epoch 20/34 => Loss 1.205, Loss_clf 0.219, Loss_fe 0.377, Loss_kd 0.426, Train_accy 56.76
2022-09-28 01:53:54,721 [foster.py] => Task 1, Epoch 21/34 => Loss 1.197, Loss_clf 0.217, Loss_fe 0.364, Loss_kd 0.431, Train_accy 57.03, Test_accy 69.83
2022-09-28 01:53:56,430 [foster.py] => Task 1, Epoch 22/34 => Loss 1.196, Loss_clf 0.213, Loss_fe 0.360, Loss_kd 0.436, Train_accy 57.43
2022-09-28 01:53:58,129 [foster.py] => Task 1, Epoch 23/34 => Loss 1.136, Loss_clf 0.199, Loss_fe 0.337, Loss_kd 0.420, Train_accy 58.09
2022-09-28 01:53:59,842 [foster.py] => Task 1, Epoch 24/34 => Loss 1.198, Loss_clf 0.225, Loss_fe 0.369, Loss_kd 0.423, Train_accy 56.10
2022-09-28 01:54:01,553 [foster.py] => Task 1, Epoch 25/34 => Loss 1.182, Loss_clf 0.216, Loss_fe 0.355, Loss_kd 0.428, Train_accy 57.03
2022-09-28 01:54:03,985 [foster.py] => Task 1, Epoch 26/34 => Loss 1.161, Loss_clf 0.206, Loss_fe 0.347, Loss_kd 0.425, Train_accy 56.37, Test_accy 69.83
2022-09-28 01:54:05,719 [foster.py] => Task 1, Epoch 27/34 => Loss 1.154, Loss_clf 0.203, Loss_fe 0.339, Loss_kd 0.428, Train_accy 58.09
2022-09-28 01:54:07,418 [foster.py] => Task 1, Epoch 28/34 => Loss 1.162, Loss_clf 0.207, Loss_fe 0.341, Loss_kd 0.430, Train_accy 56.23
2022-09-28 01:54:09,137 [foster.py] => Task 1, Epoch 29/34 => Loss 1.144, Loss_clf 0.203, Loss_fe 0.334, Loss_kd 0.425, Train_accy 57.56
2022-09-28 01:54:10,881 [foster.py] => Task 1, Epoch 30/34 => Loss 1.180, Loss_clf 0.212, Loss_fe 0.352, Loss_kd 0.431, Train_accy 57.96
2022-09-28 01:54:13,364 [foster.py] => Task 1, Epoch 31/34 => Loss 1.134, Loss_clf 0.199, Loss_fe 0.327, Loss_kd 0.425, Train_accy 56.23, Test_accy 69.83
2022-09-28 01:54:15,109 [foster.py] => Task 1, Epoch 32/34 => Loss 1.155, Loss_clf 0.200, Loss_fe 0.335, Loss_kd 0.433, Train_accy 58.89
2022-09-28 01:54:16,842 [foster.py] => Task 1, Epoch 33/34 => Loss 1.149, Loss_clf 0.207, Loss_fe 0.337, Loss_kd 0.424, Train_accy 57.96
2022-09-28 01:54:18,547 [foster.py] => Task 1, Epoch 34/34 => Loss 1.141, Loss_clf 0.199, Loss_fe 0.329, Loss_kd 0.429, Train_accy 56.76
2022-09-28 01:54:18,547 [foster.py] => do not weight align teacher!
2022-09-28 01:54:18,548 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 01:54:21,327 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.513,  Train_accy 17.90, Test_accy 59.05
2022-09-28 01:54:23,256 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.390,  Train_accy 18.17
2022-09-28 01:54:25,204 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.311,  Train_accy 19.10
2022-09-28 01:54:27,097 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.260,  Train_accy 21.88
2022-09-28 01:54:29,014 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.237,  Train_accy 24.27
2022-09-28 01:54:31,648 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.214,  Train_accy 27.59, Test_accy 62.07
2022-09-28 01:54:33,585 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.201,  Train_accy 26.92
2022-09-28 01:54:35,546 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.188,  Train_accy 29.05
2022-09-28 01:54:37,482 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.178,  Train_accy 30.11
2022-09-28 01:54:39,419 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.171,  Train_accy 30.64
2022-09-28 01:54:42,095 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.184,  Train_accy 30.64, Test_accy 65.09
2022-09-28 01:54:44,025 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.167,  Train_accy 31.17
2022-09-28 01:54:45,936 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.182,  Train_accy 32.63
2022-09-28 01:54:47,851 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.152,  Train_accy 33.95
2022-09-28 01:54:49,759 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.166,  Train_accy 33.29
2022-09-28 01:54:52,411 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.161,  Train_accy 33.95, Test_accy 66.38
2022-09-28 01:54:54,316 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.156,  Train_accy 34.08
2022-09-28 01:54:56,276 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.152,  Train_accy 32.49
2022-09-28 01:54:58,216 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.145,  Train_accy 32.36
2022-09-28 01:55:00,120 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.158,  Train_accy 34.75
2022-09-28 01:55:02,750 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.159,  Train_accy 35.54, Test_accy 66.38
2022-09-28 01:55:04,652 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.150,  Train_accy 34.75
2022-09-28 01:55:06,593 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.140,  Train_accy 32.76
2022-09-28 01:55:08,483 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.143,  Train_accy 33.02
2022-09-28 01:55:10,416 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.163,  Train_accy 33.82
2022-09-28 01:55:12,997 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.153,  Train_accy 34.48, Test_accy 66.38
2022-09-28 01:55:12,998 [foster.py] => do not weight align student!
2022-09-28 01:55:13,684 [foster.py] => darknet eval: 
2022-09-28 01:55:13,684 [foster.py] => CNN top1 curve: 66.38
2022-09-28 01:55:13,684 [foster.py] => CNN top5 curve: 98.28
2022-09-28 01:55:13,684 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 01:55:20,094 [foster.py] => Exemplar size: 200
2022-09-28 01:55:20,094 [trainer.py] => CNN: {'total': 69.83, 'old': 86.71, 'new': 33.78, 'base': 86.71, 'compound': 33.78}
2022-09-28 01:55:20,094 [trainer.py] => CNN top1 curve: [88.61, 69.83]
2022-09-28 01:55:20,094 [trainer.py] => CNN base curve: [88.61, 86.71]
2022-09-28 01:55:20,094 [trainer.py] => CNN old curve: [88.61, 86.71]
2022-09-28 01:55:20,094 [trainer.py] => CNN new curve: [0, 33.78]
2022-09-28 01:55:20,094 [trainer.py] => CNN compound curve: [0, 33.78]
2022-09-28 01:55:20,094 [trainer.py] => NME: {'total': 78.88, 'old': 83.54, 'new': 68.92, 'base': 83.54, 'compound': 68.92}
2022-09-28 01:55:20,094 [trainer.py] => NME top1 curve: [89.87, 78.88]
2022-09-28 01:55:20,094 [trainer.py] => NME base curve: [89.87, 83.54]
2022-09-28 01:55:20,094 [trainer.py] => NME old curve: [89.87, 83.54]
2022-09-28 01:55:20,094 [trainer.py] => NME new curve: [0, 68.92]
2022-09-28 01:55:20,094 [trainer.py] => NME compound curve: [0, 68.92]
2022-09-28 01:55:20,324 [foster.py] => Learning on 10-13
2022-09-28 01:55:20,324 [foster.py] => All params: 22378148
2022-09-28 01:55:20,325 [foster.py] => Trainable params: 11196506
2022-09-28 01:55:20,345 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 01:55:22,995 [foster.py] => Task 2, Epoch 1/34 => Loss 5.333, Loss_clf 2.450, Loss_fe 1.820, Loss_kd 0.818, Train_accy 39.26, Test_accy 44.26
2022-09-28 01:55:24,805 [foster.py] => Task 2, Epoch 2/34 => Loss 3.328, Loss_clf 0.934, Loss_fe 1.330, Loss_kd 0.818, Train_accy 53.74
2022-09-28 01:55:26,676 [foster.py] => Task 2, Epoch 3/34 => Loss 2.964, Loss_clf 0.766, Loss_fe 1.163, Loss_kd 0.796, Train_accy 37.79
2022-09-28 01:55:28,488 [foster.py] => Task 2, Epoch 4/34 => Loss 2.744, Loss_clf 0.667, Loss_fe 1.055, Loss_kd 0.787, Train_accy 41.96
2022-09-28 01:55:30,336 [foster.py] => Task 2, Epoch 5/34 => Loss 2.655, Loss_clf 0.652, Loss_fe 0.979, Loss_kd 0.787, Train_accy 42.21
2022-09-28 01:55:32,989 [foster.py] => Task 2, Epoch 6/34 => Loss 2.562, Loss_clf 0.601, Loss_fe 0.923, Loss_kd 0.798, Train_accy 43.31, Test_accy 59.67
2022-09-28 01:55:34,821 [foster.py] => Task 2, Epoch 7/34 => Loss 2.445, Loss_clf 0.568, Loss_fe 0.848, Loss_kd 0.791, Train_accy 43.07
2022-09-28 01:55:36,625 [foster.py] => Task 2, Epoch 8/34 => Loss 2.410, Loss_clf 0.556, Loss_fe 0.829, Loss_kd 0.788, Train_accy 43.31
2022-09-28 01:55:38,495 [foster.py] => Task 2, Epoch 9/34 => Loss 2.359, Loss_clf 0.556, Loss_fe 0.789, Loss_kd 0.780, Train_accy 41.23
2022-09-28 01:55:40,295 [foster.py] => Task 2, Epoch 10/34 => Loss 2.313, Loss_clf 0.533, Loss_fe 0.753, Loss_kd 0.790, Train_accy 45.77
2022-09-28 01:55:42,939 [foster.py] => Task 2, Epoch 11/34 => Loss 2.285, Loss_clf 0.531, Loss_fe 0.735, Loss_kd 0.784, Train_accy 41.84, Test_accy 59.02
2022-09-28 01:55:44,780 [foster.py] => Task 2, Epoch 12/34 => Loss 2.201, Loss_clf 0.486, Loss_fe 0.678, Loss_kd 0.798, Train_accy 46.63
2022-09-28 01:55:46,583 [foster.py] => Task 2, Epoch 13/34 => Loss 2.180, Loss_clf 0.487, Loss_fe 0.668, Loss_kd 0.788, Train_accy 43.31
2022-09-28 01:55:48,452 [foster.py] => Task 2, Epoch 14/34 => Loss 2.174, Loss_clf 0.479, Loss_fe 0.660, Loss_kd 0.796, Train_accy 46.01
2022-09-28 01:55:50,336 [foster.py] => Task 2, Epoch 15/34 => Loss 2.138, Loss_clf 0.476, Loss_fe 0.645, Loss_kd 0.783, Train_accy 46.87
2022-09-28 01:55:52,973 [foster.py] => Task 2, Epoch 16/34 => Loss 2.111, Loss_clf 0.462, Loss_fe 0.620, Loss_kd 0.791, Train_accy 45.40, Test_accy 60.33
2022-09-28 01:55:54,762 [foster.py] => Task 2, Epoch 17/34 => Loss 2.113, Loss_clf 0.466, Loss_fe 0.630, Loss_kd 0.782, Train_accy 46.01
2022-09-28 01:55:56,553 [foster.py] => Task 2, Epoch 18/34 => Loss 2.074, Loss_clf 0.444, Loss_fe 0.599, Loss_kd 0.793, Train_accy 46.38
2022-09-28 01:55:58,357 [foster.py] => Task 2, Epoch 19/34 => Loss 2.048, Loss_clf 0.448, Loss_fe 0.582, Loss_kd 0.783, Train_accy 44.91
2022-09-28 01:56:00,225 [foster.py] => Task 2, Epoch 20/34 => Loss 2.055, Loss_clf 0.446, Loss_fe 0.591, Loss_kd 0.783, Train_accy 47.48
2022-09-28 01:56:02,804 [foster.py] => Task 2, Epoch 21/34 => Loss 2.010, Loss_clf 0.425, Loss_fe 0.564, Loss_kd 0.785, Train_accy 47.61, Test_accy 61.64
2022-09-28 01:56:04,621 [foster.py] => Task 2, Epoch 22/34 => Loss 2.026, Loss_clf 0.431, Loss_fe 0.563, Loss_kd 0.795, Train_accy 48.71
2022-09-28 01:56:06,417 [foster.py] => Task 2, Epoch 23/34 => Loss 2.032, Loss_clf 0.426, Loss_fe 0.568, Loss_kd 0.798, Train_accy 46.63
2022-09-28 01:56:08,236 [foster.py] => Task 2, Epoch 24/34 => Loss 1.993, Loss_clf 0.415, Loss_fe 0.556, Loss_kd 0.786, Train_accy 46.50
2022-09-28 01:56:10,081 [foster.py] => Task 2, Epoch 25/34 => Loss 2.016, Loss_clf 0.425, Loss_fe 0.563, Loss_kd 0.791, Train_accy 46.26
2022-09-28 01:56:12,667 [foster.py] => Task 2, Epoch 26/34 => Loss 1.989, Loss_clf 0.419, Loss_fe 0.544, Loss_kd 0.789, Train_accy 48.59, Test_accy 60.98
2022-09-28 01:56:14,472 [foster.py] => Task 2, Epoch 27/34 => Loss 1.955, Loss_clf 0.397, Loss_fe 0.544, Loss_kd 0.780, Train_accy 46.87
2022-09-28 01:56:16,300 [foster.py] => Task 2, Epoch 28/34 => Loss 1.966, Loss_clf 0.405, Loss_fe 0.538, Loss_kd 0.787, Train_accy 47.98
2022-09-28 01:56:18,128 [foster.py] => Task 2, Epoch 29/34 => Loss 1.955, Loss_clf 0.401, Loss_fe 0.524, Loss_kd 0.792, Train_accy 47.61
2022-09-28 01:56:19,974 [foster.py] => Task 2, Epoch 30/34 => Loss 1.980, Loss_clf 0.409, Loss_fe 0.536, Loss_kd 0.796, Train_accy 46.13
2022-09-28 01:56:22,612 [foster.py] => Task 2, Epoch 31/34 => Loss 1.954, Loss_clf 0.399, Loss_fe 0.529, Loss_kd 0.789, Train_accy 46.99, Test_accy 60.98
2022-09-28 01:56:24,449 [foster.py] => Task 2, Epoch 32/34 => Loss 1.965, Loss_clf 0.397, Loss_fe 0.528, Loss_kd 0.800, Train_accy 48.71
2022-09-28 01:56:26,239 [foster.py] => Task 2, Epoch 33/34 => Loss 1.973, Loss_clf 0.400, Loss_fe 0.537, Loss_kd 0.796, Train_accy 49.57
2022-09-28 01:56:28,084 [foster.py] => Task 2, Epoch 34/34 => Loss 1.925, Loss_clf 0.381, Loss_fe 0.517, Loss_kd 0.790, Train_accy 46.38
2022-09-28 01:56:28,085 [foster.py] => do not weight align teacher!
2022-09-28 01:56:28,085 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 01:56:31,159 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.760,  Train_accy 17.55, Test_accy 46.89
2022-09-28 01:56:33,213 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.644,  Train_accy 18.28
2022-09-28 01:56:35,273 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.622,  Train_accy 18.40
2022-09-28 01:56:37,332 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.589,  Train_accy 18.40
2022-09-28 01:56:39,370 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.562,  Train_accy 19.14
2022-09-28 01:56:42,168 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.553,  Train_accy 19.88, Test_accy 52.13
2022-09-28 01:56:44,205 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.532,  Train_accy 19.14
2022-09-28 01:56:46,208 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.535,  Train_accy 19.88
2022-09-28 01:56:48,240 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.522,  Train_accy 20.12
2022-09-28 01:56:50,320 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.528,  Train_accy 21.23
2022-09-28 01:56:53,046 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.525,  Train_accy 21.84, Test_accy 52.13
2022-09-28 01:56:55,043 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.515,  Train_accy 20.74
2022-09-28 01:56:57,057 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.511,  Train_accy 20.37
2022-09-28 01:56:59,095 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.498,  Train_accy 20.98
2022-09-28 01:57:01,137 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.504,  Train_accy 21.10
2022-09-28 01:57:03,865 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.508,  Train_accy 21.23, Test_accy 52.46
2022-09-28 01:57:05,899 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.507,  Train_accy 21.47
2022-09-28 01:57:07,948 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.499,  Train_accy 21.72
2022-09-28 01:57:09,986 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.498,  Train_accy 20.98
2022-09-28 01:57:11,985 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.507,  Train_accy 21.72
2022-09-28 01:57:14,758 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.503,  Train_accy 21.35, Test_accy 53.44
2022-09-28 01:57:16,810 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.480,  Train_accy 21.35
2022-09-28 01:57:18,854 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.502,  Train_accy 20.98
2022-09-28 01:57:20,907 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.500,  Train_accy 21.84
2022-09-28 01:57:22,955 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.496,  Train_accy 21.72
2022-09-28 01:57:25,680 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.500,  Train_accy 21.10, Test_accy 53.11
2022-09-28 01:57:25,680 [foster.py] => do not weight align student!
2022-09-28 01:57:26,445 [foster.py] => darknet eval: 
2022-09-28 01:57:26,445 [foster.py] => CNN top1 curve: 53.11
2022-09-28 01:57:26,445 [foster.py] => CNN top5 curve: 97.05
2022-09-28 01:57:26,446 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 01:57:33,830 [foster.py] => Exemplar size: 260
2022-09-28 01:57:33,830 [trainer.py] => CNN: {'total': 60.98, 'old': 68.97, 'new': 35.62, 'base': 81.01, 'compound': 39.46}
2022-09-28 01:57:33,830 [trainer.py] => CNN top1 curve: [88.61, 69.83, 60.98]
2022-09-28 01:57:33,830 [trainer.py] => CNN base curve: [88.61, 86.71, 81.01]
2022-09-28 01:57:33,830 [trainer.py] => CNN old curve: [88.61, 86.71, 68.97]
2022-09-28 01:57:33,830 [trainer.py] => CNN new curve: [0, 33.78, 35.62]
2022-09-28 01:57:33,830 [trainer.py] => CNN compound curve: [0, 33.78, 39.46]
2022-09-28 01:57:33,830 [trainer.py] => NME: {'total': 65.57, 'old': 67.24, 'new': 60.27, 'base': 70.25, 'compound': 60.54}
2022-09-28 01:57:33,830 [trainer.py] => NME top1 curve: [89.87, 78.88, 65.57]
2022-09-28 01:57:33,830 [trainer.py] => NME base curve: [89.87, 83.54, 70.25]
2022-09-28 01:57:33,830 [trainer.py] => NME old curve: [89.87, 83.54, 67.24]
2022-09-28 01:57:33,830 [trainer.py] => NME new curve: [0, 68.92, 60.27]
2022-09-28 01:57:33,830 [trainer.py] => NME compound curve: [0, 68.92, 60.54]
2022-09-28 01:57:34,060 [foster.py] => Learning on 13-16
2022-09-28 01:57:34,060 [foster.py] => All params: 22384301
2022-09-28 01:57:34,060 [foster.py] => Trainable params: 11201120
2022-09-28 01:57:34,080 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 01:57:36,871 [foster.py] => Task 3, Epoch 1/34 => Loss 5.898, Loss_clf 2.043, Loss_fe 2.229, Loss_kd 1.321, Train_accy 38.85, Test_accy 42.19
2022-09-28 01:57:38,752 [foster.py] => Task 3, Epoch 2/34 => Loss 4.307, Loss_clf 1.009, Loss_fe 1.671, Loss_kd 1.322, Train_accy 38.51
2022-09-28 01:57:40,728 [foster.py] => Task 3, Epoch 3/34 => Loss 4.009, Loss_clf 0.915, Loss_fe 1.475, Loss_kd 1.315, Train_accy 38.62
2022-09-28 01:57:42,594 [foster.py] => Task 3, Epoch 4/34 => Loss 3.878, Loss_clf 0.902, Loss_fe 1.356, Loss_kd 1.317, Train_accy 39.20
2022-09-28 01:57:44,501 [foster.py] => Task 3, Epoch 5/34 => Loss 3.749, Loss_clf 0.859, Loss_fe 1.260, Loss_kd 1.324, Train_accy 36.67
2022-09-28 01:57:47,272 [foster.py] => Task 3, Epoch 6/34 => Loss 3.655, Loss_clf 0.838, Loss_fe 1.203, Loss_kd 1.311, Train_accy 38.74, Test_accy 48.96
2022-09-28 01:57:49,209 [foster.py] => Task 3, Epoch 7/34 => Loss 3.520, Loss_clf 0.775, Loss_fe 1.130, Loss_kd 1.312, Train_accy 38.74
2022-09-28 01:57:51,090 [foster.py] => Task 3, Epoch 8/34 => Loss 3.516, Loss_clf 0.798, Loss_fe 1.103, Loss_kd 1.313, Train_accy 37.70
2022-09-28 01:57:52,998 [foster.py] => Task 3, Epoch 9/34 => Loss 3.512, Loss_clf 0.803, Loss_fe 1.071, Loss_kd 1.331, Train_accy 36.78
2022-09-28 01:57:54,879 [foster.py] => Task 3, Epoch 10/34 => Loss 3.350, Loss_clf 0.731, Loss_fe 0.995, Loss_kd 1.319, Train_accy 40.00
2022-09-28 01:57:57,671 [foster.py] => Task 3, Epoch 11/34 => Loss 3.317, Loss_clf 0.724, Loss_fe 0.969, Loss_kd 1.320, Train_accy 39.08, Test_accy 48.96
2022-09-28 01:57:59,602 [foster.py] => Task 3, Epoch 12/34 => Loss 3.355, Loss_clf 0.751, Loss_fe 0.991, Loss_kd 1.310, Train_accy 41.72
2022-09-28 01:58:01,515 [foster.py] => Task 3, Epoch 13/34 => Loss 3.293, Loss_clf 0.737, Loss_fe 0.955, Loss_kd 1.301, Train_accy 38.51
2022-09-28 01:58:03,393 [foster.py] => Task 3, Epoch 14/34 => Loss 3.255, Loss_clf 0.722, Loss_fe 0.914, Loss_kd 1.316, Train_accy 41.03
2022-09-28 01:58:05,320 [foster.py] => Task 3, Epoch 15/34 => Loss 3.256, Loss_clf 0.718, Loss_fe 0.914, Loss_kd 1.320, Train_accy 37.82
2022-09-28 01:58:08,059 [foster.py] => Task 3, Epoch 16/34 => Loss 3.200, Loss_clf 0.703, Loss_fe 0.863, Loss_kd 1.328, Train_accy 42.76, Test_accy 50.26
2022-09-28 01:58:09,971 [foster.py] => Task 3, Epoch 17/34 => Loss 3.130, Loss_clf 0.659, Loss_fe 0.836, Loss_kd 1.328, Train_accy 41.95
2022-09-28 01:58:11,900 [foster.py] => Task 3, Epoch 18/34 => Loss 3.147, Loss_clf 0.679, Loss_fe 0.847, Loss_kd 1.317, Train_accy 41.49
2022-09-28 01:58:13,804 [foster.py] => Task 3, Epoch 19/34 => Loss 3.051, Loss_clf 0.640, Loss_fe 0.792, Loss_kd 1.316, Train_accy 41.26
2022-09-28 01:58:15,690 [foster.py] => Task 3, Epoch 20/34 => Loss 3.036, Loss_clf 0.636, Loss_fe 0.781, Loss_kd 1.316, Train_accy 44.48
2022-09-28 01:58:18,461 [foster.py] => Task 3, Epoch 21/34 => Loss 3.076, Loss_clf 0.662, Loss_fe 0.797, Loss_kd 1.313, Train_accy 44.02, Test_accy 51.04
2022-09-28 01:58:20,382 [foster.py] => Task 3, Epoch 22/34 => Loss 3.109, Loss_clf 0.686, Loss_fe 0.804, Loss_kd 1.315, Train_accy 43.10
2022-09-28 01:58:22,268 [foster.py] => Task 3, Epoch 23/34 => Loss 3.039, Loss_clf 0.634, Loss_fe 0.772, Loss_kd 1.327, Train_accy 44.14
2022-09-28 01:58:24,207 [foster.py] => Task 3, Epoch 24/34 => Loss 2.976, Loss_clf 0.606, Loss_fe 0.737, Loss_kd 1.327, Train_accy 45.63
2022-09-28 01:58:26,098 [foster.py] => Task 3, Epoch 25/34 => Loss 2.978, Loss_clf 0.606, Loss_fe 0.743, Loss_kd 1.324, Train_accy 45.40
2022-09-28 01:58:28,841 [foster.py] => Task 3, Epoch 26/34 => Loss 3.004, Loss_clf 0.615, Loss_fe 0.765, Loss_kd 1.319, Train_accy 46.32, Test_accy 51.30
2022-09-28 01:58:30,754 [foster.py] => Task 3, Epoch 27/34 => Loss 2.997, Loss_clf 0.618, Loss_fe 0.746, Loss_kd 1.327, Train_accy 44.48
2022-09-28 01:58:32,620 [foster.py] => Task 3, Epoch 28/34 => Loss 2.992, Loss_clf 0.627, Loss_fe 0.751, Loss_kd 1.312, Train_accy 44.02
2022-09-28 01:58:34,522 [foster.py] => Task 3, Epoch 29/34 => Loss 2.933, Loss_clf 0.587, Loss_fe 0.729, Loss_kd 1.314, Train_accy 44.71
2022-09-28 01:58:36,423 [foster.py] => Task 3, Epoch 30/34 => Loss 2.998, Loss_clf 0.622, Loss_fe 0.745, Loss_kd 1.326, Train_accy 44.94
2022-09-28 01:58:39,221 [foster.py] => Task 3, Epoch 31/34 => Loss 2.924, Loss_clf 0.592, Loss_fe 0.719, Loss_kd 1.311, Train_accy 45.17, Test_accy 51.30
2022-09-28 01:58:41,156 [foster.py] => Task 3, Epoch 32/34 => Loss 2.955, Loss_clf 0.589, Loss_fe 0.734, Loss_kd 1.326, Train_accy 45.29
2022-09-28 01:58:43,056 [foster.py] => Task 3, Epoch 33/34 => Loss 2.938, Loss_clf 0.580, Loss_fe 0.730, Loss_kd 1.323, Train_accy 46.09
2022-09-28 01:58:44,983 [foster.py] => Task 3, Epoch 34/34 => Loss 2.961, Loss_clf 0.591, Loss_fe 0.751, Loss_kd 1.315, Train_accy 44.94
2022-09-28 01:58:44,983 [foster.py] => do not weight align teacher!
2022-09-28 01:58:44,983 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 01:58:48,215 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.088,  Train_accy 18.16, Test_accy 41.67
2022-09-28 01:58:50,409 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.022,  Train_accy 19.08
2022-09-28 01:58:52,516 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.006,  Train_accy 18.16
2022-09-28 01:58:54,661 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 1.976,  Train_accy 18.39
2022-09-28 01:58:56,869 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.966,  Train_accy 19.20
2022-09-28 01:58:59,795 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.975,  Train_accy 19.54, Test_accy 43.23
2022-09-28 01:59:01,921 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.954,  Train_accy 19.20
2022-09-28 01:59:04,069 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.956,  Train_accy 19.66
2022-09-28 01:59:06,238 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.962,  Train_accy 19.54
2022-09-28 01:59:08,424 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.944,  Train_accy 19.66
2022-09-28 01:59:11,339 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.953,  Train_accy 19.77, Test_accy 43.75
2022-09-28 01:59:13,495 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.938,  Train_accy 19.31
2022-09-28 01:59:15,604 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.937,  Train_accy 19.77
2022-09-28 01:59:17,711 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.958,  Train_accy 20.57
2022-09-28 01:59:19,902 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.928,  Train_accy 19.89
2022-09-28 01:59:22,828 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.945,  Train_accy 20.11, Test_accy 44.01
2022-09-28 01:59:24,974 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.937,  Train_accy 20.11
2022-09-28 01:59:27,097 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.939,  Train_accy 20.46
2022-09-28 01:59:29,267 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.936,  Train_accy 19.89
2022-09-28 01:59:31,363 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.939,  Train_accy 19.66
2022-09-28 01:59:34,239 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.937,  Train_accy 20.11, Test_accy 45.31
2022-09-28 01:59:36,358 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.928,  Train_accy 19.54
2022-09-28 01:59:38,466 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.935,  Train_accy 19.77
2022-09-28 01:59:40,611 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.934,  Train_accy 19.77
2022-09-28 01:59:42,760 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.929,  Train_accy 19.77
2022-09-28 01:59:45,675 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.937,  Train_accy 19.43, Test_accy 44.53
2022-09-28 01:59:45,676 [foster.py] => do not weight align student!
2022-09-28 01:59:46,431 [foster.py] => darknet eval: 
2022-09-28 01:59:46,432 [foster.py] => CNN top1 curve: 44.53
2022-09-28 01:59:46,432 [foster.py] => CNN top5 curve: 90.1
2022-09-28 01:59:46,432 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 01:59:54,914 [foster.py] => Exemplar size: 320
2022-09-28 01:59:54,914 [trainer.py] => CNN: {'total': 52.08, 'old': 57.38, 'new': 31.65, 'base': 79.75, 'compound': 32.74}
2022-09-28 01:59:54,914 [trainer.py] => CNN top1 curve: [88.61, 69.83, 60.98, 52.08]
2022-09-28 01:59:54,914 [trainer.py] => CNN base curve: [88.61, 86.71, 81.01, 79.75]
2022-09-28 01:59:54,914 [trainer.py] => CNN old curve: [88.61, 86.71, 68.97, 57.38]
2022-09-28 01:59:54,914 [trainer.py] => CNN new curve: [0, 33.78, 35.62, 31.65]
2022-09-28 01:59:54,914 [trainer.py] => CNN compound curve: [0, 33.78, 39.46, 32.74]
2022-09-28 01:59:54,914 [trainer.py] => NME: {'total': 57.81, 'old': 61.64, 'new': 43.04, 'base': 68.35, 'compound': 50.44}
2022-09-28 01:59:54,914 [trainer.py] => NME top1 curve: [89.87, 78.88, 65.57, 57.81]
2022-09-28 01:59:54,914 [trainer.py] => NME base curve: [89.87, 83.54, 70.25, 68.35]
2022-09-28 01:59:54,914 [trainer.py] => NME old curve: [89.87, 83.54, 67.24, 61.64]
2022-09-28 01:59:54,914 [trainer.py] => NME new curve: [0, 68.92, 60.27, 43.04]
2022-09-28 01:59:54,914 [trainer.py] => NME compound curve: [0, 68.92, 60.54, 50.44]
2022-09-28 01:59:55,144 [foster.py] => Learning on 16-19
2022-09-28 01:59:55,144 [foster.py] => All params: 22390454
2022-09-28 01:59:55,144 [foster.py] => Trainable params: 11205734
2022-09-28 01:59:55,165 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 01:59:58,128 [foster.py] => Task 4, Epoch 1/34 => Loss 6.342, Loss_clf 2.105, Loss_fe 2.295, Loss_kd 1.635, Train_accy 41.71, Test_accy 41.44
2022-09-28 02:00:00,237 [foster.py] => Task 4, Epoch 2/34 => Loss 4.587, Loss_clf 0.968, Loss_fe 1.663, Loss_kd 1.647, Train_accy 40.87
2022-09-28 02:00:02,277 [foster.py] => Task 4, Epoch 3/34 => Loss 4.275, Loss_clf 0.870, Loss_fe 1.459, Loss_kd 1.639, Train_accy 44.88
2022-09-28 02:00:04,294 [foster.py] => Task 4, Epoch 4/34 => Loss 4.116, Loss_clf 0.840, Loss_fe 1.343, Loss_kd 1.628, Train_accy 44.46
2022-09-28 02:00:06,286 [foster.py] => Task 4, Epoch 5/34 => Loss 4.023, Loss_clf 0.820, Loss_fe 1.260, Loss_kd 1.636, Train_accy 45.09
2022-09-28 02:00:09,210 [foster.py] => Task 4, Epoch 6/34 => Loss 3.961, Loss_clf 0.810, Loss_fe 1.206, Loss_kd 1.638, Train_accy 45.20, Test_accy 45.05
2022-09-28 02:00:11,285 [foster.py] => Task 4, Epoch 7/34 => Loss 3.837, Loss_clf 0.776, Loss_fe 1.121, Loss_kd 1.634, Train_accy 45.41
2022-09-28 02:00:13,280 [foster.py] => Task 4, Epoch 8/34 => Loss 3.752, Loss_clf 0.758, Loss_fe 1.057, Loss_kd 1.631, Train_accy 46.36
2022-09-28 02:00:15,297 [foster.py] => Task 4, Epoch 9/34 => Loss 3.730, Loss_clf 0.741, Loss_fe 1.044, Loss_kd 1.638, Train_accy 47.31
2022-09-28 02:00:17,299 [foster.py] => Task 4, Epoch 10/34 => Loss 3.663, Loss_clf 0.729, Loss_fe 0.992, Loss_kd 1.636, Train_accy 47.94
2022-09-28 02:00:20,226 [foster.py] => Task 4, Epoch 11/34 => Loss 3.617, Loss_clf 0.715, Loss_fe 0.956, Loss_kd 1.639, Train_accy 50.16, Test_accy 46.62
2022-09-28 02:00:22,247 [foster.py] => Task 4, Epoch 12/34 => Loss 3.603, Loss_clf 0.714, Loss_fe 0.945, Loss_kd 1.636, Train_accy 49.42
2022-09-28 02:00:24,313 [foster.py] => Task 4, Epoch 13/34 => Loss 3.553, Loss_clf 0.700, Loss_fe 0.906, Loss_kd 1.640, Train_accy 48.36
2022-09-28 02:00:26,371 [foster.py] => Task 4, Epoch 14/34 => Loss 3.554, Loss_clf 0.701, Loss_fe 0.897, Loss_kd 1.647, Train_accy 46.67
2022-09-28 02:00:28,377 [foster.py] => Task 4, Epoch 15/34 => Loss 3.517, Loss_clf 0.690, Loss_fe 0.887, Loss_kd 1.634, Train_accy 48.15
2022-09-28 02:00:31,304 [foster.py] => Task 4, Epoch 16/34 => Loss 3.481, Loss_clf 0.690, Loss_fe 0.859, Loss_kd 1.627, Train_accy 47.73, Test_accy 49.55
2022-09-28 02:00:33,326 [foster.py] => Task 4, Epoch 17/34 => Loss 3.470, Loss_clf 0.676, Loss_fe 0.843, Loss_kd 1.643, Train_accy 51.32
2022-09-28 02:00:35,400 [foster.py] => Task 4, Epoch 18/34 => Loss 3.425, Loss_clf 0.649, Loss_fe 0.817, Loss_kd 1.650, Train_accy 51.85
2022-09-28 02:00:37,404 [foster.py] => Task 4, Epoch 19/34 => Loss 3.413, Loss_clf 0.649, Loss_fe 0.817, Loss_kd 1.640, Train_accy 48.79
2022-09-28 02:00:39,480 [foster.py] => Task 4, Epoch 20/34 => Loss 3.390, Loss_clf 0.645, Loss_fe 0.788, Loss_kd 1.648, Train_accy 50.58
2022-09-28 02:00:42,412 [foster.py] => Task 4, Epoch 21/34 => Loss 3.381, Loss_clf 0.642, Loss_fe 0.795, Loss_kd 1.637, Train_accy 50.58, Test_accy 49.77
2022-09-28 02:00:44,453 [foster.py] => Task 4, Epoch 22/34 => Loss 3.370, Loss_clf 0.645, Loss_fe 0.786, Loss_kd 1.632, Train_accy 50.48
2022-09-28 02:00:46,439 [foster.py] => Task 4, Epoch 23/34 => Loss 3.345, Loss_clf 0.631, Loss_fe 0.766, Loss_kd 1.640, Train_accy 50.37
2022-09-28 02:00:48,473 [foster.py] => Task 4, Epoch 24/34 => Loss 3.332, Loss_clf 0.621, Loss_fe 0.760, Loss_kd 1.643, Train_accy 51.32
2022-09-28 02:00:50,460 [foster.py] => Task 4, Epoch 25/34 => Loss 3.331, Loss_clf 0.627, Loss_fe 0.758, Loss_kd 1.638, Train_accy 51.95
2022-09-28 02:00:53,401 [foster.py] => Task 4, Epoch 26/34 => Loss 3.336, Loss_clf 0.624, Loss_fe 0.764, Loss_kd 1.641, Train_accy 49.74, Test_accy 49.55
2022-09-28 02:00:55,398 [foster.py] => Task 4, Epoch 27/34 => Loss 3.342, Loss_clf 0.630, Loss_fe 0.754, Loss_kd 1.649, Train_accy 52.38
2022-09-28 02:00:57,408 [foster.py] => Task 4, Epoch 28/34 => Loss 3.310, Loss_clf 0.609, Loss_fe 0.749, Loss_kd 1.644, Train_accy 51.43
2022-09-28 02:00:59,441 [foster.py] => Task 4, Epoch 29/34 => Loss 3.331, Loss_clf 0.621, Loss_fe 0.759, Loss_kd 1.643, Train_accy 49.21
2022-09-28 02:01:01,433 [foster.py] => Task 4, Epoch 30/34 => Loss 3.301, Loss_clf 0.609, Loss_fe 0.745, Loss_kd 1.640, Train_accy 52.16
2022-09-28 02:01:04,351 [foster.py] => Task 4, Epoch 31/34 => Loss 3.318, Loss_clf 0.610, Loss_fe 0.751, Loss_kd 1.649, Train_accy 51.11, Test_accy 49.55
2022-09-28 02:01:06,381 [foster.py] => Task 4, Epoch 32/34 => Loss 3.298, Loss_clf 0.614, Loss_fe 0.745, Loss_kd 1.633, Train_accy 51.32
2022-09-28 02:01:08,414 [foster.py] => Task 4, Epoch 33/34 => Loss 3.282, Loss_clf 0.604, Loss_fe 0.731, Loss_kd 1.639, Train_accy 50.48
2022-09-28 02:01:10,411 [foster.py] => Task 4, Epoch 34/34 => Loss 3.296, Loss_clf 0.609, Loss_fe 0.742, Loss_kd 1.638, Train_accy 50.58
2022-09-28 02:01:10,411 [foster.py] => do not weight align teacher!
2022-09-28 02:01:10,412 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 02:01:13,738 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.305,  Train_accy 18.90, Test_accy 38.51
2022-09-28 02:01:15,985 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.249,  Train_accy 18.80
2022-09-28 02:01:18,265 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.217,  Train_accy 18.80
2022-09-28 02:01:20,533 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.211,  Train_accy 19.22
2022-09-28 02:01:22,831 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.201,  Train_accy 19.32
2022-09-28 02:01:25,938 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.192,  Train_accy 19.96, Test_accy 39.86
2022-09-28 02:01:28,203 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.190,  Train_accy 19.54
2022-09-28 02:01:30,443 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.186,  Train_accy 19.96
2022-09-28 02:01:32,713 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.170,  Train_accy 19.85
2022-09-28 02:01:34,995 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.180,  Train_accy 20.38
2022-09-28 02:01:38,024 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.169,  Train_accy 19.96, Test_accy 40.32
2022-09-28 02:01:40,301 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.181,  Train_accy 19.75
2022-09-28 02:01:42,559 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.176,  Train_accy 20.38
2022-09-28 02:01:44,823 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.168,  Train_accy 20.49
2022-09-28 02:01:47,094 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.170,  Train_accy 20.38
2022-09-28 02:01:50,164 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.166,  Train_accy 20.49, Test_accy 40.09
2022-09-28 02:01:52,413 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.174,  Train_accy 20.59
2022-09-28 02:01:54,656 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.158,  Train_accy 20.70
2022-09-28 02:01:56,956 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.159,  Train_accy 22.07
2022-09-28 02:01:59,239 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.161,  Train_accy 20.91
2022-09-28 02:02:02,302 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.169,  Train_accy 20.59, Test_accy 40.09
2022-09-28 02:02:04,546 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.170,  Train_accy 20.49
2022-09-28 02:02:06,833 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.165,  Train_accy 19.85
2022-09-28 02:02:09,123 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.160,  Train_accy 21.12
2022-09-28 02:02:11,364 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.170,  Train_accy 21.33
2022-09-28 02:02:14,397 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.162,  Train_accy 20.38, Test_accy 39.86
2022-09-28 02:02:14,397 [foster.py] => do not weight align student!
2022-09-28 02:02:15,201 [foster.py] => darknet eval: 
2022-09-28 02:02:15,201 [foster.py] => CNN top1 curve: 39.86
2022-09-28 02:02:15,201 [foster.py] => CNN top5 curve: 88.96
2022-09-28 02:02:15,202 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 02:02:24,753 [foster.py] => Exemplar size: 380
2022-09-28 02:02:24,754 [trainer.py] => CNN: {'total': 49.55, 'old': 49.74, 'new': 48.33, 'base': 72.78, 'compound': 36.71}
2022-09-28 02:02:24,754 [trainer.py] => CNN top1 curve: [88.61, 69.83, 60.98, 52.08, 49.55]
2022-09-28 02:02:24,754 [trainer.py] => CNN base curve: [88.61, 86.71, 81.01, 79.75, 72.78]
2022-09-28 02:02:24,754 [trainer.py] => CNN old curve: [88.61, 86.71, 68.97, 57.38, 49.74]
2022-09-28 02:02:24,754 [trainer.py] => CNN new curve: [0, 33.78, 35.62, 31.65, 48.33]
2022-09-28 02:02:24,754 [trainer.py] => CNN compound curve: [0, 33.78, 39.46, 32.74, 36.71]
2022-09-28 02:02:24,754 [trainer.py] => NME: {'total': 55.63, 'old': 54.95, 'new': 60.0, 'base': 64.56, 'compound': 50.7}
2022-09-28 02:02:24,754 [trainer.py] => NME top1 curve: [89.87, 78.88, 65.57, 57.81, 55.63]
2022-09-28 02:02:24,754 [trainer.py] => NME base curve: [89.87, 83.54, 70.25, 68.35, 64.56]
2022-09-28 02:02:24,754 [trainer.py] => NME old curve: [89.87, 83.54, 67.24, 61.64, 54.95]
2022-09-28 02:02:24,754 [trainer.py] => NME new curve: [0, 68.92, 60.27, 43.04, 60.0]
2022-09-28 02:02:24,754 [trainer.py] => NME compound curve: [0, 68.92, 60.54, 50.44, 50.7]
2022-09-28 02:02:24,981 [foster.py] => Learning on 19-22
2022-09-28 02:02:24,981 [foster.py] => All params: 22396607
2022-09-28 02:02:24,981 [foster.py] => Trainable params: 11210348
2022-09-28 02:02:25,001 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 02:02:28,030 [foster.py] => Task 5, Epoch 1/34 => Loss 6.759, Loss_clf 1.999, Loss_fe 2.539, Loss_kd 1.918, Train_accy 35.55, Test_accy 39.29
2022-09-28 02:02:30,137 [foster.py] => Task 5, Epoch 2/34 => Loss 5.261, Loss_clf 1.141, Loss_fe 1.892, Loss_kd 1.924, Train_accy 33.47
2022-09-28 02:02:32,223 [foster.py] => Task 5, Epoch 3/34 => Loss 4.993, Loss_clf 1.069, Loss_fe 1.693, Loss_kd 1.927, Train_accy 40.02
2022-09-28 02:02:34,312 [foster.py] => Task 5, Epoch 4/34 => Loss 4.779, Loss_clf 0.998, Loss_fe 1.556, Loss_kd 1.922, Train_accy 39.32
2022-09-28 02:02:36,428 [foster.py] => Task 5, Epoch 5/34 => Loss 4.639, Loss_clf 0.949, Loss_fe 1.458, Loss_kd 1.928, Train_accy 39.42
2022-09-28 02:02:39,588 [foster.py] => Task 5, Epoch 6/34 => Loss 4.582, Loss_clf 0.951, Loss_fe 1.402, Loss_kd 1.926, Train_accy 39.92, Test_accy 43.45
2022-09-28 02:02:41,726 [foster.py] => Task 5, Epoch 7/34 => Loss 4.477, Loss_clf 0.925, Loss_fe 1.314, Loss_kd 1.932, Train_accy 41.11
2022-09-28 02:02:43,891 [foster.py] => Task 5, Epoch 8/34 => Loss 4.388, Loss_clf 0.899, Loss_fe 1.258, Loss_kd 1.927, Train_accy 42.50
2022-09-28 02:02:46,014 [foster.py] => Task 5, Epoch 9/34 => Loss 4.326, Loss_clf 0.888, Loss_fe 1.207, Loss_kd 1.926, Train_accy 43.20
2022-09-28 02:02:48,183 [foster.py] => Task 5, Epoch 10/34 => Loss 4.285, Loss_clf 0.874, Loss_fe 1.177, Loss_kd 1.929, Train_accy 42.40
2022-09-28 02:02:51,291 [foster.py] => Task 5, Epoch 11/34 => Loss 4.257, Loss_clf 0.867, Loss_fe 1.153, Loss_kd 1.932, Train_accy 42.11, Test_accy 45.24
2022-09-28 02:02:53,401 [foster.py] => Task 5, Epoch 12/34 => Loss 4.154, Loss_clf 0.833, Loss_fe 1.098, Loss_kd 1.921, Train_accy 43.79
2022-09-28 02:02:55,513 [foster.py] => Task 5, Epoch 13/34 => Loss 4.101, Loss_clf 0.808, Loss_fe 1.059, Loss_kd 1.930, Train_accy 43.20
2022-09-28 02:02:57,632 [foster.py] => Task 5, Epoch 14/34 => Loss 4.108, Loss_clf 0.813, Loss_fe 1.056, Loss_kd 1.935, Train_accy 46.38
2022-09-28 02:02:59,767 [foster.py] => Task 5, Epoch 15/34 => Loss 4.052, Loss_clf 0.803, Loss_fe 1.013, Loss_kd 1.931, Train_accy 44.79
2022-09-28 02:03:02,955 [foster.py] => Task 5, Epoch 16/34 => Loss 3.990, Loss_clf 0.769, Loss_fe 0.988, Loss_kd 1.929, Train_accy 47.47, Test_accy 47.62
2022-09-28 02:03:05,060 [foster.py] => Task 5, Epoch 17/34 => Loss 4.011, Loss_clf 0.785, Loss_fe 0.983, Loss_kd 1.938, Train_accy 47.17
2022-09-28 02:03:07,200 [foster.py] => Task 5, Epoch 18/34 => Loss 4.011, Loss_clf 0.786, Loss_fe 0.981, Loss_kd 1.938, Train_accy 44.59
2022-09-28 02:03:09,284 [foster.py] => Task 5, Epoch 19/34 => Loss 3.918, Loss_clf 0.746, Loss_fe 0.925, Loss_kd 1.941, Train_accy 47.27
2022-09-28 02:03:11,426 [foster.py] => Task 5, Epoch 20/34 => Loss 3.903, Loss_clf 0.743, Loss_fe 0.920, Loss_kd 1.934, Train_accy 46.47
2022-09-28 02:03:14,485 [foster.py] => Task 5, Epoch 21/34 => Loss 3.886, Loss_clf 0.734, Loss_fe 0.908, Loss_kd 1.938, Train_accy 47.96, Test_accy 48.21
2022-09-28 02:03:16,615 [foster.py] => Task 5, Epoch 22/34 => Loss 3.847, Loss_clf 0.721, Loss_fe 0.883, Loss_kd 1.937, Train_accy 46.97
2022-09-28 02:03:18,751 [foster.py] => Task 5, Epoch 23/34 => Loss 3.873, Loss_clf 0.732, Loss_fe 0.898, Loss_kd 1.938, Train_accy 46.97
2022-09-28 02:03:20,843 [foster.py] => Task 5, Epoch 24/34 => Loss 3.881, Loss_clf 0.737, Loss_fe 0.892, Loss_kd 1.946, Train_accy 47.37
2022-09-28 02:03:22,965 [foster.py] => Task 5, Epoch 25/34 => Loss 3.862, Loss_clf 0.726, Loss_fe 0.892, Loss_kd 1.937, Train_accy 46.38
2022-09-28 02:03:26,096 [foster.py] => Task 5, Epoch 26/34 => Loss 3.852, Loss_clf 0.730, Loss_fe 0.882, Loss_kd 1.934, Train_accy 48.36, Test_accy 48.61
2022-09-28 02:03:28,217 [foster.py] => Task 5, Epoch 27/34 => Loss 3.867, Loss_clf 0.738, Loss_fe 0.886, Loss_kd 1.937, Train_accy 47.96
2022-09-28 02:03:30,301 [foster.py] => Task 5, Epoch 28/34 => Loss 3.835, Loss_clf 0.725, Loss_fe 0.878, Loss_kd 1.927, Train_accy 47.77
2022-09-28 02:03:32,404 [foster.py] => Task 5, Epoch 29/34 => Loss 3.823, Loss_clf 0.712, Loss_fe 0.863, Loss_kd 1.941, Train_accy 47.37
2022-09-28 02:03:34,486 [foster.py] => Task 5, Epoch 30/34 => Loss 3.834, Loss_clf 0.718, Loss_fe 0.869, Loss_kd 1.941, Train_accy 48.16
2022-09-28 02:03:37,609 [foster.py] => Task 5, Epoch 31/34 => Loss 3.872, Loss_clf 0.734, Loss_fe 0.897, Loss_kd 1.935, Train_accy 47.17, Test_accy 48.81
2022-09-28 02:03:39,700 [foster.py] => Task 5, Epoch 32/34 => Loss 3.828, Loss_clf 0.711, Loss_fe 0.867, Loss_kd 1.943, Train_accy 48.76
2022-09-28 02:03:41,790 [foster.py] => Task 5, Epoch 33/34 => Loss 3.801, Loss_clf 0.705, Loss_fe 0.861, Loss_kd 1.930, Train_accy 47.96
2022-09-28 02:03:43,957 [foster.py] => Task 5, Epoch 34/34 => Loss 3.755, Loss_clf 0.687, Loss_fe 0.840, Loss_kd 1.924, Train_accy 49.95
2022-09-28 02:03:43,958 [foster.py] => do not weight align teacher!
2022-09-28 02:03:43,958 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 02:03:47,386 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.425,  Train_accy 18.57, Test_accy 34.72
2022-09-28 02:03:49,739 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.415,  Train_accy 18.57
2022-09-28 02:03:52,135 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.406,  Train_accy 19.46
2022-09-28 02:03:54,538 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.398,  Train_accy 19.76
2022-09-28 02:03:56,891 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.397,  Train_accy 19.46
2022-09-28 02:04:00,136 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.393,  Train_accy 19.86, Test_accy 37.50
2022-09-28 02:04:02,490 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.396,  Train_accy 19.46
2022-09-28 02:04:04,834 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.385,  Train_accy 20.06
2022-09-28 02:04:07,176 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.384,  Train_accy 19.96
2022-09-28 02:04:09,521 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.383,  Train_accy 19.66
2022-09-28 02:04:12,801 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.379,  Train_accy 20.46, Test_accy 37.90
2022-09-28 02:04:15,185 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.382,  Train_accy 20.06
2022-09-28 02:04:17,528 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.381,  Train_accy 18.77
2022-09-28 02:04:19,872 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.370,  Train_accy 20.36
2022-09-28 02:04:22,237 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.370,  Train_accy 20.16
2022-09-28 02:04:25,454 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.373,  Train_accy 20.06, Test_accy 38.69
2022-09-28 02:04:27,831 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.367,  Train_accy 20.95
2022-09-28 02:04:30,193 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.375,  Train_accy 20.06
2022-09-28 02:04:32,559 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.369,  Train_accy 19.86
2022-09-28 02:04:34,958 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.375,  Train_accy 20.46
2022-09-28 02:04:38,185 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.371,  Train_accy 21.25, Test_accy 37.90
2022-09-28 02:04:40,580 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.371,  Train_accy 19.76
2022-09-28 02:04:42,972 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.373,  Train_accy 21.15
2022-09-28 02:04:45,329 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.370,  Train_accy 20.46
2022-09-28 02:04:47,667 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.376,  Train_accy 20.95
2022-09-28 02:04:50,876 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.362,  Train_accy 20.56, Test_accy 39.09
2022-09-28 02:04:50,877 [foster.py] => do not weight align student!
2022-09-28 02:04:51,731 [foster.py] => darknet eval: 
2022-09-28 02:04:51,731 [foster.py] => CNN top1 curve: 39.09
2022-09-28 02:04:51,731 [foster.py] => CNN top5 curve: 84.33
2022-09-28 02:04:51,732 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 02:05:02,376 [foster.py] => Exemplar size: 440
2022-09-28 02:05:02,376 [trainer.py] => CNN: {'total': 48.61, 'old': 50.45, 'new': 35.0, 'base': 66.46, 'compound': 40.46}
2022-09-28 02:05:02,376 [trainer.py] => CNN top1 curve: [88.61, 69.83, 60.98, 52.08, 49.55, 48.61]
2022-09-28 02:05:02,376 [trainer.py] => CNN base curve: [88.61, 86.71, 81.01, 79.75, 72.78, 66.46]
2022-09-28 02:05:02,376 [trainer.py] => CNN old curve: [88.61, 86.71, 68.97, 57.38, 49.74, 50.45]
2022-09-28 02:05:02,376 [trainer.py] => CNN new curve: [0, 33.78, 35.62, 31.65, 48.33, 35.0]
2022-09-28 02:05:02,376 [trainer.py] => CNN compound curve: [0, 33.78, 39.46, 32.74, 36.71, 40.46]
2022-09-28 02:05:02,376 [trainer.py] => NME: {'total': 53.37, 'old': 52.48, 'new': 60.0, 'base': 64.56, 'compound': 48.27}
2022-09-28 02:05:02,376 [trainer.py] => NME top1 curve: [89.87, 78.88, 65.57, 57.81, 55.63, 53.37]
2022-09-28 02:05:02,376 [trainer.py] => NME base curve: [89.87, 83.54, 70.25, 68.35, 64.56, 64.56]
2022-09-28 02:05:02,377 [trainer.py] => NME old curve: [89.87, 83.54, 67.24, 61.64, 54.95, 52.48]
2022-09-28 02:05:02,377 [trainer.py] => NME new curve: [0, 68.92, 60.27, 43.04, 60.0, 60.0]
2022-09-28 02:05:02,377 [trainer.py] => NME compound curve: [0, 68.92, 60.54, 50.44, 50.7, 48.27]
2022-09-28 02:05:02,378 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 02:05:02,378 [trainer.py] => prefix: cil
2022-09-28 02:05:02,378 [trainer.py] => dataset: CFEE
2022-09-28 02:05:02,378 [trainer.py] => memory_size: 2000
2022-09-28 02:05:02,378 [trainer.py] => memory_per_class: 20
2022-09-28 02:05:02,378 [trainer.py] => fixed_memory: True
2022-09-28 02:05:02,378 [trainer.py] => shuffle: True
2022-09-28 02:05:02,378 [trainer.py] => init_cls: 7
2022-09-28 02:05:02,378 [trainer.py] => increment: 3
2022-09-28 02:05:02,378 [trainer.py] => model_name: foster
2022-09-28 02:05:02,378 [trainer.py] => convnet_type: resnet18
2022-09-28 02:05:02,378 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 02:05:02,378 [trainer.py] => seed: 1993
2022-09-28 02:05:02,378 [trainer.py] => beta1: 0.96
2022-09-28 02:05:02,378 [trainer.py] => beta2: 0.97
2022-09-28 02:05:02,378 [trainer.py] => oofc: ft
2022-09-28 02:05:02,378 [trainer.py] => is_teacher_wa: False
2022-09-28 02:05:02,378 [trainer.py] => is_student_wa: False
2022-09-28 02:05:02,378 [trainer.py] => lambda_okd: 1
2022-09-28 02:05:02,378 [trainer.py] => wa_value: 1
2022-09-28 02:05:02,378 [trainer.py] => init_epochs: 40
2022-09-28 02:05:02,378 [trainer.py] => init_lr: 0.01
2022-09-28 02:05:02,378 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 02:05:02,378 [trainer.py] => boosting_epochs: 34
2022-09-28 02:05:02,379 [trainer.py] => compression_epochs: 26
2022-09-28 02:05:02,379 [trainer.py] => lr: 0.001
2022-09-28 02:05:02,379 [trainer.py] => batch_size: 32
2022-09-28 02:05:02,379 [trainer.py] => weight_decay: 0.0005
2022-09-28 02:05:02,379 [trainer.py] => num_workers: 8
2022-09-28 02:05:02,379 [trainer.py] => T: 2
2022-09-28 02:05:02,379 [trainer.py] => nb_runs: 3
2022-09-28 02:05:02,379 [trainer.py] => fold: 10
2022-09-28 02:05:02,379 [data.py] => ========== Fold:9 ==========
2022-09-28 02:05:02,384 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 13, 17, 15, 9, 11, 20, 18, 12, 14, 7, 10, 19, 21, 16, 8]
2022-09-28 02:05:02,598 [foster.py] => Learning on 0-7
2022-09-28 02:05:02,598 [foster.py] => All params: 11183694
2022-09-28 02:05:02,599 [foster.py] => Trainable params: 11183694
2022-09-28 02:05:04,996 [foster.py] => Task 0, Epoch 1/40 => Loss 1.331, Train_accy 50.24
2022-09-28 02:05:07,992 [foster.py] => Task 0, Epoch 2/40 => Loss 0.542, Train_accy 82.05, Test_accy 79.88
2022-09-28 02:05:10,959 [foster.py] => Task 0, Epoch 3/40 => Loss 0.422, Train_accy 86.14, Test_accy 85.37
2022-09-28 02:05:13,953 [foster.py] => Task 0, Epoch 4/40 => Loss 0.304, Train_accy 88.29, Test_accy 82.32
2022-09-28 02:05:16,916 [foster.py] => Task 0, Epoch 5/40 => Loss 0.247, Train_accy 91.68, Test_accy 84.76
2022-09-28 02:05:19,336 [foster.py] => Task 0, Epoch 6/40 => Loss 0.234, Train_accy 91.61
2022-09-28 02:05:22,292 [foster.py] => Task 0, Epoch 7/40 => Loss 0.189, Train_accy 93.56, Test_accy 84.15
2022-09-28 02:05:25,256 [foster.py] => Task 0, Epoch 8/40 => Loss 0.154, Train_accy 95.01, Test_accy 86.59
2022-09-28 02:05:28,259 [foster.py] => Task 0, Epoch 9/40 => Loss 0.132, Train_accy 95.36, Test_accy 85.37
2022-09-28 02:05:31,207 [foster.py] => Task 0, Epoch 10/40 => Loss 0.185, Train_accy 97.37, Test_accy 83.54
2022-09-28 02:05:33,595 [foster.py] => Task 0, Epoch 11/40 => Loss 0.167, Train_accy 95.01
2022-09-28 02:05:36,610 [foster.py] => Task 0, Epoch 12/40 => Loss 0.111, Train_accy 95.84, Test_accy 85.98
2022-09-28 02:05:39,622 [foster.py] => Task 0, Epoch 13/40 => Loss 0.075, Train_accy 98.06, Test_accy 85.98
2022-09-28 02:05:42,593 [foster.py] => Task 0, Epoch 14/40 => Loss 0.059, Train_accy 98.41, Test_accy 85.37
2022-09-28 02:05:45,597 [foster.py] => Task 0, Epoch 15/40 => Loss 0.050, Train_accy 98.89, Test_accy 84.15
2022-09-28 02:05:47,948 [foster.py] => Task 0, Epoch 16/40 => Loss 0.097, Train_accy 98.68
2022-09-28 02:05:50,928 [foster.py] => Task 0, Epoch 17/40 => Loss 0.081, Train_accy 98.06, Test_accy 80.49
2022-09-28 02:05:53,931 [foster.py] => Task 0, Epoch 18/40 => Loss 0.040, Train_accy 99.03, Test_accy 85.37
2022-09-28 02:05:56,938 [foster.py] => Task 0, Epoch 19/40 => Loss 0.042, Train_accy 99.31, Test_accy 84.76
2022-09-28 02:05:59,946 [foster.py] => Task 0, Epoch 20/40 => Loss 0.043, Train_accy 98.89, Test_accy 85.37
2022-09-28 02:06:02,338 [foster.py] => Task 0, Epoch 21/40 => Loss 0.064, Train_accy 98.89
2022-09-28 02:06:05,332 [foster.py] => Task 0, Epoch 22/40 => Loss 0.073, Train_accy 98.27, Test_accy 83.54
2022-09-28 02:06:08,317 [foster.py] => Task 0, Epoch 23/40 => Loss 0.042, Train_accy 98.27, Test_accy 84.76
2022-09-28 02:06:11,317 [foster.py] => Task 0, Epoch 24/40 => Loss 0.028, Train_accy 99.38, Test_accy 86.59
2022-09-28 02:06:14,325 [foster.py] => Task 0, Epoch 25/40 => Loss 0.024, Train_accy 99.86, Test_accy 84.76
2022-09-28 02:06:16,676 [foster.py] => Task 0, Epoch 26/40 => Loss 0.024, Train_accy 99.79
2022-09-28 02:06:19,652 [foster.py] => Task 0, Epoch 27/40 => Loss 0.025, Train_accy 99.65, Test_accy 87.80
2022-09-28 02:06:22,654 [foster.py] => Task 0, Epoch 28/40 => Loss 0.037, Train_accy 99.38, Test_accy 85.98
2022-09-28 02:06:25,633 [foster.py] => Task 0, Epoch 29/40 => Loss 0.024, Train_accy 99.45, Test_accy 85.98
2022-09-28 02:06:28,633 [foster.py] => Task 0, Epoch 30/40 => Loss 0.019, Train_accy 99.79, Test_accy 85.98
2022-09-28 02:06:31,090 [foster.py] => Task 0, Epoch 31/40 => Loss 0.019, Train_accy 99.79
2022-09-28 02:06:34,089 [foster.py] => Task 0, Epoch 32/40 => Loss 0.022, Train_accy 99.65, Test_accy 84.76
2022-09-28 02:06:37,127 [foster.py] => Task 0, Epoch 33/40 => Loss 0.027, Train_accy 99.45, Test_accy 85.98
2022-09-28 02:06:40,117 [foster.py] => Task 0, Epoch 34/40 => Loss 0.018, Train_accy 99.79, Test_accy 85.98
2022-09-28 02:06:43,124 [foster.py] => Task 0, Epoch 35/40 => Loss 0.020, Train_accy 99.79, Test_accy 84.15
2022-09-28 02:06:45,483 [foster.py] => Task 0, Epoch 36/40 => Loss 0.019, Train_accy 99.65
2022-09-28 02:06:48,445 [foster.py] => Task 0, Epoch 37/40 => Loss 0.015, Train_accy 99.86, Test_accy 84.76
2022-09-28 02:06:51,497 [foster.py] => Task 0, Epoch 38/40 => Loss 0.016, Train_accy 99.65, Test_accy 82.93
2022-09-28 02:06:54,479 [foster.py] => Task 0, Epoch 39/40 => Loss 0.038, Train_accy 99.45, Test_accy 84.76
2022-09-28 02:06:57,474 [foster.py] => Task 0, Epoch 40/40 => Loss 0.019, Train_accy 99.79, Test_accy 84.76
2022-09-28 02:06:57,474 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 02:07:04,366 [foster.py] => Exemplar size: 140
2022-09-28 02:07:04,366 [trainer.py] => CNN: {'total': 84.76, 'old': 84.76, 'new': 0, 'base': 84.76, 'compound': 0}
2022-09-28 02:07:04,366 [trainer.py] => CNN top1 curve: [84.76]
2022-09-28 02:07:04,366 [trainer.py] => CNN base curve: [84.76]
2022-09-28 02:07:04,366 [trainer.py] => CNN old curve: [84.76]
2022-09-28 02:07:04,366 [trainer.py] => CNN new curve: [0]
2022-09-28 02:07:04,366 [trainer.py] => CNN compound curve: [0]
2022-09-28 02:07:04,366 [trainer.py] => NME: {'total': 86.59, 'old': 86.59, 'new': 0, 'base': 86.59, 'compound': 0}
2022-09-28 02:07:04,366 [trainer.py] => NME top1 curve: [86.59]
2022-09-28 02:07:04,366 [trainer.py] => NME base curve: [86.59]
2022-09-28 02:07:04,366 [trainer.py] => NME old curve: [86.59]
2022-09-28 02:07:04,366 [trainer.py] => NME new curve: [0]
2022-09-28 02:07:04,366 [trainer.py] => NME compound curve: [0]
2022-09-28 02:07:04,596 [foster.py] => Learning on 7-10
2022-09-28 02:07:04,596 [foster.py] => All params: 22371995
2022-09-28 02:07:04,597 [foster.py] => Trainable params: 11191892
2022-09-28 02:07:04,617 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 02:07:07,156 [foster.py] => Task 1, Epoch 1/34 => Loss 4.659, Loss_clf 1.992, Loss_fe 1.930, Loss_kd 0.516, Train_accy 41.17, Test_accy 64.86
2022-09-28 02:07:08,886 [foster.py] => Task 1, Epoch 2/34 => Loss 2.594, Loss_clf 0.669, Loss_fe 1.167, Loss_kd 0.531, Train_accy 78.96
2022-09-28 02:07:10,649 [foster.py] => Task 1, Epoch 3/34 => Loss 1.989, Loss_clf 0.375, Loss_fe 0.914, Loss_kd 0.491, Train_accy 56.62
2022-09-28 02:07:12,417 [foster.py] => Task 1, Epoch 4/34 => Loss 1.817, Loss_clf 0.338, Loss_fe 0.771, Loss_kd 0.495, Train_accy 54.42
2022-09-28 02:07:14,205 [foster.py] => Task 1, Epoch 5/34 => Loss 1.755, Loss_clf 0.325, Loss_fe 0.705, Loss_kd 0.508, Train_accy 57.14
2022-09-28 02:07:16,700 [foster.py] => Task 1, Epoch 6/34 => Loss 1.647, Loss_clf 0.284, Loss_fe 0.669, Loss_kd 0.486, Train_accy 54.68, Test_accy 71.62
2022-09-28 02:07:18,434 [foster.py] => Task 1, Epoch 7/34 => Loss 1.604, Loss_clf 0.320, Loss_fe 0.590, Loss_kd 0.486, Train_accy 58.44
2022-09-28 02:07:20,173 [foster.py] => Task 1, Epoch 8/34 => Loss 1.592, Loss_clf 0.308, Loss_fe 0.608, Loss_kd 0.473, Train_accy 59.74
2022-09-28 02:07:21,965 [foster.py] => Task 1, Epoch 9/34 => Loss 1.554, Loss_clf 0.281, Loss_fe 0.574, Loss_kd 0.489, Train_accy 57.14
2022-09-28 02:07:23,741 [foster.py] => Task 1, Epoch 10/34 => Loss 1.542, Loss_clf 0.273, Loss_fe 0.574, Loss_kd 0.486, Train_accy 56.10
2022-09-28 02:07:26,226 [foster.py] => Task 1, Epoch 11/34 => Loss 1.431, Loss_clf 0.263, Loss_fe 0.464, Loss_kd 0.493, Train_accy 56.88, Test_accy 71.17
2022-09-28 02:07:28,008 [foster.py] => Task 1, Epoch 12/34 => Loss 1.399, Loss_clf 0.250, Loss_fe 0.442, Loss_kd 0.495, Train_accy 58.31
2022-09-28 02:07:29,742 [foster.py] => Task 1, Epoch 13/34 => Loss 1.416, Loss_clf 0.246, Loss_fe 0.464, Loss_kd 0.494, Train_accy 59.35
2022-09-28 02:07:31,504 [foster.py] => Task 1, Epoch 14/34 => Loss 1.346, Loss_clf 0.234, Loss_fe 0.413, Loss_kd 0.489, Train_accy 58.83
2022-09-28 02:07:33,265 [foster.py] => Task 1, Epoch 15/34 => Loss 1.373, Loss_clf 0.245, Loss_fe 0.461, Loss_kd 0.467, Train_accy 58.83
2022-09-28 02:07:35,746 [foster.py] => Task 1, Epoch 16/34 => Loss 1.410, Loss_clf 0.257, Loss_fe 0.465, Loss_kd 0.481, Train_accy 57.40, Test_accy 71.62
2022-09-28 02:07:37,499 [foster.py] => Task 1, Epoch 17/34 => Loss 1.322, Loss_clf 0.233, Loss_fe 0.399, Loss_kd 0.484, Train_accy 58.44
2022-09-28 02:07:39,252 [foster.py] => Task 1, Epoch 18/34 => Loss 1.348, Loss_clf 0.229, Loss_fe 0.421, Loss_kd 0.489, Train_accy 59.61
2022-09-28 02:07:41,009 [foster.py] => Task 1, Epoch 19/34 => Loss 1.302, Loss_clf 0.222, Loss_fe 0.371, Loss_kd 0.496, Train_accy 60.39
2022-09-28 02:07:42,776 [foster.py] => Task 1, Epoch 20/34 => Loss 1.407, Loss_clf 0.261, Loss_fe 0.456, Loss_kd 0.482, Train_accy 60.91
2022-09-28 02:07:45,308 [foster.py] => Task 1, Epoch 21/34 => Loss 1.292, Loss_clf 0.238, Loss_fe 0.365, Loss_kd 0.482, Train_accy 57.66, Test_accy 70.27
2022-09-28 02:07:47,046 [foster.py] => Task 1, Epoch 22/34 => Loss 1.282, Loss_clf 0.237, Loss_fe 0.350, Loss_kd 0.486, Train_accy 58.31
2022-09-28 02:07:48,816 [foster.py] => Task 1, Epoch 23/34 => Loss 1.398, Loss_clf 0.289, Loss_fe 0.419, Loss_kd 0.483, Train_accy 61.43
2022-09-28 02:07:50,588 [foster.py] => Task 1, Epoch 24/34 => Loss 1.292, Loss_clf 0.216, Loss_fe 0.383, Loss_kd 0.485, Train_accy 58.70
2022-09-28 02:07:52,327 [foster.py] => Task 1, Epoch 25/34 => Loss 1.268, Loss_clf 0.222, Loss_fe 0.346, Loss_kd 0.490, Train_accy 58.18
2022-09-28 02:07:54,829 [foster.py] => Task 1, Epoch 26/34 => Loss 1.251, Loss_clf 0.209, Loss_fe 0.340, Loss_kd 0.492, Train_accy 59.61, Test_accy 72.52
2022-09-28 02:07:56,552 [foster.py] => Task 1, Epoch 27/34 => Loss 1.233, Loss_clf 0.214, Loss_fe 0.337, Loss_kd 0.478, Train_accy 58.70
2022-09-28 02:07:58,286 [foster.py] => Task 1, Epoch 28/34 => Loss 1.228, Loss_clf 0.202, Loss_fe 0.326, Loss_kd 0.489, Train_accy 60.91
2022-09-28 02:08:00,035 [foster.py] => Task 1, Epoch 29/34 => Loss 1.271, Loss_clf 0.210, Loss_fe 0.345, Loss_kd 0.501, Train_accy 61.30
2022-09-28 02:08:01,794 [foster.py] => Task 1, Epoch 30/34 => Loss 1.259, Loss_clf 0.225, Loss_fe 0.350, Loss_kd 0.478, Train_accy 60.26
2022-09-28 02:08:04,311 [foster.py] => Task 1, Epoch 31/34 => Loss 1.240, Loss_clf 0.193, Loss_fe 0.353, Loss_kd 0.486, Train_accy 60.65, Test_accy 71.17
2022-09-28 02:08:06,063 [foster.py] => Task 1, Epoch 32/34 => Loss 1.291, Loss_clf 0.226, Loss_fe 0.386, Loss_kd 0.476, Train_accy 60.26
2022-09-28 02:08:07,830 [foster.py] => Task 1, Epoch 33/34 => Loss 1.245, Loss_clf 0.202, Loss_fe 0.340, Loss_kd 0.493, Train_accy 61.56
2022-09-28 02:08:09,601 [foster.py] => Task 1, Epoch 34/34 => Loss 1.276, Loss_clf 0.205, Loss_fe 0.393, Loss_kd 0.475, Train_accy 60.78
2022-09-28 02:08:09,601 [foster.py] => do not weight align teacher!
2022-09-28 02:08:09,602 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 02:08:12,524 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.555,  Train_accy 18.18, Test_accy 59.91
2022-09-28 02:08:14,509 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.475,  Train_accy 18.31
2022-09-28 02:08:16,470 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.397,  Train_accy 18.57
2022-09-28 02:08:18,400 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.370,  Train_accy 20.00
2022-09-28 02:08:20,339 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.337,  Train_accy 21.82
2022-09-28 02:08:22,977 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.298,  Train_accy 23.90, Test_accy 61.71
2022-09-28 02:08:24,938 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.270,  Train_accy 25.84
2022-09-28 02:08:26,874 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.314,  Train_accy 26.75
2022-09-28 02:08:28,844 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.231,  Train_accy 27.14
2022-09-28 02:08:30,803 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.262,  Train_accy 28.18
2022-09-28 02:08:33,485 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.256,  Train_accy 28.70, Test_accy 65.77
2022-09-28 02:08:35,523 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.252,  Train_accy 29.61
2022-09-28 02:08:37,486 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.231,  Train_accy 30.78
2022-09-28 02:08:39,467 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.240,  Train_accy 30.26
2022-09-28 02:08:41,389 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.240,  Train_accy 31.69
2022-09-28 02:08:44,036 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.224,  Train_accy 32.47, Test_accy 66.22
2022-09-28 02:08:45,967 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.213,  Train_accy 31.95
2022-09-28 02:08:47,912 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.231,  Train_accy 32.73
2022-09-28 02:08:49,894 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.240,  Train_accy 33.38
2022-09-28 02:08:51,878 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.235,  Train_accy 32.60
2022-09-28 02:08:54,507 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.248,  Train_accy 33.12, Test_accy 67.12
2022-09-28 02:08:56,487 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.238,  Train_accy 31.43
2022-09-28 02:08:58,462 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.232,  Train_accy 30.65
2022-09-28 02:09:00,434 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.223,  Train_accy 34.29
2022-09-28 02:09:02,359 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.227,  Train_accy 32.60
2022-09-28 02:09:04,967 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.203,  Train_accy 34.03, Test_accy 66.22
2022-09-28 02:09:04,967 [foster.py] => do not weight align student!
2022-09-28 02:09:05,613 [foster.py] => darknet eval: 
2022-09-28 02:09:05,614 [foster.py] => CNN top1 curve: 66.22
2022-09-28 02:09:05,614 [foster.py] => CNN top5 curve: 97.75
2022-09-28 02:09:05,614 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 02:09:11,992 [foster.py] => Exemplar size: 200
2022-09-28 02:09:11,992 [trainer.py] => CNN: {'total': 71.17, 'old': 79.88, 'new': 46.55, 'base': 79.88, 'compound': 46.55}
2022-09-28 02:09:11,992 [trainer.py] => CNN top1 curve: [84.76, 71.17]
2022-09-28 02:09:11,992 [trainer.py] => CNN base curve: [84.76, 79.88]
2022-09-28 02:09:11,992 [trainer.py] => CNN old curve: [84.76, 79.88]
2022-09-28 02:09:11,992 [trainer.py] => CNN new curve: [0, 46.55]
2022-09-28 02:09:11,992 [trainer.py] => CNN compound curve: [0, 46.55]
2022-09-28 02:09:11,992 [trainer.py] => NME: {'total': 75.23, 'old': 76.83, 'new': 70.69, 'base': 76.83, 'compound': 70.69}
2022-09-28 02:09:11,992 [trainer.py] => NME top1 curve: [86.59, 75.23]
2022-09-28 02:09:11,992 [trainer.py] => NME base curve: [86.59, 76.83]
2022-09-28 02:09:11,992 [trainer.py] => NME old curve: [86.59, 76.83]
2022-09-28 02:09:11,992 [trainer.py] => NME new curve: [0, 70.69]
2022-09-28 02:09:11,993 [trainer.py] => NME compound curve: [0, 70.69]
2022-09-28 02:09:12,221 [foster.py] => Learning on 10-13
2022-09-28 02:09:12,222 [foster.py] => All params: 22378148
2022-09-28 02:09:12,222 [foster.py] => Trainable params: 11196506
2022-09-28 02:09:12,242 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 02:09:14,841 [foster.py] => Task 2, Epoch 1/34 => Loss 5.430, Loss_clf 2.265, Loss_fe 2.105, Loss_kd 0.816, Train_accy 40.51, Test_accy 46.64
2022-09-28 02:09:16,657 [foster.py] => Task 2, Epoch 2/34 => Loss 3.375, Loss_clf 0.913, Loss_fe 1.407, Loss_kd 0.812, Train_accy 49.46
2022-09-28 02:09:18,503 [foster.py] => Task 2, Epoch 3/34 => Loss 2.932, Loss_clf 0.724, Loss_fe 1.186, Loss_kd 0.787, Train_accy 36.76
2022-09-28 02:09:20,396 [foster.py] => Task 2, Epoch 4/34 => Loss 2.773, Loss_clf 0.656, Loss_fe 1.076, Loss_kd 0.801, Train_accy 40.99
2022-09-28 02:09:22,271 [foster.py] => Task 2, Epoch 5/34 => Loss 2.686, Loss_clf 0.648, Loss_fe 0.999, Loss_kd 0.799, Train_accy 38.57
2022-09-28 02:09:24,895 [foster.py] => Task 2, Epoch 6/34 => Loss 2.535, Loss_clf 0.595, Loss_fe 0.907, Loss_kd 0.794, Train_accy 39.18, Test_accy 57.24
2022-09-28 02:09:26,727 [foster.py] => Task 2, Epoch 7/34 => Loss 2.464, Loss_clf 0.576, Loss_fe 0.852, Loss_kd 0.797, Train_accy 39.54
2022-09-28 02:09:28,593 [foster.py] => Task 2, Epoch 8/34 => Loss 2.420, Loss_clf 0.570, Loss_fe 0.818, Loss_kd 0.794, Train_accy 40.02
2022-09-28 02:09:30,393 [foster.py] => Task 2, Epoch 9/34 => Loss 2.366, Loss_clf 0.550, Loss_fe 0.781, Loss_kd 0.796, Train_accy 39.90
2022-09-28 02:09:32,268 [foster.py] => Task 2, Epoch 10/34 => Loss 2.334, Loss_clf 0.545, Loss_fe 0.757, Loss_kd 0.794, Train_accy 43.17
2022-09-28 02:09:34,866 [foster.py] => Task 2, Epoch 11/34 => Loss 2.319, Loss_clf 0.550, Loss_fe 0.741, Loss_kd 0.790, Train_accy 42.08, Test_accy 58.30
2022-09-28 02:09:36,695 [foster.py] => Task 2, Epoch 12/34 => Loss 2.272, Loss_clf 0.526, Loss_fe 0.704, Loss_kd 0.801, Train_accy 40.99
2022-09-28 02:09:38,517 [foster.py] => Task 2, Epoch 13/34 => Loss 2.256, Loss_clf 0.522, Loss_fe 0.695, Loss_kd 0.800, Train_accy 44.01
2022-09-28 02:09:40,371 [foster.py] => Task 2, Epoch 14/34 => Loss 2.269, Loss_clf 0.536, Loss_fe 0.692, Loss_kd 0.801, Train_accy 41.11
2022-09-28 02:09:42,238 [foster.py] => Task 2, Epoch 15/34 => Loss 2.227, Loss_clf 0.515, Loss_fe 0.670, Loss_kd 0.801, Train_accy 41.23
2022-09-28 02:09:44,836 [foster.py] => Task 2, Epoch 16/34 => Loss 2.176, Loss_clf 0.506, Loss_fe 0.640, Loss_kd 0.793, Train_accy 43.17, Test_accy 57.60
2022-09-28 02:09:46,648 [foster.py] => Task 2, Epoch 17/34 => Loss 2.154, Loss_clf 0.497, Loss_fe 0.624, Loss_kd 0.795, Train_accy 44.98
2022-09-28 02:09:48,490 [foster.py] => Task 2, Epoch 18/34 => Loss 2.123, Loss_clf 0.473, Loss_fe 0.614, Loss_kd 0.797, Train_accy 42.93
2022-09-28 02:09:50,342 [foster.py] => Task 2, Epoch 19/34 => Loss 2.099, Loss_clf 0.466, Loss_fe 0.591, Loss_kd 0.802, Train_accy 43.41
2022-09-28 02:09:52,228 [foster.py] => Task 2, Epoch 20/34 => Loss 2.079, Loss_clf 0.462, Loss_fe 0.581, Loss_kd 0.797, Train_accy 44.26
2022-09-28 02:09:54,866 [foster.py] => Task 2, Epoch 21/34 => Loss 2.086, Loss_clf 0.463, Loss_fe 0.581, Loss_kd 0.801, Train_accy 42.56, Test_accy 58.66
2022-09-28 02:09:56,694 [foster.py] => Task 2, Epoch 22/34 => Loss 2.081, Loss_clf 0.457, Loss_fe 0.585, Loss_kd 0.799, Train_accy 42.68
2022-09-28 02:09:58,567 [foster.py] => Task 2, Epoch 23/34 => Loss 2.024, Loss_clf 0.438, Loss_fe 0.549, Loss_kd 0.797, Train_accy 44.50
2022-09-28 02:10:00,368 [foster.py] => Task 2, Epoch 24/34 => Loss 2.067, Loss_clf 0.451, Loss_fe 0.568, Loss_kd 0.806, Train_accy 43.05
2022-09-28 02:10:02,231 [foster.py] => Task 2, Epoch 25/34 => Loss 2.084, Loss_clf 0.459, Loss_fe 0.583, Loss_kd 0.802, Train_accy 44.26
2022-09-28 02:10:04,817 [foster.py] => Task 2, Epoch 26/34 => Loss 2.042, Loss_clf 0.448, Loss_fe 0.563, Loss_kd 0.793, Train_accy 44.01, Test_accy 58.66
2022-09-28 02:10:06,684 [foster.py] => Task 2, Epoch 27/34 => Loss 2.013, Loss_clf 0.432, Loss_fe 0.544, Loss_kd 0.798, Train_accy 43.77
2022-09-28 02:10:08,592 [foster.py] => Task 2, Epoch 28/34 => Loss 2.031, Loss_clf 0.430, Loss_fe 0.557, Loss_kd 0.803, Train_accy 45.34
2022-09-28 02:10:10,433 [foster.py] => Task 2, Epoch 29/34 => Loss 1.996, Loss_clf 0.428, Loss_fe 0.535, Loss_kd 0.794, Train_accy 43.53
2022-09-28 02:10:12,313 [foster.py] => Task 2, Epoch 30/34 => Loss 1.973, Loss_clf 0.412, Loss_fe 0.527, Loss_kd 0.795, Train_accy 44.50
2022-09-28 02:10:14,935 [foster.py] => Task 2, Epoch 31/34 => Loss 2.014, Loss_clf 0.433, Loss_fe 0.543, Loss_kd 0.799, Train_accy 43.77, Test_accy 58.30
2022-09-28 02:10:16,777 [foster.py] => Task 2, Epoch 32/34 => Loss 2.041, Loss_clf 0.442, Loss_fe 0.558, Loss_kd 0.802, Train_accy 44.50
2022-09-28 02:10:18,630 [foster.py] => Task 2, Epoch 33/34 => Loss 2.032, Loss_clf 0.431, Loss_fe 0.559, Loss_kd 0.801, Train_accy 43.17
2022-09-28 02:10:20,445 [foster.py] => Task 2, Epoch 34/34 => Loss 2.016, Loss_clf 0.428, Loss_fe 0.544, Loss_kd 0.803, Train_accy 44.50
2022-09-28 02:10:20,445 [foster.py] => do not weight align teacher!
2022-09-28 02:10:20,446 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 02:10:23,414 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.800,  Train_accy 17.05, Test_accy 50.88
2022-09-28 02:10:25,430 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.692,  Train_accy 17.65
2022-09-28 02:10:27,458 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.618,  Train_accy 18.38
2022-09-28 02:10:29,510 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.584,  Train_accy 18.50
2022-09-28 02:10:31,524 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.552,  Train_accy 19.11
2022-09-28 02:10:34,295 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.537,  Train_accy 19.11, Test_accy 54.06
2022-09-28 02:10:36,344 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.539,  Train_accy 18.86
2022-09-28 02:10:38,395 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.535,  Train_accy 19.23
2022-09-28 02:10:40,553 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.533,  Train_accy 19.47
2022-09-28 02:10:42,616 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.527,  Train_accy 19.47
2022-09-28 02:10:45,379 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.513,  Train_accy 19.35, Test_accy 54.42
2022-09-28 02:10:47,443 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.509,  Train_accy 19.59
2022-09-28 02:10:49,486 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.507,  Train_accy 19.95
2022-09-28 02:10:51,537 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.517,  Train_accy 19.59
2022-09-28 02:10:53,578 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.499,  Train_accy 19.95
2022-09-28 02:10:56,373 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.511,  Train_accy 19.95, Test_accy 55.12
2022-09-28 02:10:58,413 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.503,  Train_accy 19.83
2022-09-28 02:11:00,471 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.495,  Train_accy 19.95
2022-09-28 02:11:02,543 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.501,  Train_accy 20.07
2022-09-28 02:11:04,583 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.506,  Train_accy 19.83
2022-09-28 02:11:07,349 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.495,  Train_accy 20.31, Test_accy 53.71
2022-09-28 02:11:09,368 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.494,  Train_accy 19.59
2022-09-28 02:11:11,386 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.502,  Train_accy 20.07
2022-09-28 02:11:13,428 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.504,  Train_accy 19.83
2022-09-28 02:11:15,437 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.484,  Train_accy 19.95
2022-09-28 02:11:18,255 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.510,  Train_accy 19.95, Test_accy 53.36
2022-09-28 02:11:18,256 [foster.py] => do not weight align student!
2022-09-28 02:11:18,976 [foster.py] => darknet eval: 
2022-09-28 02:11:18,976 [foster.py] => CNN top1 curve: 53.36
2022-09-28 02:11:18,976 [foster.py] => CNN top5 curve: 97.53
2022-09-28 02:11:18,977 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 02:11:26,285 [foster.py] => Exemplar size: 260
2022-09-28 02:11:26,286 [trainer.py] => CNN: {'total': 58.3, 'old': 67.57, 'new': 24.59, 'base': 75.0, 'compound': 35.29}
2022-09-28 02:11:26,286 [trainer.py] => CNN top1 curve: [84.76, 71.17, 58.3]
2022-09-28 02:11:26,286 [trainer.py] => CNN base curve: [84.76, 79.88, 75.0]
2022-09-28 02:11:26,286 [trainer.py] => CNN old curve: [84.76, 79.88, 67.57]
2022-09-28 02:11:26,286 [trainer.py] => CNN new curve: [0, 46.55, 24.59]
2022-09-28 02:11:26,286 [trainer.py] => CNN compound curve: [0, 46.55, 35.29]
2022-09-28 02:11:26,286 [trainer.py] => NME: {'total': 67.14, 'old': 69.37, 'new': 59.02, 'base': 70.12, 'compound': 63.03}
2022-09-28 02:11:26,286 [trainer.py] => NME top1 curve: [86.59, 75.23, 67.14]
2022-09-28 02:11:26,286 [trainer.py] => NME base curve: [86.59, 76.83, 70.12]
2022-09-28 02:11:26,286 [trainer.py] => NME old curve: [86.59, 76.83, 69.37]
2022-09-28 02:11:26,286 [trainer.py] => NME new curve: [0, 70.69, 59.02]
2022-09-28 02:11:26,286 [trainer.py] => NME compound curve: [0, 70.69, 63.03]
2022-09-28 02:11:26,517 [foster.py] => Learning on 13-16
2022-09-28 02:11:26,518 [foster.py] => All params: 22384301
2022-09-28 02:11:26,518 [foster.py] => Trainable params: 11201120
2022-09-28 02:11:26,538 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 02:11:29,332 [foster.py] => Task 3, Epoch 1/34 => Loss 6.127, Loss_clf 2.053, Loss_fe 2.448, Loss_kd 1.320, Train_accy 38.07, Test_accy 45.56
2022-09-28 02:11:31,272 [foster.py] => Task 3, Epoch 2/34 => Loss 4.347, Loss_clf 1.038, Loss_fe 1.690, Loss_kd 1.315, Train_accy 40.83
2022-09-28 02:11:33,194 [foster.py] => Task 3, Epoch 3/34 => Loss 4.006, Loss_clf 0.907, Loss_fe 1.491, Loss_kd 1.307, Train_accy 42.66
2022-09-28 02:11:35,083 [foster.py] => Task 3, Epoch 4/34 => Loss 3.808, Loss_clf 0.857, Loss_fe 1.342, Loss_kd 1.307, Train_accy 39.79
2022-09-28 02:11:36,987 [foster.py] => Task 3, Epoch 5/34 => Loss 3.715, Loss_clf 0.852, Loss_fe 1.247, Loss_kd 1.313, Train_accy 38.53
2022-09-28 02:11:39,784 [foster.py] => Task 3, Epoch 6/34 => Loss 3.605, Loss_clf 0.817, Loss_fe 1.185, Loss_kd 1.302, Train_accy 42.43, Test_accy 44.72
2022-09-28 02:11:41,674 [foster.py] => Task 3, Epoch 7/34 => Loss 3.524, Loss_clf 0.787, Loss_fe 1.127, Loss_kd 1.309, Train_accy 39.79
2022-09-28 02:11:43,572 [foster.py] => Task 3, Epoch 8/34 => Loss 3.466, Loss_clf 0.783, Loss_fe 1.079, Loss_kd 1.303, Train_accy 41.97
2022-09-28 02:11:45,500 [foster.py] => Task 3, Epoch 9/34 => Loss 3.465, Loss_clf 0.795, Loss_fe 1.064, Loss_kd 1.305, Train_accy 40.14
2022-09-28 02:11:47,420 [foster.py] => Task 3, Epoch 10/34 => Loss 3.415, Loss_clf 0.771, Loss_fe 1.012, Loss_kd 1.327, Train_accy 40.60
2022-09-28 02:11:50,202 [foster.py] => Task 3, Epoch 11/34 => Loss 3.300, Loss_clf 0.729, Loss_fe 0.958, Loss_kd 1.310, Train_accy 42.32, Test_accy 46.67
2022-09-28 02:11:52,115 [foster.py] => Task 3, Epoch 12/34 => Loss 3.331, Loss_clf 0.758, Loss_fe 0.962, Loss_kd 1.309, Train_accy 37.84
2022-09-28 02:11:54,036 [foster.py] => Task 3, Epoch 13/34 => Loss 3.265, Loss_clf 0.719, Loss_fe 0.926, Loss_kd 1.316, Train_accy 41.17
2022-09-28 02:11:55,957 [foster.py] => Task 3, Epoch 14/34 => Loss 3.221, Loss_clf 0.717, Loss_fe 0.887, Loss_kd 1.314, Train_accy 42.32
2022-09-28 02:11:57,864 [foster.py] => Task 3, Epoch 15/34 => Loss 3.173, Loss_clf 0.689, Loss_fe 0.881, Loss_kd 1.303, Train_accy 43.92
2022-09-28 02:12:00,624 [foster.py] => Task 3, Epoch 16/34 => Loss 3.184, Loss_clf 0.700, Loss_fe 0.871, Loss_kd 1.310, Train_accy 41.86, Test_accy 49.44
2022-09-28 02:12:02,507 [foster.py] => Task 3, Epoch 17/34 => Loss 3.152, Loss_clf 0.683, Loss_fe 0.848, Loss_kd 1.317, Train_accy 43.46
2022-09-28 02:12:04,426 [foster.py] => Task 3, Epoch 18/34 => Loss 3.117, Loss_clf 0.671, Loss_fe 0.829, Loss_kd 1.313, Train_accy 42.66
2022-09-28 02:12:06,339 [foster.py] => Task 3, Epoch 19/34 => Loss 3.136, Loss_clf 0.686, Loss_fe 0.837, Loss_kd 1.310, Train_accy 43.69
2022-09-28 02:12:08,263 [foster.py] => Task 3, Epoch 20/34 => Loss 3.069, Loss_clf 0.651, Loss_fe 0.804, Loss_kd 1.311, Train_accy 43.46
2022-09-28 02:12:11,032 [foster.py] => Task 3, Epoch 21/34 => Loss 3.087, Loss_clf 0.654, Loss_fe 0.815, Loss_kd 1.314, Train_accy 43.58, Test_accy 49.17
2022-09-28 02:12:12,918 [foster.py] => Task 3, Epoch 22/34 => Loss 3.084, Loss_clf 0.664, Loss_fe 0.805, Loss_kd 1.312, Train_accy 43.92
2022-09-28 02:12:14,814 [foster.py] => Task 3, Epoch 23/34 => Loss 3.025, Loss_clf 0.646, Loss_fe 0.769, Loss_kd 1.308, Train_accy 45.99
2022-09-28 02:12:16,689 [foster.py] => Task 3, Epoch 24/34 => Loss 3.018, Loss_clf 0.629, Loss_fe 0.773, Loss_kd 1.313, Train_accy 46.79
2022-09-28 02:12:18,600 [foster.py] => Task 3, Epoch 25/34 => Loss 3.039, Loss_clf 0.651, Loss_fe 0.782, Loss_kd 1.306, Train_accy 44.50
2022-09-28 02:12:21,359 [foster.py] => Task 3, Epoch 26/34 => Loss 3.040, Loss_clf 0.653, Loss_fe 0.775, Loss_kd 1.309, Train_accy 45.07, Test_accy 49.44
2022-09-28 02:12:23,287 [foster.py] => Task 3, Epoch 27/34 => Loss 3.021, Loss_clf 0.636, Loss_fe 0.770, Loss_kd 1.312, Train_accy 45.41
2022-09-28 02:12:25,210 [foster.py] => Task 3, Epoch 28/34 => Loss 3.010, Loss_clf 0.636, Loss_fe 0.766, Loss_kd 1.306, Train_accy 46.44
2022-09-28 02:12:27,153 [foster.py] => Task 3, Epoch 29/34 => Loss 3.031, Loss_clf 0.639, Loss_fe 0.778, Loss_kd 1.312, Train_accy 45.64
2022-09-28 02:12:29,078 [foster.py] => Task 3, Epoch 30/34 => Loss 2.986, Loss_clf 0.611, Loss_fe 0.752, Loss_kd 1.319, Train_accy 45.64
2022-09-28 02:12:31,828 [foster.py] => Task 3, Epoch 31/34 => Loss 3.029, Loss_clf 0.636, Loss_fe 0.779, Loss_kd 1.312, Train_accy 45.76, Test_accy 50.00
2022-09-28 02:12:33,751 [foster.py] => Task 3, Epoch 32/34 => Loss 3.017, Loss_clf 0.630, Loss_fe 0.763, Loss_kd 1.320, Train_accy 45.18
2022-09-28 02:12:35,647 [foster.py] => Task 3, Epoch 33/34 => Loss 2.992, Loss_clf 0.621, Loss_fe 0.761, Loss_kd 1.307, Train_accy 45.18
2022-09-28 02:12:37,569 [foster.py] => Task 3, Epoch 34/34 => Loss 3.000, Loss_clf 0.619, Loss_fe 0.749, Loss_kd 1.326, Train_accy 47.36
2022-09-28 02:12:37,570 [foster.py] => do not weight align teacher!
2022-09-28 02:12:37,570 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 02:12:40,730 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.079,  Train_accy 18.35, Test_accy 40.83
2022-09-28 02:12:42,924 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.011,  Train_accy 18.92
2022-09-28 02:12:45,026 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.001,  Train_accy 18.81
2022-09-28 02:12:47,193 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 1.977,  Train_accy 19.84
2022-09-28 02:12:49,335 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.975,  Train_accy 19.04
2022-09-28 02:12:52,243 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.962,  Train_accy 18.69, Test_accy 43.33
2022-09-28 02:12:54,363 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.961,  Train_accy 19.27
2022-09-28 02:12:56,528 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.950,  Train_accy 19.27
2022-09-28 02:12:58,675 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.955,  Train_accy 18.92
2022-09-28 02:13:00,813 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.945,  Train_accy 19.84
2022-09-28 02:13:03,740 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.939,  Train_accy 19.38, Test_accy 43.89
2022-09-28 02:13:05,861 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.943,  Train_accy 19.50
2022-09-28 02:13:07,987 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.952,  Train_accy 19.50
2022-09-28 02:13:10,147 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.932,  Train_accy 19.72
2022-09-28 02:13:12,311 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.932,  Train_accy 19.72
2022-09-28 02:13:15,233 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.922,  Train_accy 19.50, Test_accy 43.33
2022-09-28 02:13:17,381 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.933,  Train_accy 19.72
2022-09-28 02:13:19,535 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.940,  Train_accy 19.04
2022-09-28 02:13:21,727 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.925,  Train_accy 19.38
2022-09-28 02:13:23,867 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.924,  Train_accy 20.07
2022-09-28 02:13:26,773 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.918,  Train_accy 19.50, Test_accy 45.00
2022-09-28 02:13:28,887 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.936,  Train_accy 19.95
2022-09-28 02:13:31,054 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.933,  Train_accy 19.72
2022-09-28 02:13:33,318 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.920,  Train_accy 19.27
2022-09-28 02:13:35,484 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.932,  Train_accy 19.72
2022-09-28 02:13:38,362 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.933,  Train_accy 19.50, Test_accy 44.17
2022-09-28 02:13:38,362 [foster.py] => do not weight align student!
2022-09-28 02:13:39,125 [foster.py] => darknet eval: 
2022-09-28 02:13:39,125 [foster.py] => CNN top1 curve: 44.17
2022-09-28 02:13:39,125 [foster.py] => CNN top5 curve: 86.67
2022-09-28 02:13:39,125 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 02:13:47,630 [foster.py] => Exemplar size: 320
2022-09-28 02:13:47,630 [trainer.py] => CNN: {'total': 49.72, 'old': 56.89, 'new': 23.38, 'base': 73.17, 'compound': 30.1}
2022-09-28 02:13:47,630 [trainer.py] => CNN top1 curve: [84.76, 71.17, 58.3, 49.72]
2022-09-28 02:13:47,630 [trainer.py] => CNN base curve: [84.76, 79.88, 75.0, 73.17]
2022-09-28 02:13:47,630 [trainer.py] => CNN old curve: [84.76, 79.88, 67.57, 56.89]
2022-09-28 02:13:47,630 [trainer.py] => CNN new curve: [0, 46.55, 24.59, 23.38]
2022-09-28 02:13:47,630 [trainer.py] => CNN compound curve: [0, 46.55, 35.29, 30.1]
2022-09-28 02:13:47,630 [trainer.py] => NME: {'total': 59.17, 'old': 61.13, 'new': 51.95, 'base': 68.29, 'compound': 51.53}
2022-09-28 02:13:47,630 [trainer.py] => NME top1 curve: [86.59, 75.23, 67.14, 59.17]
2022-09-28 02:13:47,630 [trainer.py] => NME base curve: [86.59, 76.83, 70.12, 68.29]
2022-09-28 02:13:47,630 [trainer.py] => NME old curve: [86.59, 76.83, 69.37, 61.13]
2022-09-28 02:13:47,630 [trainer.py] => NME new curve: [0, 70.69, 59.02, 51.95]
2022-09-28 02:13:47,630 [trainer.py] => NME compound curve: [0, 70.69, 63.03, 51.53]
2022-09-28 02:13:47,858 [foster.py] => Learning on 16-19
2022-09-28 02:13:47,859 [foster.py] => All params: 22390454
2022-09-28 02:13:47,859 [foster.py] => Trainable params: 11205734
2022-09-28 02:13:47,879 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 02:13:50,814 [foster.py] => Task 4, Epoch 1/34 => Loss 6.387, Loss_clf 2.149, Loss_fe 2.337, Loss_kd 1.601, Train_accy 42.63, Test_accy 41.78
2022-09-28 02:13:52,786 [foster.py] => Task 4, Epoch 2/34 => Loss 4.663, Loss_clf 1.033, Loss_fe 1.703, Loss_kd 1.623, Train_accy 40.69
2022-09-28 02:13:54,807 [foster.py] => Task 4, Epoch 3/34 => Loss 4.398, Loss_clf 0.909, Loss_fe 1.565, Loss_kd 1.620, Train_accy 43.92
2022-09-28 02:13:56,862 [foster.py] => Task 4, Epoch 4/34 => Loss 4.162, Loss_clf 0.854, Loss_fe 1.381, Loss_kd 1.622, Train_accy 45.21
2022-09-28 02:13:58,845 [foster.py] => Task 4, Epoch 5/34 => Loss 3.976, Loss_clf 0.812, Loss_fe 1.264, Loss_kd 1.600, Train_accy 44.78
2022-09-28 02:14:01,804 [foster.py] => Task 4, Epoch 6/34 => Loss 3.897, Loss_clf 0.802, Loss_fe 1.181, Loss_kd 1.611, Train_accy 50.38, Test_accy 46.35
2022-09-28 02:14:03,819 [foster.py] => Task 4, Epoch 7/34 => Loss 3.850, Loss_clf 0.752, Loss_fe 1.200, Loss_kd 1.598, Train_accy 49.52
2022-09-28 02:14:05,841 [foster.py] => Task 4, Epoch 8/34 => Loss 3.775, Loss_clf 0.764, Loss_fe 1.093, Loss_kd 1.615, Train_accy 45.10
2022-09-28 02:14:07,839 [foster.py] => Task 4, Epoch 9/34 => Loss 3.763, Loss_clf 0.784, Loss_fe 1.067, Loss_kd 1.610, Train_accy 49.73
2022-09-28 02:14:09,849 [foster.py] => Task 4, Epoch 10/34 => Loss 3.763, Loss_clf 0.782, Loss_fe 1.066, Loss_kd 1.613, Train_accy 46.93
2022-09-28 02:14:12,858 [foster.py] => Task 4, Epoch 11/34 => Loss 3.623, Loss_clf 0.691, Loss_fe 1.044, Loss_kd 1.589, Train_accy 46.72, Test_accy 47.95
2022-09-28 02:14:14,862 [foster.py] => Task 4, Epoch 12/34 => Loss 3.608, Loss_clf 0.715, Loss_fe 0.979, Loss_kd 1.612, Train_accy 48.44
2022-09-28 02:14:16,858 [foster.py] => Task 4, Epoch 13/34 => Loss 3.571, Loss_clf 0.754, Loss_fe 0.955, Loss_kd 1.568, Train_accy 49.62
2022-09-28 02:14:18,897 [foster.py] => Task 4, Epoch 14/34 => Loss 3.664, Loss_clf 0.774, Loss_fe 0.976, Loss_kd 1.613, Train_accy 55.97
2022-09-28 02:14:20,908 [foster.py] => Task 4, Epoch 15/34 => Loss 3.665, Loss_clf 0.791, Loss_fe 0.958, Loss_kd 1.613, Train_accy 44.35
2022-09-28 02:14:23,809 [foster.py] => Task 4, Epoch 16/34 => Loss 3.507, Loss_clf 0.694, Loss_fe 0.895, Loss_kd 1.614, Train_accy 50.59, Test_accy 50.23
2022-09-28 02:14:25,806 [foster.py] => Task 4, Epoch 17/34 => Loss 3.440, Loss_clf 0.699, Loss_fe 0.859, Loss_kd 1.585, Train_accy 53.50
2022-09-28 02:14:27,801 [foster.py] => Task 4, Epoch 18/34 => Loss 3.406, Loss_clf 0.650, Loss_fe 0.838, Loss_kd 1.616, Train_accy 55.97
2022-09-28 02:14:29,780 [foster.py] => Task 4, Epoch 19/34 => Loss 3.424, Loss_clf 0.622, Loss_fe 0.914, Loss_kd 1.590, Train_accy 52.74
2022-09-28 02:14:31,776 [foster.py] => Task 4, Epoch 20/34 => Loss 3.401, Loss_clf 0.630, Loss_fe 0.834, Loss_kd 1.631, Train_accy 51.67
2022-09-28 02:14:34,709 [foster.py] => Task 4, Epoch 21/34 => Loss 3.401, Loss_clf 0.648, Loss_fe 0.858, Loss_kd 1.597, Train_accy 48.33, Test_accy 47.95
2022-09-28 02:14:36,707 [foster.py] => Task 4, Epoch 22/34 => Loss 3.393, Loss_clf 0.628, Loss_fe 0.865, Loss_kd 1.600, Train_accy 52.85
2022-09-28 02:14:38,729 [foster.py] => Task 4, Epoch 23/34 => Loss 3.450, Loss_clf 0.678, Loss_fe 0.848, Loss_kd 1.620, Train_accy 50.59
2022-09-28 02:14:40,724 [foster.py] => Task 4, Epoch 24/34 => Loss 3.452, Loss_clf 0.673, Loss_fe 0.849, Loss_kd 1.626, Train_accy 50.48
2022-09-28 02:14:42,694 [foster.py] => Task 4, Epoch 25/34 => Loss 3.459, Loss_clf 0.720, Loss_fe 0.846, Loss_kd 1.595, Train_accy 50.16
2022-09-28 02:14:45,638 [foster.py] => Task 4, Epoch 26/34 => Loss 3.318, Loss_clf 0.598, Loss_fe 0.780, Loss_kd 1.634, Train_accy 50.70, Test_accy 48.86
2022-09-28 02:14:47,649 [foster.py] => Task 4, Epoch 27/34 => Loss 3.341, Loss_clf 0.609, Loss_fe 0.802, Loss_kd 1.625, Train_accy 53.07
2022-09-28 02:14:49,636 [foster.py] => Task 4, Epoch 28/34 => Loss 3.348, Loss_clf 0.629, Loss_fe 0.794, Loss_kd 1.621, Train_accy 50.91
2022-09-28 02:14:51,610 [foster.py] => Task 4, Epoch 29/34 => Loss 3.348, Loss_clf 0.636, Loss_fe 0.805, Loss_kd 1.606, Train_accy 53.07
2022-09-28 02:14:53,605 [foster.py] => Task 4, Epoch 30/34 => Loss 3.339, Loss_clf 0.592, Loss_fe 0.845, Loss_kd 1.601, Train_accy 51.88
2022-09-28 02:14:56,543 [foster.py] => Task 4, Epoch 31/34 => Loss 3.328, Loss_clf 0.599, Loss_fe 0.795, Loss_kd 1.628, Train_accy 53.61, Test_accy 48.17
2022-09-28 02:14:58,558 [foster.py] => Task 4, Epoch 32/34 => Loss 3.449, Loss_clf 0.688, Loss_fe 0.840, Loss_kd 1.617, Train_accy 54.14
2022-09-28 02:15:00,546 [foster.py] => Task 4, Epoch 33/34 => Loss 3.282, Loss_clf 0.608, Loss_fe 0.760, Loss_kd 1.612, Train_accy 51.24
2022-09-28 02:15:02,547 [foster.py] => Task 4, Epoch 34/34 => Loss 3.317, Loss_clf 0.590, Loss_fe 0.840, Loss_kd 1.589, Train_accy 52.64
2022-09-28 02:15:02,548 [foster.py] => do not weight align teacher!
2022-09-28 02:15:02,548 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 02:15:05,835 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.322,  Train_accy 18.51, Test_accy 37.67
2022-09-28 02:15:08,086 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.257,  Train_accy 18.41
2022-09-28 02:15:10,321 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.259,  Train_accy 18.41
2022-09-28 02:15:12,608 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.212,  Train_accy 19.05
2022-09-28 02:15:14,858 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.216,  Train_accy 19.48
2022-09-28 02:15:17,893 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.202,  Train_accy 19.27, Test_accy 37.90
2022-09-28 02:15:20,149 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.191,  Train_accy 19.27
2022-09-28 02:15:22,382 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.185,  Train_accy 19.38
2022-09-28 02:15:24,599 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.186,  Train_accy 19.16
2022-09-28 02:15:26,901 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.169,  Train_accy 19.38
2022-09-28 02:15:29,917 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.173,  Train_accy 19.48, Test_accy 37.90
2022-09-28 02:15:32,133 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.186,  Train_accy 21.10
2022-09-28 02:15:34,373 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.194,  Train_accy 19.91
2022-09-28 02:15:36,649 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.179,  Train_accy 20.78
2022-09-28 02:15:38,861 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.161,  Train_accy 20.56
2022-09-28 02:15:41,960 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.174,  Train_accy 19.70, Test_accy 38.58
2022-09-28 02:15:44,226 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.155,  Train_accy 20.67
2022-09-28 02:15:46,549 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.154,  Train_accy 20.88
2022-09-28 02:15:48,759 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.183,  Train_accy 19.91
2022-09-28 02:15:50,989 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.154,  Train_accy 19.91
2022-09-28 02:15:54,052 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.171,  Train_accy 20.34, Test_accy 39.04
2022-09-28 02:15:56,267 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.152,  Train_accy 20.45
2022-09-28 02:15:58,543 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.160,  Train_accy 21.31
2022-09-28 02:16:00,820 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.160,  Train_accy 20.56
2022-09-28 02:16:03,068 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.174,  Train_accy 20.13
2022-09-28 02:16:06,135 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.189,  Train_accy 21.31, Test_accy 39.27
2022-09-28 02:16:06,135 [foster.py] => do not weight align student!
2022-09-28 02:16:06,930 [foster.py] => darknet eval: 
2022-09-28 02:16:06,930 [foster.py] => CNN top1 curve: 39.27
2022-09-28 02:16:06,930 [foster.py] => CNN top5 curve: 86.53
2022-09-28 02:16:06,930 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 02:16:16,484 [foster.py] => Exemplar size: 380
2022-09-28 02:16:16,484 [trainer.py] => CNN: {'total': 48.17, 'old': 46.94, 'new': 53.85, 'base': 67.68, 'compound': 36.5}
2022-09-28 02:16:16,484 [trainer.py] => CNN top1 curve: [84.76, 71.17, 58.3, 49.72, 48.17]
2022-09-28 02:16:16,484 [trainer.py] => CNN base curve: [84.76, 79.88, 75.0, 73.17, 67.68]
2022-09-28 02:16:16,484 [trainer.py] => CNN old curve: [84.76, 79.88, 67.57, 56.89, 46.94]
2022-09-28 02:16:16,484 [trainer.py] => CNN new curve: [0, 46.55, 24.59, 23.38, 53.85]
2022-09-28 02:16:16,484 [trainer.py] => CNN compound curve: [0, 46.55, 35.29, 30.1, 36.5]
2022-09-28 02:16:16,484 [trainer.py] => NME: {'total': 55.94, 'old': 54.44, 'new': 62.82, 'base': 67.07, 'compound': 49.27}
2022-09-28 02:16:16,484 [trainer.py] => NME top1 curve: [86.59, 75.23, 67.14, 59.17, 55.94]
2022-09-28 02:16:16,484 [trainer.py] => NME base curve: [86.59, 76.83, 70.12, 68.29, 67.07]
2022-09-28 02:16:16,484 [trainer.py] => NME old curve: [86.59, 76.83, 69.37, 61.13, 54.44]
2022-09-28 02:16:16,484 [trainer.py] => NME new curve: [0, 70.69, 59.02, 51.95, 62.82]
2022-09-28 02:16:16,484 [trainer.py] => NME compound curve: [0, 70.69, 63.03, 51.53, 49.27]
2022-09-28 02:16:16,713 [foster.py] => Learning on 19-22
2022-09-28 02:16:16,713 [foster.py] => All params: 22396607
2022-09-28 02:16:16,713 [foster.py] => Trainable params: 11210348
2022-09-28 02:16:16,734 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 02:16:19,807 [foster.py] => Task 5, Epoch 1/34 => Loss 6.624, Loss_clf 1.858, Loss_fe 2.566, Loss_kd 1.900, Train_accy 37.16, Test_accy 39.09
2022-09-28 02:16:21,876 [foster.py] => Task 5, Epoch 2/34 => Loss 5.339, Loss_clf 1.170, Loss_fe 1.954, Loss_kd 1.913, Train_accy 34.67
2022-09-28 02:16:24,019 [foster.py] => Task 5, Epoch 3/34 => Loss 5.051, Loss_clf 1.084, Loss_fe 1.765, Loss_kd 1.902, Train_accy 39.16
2022-09-28 02:16:26,139 [foster.py] => Task 5, Epoch 4/34 => Loss 4.826, Loss_clf 1.029, Loss_fe 1.599, Loss_kd 1.899, Train_accy 35.76
2022-09-28 02:16:28,270 [foster.py] => Task 5, Epoch 5/34 => Loss 4.689, Loss_clf 0.991, Loss_fe 1.494, Loss_kd 1.903, Train_accy 40.66
2022-09-28 02:16:31,355 [foster.py] => Task 5, Epoch 6/34 => Loss 4.621, Loss_clf 0.994, Loss_fe 1.422, Loss_kd 1.904, Train_accy 40.06, Test_accy 40.87
2022-09-28 02:16:33,435 [foster.py] => Task 5, Epoch 7/34 => Loss 4.511, Loss_clf 0.956, Loss_fe 1.352, Loss_kd 1.903, Train_accy 39.96
2022-09-28 02:16:35,532 [foster.py] => Task 5, Epoch 8/34 => Loss 4.397, Loss_clf 0.916, Loss_fe 1.276, Loss_kd 1.904, Train_accy 41.66
2022-09-28 02:16:37,657 [foster.py] => Task 5, Epoch 9/34 => Loss 4.336, Loss_clf 0.899, Loss_fe 1.248, Loss_kd 1.890, Train_accy 42.46
2022-09-28 02:16:39,761 [foster.py] => Task 5, Epoch 10/34 => Loss 4.301, Loss_clf 0.888, Loss_fe 1.210, Loss_kd 1.903, Train_accy 42.56
2022-09-28 02:16:42,906 [foster.py] => Task 5, Epoch 11/34 => Loss 4.273, Loss_clf 0.896, Loss_fe 1.162, Loss_kd 1.913, Train_accy 41.56, Test_accy 41.87
2022-09-28 02:16:45,049 [foster.py] => Task 5, Epoch 12/34 => Loss 4.139, Loss_clf 0.831, Loss_fe 1.112, Loss_kd 1.896, Train_accy 42.96
2022-09-28 02:16:47,166 [foster.py] => Task 5, Epoch 13/34 => Loss 4.146, Loss_clf 0.841, Loss_fe 1.098, Loss_kd 1.906, Train_accy 43.36
2022-09-28 02:16:49,265 [foster.py] => Task 5, Epoch 14/34 => Loss 4.126, Loss_clf 0.838, Loss_fe 1.081, Loss_kd 1.906, Train_accy 43.56
2022-09-28 02:16:51,332 [foster.py] => Task 5, Epoch 15/34 => Loss 4.143, Loss_clf 0.847, Loss_fe 1.083, Loss_kd 1.911, Train_accy 42.76
2022-09-28 02:16:54,443 [foster.py] => Task 5, Epoch 16/34 => Loss 4.086, Loss_clf 0.819, Loss_fe 1.060, Loss_kd 1.906, Train_accy 44.96, Test_accy 44.84
2022-09-28 02:16:56,541 [foster.py] => Task 5, Epoch 17/34 => Loss 4.000, Loss_clf 0.787, Loss_fe 0.998, Loss_kd 1.913, Train_accy 43.56
2022-09-28 02:16:58,648 [foster.py] => Task 5, Epoch 18/34 => Loss 4.003, Loss_clf 0.791, Loss_fe 0.997, Loss_kd 1.913, Train_accy 45.65
2022-09-28 02:17:00,779 [foster.py] => Task 5, Epoch 19/34 => Loss 3.973, Loss_clf 0.777, Loss_fe 0.986, Loss_kd 1.908, Train_accy 44.66
2022-09-28 02:17:02,891 [foster.py] => Task 5, Epoch 20/34 => Loss 3.950, Loss_clf 0.773, Loss_fe 0.967, Loss_kd 1.908, Train_accy 45.25
2022-09-28 02:17:05,978 [foster.py] => Task 5, Epoch 21/34 => Loss 3.927, Loss_clf 0.761, Loss_fe 0.951, Loss_kd 1.913, Train_accy 45.75, Test_accy 43.85
2022-09-28 02:17:08,070 [foster.py] => Task 5, Epoch 22/34 => Loss 3.919, Loss_clf 0.756, Loss_fe 0.940, Loss_kd 1.921, Train_accy 46.25
2022-09-28 02:17:10,181 [foster.py] => Task 5, Epoch 23/34 => Loss 3.913, Loss_clf 0.764, Loss_fe 0.944, Loss_kd 1.904, Train_accy 45.75
2022-09-28 02:17:12,248 [foster.py] => Task 5, Epoch 24/34 => Loss 3.921, Loss_clf 0.774, Loss_fe 0.937, Loss_kd 1.909, Train_accy 44.96
2022-09-28 02:17:14,440 [foster.py] => Task 5, Epoch 25/34 => Loss 3.932, Loss_clf 0.774, Loss_fe 0.935, Loss_kd 1.919, Train_accy 46.75
2022-09-28 02:17:17,524 [foster.py] => Task 5, Epoch 26/34 => Loss 3.911, Loss_clf 0.765, Loss_fe 0.936, Loss_kd 1.908, Train_accy 45.85, Test_accy 45.24
2022-09-28 02:17:19,631 [foster.py] => Task 5, Epoch 27/34 => Loss 3.880, Loss_clf 0.750, Loss_fe 0.919, Loss_kd 1.910, Train_accy 45.65
2022-09-28 02:17:21,724 [foster.py] => Task 5, Epoch 28/34 => Loss 3.860, Loss_clf 0.734, Loss_fe 0.907, Loss_kd 1.916, Train_accy 46.95
2022-09-28 02:17:23,819 [foster.py] => Task 5, Epoch 29/34 => Loss 3.846, Loss_clf 0.734, Loss_fe 0.899, Loss_kd 1.911, Train_accy 46.65
2022-09-28 02:17:25,939 [foster.py] => Task 5, Epoch 30/34 => Loss 3.855, Loss_clf 0.734, Loss_fe 0.903, Loss_kd 1.916, Train_accy 47.15
2022-09-28 02:17:29,014 [foster.py] => Task 5, Epoch 31/34 => Loss 3.859, Loss_clf 0.742, Loss_fe 0.897, Loss_kd 1.918, Train_accy 46.45, Test_accy 45.24
2022-09-28 02:17:31,119 [foster.py] => Task 5, Epoch 32/34 => Loss 3.929, Loss_clf 0.773, Loss_fe 0.938, Loss_kd 1.916, Train_accy 43.06
2022-09-28 02:17:33,203 [foster.py] => Task 5, Epoch 33/34 => Loss 3.867, Loss_clf 0.750, Loss_fe 0.904, Loss_kd 1.912, Train_accy 46.05
2022-09-28 02:17:35,277 [foster.py] => Task 5, Epoch 34/34 => Loss 3.871, Loss_clf 0.745, Loss_fe 0.908, Loss_kd 1.915, Train_accy 47.75
2022-09-28 02:17:35,277 [foster.py] => do not weight align teacher!
2022-09-28 02:17:35,278 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 02:17:38,698 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.403,  Train_accy 18.68, Test_accy 34.52
2022-09-28 02:17:41,043 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.394,  Train_accy 18.78
2022-09-28 02:17:43,425 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.403,  Train_accy 18.28
2022-09-28 02:17:45,781 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.387,  Train_accy 19.28
2022-09-28 02:17:48,199 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.383,  Train_accy 19.88
2022-09-28 02:17:51,429 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.381,  Train_accy 19.08, Test_accy 35.71
2022-09-28 02:17:53,782 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.387,  Train_accy 19.18
2022-09-28 02:17:56,114 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.374,  Train_accy 19.68
2022-09-28 02:17:58,544 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.367,  Train_accy 20.38
2022-09-28 02:18:00,895 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.364,  Train_accy 19.48
2022-09-28 02:18:04,115 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.372,  Train_accy 18.98, Test_accy 36.31
2022-09-28 02:18:06,489 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.359,  Train_accy 20.18
2022-09-28 02:18:08,840 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.369,  Train_accy 20.28
2022-09-28 02:18:11,227 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.363,  Train_accy 20.18
2022-09-28 02:18:13,557 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.358,  Train_accy 20.58
2022-09-28 02:18:16,752 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.376,  Train_accy 20.38, Test_accy 35.91
2022-09-28 02:18:19,150 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.362,  Train_accy 20.78
2022-09-28 02:18:21,532 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.362,  Train_accy 20.98
2022-09-28 02:18:23,894 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.355,  Train_accy 19.78
2022-09-28 02:18:26,246 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.349,  Train_accy 20.88
2022-09-28 02:18:29,459 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.365,  Train_accy 20.28, Test_accy 37.10
2022-09-28 02:18:31,846 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.361,  Train_accy 20.28
2022-09-28 02:18:34,220 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.361,  Train_accy 20.48
2022-09-28 02:18:36,596 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.366,  Train_accy 20.08
2022-09-28 02:18:38,927 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.366,  Train_accy 20.08
2022-09-28 02:18:42,198 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.363,  Train_accy 20.68, Test_accy 36.90
2022-09-28 02:18:42,198 [foster.py] => do not weight align student!
2022-09-28 02:18:43,052 [foster.py] => darknet eval: 
2022-09-28 02:18:43,052 [foster.py] => CNN top1 curve: 36.9
2022-09-28 02:18:43,052 [foster.py] => CNN top5 curve: 84.92
2022-09-28 02:18:43,053 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 02:18:53,654 [foster.py] => Exemplar size: 440
2022-09-28 02:18:53,654 [trainer.py] => CNN: {'total': 45.24, 'old': 46.35, 'new': 37.88, 'base': 67.68, 'compound': 34.41}
2022-09-28 02:18:53,654 [trainer.py] => CNN top1 curve: [84.76, 71.17, 58.3, 49.72, 48.17, 45.24]
2022-09-28 02:18:53,654 [trainer.py] => CNN base curve: [84.76, 79.88, 75.0, 73.17, 67.68, 67.68]
2022-09-28 02:18:53,654 [trainer.py] => CNN old curve: [84.76, 79.88, 67.57, 56.89, 46.94, 46.35]
2022-09-28 02:18:53,654 [trainer.py] => CNN new curve: [0, 46.55, 24.59, 23.38, 53.85, 37.88]
2022-09-28 02:18:53,654 [trainer.py] => CNN compound curve: [0, 46.55, 35.29, 30.1, 36.5, 34.41]
2022-09-28 02:18:53,654 [trainer.py] => NME: {'total': 54.56, 'old': 55.02, 'new': 51.52, 'base': 66.46, 'compound': 48.82}
2022-09-28 02:18:53,654 [trainer.py] => NME top1 curve: [86.59, 75.23, 67.14, 59.17, 55.94, 54.56]
2022-09-28 02:18:53,654 [trainer.py] => NME base curve: [86.59, 76.83, 70.12, 68.29, 67.07, 66.46]
2022-09-28 02:18:53,654 [trainer.py] => NME old curve: [86.59, 76.83, 69.37, 61.13, 54.44, 55.02]
2022-09-28 02:18:53,654 [trainer.py] => NME new curve: [0, 70.69, 59.02, 51.95, 62.82, 51.52]
2022-09-28 02:18:53,654 [trainer.py] => NME compound curve: [0, 70.69, 63.03, 51.53, 49.27, 48.82]
2022-09-28 02:18:53,656 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 02:18:53,656 [trainer.py] => prefix: cil
2022-09-28 02:18:53,656 [trainer.py] => dataset: CFEE
2022-09-28 02:18:53,656 [trainer.py] => memory_size: 2000
2022-09-28 02:18:53,656 [trainer.py] => memory_per_class: 20
2022-09-28 02:18:53,656 [trainer.py] => fixed_memory: True
2022-09-28 02:18:53,656 [trainer.py] => shuffle: True
2022-09-28 02:18:53,656 [trainer.py] => init_cls: 7
2022-09-28 02:18:53,656 [trainer.py] => increment: 3
2022-09-28 02:18:53,656 [trainer.py] => model_name: foster
2022-09-28 02:18:53,656 [trainer.py] => convnet_type: resnet18
2022-09-28 02:18:53,656 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 02:18:53,656 [trainer.py] => seed: 1993
2022-09-28 02:18:53,656 [trainer.py] => beta1: 0.96
2022-09-28 02:18:53,656 [trainer.py] => beta2: 0.97
2022-09-28 02:18:53,656 [trainer.py] => oofc: ft
2022-09-28 02:18:53,656 [trainer.py] => is_teacher_wa: False
2022-09-28 02:18:53,656 [trainer.py] => is_student_wa: False
2022-09-28 02:18:53,656 [trainer.py] => lambda_okd: 1
2022-09-28 02:18:53,656 [trainer.py] => wa_value: 1
2022-09-28 02:18:53,656 [trainer.py] => init_epochs: 40
2022-09-28 02:18:53,656 [trainer.py] => init_lr: 0.01
2022-09-28 02:18:53,656 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 02:18:53,656 [trainer.py] => boosting_epochs: 34
2022-09-28 02:18:53,656 [trainer.py] => compression_epochs: 26
2022-09-28 02:18:53,656 [trainer.py] => lr: 0.001
2022-09-28 02:18:53,656 [trainer.py] => batch_size: 32
2022-09-28 02:18:53,656 [trainer.py] => weight_decay: 0.0005
2022-09-28 02:18:53,656 [trainer.py] => num_workers: 8
2022-09-28 02:18:53,656 [trainer.py] => T: 2
2022-09-28 02:18:53,656 [trainer.py] => nb_runs: 3
2022-09-28 02:18:53,656 [trainer.py] => fold: 10
2022-09-28 02:18:53,657 [data.py] => ========== Fold:0 ==========
2022-09-28 02:18:53,662 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 8, 15, 13, 17, 9, 11, 19, 21, 14, 10, 18, 12, 7, 16]
2022-09-28 02:18:53,874 [foster.py] => Learning on 0-7
2022-09-28 02:18:53,874 [foster.py] => All params: 11183694
2022-09-28 02:18:53,875 [foster.py] => Trainable params: 11183694
2022-09-28 02:18:56,235 [foster.py] => Task 0, Epoch 1/40 => Loss 1.375, Train_accy 49.51
2022-09-28 02:18:59,259 [foster.py] => Task 0, Epoch 2/40 => Loss 0.583, Train_accy 81.26, Test_accy 87.01
2022-09-28 02:19:02,267 [foster.py] => Task 0, Epoch 3/40 => Loss 0.387, Train_accy 86.57, Test_accy 88.14
2022-09-28 02:19:05,237 [foster.py] => Task 0, Epoch 4/40 => Loss 0.283, Train_accy 90.63, Test_accy 84.18
2022-09-28 02:19:08,188 [foster.py] => Task 0, Epoch 5/40 => Loss 0.225, Train_accy 92.24, Test_accy 89.27
2022-09-28 02:19:10,553 [foster.py] => Task 0, Epoch 6/40 => Loss 0.204, Train_accy 93.15
2022-09-28 02:19:13,556 [foster.py] => Task 0, Epoch 7/40 => Loss 0.176, Train_accy 94.20, Test_accy 88.70
2022-09-28 02:19:16,526 [foster.py] => Task 0, Epoch 8/40 => Loss 0.150, Train_accy 94.97, Test_accy 87.57
2022-09-28 02:19:19,589 [foster.py] => Task 0, Epoch 9/40 => Loss 0.116, Train_accy 96.22, Test_accy 87.57
2022-09-28 02:19:22,594 [foster.py] => Task 0, Epoch 10/40 => Loss 0.098, Train_accy 96.71, Test_accy 87.01
2022-09-28 02:19:24,966 [foster.py] => Task 0, Epoch 11/40 => Loss 0.085, Train_accy 97.76
2022-09-28 02:19:28,018 [foster.py] => Task 0, Epoch 12/40 => Loss 0.069, Train_accy 98.11, Test_accy 87.01
2022-09-28 02:19:30,974 [foster.py] => Task 0, Epoch 13/40 => Loss 0.060, Train_accy 98.18, Test_accy 89.27
2022-09-28 02:19:33,996 [foster.py] => Task 0, Epoch 14/40 => Loss 0.055, Train_accy 98.67, Test_accy 88.14
2022-09-28 02:19:36,993 [foster.py] => Task 0, Epoch 15/40 => Loss 0.062, Train_accy 98.18, Test_accy 88.14
2022-09-28 02:19:39,367 [foster.py] => Task 0, Epoch 16/40 => Loss 0.038, Train_accy 99.23
2022-09-28 02:19:42,334 [foster.py] => Task 0, Epoch 17/40 => Loss 0.039, Train_accy 99.37, Test_accy 88.70
2022-09-28 02:19:45,331 [foster.py] => Task 0, Epoch 18/40 => Loss 0.028, Train_accy 99.58, Test_accy 89.27
2022-09-28 02:19:48,282 [foster.py] => Task 0, Epoch 19/40 => Loss 0.025, Train_accy 99.65, Test_accy 88.70
2022-09-28 02:19:51,255 [foster.py] => Task 0, Epoch 20/40 => Loss 0.031, Train_accy 99.30, Test_accy 89.83
2022-09-28 02:19:53,623 [foster.py] => Task 0, Epoch 21/40 => Loss 0.026, Train_accy 99.44
2022-09-28 02:19:56,604 [foster.py] => Task 0, Epoch 22/40 => Loss 0.030, Train_accy 99.44, Test_accy 89.83
2022-09-28 02:19:59,632 [foster.py] => Task 0, Epoch 23/40 => Loss 0.026, Train_accy 99.30, Test_accy 88.70
2022-09-28 02:20:02,716 [foster.py] => Task 0, Epoch 24/40 => Loss 0.022, Train_accy 99.51, Test_accy 88.70
2022-09-28 02:20:05,699 [foster.py] => Task 0, Epoch 25/40 => Loss 0.020, Train_accy 99.58, Test_accy 89.27
2022-09-28 02:20:08,071 [foster.py] => Task 0, Epoch 26/40 => Loss 0.018, Train_accy 99.72
2022-09-28 02:20:11,073 [foster.py] => Task 0, Epoch 27/40 => Loss 0.027, Train_accy 99.37, Test_accy 90.40
2022-09-28 02:20:14,081 [foster.py] => Task 0, Epoch 28/40 => Loss 0.020, Train_accy 99.65, Test_accy 89.83
2022-09-28 02:20:17,072 [foster.py] => Task 0, Epoch 29/40 => Loss 0.016, Train_accy 99.79, Test_accy 89.27
2022-09-28 02:20:20,013 [foster.py] => Task 0, Epoch 30/40 => Loss 0.027, Train_accy 99.09, Test_accy 89.83
2022-09-28 02:20:22,429 [foster.py] => Task 0, Epoch 31/40 => Loss 0.014, Train_accy 100.00
2022-09-28 02:20:25,392 [foster.py] => Task 0, Epoch 32/40 => Loss 0.016, Train_accy 99.72, Test_accy 90.40
2022-09-28 02:20:28,385 [foster.py] => Task 0, Epoch 33/40 => Loss 0.014, Train_accy 99.86, Test_accy 89.83
2022-09-28 02:20:31,392 [foster.py] => Task 0, Epoch 34/40 => Loss 0.017, Train_accy 99.65, Test_accy 90.96
2022-09-28 02:20:34,404 [foster.py] => Task 0, Epoch 35/40 => Loss 0.012, Train_accy 99.93, Test_accy 90.40
2022-09-28 02:20:36,733 [foster.py] => Task 0, Epoch 36/40 => Loss 0.016, Train_accy 99.86
2022-09-28 02:20:39,720 [foster.py] => Task 0, Epoch 37/40 => Loss 0.013, Train_accy 99.86, Test_accy 90.40
2022-09-28 02:20:42,714 [foster.py] => Task 0, Epoch 38/40 => Loss 0.015, Train_accy 99.79, Test_accy 90.40
2022-09-28 02:20:45,672 [foster.py] => Task 0, Epoch 39/40 => Loss 0.015, Train_accy 99.86, Test_accy 88.70
2022-09-28 02:20:48,737 [foster.py] => Task 0, Epoch 40/40 => Loss 0.012, Train_accy 99.93, Test_accy 90.40
2022-09-28 02:20:48,738 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 02:20:55,712 [foster.py] => Exemplar size: 140
2022-09-28 02:20:55,712 [trainer.py] => CNN: {'total': 90.4, 'old': 90.4, 'new': 0, 'base': 90.4, 'compound': 0}
2022-09-28 02:20:55,712 [trainer.py] => CNN top1 curve: [90.4]
2022-09-28 02:20:55,713 [trainer.py] => CNN base curve: [90.4]
2022-09-28 02:20:55,713 [trainer.py] => CNN old curve: [90.4]
2022-09-28 02:20:55,713 [trainer.py] => CNN new curve: [0]
2022-09-28 02:20:55,713 [trainer.py] => CNN compound curve: [0]
2022-09-28 02:20:55,713 [trainer.py] => NME: {'total': 90.4, 'old': 90.4, 'new': 0, 'base': 90.4, 'compound': 0}
2022-09-28 02:20:55,713 [trainer.py] => NME top1 curve: [90.4]
2022-09-28 02:20:55,713 [trainer.py] => NME base curve: [90.4]
2022-09-28 02:20:55,713 [trainer.py] => NME old curve: [90.4]
2022-09-28 02:20:55,713 [trainer.py] => NME new curve: [0]
2022-09-28 02:20:55,713 [trainer.py] => NME compound curve: [0]
2022-09-28 02:20:55,942 [foster.py] => Learning on 7-10
2022-09-28 02:20:55,942 [foster.py] => All params: 22371995
2022-09-28 02:20:55,943 [foster.py] => Trainable params: 11191892
2022-09-28 02:20:55,963 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 02:20:58,404 [foster.py] => Task 1, Epoch 1/34 => Loss 4.720, Loss_clf 2.098, Loss_fe 1.963, Loss_kd 0.461, Train_accy 38.36, Test_accy 72.98
2022-09-28 02:21:00,157 [foster.py] => Task 1, Epoch 2/34 => Loss 2.453, Loss_clf 0.623, Loss_fe 1.170, Loss_kd 0.462, Train_accy 75.26
2022-09-28 02:21:01,888 [foster.py] => Task 1, Epoch 3/34 => Loss 1.956, Loss_clf 0.374, Loss_fe 0.943, Loss_kd 0.448, Train_accy 51.98
2022-09-28 02:21:03,609 [foster.py] => Task 1, Epoch 4/34 => Loss 1.761, Loss_clf 0.318, Loss_fe 0.801, Loss_kd 0.449, Train_accy 53.17
2022-09-28 02:21:05,348 [foster.py] => Task 1, Epoch 5/34 => Loss 1.666, Loss_clf 0.303, Loss_fe 0.721, Loss_kd 0.449, Train_accy 53.17
2022-09-28 02:21:07,842 [foster.py] => Task 1, Epoch 6/34 => Loss 1.599, Loss_clf 0.295, Loss_fe 0.669, Loss_kd 0.444, Train_accy 54.37, Test_accy 71.77
2022-09-28 02:21:09,547 [foster.py] => Task 1, Epoch 7/34 => Loss 1.550, Loss_clf 0.291, Loss_fe 0.618, Loss_kd 0.448, Train_accy 54.10
2022-09-28 02:21:11,258 [foster.py] => Task 1, Epoch 8/34 => Loss 1.456, Loss_clf 0.248, Loss_fe 0.561, Loss_kd 0.454, Train_accy 56.08
2022-09-28 02:21:13,060 [foster.py] => Task 1, Epoch 9/34 => Loss 1.410, Loss_clf 0.239, Loss_fe 0.527, Loss_kd 0.451, Train_accy 57.54
2022-09-28 02:21:14,820 [foster.py] => Task 1, Epoch 10/34 => Loss 1.394, Loss_clf 0.248, Loss_fe 0.502, Loss_kd 0.451, Train_accy 55.42
2022-09-28 02:21:17,324 [foster.py] => Task 1, Epoch 11/34 => Loss 1.350, Loss_clf 0.231, Loss_fe 0.477, Loss_kd 0.449, Train_accy 60.32, Test_accy 74.19
2022-09-28 02:21:19,091 [foster.py] => Task 1, Epoch 12/34 => Loss 1.296, Loss_clf 0.220, Loss_fe 0.436, Loss_kd 0.448, Train_accy 59.13
2022-09-28 02:21:20,807 [foster.py] => Task 1, Epoch 13/34 => Loss 1.297, Loss_clf 0.213, Loss_fe 0.436, Loss_kd 0.454, Train_accy 59.26
2022-09-28 02:21:22,546 [foster.py] => Task 1, Epoch 14/34 => Loss 1.260, Loss_clf 0.202, Loss_fe 0.411, Loss_kd 0.452, Train_accy 58.47
2022-09-28 02:21:24,284 [foster.py] => Task 1, Epoch 15/34 => Loss 1.242, Loss_clf 0.204, Loss_fe 0.401, Loss_kd 0.445, Train_accy 58.73
2022-09-28 02:21:26,786 [foster.py] => Task 1, Epoch 16/34 => Loss 1.241, Loss_clf 0.202, Loss_fe 0.392, Loss_kd 0.453, Train_accy 60.19, Test_accy 75.81
2022-09-28 02:21:28,538 [foster.py] => Task 1, Epoch 17/34 => Loss 1.212, Loss_clf 0.198, Loss_fe 0.374, Loss_kd 0.448, Train_accy 58.73
2022-09-28 02:21:30,233 [foster.py] => Task 1, Epoch 18/34 => Loss 1.189, Loss_clf 0.189, Loss_fe 0.359, Loss_kd 0.448, Train_accy 60.32
2022-09-28 02:21:31,979 [foster.py] => Task 1, Epoch 19/34 => Loss 1.177, Loss_clf 0.185, Loss_fe 0.352, Loss_kd 0.448, Train_accy 61.11
2022-09-28 02:21:33,761 [foster.py] => Task 1, Epoch 20/34 => Loss 1.184, Loss_clf 0.195, Loss_fe 0.358, Loss_kd 0.442, Train_accy 60.98
2022-09-28 02:21:36,244 [foster.py] => Task 1, Epoch 21/34 => Loss 1.182, Loss_clf 0.181, Loss_fe 0.360, Loss_kd 0.449, Train_accy 61.24, Test_accy 75.00
2022-09-28 02:21:38,015 [foster.py] => Task 1, Epoch 22/34 => Loss 1.128, Loss_clf 0.166, Loss_fe 0.322, Loss_kd 0.448, Train_accy 62.43
2022-09-28 02:21:39,740 [foster.py] => Task 1, Epoch 23/34 => Loss 1.135, Loss_clf 0.174, Loss_fe 0.336, Loss_kd 0.438, Train_accy 61.77
2022-09-28 02:21:41,464 [foster.py] => Task 1, Epoch 24/34 => Loss 1.152, Loss_clf 0.178, Loss_fe 0.337, Loss_kd 0.446, Train_accy 61.77
2022-09-28 02:21:43,224 [foster.py] => Task 1, Epoch 25/34 => Loss 1.124, Loss_clf 0.156, Loss_fe 0.317, Loss_kd 0.456, Train_accy 64.42
2022-09-28 02:21:45,707 [foster.py] => Task 1, Epoch 26/34 => Loss 1.134, Loss_clf 0.171, Loss_fe 0.318, Loss_kd 0.452, Train_accy 62.70, Test_accy 75.00
2022-09-28 02:21:47,462 [foster.py] => Task 1, Epoch 27/34 => Loss 1.131, Loss_clf 0.177, Loss_fe 0.316, Loss_kd 0.446, Train_accy 61.64
2022-09-28 02:21:49,169 [foster.py] => Task 1, Epoch 28/34 => Loss 1.136, Loss_clf 0.174, Loss_fe 0.316, Loss_kd 0.452, Train_accy 63.23
2022-09-28 02:21:50,920 [foster.py] => Task 1, Epoch 29/34 => Loss 1.117, Loss_clf 0.164, Loss_fe 0.317, Loss_kd 0.445, Train_accy 60.85
2022-09-28 02:21:52,630 [foster.py] => Task 1, Epoch 30/34 => Loss 1.127, Loss_clf 0.172, Loss_fe 0.317, Loss_kd 0.446, Train_accy 63.89
2022-09-28 02:21:55,111 [foster.py] => Task 1, Epoch 31/34 => Loss 1.150, Loss_clf 0.178, Loss_fe 0.331, Loss_kd 0.449, Train_accy 61.51, Test_accy 75.00
2022-09-28 02:21:56,814 [foster.py] => Task 1, Epoch 32/34 => Loss 1.120, Loss_clf 0.162, Loss_fe 0.314, Loss_kd 0.450, Train_accy 62.83
2022-09-28 02:21:58,568 [foster.py] => Task 1, Epoch 33/34 => Loss 1.107, Loss_clf 0.159, Loss_fe 0.312, Loss_kd 0.446, Train_accy 62.30
2022-09-28 02:22:00,310 [foster.py] => Task 1, Epoch 34/34 => Loss 1.097, Loss_clf 0.159, Loss_fe 0.299, Loss_kd 0.447, Train_accy 61.51
2022-09-28 02:22:00,310 [foster.py] => do not weight align teacher!
2022-09-28 02:22:00,311 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 02:22:03,229 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.619,  Train_accy 18.25, Test_accy 61.69
2022-09-28 02:22:05,124 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.465,  Train_accy 18.52
2022-09-28 02:22:07,075 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.388,  Train_accy 18.52
2022-09-28 02:22:08,975 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.312,  Train_accy 19.44
2022-09-28 02:22:10,922 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.284,  Train_accy 20.37
2022-09-28 02:22:13,506 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.262,  Train_accy 22.09, Test_accy 66.13
2022-09-28 02:22:15,472 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.250,  Train_accy 22.62
2022-09-28 02:22:17,376 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.248,  Train_accy 23.02
2022-09-28 02:22:19,267 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.226,  Train_accy 24.34
2022-09-28 02:22:21,212 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.230,  Train_accy 25.93
2022-09-28 02:22:23,808 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.213,  Train_accy 26.32, Test_accy 66.94
2022-09-28 02:22:25,752 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.205,  Train_accy 26.85
2022-09-28 02:22:27,717 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.215,  Train_accy 27.51
2022-09-28 02:22:29,721 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.210,  Train_accy 26.72
2022-09-28 02:22:31,623 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.191,  Train_accy 26.72
2022-09-28 02:22:34,223 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.202,  Train_accy 27.38, Test_accy 68.15
2022-09-28 02:22:36,105 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.209,  Train_accy 28.44
2022-09-28 02:22:38,038 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.196,  Train_accy 27.91
2022-09-28 02:22:39,987 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.202,  Train_accy 26.72
2022-09-28 02:22:41,892 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.189,  Train_accy 26.72
2022-09-28 02:22:44,516 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.190,  Train_accy 28.70, Test_accy 67.74
2022-09-28 02:22:46,452 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.197,  Train_accy 27.25
2022-09-28 02:22:48,420 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.190,  Train_accy 28.04
2022-09-28 02:22:50,336 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.189,  Train_accy 27.65
2022-09-28 02:22:52,240 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.186,  Train_accy 28.44
2022-09-28 02:22:54,860 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.186,  Train_accy 28.70, Test_accy 67.74
2022-09-28 02:22:54,861 [foster.py] => do not weight align student!
2022-09-28 02:22:55,536 [foster.py] => darknet eval: 
2022-09-28 02:22:55,536 [foster.py] => CNN top1 curve: 67.74
2022-09-28 02:22:55,536 [foster.py] => CNN top5 curve: 98.79
2022-09-28 02:22:55,537 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 02:23:01,874 [foster.py] => Exemplar size: 200
2022-09-28 02:23:01,874 [trainer.py] => CNN: {'total': 75.4, 'old': 87.01, 'new': 46.48, 'base': 87.01, 'compound': 46.48}
2022-09-28 02:23:01,874 [trainer.py] => CNN top1 curve: [90.4, 75.4]
2022-09-28 02:23:01,874 [trainer.py] => CNN base curve: [90.4, 87.01]
2022-09-28 02:23:01,874 [trainer.py] => CNN old curve: [90.4, 87.01]
2022-09-28 02:23:01,874 [trainer.py] => CNN new curve: [0, 46.48]
2022-09-28 02:23:01,874 [trainer.py] => CNN compound curve: [0, 46.48]
2022-09-28 02:23:01,874 [trainer.py] => NME: {'total': 84.27, 'old': 85.31, 'new': 81.69, 'base': 85.31, 'compound': 81.69}
2022-09-28 02:23:01,874 [trainer.py] => NME top1 curve: [90.4, 84.27]
2022-09-28 02:23:01,874 [trainer.py] => NME base curve: [90.4, 85.31]
2022-09-28 02:23:01,875 [trainer.py] => NME old curve: [90.4, 85.31]
2022-09-28 02:23:01,875 [trainer.py] => NME new curve: [0, 81.69]
2022-09-28 02:23:01,875 [trainer.py] => NME compound curve: [0, 81.69]
2022-09-28 02:23:02,105 [foster.py] => Learning on 10-13
2022-09-28 02:23:02,105 [foster.py] => All params: 22378148
2022-09-28 02:23:02,105 [foster.py] => Trainable params: 11196506
2022-09-28 02:23:02,126 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 02:23:04,769 [foster.py] => Task 2, Epoch 1/34 => Loss 5.218, Loss_clf 2.083, Loss_fe 1.972, Loss_kd 0.895, Train_accy 41.38, Test_accy 56.48
2022-09-28 02:23:06,593 [foster.py] => Task 2, Epoch 2/34 => Loss 3.215, Loss_clf 0.708, Loss_fe 1.342, Loss_kd 0.897, Train_accy 57.51
2022-09-28 02:23:08,417 [foster.py] => Task 2, Epoch 3/34 => Loss 2.793, Loss_clf 0.535, Loss_fe 1.114, Loss_kd 0.880, Train_accy 42.49
2022-09-28 02:23:10,248 [foster.py] => Task 2, Epoch 4/34 => Loss 2.680, Loss_clf 0.505, Loss_fe 1.011, Loss_kd 0.895, Train_accy 49.14
2022-09-28 02:23:12,085 [foster.py] => Task 2, Epoch 5/34 => Loss 2.535, Loss_clf 0.479, Loss_fe 0.907, Loss_kd 0.884, Train_accy 49.14
2022-09-28 02:23:14,746 [foster.py] => Task 2, Epoch 6/34 => Loss 2.453, Loss_clf 0.461, Loss_fe 0.844, Loss_kd 0.884, Train_accy 46.18, Test_accy 63.89
2022-09-28 02:23:16,556 [foster.py] => Task 2, Epoch 7/34 => Loss 2.396, Loss_clf 0.448, Loss_fe 0.793, Loss_kd 0.889, Train_accy 49.14
2022-09-28 02:23:18,428 [foster.py] => Task 2, Epoch 8/34 => Loss 2.311, Loss_clf 0.414, Loss_fe 0.743, Loss_kd 0.887, Train_accy 48.03
2022-09-28 02:23:20,231 [foster.py] => Task 2, Epoch 9/34 => Loss 2.264, Loss_clf 0.410, Loss_fe 0.703, Loss_kd 0.886, Train_accy 49.26
2022-09-28 02:23:22,027 [foster.py] => Task 2, Epoch 10/34 => Loss 2.198, Loss_clf 0.398, Loss_fe 0.672, Loss_kd 0.867, Train_accy 48.65
2022-09-28 02:23:24,757 [foster.py] => Task 2, Epoch 11/34 => Loss 2.196, Loss_clf 0.396, Loss_fe 0.638, Loss_kd 0.894, Train_accy 48.65, Test_accy 64.51
2022-09-28 02:23:26,587 [foster.py] => Task 2, Epoch 12/34 => Loss 2.170, Loss_clf 0.399, Loss_fe 0.614, Loss_kd 0.889, Train_accy 49.14
2022-09-28 02:23:28,375 [foster.py] => Task 2, Epoch 13/34 => Loss 2.149, Loss_clf 0.383, Loss_fe 0.609, Loss_kd 0.890, Train_accy 50.25
2022-09-28 02:23:30,192 [foster.py] => Task 2, Epoch 14/34 => Loss 2.105, Loss_clf 0.381, Loss_fe 0.576, Loss_kd 0.883, Train_accy 48.77
2022-09-28 02:23:32,035 [foster.py] => Task 2, Epoch 15/34 => Loss 2.066, Loss_clf 0.354, Loss_fe 0.540, Loss_kd 0.902, Train_accy 49.63
2022-09-28 02:23:34,673 [foster.py] => Task 2, Epoch 16/34 => Loss 2.051, Loss_clf 0.354, Loss_fe 0.539, Loss_kd 0.891, Train_accy 50.00, Test_accy 64.81
2022-09-28 02:23:36,555 [foster.py] => Task 2, Epoch 17/34 => Loss 2.019, Loss_clf 0.347, Loss_fe 0.530, Loss_kd 0.879, Train_accy 47.66
2022-09-28 02:23:38,385 [foster.py] => Task 2, Epoch 18/34 => Loss 2.021, Loss_clf 0.349, Loss_fe 0.527, Loss_kd 0.881, Train_accy 50.00
2022-09-28 02:23:40,194 [foster.py] => Task 2, Epoch 19/34 => Loss 2.007, Loss_clf 0.351, Loss_fe 0.516, Loss_kd 0.877, Train_accy 49.63
2022-09-28 02:23:41,991 [foster.py] => Task 2, Epoch 20/34 => Loss 2.012, Loss_clf 0.346, Loss_fe 0.503, Loss_kd 0.894, Train_accy 49.51
2022-09-28 02:23:44,675 [foster.py] => Task 2, Epoch 21/34 => Loss 1.964, Loss_clf 0.329, Loss_fe 0.485, Loss_kd 0.884, Train_accy 51.72, Test_accy 65.74
2022-09-28 02:23:46,458 [foster.py] => Task 2, Epoch 22/34 => Loss 1.943, Loss_clf 0.322, Loss_fe 0.474, Loss_kd 0.882, Train_accy 50.99
2022-09-28 02:23:48,278 [foster.py] => Task 2, Epoch 23/34 => Loss 1.974, Loss_clf 0.339, Loss_fe 0.485, Loss_kd 0.884, Train_accy 50.00
2022-09-28 02:23:50,081 [foster.py] => Task 2, Epoch 24/34 => Loss 1.941, Loss_clf 0.324, Loss_fe 0.470, Loss_kd 0.882, Train_accy 51.11
2022-09-28 02:23:51,867 [foster.py] => Task 2, Epoch 25/34 => Loss 1.945, Loss_clf 0.324, Loss_fe 0.478, Loss_kd 0.879, Train_accy 50.12
2022-09-28 02:23:54,592 [foster.py] => Task 2, Epoch 26/34 => Loss 1.941, Loss_clf 0.329, Loss_fe 0.464, Loss_kd 0.882, Train_accy 49.88, Test_accy 65.43
2022-09-28 02:23:56,427 [foster.py] => Task 2, Epoch 27/34 => Loss 1.927, Loss_clf 0.317, Loss_fe 0.458, Loss_kd 0.886, Train_accy 49.88
2022-09-28 02:23:58,235 [foster.py] => Task 2, Epoch 28/34 => Loss 1.924, Loss_clf 0.318, Loss_fe 0.455, Loss_kd 0.886, Train_accy 49.88
2022-09-28 02:24:00,039 [foster.py] => Task 2, Epoch 29/34 => Loss 1.919, Loss_clf 0.314, Loss_fe 0.458, Loss_kd 0.882, Train_accy 50.25
2022-09-28 02:24:01,847 [foster.py] => Task 2, Epoch 30/34 => Loss 1.967, Loss_clf 0.334, Loss_fe 0.478, Loss_kd 0.888, Train_accy 52.59
2022-09-28 02:24:04,505 [foster.py] => Task 2, Epoch 31/34 => Loss 1.920, Loss_clf 0.313, Loss_fe 0.457, Loss_kd 0.885, Train_accy 51.85, Test_accy 63.58
2022-09-28 02:24:06,336 [foster.py] => Task 2, Epoch 32/34 => Loss 1.909, Loss_clf 0.310, Loss_fe 0.440, Loss_kd 0.892, Train_accy 50.86
2022-09-28 02:24:08,127 [foster.py] => Task 2, Epoch 33/34 => Loss 1.935, Loss_clf 0.313, Loss_fe 0.468, Loss_kd 0.888, Train_accy 50.12
2022-09-28 02:24:09,945 [foster.py] => Task 2, Epoch 34/34 => Loss 1.950, Loss_clf 0.328, Loss_fe 0.474, Loss_kd 0.884, Train_accy 49.75
2022-09-28 02:24:09,946 [foster.py] => do not weight align teacher!
2022-09-28 02:24:09,947 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 02:24:12,961 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.752,  Train_accy 17.36, Test_accy 48.77
2022-09-28 02:24:14,958 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.659,  Train_accy 17.98
2022-09-28 02:24:16,996 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.608,  Train_accy 17.98
2022-09-28 02:24:19,014 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.584,  Train_accy 18.10
2022-09-28 02:24:21,020 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.578,  Train_accy 18.84
2022-09-28 02:24:23,773 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.582,  Train_accy 19.33, Test_accy 50.62
2022-09-28 02:24:25,767 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.560,  Train_accy 20.69
2022-09-28 02:24:27,769 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.559,  Train_accy 21.18
2022-09-28 02:24:29,785 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.554,  Train_accy 21.67
2022-09-28 02:24:31,815 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.547,  Train_accy 22.78
2022-09-28 02:24:34,554 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.539,  Train_accy 22.54, Test_accy 51.23
2022-09-28 02:24:36,569 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.551,  Train_accy 22.17
2022-09-28 02:24:38,609 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.542,  Train_accy 23.28
2022-09-28 02:24:40,630 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.528,  Train_accy 22.66
2022-09-28 02:24:42,630 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.525,  Train_accy 24.88
2022-09-28 02:24:45,425 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.518,  Train_accy 24.75, Test_accy 52.16
2022-09-28 02:24:47,439 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.532,  Train_accy 24.88
2022-09-28 02:24:49,479 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.525,  Train_accy 24.38
2022-09-28 02:24:51,486 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.531,  Train_accy 24.14
2022-09-28 02:24:53,543 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.520,  Train_accy 25.49
2022-09-28 02:24:56,353 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.526,  Train_accy 25.00, Test_accy 53.70
2022-09-28 02:24:58,367 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.528,  Train_accy 25.86
2022-09-28 02:25:00,395 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.537,  Train_accy 25.12
2022-09-28 02:25:02,384 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.519,  Train_accy 24.26
2022-09-28 02:25:04,422 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.533,  Train_accy 26.23
2022-09-28 02:25:07,150 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.528,  Train_accy 25.99, Test_accy 53.09
2022-09-28 02:25:07,151 [foster.py] => do not weight align student!
2022-09-28 02:25:07,877 [foster.py] => darknet eval: 
2022-09-28 02:25:07,877 [foster.py] => CNN top1 curve: 53.09
2022-09-28 02:25:07,877 [foster.py] => CNN top5 curve: 98.15
2022-09-28 02:25:07,877 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 02:25:15,318 [foster.py] => Exemplar size: 260
2022-09-28 02:25:15,318 [trainer.py] => CNN: {'total': 64.81, 'old': 73.79, 'new': 35.53, 'base': 81.36, 'compound': 44.9}
2022-09-28 02:25:15,318 [trainer.py] => CNN top1 curve: [90.4, 75.4, 64.81]
2022-09-28 02:25:15,318 [trainer.py] => CNN base curve: [90.4, 87.01, 81.36]
2022-09-28 02:25:15,318 [trainer.py] => CNN old curve: [90.4, 87.01, 73.79]
2022-09-28 02:25:15,318 [trainer.py] => CNN new curve: [0, 46.48, 35.53]
2022-09-28 02:25:15,318 [trainer.py] => CNN compound curve: [0, 46.48, 44.9]
2022-09-28 02:25:15,318 [trainer.py] => NME: {'total': 75.93, 'old': 77.02, 'new': 72.37, 'base': 76.27, 'compound': 75.51}
2022-09-28 02:25:15,318 [trainer.py] => NME top1 curve: [90.4, 84.27, 75.93]
2022-09-28 02:25:15,318 [trainer.py] => NME base curve: [90.4, 85.31, 76.27]
2022-09-28 02:25:15,319 [trainer.py] => NME old curve: [90.4, 85.31, 77.02]
2022-09-28 02:25:15,319 [trainer.py] => NME new curve: [0, 81.69, 72.37]
2022-09-28 02:25:15,319 [trainer.py] => NME compound curve: [0, 81.69, 75.51]
2022-09-28 02:25:15,550 [foster.py] => Learning on 13-16
2022-09-28 02:25:15,550 [foster.py] => All params: 22384301
2022-09-28 02:25:15,551 [foster.py] => Trainable params: 11201120
2022-09-28 02:25:15,571 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 02:25:18,346 [foster.py] => Task 3, Epoch 1/34 => Loss 6.286, Loss_clf 2.342, Loss_fe 2.323, Loss_kd 1.317, Train_accy 34.65, Test_accy 42.23
2022-09-28 02:25:20,286 [foster.py] => Task 3, Epoch 2/34 => Loss 4.446, Loss_clf 1.129, Loss_fe 1.716, Loss_kd 1.301, Train_accy 36.00
2022-09-28 02:25:22,205 [foster.py] => Task 3, Epoch 3/34 => Loss 4.040, Loss_clf 0.948, Loss_fe 1.495, Loss_kd 1.297, Train_accy 39.50
2022-09-28 02:25:24,130 [foster.py] => Task 3, Epoch 4/34 => Loss 3.912, Loss_clf 0.946, Loss_fe 1.389, Loss_kd 1.281, Train_accy 37.70
2022-09-28 02:25:26,040 [foster.py] => Task 3, Epoch 5/34 => Loss 3.766, Loss_clf 0.889, Loss_fe 1.283, Loss_kd 1.295, Train_accy 38.60
2022-09-28 02:25:28,802 [foster.py] => Task 3, Epoch 6/34 => Loss 3.639, Loss_clf 0.864, Loss_fe 1.199, Loss_kd 1.280, Train_accy 39.28, Test_accy 56.74
2022-09-28 02:25:30,777 [foster.py] => Task 3, Epoch 7/34 => Loss 3.532, Loss_clf 0.816, Loss_fe 1.131, Loss_kd 1.288, Train_accy 40.74
2022-09-28 02:25:32,676 [foster.py] => Task 3, Epoch 8/34 => Loss 3.481, Loss_clf 0.814, Loss_fe 1.089, Loss_kd 1.281, Train_accy 38.04
2022-09-28 02:25:34,641 [foster.py] => Task 3, Epoch 9/34 => Loss 3.430, Loss_clf 0.802, Loss_fe 1.052, Loss_kd 1.281, Train_accy 39.50
2022-09-28 02:25:36,537 [foster.py] => Task 3, Epoch 10/34 => Loss 3.378, Loss_clf 0.786, Loss_fe 1.007, Loss_kd 1.288, Train_accy 42.78
2022-09-28 02:25:39,359 [foster.py] => Task 3, Epoch 11/34 => Loss 3.348, Loss_clf 0.772, Loss_fe 0.990, Loss_kd 1.289, Train_accy 41.42, Test_accy 59.84
2022-09-28 02:25:41,250 [foster.py] => Task 3, Epoch 12/34 => Loss 3.292, Loss_clf 0.750, Loss_fe 0.954, Loss_kd 1.291, Train_accy 42.44
2022-09-28 02:25:43,161 [foster.py] => Task 3, Epoch 13/34 => Loss 3.274, Loss_clf 0.756, Loss_fe 0.934, Loss_kd 1.287, Train_accy 40.18
2022-09-28 02:25:45,077 [foster.py] => Task 3, Epoch 14/34 => Loss 3.224, Loss_clf 0.724, Loss_fe 0.907, Loss_kd 1.294, Train_accy 43.00
2022-09-28 02:25:47,002 [foster.py] => Task 3, Epoch 15/34 => Loss 3.165, Loss_clf 0.702, Loss_fe 0.886, Loss_kd 1.281, Train_accy 44.58
2022-09-28 02:25:49,850 [foster.py] => Task 3, Epoch 16/34 => Loss 3.161, Loss_clf 0.717, Loss_fe 0.855, Loss_kd 1.291, Train_accy 42.21, Test_accy 59.33
2022-09-28 02:25:51,742 [foster.py] => Task 3, Epoch 17/34 => Loss 3.114, Loss_clf 0.691, Loss_fe 0.841, Loss_kd 1.286, Train_accy 42.55
2022-09-28 02:25:53,690 [foster.py] => Task 3, Epoch 18/34 => Loss 3.097, Loss_clf 0.684, Loss_fe 0.839, Loss_kd 1.279, Train_accy 41.99
2022-09-28 02:25:55,598 [foster.py] => Task 3, Epoch 19/34 => Loss 3.060, Loss_clf 0.669, Loss_fe 0.805, Loss_kd 1.289, Train_accy 45.82
2022-09-28 02:25:57,555 [foster.py] => Task 3, Epoch 20/34 => Loss 3.066, Loss_clf 0.682, Loss_fe 0.801, Loss_kd 1.286, Train_accy 41.87
2022-09-28 02:26:00,385 [foster.py] => Task 3, Epoch 21/34 => Loss 3.028, Loss_clf 0.667, Loss_fe 0.788, Loss_kd 1.278, Train_accy 46.28, Test_accy 60.88
2022-09-28 02:26:02,319 [foster.py] => Task 3, Epoch 22/34 => Loss 2.999, Loss_clf 0.648, Loss_fe 0.770, Loss_kd 1.285, Train_accy 46.05
2022-09-28 02:26:04,258 [foster.py] => Task 3, Epoch 23/34 => Loss 3.013, Loss_clf 0.644, Loss_fe 0.777, Loss_kd 1.294, Train_accy 45.94
2022-09-28 02:26:06,209 [foster.py] => Task 3, Epoch 24/34 => Loss 2.988, Loss_clf 0.634, Loss_fe 0.766, Loss_kd 1.291, Train_accy 46.05
2022-09-28 02:26:08,135 [foster.py] => Task 3, Epoch 25/34 => Loss 2.944, Loss_clf 0.616, Loss_fe 0.739, Loss_kd 1.292, Train_accy 45.60
2022-09-28 02:26:10,939 [foster.py] => Task 3, Epoch 26/34 => Loss 2.951, Loss_clf 0.623, Loss_fe 0.744, Loss_kd 1.287, Train_accy 46.16, Test_accy 61.14
2022-09-28 02:26:12,855 [foster.py] => Task 3, Epoch 27/34 => Loss 2.935, Loss_clf 0.618, Loss_fe 0.743, Loss_kd 1.279, Train_accy 45.82
2022-09-28 02:26:14,756 [foster.py] => Task 3, Epoch 28/34 => Loss 2.972, Loss_clf 0.634, Loss_fe 0.753, Loss_kd 1.288, Train_accy 45.15
2022-09-28 02:26:16,690 [foster.py] => Task 3, Epoch 29/34 => Loss 2.940, Loss_clf 0.613, Loss_fe 0.733, Loss_kd 1.295, Train_accy 47.97
2022-09-28 02:26:18,598 [foster.py] => Task 3, Epoch 30/34 => Loss 2.960, Loss_clf 0.627, Loss_fe 0.743, Loss_kd 1.291, Train_accy 46.50
2022-09-28 02:26:21,397 [foster.py] => Task 3, Epoch 31/34 => Loss 2.944, Loss_clf 0.629, Loss_fe 0.733, Loss_kd 1.285, Train_accy 46.39, Test_accy 61.66
2022-09-28 02:26:23,320 [foster.py] => Task 3, Epoch 32/34 => Loss 2.937, Loss_clf 0.614, Loss_fe 0.738, Loss_kd 1.287, Train_accy 45.03
2022-09-28 02:26:25,233 [foster.py] => Task 3, Epoch 33/34 => Loss 2.916, Loss_clf 0.610, Loss_fe 0.730, Loss_kd 1.280, Train_accy 46.05
2022-09-28 02:26:27,164 [foster.py] => Task 3, Epoch 34/34 => Loss 2.974, Loss_clf 0.628, Loss_fe 0.757, Loss_kd 1.292, Train_accy 47.07
2022-09-28 02:26:27,164 [foster.py] => do not weight align teacher!
2022-09-28 02:26:27,165 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 02:26:30,363 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.170,  Train_accy 17.83, Test_accy 44.56
2022-09-28 02:26:32,503 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.053,  Train_accy 19.19
2022-09-28 02:26:34,663 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.006,  Train_accy 19.41
2022-09-28 02:26:36,804 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 1.991,  Train_accy 20.09
2022-09-28 02:26:38,924 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.966,  Train_accy 19.41
2022-09-28 02:26:41,882 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.961,  Train_accy 19.86, Test_accy 47.41
2022-09-28 02:26:44,056 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.964,  Train_accy 19.64
2022-09-28 02:26:46,254 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.954,  Train_accy 19.75
2022-09-28 02:26:48,427 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.948,  Train_accy 19.98
2022-09-28 02:26:50,582 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.939,  Train_accy 19.64
2022-09-28 02:26:53,514 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.935,  Train_accy 19.86, Test_accy 49.48
2022-09-28 02:26:55,626 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.936,  Train_accy 20.09
2022-09-28 02:26:57,784 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.935,  Train_accy 20.09
2022-09-28 02:26:59,924 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.936,  Train_accy 19.75
2022-09-28 02:27:02,050 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.939,  Train_accy 20.20
2022-09-28 02:27:04,978 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.936,  Train_accy 20.32, Test_accy 51.30
2022-09-28 02:27:07,101 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.919,  Train_accy 20.09
2022-09-28 02:27:09,286 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.932,  Train_accy 20.09
2022-09-28 02:27:11,411 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.937,  Train_accy 20.32
2022-09-28 02:27:13,584 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.930,  Train_accy 20.09
2022-09-28 02:27:16,536 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.926,  Train_accy 20.77, Test_accy 51.04
2022-09-28 02:27:18,715 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.929,  Train_accy 20.65
2022-09-28 02:27:20,876 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.924,  Train_accy 20.09
2022-09-28 02:27:23,027 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.932,  Train_accy 20.09
2022-09-28 02:27:25,193 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.925,  Train_accy 20.09
2022-09-28 02:27:28,153 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.923,  Train_accy 20.65, Test_accy 51.30
2022-09-28 02:27:28,154 [foster.py] => do not weight align student!
2022-09-28 02:27:28,926 [foster.py] => darknet eval: 
2022-09-28 02:27:28,926 [foster.py] => CNN top1 curve: 51.3
2022-09-28 02:27:28,926 [foster.py] => CNN top5 curve: 92.23
2022-09-28 02:27:28,926 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 02:27:37,486 [foster.py] => Exemplar size: 320
2022-09-28 02:27:37,486 [trainer.py] => CNN: {'total': 61.92, 'old': 65.74, 'new': 41.94, 'base': 79.66, 'compound': 46.89}
2022-09-28 02:27:37,486 [trainer.py] => CNN top1 curve: [90.4, 75.4, 64.81, 61.92]
2022-09-28 02:27:37,486 [trainer.py] => CNN base curve: [90.4, 87.01, 81.36, 79.66]
2022-09-28 02:27:37,486 [trainer.py] => CNN old curve: [90.4, 87.01, 73.79, 65.74]
2022-09-28 02:27:37,486 [trainer.py] => CNN new curve: [0, 46.48, 35.53, 41.94]
2022-09-28 02:27:37,486 [trainer.py] => CNN compound curve: [0, 46.48, 44.9, 46.89]
2022-09-28 02:27:37,486 [trainer.py] => NME: {'total': 65.54, 'old': 71.3, 'new': 35.48, 'base': 74.58, 'compound': 57.89}
2022-09-28 02:27:37,486 [trainer.py] => NME top1 curve: [90.4, 84.27, 75.93, 65.54]
2022-09-28 02:27:37,486 [trainer.py] => NME base curve: [90.4, 85.31, 76.27, 74.58]
2022-09-28 02:27:37,486 [trainer.py] => NME old curve: [90.4, 85.31, 77.02, 71.3]
2022-09-28 02:27:37,486 [trainer.py] => NME new curve: [0, 81.69, 72.37, 35.48]
2022-09-28 02:27:37,486 [trainer.py] => NME compound curve: [0, 81.69, 75.51, 57.89]
2022-09-28 02:27:37,714 [foster.py] => Learning on 16-19
2022-09-28 02:27:37,715 [foster.py] => All params: 22390454
2022-09-28 02:27:37,715 [foster.py] => Trainable params: 11205734
2022-09-28 02:27:37,735 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 02:27:40,804 [foster.py] => Task 4, Epoch 1/34 => Loss 6.510, Loss_clf 2.061, Loss_fe 2.491, Loss_kd 1.649, Train_accy 38.55, Test_accy 47.74
2022-09-28 02:27:42,835 [foster.py] => Task 4, Epoch 2/34 => Loss 4.819, Loss_clf 1.042, Loss_fe 1.821, Loss_kd 1.647, Train_accy 34.66
2022-09-28 02:27:44,835 [foster.py] => Task 4, Epoch 3/34 => Loss 4.548, Loss_clf 0.973, Loss_fe 1.619, Loss_kd 1.647, Train_accy 38.76
2022-09-28 02:27:46,855 [foster.py] => Task 4, Epoch 4/34 => Loss 4.394, Loss_clf 0.942, Loss_fe 1.503, Loss_kd 1.641, Train_accy 37.71
2022-09-28 02:27:48,938 [foster.py] => Task 4, Epoch 5/34 => Loss 4.291, Loss_clf 0.927, Loss_fe 1.408, Loss_kd 1.647, Train_accy 39.18
2022-09-28 02:27:51,876 [foster.py] => Task 4, Epoch 6/34 => Loss 4.195, Loss_clf 0.906, Loss_fe 1.334, Loss_kd 1.646, Train_accy 36.66, Test_accy 51.36
2022-09-28 02:27:53,869 [foster.py] => Task 4, Epoch 7/34 => Loss 4.110, Loss_clf 0.879, Loss_fe 1.277, Loss_kd 1.645, Train_accy 37.18
2022-09-28 02:27:55,857 [foster.py] => Task 4, Epoch 8/34 => Loss 4.057, Loss_clf 0.874, Loss_fe 1.220, Loss_kd 1.653, Train_accy 37.71
2022-09-28 02:27:57,897 [foster.py] => Task 4, Epoch 9/34 => Loss 3.982, Loss_clf 0.852, Loss_fe 1.171, Loss_kd 1.649, Train_accy 39.18
2022-09-28 02:27:59,900 [foster.py] => Task 4, Epoch 10/34 => Loss 3.887, Loss_clf 0.819, Loss_fe 1.119, Loss_kd 1.641, Train_accy 40.65
2022-09-28 02:28:02,834 [foster.py] => Task 4, Epoch 11/34 => Loss 3.879, Loss_clf 0.832, Loss_fe 1.097, Loss_kd 1.642, Train_accy 38.76, Test_accy 52.26
2022-09-28 02:28:04,847 [foster.py] => Task 4, Epoch 12/34 => Loss 3.841, Loss_clf 0.821, Loss_fe 1.070, Loss_kd 1.641, Train_accy 38.76
2022-09-28 02:28:06,857 [foster.py] => Task 4, Epoch 13/34 => Loss 3.767, Loss_clf 0.793, Loss_fe 1.021, Loss_kd 1.645, Train_accy 39.18
2022-09-28 02:28:08,874 [foster.py] => Task 4, Epoch 14/34 => Loss 3.778, Loss_clf 0.799, Loss_fe 1.020, Loss_kd 1.649, Train_accy 41.18
2022-09-28 02:28:10,882 [foster.py] => Task 4, Epoch 15/34 => Loss 3.703, Loss_clf 0.764, Loss_fe 0.981, Loss_kd 1.649, Train_accy 41.18
2022-09-28 02:28:13,885 [foster.py] => Task 4, Epoch 16/34 => Loss 3.707, Loss_clf 0.781, Loss_fe 0.966, Loss_kd 1.651, Train_accy 40.44, Test_accy 53.17
2022-09-28 02:28:15,931 [foster.py] => Task 4, Epoch 17/34 => Loss 3.648, Loss_clf 0.750, Loss_fe 0.945, Loss_kd 1.644, Train_accy 41.39
2022-09-28 02:28:17,931 [foster.py] => Task 4, Epoch 18/34 => Loss 3.621, Loss_clf 0.744, Loss_fe 0.925, Loss_kd 1.644, Train_accy 42.75
2022-09-28 02:28:19,973 [foster.py] => Task 4, Epoch 19/34 => Loss 3.591, Loss_clf 0.735, Loss_fe 0.905, Loss_kd 1.643, Train_accy 41.49
2022-09-28 02:28:22,010 [foster.py] => Task 4, Epoch 20/34 => Loss 3.605, Loss_clf 0.738, Loss_fe 0.909, Loss_kd 1.648, Train_accy 42.65
2022-09-28 02:28:24,953 [foster.py] => Task 4, Epoch 21/34 => Loss 3.580, Loss_clf 0.737, Loss_fe 0.890, Loss_kd 1.644, Train_accy 42.75, Test_accy 53.17
2022-09-28 02:28:27,032 [foster.py] => Task 4, Epoch 22/34 => Loss 3.571, Loss_clf 0.719, Loss_fe 0.894, Loss_kd 1.648, Train_accy 44.22
2022-09-28 02:28:29,025 [foster.py] => Task 4, Epoch 23/34 => Loss 3.528, Loss_clf 0.708, Loss_fe 0.868, Loss_kd 1.644, Train_accy 42.65
2022-09-28 02:28:31,022 [foster.py] => Task 4, Epoch 24/34 => Loss 3.539, Loss_clf 0.709, Loss_fe 0.868, Loss_kd 1.653, Train_accy 42.75
2022-09-28 02:28:33,066 [foster.py] => Task 4, Epoch 25/34 => Loss 3.513, Loss_clf 0.698, Loss_fe 0.859, Loss_kd 1.648, Train_accy 44.22
2022-09-28 02:28:36,032 [foster.py] => Task 4, Epoch 26/34 => Loss 3.552, Loss_clf 0.715, Loss_fe 0.884, Loss_kd 1.645, Train_accy 41.70, Test_accy 53.17
2022-09-28 02:28:38,055 [foster.py] => Task 4, Epoch 27/34 => Loss 3.482, Loss_clf 0.688, Loss_fe 0.838, Loss_kd 1.647, Train_accy 45.06
2022-09-28 02:28:40,057 [foster.py] => Task 4, Epoch 28/34 => Loss 3.532, Loss_clf 0.708, Loss_fe 0.863, Loss_kd 1.651, Train_accy 43.91
2022-09-28 02:28:42,073 [foster.py] => Task 4, Epoch 29/34 => Loss 3.513, Loss_clf 0.704, Loss_fe 0.854, Loss_kd 1.646, Train_accy 43.91
2022-09-28 02:28:44,134 [foster.py] => Task 4, Epoch 30/34 => Loss 3.508, Loss_clf 0.699, Loss_fe 0.855, Loss_kd 1.646, Train_accy 45.06
2022-09-28 02:28:47,029 [foster.py] => Task 4, Epoch 31/34 => Loss 3.465, Loss_clf 0.664, Loss_fe 0.839, Loss_kd 1.652, Train_accy 46.11, Test_accy 52.94
2022-09-28 02:28:49,040 [foster.py] => Task 4, Epoch 32/34 => Loss 3.507, Loss_clf 0.692, Loss_fe 0.851, Loss_kd 1.654, Train_accy 44.43
2022-09-28 02:28:51,033 [foster.py] => Task 4, Epoch 33/34 => Loss 3.479, Loss_clf 0.681, Loss_fe 0.837, Loss_kd 1.651, Train_accy 43.91
2022-09-28 02:28:53,079 [foster.py] => Task 4, Epoch 34/34 => Loss 3.482, Loss_clf 0.692, Loss_fe 0.834, Loss_kd 1.648, Train_accy 43.70
2022-09-28 02:28:53,079 [foster.py] => do not weight align teacher!
2022-09-28 02:28:53,080 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 02:28:56,360 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.317,  Train_accy 17.96, Test_accy 43.44
2022-09-28 02:28:58,630 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.256,  Train_accy 19.85
2022-09-28 02:29:00,887 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.234,  Train_accy 19.12
2022-09-28 02:29:03,164 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.224,  Train_accy 19.75
2022-09-28 02:29:05,437 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.223,  Train_accy 19.85
2022-09-28 02:29:08,489 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.210,  Train_accy 20.06, Test_accy 46.38
2022-09-28 02:29:10,746 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.203,  Train_accy 19.75
2022-09-28 02:29:13,066 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.209,  Train_accy 20.17
2022-09-28 02:29:15,298 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.205,  Train_accy 20.17
2022-09-28 02:29:17,531 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.208,  Train_accy 20.38
2022-09-28 02:29:20,585 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.201,  Train_accy 20.27, Test_accy 47.29
2022-09-28 02:29:22,887 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.195,  Train_accy 20.27
2022-09-28 02:29:25,161 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.197,  Train_accy 20.17
2022-09-28 02:29:27,405 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.195,  Train_accy 20.90
2022-09-28 02:29:29,645 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.196,  Train_accy 20.17
2022-09-28 02:29:32,767 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.189,  Train_accy 20.90, Test_accy 46.83
2022-09-28 02:29:35,053 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.185,  Train_accy 21.01
2022-09-28 02:29:37,343 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.184,  Train_accy 20.69
2022-09-28 02:29:39,703 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.189,  Train_accy 20.80
2022-09-28 02:29:41,993 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.193,  Train_accy 21.32
2022-09-28 02:29:45,085 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.180,  Train_accy 20.59, Test_accy 48.19
2022-09-28 02:29:47,347 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.187,  Train_accy 21.22
2022-09-28 02:29:49,629 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.181,  Train_accy 21.11
2022-09-28 02:29:51,929 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.185,  Train_accy 20.59
2022-09-28 02:29:54,194 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.184,  Train_accy 21.22
2022-09-28 02:29:57,250 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.179,  Train_accy 20.06, Test_accy 48.42
2022-09-28 02:29:57,250 [foster.py] => do not weight align student!
2022-09-28 02:29:58,061 [foster.py] => darknet eval: 
2022-09-28 02:29:58,061 [foster.py] => CNN top1 curve: 48.42
2022-09-28 02:29:58,061 [foster.py] => CNN top5 curve: 87.56
2022-09-28 02:29:58,061 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 02:30:07,607 [foster.py] => Exemplar size: 380
2022-09-28 02:30:07,607 [trainer.py] => CNN: {'total': 53.17, 'old': 55.96, 'new': 33.93, 'base': 75.14, 'compound': 38.49}
2022-09-28 02:30:07,607 [trainer.py] => CNN top1 curve: [90.4, 75.4, 64.81, 61.92, 53.17]
2022-09-28 02:30:07,607 [trainer.py] => CNN base curve: [90.4, 87.01, 81.36, 79.66, 75.14]
2022-09-28 02:30:07,607 [trainer.py] => CNN old curve: [90.4, 87.01, 73.79, 65.74, 55.96]
2022-09-28 02:30:07,607 [trainer.py] => CNN new curve: [0, 46.48, 35.53, 41.94, 33.93]
2022-09-28 02:30:07,607 [trainer.py] => CNN compound curve: [0, 46.48, 44.9, 46.89, 38.49]
2022-09-28 02:30:07,607 [trainer.py] => NME: {'total': 59.73, 'old': 60.88, 'new': 51.79, 'base': 71.19, 'compound': 52.08}
2022-09-28 02:30:07,607 [trainer.py] => NME top1 curve: [90.4, 84.27, 75.93, 65.54, 59.73]
2022-09-28 02:30:07,607 [trainer.py] => NME base curve: [90.4, 85.31, 76.27, 74.58, 71.19]
2022-09-28 02:30:07,607 [trainer.py] => NME old curve: [90.4, 85.31, 77.02, 71.3, 60.88]
2022-09-28 02:30:07,607 [trainer.py] => NME new curve: [0, 81.69, 72.37, 35.48, 51.79]
2022-09-28 02:30:07,607 [trainer.py] => NME compound curve: [0, 81.69, 75.51, 57.89, 52.08]
2022-09-28 02:30:07,836 [foster.py] => Learning on 19-22
2022-09-28 02:30:07,837 [foster.py] => All params: 22396607
2022-09-28 02:30:07,837 [foster.py] => Trainable params: 11210348
2022-09-28 02:30:07,857 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 02:30:11,035 [foster.py] => Task 5, Epoch 1/34 => Loss 6.598, Loss_clf 1.951, Loss_fe 2.462, Loss_kd 1.887, Train_accy 38.71, Test_accy 46.14
2022-09-28 02:30:13,123 [foster.py] => Task 5, Epoch 2/34 => Loss 5.144, Loss_clf 1.112, Loss_fe 1.844, Loss_kd 1.890, Train_accy 35.12
2022-09-28 02:30:15,229 [foster.py] => Task 5, Epoch 3/34 => Loss 4.887, Loss_clf 1.017, Loss_fe 1.680, Loss_kd 1.891, Train_accy 38.11
2022-09-28 02:30:17,344 [foster.py] => Task 5, Epoch 4/34 => Loss 4.703, Loss_clf 0.973, Loss_fe 1.542, Loss_kd 1.889, Train_accy 38.21
2022-09-28 02:30:19,471 [foster.py] => Task 5, Epoch 5/34 => Loss 4.601, Loss_clf 0.946, Loss_fe 1.461, Loss_kd 1.894, Train_accy 41.99
2022-09-28 02:30:22,582 [foster.py] => Task 5, Epoch 6/34 => Loss 4.502, Loss_clf 0.938, Loss_fe 1.380, Loss_kd 1.886, Train_accy 40.10, Test_accy 47.52
2022-09-28 02:30:24,705 [foster.py] => Task 5, Epoch 7/34 => Loss 4.394, Loss_clf 0.886, Loss_fe 1.312, Loss_kd 1.896, Train_accy 40.80
2022-09-28 02:30:26,799 [foster.py] => Task 5, Epoch 8/34 => Loss 4.369, Loss_clf 0.893, Loss_fe 1.275, Loss_kd 1.900, Train_accy 41.09
2022-09-28 02:30:28,889 [foster.py] => Task 5, Epoch 9/34 => Loss 4.275, Loss_clf 0.864, Loss_fe 1.218, Loss_kd 1.894, Train_accy 41.59
2022-09-28 02:30:30,970 [foster.py] => Task 5, Epoch 10/34 => Loss 4.224, Loss_clf 0.859, Loss_fe 1.171, Loss_kd 1.894, Train_accy 43.78
2022-09-28 02:30:34,056 [foster.py] => Task 5, Epoch 11/34 => Loss 4.200, Loss_clf 0.857, Loss_fe 1.143, Loss_kd 1.901, Train_accy 42.79, Test_accy 51.09
2022-09-28 02:30:36,166 [foster.py] => Task 5, Epoch 12/34 => Loss 4.159, Loss_clf 0.841, Loss_fe 1.126, Loss_kd 1.893, Train_accy 44.28
2022-09-28 02:30:38,293 [foster.py] => Task 5, Epoch 13/34 => Loss 4.101, Loss_clf 0.824, Loss_fe 1.087, Loss_kd 1.891, Train_accy 45.67
2022-09-28 02:30:40,369 [foster.py] => Task 5, Epoch 14/34 => Loss 4.099, Loss_clf 0.819, Loss_fe 1.078, Loss_kd 1.901, Train_accy 44.68
2022-09-28 02:30:42,552 [foster.py] => Task 5, Epoch 15/34 => Loss 4.024, Loss_clf 0.802, Loss_fe 1.030, Loss_kd 1.893, Train_accy 44.48
2022-09-28 02:30:45,630 [foster.py] => Task 5, Epoch 16/34 => Loss 4.025, Loss_clf 0.793, Loss_fe 1.037, Loss_kd 1.896, Train_accy 42.99, Test_accy 52.48
2022-09-28 02:30:47,721 [foster.py] => Task 5, Epoch 17/34 => Loss 3.983, Loss_clf 0.789, Loss_fe 1.007, Loss_kd 1.889, Train_accy 44.68
2022-09-28 02:30:49,811 [foster.py] => Task 5, Epoch 18/34 => Loss 4.004, Loss_clf 0.803, Loss_fe 1.009, Loss_kd 1.893, Train_accy 45.97
2022-09-28 02:30:51,933 [foster.py] => Task 5, Epoch 19/34 => Loss 3.965, Loss_clf 0.788, Loss_fe 0.986, Loss_kd 1.892, Train_accy 46.37
2022-09-28 02:30:54,048 [foster.py] => Task 5, Epoch 20/34 => Loss 3.929, Loss_clf 0.773, Loss_fe 0.961, Loss_kd 1.896, Train_accy 45.87
2022-09-28 02:30:57,176 [foster.py] => Task 5, Epoch 21/34 => Loss 3.941, Loss_clf 0.778, Loss_fe 0.967, Loss_kd 1.897, Train_accy 45.37, Test_accy 51.88
2022-09-28 02:30:59,293 [foster.py] => Task 5, Epoch 22/34 => Loss 3.899, Loss_clf 0.752, Loss_fe 0.943, Loss_kd 1.904, Train_accy 46.27
2022-09-28 02:31:01,416 [foster.py] => Task 5, Epoch 23/34 => Loss 3.885, Loss_clf 0.750, Loss_fe 0.930, Loss_kd 1.905, Train_accy 47.26
2022-09-28 02:31:03,537 [foster.py] => Task 5, Epoch 24/34 => Loss 3.870, Loss_clf 0.751, Loss_fe 0.924, Loss_kd 1.896, Train_accy 46.37
2022-09-28 02:31:05,655 [foster.py] => Task 5, Epoch 25/34 => Loss 3.900, Loss_clf 0.762, Loss_fe 0.929, Loss_kd 1.907, Train_accy 47.26
2022-09-28 02:31:08,757 [foster.py] => Task 5, Epoch 26/34 => Loss 3.868, Loss_clf 0.742, Loss_fe 0.928, Loss_kd 1.899, Train_accy 45.17, Test_accy 52.08
2022-09-28 02:31:10,875 [foster.py] => Task 5, Epoch 27/34 => Loss 3.872, Loss_clf 0.752, Loss_fe 0.921, Loss_kd 1.899, Train_accy 46.37
2022-09-28 02:31:12,987 [foster.py] => Task 5, Epoch 28/34 => Loss 3.870, Loss_clf 0.749, Loss_fe 0.928, Loss_kd 1.893, Train_accy 45.47
2022-09-28 02:31:15,068 [foster.py] => Task 5, Epoch 29/34 => Loss 3.843, Loss_clf 0.729, Loss_fe 0.911, Loss_kd 1.903, Train_accy 46.77
2022-09-28 02:31:17,209 [foster.py] => Task 5, Epoch 30/34 => Loss 3.815, Loss_clf 0.721, Loss_fe 0.893, Loss_kd 1.901, Train_accy 47.66
2022-09-28 02:31:20,293 [foster.py] => Task 5, Epoch 31/34 => Loss 3.872, Loss_clf 0.746, Loss_fe 0.925, Loss_kd 1.901, Train_accy 46.37, Test_accy 52.28
2022-09-28 02:31:22,425 [foster.py] => Task 5, Epoch 32/34 => Loss 3.853, Loss_clf 0.742, Loss_fe 0.905, Loss_kd 1.906, Train_accy 46.57
2022-09-28 02:31:24,524 [foster.py] => Task 5, Epoch 33/34 => Loss 3.853, Loss_clf 0.751, Loss_fe 0.911, Loss_kd 1.892, Train_accy 46.27
2022-09-28 02:31:26,612 [foster.py] => Task 5, Epoch 34/34 => Loss 3.842, Loss_clf 0.737, Loss_fe 0.908, Loss_kd 1.897, Train_accy 46.97
2022-09-28 02:31:26,612 [foster.py] => do not weight align teacher!
2022-09-28 02:31:26,612 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 02:31:30,095 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.449,  Train_accy 18.81, Test_accy 42.57
2022-09-28 02:31:32,469 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.427,  Train_accy 20.60
2022-09-28 02:31:34,823 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.408,  Train_accy 20.60
2022-09-28 02:31:37,162 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.405,  Train_accy 20.60
2022-09-28 02:31:39,522 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.389,  Train_accy 20.10
2022-09-28 02:31:42,742 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.381,  Train_accy 20.10, Test_accy 43.56
2022-09-28 02:31:45,122 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.381,  Train_accy 21.09
2022-09-28 02:31:47,477 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.375,  Train_accy 20.30
2022-09-28 02:31:49,815 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.363,  Train_accy 21.49
2022-09-28 02:31:52,204 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.362,  Train_accy 20.90
2022-09-28 02:31:55,449 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.373,  Train_accy 20.80, Test_accy 44.55
2022-09-28 02:31:57,818 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.357,  Train_accy 21.49
2022-09-28 02:32:00,215 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.365,  Train_accy 21.29
2022-09-28 02:32:02,581 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.362,  Train_accy 21.99
2022-09-28 02:32:04,925 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.358,  Train_accy 21.79
2022-09-28 02:32:08,144 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.368,  Train_accy 22.99, Test_accy 44.95
2022-09-28 02:32:10,540 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.347,  Train_accy 22.99
2022-09-28 02:32:12,910 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.354,  Train_accy 23.58
2022-09-28 02:32:15,283 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.350,  Train_accy 22.89
2022-09-28 02:32:17,710 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.353,  Train_accy 22.99
2022-09-28 02:32:20,934 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.348,  Train_accy 22.99, Test_accy 45.54
2022-09-28 02:32:23,266 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.348,  Train_accy 23.48
2022-09-28 02:32:25,717 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.350,  Train_accy 22.59
2022-09-28 02:32:28,060 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.351,  Train_accy 22.89
2022-09-28 02:32:30,407 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.358,  Train_accy 23.08
2022-09-28 02:32:33,646 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.353,  Train_accy 22.59, Test_accy 44.75
2022-09-28 02:32:33,647 [foster.py] => do not weight align student!
2022-09-28 02:32:34,536 [foster.py] => darknet eval: 
2022-09-28 02:32:34,536 [foster.py] => CNN top1 curve: 44.75
2022-09-28 02:32:34,536 [foster.py] => CNN top5 curve: 85.94
2022-09-28 02:32:34,537 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 02:32:45,209 [foster.py] => Exemplar size: 440
2022-09-28 02:32:45,209 [trainer.py] => CNN: {'total': 51.88, 'old': 54.07, 'new': 36.51, 'base': 74.01, 'compound': 39.94}
2022-09-28 02:32:45,209 [trainer.py] => CNN top1 curve: [90.4, 75.4, 64.81, 61.92, 53.17, 51.88]
2022-09-28 02:32:45,209 [trainer.py] => CNN base curve: [90.4, 87.01, 81.36, 79.66, 75.14, 74.01]
2022-09-28 02:32:45,209 [trainer.py] => CNN old curve: [90.4, 87.01, 73.79, 65.74, 55.96, 54.07]
2022-09-28 02:32:45,209 [trainer.py] => CNN new curve: [0, 46.48, 35.53, 41.94, 33.93, 36.51]
2022-09-28 02:32:45,209 [trainer.py] => CNN compound curve: [0, 46.48, 44.9, 46.89, 38.49, 39.94]
2022-09-28 02:32:45,209 [trainer.py] => NME: {'total': 59.01, 'old': 59.95, 'new': 52.38, 'base': 69.49, 'compound': 53.35}
2022-09-28 02:32:45,209 [trainer.py] => NME top1 curve: [90.4, 84.27, 75.93, 65.54, 59.73, 59.01]
2022-09-28 02:32:45,209 [trainer.py] => NME base curve: [90.4, 85.31, 76.27, 74.58, 71.19, 69.49]
2022-09-28 02:32:45,209 [trainer.py] => NME old curve: [90.4, 85.31, 77.02, 71.3, 60.88, 59.95]
2022-09-28 02:32:45,209 [trainer.py] => NME new curve: [0, 81.69, 72.37, 35.48, 51.79, 52.38]
2022-09-28 02:32:45,209 [trainer.py] => NME compound curve: [0, 81.69, 75.51, 57.89, 52.08, 53.35]
2022-09-28 02:32:45,210 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 02:32:45,210 [trainer.py] => prefix: cil
2022-09-28 02:32:45,210 [trainer.py] => dataset: CFEE
2022-09-28 02:32:45,210 [trainer.py] => memory_size: 2000
2022-09-28 02:32:45,211 [trainer.py] => memory_per_class: 20
2022-09-28 02:32:45,211 [trainer.py] => fixed_memory: True
2022-09-28 02:32:45,211 [trainer.py] => shuffle: True
2022-09-28 02:32:45,211 [trainer.py] => init_cls: 7
2022-09-28 02:32:45,211 [trainer.py] => increment: 3
2022-09-28 02:32:45,211 [trainer.py] => model_name: foster
2022-09-28 02:32:45,211 [trainer.py] => convnet_type: resnet18
2022-09-28 02:32:45,211 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 02:32:45,211 [trainer.py] => seed: 1993
2022-09-28 02:32:45,211 [trainer.py] => beta1: 0.96
2022-09-28 02:32:45,211 [trainer.py] => beta2: 0.97
2022-09-28 02:32:45,211 [trainer.py] => oofc: ft
2022-09-28 02:32:45,211 [trainer.py] => is_teacher_wa: False
2022-09-28 02:32:45,211 [trainer.py] => is_student_wa: False
2022-09-28 02:32:45,211 [trainer.py] => lambda_okd: 1
2022-09-28 02:32:45,211 [trainer.py] => wa_value: 1
2022-09-28 02:32:45,211 [trainer.py] => init_epochs: 40
2022-09-28 02:32:45,211 [trainer.py] => init_lr: 0.01
2022-09-28 02:32:45,211 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 02:32:45,211 [trainer.py] => boosting_epochs: 34
2022-09-28 02:32:45,211 [trainer.py] => compression_epochs: 26
2022-09-28 02:32:45,211 [trainer.py] => lr: 0.001
2022-09-28 02:32:45,211 [trainer.py] => batch_size: 32
2022-09-28 02:32:45,211 [trainer.py] => weight_decay: 0.0005
2022-09-28 02:32:45,211 [trainer.py] => num_workers: 8
2022-09-28 02:32:45,211 [trainer.py] => T: 2
2022-09-28 02:32:45,211 [trainer.py] => nb_runs: 3
2022-09-28 02:32:45,211 [trainer.py] => fold: 10
2022-09-28 02:32:45,211 [data.py] => ========== Fold:1 ==========
2022-09-28 02:32:45,216 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 8, 15, 13, 17, 9, 11, 19, 21, 14, 10, 18, 12, 7, 16]
2022-09-28 02:32:45,428 [foster.py] => Learning on 0-7
2022-09-28 02:32:45,429 [foster.py] => All params: 11183694
2022-09-28 02:32:45,429 [foster.py] => Trainable params: 11183694
2022-09-28 02:32:47,832 [foster.py] => Task 0, Epoch 1/40 => Loss 1.342, Train_accy 49.07
2022-09-28 02:32:50,812 [foster.py] => Task 0, Epoch 2/40 => Loss 0.542, Train_accy 81.15, Test_accy 87.16
2022-09-28 02:32:53,792 [foster.py] => Task 0, Epoch 3/40 => Loss 0.360, Train_accy 86.84, Test_accy 89.19
2022-09-28 02:32:56,747 [foster.py] => Task 0, Epoch 4/40 => Loss 0.270, Train_accy 91.02, Test_accy 90.54
2022-09-28 02:32:59,762 [foster.py] => Task 0, Epoch 5/40 => Loss 0.241, Train_accy 91.98, Test_accy 85.81
2022-09-28 02:33:02,125 [foster.py] => Task 0, Epoch 6/40 => Loss 0.181, Train_accy 94.31
2022-09-28 02:33:05,108 [foster.py] => Task 0, Epoch 7/40 => Loss 0.156, Train_accy 95.00, Test_accy 89.19
2022-09-28 02:33:08,085 [foster.py] => Task 0, Epoch 8/40 => Loss 0.133, Train_accy 95.89, Test_accy 88.51
2022-09-28 02:33:11,055 [foster.py] => Task 0, Epoch 9/40 => Loss 0.134, Train_accy 95.13, Test_accy 89.19
2022-09-28 02:33:14,010 [foster.py] => Task 0, Epoch 10/40 => Loss 0.100, Train_accy 96.78, Test_accy 85.81
2022-09-28 02:33:16,371 [foster.py] => Task 0, Epoch 11/40 => Loss 0.081, Train_accy 97.19
2022-09-28 02:33:19,384 [foster.py] => Task 0, Epoch 12/40 => Loss 0.073, Train_accy 97.67, Test_accy 88.51
2022-09-28 02:33:22,349 [foster.py] => Task 0, Epoch 13/40 => Loss 0.061, Train_accy 98.70, Test_accy 86.49
2022-09-28 02:33:25,330 [foster.py] => Task 0, Epoch 14/40 => Loss 0.053, Train_accy 98.63, Test_accy 86.49
2022-09-28 02:33:28,331 [foster.py] => Task 0, Epoch 15/40 => Loss 0.050, Train_accy 98.63, Test_accy 85.14
2022-09-28 02:33:30,725 [foster.py] => Task 0, Epoch 16/40 => Loss 0.056, Train_accy 98.70
2022-09-28 02:33:33,707 [foster.py] => Task 0, Epoch 17/40 => Loss 0.032, Train_accy 99.59, Test_accy 89.19
2022-09-28 02:33:36,709 [foster.py] => Task 0, Epoch 18/40 => Loss 0.034, Train_accy 99.31, Test_accy 89.86
2022-09-28 02:33:39,670 [foster.py] => Task 0, Epoch 19/40 => Loss 0.037, Train_accy 98.90, Test_accy 87.16
2022-09-28 02:33:42,650 [foster.py] => Task 0, Epoch 20/40 => Loss 0.030, Train_accy 99.59, Test_accy 87.84
2022-09-28 02:33:45,046 [foster.py] => Task 0, Epoch 21/40 => Loss 0.027, Train_accy 99.38
2022-09-28 02:33:47,994 [foster.py] => Task 0, Epoch 22/40 => Loss 0.030, Train_accy 99.38, Test_accy 89.19
2022-09-28 02:33:51,019 [foster.py] => Task 0, Epoch 23/40 => Loss 0.021, Train_accy 99.73, Test_accy 88.51
2022-09-28 02:33:53,975 [foster.py] => Task 0, Epoch 24/40 => Loss 0.023, Train_accy 99.52, Test_accy 89.19
2022-09-28 02:33:56,978 [foster.py] => Task 0, Epoch 25/40 => Loss 0.021, Train_accy 99.52, Test_accy 88.51
2022-09-28 02:33:59,369 [foster.py] => Task 0, Epoch 26/40 => Loss 0.022, Train_accy 99.66
2022-09-28 02:34:02,428 [foster.py] => Task 0, Epoch 27/40 => Loss 0.019, Train_accy 99.79, Test_accy 87.84
2022-09-28 02:34:05,487 [foster.py] => Task 0, Epoch 28/40 => Loss 0.019, Train_accy 99.73, Test_accy 88.51
2022-09-28 02:34:08,453 [foster.py] => Task 0, Epoch 29/40 => Loss 0.014, Train_accy 99.79, Test_accy 88.51
2022-09-28 02:34:11,551 [foster.py] => Task 0, Epoch 30/40 => Loss 0.016, Train_accy 99.93, Test_accy 87.84
2022-09-28 02:34:13,948 [foster.py] => Task 0, Epoch 31/40 => Loss 0.014, Train_accy 99.73
2022-09-28 02:34:16,994 [foster.py] => Task 0, Epoch 32/40 => Loss 0.020, Train_accy 99.59, Test_accy 89.19
2022-09-28 02:34:19,979 [foster.py] => Task 0, Epoch 33/40 => Loss 0.014, Train_accy 99.93, Test_accy 88.51
2022-09-28 02:34:23,000 [foster.py] => Task 0, Epoch 34/40 => Loss 0.016, Train_accy 99.59, Test_accy 87.84
2022-09-28 02:34:25,969 [foster.py] => Task 0, Epoch 35/40 => Loss 0.019, Train_accy 99.66, Test_accy 88.51
2022-09-28 02:34:28,329 [foster.py] => Task 0, Epoch 36/40 => Loss 0.013, Train_accy 99.79
2022-09-28 02:34:31,319 [foster.py] => Task 0, Epoch 37/40 => Loss 0.013, Train_accy 99.86, Test_accy 87.84
2022-09-28 02:34:34,345 [foster.py] => Task 0, Epoch 38/40 => Loss 0.014, Train_accy 100.00, Test_accy 87.84
2022-09-28 02:34:37,331 [foster.py] => Task 0, Epoch 39/40 => Loss 0.016, Train_accy 99.66, Test_accy 87.84
2022-09-28 02:34:40,331 [foster.py] => Task 0, Epoch 40/40 => Loss 0.012, Train_accy 99.93, Test_accy 87.16
2022-09-28 02:34:40,332 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 02:34:47,187 [foster.py] => Exemplar size: 140
2022-09-28 02:34:47,187 [trainer.py] => CNN: {'total': 87.16, 'old': 87.16, 'new': 0, 'base': 87.16, 'compound': 0}
2022-09-28 02:34:47,187 [trainer.py] => CNN top1 curve: [87.16]
2022-09-28 02:34:47,187 [trainer.py] => CNN base curve: [87.16]
2022-09-28 02:34:47,188 [trainer.py] => CNN old curve: [87.16]
2022-09-28 02:34:47,188 [trainer.py] => CNN new curve: [0]
2022-09-28 02:34:47,188 [trainer.py] => CNN compound curve: [0]
2022-09-28 02:34:47,188 [trainer.py] => NME: {'total': 87.16, 'old': 87.16, 'new': 0, 'base': 87.16, 'compound': 0}
2022-09-28 02:34:47,188 [trainer.py] => NME top1 curve: [87.16]
2022-09-28 02:34:47,188 [trainer.py] => NME base curve: [87.16]
2022-09-28 02:34:47,188 [trainer.py] => NME old curve: [87.16]
2022-09-28 02:34:47,188 [trainer.py] => NME new curve: [0]
2022-09-28 02:34:47,188 [trainer.py] => NME compound curve: [0]
2022-09-28 02:34:47,417 [foster.py] => Learning on 7-10
2022-09-28 02:34:47,417 [foster.py] => All params: 22371995
2022-09-28 02:34:47,417 [foster.py] => Trainable params: 11191892
2022-09-28 02:34:47,437 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 02:34:49,912 [foster.py] => Task 1, Epoch 1/34 => Loss 4.673, Loss_clf 2.153, Loss_fe 1.846, Loss_kd 0.472, Train_accy 41.72, Test_accy 67.79
2022-09-28 02:34:51,619 [foster.py] => Task 1, Epoch 2/34 => Loss 2.570, Loss_clf 0.677, Loss_fe 1.205, Loss_kd 0.482, Train_accy 75.88
2022-09-28 02:34:53,334 [foster.py] => Task 1, Epoch 3/34 => Loss 2.022, Loss_clf 0.402, Loss_fe 0.958, Loss_kd 0.463, Train_accy 53.59
2022-09-28 02:34:55,081 [foster.py] => Task 1, Epoch 4/34 => Loss 1.834, Loss_clf 0.352, Loss_fe 0.826, Loss_kd 0.460, Train_accy 54.50
2022-09-28 02:34:56,795 [foster.py] => Task 1, Epoch 5/34 => Loss 1.706, Loss_clf 0.321, Loss_fe 0.728, Loss_kd 0.460, Train_accy 56.98
2022-09-28 02:34:59,236 [foster.py] => Task 1, Epoch 6/34 => Loss 1.639, Loss_clf 0.321, Loss_fe 0.666, Loss_kd 0.456, Train_accy 58.54, Test_accy 72.60
2022-09-28 02:35:00,967 [foster.py] => Task 1, Epoch 7/34 => Loss 1.542, Loss_clf 0.284, Loss_fe 0.605, Loss_kd 0.456, Train_accy 58.02
2022-09-28 02:35:02,711 [foster.py] => Task 1, Epoch 8/34 => Loss 1.461, Loss_clf 0.252, Loss_fe 0.551, Loss_kd 0.460, Train_accy 58.41
2022-09-28 02:35:04,429 [foster.py] => Task 1, Epoch 9/34 => Loss 1.451, Loss_clf 0.259, Loss_fe 0.535, Loss_kd 0.460, Train_accy 61.41
2022-09-28 02:35:06,156 [foster.py] => Task 1, Epoch 10/34 => Loss 1.398, Loss_clf 0.253, Loss_fe 0.492, Loss_kd 0.457, Train_accy 60.37
2022-09-28 02:35:08,633 [foster.py] => Task 1, Epoch 11/34 => Loss 1.356, Loss_clf 0.236, Loss_fe 0.466, Loss_kd 0.457, Train_accy 59.71, Test_accy 73.08
2022-09-28 02:35:10,407 [foster.py] => Task 1, Epoch 12/34 => Loss 1.302, Loss_clf 0.223, Loss_fe 0.434, Loss_kd 0.451, Train_accy 59.97
2022-09-28 02:35:12,130 [foster.py] => Task 1, Epoch 13/34 => Loss 1.348, Loss_clf 0.246, Loss_fe 0.442, Loss_kd 0.462, Train_accy 63.62
2022-09-28 02:35:13,865 [foster.py] => Task 1, Epoch 14/34 => Loss 1.291, Loss_clf 0.226, Loss_fe 0.412, Loss_kd 0.457, Train_accy 60.63
2022-09-28 02:35:15,577 [foster.py] => Task 1, Epoch 15/34 => Loss 1.251, Loss_clf 0.206, Loss_fe 0.397, Loss_kd 0.453, Train_accy 62.19
2022-09-28 02:35:18,018 [foster.py] => Task 1, Epoch 16/34 => Loss 1.232, Loss_clf 0.198, Loss_fe 0.376, Loss_kd 0.460, Train_accy 63.75, Test_accy 75.00
2022-09-28 02:35:19,829 [foster.py] => Task 1, Epoch 17/34 => Loss 1.228, Loss_clf 0.199, Loss_fe 0.371, Loss_kd 0.461, Train_accy 63.36
2022-09-28 02:35:21,575 [foster.py] => Task 1, Epoch 18/34 => Loss 1.192, Loss_clf 0.195, Loss_fe 0.345, Loss_kd 0.457, Train_accy 64.67
2022-09-28 02:35:23,343 [foster.py] => Task 1, Epoch 19/34 => Loss 1.173, Loss_clf 0.177, Loss_fe 0.339, Loss_kd 0.460, Train_accy 65.45
2022-09-28 02:35:25,136 [foster.py] => Task 1, Epoch 20/34 => Loss 1.182, Loss_clf 0.188, Loss_fe 0.331, Loss_kd 0.465, Train_accy 64.93
2022-09-28 02:35:27,541 [foster.py] => Task 1, Epoch 21/34 => Loss 1.149, Loss_clf 0.174, Loss_fe 0.322, Loss_kd 0.457, Train_accy 63.10, Test_accy 75.48
2022-09-28 02:35:29,265 [foster.py] => Task 1, Epoch 22/34 => Loss 1.150, Loss_clf 0.175, Loss_fe 0.323, Loss_kd 0.457, Train_accy 65.06
2022-09-28 02:35:31,021 [foster.py] => Task 1, Epoch 23/34 => Loss 1.157, Loss_clf 0.189, Loss_fe 0.319, Loss_kd 0.454, Train_accy 63.62
2022-09-28 02:35:32,756 [foster.py] => Task 1, Epoch 24/34 => Loss 1.151, Loss_clf 0.187, Loss_fe 0.326, Loss_kd 0.446, Train_accy 62.32
2022-09-28 02:35:34,509 [foster.py] => Task 1, Epoch 25/34 => Loss 1.121, Loss_clf 0.164, Loss_fe 0.304, Loss_kd 0.457, Train_accy 66.62
2022-09-28 02:35:36,912 [foster.py] => Task 1, Epoch 26/34 => Loss 1.129, Loss_clf 0.170, Loss_fe 0.309, Loss_kd 0.455, Train_accy 64.02, Test_accy 75.48
2022-09-28 02:35:38,663 [foster.py] => Task 1, Epoch 27/34 => Loss 1.137, Loss_clf 0.171, Loss_fe 0.314, Loss_kd 0.457, Train_accy 64.54
2022-09-28 02:35:40,407 [foster.py] => Task 1, Epoch 28/34 => Loss 1.135, Loss_clf 0.178, Loss_fe 0.308, Loss_kd 0.455, Train_accy 64.80
2022-09-28 02:35:42,173 [foster.py] => Task 1, Epoch 29/34 => Loss 1.142, Loss_clf 0.170, Loss_fe 0.313, Loss_kd 0.461, Train_accy 65.19
2022-09-28 02:35:43,892 [foster.py] => Task 1, Epoch 30/34 => Loss 1.137, Loss_clf 0.169, Loss_fe 0.305, Loss_kd 0.464, Train_accy 65.19
2022-09-28 02:35:46,356 [foster.py] => Task 1, Epoch 31/34 => Loss 1.133, Loss_clf 0.174, Loss_fe 0.306, Loss_kd 0.458, Train_accy 64.28, Test_accy 75.48
2022-09-28 02:35:48,079 [foster.py] => Task 1, Epoch 32/34 => Loss 1.108, Loss_clf 0.164, Loss_fe 0.294, Loss_kd 0.455, Train_accy 63.89
2022-09-28 02:35:49,837 [foster.py] => Task 1, Epoch 33/34 => Loss 1.124, Loss_clf 0.164, Loss_fe 0.306, Loss_kd 0.458, Train_accy 66.23
2022-09-28 02:35:51,591 [foster.py] => Task 1, Epoch 34/34 => Loss 1.110, Loss_clf 0.165, Loss_fe 0.297, Loss_kd 0.454, Train_accy 65.19
2022-09-28 02:35:51,592 [foster.py] => do not weight align teacher!
2022-09-28 02:35:51,592 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 02:35:54,437 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.591,  Train_accy 17.21, Test_accy 59.13
2022-09-28 02:35:56,357 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.463,  Train_accy 17.99
2022-09-28 02:35:58,277 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.367,  Train_accy 18.51
2022-09-28 02:36:00,221 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.318,  Train_accy 19.95
2022-09-28 02:36:02,175 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.285,  Train_accy 22.16
2022-09-28 02:36:04,768 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.282,  Train_accy 22.56, Test_accy 61.54
2022-09-28 02:36:06,684 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.261,  Train_accy 23.34
2022-09-28 02:36:08,594 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.248,  Train_accy 25.03
2022-09-28 02:36:10,505 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.240,  Train_accy 26.21
2022-09-28 02:36:12,467 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.225,  Train_accy 27.90
2022-09-28 02:36:15,069 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.237,  Train_accy 27.90, Test_accy 61.54
2022-09-28 02:36:16,999 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.214,  Train_accy 28.68
2022-09-28 02:36:18,994 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.217,  Train_accy 29.60
2022-09-28 02:36:20,978 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.214,  Train_accy 29.99
2022-09-28 02:36:22,904 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.214,  Train_accy 30.51
2022-09-28 02:36:25,528 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.207,  Train_accy 30.77, Test_accy 62.50
2022-09-28 02:36:27,443 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.200,  Train_accy 30.12
2022-09-28 02:36:29,453 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.202,  Train_accy 31.68
2022-09-28 02:36:31,372 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.205,  Train_accy 29.47
2022-09-28 02:36:33,292 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.212,  Train_accy 29.20
2022-09-28 02:36:35,856 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.193,  Train_accy 29.20, Test_accy 62.98
2022-09-28 02:36:37,838 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.199,  Train_accy 29.86
2022-09-28 02:36:39,792 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.200,  Train_accy 30.77
2022-09-28 02:36:41,735 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.205,  Train_accy 32.59
2022-09-28 02:36:43,661 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.193,  Train_accy 33.12
2022-09-28 02:36:46,221 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.202,  Train_accy 31.42, Test_accy 62.98
2022-09-28 02:36:46,221 [foster.py] => do not weight align student!
2022-09-28 02:36:46,872 [foster.py] => darknet eval: 
2022-09-28 02:36:46,872 [foster.py] => CNN top1 curve: 62.98
2022-09-28 02:36:46,872 [foster.py] => CNN top5 curve: 98.08
2022-09-28 02:36:46,873 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 02:36:53,209 [foster.py] => Exemplar size: 200
2022-09-28 02:36:53,209 [trainer.py] => CNN: {'total': 75.48, 'old': 86.49, 'new': 48.33, 'base': 86.49, 'compound': 48.33}
2022-09-28 02:36:53,209 [trainer.py] => CNN top1 curve: [87.16, 75.48]
2022-09-28 02:36:53,210 [trainer.py] => CNN base curve: [87.16, 86.49]
2022-09-28 02:36:53,210 [trainer.py] => CNN old curve: [87.16, 86.49]
2022-09-28 02:36:53,210 [trainer.py] => CNN new curve: [0, 48.33]
2022-09-28 02:36:53,210 [trainer.py] => CNN compound curve: [0, 48.33]
2022-09-28 02:36:53,210 [trainer.py] => NME: {'total': 78.37, 'old': 83.11, 'new': 66.67, 'base': 83.11, 'compound': 66.67}
2022-09-28 02:36:53,210 [trainer.py] => NME top1 curve: [87.16, 78.37]
2022-09-28 02:36:53,210 [trainer.py] => NME base curve: [87.16, 83.11]
2022-09-28 02:36:53,210 [trainer.py] => NME old curve: [87.16, 83.11]
2022-09-28 02:36:53,210 [trainer.py] => NME new curve: [0, 66.67]
2022-09-28 02:36:53,210 [trainer.py] => NME compound curve: [0, 66.67]
2022-09-28 02:36:53,440 [foster.py] => Learning on 10-13
2022-09-28 02:36:53,440 [foster.py] => All params: 22378148
2022-09-28 02:36:53,440 [foster.py] => Trainable params: 11196506
2022-09-28 02:36:53,460 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 02:36:56,046 [foster.py] => Task 2, Epoch 1/34 => Loss 5.421, Loss_clf 2.088, Loss_fe 2.188, Loss_kd 0.881, Train_accy 42.59, Test_accy 53.41
2022-09-28 02:36:57,861 [foster.py] => Task 2, Epoch 2/34 => Loss 3.226, Loss_clf 0.718, Loss_fe 1.375, Loss_kd 0.872, Train_accy 53.00
2022-09-28 02:36:59,655 [foster.py] => Task 2, Epoch 3/34 => Loss 2.812, Loss_clf 0.527, Loss_fe 1.146, Loss_kd 0.876, Train_accy 46.51
2022-09-28 02:37:01,483 [foster.py] => Task 2, Epoch 4/34 => Loss 2.631, Loss_clf 0.500, Loss_fe 0.996, Loss_kd 0.873, Train_accy 48.23
2022-09-28 02:37:03,347 [foster.py] => Task 2, Epoch 5/34 => Loss 2.543, Loss_clf 0.467, Loss_fe 0.924, Loss_kd 0.887, Train_accy 47.86
2022-09-28 02:37:05,977 [foster.py] => Task 2, Epoch 6/34 => Loss 2.466, Loss_clf 0.465, Loss_fe 0.857, Loss_kd 0.880, Train_accy 47.37, Test_accy 55.91
2022-09-28 02:37:07,806 [foster.py] => Task 2, Epoch 7/34 => Loss 2.317, Loss_clf 0.417, Loss_fe 0.771, Loss_kd 0.869, Train_accy 48.23
2022-09-28 02:37:09,660 [foster.py] => Task 2, Epoch 8/34 => Loss 2.291, Loss_clf 0.414, Loss_fe 0.738, Loss_kd 0.877, Train_accy 48.96
2022-09-28 02:37:11,496 [foster.py] => Task 2, Epoch 9/34 => Loss 2.246, Loss_clf 0.416, Loss_fe 0.695, Loss_kd 0.873, Train_accy 49.69
2022-09-28 02:37:13,276 [foster.py] => Task 2, Epoch 10/34 => Loss 2.172, Loss_clf 0.386, Loss_fe 0.644, Loss_kd 0.879, Train_accy 47.25
2022-09-28 02:37:15,858 [foster.py] => Task 2, Epoch 11/34 => Loss 2.196, Loss_clf 0.401, Loss_fe 0.657, Loss_kd 0.875, Train_accy 48.47, Test_accy 58.06
2022-09-28 02:37:17,650 [foster.py] => Task 2, Epoch 12/34 => Loss 2.177, Loss_clf 0.400, Loss_fe 0.631, Loss_kd 0.881, Train_accy 51.53
2022-09-28 02:37:19,554 [foster.py] => Task 2, Epoch 13/34 => Loss 2.090, Loss_clf 0.378, Loss_fe 0.583, Loss_kd 0.868, Train_accy 49.20
2022-09-28 02:37:21,348 [foster.py] => Task 2, Epoch 14/34 => Loss 2.031, Loss_clf 0.349, Loss_fe 0.547, Loss_kd 0.874, Train_accy 47.25
2022-09-28 02:37:23,161 [foster.py] => Task 2, Epoch 15/34 => Loss 2.058, Loss_clf 0.361, Loss_fe 0.560, Loss_kd 0.874, Train_accy 51.04
2022-09-28 02:37:25,749 [foster.py] => Task 2, Epoch 16/34 => Loss 2.033, Loss_clf 0.363, Loss_fe 0.539, Loss_kd 0.869, Train_accy 50.80, Test_accy 59.50
2022-09-28 02:37:27,543 [foster.py] => Task 2, Epoch 17/34 => Loss 2.004, Loss_clf 0.353, Loss_fe 0.516, Loss_kd 0.873, Train_accy 46.63
2022-09-28 02:37:29,366 [foster.py] => Task 2, Epoch 18/34 => Loss 1.984, Loss_clf 0.346, Loss_fe 0.504, Loss_kd 0.873, Train_accy 49.94
2022-09-28 02:37:31,200 [foster.py] => Task 2, Epoch 19/34 => Loss 2.022, Loss_clf 0.351, Loss_fe 0.532, Loss_kd 0.876, Train_accy 50.31
2022-09-28 02:37:33,057 [foster.py] => Task 2, Epoch 20/34 => Loss 1.970, Loss_clf 0.346, Loss_fe 0.504, Loss_kd 0.861, Train_accy 46.27
2022-09-28 02:37:35,678 [foster.py] => Task 2, Epoch 21/34 => Loss 1.954, Loss_clf 0.332, Loss_fe 0.484, Loss_kd 0.876, Train_accy 48.71, Test_accy 59.86
2022-09-28 02:37:37,476 [foster.py] => Task 2, Epoch 22/34 => Loss 1.957, Loss_clf 0.332, Loss_fe 0.485, Loss_kd 0.877, Train_accy 48.84
2022-09-28 02:37:39,301 [foster.py] => Task 2, Epoch 23/34 => Loss 1.936, Loss_clf 0.335, Loss_fe 0.469, Loss_kd 0.871, Train_accy 49.82
2022-09-28 02:37:41,134 [foster.py] => Task 2, Epoch 24/34 => Loss 1.933, Loss_clf 0.327, Loss_fe 0.465, Loss_kd 0.877, Train_accy 50.06
2022-09-28 02:37:42,918 [foster.py] => Task 2, Epoch 25/34 => Loss 1.908, Loss_clf 0.316, Loss_fe 0.454, Loss_kd 0.875, Train_accy 48.71
2022-09-28 02:37:45,547 [foster.py] => Task 2, Epoch 26/34 => Loss 1.916, Loss_clf 0.319, Loss_fe 0.456, Loss_kd 0.878, Train_accy 48.96, Test_accy 60.57
2022-09-28 02:37:47,354 [foster.py] => Task 2, Epoch 27/34 => Loss 1.910, Loss_clf 0.318, Loss_fe 0.451, Loss_kd 0.878, Train_accy 50.80
2022-09-28 02:37:49,229 [foster.py] => Task 2, Epoch 28/34 => Loss 1.931, Loss_clf 0.328, Loss_fe 0.466, Loss_kd 0.874, Train_accy 50.06
2022-09-28 02:37:51,018 [foster.py] => Task 2, Epoch 29/34 => Loss 1.905, Loss_clf 0.324, Loss_fe 0.450, Loss_kd 0.870, Train_accy 47.98
2022-09-28 02:37:52,808 [foster.py] => Task 2, Epoch 30/34 => Loss 1.900, Loss_clf 0.318, Loss_fe 0.447, Loss_kd 0.873, Train_accy 50.18
2022-09-28 02:37:55,392 [foster.py] => Task 2, Epoch 31/34 => Loss 1.909, Loss_clf 0.328, Loss_fe 0.454, Loss_kd 0.867, Train_accy 49.57, Test_accy 60.93
2022-09-28 02:37:57,208 [foster.py] => Task 2, Epoch 32/34 => Loss 1.898, Loss_clf 0.315, Loss_fe 0.440, Loss_kd 0.880, Train_accy 50.18
2022-09-28 02:37:59,052 [foster.py] => Task 2, Epoch 33/34 => Loss 1.928, Loss_clf 0.324, Loss_fe 0.449, Loss_kd 0.888, Train_accy 51.77
2022-09-28 02:38:00,883 [foster.py] => Task 2, Epoch 34/34 => Loss 1.893, Loss_clf 0.311, Loss_fe 0.444, Loss_kd 0.875, Train_accy 50.67
2022-09-28 02:38:00,884 [foster.py] => do not weight align teacher!
2022-09-28 02:38:00,884 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 02:38:03,873 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.750,  Train_accy 16.77, Test_accy 46.24
2022-09-28 02:38:05,888 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.647,  Train_accy 17.99
2022-09-28 02:38:07,943 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.595,  Train_accy 17.87
2022-09-28 02:38:09,995 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.575,  Train_accy 18.24
2022-09-28 02:38:12,012 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.555,  Train_accy 17.99
2022-09-28 02:38:14,793 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.557,  Train_accy 18.48, Test_accy 48.39
2022-09-28 02:38:16,791 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.546,  Train_accy 19.34
2022-09-28 02:38:18,827 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.537,  Train_accy 19.09
2022-09-28 02:38:20,853 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.537,  Train_accy 19.83
2022-09-28 02:38:22,886 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.525,  Train_accy 19.83
2022-09-28 02:38:25,682 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.517,  Train_accy 19.71, Test_accy 48.75
2022-09-28 02:38:27,708 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.529,  Train_accy 20.07
2022-09-28 02:38:29,769 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.508,  Train_accy 20.32
2022-09-28 02:38:31,812 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.508,  Train_accy 20.44
2022-09-28 02:38:33,838 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.507,  Train_accy 21.05
2022-09-28 02:38:36,530 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.510,  Train_accy 22.15, Test_accy 49.10
2022-09-28 02:38:38,619 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.511,  Train_accy 22.40
2022-09-28 02:38:40,644 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.500,  Train_accy 21.91
2022-09-28 02:38:42,647 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.502,  Train_accy 22.03
2022-09-28 02:38:44,688 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.508,  Train_accy 23.50
2022-09-28 02:38:47,432 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.501,  Train_accy 22.89, Test_accy 49.82
2022-09-28 02:38:49,484 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.493,  Train_accy 21.79
2022-09-28 02:38:51,521 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.503,  Train_accy 21.79
2022-09-28 02:38:53,521 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.499,  Train_accy 23.01
2022-09-28 02:38:55,520 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.514,  Train_accy 23.01
2022-09-28 02:38:58,280 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.493,  Train_accy 21.79, Test_accy 49.82
2022-09-28 02:38:58,281 [foster.py] => do not weight align student!
2022-09-28 02:38:58,997 [foster.py] => darknet eval: 
2022-09-28 02:38:58,997 [foster.py] => CNN top1 curve: 49.82
2022-09-28 02:38:58,998 [foster.py] => CNN top5 curve: 96.77
2022-09-28 02:38:58,998 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 02:39:06,349 [foster.py] => Exemplar size: 260
2022-09-28 02:39:06,349 [trainer.py] => CNN: {'total': 61.65, 'old': 72.12, 'new': 30.99, 'base': 81.76, 'compound': 38.93}
2022-09-28 02:39:06,349 [trainer.py] => CNN top1 curve: [87.16, 75.48, 61.65]
2022-09-28 02:39:06,349 [trainer.py] => CNN base curve: [87.16, 86.49, 81.76]
2022-09-28 02:39:06,349 [trainer.py] => CNN old curve: [87.16, 86.49, 72.12]
2022-09-28 02:39:06,349 [trainer.py] => CNN new curve: [0, 48.33, 30.99]
2022-09-28 02:39:06,349 [trainer.py] => CNN compound curve: [0, 48.33, 38.93]
2022-09-28 02:39:06,349 [trainer.py] => NME: {'total': 71.33, 'old': 71.63, 'new': 70.42, 'base': 77.03, 'compound': 64.89}
2022-09-28 02:39:06,349 [trainer.py] => NME top1 curve: [87.16, 78.37, 71.33]
2022-09-28 02:39:06,349 [trainer.py] => NME base curve: [87.16, 83.11, 77.03]
2022-09-28 02:39:06,349 [trainer.py] => NME old curve: [87.16, 83.11, 71.63]
2022-09-28 02:39:06,349 [trainer.py] => NME new curve: [0, 66.67, 70.42]
2022-09-28 02:39:06,349 [trainer.py] => NME compound curve: [0, 66.67, 64.89]
2022-09-28 02:39:06,579 [foster.py] => Learning on 13-16
2022-09-28 02:39:06,580 [foster.py] => All params: 22384301
2022-09-28 02:39:06,580 [foster.py] => Trainable params: 11201120
2022-09-28 02:39:06,600 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 02:39:09,315 [foster.py] => Task 3, Epoch 1/34 => Loss 6.196, Loss_clf 2.123, Loss_fe 2.458, Loss_kd 1.313, Train_accy 35.25, Test_accy 41.85
2022-09-28 02:39:11,189 [foster.py] => Task 3, Epoch 2/34 => Loss 4.483, Loss_clf 1.111, Loss_fe 1.749, Loss_kd 1.319, Train_accy 36.97
2022-09-28 02:39:13,078 [foster.py] => Task 3, Epoch 3/34 => Loss 4.177, Loss_clf 1.006, Loss_fe 1.582, Loss_kd 1.291, Train_accy 38.92
2022-09-28 02:39:14,997 [foster.py] => Task 3, Epoch 4/34 => Loss 3.967, Loss_clf 0.943, Loss_fe 1.441, Loss_kd 1.286, Train_accy 39.49
2022-09-28 02:39:16,899 [foster.py] => Task 3, Epoch 5/34 => Loss 3.858, Loss_clf 0.912, Loss_fe 1.340, Loss_kd 1.304, Train_accy 40.41
2022-09-28 02:39:19,622 [foster.py] => Task 3, Epoch 6/34 => Loss 3.771, Loss_clf 0.887, Loss_fe 1.273, Loss_kd 1.308, Train_accy 42.48, Test_accy 49.16
2022-09-28 02:39:21,496 [foster.py] => Task 3, Epoch 7/34 => Loss 3.633, Loss_clf 0.846, Loss_fe 1.186, Loss_kd 1.301, Train_accy 42.25
2022-09-28 02:39:23,421 [foster.py] => Task 3, Epoch 8/34 => Loss 3.551, Loss_clf 0.811, Loss_fe 1.128, Loss_kd 1.310, Train_accy 41.33
2022-09-28 02:39:25,343 [foster.py] => Task 3, Epoch 9/34 => Loss 3.518, Loss_clf 0.823, Loss_fe 1.087, Loss_kd 1.307, Train_accy 42.25
2022-09-28 02:39:27,215 [foster.py] => Task 3, Epoch 10/34 => Loss 3.479, Loss_clf 0.815, Loss_fe 1.068, Loss_kd 1.297, Train_accy 45.81
2022-09-28 02:39:30,026 [foster.py] => Task 3, Epoch 11/34 => Loss 3.412, Loss_clf 0.790, Loss_fe 1.012, Loss_kd 1.309, Train_accy 42.25, Test_accy 51.69
2022-09-28 02:39:32,001 [foster.py] => Task 3, Epoch 12/34 => Loss 3.351, Loss_clf 0.765, Loss_fe 0.987, Loss_kd 1.299, Train_accy 45.01
2022-09-28 02:39:33,881 [foster.py] => Task 3, Epoch 13/34 => Loss 3.327, Loss_clf 0.762, Loss_fe 0.967, Loss_kd 1.298, Train_accy 44.20
2022-09-28 02:39:35,766 [foster.py] => Task 3, Epoch 14/34 => Loss 3.279, Loss_clf 0.747, Loss_fe 0.931, Loss_kd 1.301, Train_accy 44.43
2022-09-28 02:39:37,677 [foster.py] => Task 3, Epoch 15/34 => Loss 3.239, Loss_clf 0.733, Loss_fe 0.906, Loss_kd 1.300, Train_accy 43.63
2022-09-28 02:39:40,516 [foster.py] => Task 3, Epoch 16/34 => Loss 3.261, Loss_clf 0.739, Loss_fe 0.903, Loss_kd 1.316, Train_accy 46.73, Test_accy 51.97
2022-09-28 02:39:42,441 [foster.py] => Task 3, Epoch 17/34 => Loss 3.181, Loss_clf 0.715, Loss_fe 0.869, Loss_kd 1.298, Train_accy 44.09
2022-09-28 02:39:44,326 [foster.py] => Task 3, Epoch 18/34 => Loss 3.155, Loss_clf 0.685, Loss_fe 0.854, Loss_kd 1.313, Train_accy 46.15
2022-09-28 02:39:46,261 [foster.py] => Task 3, Epoch 19/34 => Loss 3.141, Loss_clf 0.685, Loss_fe 0.845, Loss_kd 1.309, Train_accy 47.76
2022-09-28 02:39:48,155 [foster.py] => Task 3, Epoch 20/34 => Loss 3.158, Loss_clf 0.706, Loss_fe 0.853, Loss_kd 1.300, Train_accy 47.19
2022-09-28 02:39:50,894 [foster.py] => Task 3, Epoch 21/34 => Loss 3.124, Loss_clf 0.696, Loss_fe 0.821, Loss_kd 1.305, Train_accy 44.32, Test_accy 52.81
2022-09-28 02:39:52,772 [foster.py] => Task 3, Epoch 22/34 => Loss 3.068, Loss_clf 0.659, Loss_fe 0.801, Loss_kd 1.306, Train_accy 46.73
2022-09-28 02:39:54,674 [foster.py] => Task 3, Epoch 23/34 => Loss 3.071, Loss_clf 0.651, Loss_fe 0.806, Loss_kd 1.311, Train_accy 47.88
2022-09-28 02:39:56,639 [foster.py] => Task 3, Epoch 24/34 => Loss 3.081, Loss_clf 0.660, Loss_fe 0.799, Loss_kd 1.318, Train_accy 47.19
2022-09-28 02:39:58,531 [foster.py] => Task 3, Epoch 25/34 => Loss 2.998, Loss_clf 0.635, Loss_fe 0.762, Loss_kd 1.302, Train_accy 47.76
2022-09-28 02:40:01,297 [foster.py] => Task 3, Epoch 26/34 => Loss 3.002, Loss_clf 0.628, Loss_fe 0.768, Loss_kd 1.305, Train_accy 48.11, Test_accy 54.21
2022-09-28 02:40:03,224 [foster.py] => Task 3, Epoch 27/34 => Loss 3.016, Loss_clf 0.632, Loss_fe 0.770, Loss_kd 1.312, Train_accy 49.60
2022-09-28 02:40:05,142 [foster.py] => Task 3, Epoch 28/34 => Loss 3.003, Loss_clf 0.635, Loss_fe 0.764, Loss_kd 1.303, Train_accy 48.34
2022-09-28 02:40:07,065 [foster.py] => Task 3, Epoch 29/34 => Loss 3.047, Loss_clf 0.658, Loss_fe 0.781, Loss_kd 1.306, Train_accy 48.68
2022-09-28 02:40:08,983 [foster.py] => Task 3, Epoch 30/34 => Loss 2.982, Loss_clf 0.630, Loss_fe 0.753, Loss_kd 1.299, Train_accy 48.56
2022-09-28 02:40:11,746 [foster.py] => Task 3, Epoch 31/34 => Loss 2.993, Loss_clf 0.636, Loss_fe 0.754, Loss_kd 1.302, Train_accy 49.71, Test_accy 54.78
2022-09-28 02:40:13,613 [foster.py] => Task 3, Epoch 32/34 => Loss 3.022, Loss_clf 0.651, Loss_fe 0.772, Loss_kd 1.299, Train_accy 48.11
2022-09-28 02:40:15,517 [foster.py] => Task 3, Epoch 33/34 => Loss 2.987, Loss_clf 0.623, Loss_fe 0.752, Loss_kd 1.309, Train_accy 50.06
2022-09-28 02:40:17,436 [foster.py] => Task 3, Epoch 34/34 => Loss 3.006, Loss_clf 0.628, Loss_fe 0.767, Loss_kd 1.309, Train_accy 48.68
2022-09-28 02:40:17,437 [foster.py] => do not weight align teacher!
2022-09-28 02:40:17,437 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 02:40:20,575 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.202,  Train_accy 17.34, Test_accy 38.20
2022-09-28 02:40:22,728 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.064,  Train_accy 19.29
2022-09-28 02:40:24,853 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.018,  Train_accy 19.29
2022-09-28 02:40:27,030 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.006,  Train_accy 19.98
2022-09-28 02:40:29,141 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.981,  Train_accy 19.75
2022-09-28 02:40:32,032 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.980,  Train_accy 20.44, Test_accy 40.17
2022-09-28 02:40:34,123 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.970,  Train_accy 21.01
2022-09-28 02:40:36,235 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.977,  Train_accy 20.44
2022-09-28 02:40:38,383 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.968,  Train_accy 20.09
2022-09-28 02:40:40,525 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.976,  Train_accy 20.09
2022-09-28 02:40:43,384 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.959,  Train_accy 20.55, Test_accy 41.01
2022-09-28 02:40:45,495 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.953,  Train_accy 20.78
2022-09-28 02:40:47,619 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.953,  Train_accy 20.78
2022-09-28 02:40:49,731 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.975,  Train_accy 20.67
2022-09-28 02:40:51,929 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.954,  Train_accy 20.78
2022-09-28 02:40:54,850 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.955,  Train_accy 20.32, Test_accy 42.13
2022-09-28 02:40:56,969 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.950,  Train_accy 20.90
2022-09-28 02:40:59,111 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.947,  Train_accy 20.67
2022-09-28 02:41:01,242 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.959,  Train_accy 21.01
2022-09-28 02:41:03,352 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.945,  Train_accy 20.78
2022-09-28 02:41:06,206 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.945,  Train_accy 20.78, Test_accy 42.13
2022-09-28 02:41:08,317 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.951,  Train_accy 20.44
2022-09-28 02:41:10,450 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.939,  Train_accy 21.01
2022-09-28 02:41:12,565 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.944,  Train_accy 21.01
2022-09-28 02:41:14,681 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.966,  Train_accy 21.47
2022-09-28 02:41:17,531 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.945,  Train_accy 21.13, Test_accy 42.13
2022-09-28 02:41:17,532 [foster.py] => do not weight align student!
2022-09-28 02:41:18,277 [foster.py] => darknet eval: 
2022-09-28 02:41:18,277 [foster.py] => CNN top1 curve: 42.13
2022-09-28 02:41:18,277 [foster.py] => CNN top5 curve: 90.17
2022-09-28 02:41:18,277 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 02:41:26,775 [foster.py] => Exemplar size: 320
2022-09-28 02:41:26,775 [trainer.py] => CNN: {'total': 54.78, 'old': 61.65, 'new': 29.87, 'base': 77.7, 'compound': 38.46}
2022-09-28 02:41:26,775 [trainer.py] => CNN top1 curve: [87.16, 75.48, 61.65, 54.78]
2022-09-28 02:41:26,775 [trainer.py] => CNN base curve: [87.16, 86.49, 81.76, 77.7]
2022-09-28 02:41:26,775 [trainer.py] => CNN old curve: [87.16, 86.49, 72.12, 61.65]
2022-09-28 02:41:26,775 [trainer.py] => CNN new curve: [0, 48.33, 30.99, 29.87]
2022-09-28 02:41:26,775 [trainer.py] => CNN compound curve: [0, 48.33, 38.93, 38.46]
2022-09-28 02:41:26,775 [trainer.py] => NME: {'total': 58.71, 'old': 62.37, 'new': 45.45, 'base': 66.89, 'compound': 52.88}
2022-09-28 02:41:26,776 [trainer.py] => NME top1 curve: [87.16, 78.37, 71.33, 58.71]
2022-09-28 02:41:26,776 [trainer.py] => NME base curve: [87.16, 83.11, 77.03, 66.89]
2022-09-28 02:41:26,776 [trainer.py] => NME old curve: [87.16, 83.11, 71.63, 62.37]
2022-09-28 02:41:26,776 [trainer.py] => NME new curve: [0, 66.67, 70.42, 45.45]
2022-09-28 02:41:26,776 [trainer.py] => NME compound curve: [0, 66.67, 64.89, 52.88]
2022-09-28 02:41:27,006 [foster.py] => Learning on 16-19
2022-09-28 02:41:27,007 [foster.py] => All params: 22390454
2022-09-28 02:41:27,007 [foster.py] => Trainable params: 11205734
2022-09-28 02:41:27,027 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 02:41:29,930 [foster.py] => Task 4, Epoch 1/34 => Loss 6.459, Loss_clf 2.076, Loss_fe 2.431, Loss_kd 1.643, Train_accy 38.91, Test_accy 36.85
2022-09-28 02:41:31,931 [foster.py] => Task 4, Epoch 2/34 => Loss 4.819, Loss_clf 1.096, Loss_fe 1.782, Loss_kd 1.635, Train_accy 34.97
2022-09-28 02:41:33,933 [foster.py] => Task 4, Epoch 3/34 => Loss 4.500, Loss_clf 0.975, Loss_fe 1.601, Loss_kd 1.620, Train_accy 37.42
2022-09-28 02:41:35,908 [foster.py] => Task 4, Epoch 4/34 => Loss 4.349, Loss_clf 0.945, Loss_fe 1.483, Loss_kd 1.618, Train_accy 38.06
2022-09-28 02:41:38,002 [foster.py] => Task 4, Epoch 5/34 => Loss 4.255, Loss_clf 0.931, Loss_fe 1.403, Loss_kd 1.618, Train_accy 35.82
2022-09-28 02:41:40,947 [foster.py] => Task 4, Epoch 6/34 => Loss 4.160, Loss_clf 0.915, Loss_fe 1.315, Loss_kd 1.625, Train_accy 37.42, Test_accy 43.43
2022-09-28 02:41:42,948 [foster.py] => Task 4, Epoch 7/34 => Loss 4.076, Loss_clf 0.890, Loss_fe 1.255, Loss_kd 1.626, Train_accy 35.29
2022-09-28 02:41:44,976 [foster.py] => Task 4, Epoch 8/34 => Loss 4.019, Loss_clf 0.877, Loss_fe 1.193, Loss_kd 1.642, Train_accy 37.85
2022-09-28 02:41:46,971 [foster.py] => Task 4, Epoch 9/34 => Loss 3.941, Loss_clf 0.843, Loss_fe 1.159, Loss_kd 1.633, Train_accy 37.10
2022-09-28 02:41:49,021 [foster.py] => Task 4, Epoch 10/34 => Loss 3.947, Loss_clf 0.868, Loss_fe 1.140, Loss_kd 1.633, Train_accy 40.19
2022-09-28 02:41:51,899 [foster.py] => Task 4, Epoch 11/34 => Loss 3.871, Loss_clf 0.847, Loss_fe 1.088, Loss_kd 1.630, Train_accy 38.38, Test_accy 45.54
2022-09-28 02:41:53,901 [foster.py] => Task 4, Epoch 12/34 => Loss 3.780, Loss_clf 0.813, Loss_fe 1.033, Loss_kd 1.629, Train_accy 41.36
2022-09-28 02:41:55,872 [foster.py] => Task 4, Epoch 13/34 => Loss 3.774, Loss_clf 0.813, Loss_fe 1.023, Loss_kd 1.632, Train_accy 38.70
2022-09-28 02:41:57,883 [foster.py] => Task 4, Epoch 14/34 => Loss 3.719, Loss_clf 0.778, Loss_fe 1.003, Loss_kd 1.632, Train_accy 39.55
2022-09-28 02:41:59,842 [foster.py] => Task 4, Epoch 15/34 => Loss 3.684, Loss_clf 0.773, Loss_fe 0.972, Loss_kd 1.632, Train_accy 40.83
2022-09-28 02:42:02,737 [foster.py] => Task 4, Epoch 16/34 => Loss 3.667, Loss_clf 0.759, Loss_fe 0.964, Loss_kd 1.637, Train_accy 41.68, Test_accy 46.01
2022-09-28 02:42:04,750 [foster.py] => Task 4, Epoch 17/34 => Loss 3.629, Loss_clf 0.754, Loss_fe 0.939, Loss_kd 1.631, Train_accy 40.09
2022-09-28 02:42:06,753 [foster.py] => Task 4, Epoch 18/34 => Loss 3.567, Loss_clf 0.740, Loss_fe 0.900, Loss_kd 1.623, Train_accy 40.51
2022-09-28 02:42:08,720 [foster.py] => Task 4, Epoch 19/34 => Loss 3.590, Loss_clf 0.747, Loss_fe 0.902, Loss_kd 1.634, Train_accy 42.86
2022-09-28 02:42:10,737 [foster.py] => Task 4, Epoch 20/34 => Loss 3.589, Loss_clf 0.742, Loss_fe 0.900, Loss_kd 1.640, Train_accy 42.00
2022-09-28 02:42:13,647 [foster.py] => Task 4, Epoch 21/34 => Loss 3.529, Loss_clf 0.719, Loss_fe 0.871, Loss_kd 1.633, Train_accy 42.22, Test_accy 47.18
2022-09-28 02:42:15,629 [foster.py] => Task 4, Epoch 22/34 => Loss 3.523, Loss_clf 0.712, Loss_fe 0.863, Loss_kd 1.641, Train_accy 40.62
2022-09-28 02:42:17,642 [foster.py] => Task 4, Epoch 23/34 => Loss 3.546, Loss_clf 0.729, Loss_fe 0.875, Loss_kd 1.635, Train_accy 42.75
2022-09-28 02:42:19,615 [foster.py] => Task 4, Epoch 24/34 => Loss 3.519, Loss_clf 0.710, Loss_fe 0.861, Loss_kd 1.640, Train_accy 41.68
2022-09-28 02:42:21,602 [foster.py] => Task 4, Epoch 25/34 => Loss 3.498, Loss_clf 0.713, Loss_fe 0.843, Loss_kd 1.636, Train_accy 43.07
2022-09-28 02:42:24,478 [foster.py] => Task 4, Epoch 26/34 => Loss 3.476, Loss_clf 0.701, Loss_fe 0.839, Loss_kd 1.631, Train_accy 43.28, Test_accy 46.95
2022-09-28 02:42:26,516 [foster.py] => Task 4, Epoch 27/34 => Loss 3.470, Loss_clf 0.699, Loss_fe 0.844, Loss_kd 1.623, Train_accy 43.07
2022-09-28 02:42:28,553 [foster.py] => Task 4, Epoch 28/34 => Loss 3.496, Loss_clf 0.711, Loss_fe 0.852, Loss_kd 1.628, Train_accy 43.60
2022-09-28 02:42:30,531 [foster.py] => Task 4, Epoch 29/34 => Loss 3.473, Loss_clf 0.703, Loss_fe 0.833, Loss_kd 1.631, Train_accy 42.96
2022-09-28 02:42:32,505 [foster.py] => Task 4, Epoch 30/34 => Loss 3.496, Loss_clf 0.704, Loss_fe 0.841, Loss_kd 1.643, Train_accy 43.82
2022-09-28 02:42:35,435 [foster.py] => Task 4, Epoch 31/34 => Loss 3.481, Loss_clf 0.698, Loss_fe 0.847, Loss_kd 1.630, Train_accy 42.75, Test_accy 47.18
2022-09-28 02:42:37,418 [foster.py] => Task 4, Epoch 32/34 => Loss 3.475, Loss_clf 0.704, Loss_fe 0.838, Loss_kd 1.628, Train_accy 42.32
2022-09-28 02:42:39,394 [foster.py] => Task 4, Epoch 33/34 => Loss 3.435, Loss_clf 0.679, Loss_fe 0.819, Loss_kd 1.631, Train_accy 42.96
2022-09-28 02:42:41,455 [foster.py] => Task 4, Epoch 34/34 => Loss 3.468, Loss_clf 0.699, Loss_fe 0.833, Loss_kd 1.630, Train_accy 43.07
2022-09-28 02:42:41,455 [foster.py] => do not weight align teacher!
2022-09-28 02:42:41,456 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 02:42:44,760 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.279,  Train_accy 19.30, Test_accy 36.38
2022-09-28 02:42:46,987 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.226,  Train_accy 19.40
2022-09-28 02:42:49,264 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.216,  Train_accy 19.83
2022-09-28 02:42:51,523 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.195,  Train_accy 19.94
2022-09-28 02:42:53,755 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.203,  Train_accy 20.36
2022-09-28 02:42:56,894 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.189,  Train_accy 20.15, Test_accy 36.85
2022-09-28 02:42:59,150 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.188,  Train_accy 20.36
2022-09-28 02:43:01,392 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.184,  Train_accy 19.83
2022-09-28 02:43:03,701 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.169,  Train_accy 19.83
2022-09-28 02:43:05,982 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.178,  Train_accy 21.11
2022-09-28 02:43:09,079 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.176,  Train_accy 20.15, Test_accy 38.26
2022-09-28 02:43:11,340 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.171,  Train_accy 20.58
2022-09-28 02:43:13,570 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.187,  Train_accy 20.26
2022-09-28 02:43:15,829 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.180,  Train_accy 20.58
2022-09-28 02:43:18,114 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.162,  Train_accy 21.00
2022-09-28 02:43:21,211 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.168,  Train_accy 20.26, Test_accy 38.97
2022-09-28 02:43:23,431 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.164,  Train_accy 21.43
2022-09-28 02:43:25,663 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.178,  Train_accy 20.68
2022-09-28 02:43:27,899 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.163,  Train_accy 20.58
2022-09-28 02:43:30,136 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.180,  Train_accy 21.64
2022-09-28 02:43:33,143 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.168,  Train_accy 20.68, Test_accy 38.97
2022-09-28 02:43:35,369 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.158,  Train_accy 20.68
2022-09-28 02:43:37,626 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.163,  Train_accy 20.36
2022-09-28 02:43:39,910 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.162,  Train_accy 20.36
2022-09-28 02:43:42,183 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.164,  Train_accy 21.11
2022-09-28 02:43:45,205 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.169,  Train_accy 20.26, Test_accy 38.50
2022-09-28 02:43:45,205 [foster.py] => do not weight align student!
2022-09-28 02:43:46,002 [foster.py] => darknet eval: 
2022-09-28 02:43:46,002 [foster.py] => CNN top1 curve: 38.5
2022-09-28 02:43:46,002 [foster.py] => CNN top5 curve: 80.99
2022-09-28 02:43:46,003 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 02:43:55,548 [foster.py] => Exemplar size: 380
2022-09-28 02:43:55,548 [trainer.py] => CNN: {'total': 46.95, 'old': 51.69, 'new': 22.86, 'base': 75.0, 'compound': 32.01}
2022-09-28 02:43:55,548 [trainer.py] => CNN top1 curve: [87.16, 75.48, 61.65, 54.78, 46.95]
2022-09-28 02:43:55,548 [trainer.py] => CNN base curve: [87.16, 86.49, 81.76, 77.7, 75.0]
2022-09-28 02:43:55,548 [trainer.py] => CNN old curve: [87.16, 86.49, 72.12, 61.65, 51.69]
2022-09-28 02:43:55,548 [trainer.py] => CNN new curve: [0, 48.33, 30.99, 29.87, 22.86]
2022-09-28 02:43:55,548 [trainer.py] => CNN compound curve: [0, 48.33, 38.93, 38.46, 32.01]
2022-09-28 02:43:55,548 [trainer.py] => NME: {'total': 54.93, 'old': 57.58, 'new': 41.43, 'base': 67.57, 'compound': 48.2}
2022-09-28 02:43:55,548 [trainer.py] => NME top1 curve: [87.16, 78.37, 71.33, 58.71, 54.93]
2022-09-28 02:43:55,548 [trainer.py] => NME base curve: [87.16, 83.11, 77.03, 66.89, 67.57]
2022-09-28 02:43:55,548 [trainer.py] => NME old curve: [87.16, 83.11, 71.63, 62.37, 57.58]
2022-09-28 02:43:55,548 [trainer.py] => NME new curve: [0, 66.67, 70.42, 45.45, 41.43]
2022-09-28 02:43:55,548 [trainer.py] => NME compound curve: [0, 66.67, 64.89, 52.88, 48.2]
2022-09-28 02:43:55,777 [foster.py] => Learning on 19-22
2022-09-28 02:43:55,778 [foster.py] => All params: 22396607
2022-09-28 02:43:55,778 [foster.py] => Trainable params: 11210348
2022-09-28 02:43:55,798 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 02:43:58,908 [foster.py] => Task 5, Epoch 1/34 => Loss 6.835, Loss_clf 2.162, Loss_fe 2.525, Loss_kd 1.855, Train_accy 39.74, Test_accy 37.62
2022-09-28 02:44:00,978 [foster.py] => Task 5, Epoch 2/34 => Loss 5.155, Loss_clf 1.133, Loss_fe 1.876, Loss_kd 1.853, Train_accy 37.51
2022-09-28 02:44:03,054 [foster.py] => Task 5, Epoch 3/34 => Loss 4.875, Loss_clf 1.033, Loss_fe 1.685, Loss_kd 1.863, Train_accy 41.25
2022-09-28 02:44:05,132 [foster.py] => Task 5, Epoch 4/34 => Loss 4.686, Loss_clf 0.975, Loss_fe 1.568, Loss_kd 1.851, Train_accy 38.93
2022-09-28 02:44:07,215 [foster.py] => Task 5, Epoch 5/34 => Loss 4.598, Loss_clf 0.970, Loss_fe 1.484, Loss_kd 1.852, Train_accy 42.16
2022-09-28 02:44:10,256 [foster.py] => Task 5, Epoch 6/34 => Loss 4.482, Loss_clf 0.928, Loss_fe 1.404, Loss_kd 1.857, Train_accy 41.66, Test_accy 42.77
2022-09-28 02:44:12,310 [foster.py] => Task 5, Epoch 7/34 => Loss 4.377, Loss_clf 0.906, Loss_fe 1.320, Loss_kd 1.858, Train_accy 43.07
2022-09-28 02:44:14,388 [foster.py] => Task 5, Epoch 8/34 => Loss 4.371, Loss_clf 0.903, Loss_fe 1.318, Loss_kd 1.857, Train_accy 43.48
2022-09-28 02:44:16,451 [foster.py] => Task 5, Epoch 9/34 => Loss 4.280, Loss_clf 0.879, Loss_fe 1.251, Loss_kd 1.857, Train_accy 43.58
2022-09-28 02:44:18,549 [foster.py] => Task 5, Epoch 10/34 => Loss 4.210, Loss_clf 0.868, Loss_fe 1.200, Loss_kd 1.850, Train_accy 41.46
2022-09-28 02:44:21,687 [foster.py] => Task 5, Epoch 11/34 => Loss 4.120, Loss_clf 0.828, Loss_fe 1.147, Loss_kd 1.852, Train_accy 42.77, Test_accy 42.97
2022-09-28 02:44:23,734 [foster.py] => Task 5, Epoch 12/34 => Loss 4.120, Loss_clf 0.838, Loss_fe 1.130, Loss_kd 1.859, Train_accy 44.99
2022-09-28 02:44:25,788 [foster.py] => Task 5, Epoch 13/34 => Loss 4.075, Loss_clf 0.814, Loss_fe 1.114, Loss_kd 1.855, Train_accy 44.79
2022-09-28 02:44:27,877 [foster.py] => Task 5, Epoch 14/34 => Loss 4.037, Loss_clf 0.812, Loss_fe 1.076, Loss_kd 1.856, Train_accy 44.99
2022-09-28 02:44:29,970 [foster.py] => Task 5, Epoch 15/34 => Loss 4.042, Loss_clf 0.821, Loss_fe 1.069, Loss_kd 1.858, Train_accy 43.07
2022-09-28 02:44:33,035 [foster.py] => Task 5, Epoch 16/34 => Loss 4.006, Loss_clf 0.804, Loss_fe 1.046, Loss_kd 1.861, Train_accy 46.21, Test_accy 44.16
2022-09-28 02:44:35,085 [foster.py] => Task 5, Epoch 17/34 => Loss 3.929, Loss_clf 0.776, Loss_fe 1.003, Loss_kd 1.857, Train_accy 46.11
2022-09-28 02:44:37,156 [foster.py] => Task 5, Epoch 18/34 => Loss 3.926, Loss_clf 0.778, Loss_fe 0.999, Loss_kd 1.856, Train_accy 44.29
2022-09-28 02:44:39,229 [foster.py] => Task 5, Epoch 19/34 => Loss 3.913, Loss_clf 0.774, Loss_fe 0.984, Loss_kd 1.861, Train_accy 47.62
2022-09-28 02:44:41,322 [foster.py] => Task 5, Epoch 20/34 => Loss 3.918, Loss_clf 0.775, Loss_fe 0.986, Loss_kd 1.863, Train_accy 46.92
2022-09-28 02:44:44,375 [foster.py] => Task 5, Epoch 21/34 => Loss 3.874, Loss_clf 0.759, Loss_fe 0.963, Loss_kd 1.858, Train_accy 46.01, Test_accy 44.55
2022-09-28 02:44:46,453 [foster.py] => Task 5, Epoch 22/34 => Loss 3.854, Loss_clf 0.750, Loss_fe 0.940, Loss_kd 1.868, Train_accy 47.83
2022-09-28 02:44:48,546 [foster.py] => Task 5, Epoch 23/34 => Loss 3.857, Loss_clf 0.756, Loss_fe 0.952, Loss_kd 1.856, Train_accy 46.81
2022-09-28 02:44:50,624 [foster.py] => Task 5, Epoch 24/34 => Loss 3.848, Loss_clf 0.747, Loss_fe 0.950, Loss_kd 1.858, Train_accy 46.71
2022-09-28 02:44:52,696 [foster.py] => Task 5, Epoch 25/34 => Loss 3.832, Loss_clf 0.747, Loss_fe 0.937, Loss_kd 1.855, Train_accy 47.12
2022-09-28 02:44:55,721 [foster.py] => Task 5, Epoch 26/34 => Loss 3.807, Loss_clf 0.733, Loss_fe 0.915, Loss_kd 1.864, Train_accy 47.72, Test_accy 44.36
2022-09-28 02:44:57,757 [foster.py] => Task 5, Epoch 27/34 => Loss 3.823, Loss_clf 0.735, Loss_fe 0.921, Loss_kd 1.871, Train_accy 47.42
2022-09-28 02:44:59,854 [foster.py] => Task 5, Epoch 28/34 => Loss 3.806, Loss_clf 0.730, Loss_fe 0.922, Loss_kd 1.861, Train_accy 46.51
2022-09-28 02:45:01,919 [foster.py] => Task 5, Epoch 29/34 => Loss 3.804, Loss_clf 0.735, Loss_fe 0.905, Loss_kd 1.869, Train_accy 47.83
2022-09-28 02:45:04,012 [foster.py] => Task 5, Epoch 30/34 => Loss 3.783, Loss_clf 0.721, Loss_fe 0.903, Loss_kd 1.864, Train_accy 46.01
2022-09-28 02:45:07,078 [foster.py] => Task 5, Epoch 31/34 => Loss 3.807, Loss_clf 0.735, Loss_fe 0.913, Loss_kd 1.865, Train_accy 47.83, Test_accy 44.55
2022-09-28 02:45:09,126 [foster.py] => Task 5, Epoch 32/34 => Loss 3.799, Loss_clf 0.729, Loss_fe 0.913, Loss_kd 1.863, Train_accy 47.52
2022-09-28 02:45:11,166 [foster.py] => Task 5, Epoch 33/34 => Loss 3.830, Loss_clf 0.741, Loss_fe 0.925, Loss_kd 1.869, Train_accy 46.71
2022-09-28 02:45:13,291 [foster.py] => Task 5, Epoch 34/34 => Loss 3.773, Loss_clf 0.715, Loss_fe 0.900, Loss_kd 1.863, Train_accy 47.52
2022-09-28 02:45:13,292 [foster.py] => do not weight align teacher!
2022-09-28 02:45:13,292 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 02:45:16,658 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.433,  Train_accy 19.21, Test_accy 33.07
2022-09-28 02:45:19,020 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.409,  Train_accy 19.31
2022-09-28 02:45:21,347 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.385,  Train_accy 20.73
2022-09-28 02:45:23,698 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.375,  Train_accy 19.51
2022-09-28 02:45:26,040 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.359,  Train_accy 20.42
2022-09-28 02:45:29,223 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.352,  Train_accy 20.42, Test_accy 33.47
2022-09-28 02:45:31,579 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.349,  Train_accy 21.13
2022-09-28 02:45:33,904 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.342,  Train_accy 21.54
2022-09-28 02:45:36,221 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.340,  Train_accy 22.14
2022-09-28 02:45:38,553 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.329,  Train_accy 21.23
2022-09-28 02:45:41,728 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.337,  Train_accy 21.33, Test_accy 34.46
2022-09-28 02:45:44,054 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.338,  Train_accy 21.94
2022-09-28 02:45:46,368 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.320,  Train_accy 22.85
2022-09-28 02:45:48,724 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.327,  Train_accy 22.75
2022-09-28 02:45:51,087 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.328,  Train_accy 23.46
2022-09-28 02:45:54,228 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.326,  Train_accy 22.45, Test_accy 34.26
2022-09-28 02:45:56,563 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.319,  Train_accy 22.35
2022-09-28 02:45:58,869 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.327,  Train_accy 24.17
2022-09-28 02:46:01,194 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.323,  Train_accy 22.95
2022-09-28 02:46:03,544 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.316,  Train_accy 23.46
2022-09-28 02:46:06,725 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.327,  Train_accy 23.76, Test_accy 35.25
2022-09-28 02:46:09,135 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.321,  Train_accy 24.06
2022-09-28 02:46:11,441 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.312,  Train_accy 22.24
2022-09-28 02:46:13,764 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.320,  Train_accy 23.56
2022-09-28 02:46:16,067 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.323,  Train_accy 24.87
2022-09-28 02:46:19,315 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.318,  Train_accy 23.56, Test_accy 34.85
2022-09-28 02:46:19,316 [foster.py] => do not weight align student!
2022-09-28 02:46:20,157 [foster.py] => darknet eval: 
2022-09-28 02:46:20,157 [foster.py] => CNN top1 curve: 34.85
2022-09-28 02:46:20,157 [foster.py] => CNN top5 curve: 81.98
2022-09-28 02:46:20,158 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 02:46:30,800 [foster.py] => Exemplar size: 440
2022-09-28 02:46:30,800 [trainer.py] => CNN: {'total': 44.55, 'old': 46.24, 'new': 35.44, 'base': 73.65, 'compound': 32.49}
2022-09-28 02:46:30,800 [trainer.py] => CNN top1 curve: [87.16, 75.48, 61.65, 54.78, 46.95, 44.55]
2022-09-28 02:46:30,801 [trainer.py] => CNN base curve: [87.16, 86.49, 81.76, 77.7, 75.0, 73.65]
2022-09-28 02:46:30,801 [trainer.py] => CNN old curve: [87.16, 86.49, 72.12, 61.65, 51.69, 46.24]
2022-09-28 02:46:30,801 [trainer.py] => CNN new curve: [0, 48.33, 30.99, 29.87, 22.86, 35.44]
2022-09-28 02:46:30,801 [trainer.py] => CNN compound curve: [0, 48.33, 38.93, 38.46, 32.01, 32.49]
2022-09-28 02:46:30,801 [trainer.py] => NME: {'total': 51.09, 'old': 50.47, 'new': 54.43, 'base': 62.84, 'compound': 46.22}
2022-09-28 02:46:30,801 [trainer.py] => NME top1 curve: [87.16, 78.37, 71.33, 58.71, 54.93, 51.09]
2022-09-28 02:46:30,801 [trainer.py] => NME base curve: [87.16, 83.11, 77.03, 66.89, 67.57, 62.84]
2022-09-28 02:46:30,801 [trainer.py] => NME old curve: [87.16, 83.11, 71.63, 62.37, 57.58, 50.47]
2022-09-28 02:46:30,801 [trainer.py] => NME new curve: [0, 66.67, 70.42, 45.45, 41.43, 54.43]
2022-09-28 02:46:30,801 [trainer.py] => NME compound curve: [0, 66.67, 64.89, 52.88, 48.2, 46.22]
2022-09-28 02:46:30,802 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 02:46:30,802 [trainer.py] => prefix: cil
2022-09-28 02:46:30,802 [trainer.py] => dataset: CFEE
2022-09-28 02:46:30,802 [trainer.py] => memory_size: 2000
2022-09-28 02:46:30,802 [trainer.py] => memory_per_class: 20
2022-09-28 02:46:30,802 [trainer.py] => fixed_memory: True
2022-09-28 02:46:30,802 [trainer.py] => shuffle: True
2022-09-28 02:46:30,802 [trainer.py] => init_cls: 7
2022-09-28 02:46:30,802 [trainer.py] => increment: 3
2022-09-28 02:46:30,802 [trainer.py] => model_name: foster
2022-09-28 02:46:30,802 [trainer.py] => convnet_type: resnet18
2022-09-28 02:46:30,803 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 02:46:30,803 [trainer.py] => seed: 1993
2022-09-28 02:46:30,803 [trainer.py] => beta1: 0.96
2022-09-28 02:46:30,803 [trainer.py] => beta2: 0.97
2022-09-28 02:46:30,803 [trainer.py] => oofc: ft
2022-09-28 02:46:30,803 [trainer.py] => is_teacher_wa: False
2022-09-28 02:46:30,803 [trainer.py] => is_student_wa: False
2022-09-28 02:46:30,803 [trainer.py] => lambda_okd: 1
2022-09-28 02:46:30,803 [trainer.py] => wa_value: 1
2022-09-28 02:46:30,803 [trainer.py] => init_epochs: 40
2022-09-28 02:46:30,803 [trainer.py] => init_lr: 0.01
2022-09-28 02:46:30,803 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 02:46:30,803 [trainer.py] => boosting_epochs: 34
2022-09-28 02:46:30,803 [trainer.py] => compression_epochs: 26
2022-09-28 02:46:30,803 [trainer.py] => lr: 0.001
2022-09-28 02:46:30,803 [trainer.py] => batch_size: 32
2022-09-28 02:46:30,803 [trainer.py] => weight_decay: 0.0005
2022-09-28 02:46:30,803 [trainer.py] => num_workers: 8
2022-09-28 02:46:30,803 [trainer.py] => T: 2
2022-09-28 02:46:30,803 [trainer.py] => nb_runs: 3
2022-09-28 02:46:30,803 [trainer.py] => fold: 10
2022-09-28 02:46:30,803 [data.py] => ========== Fold:2 ==========
2022-09-28 02:46:30,808 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 8, 15, 13, 17, 9, 11, 19, 21, 14, 10, 18, 12, 7, 16]
2022-09-28 02:46:31,021 [foster.py] => Learning on 0-7
2022-09-28 02:46:31,021 [foster.py] => All params: 11183694
2022-09-28 02:46:31,022 [foster.py] => Trainable params: 11183694
2022-09-28 02:46:33,430 [foster.py] => Task 0, Epoch 1/40 => Loss 1.358, Train_accy 49.83
2022-09-28 02:46:36,428 [foster.py] => Task 0, Epoch 2/40 => Loss 0.560, Train_accy 80.06, Test_accy 82.28
2022-09-28 02:46:39,408 [foster.py] => Task 0, Epoch 3/40 => Loss 0.352, Train_accy 87.92, Test_accy 86.08
2022-09-28 02:46:42,371 [foster.py] => Task 0, Epoch 4/40 => Loss 0.303, Train_accy 89.16, Test_accy 86.08
2022-09-28 02:46:45,344 [foster.py] => Task 0, Epoch 5/40 => Loss 0.226, Train_accy 91.93, Test_accy 85.44
2022-09-28 02:46:47,742 [foster.py] => Task 0, Epoch 6/40 => Loss 0.182, Train_accy 94.13
2022-09-28 02:46:50,755 [foster.py] => Task 0, Epoch 7/40 => Loss 0.175, Train_accy 93.93, Test_accy 84.18
2022-09-28 02:46:53,755 [foster.py] => Task 0, Epoch 8/40 => Loss 0.131, Train_accy 95.79, Test_accy 87.34
2022-09-28 02:46:56,714 [foster.py] => Task 0, Epoch 9/40 => Loss 0.106, Train_accy 96.83, Test_accy 87.34
2022-09-28 02:46:59,686 [foster.py] => Task 0, Epoch 10/40 => Loss 0.097, Train_accy 97.10, Test_accy 85.44
2022-09-28 02:47:02,051 [foster.py] => Task 0, Epoch 11/40 => Loss 0.080, Train_accy 97.65
2022-09-28 02:47:05,112 [foster.py] => Task 0, Epoch 12/40 => Loss 0.110, Train_accy 96.34, Test_accy 86.71
2022-09-28 02:47:08,099 [foster.py] => Task 0, Epoch 13/40 => Loss 0.080, Train_accy 97.31, Test_accy 87.97
2022-09-28 02:47:11,141 [foster.py] => Task 0, Epoch 14/40 => Loss 0.058, Train_accy 98.34, Test_accy 87.34
2022-09-28 02:47:14,173 [foster.py] => Task 0, Epoch 15/40 => Loss 0.053, Train_accy 98.76, Test_accy 84.18
2022-09-28 02:47:16,546 [foster.py] => Task 0, Epoch 16/40 => Loss 0.046, Train_accy 98.96
2022-09-28 02:47:19,525 [foster.py] => Task 0, Epoch 17/40 => Loss 0.044, Train_accy 98.83, Test_accy 88.61
2022-09-28 02:47:22,563 [foster.py] => Task 0, Epoch 18/40 => Loss 0.036, Train_accy 98.90, Test_accy 87.97
2022-09-28 02:47:25,639 [foster.py] => Task 0, Epoch 19/40 => Loss 0.027, Train_accy 99.24, Test_accy 87.34
2022-09-28 02:47:28,647 [foster.py] => Task 0, Epoch 20/40 => Loss 0.027, Train_accy 99.10, Test_accy 87.34
2022-09-28 02:47:31,038 [foster.py] => Task 0, Epoch 21/40 => Loss 0.027, Train_accy 99.59
2022-09-28 02:47:34,088 [foster.py] => Task 0, Epoch 22/40 => Loss 0.021, Train_accy 99.59, Test_accy 86.08
2022-09-28 02:47:37,086 [foster.py] => Task 0, Epoch 23/40 => Loss 0.032, Train_accy 99.52, Test_accy 84.18
2022-09-28 02:47:40,087 [foster.py] => Task 0, Epoch 24/40 => Loss 0.033, Train_accy 98.90, Test_accy 84.18
2022-09-28 02:47:43,071 [foster.py] => Task 0, Epoch 25/40 => Loss 0.030, Train_accy 99.38, Test_accy 87.34
2022-09-28 02:47:45,476 [foster.py] => Task 0, Epoch 26/40 => Loss 0.026, Train_accy 99.45
2022-09-28 02:47:48,469 [foster.py] => Task 0, Epoch 27/40 => Loss 0.018, Train_accy 99.72, Test_accy 86.08
2022-09-28 02:47:51,422 [foster.py] => Task 0, Epoch 28/40 => Loss 0.016, Train_accy 99.86, Test_accy 86.08
2022-09-28 02:47:54,384 [foster.py] => Task 0, Epoch 29/40 => Loss 0.013, Train_accy 99.86, Test_accy 86.08
2022-09-28 02:47:57,368 [foster.py] => Task 0, Epoch 30/40 => Loss 0.014, Train_accy 99.86, Test_accy 86.71
2022-09-28 02:47:59,749 [foster.py] => Task 0, Epoch 31/40 => Loss 0.014, Train_accy 99.86
2022-09-28 02:48:02,719 [foster.py] => Task 0, Epoch 32/40 => Loss 0.012, Train_accy 100.00, Test_accy 84.81
2022-09-28 02:48:05,776 [foster.py] => Task 0, Epoch 33/40 => Loss 0.013, Train_accy 99.86, Test_accy 85.44
2022-09-28 02:48:08,796 [foster.py] => Task 0, Epoch 34/40 => Loss 0.015, Train_accy 99.86, Test_accy 86.08
2022-09-28 02:48:11,799 [foster.py] => Task 0, Epoch 35/40 => Loss 0.015, Train_accy 99.86, Test_accy 84.81
2022-09-28 02:48:14,178 [foster.py] => Task 0, Epoch 36/40 => Loss 0.011, Train_accy 99.79
2022-09-28 02:48:17,192 [foster.py] => Task 0, Epoch 37/40 => Loss 0.014, Train_accy 99.79, Test_accy 85.44
2022-09-28 02:48:20,198 [foster.py] => Task 0, Epoch 38/40 => Loss 0.014, Train_accy 99.79, Test_accy 86.08
2022-09-28 02:48:23,190 [foster.py] => Task 0, Epoch 39/40 => Loss 0.013, Train_accy 99.79, Test_accy 86.08
2022-09-28 02:48:26,176 [foster.py] => Task 0, Epoch 40/40 => Loss 0.013, Train_accy 99.93, Test_accy 85.44
2022-09-28 02:48:26,176 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 02:48:32,986 [foster.py] => Exemplar size: 140
2022-09-28 02:48:32,987 [trainer.py] => CNN: {'total': 85.44, 'old': 85.44, 'new': 0, 'base': 85.44, 'compound': 0}
2022-09-28 02:48:32,987 [trainer.py] => CNN top1 curve: [85.44]
2022-09-28 02:48:32,987 [trainer.py] => CNN base curve: [85.44]
2022-09-28 02:48:32,987 [trainer.py] => CNN old curve: [85.44]
2022-09-28 02:48:32,987 [trainer.py] => CNN new curve: [0]
2022-09-28 02:48:32,987 [trainer.py] => CNN compound curve: [0]
2022-09-28 02:48:32,987 [trainer.py] => NME: {'total': 88.61, 'old': 88.61, 'new': 0, 'base': 88.61, 'compound': 0}
2022-09-28 02:48:32,987 [trainer.py] => NME top1 curve: [88.61]
2022-09-28 02:48:32,987 [trainer.py] => NME base curve: [88.61]
2022-09-28 02:48:32,987 [trainer.py] => NME old curve: [88.61]
2022-09-28 02:48:32,987 [trainer.py] => NME new curve: [0]
2022-09-28 02:48:32,987 [trainer.py] => NME compound curve: [0]
2022-09-28 02:48:33,217 [foster.py] => Learning on 7-10
2022-09-28 02:48:33,217 [foster.py] => All params: 22371995
2022-09-28 02:48:33,218 [foster.py] => Trainable params: 11191892
2022-09-28 02:48:33,238 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 02:48:35,747 [foster.py] => Task 1, Epoch 1/34 => Loss 4.437, Loss_clf 2.111, Loss_fe 1.674, Loss_kd 0.456, Train_accy 40.10, Test_accy 68.02
2022-09-28 02:48:37,535 [foster.py] => Task 1, Epoch 2/34 => Loss 2.410, Loss_clf 0.642, Loss_fe 1.111, Loss_kd 0.460, Train_accy 77.85
2022-09-28 02:48:39,261 [foster.py] => Task 1, Epoch 3/34 => Loss 1.932, Loss_clf 0.390, Loss_fe 0.913, Loss_kd 0.440, Train_accy 52.29
2022-09-28 02:48:41,013 [foster.py] => Task 1, Epoch 4/34 => Loss 1.796, Loss_clf 0.356, Loss_fe 0.811, Loss_kd 0.441, Train_accy 52.56
2022-09-28 02:48:42,736 [foster.py] => Task 1, Epoch 5/34 => Loss 1.612, Loss_clf 0.298, Loss_fe 0.679, Loss_kd 0.444, Train_accy 56.49
2022-09-28 02:48:45,216 [foster.py] => Task 1, Epoch 6/34 => Loss 1.531, Loss_clf 0.282, Loss_fe 0.624, Loss_kd 0.437, Train_accy 54.78, Test_accy 68.02
2022-09-28 02:48:46,951 [foster.py] => Task 1, Epoch 7/34 => Loss 1.503, Loss_clf 0.275, Loss_fe 0.595, Loss_kd 0.444, Train_accy 57.14
2022-09-28 02:48:48,691 [foster.py] => Task 1, Epoch 8/34 => Loss 1.424, Loss_clf 0.253, Loss_fe 0.541, Loss_kd 0.441, Train_accy 57.93
2022-09-28 02:48:50,449 [foster.py] => Task 1, Epoch 9/34 => Loss 1.362, Loss_clf 0.237, Loss_fe 0.498, Loss_kd 0.439, Train_accy 59.50
2022-09-28 02:48:52,185 [foster.py] => Task 1, Epoch 10/34 => Loss 1.319, Loss_clf 0.227, Loss_fe 0.458, Loss_kd 0.444, Train_accy 59.63
2022-09-28 02:48:54,611 [foster.py] => Task 1, Epoch 11/34 => Loss 1.281, Loss_clf 0.216, Loss_fe 0.441, Loss_kd 0.437, Train_accy 61.73, Test_accy 69.82
2022-09-28 02:48:56,323 [foster.py] => Task 1, Epoch 12/34 => Loss 1.282, Loss_clf 0.223, Loss_fe 0.433, Loss_kd 0.438, Train_accy 62.12
2022-09-28 02:48:58,042 [foster.py] => Task 1, Epoch 13/34 => Loss 1.239, Loss_clf 0.205, Loss_fe 0.403, Loss_kd 0.442, Train_accy 62.25
2022-09-28 02:48:59,756 [foster.py] => Task 1, Epoch 14/34 => Loss 1.192, Loss_clf 0.191, Loss_fe 0.379, Loss_kd 0.435, Train_accy 60.81
2022-09-28 02:49:01,495 [foster.py] => Task 1, Epoch 15/34 => Loss 1.222, Loss_clf 0.203, Loss_fe 0.391, Loss_kd 0.440, Train_accy 60.68
2022-09-28 02:49:03,966 [foster.py] => Task 1, Epoch 16/34 => Loss 1.156, Loss_clf 0.182, Loss_fe 0.351, Loss_kd 0.435, Train_accy 62.65, Test_accy 70.72
2022-09-28 02:49:05,713 [foster.py] => Task 1, Epoch 17/34 => Loss 1.140, Loss_clf 0.173, Loss_fe 0.348, Loss_kd 0.434, Train_accy 64.22
2022-09-28 02:49:07,422 [foster.py] => Task 1, Epoch 18/34 => Loss 1.166, Loss_clf 0.182, Loss_fe 0.354, Loss_kd 0.441, Train_accy 64.35
2022-09-28 02:49:09,123 [foster.py] => Task 1, Epoch 19/34 => Loss 1.122, Loss_clf 0.166, Loss_fe 0.330, Loss_kd 0.439, Train_accy 64.35
2022-09-28 02:49:10,874 [foster.py] => Task 1, Epoch 20/34 => Loss 1.098, Loss_clf 0.159, Loss_fe 0.308, Loss_kd 0.442, Train_accy 67.50
2022-09-28 02:49:13,333 [foster.py] => Task 1, Epoch 21/34 => Loss 1.078, Loss_clf 0.150, Loss_fe 0.306, Loss_kd 0.436, Train_accy 66.45, Test_accy 71.17
2022-09-28 02:49:15,094 [foster.py] => Task 1, Epoch 22/34 => Loss 1.087, Loss_clf 0.163, Loss_fe 0.304, Loss_kd 0.435, Train_accy 64.61
2022-09-28 02:49:16,828 [foster.py] => Task 1, Epoch 23/34 => Loss 1.089, Loss_clf 0.162, Loss_fe 0.300, Loss_kd 0.439, Train_accy 64.74
2022-09-28 02:49:18,564 [foster.py] => Task 1, Epoch 24/34 => Loss 1.103, Loss_clf 0.167, Loss_fe 0.308, Loss_kd 0.439, Train_accy 63.70
2022-09-28 02:49:20,310 [foster.py] => Task 1, Epoch 25/34 => Loss 1.071, Loss_clf 0.151, Loss_fe 0.295, Loss_kd 0.437, Train_accy 66.58
2022-09-28 02:49:22,848 [foster.py] => Task 1, Epoch 26/34 => Loss 1.071, Loss_clf 0.153, Loss_fe 0.293, Loss_kd 0.438, Train_accy 63.96, Test_accy 71.62
2022-09-28 02:49:24,548 [foster.py] => Task 1, Epoch 27/34 => Loss 1.082, Loss_clf 0.151, Loss_fe 0.291, Loss_kd 0.447, Train_accy 66.45
2022-09-28 02:49:26,281 [foster.py] => Task 1, Epoch 28/34 => Loss 1.112, Loss_clf 0.174, Loss_fe 0.309, Loss_kd 0.441, Train_accy 66.19
2022-09-28 02:49:28,015 [foster.py] => Task 1, Epoch 29/34 => Loss 1.074, Loss_clf 0.154, Loss_fe 0.299, Loss_kd 0.435, Train_accy 64.22
2022-09-28 02:49:29,715 [foster.py] => Task 1, Epoch 30/34 => Loss 1.060, Loss_clf 0.148, Loss_fe 0.292, Loss_kd 0.434, Train_accy 64.22
2022-09-28 02:49:32,202 [foster.py] => Task 1, Epoch 31/34 => Loss 1.059, Loss_clf 0.151, Loss_fe 0.289, Loss_kd 0.434, Train_accy 65.53, Test_accy 71.62
2022-09-28 02:49:33,920 [foster.py] => Task 1, Epoch 32/34 => Loss 1.083, Loss_clf 0.162, Loss_fe 0.293, Loss_kd 0.440, Train_accy 65.92
2022-09-28 02:49:35,628 [foster.py] => Task 1, Epoch 33/34 => Loss 1.034, Loss_clf 0.135, Loss_fe 0.273, Loss_kd 0.438, Train_accy 64.35
2022-09-28 02:49:37,374 [foster.py] => Task 1, Epoch 34/34 => Loss 1.065, Loss_clf 0.152, Loss_fe 0.293, Loss_kd 0.434, Train_accy 65.40
2022-09-28 02:49:37,374 [foster.py] => do not weight align teacher!
2022-09-28 02:49:37,375 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 02:49:40,252 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.530,  Train_accy 17.69, Test_accy 59.91
2022-09-28 02:49:42,237 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.436,  Train_accy 18.09
2022-09-28 02:49:44,143 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.353,  Train_accy 18.09
2022-09-28 02:49:46,057 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.309,  Train_accy 19.27
2022-09-28 02:49:48,010 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.273,  Train_accy 20.84
2022-09-28 02:49:50,590 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.264,  Train_accy 20.84, Test_accy 63.06
2022-09-28 02:49:52,550 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.247,  Train_accy 22.80
2022-09-28 02:49:54,496 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.227,  Train_accy 25.16
2022-09-28 02:49:56,408 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.224,  Train_accy 24.90
2022-09-28 02:49:58,329 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.221,  Train_accy 25.69
2022-09-28 02:50:00,973 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.212,  Train_accy 26.61, Test_accy 64.41
2022-09-28 02:50:02,902 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.210,  Train_accy 28.18
2022-09-28 02:50:04,853 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.196,  Train_accy 27.92
2022-09-28 02:50:06,784 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.194,  Train_accy 26.87
2022-09-28 02:50:08,759 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.199,  Train_accy 30.80
2022-09-28 02:50:11,320 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.187,  Train_accy 30.01, Test_accy 65.32
2022-09-28 02:50:13,225 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.186,  Train_accy 29.75
2022-09-28 02:50:15,166 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.184,  Train_accy 30.54
2022-09-28 02:50:17,083 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.184,  Train_accy 28.70
2022-09-28 02:50:19,056 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.184,  Train_accy 29.10
2022-09-28 02:50:21,669 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.183,  Train_accy 30.93, Test_accy 65.77
2022-09-28 02:50:23,586 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.163,  Train_accy 29.36
2022-09-28 02:50:25,491 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.182,  Train_accy 30.54
2022-09-28 02:50:27,427 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.175,  Train_accy 31.72
2022-09-28 02:50:29,351 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.177,  Train_accy 31.85
2022-09-28 02:50:31,910 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.176,  Train_accy 30.01, Test_accy 65.77
2022-09-28 02:50:31,910 [foster.py] => do not weight align student!
2022-09-28 02:50:32,572 [foster.py] => darknet eval: 
2022-09-28 02:50:32,572 [foster.py] => CNN top1 curve: 65.77
2022-09-28 02:50:32,572 [foster.py] => CNN top5 curve: 98.65
2022-09-28 02:50:32,573 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 02:50:38,908 [foster.py] => Exemplar size: 200
2022-09-28 02:50:38,908 [trainer.py] => CNN: {'total': 71.17, 'old': 81.01, 'new': 46.88, 'base': 81.01, 'compound': 46.88}
2022-09-28 02:50:38,909 [trainer.py] => CNN top1 curve: [85.44, 71.17]
2022-09-28 02:50:38,909 [trainer.py] => CNN base curve: [85.44, 81.01]
2022-09-28 02:50:38,909 [trainer.py] => CNN old curve: [85.44, 81.01]
2022-09-28 02:50:38,909 [trainer.py] => CNN new curve: [0, 46.88]
2022-09-28 02:50:38,909 [trainer.py] => CNN compound curve: [0, 46.88]
2022-09-28 02:50:38,909 [trainer.py] => NME: {'total': 78.83, 'old': 80.38, 'new': 75.0, 'base': 80.38, 'compound': 75.0}
2022-09-28 02:50:38,909 [trainer.py] => NME top1 curve: [88.61, 78.83]
2022-09-28 02:50:38,909 [trainer.py] => NME base curve: [88.61, 80.38]
2022-09-28 02:50:38,909 [trainer.py] => NME old curve: [88.61, 80.38]
2022-09-28 02:50:38,909 [trainer.py] => NME new curve: [0, 75.0]
2022-09-28 02:50:38,909 [trainer.py] => NME compound curve: [0, 75.0]
2022-09-28 02:50:39,139 [foster.py] => Learning on 10-13
2022-09-28 02:50:39,139 [foster.py] => All params: 22378148
2022-09-28 02:50:39,140 [foster.py] => Trainable params: 11196506
2022-09-28 02:50:39,160 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 02:50:41,739 [foster.py] => Task 2, Epoch 1/34 => Loss 5.275, Loss_clf 2.050, Loss_fe 2.056, Loss_kd 0.900, Train_accy 41.54, Test_accy 53.06
2022-09-28 02:50:43,619 [foster.py] => Task 2, Epoch 2/34 => Loss 3.175, Loss_clf 0.708, Loss_fe 1.299, Loss_kd 0.898, Train_accy 56.99
2022-09-28 02:50:45,400 [foster.py] => Task 2, Epoch 3/34 => Loss 2.820, Loss_clf 0.571, Loss_fe 1.102, Loss_kd 0.882, Train_accy 46.57
2022-09-28 02:50:47,238 [foster.py] => Task 2, Epoch 4/34 => Loss 2.578, Loss_clf 0.475, Loss_fe 0.948, Loss_kd 0.888, Train_accy 47.92
2022-09-28 02:50:49,085 [foster.py] => Task 2, Epoch 5/34 => Loss 2.493, Loss_clf 0.462, Loss_fe 0.883, Loss_kd 0.882, Train_accy 49.26
2022-09-28 02:50:51,679 [foster.py] => Task 2, Epoch 6/34 => Loss 2.385, Loss_clf 0.450, Loss_fe 0.791, Loss_kd 0.880, Train_accy 46.32, Test_accy 60.88
2022-09-28 02:50:53,511 [foster.py] => Task 2, Epoch 7/34 => Loss 2.330, Loss_clf 0.430, Loss_fe 0.751, Loss_kd 0.884, Train_accy 49.39
2022-09-28 02:50:55,342 [foster.py] => Task 2, Epoch 8/34 => Loss 2.255, Loss_clf 0.412, Loss_fe 0.694, Loss_kd 0.883, Train_accy 48.04
2022-09-28 02:50:57,182 [foster.py] => Task 2, Epoch 9/34 => Loss 2.215, Loss_clf 0.406, Loss_fe 0.659, Loss_kd 0.885, Train_accy 50.74
2022-09-28 02:50:59,028 [foster.py] => Task 2, Epoch 10/34 => Loss 2.170, Loss_clf 0.389, Loss_fe 0.631, Loss_kd 0.885, Train_accy 48.77
2022-09-28 02:51:01,609 [foster.py] => Task 2, Epoch 11/34 => Loss 2.145, Loss_clf 0.393, Loss_fe 0.596, Loss_kd 0.890, Train_accy 50.49, Test_accy 62.24
2022-09-28 02:51:03,444 [foster.py] => Task 2, Epoch 12/34 => Loss 2.133, Loss_clf 0.393, Loss_fe 0.601, Loss_kd 0.877, Train_accy 52.45
2022-09-28 02:51:05,296 [foster.py] => Task 2, Epoch 13/34 => Loss 2.044, Loss_clf 0.361, Loss_fe 0.547, Loss_kd 0.874, Train_accy 49.88
2022-09-28 02:51:07,120 [foster.py] => Task 2, Epoch 14/34 => Loss 2.058, Loss_clf 0.361, Loss_fe 0.537, Loss_kd 0.892, Train_accy 48.90
2022-09-28 02:51:08,964 [foster.py] => Task 2, Epoch 15/34 => Loss 2.036, Loss_clf 0.360, Loss_fe 0.529, Loss_kd 0.882, Train_accy 51.47
2022-09-28 02:51:11,593 [foster.py] => Task 2, Epoch 16/34 => Loss 2.013, Loss_clf 0.348, Loss_fe 0.523, Loss_kd 0.878, Train_accy 49.26, Test_accy 62.24
2022-09-28 02:51:13,413 [foster.py] => Task 2, Epoch 17/34 => Loss 2.008, Loss_clf 0.352, Loss_fe 0.500, Loss_kd 0.889, Train_accy 51.35
2022-09-28 02:51:15,227 [foster.py] => Task 2, Epoch 18/34 => Loss 1.987, Loss_clf 0.346, Loss_fe 0.488, Loss_kd 0.887, Train_accy 48.65
2022-09-28 02:51:17,107 [foster.py] => Task 2, Epoch 19/34 => Loss 1.947, Loss_clf 0.327, Loss_fe 0.474, Loss_kd 0.881, Train_accy 52.33
2022-09-28 02:51:18,929 [foster.py] => Task 2, Epoch 20/34 => Loss 1.964, Loss_clf 0.340, Loss_fe 0.474, Loss_kd 0.885, Train_accy 51.84
2022-09-28 02:51:21,512 [foster.py] => Task 2, Epoch 21/34 => Loss 1.913, Loss_clf 0.316, Loss_fe 0.451, Loss_kd 0.882, Train_accy 51.10, Test_accy 60.88
2022-09-28 02:51:23,334 [foster.py] => Task 2, Epoch 22/34 => Loss 1.925, Loss_clf 0.321, Loss_fe 0.451, Loss_kd 0.887, Train_accy 51.10
2022-09-28 02:51:25,185 [foster.py] => Task 2, Epoch 23/34 => Loss 1.905, Loss_clf 0.308, Loss_fe 0.447, Loss_kd 0.885, Train_accy 51.35
2022-09-28 02:51:26,981 [foster.py] => Task 2, Epoch 24/34 => Loss 1.911, Loss_clf 0.312, Loss_fe 0.439, Loss_kd 0.892, Train_accy 50.98
2022-09-28 02:51:28,827 [foster.py] => Task 2, Epoch 25/34 => Loss 1.925, Loss_clf 0.317, Loss_fe 0.451, Loss_kd 0.890, Train_accy 50.86
2022-09-28 02:51:31,414 [foster.py] => Task 2, Epoch 26/34 => Loss 1.936, Loss_clf 0.325, Loss_fe 0.463, Loss_kd 0.884, Train_accy 52.21, Test_accy 62.59
2022-09-28 02:51:33,255 [foster.py] => Task 2, Epoch 27/34 => Loss 1.897, Loss_clf 0.308, Loss_fe 0.432, Loss_kd 0.890, Train_accy 52.21
2022-09-28 02:51:35,039 [foster.py] => Task 2, Epoch 28/34 => Loss 1.934, Loss_clf 0.319, Loss_fe 0.454, Loss_kd 0.893, Train_accy 53.43
2022-09-28 02:51:36,849 [foster.py] => Task 2, Epoch 29/34 => Loss 1.917, Loss_clf 0.320, Loss_fe 0.441, Loss_kd 0.889, Train_accy 51.10
2022-09-28 02:51:38,653 [foster.py] => Task 2, Epoch 30/34 => Loss 1.895, Loss_clf 0.306, Loss_fe 0.436, Loss_kd 0.887, Train_accy 51.10
2022-09-28 02:51:41,315 [foster.py] => Task 2, Epoch 31/34 => Loss 1.875, Loss_clf 0.298, Loss_fe 0.429, Loss_kd 0.883, Train_accy 53.06, Test_accy 61.56
2022-09-28 02:51:43,148 [foster.py] => Task 2, Epoch 32/34 => Loss 1.877, Loss_clf 0.299, Loss_fe 0.425, Loss_kd 0.887, Train_accy 51.10
2022-09-28 02:51:44,945 [foster.py] => Task 2, Epoch 33/34 => Loss 1.912, Loss_clf 0.313, Loss_fe 0.434, Loss_kd 0.896, Train_accy 52.33
2022-09-28 02:51:46,771 [foster.py] => Task 2, Epoch 34/34 => Loss 1.924, Loss_clf 0.327, Loss_fe 0.436, Loss_kd 0.893, Train_accy 52.82
2022-09-28 02:51:46,772 [foster.py] => do not weight align teacher!
2022-09-28 02:51:46,772 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 02:51:49,766 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.739,  Train_accy 16.91, Test_accy 48.30
2022-09-28 02:51:51,772 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.666,  Train_accy 17.40
2022-09-28 02:51:53,830 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.628,  Train_accy 17.89
2022-09-28 02:51:55,821 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.588,  Train_accy 17.77
2022-09-28 02:51:57,818 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.579,  Train_accy 18.87
2022-09-28 02:52:00,603 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.574,  Train_accy 19.73, Test_accy 51.70
2022-09-28 02:52:02,603 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.570,  Train_accy 20.47
2022-09-28 02:52:04,609 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.559,  Train_accy 22.18
2022-09-28 02:52:06,599 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.540,  Train_accy 22.55
2022-09-28 02:52:08,652 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.543,  Train_accy 25.25
2022-09-28 02:52:11,439 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.540,  Train_accy 24.39, Test_accy 52.38
2022-09-28 02:52:13,479 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.547,  Train_accy 23.04
2022-09-28 02:52:15,487 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.526,  Train_accy 24.75
2022-09-28 02:52:17,539 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.527,  Train_accy 25.86
2022-09-28 02:52:19,585 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.522,  Train_accy 25.25
2022-09-28 02:52:22,377 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.524,  Train_accy 25.37, Test_accy 53.40
2022-09-28 02:52:24,462 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.524,  Train_accy 26.72
2022-09-28 02:52:26,475 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.523,  Train_accy 25.61
2022-09-28 02:52:28,547 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.516,  Train_accy 26.10
2022-09-28 02:52:30,612 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.532,  Train_accy 25.74
2022-09-28 02:52:33,435 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.510,  Train_accy 27.57, Test_accy 54.08
2022-09-28 02:52:35,538 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.523,  Train_accy 27.70
2022-09-28 02:52:37,557 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.508,  Train_accy 26.96
2022-09-28 02:52:39,594 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.520,  Train_accy 27.33
2022-09-28 02:52:41,686 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.525,  Train_accy 25.86
2022-09-28 02:52:44,434 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.524,  Train_accy 26.23, Test_accy 53.74
2022-09-28 02:52:44,434 [foster.py] => do not weight align student!
2022-09-28 02:52:45,156 [foster.py] => darknet eval: 
2022-09-28 02:52:45,156 [foster.py] => CNN top1 curve: 53.74
2022-09-28 02:52:45,156 [foster.py] => CNN top5 curve: 97.62
2022-09-28 02:52:45,156 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 02:52:52,522 [foster.py] => Exemplar size: 260
2022-09-28 02:52:52,522 [trainer.py] => CNN: {'total': 61.22, 'old': 70.27, 'new': 33.33, 'base': 78.48, 'compound': 41.18}
2022-09-28 02:52:52,522 [trainer.py] => CNN top1 curve: [85.44, 71.17, 61.22]
2022-09-28 02:52:52,522 [trainer.py] => CNN base curve: [85.44, 81.01, 78.48]
2022-09-28 02:52:52,522 [trainer.py] => CNN old curve: [85.44, 81.01, 70.27]
2022-09-28 02:52:52,522 [trainer.py] => CNN new curve: [0, 46.88, 33.33]
2022-09-28 02:52:52,522 [trainer.py] => CNN compound curve: [0, 46.88, 41.18]
2022-09-28 02:52:52,522 [trainer.py] => NME: {'total': 73.13, 'old': 73.87, 'new': 70.83, 'base': 77.22, 'compound': 68.38}
2022-09-28 02:52:52,522 [trainer.py] => NME top1 curve: [88.61, 78.83, 73.13]
2022-09-28 02:52:52,522 [trainer.py] => NME base curve: [88.61, 80.38, 77.22]
2022-09-28 02:52:52,522 [trainer.py] => NME old curve: [88.61, 80.38, 73.87]
2022-09-28 02:52:52,523 [trainer.py] => NME new curve: [0, 75.0, 70.83]
2022-09-28 02:52:52,523 [trainer.py] => NME compound curve: [0, 75.0, 68.38]
2022-09-28 02:52:52,752 [foster.py] => Learning on 13-16
2022-09-28 02:52:52,753 [foster.py] => All params: 22384301
2022-09-28 02:52:52,753 [foster.py] => Trainable params: 11201120
2022-09-28 02:52:52,773 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 02:52:55,611 [foster.py] => Task 3, Epoch 1/34 => Loss 6.238, Loss_clf 2.181, Loss_fe 2.423, Loss_kd 1.328, Train_accy 36.81, Test_accy 43.59
2022-09-28 02:52:57,567 [foster.py] => Task 3, Epoch 2/34 => Loss 4.498, Loss_clf 1.113, Loss_fe 1.765, Loss_kd 1.316, Train_accy 39.73
2022-09-28 02:52:59,481 [foster.py] => Task 3, Epoch 3/34 => Loss 4.124, Loss_clf 0.952, Loss_fe 1.564, Loss_kd 1.307, Train_accy 40.40
2022-09-28 02:53:01,443 [foster.py] => Task 3, Epoch 4/34 => Loss 3.938, Loss_clf 0.909, Loss_fe 1.421, Loss_kd 1.307, Train_accy 39.39
2022-09-28 02:53:03,375 [foster.py] => Task 3, Epoch 5/34 => Loss 3.826, Loss_clf 0.889, Loss_fe 1.340, Loss_kd 1.298, Train_accy 38.50
2022-09-28 02:53:06,240 [foster.py] => Task 3, Epoch 6/34 => Loss 3.704, Loss_clf 0.863, Loss_fe 1.244, Loss_kd 1.298, Train_accy 39.84, Test_accy 53.85
2022-09-28 02:53:08,143 [foster.py] => Task 3, Epoch 7/34 => Loss 3.646, Loss_clf 0.859, Loss_fe 1.188, Loss_kd 1.300, Train_accy 41.86
2022-09-28 02:53:10,057 [foster.py] => Task 3, Epoch 8/34 => Loss 3.550, Loss_clf 0.819, Loss_fe 1.126, Loss_kd 1.304, Train_accy 40.63
2022-09-28 02:53:12,003 [foster.py] => Task 3, Epoch 9/34 => Loss 3.488, Loss_clf 0.798, Loss_fe 1.090, Loss_kd 1.300, Train_accy 41.08
2022-09-28 02:53:13,912 [foster.py] => Task 3, Epoch 10/34 => Loss 3.445, Loss_clf 0.789, Loss_fe 1.043, Loss_kd 1.311, Train_accy 43.10
2022-09-28 02:53:16,738 [foster.py] => Task 3, Epoch 11/34 => Loss 3.383, Loss_clf 0.767, Loss_fe 1.008, Loss_kd 1.307, Train_accy 40.40, Test_accy 53.56
2022-09-28 02:53:18,664 [foster.py] => Task 3, Epoch 12/34 => Loss 3.300, Loss_clf 0.739, Loss_fe 0.958, Loss_kd 1.302, Train_accy 43.43
2022-09-28 02:53:20,567 [foster.py] => Task 3, Epoch 13/34 => Loss 3.281, Loss_clf 0.736, Loss_fe 0.943, Loss_kd 1.301, Train_accy 41.86
2022-09-28 02:53:22,465 [foster.py] => Task 3, Epoch 14/34 => Loss 3.275, Loss_clf 0.740, Loss_fe 0.926, Loss_kd 1.307, Train_accy 42.42
2022-09-28 02:53:24,363 [foster.py] => Task 3, Epoch 15/34 => Loss 3.205, Loss_clf 0.710, Loss_fe 0.887, Loss_kd 1.307, Train_accy 40.97
2022-09-28 02:53:27,139 [foster.py] => Task 3, Epoch 16/34 => Loss 3.174, Loss_clf 0.703, Loss_fe 0.858, Loss_kd 1.310, Train_accy 43.66, Test_accy 54.70
2022-09-28 02:53:29,083 [foster.py] => Task 3, Epoch 17/34 => Loss 3.177, Loss_clf 0.695, Loss_fe 0.868, Loss_kd 1.311, Train_accy 44.89
2022-09-28 02:53:31,031 [foster.py] => Task 3, Epoch 18/34 => Loss 3.094, Loss_clf 0.665, Loss_fe 0.822, Loss_kd 1.306, Train_accy 44.89
2022-09-28 02:53:32,957 [foster.py] => Task 3, Epoch 19/34 => Loss 3.101, Loss_clf 0.668, Loss_fe 0.819, Loss_kd 1.311, Train_accy 45.01
2022-09-28 02:53:34,879 [foster.py] => Task 3, Epoch 20/34 => Loss 3.056, Loss_clf 0.649, Loss_fe 0.798, Loss_kd 1.307, Train_accy 44.67
2022-09-28 02:53:37,692 [foster.py] => Task 3, Epoch 21/34 => Loss 3.101, Loss_clf 0.682, Loss_fe 0.816, Loss_kd 1.303, Train_accy 44.56, Test_accy 54.70
2022-09-28 02:53:39,681 [foster.py] => Task 3, Epoch 22/34 => Loss 3.014, Loss_clf 0.633, Loss_fe 0.766, Loss_kd 1.312, Train_accy 47.03
2022-09-28 02:53:41,595 [foster.py] => Task 3, Epoch 23/34 => Loss 3.005, Loss_clf 0.629, Loss_fe 0.767, Loss_kd 1.308, Train_accy 46.24
2022-09-28 02:53:43,501 [foster.py] => Task 3, Epoch 24/34 => Loss 3.012, Loss_clf 0.640, Loss_fe 0.768, Loss_kd 1.303, Train_accy 46.24
2022-09-28 02:53:45,440 [foster.py] => Task 3, Epoch 25/34 => Loss 3.016, Loss_clf 0.637, Loss_fe 0.770, Loss_kd 1.308, Train_accy 46.02
2022-09-28 02:53:48,228 [foster.py] => Task 3, Epoch 26/34 => Loss 2.984, Loss_clf 0.617, Loss_fe 0.757, Loss_kd 1.309, Train_accy 45.90, Test_accy 55.27
2022-09-28 02:53:50,184 [foster.py] => Task 3, Epoch 27/34 => Loss 2.982, Loss_clf 0.617, Loss_fe 0.753, Loss_kd 1.310, Train_accy 47.14
2022-09-28 02:53:52,122 [foster.py] => Task 3, Epoch 28/34 => Loss 2.953, Loss_clf 0.611, Loss_fe 0.740, Loss_kd 1.302, Train_accy 46.13
2022-09-28 02:53:54,027 [foster.py] => Task 3, Epoch 29/34 => Loss 2.989, Loss_clf 0.630, Loss_fe 0.746, Loss_kd 1.311, Train_accy 45.68
2022-09-28 02:53:55,992 [foster.py] => Task 3, Epoch 30/34 => Loss 2.980, Loss_clf 0.614, Loss_fe 0.748, Loss_kd 1.314, Train_accy 45.90
2022-09-28 02:53:58,735 [foster.py] => Task 3, Epoch 31/34 => Loss 2.975, Loss_clf 0.614, Loss_fe 0.751, Loss_kd 1.308, Train_accy 44.78, Test_accy 54.99
2022-09-28 02:54:00,645 [foster.py] => Task 3, Epoch 32/34 => Loss 2.978, Loss_clf 0.620, Loss_fe 0.743, Loss_kd 1.312, Train_accy 45.79
2022-09-28 02:54:02,565 [foster.py] => Task 3, Epoch 33/34 => Loss 2.973, Loss_clf 0.626, Loss_fe 0.739, Loss_kd 1.307, Train_accy 46.35
2022-09-28 02:54:04,470 [foster.py] => Task 3, Epoch 34/34 => Loss 3.031, Loss_clf 0.651, Loss_fe 0.771, Loss_kd 1.308, Train_accy 44.78
2022-09-28 02:54:04,471 [foster.py] => do not weight align teacher!
2022-09-28 02:54:04,471 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 02:54:07,624 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.189,  Train_accy 18.29, Test_accy 47.58
2022-09-28 02:54:09,788 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.078,  Train_accy 19.53
2022-09-28 02:54:11,963 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.012,  Train_accy 20.43
2022-09-28 02:54:14,118 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 1.989,  Train_accy 20.09
2022-09-28 02:54:16,289 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.997,  Train_accy 19.87
2022-09-28 02:54:19,242 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.975,  Train_accy 19.87, Test_accy 48.43
2022-09-28 02:54:21,438 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.954,  Train_accy 20.43
2022-09-28 02:54:23,629 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.957,  Train_accy 20.99
2022-09-28 02:54:25,806 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.956,  Train_accy 20.76
2022-09-28 02:54:27,977 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.945,  Train_accy 19.87
2022-09-28 02:54:30,871 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.950,  Train_accy 19.64, Test_accy 49.29
2022-09-28 02:54:33,090 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.942,  Train_accy 20.09
2022-09-28 02:54:35,223 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.946,  Train_accy 20.65
2022-09-28 02:54:37,407 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.942,  Train_accy 21.66
2022-09-28 02:54:39,608 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.940,  Train_accy 21.55
2022-09-28 02:54:42,579 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.938,  Train_accy 21.32, Test_accy 49.57
2022-09-28 02:54:44,707 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.937,  Train_accy 20.99
2022-09-28 02:54:46,886 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.933,  Train_accy 20.54
2022-09-28 02:54:49,034 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.941,  Train_accy 20.65
2022-09-28 02:54:51,221 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.944,  Train_accy 21.10
2022-09-28 02:54:54,116 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.939,  Train_accy 20.43, Test_accy 50.14
2022-09-28 02:54:56,266 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.939,  Train_accy 21.21
2022-09-28 02:54:58,434 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.941,  Train_accy 21.89
2022-09-28 02:55:00,655 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.933,  Train_accy 21.44
2022-09-28 02:55:02,788 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.939,  Train_accy 20.65
2022-09-28 02:55:05,676 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.932,  Train_accy 20.65, Test_accy 49.86
2022-09-28 02:55:05,676 [foster.py] => do not weight align student!
2022-09-28 02:55:06,406 [foster.py] => darknet eval: 
2022-09-28 02:55:06,406 [foster.py] => CNN top1 curve: 49.86
2022-09-28 02:55:06,406 [foster.py] => CNN top5 curve: 92.59
2022-09-28 02:55:06,406 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 02:55:14,883 [foster.py] => Exemplar size: 320
2022-09-28 02:55:14,883 [trainer.py] => CNN: {'total': 55.56, 'old': 60.88, 'new': 28.07, 'base': 75.95, 'compound': 38.86}
2022-09-28 02:55:14,883 [trainer.py] => CNN top1 curve: [85.44, 71.17, 61.22, 55.56]
2022-09-28 02:55:14,883 [trainer.py] => CNN base curve: [85.44, 81.01, 78.48, 75.95]
2022-09-28 02:55:14,883 [trainer.py] => CNN old curve: [85.44, 81.01, 70.27, 60.88]
2022-09-28 02:55:14,883 [trainer.py] => CNN new curve: [0, 46.88, 33.33, 28.07]
2022-09-28 02:55:14,883 [trainer.py] => CNN compound curve: [0, 46.88, 41.18, 38.86]
2022-09-28 02:55:14,883 [trainer.py] => NME: {'total': 64.39, 'old': 68.37, 'new': 43.86, 'base': 72.78, 'compound': 57.51}
2022-09-28 02:55:14,883 [trainer.py] => NME top1 curve: [88.61, 78.83, 73.13, 64.39]
2022-09-28 02:55:14,883 [trainer.py] => NME base curve: [88.61, 80.38, 77.22, 72.78]
2022-09-28 02:55:14,883 [trainer.py] => NME old curve: [88.61, 80.38, 73.87, 68.37]
2022-09-28 02:55:14,883 [trainer.py] => NME new curve: [0, 75.0, 70.83, 43.86]
2022-09-28 02:55:14,883 [trainer.py] => NME compound curve: [0, 75.0, 68.38, 57.51]
2022-09-28 02:55:15,111 [foster.py] => Learning on 16-19
2022-09-28 02:55:15,111 [foster.py] => All params: 22390454
2022-09-28 02:55:15,111 [foster.py] => Trainable params: 11205734
2022-09-28 02:55:15,131 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 02:55:18,032 [foster.py] => Task 4, Epoch 1/34 => Loss 6.433, Loss_clf 1.977, Loss_fe 2.502, Loss_kd 1.646, Train_accy 40.80, Test_accy 43.68
2022-09-28 02:55:20,019 [foster.py] => Task 4, Epoch 2/34 => Loss 4.886, Loss_clf 1.086, Loss_fe 1.841, Loss_kd 1.650, Train_accy 37.45
2022-09-28 02:55:22,082 [foster.py] => Task 4, Epoch 3/34 => Loss 4.596, Loss_clf 0.998, Loss_fe 1.642, Loss_kd 1.647, Train_accy 41.77
2022-09-28 02:55:24,095 [foster.py] => Task 4, Epoch 4/34 => Loss 4.414, Loss_clf 0.961, Loss_fe 1.502, Loss_kd 1.643, Train_accy 38.85
2022-09-28 02:55:26,071 [foster.py] => Task 4, Epoch 5/34 => Loss 4.277, Loss_clf 0.922, Loss_fe 1.413, Loss_kd 1.636, Train_accy 40.48
2022-09-28 02:55:28,977 [foster.py] => Task 4, Epoch 6/34 => Loss 4.208, Loss_clf 0.919, Loss_fe 1.336, Loss_kd 1.644, Train_accy 40.37, Test_accy 46.44
2022-09-28 02:55:30,948 [foster.py] => Task 4, Epoch 7/34 => Loss 4.124, Loss_clf 0.896, Loss_fe 1.283, Loss_kd 1.637, Train_accy 39.61
2022-09-28 02:55:32,909 [foster.py] => Task 4, Epoch 8/34 => Loss 4.033, Loss_clf 0.884, Loss_fe 1.208, Loss_kd 1.635, Train_accy 40.26
2022-09-28 02:55:34,869 [foster.py] => Task 4, Epoch 9/34 => Loss 4.001, Loss_clf 0.869, Loss_fe 1.180, Loss_kd 1.643, Train_accy 41.02
2022-09-28 02:55:36,855 [foster.py] => Task 4, Epoch 10/34 => Loss 3.900, Loss_clf 0.832, Loss_fe 1.121, Loss_kd 1.640, Train_accy 40.91
2022-09-28 02:55:39,786 [foster.py] => Task 4, Epoch 11/34 => Loss 3.863, Loss_clf 0.826, Loss_fe 1.090, Loss_kd 1.640, Train_accy 40.37, Test_accy 47.36
2022-09-28 02:55:41,756 [foster.py] => Task 4, Epoch 12/34 => Loss 3.852, Loss_clf 0.825, Loss_fe 1.072, Loss_kd 1.646, Train_accy 39.29
2022-09-28 02:55:43,722 [foster.py] => Task 4, Epoch 13/34 => Loss 3.809, Loss_clf 0.822, Loss_fe 1.043, Loss_kd 1.637, Train_accy 42.75
2022-09-28 02:55:45,684 [foster.py] => Task 4, Epoch 14/34 => Loss 3.811, Loss_clf 0.818, Loss_fe 1.035, Loss_kd 1.649, Train_accy 41.56
2022-09-28 02:55:47,671 [foster.py] => Task 4, Epoch 15/34 => Loss 3.700, Loss_clf 0.775, Loss_fe 0.981, Loss_kd 1.637, Train_accy 44.05
2022-09-28 02:55:50,576 [foster.py] => Task 4, Epoch 16/34 => Loss 3.680, Loss_clf 0.769, Loss_fe 0.962, Loss_kd 1.641, Train_accy 43.51, Test_accy 50.34
2022-09-28 02:55:52,574 [foster.py] => Task 4, Epoch 17/34 => Loss 3.661, Loss_clf 0.755, Loss_fe 0.949, Loss_kd 1.648, Train_accy 41.56
2022-09-28 02:55:54,568 [foster.py] => Task 4, Epoch 18/34 => Loss 3.652, Loss_clf 0.757, Loss_fe 0.934, Loss_kd 1.651, Train_accy 45.67
2022-09-28 02:55:56,537 [foster.py] => Task 4, Epoch 19/34 => Loss 3.615, Loss_clf 0.748, Loss_fe 0.911, Loss_kd 1.647, Train_accy 43.51
2022-09-28 02:55:58,492 [foster.py] => Task 4, Epoch 20/34 => Loss 3.611, Loss_clf 0.746, Loss_fe 0.906, Loss_kd 1.650, Train_accy 42.64
2022-09-28 02:56:01,432 [foster.py] => Task 4, Epoch 21/34 => Loss 3.595, Loss_clf 0.743, Loss_fe 0.899, Loss_kd 1.645, Train_accy 41.99, Test_accy 50.11
2022-09-28 02:56:03,400 [foster.py] => Task 4, Epoch 22/34 => Loss 3.593, Loss_clf 0.746, Loss_fe 0.898, Loss_kd 1.642, Train_accy 43.72
2022-09-28 02:56:05,431 [foster.py] => Task 4, Epoch 23/34 => Loss 3.522, Loss_clf 0.709, Loss_fe 0.859, Loss_kd 1.645, Train_accy 44.48
2022-09-28 02:56:07,458 [foster.py] => Task 4, Epoch 24/34 => Loss 3.563, Loss_clf 0.733, Loss_fe 0.880, Loss_kd 1.642, Train_accy 42.53
2022-09-28 02:56:09,481 [foster.py] => Task 4, Epoch 25/34 => Loss 3.551, Loss_clf 0.716, Loss_fe 0.874, Loss_kd 1.651, Train_accy 44.59
2022-09-28 02:56:12,509 [foster.py] => Task 4, Epoch 26/34 => Loss 3.520, Loss_clf 0.705, Loss_fe 0.863, Loss_kd 1.644, Train_accy 45.02, Test_accy 50.34
2022-09-28 02:56:14,474 [foster.py] => Task 4, Epoch 27/34 => Loss 3.525, Loss_clf 0.706, Loss_fe 0.864, Loss_kd 1.646, Train_accy 43.29
2022-09-28 02:56:16,458 [foster.py] => Task 4, Epoch 28/34 => Loss 3.528, Loss_clf 0.719, Loss_fe 0.854, Loss_kd 1.646, Train_accy 46.00
2022-09-28 02:56:18,416 [foster.py] => Task 4, Epoch 29/34 => Loss 3.550, Loss_clf 0.721, Loss_fe 0.872, Loss_kd 1.648, Train_accy 45.24
2022-09-28 02:56:20,387 [foster.py] => Task 4, Epoch 30/34 => Loss 3.553, Loss_clf 0.727, Loss_fe 0.870, Loss_kd 1.647, Train_accy 44.05
2022-09-28 02:56:23,318 [foster.py] => Task 4, Epoch 31/34 => Loss 3.526, Loss_clf 0.710, Loss_fe 0.851, Loss_kd 1.655, Train_accy 43.61, Test_accy 49.89
2022-09-28 02:56:25,282 [foster.py] => Task 4, Epoch 32/34 => Loss 3.546, Loss_clf 0.727, Loss_fe 0.862, Loss_kd 1.648, Train_accy 45.24
2022-09-28 02:56:27,244 [foster.py] => Task 4, Epoch 33/34 => Loss 3.525, Loss_clf 0.709, Loss_fe 0.859, Loss_kd 1.648, Train_accy 45.67
2022-09-28 02:56:29,209 [foster.py] => Task 4, Epoch 34/34 => Loss 3.489, Loss_clf 0.686, Loss_fe 0.846, Loss_kd 1.648, Train_accy 44.16
2022-09-28 02:56:29,209 [foster.py] => do not weight align teacher!
2022-09-28 02:56:29,210 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 02:56:32,451 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.290,  Train_accy 18.94, Test_accy 41.15
2022-09-28 02:56:34,666 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.228,  Train_accy 19.59
2022-09-28 02:56:36,862 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.220,  Train_accy 20.45
2022-09-28 02:56:39,131 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.208,  Train_accy 21.10
2022-09-28 02:56:41,363 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.205,  Train_accy 21.10
2022-09-28 02:56:44,363 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.196,  Train_accy 21.21, Test_accy 41.61
2022-09-28 02:56:46,606 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.190,  Train_accy 21.65
2022-09-28 02:56:48,798 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.197,  Train_accy 21.21
2022-09-28 02:56:51,089 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.179,  Train_accy 21.54
2022-09-28 02:56:53,320 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.191,  Train_accy 22.08
2022-09-28 02:56:56,355 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.184,  Train_accy 21.75, Test_accy 41.61
2022-09-28 02:56:58,579 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.183,  Train_accy 21.75
2022-09-28 02:57:00,775 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.186,  Train_accy 22.51
2022-09-28 02:57:03,020 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.171,  Train_accy 22.40
2022-09-28 02:57:05,217 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.183,  Train_accy 21.10
2022-09-28 02:57:08,314 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.171,  Train_accy 22.29, Test_accy 41.84
2022-09-28 02:57:10,551 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.175,  Train_accy 22.84
2022-09-28 02:57:12,784 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.178,  Train_accy 21.97
2022-09-28 02:57:14,986 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.169,  Train_accy 22.29
2022-09-28 02:57:17,220 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.170,  Train_accy 21.32
2022-09-28 02:57:20,221 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.178,  Train_accy 21.75, Test_accy 42.07
2022-09-28 02:57:22,439 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.174,  Train_accy 21.75
2022-09-28 02:57:24,683 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.172,  Train_accy 22.40
2022-09-28 02:57:26,925 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.180,  Train_accy 21.21
2022-09-28 02:57:29,121 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.180,  Train_accy 21.65
2022-09-28 02:57:32,169 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.179,  Train_accy 21.97, Test_accy 41.61
2022-09-28 02:57:32,169 [foster.py] => do not weight align student!
2022-09-28 02:57:32,973 [foster.py] => darknet eval: 
2022-09-28 02:57:32,974 [foster.py] => CNN top1 curve: 41.61
2022-09-28 02:57:32,974 [foster.py] => CNN top5 curve: 83.22
2022-09-28 02:57:32,974 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 02:57:42,617 [foster.py] => Exemplar size: 380
2022-09-28 02:57:42,617 [trainer.py] => CNN: {'total': 50.11, 'old': 55.84, 'new': 26.19, 'base': 71.52, 'compound': 37.91}
2022-09-28 02:57:42,617 [trainer.py] => CNN top1 curve: [85.44, 71.17, 61.22, 55.56, 50.11]
2022-09-28 02:57:42,617 [trainer.py] => CNN base curve: [85.44, 81.01, 78.48, 75.95, 71.52]
2022-09-28 02:57:42,617 [trainer.py] => CNN old curve: [85.44, 81.01, 70.27, 60.88, 55.84]
2022-09-28 02:57:42,617 [trainer.py] => CNN new curve: [0, 46.88, 33.33, 28.07, 26.19]
2022-09-28 02:57:42,617 [trainer.py] => CNN compound curve: [0, 46.88, 41.18, 38.86, 37.91]
2022-09-28 02:57:42,617 [trainer.py] => NME: {'total': 57.24, 'old': 60.11, 'new': 45.24, 'base': 68.99, 'compound': 50.54}
2022-09-28 02:57:42,617 [trainer.py] => NME top1 curve: [88.61, 78.83, 73.13, 64.39, 57.24]
2022-09-28 02:57:42,617 [trainer.py] => NME base curve: [88.61, 80.38, 77.22, 72.78, 68.99]
2022-09-28 02:57:42,617 [trainer.py] => NME old curve: [88.61, 80.38, 73.87, 68.37, 60.11]
2022-09-28 02:57:42,617 [trainer.py] => NME new curve: [0, 75.0, 70.83, 43.86, 45.24]
2022-09-28 02:57:42,617 [trainer.py] => NME compound curve: [0, 75.0, 68.38, 57.51, 50.54]
2022-09-28 02:57:42,846 [foster.py] => Learning on 19-22
2022-09-28 02:57:42,846 [foster.py] => All params: 22396607
2022-09-28 02:57:42,847 [foster.py] => Trainable params: 11210348
2022-09-28 02:57:42,867 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 02:57:46,019 [foster.py] => Task 5, Epoch 1/34 => Loss 6.792, Loss_clf 2.063, Loss_fe 2.569, Loss_kd 1.865, Train_accy 37.27, Test_accy 40.79
2022-09-28 02:57:48,146 [foster.py] => Task 5, Epoch 2/34 => Loss 5.199, Loss_clf 1.120, Loss_fe 1.897, Loss_kd 1.884, Train_accy 34.77
2022-09-28 02:57:50,250 [foster.py] => Task 5, Epoch 3/34 => Loss 4.904, Loss_clf 1.018, Loss_fe 1.710, Loss_kd 1.879, Train_accy 39.18
2022-09-28 02:57:52,364 [foster.py] => Task 5, Epoch 4/34 => Loss 4.710, Loss_clf 0.958, Loss_fe 1.568, Loss_kd 1.886, Train_accy 38.58
2022-09-28 02:57:54,448 [foster.py] => Task 5, Epoch 5/34 => Loss 4.587, Loss_clf 0.937, Loss_fe 1.493, Loss_kd 1.863, Train_accy 41.28
2022-09-28 02:57:57,535 [foster.py] => Task 5, Epoch 6/34 => Loss 4.495, Loss_clf 0.910, Loss_fe 1.410, Loss_kd 1.879, Train_accy 42.38, Test_accy 42.38
2022-09-28 02:57:59,606 [foster.py] => Task 5, Epoch 7/34 => Loss 4.398, Loss_clf 0.900, Loss_fe 1.321, Loss_kd 1.881, Train_accy 43.09
2022-09-28 02:58:01,716 [foster.py] => Task 5, Epoch 8/34 => Loss 4.357, Loss_clf 0.892, Loss_fe 1.290, Loss_kd 1.878, Train_accy 43.89
2022-09-28 02:58:03,809 [foster.py] => Task 5, Epoch 9/34 => Loss 4.279, Loss_clf 0.880, Loss_fe 1.231, Loss_kd 1.872, Train_accy 42.38
2022-09-28 02:58:05,869 [foster.py] => Task 5, Epoch 10/34 => Loss 4.212, Loss_clf 0.848, Loss_fe 1.179, Loss_kd 1.888, Train_accy 44.39
2022-09-28 02:58:08,960 [foster.py] => Task 5, Epoch 11/34 => Loss 4.157, Loss_clf 0.819, Loss_fe 1.155, Loss_kd 1.885, Train_accy 44.19, Test_accy 44.16
2022-09-28 02:58:11,077 [foster.py] => Task 5, Epoch 12/34 => Loss 4.141, Loss_clf 0.827, Loss_fe 1.138, Loss_kd 1.879, Train_accy 45.29
2022-09-28 02:58:13,163 [foster.py] => Task 5, Epoch 13/34 => Loss 4.048, Loss_clf 0.788, Loss_fe 1.080, Loss_kd 1.883, Train_accy 43.39
2022-09-28 02:58:15,226 [foster.py] => Task 5, Epoch 14/34 => Loss 4.035, Loss_clf 0.799, Loss_fe 1.070, Loss_kd 1.871, Train_accy 45.89
2022-09-28 02:58:17,301 [foster.py] => Task 5, Epoch 15/34 => Loss 4.027, Loss_clf 0.795, Loss_fe 1.047, Loss_kd 1.887, Train_accy 44.49
2022-09-28 02:58:20,351 [foster.py] => Task 5, Epoch 16/34 => Loss 4.017, Loss_clf 0.804, Loss_fe 1.037, Loss_kd 1.879, Train_accy 47.70, Test_accy 44.95
2022-09-28 02:58:22,460 [foster.py] => Task 5, Epoch 17/34 => Loss 3.961, Loss_clf 0.777, Loss_fe 1.012, Loss_kd 1.876, Train_accy 44.29
2022-09-28 02:58:24,526 [foster.py] => Task 5, Epoch 18/34 => Loss 3.963, Loss_clf 0.776, Loss_fe 1.009, Loss_kd 1.880, Train_accy 44.79
2022-09-28 02:58:26,647 [foster.py] => Task 5, Epoch 19/34 => Loss 3.985, Loss_clf 0.787, Loss_fe 1.012, Loss_kd 1.889, Train_accy 46.99
2022-09-28 02:58:28,741 [foster.py] => Task 5, Epoch 20/34 => Loss 3.915, Loss_clf 0.758, Loss_fe 0.965, Loss_kd 1.893, Train_accy 46.29
2022-09-28 02:58:31,803 [foster.py] => Task 5, Epoch 21/34 => Loss 3.894, Loss_clf 0.750, Loss_fe 0.963, Loss_kd 1.884, Train_accy 46.69, Test_accy 46.73
2022-09-28 02:58:33,908 [foster.py] => Task 5, Epoch 22/34 => Loss 3.847, Loss_clf 0.740, Loss_fe 0.934, Loss_kd 1.877, Train_accy 43.89
2022-09-28 02:58:35,979 [foster.py] => Task 5, Epoch 23/34 => Loss 3.881, Loss_clf 0.749, Loss_fe 0.955, Loss_kd 1.880, Train_accy 45.89
2022-09-28 02:58:38,045 [foster.py] => Task 5, Epoch 24/34 => Loss 3.873, Loss_clf 0.744, Loss_fe 0.953, Loss_kd 1.879, Train_accy 48.00
2022-09-28 02:58:40,147 [foster.py] => Task 5, Epoch 25/34 => Loss 3.827, Loss_clf 0.722, Loss_fe 0.924, Loss_kd 1.884, Train_accy 45.79
2022-09-28 02:58:43,239 [foster.py] => Task 5, Epoch 26/34 => Loss 3.819, Loss_clf 0.728, Loss_fe 0.910, Loss_kd 1.883, Train_accy 48.60, Test_accy 46.34
2022-09-28 02:58:45,359 [foster.py] => Task 5, Epoch 27/34 => Loss 3.817, Loss_clf 0.721, Loss_fe 0.922, Loss_kd 1.877, Train_accy 46.09
2022-09-28 02:58:47,479 [foster.py] => Task 5, Epoch 28/34 => Loss 3.849, Loss_clf 0.737, Loss_fe 0.926, Loss_kd 1.887, Train_accy 45.79
2022-09-28 02:58:49,586 [foster.py] => Task 5, Epoch 29/34 => Loss 3.788, Loss_clf 0.715, Loss_fe 0.889, Loss_kd 1.886, Train_accy 47.49
2022-09-28 02:58:51,692 [foster.py] => Task 5, Epoch 30/34 => Loss 3.780, Loss_clf 0.709, Loss_fe 0.896, Loss_kd 1.878, Train_accy 47.80
2022-09-28 02:58:54,787 [foster.py] => Task 5, Epoch 31/34 => Loss 3.798, Loss_clf 0.724, Loss_fe 0.905, Loss_kd 1.874, Train_accy 46.79, Test_accy 46.93
2022-09-28 02:58:56,923 [foster.py] => Task 5, Epoch 32/34 => Loss 3.751, Loss_clf 0.693, Loss_fe 0.867, Loss_kd 1.892, Train_accy 46.59
2022-09-28 02:58:59,001 [foster.py] => Task 5, Epoch 33/34 => Loss 3.790, Loss_clf 0.713, Loss_fe 0.893, Loss_kd 1.886, Train_accy 49.10
2022-09-28 02:59:01,105 [foster.py] => Task 5, Epoch 34/34 => Loss 3.775, Loss_clf 0.712, Loss_fe 0.887, Loss_kd 1.880, Train_accy 47.29
2022-09-28 02:59:01,105 [foster.py] => do not weight align teacher!
2022-09-28 02:59:01,105 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 02:59:04,516 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.445,  Train_accy 19.64, Test_accy 37.62
2022-09-28 02:59:06,879 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.411,  Train_accy 20.64
2022-09-28 02:59:09,237 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.404,  Train_accy 21.04
2022-09-28 02:59:11,588 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.394,  Train_accy 21.94
2022-09-28 02:59:13,974 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.388,  Train_accy 21.34
2022-09-28 02:59:17,194 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.354,  Train_accy 21.04, Test_accy 37.03
2022-09-28 02:59:19,561 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.371,  Train_accy 21.24
2022-09-28 02:59:21,968 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.371,  Train_accy 21.54
2022-09-28 02:59:24,319 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.368,  Train_accy 21.94
2022-09-28 02:59:26,672 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.348,  Train_accy 21.94
2022-09-28 02:59:29,890 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.349,  Train_accy 21.64, Test_accy 36.63
2022-09-28 02:59:32,238 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.351,  Train_accy 22.44
2022-09-28 02:59:34,605 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.355,  Train_accy 22.04
2022-09-28 02:59:36,972 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.353,  Train_accy 21.64
2022-09-28 02:59:39,377 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.338,  Train_accy 21.04
2022-09-28 02:59:42,615 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.339,  Train_accy 21.94, Test_accy 38.02
2022-09-28 02:59:44,974 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.347,  Train_accy 22.24
2022-09-28 02:59:47,368 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.336,  Train_accy 23.65
2022-09-28 02:59:49,790 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.340,  Train_accy 21.64
2022-09-28 02:59:52,142 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.338,  Train_accy 21.94
2022-09-28 02:59:55,403 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.331,  Train_accy 23.05, Test_accy 38.22
2022-09-28 02:59:57,797 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.350,  Train_accy 22.04
2022-09-28 03:00:00,182 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.354,  Train_accy 22.14
2022-09-28 03:00:02,555 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.336,  Train_accy 22.75
2022-09-28 03:00:04,900 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.345,  Train_accy 22.95
2022-09-28 03:00:08,097 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.338,  Train_accy 22.95, Test_accy 38.22
2022-09-28 03:00:08,097 [foster.py] => do not weight align student!
2022-09-28 03:00:08,944 [foster.py] => darknet eval: 
2022-09-28 03:00:08,944 [foster.py] => CNN top1 curve: 38.22
2022-09-28 03:00:08,944 [foster.py] => CNN top5 curve: 84.55
2022-09-28 03:00:08,945 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 03:00:19,549 [foster.py] => Exemplar size: 440
2022-09-28 03:00:19,549 [trainer.py] => CNN: {'total': 47.13, 'old': 48.74, 'new': 37.14, 'base': 70.89, 'compound': 36.31}
2022-09-28 03:00:19,549 [trainer.py] => CNN top1 curve: [85.44, 71.17, 61.22, 55.56, 50.11, 47.13]
2022-09-28 03:00:19,549 [trainer.py] => CNN base curve: [85.44, 81.01, 78.48, 75.95, 71.52, 70.89]
2022-09-28 03:00:19,549 [trainer.py] => CNN old curve: [85.44, 81.01, 70.27, 60.88, 55.84, 48.74]
2022-09-28 03:00:19,550 [trainer.py] => CNN new curve: [0, 46.88, 33.33, 28.07, 26.19, 37.14]
2022-09-28 03:00:19,550 [trainer.py] => CNN compound curve: [0, 46.88, 41.18, 38.86, 37.91, 36.31]
2022-09-28 03:00:19,550 [trainer.py] => NME: {'total': 54.65, 'old': 54.94, 'new': 52.86, 'base': 68.99, 'compound': 48.13}
2022-09-28 03:00:19,550 [trainer.py] => NME top1 curve: [88.61, 78.83, 73.13, 64.39, 57.24, 54.65]
2022-09-28 03:00:19,550 [trainer.py] => NME base curve: [88.61, 80.38, 77.22, 72.78, 68.99, 68.99]
2022-09-28 03:00:19,550 [trainer.py] => NME old curve: [88.61, 80.38, 73.87, 68.37, 60.11, 54.94]
2022-09-28 03:00:19,550 [trainer.py] => NME new curve: [0, 75.0, 70.83, 43.86, 45.24, 52.86]
2022-09-28 03:00:19,550 [trainer.py] => NME compound curve: [0, 75.0, 68.38, 57.51, 50.54, 48.13]
2022-09-28 03:00:19,551 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 03:00:19,551 [trainer.py] => prefix: cil
2022-09-28 03:00:19,551 [trainer.py] => dataset: CFEE
2022-09-28 03:00:19,551 [trainer.py] => memory_size: 2000
2022-09-28 03:00:19,551 [trainer.py] => memory_per_class: 20
2022-09-28 03:00:19,551 [trainer.py] => fixed_memory: True
2022-09-28 03:00:19,551 [trainer.py] => shuffle: True
2022-09-28 03:00:19,551 [trainer.py] => init_cls: 7
2022-09-28 03:00:19,551 [trainer.py] => increment: 3
2022-09-28 03:00:19,551 [trainer.py] => model_name: foster
2022-09-28 03:00:19,551 [trainer.py] => convnet_type: resnet18
2022-09-28 03:00:19,551 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 03:00:19,551 [trainer.py] => seed: 1993
2022-09-28 03:00:19,551 [trainer.py] => beta1: 0.96
2022-09-28 03:00:19,551 [trainer.py] => beta2: 0.97
2022-09-28 03:00:19,551 [trainer.py] => oofc: ft
2022-09-28 03:00:19,551 [trainer.py] => is_teacher_wa: False
2022-09-28 03:00:19,552 [trainer.py] => is_student_wa: False
2022-09-28 03:00:19,552 [trainer.py] => lambda_okd: 1
2022-09-28 03:00:19,552 [trainer.py] => wa_value: 1
2022-09-28 03:00:19,552 [trainer.py] => init_epochs: 40
2022-09-28 03:00:19,552 [trainer.py] => init_lr: 0.01
2022-09-28 03:00:19,552 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 03:00:19,552 [trainer.py] => boosting_epochs: 34
2022-09-28 03:00:19,552 [trainer.py] => compression_epochs: 26
2022-09-28 03:00:19,552 [trainer.py] => lr: 0.001
2022-09-28 03:00:19,552 [trainer.py] => batch_size: 32
2022-09-28 03:00:19,552 [trainer.py] => weight_decay: 0.0005
2022-09-28 03:00:19,552 [trainer.py] => num_workers: 8
2022-09-28 03:00:19,552 [trainer.py] => T: 2
2022-09-28 03:00:19,552 [trainer.py] => nb_runs: 3
2022-09-28 03:00:19,552 [trainer.py] => fold: 10
2022-09-28 03:00:19,552 [data.py] => ========== Fold:3 ==========
2022-09-28 03:00:19,557 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 8, 15, 13, 17, 9, 11, 19, 21, 14, 10, 18, 12, 7, 16]
2022-09-28 03:00:19,769 [foster.py] => Learning on 0-7
2022-09-28 03:00:19,769 [foster.py] => All params: 11183694
2022-09-28 03:00:19,769 [foster.py] => Trainable params: 11183694
2022-09-28 03:00:22,142 [foster.py] => Task 0, Epoch 1/40 => Loss 1.344, Train_accy 50.70
2022-09-28 03:00:25,086 [foster.py] => Task 0, Epoch 2/40 => Loss 0.554, Train_accy 80.95, Test_accy 78.77
2022-09-28 03:00:28,103 [foster.py] => Task 0, Epoch 3/40 => Loss 0.341, Train_accy 88.45, Test_accy 86.03
2022-09-28 03:00:31,061 [foster.py] => Task 0, Epoch 4/40 => Loss 0.274, Train_accy 89.50, Test_accy 84.92
2022-09-28 03:00:34,039 [foster.py] => Task 0, Epoch 5/40 => Loss 0.221, Train_accy 92.72, Test_accy 84.92
2022-09-28 03:00:36,470 [foster.py] => Task 0, Epoch 6/40 => Loss 0.182, Train_accy 93.63
2022-09-28 03:00:39,442 [foster.py] => Task 0, Epoch 7/40 => Loss 0.159, Train_accy 94.89, Test_accy 86.59
2022-09-28 03:00:42,434 [foster.py] => Task 0, Epoch 8/40 => Loss 0.150, Train_accy 95.52, Test_accy 85.47
2022-09-28 03:00:45,371 [foster.py] => Task 0, Epoch 9/40 => Loss 0.134, Train_accy 95.03, Test_accy 82.12
2022-09-28 03:00:48,310 [foster.py] => Task 0, Epoch 10/40 => Loss 0.104, Train_accy 97.13, Test_accy 85.47
2022-09-28 03:00:50,672 [foster.py] => Task 0, Epoch 11/40 => Loss 0.077, Train_accy 97.76
2022-09-28 03:00:53,711 [foster.py] => Task 0, Epoch 12/40 => Loss 0.079, Train_accy 97.48, Test_accy 85.47
2022-09-28 03:00:56,688 [foster.py] => Task 0, Epoch 13/40 => Loss 0.066, Train_accy 98.11, Test_accy 87.15
2022-09-28 03:00:59,662 [foster.py] => Task 0, Epoch 14/40 => Loss 0.056, Train_accy 98.18, Test_accy 88.27
2022-09-28 03:01:02,624 [foster.py] => Task 0, Epoch 15/40 => Loss 0.049, Train_accy 98.88, Test_accy 86.59
2022-09-28 03:01:05,040 [foster.py] => Task 0, Epoch 16/40 => Loss 0.034, Train_accy 99.30
2022-09-28 03:01:08,028 [foster.py] => Task 0, Epoch 17/40 => Loss 0.034, Train_accy 99.16, Test_accy 86.59
2022-09-28 03:01:10,978 [foster.py] => Task 0, Epoch 18/40 => Loss 0.044, Train_accy 98.67, Test_accy 87.15
2022-09-28 03:01:13,957 [foster.py] => Task 0, Epoch 19/40 => Loss 0.035, Train_accy 99.37, Test_accy 87.15
2022-09-28 03:01:16,915 [foster.py] => Task 0, Epoch 20/40 => Loss 0.027, Train_accy 99.65, Test_accy 87.15
2022-09-28 03:01:19,236 [foster.py] => Task 0, Epoch 21/40 => Loss 0.025, Train_accy 99.37
2022-09-28 03:01:22,233 [foster.py] => Task 0, Epoch 22/40 => Loss 0.023, Train_accy 99.58, Test_accy 87.71
2022-09-28 03:01:25,211 [foster.py] => Task 0, Epoch 23/40 => Loss 0.025, Train_accy 99.44, Test_accy 86.03
2022-09-28 03:01:28,177 [foster.py] => Task 0, Epoch 24/40 => Loss 0.021, Train_accy 99.58, Test_accy 86.59
2022-09-28 03:01:31,179 [foster.py] => Task 0, Epoch 25/40 => Loss 0.016, Train_accy 99.72, Test_accy 87.15
2022-09-28 03:01:33,535 [foster.py] => Task 0, Epoch 26/40 => Loss 0.014, Train_accy 99.86
2022-09-28 03:01:36,492 [foster.py] => Task 0, Epoch 27/40 => Loss 0.016, Train_accy 99.86, Test_accy 87.15
2022-09-28 03:01:39,488 [foster.py] => Task 0, Epoch 28/40 => Loss 0.019, Train_accy 99.65, Test_accy 87.15
2022-09-28 03:01:42,526 [foster.py] => Task 0, Epoch 29/40 => Loss 0.021, Train_accy 99.65, Test_accy 87.15
2022-09-28 03:01:45,510 [foster.py] => Task 0, Epoch 30/40 => Loss 0.014, Train_accy 99.86, Test_accy 87.15
2022-09-28 03:01:47,854 [foster.py] => Task 0, Epoch 31/40 => Loss 0.014, Train_accy 99.93
2022-09-28 03:01:50,804 [foster.py] => Task 0, Epoch 32/40 => Loss 0.023, Train_accy 99.65, Test_accy 87.15
2022-09-28 03:01:53,745 [foster.py] => Task 0, Epoch 33/40 => Loss 0.013, Train_accy 99.86, Test_accy 87.71
2022-09-28 03:01:56,724 [foster.py] => Task 0, Epoch 34/40 => Loss 0.011, Train_accy 99.86, Test_accy 87.15
2022-09-28 03:01:59,720 [foster.py] => Task 0, Epoch 35/40 => Loss 0.013, Train_accy 99.79, Test_accy 87.15
2022-09-28 03:02:02,108 [foster.py] => Task 0, Epoch 36/40 => Loss 0.012, Train_accy 99.86
2022-09-28 03:02:05,087 [foster.py] => Task 0, Epoch 37/40 => Loss 0.015, Train_accy 99.79, Test_accy 88.27
2022-09-28 03:02:08,115 [foster.py] => Task 0, Epoch 38/40 => Loss 0.012, Train_accy 99.86, Test_accy 88.27
2022-09-28 03:02:11,091 [foster.py] => Task 0, Epoch 39/40 => Loss 0.011, Train_accy 99.86, Test_accy 87.15
2022-09-28 03:02:14,121 [foster.py] => Task 0, Epoch 40/40 => Loss 0.015, Train_accy 99.86, Test_accy 87.71
2022-09-28 03:02:14,122 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 03:02:20,953 [foster.py] => Exemplar size: 140
2022-09-28 03:02:20,953 [trainer.py] => CNN: {'total': 87.71, 'old': 87.71, 'new': 0, 'base': 87.71, 'compound': 0}
2022-09-28 03:02:20,953 [trainer.py] => CNN top1 curve: [87.71]
2022-09-28 03:02:20,953 [trainer.py] => CNN base curve: [87.71]
2022-09-28 03:02:20,953 [trainer.py] => CNN old curve: [87.71]
2022-09-28 03:02:20,953 [trainer.py] => CNN new curve: [0]
2022-09-28 03:02:20,953 [trainer.py] => CNN compound curve: [0]
2022-09-28 03:02:20,953 [trainer.py] => NME: {'total': 86.59, 'old': 86.59, 'new': 0, 'base': 86.59, 'compound': 0}
2022-09-28 03:02:20,953 [trainer.py] => NME top1 curve: [86.59]
2022-09-28 03:02:20,953 [trainer.py] => NME base curve: [86.59]
2022-09-28 03:02:20,953 [trainer.py] => NME old curve: [86.59]
2022-09-28 03:02:20,953 [trainer.py] => NME new curve: [0]
2022-09-28 03:02:20,953 [trainer.py] => NME compound curve: [0]
2022-09-28 03:02:21,182 [foster.py] => Learning on 7-10
2022-09-28 03:02:21,183 [foster.py] => All params: 22371995
2022-09-28 03:02:21,183 [foster.py] => Trainable params: 11191892
2022-09-28 03:02:21,203 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 03:02:23,664 [foster.py] => Task 1, Epoch 1/34 => Loss 4.405, Loss_clf 1.926, Loss_fe 1.835, Loss_kd 0.451, Train_accy 43.06, Test_accy 66.27
2022-09-28 03:02:25,380 [foster.py] => Task 1, Epoch 2/34 => Loss 2.451, Loss_clf 0.667, Loss_fe 1.144, Loss_kd 0.448, Train_accy 78.47
2022-09-28 03:02:27,105 [foster.py] => Task 1, Epoch 3/34 => Loss 1.907, Loss_clf 0.370, Loss_fe 0.915, Loss_kd 0.435, Train_accy 57.86
2022-09-28 03:02:28,839 [foster.py] => Task 1, Epoch 4/34 => Loss 1.719, Loss_clf 0.318, Loss_fe 0.788, Loss_kd 0.429, Train_accy 51.12
2022-09-28 03:02:30,539 [foster.py] => Task 1, Epoch 5/34 => Loss 1.608, Loss_clf 0.297, Loss_fe 0.704, Loss_kd 0.425, Train_accy 54.29
2022-09-28 03:02:33,109 [foster.py] => Task 1, Epoch 6/34 => Loss 1.550, Loss_clf 0.295, Loss_fe 0.648, Loss_kd 0.425, Train_accy 55.75, Test_accy 72.69
2022-09-28 03:02:34,854 [foster.py] => Task 1, Epoch 7/34 => Loss 1.456, Loss_clf 0.258, Loss_fe 0.584, Loss_kd 0.429, Train_accy 57.20
2022-09-28 03:02:36,566 [foster.py] => Task 1, Epoch 8/34 => Loss 1.416, Loss_clf 0.247, Loss_fe 0.564, Loss_kd 0.423, Train_accy 57.20
2022-09-28 03:02:38,325 [foster.py] => Task 1, Epoch 9/34 => Loss 1.367, Loss_clf 0.245, Loss_fe 0.506, Loss_kd 0.431, Train_accy 57.73
2022-09-28 03:02:40,046 [foster.py] => Task 1, Epoch 10/34 => Loss 1.323, Loss_clf 0.233, Loss_fe 0.479, Loss_kd 0.428, Train_accy 57.99
2022-09-28 03:02:42,616 [foster.py] => Task 1, Epoch 11/34 => Loss 1.288, Loss_clf 0.222, Loss_fe 0.450, Loss_kd 0.431, Train_accy 58.52, Test_accy 74.70
2022-09-28 03:02:44,324 [foster.py] => Task 1, Epoch 12/34 => Loss 1.282, Loss_clf 0.228, Loss_fe 0.452, Loss_kd 0.421, Train_accy 58.78
2022-09-28 03:02:46,083 [foster.py] => Task 1, Epoch 13/34 => Loss 1.251, Loss_clf 0.223, Loss_fe 0.419, Loss_kd 0.426, Train_accy 59.31
2022-09-28 03:02:47,823 [foster.py] => Task 1, Epoch 14/34 => Loss 1.204, Loss_clf 0.199, Loss_fe 0.393, Loss_kd 0.429, Train_accy 57.99
2022-09-28 03:02:49,581 [foster.py] => Task 1, Epoch 15/34 => Loss 1.207, Loss_clf 0.208, Loss_fe 0.373, Loss_kd 0.438, Train_accy 60.90
2022-09-28 03:02:52,028 [foster.py] => Task 1, Epoch 16/34 => Loss 1.167, Loss_clf 0.194, Loss_fe 0.361, Loss_kd 0.429, Train_accy 61.43, Test_accy 75.10
2022-09-28 03:02:53,786 [foster.py] => Task 1, Epoch 17/34 => Loss 1.149, Loss_clf 0.189, Loss_fe 0.351, Loss_kd 0.427, Train_accy 60.90
2022-09-28 03:02:55,541 [foster.py] => Task 1, Epoch 18/34 => Loss 1.126, Loss_clf 0.191, Loss_fe 0.331, Loss_kd 0.423, Train_accy 61.43
2022-09-28 03:02:57,308 [foster.py] => Task 1, Epoch 19/34 => Loss 1.145, Loss_clf 0.181, Loss_fe 0.346, Loss_kd 0.433, Train_accy 63.01
2022-09-28 03:02:59,092 [foster.py] => Task 1, Epoch 20/34 => Loss 1.126, Loss_clf 0.184, Loss_fe 0.330, Loss_kd 0.428, Train_accy 60.90
2022-09-28 03:03:01,570 [foster.py] => Task 1, Epoch 21/34 => Loss 1.109, Loss_clf 0.175, Loss_fe 0.317, Loss_kd 0.432, Train_accy 62.75, Test_accy 75.90
2022-09-28 03:03:03,317 [foster.py] => Task 1, Epoch 22/34 => Loss 1.078, Loss_clf 0.160, Loss_fe 0.308, Loss_kd 0.427, Train_accy 63.41
2022-09-28 03:03:05,035 [foster.py] => Task 1, Epoch 23/34 => Loss 1.098, Loss_clf 0.178, Loss_fe 0.307, Loss_kd 0.429, Train_accy 64.73
2022-09-28 03:03:06,751 [foster.py] => Task 1, Epoch 24/34 => Loss 1.097, Loss_clf 0.170, Loss_fe 0.311, Loss_kd 0.431, Train_accy 62.75
2022-09-28 03:03:08,479 [foster.py] => Task 1, Epoch 25/34 => Loss 1.085, Loss_clf 0.171, Loss_fe 0.303, Loss_kd 0.428, Train_accy 63.14
2022-09-28 03:03:10,951 [foster.py] => Task 1, Epoch 26/34 => Loss 1.086, Loss_clf 0.165, Loss_fe 0.304, Loss_kd 0.432, Train_accy 63.41, Test_accy 76.31
2022-09-28 03:03:12,762 [foster.py] => Task 1, Epoch 27/34 => Loss 1.047, Loss_clf 0.160, Loss_fe 0.284, Loss_kd 0.422, Train_accy 64.07
2022-09-28 03:03:14,468 [foster.py] => Task 1, Epoch 28/34 => Loss 1.079, Loss_clf 0.167, Loss_fe 0.296, Loss_kd 0.431, Train_accy 64.46
2022-09-28 03:03:16,231 [foster.py] => Task 1, Epoch 29/34 => Loss 1.074, Loss_clf 0.163, Loss_fe 0.302, Loss_kd 0.427, Train_accy 64.33
2022-09-28 03:03:17,998 [foster.py] => Task 1, Epoch 30/34 => Loss 1.086, Loss_clf 0.170, Loss_fe 0.301, Loss_kd 0.430, Train_accy 63.54
2022-09-28 03:03:20,504 [foster.py] => Task 1, Epoch 31/34 => Loss 1.113, Loss_clf 0.184, Loss_fe 0.314, Loss_kd 0.431, Train_accy 63.94, Test_accy 76.31
2022-09-28 03:03:22,230 [foster.py] => Task 1, Epoch 32/34 => Loss 1.045, Loss_clf 0.156, Loss_fe 0.289, Loss_kd 0.419, Train_accy 62.88
2022-09-28 03:03:24,010 [foster.py] => Task 1, Epoch 33/34 => Loss 1.082, Loss_clf 0.165, Loss_fe 0.296, Loss_kd 0.435, Train_accy 64.33
2022-09-28 03:03:25,724 [foster.py] => Task 1, Epoch 34/34 => Loss 1.075, Loss_clf 0.159, Loss_fe 0.300, Loss_kd 0.431, Train_accy 63.41
2022-09-28 03:03:25,724 [foster.py] => do not weight align teacher!
2022-09-28 03:03:25,725 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 03:03:28,557 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.569,  Train_accy 17.57, Test_accy 57.43
2022-09-28 03:03:30,489 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.428,  Train_accy 18.23
2022-09-28 03:03:32,408 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.348,  Train_accy 18.63
2022-09-28 03:03:34,352 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.286,  Train_accy 19.95
2022-09-28 03:03:36,279 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.266,  Train_accy 21.14
2022-09-28 03:03:38,878 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.236,  Train_accy 22.59, Test_accy 60.64
2022-09-28 03:03:40,833 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.219,  Train_accy 22.72
2022-09-28 03:03:42,751 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.213,  Train_accy 24.17
2022-09-28 03:03:44,728 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.210,  Train_accy 24.70
2022-09-28 03:03:46,654 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.197,  Train_accy 25.36
2022-09-28 03:03:49,271 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.185,  Train_accy 26.55, Test_accy 62.65
2022-09-28 03:03:51,186 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.181,  Train_accy 28.27
2022-09-28 03:03:53,141 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.169,  Train_accy 27.48
2022-09-28 03:03:55,079 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.172,  Train_accy 27.48
2022-09-28 03:03:57,006 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.168,  Train_accy 29.19
2022-09-28 03:03:59,659 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.174,  Train_accy 27.87, Test_accy 63.86
2022-09-28 03:04:01,578 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.177,  Train_accy 30.65
2022-09-28 03:04:03,486 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.168,  Train_accy 29.46
2022-09-28 03:04:05,443 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.165,  Train_accy 29.46
2022-09-28 03:04:07,352 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.162,  Train_accy 30.78
2022-09-28 03:04:09,960 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.168,  Train_accy 30.91, Test_accy 64.26
2022-09-28 03:04:11,905 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.152,  Train_accy 29.72
2022-09-28 03:04:13,844 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.171,  Train_accy 31.04
2022-09-28 03:04:15,791 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.163,  Train_accy 28.67
2022-09-28 03:04:17,727 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.166,  Train_accy 30.52
2022-09-28 03:04:20,347 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.163,  Train_accy 29.33, Test_accy 63.86
2022-09-28 03:04:20,347 [foster.py] => do not weight align student!
2022-09-28 03:04:21,028 [foster.py] => darknet eval: 
2022-09-28 03:04:21,028 [foster.py] => CNN top1 curve: 63.86
2022-09-28 03:04:21,028 [foster.py] => CNN top5 curve: 96.79
2022-09-28 03:04:21,028 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 03:04:27,356 [foster.py] => Exemplar size: 200
2022-09-28 03:04:27,356 [trainer.py] => CNN: {'total': 76.31, 'old': 85.47, 'new': 52.86, 'base': 85.47, 'compound': 52.86}
2022-09-28 03:04:27,357 [trainer.py] => CNN top1 curve: [87.71, 76.31]
2022-09-28 03:04:27,357 [trainer.py] => CNN base curve: [87.71, 85.47]
2022-09-28 03:04:27,357 [trainer.py] => CNN old curve: [87.71, 85.47]
2022-09-28 03:04:27,357 [trainer.py] => CNN new curve: [0, 52.86]
2022-09-28 03:04:27,357 [trainer.py] => CNN compound curve: [0, 52.86]
2022-09-28 03:04:27,357 [trainer.py] => NME: {'total': 79.92, 'old': 82.12, 'new': 74.29, 'base': 82.12, 'compound': 74.29}
2022-09-28 03:04:27,357 [trainer.py] => NME top1 curve: [86.59, 79.92]
2022-09-28 03:04:27,357 [trainer.py] => NME base curve: [86.59, 82.12]
2022-09-28 03:04:27,357 [trainer.py] => NME old curve: [86.59, 82.12]
2022-09-28 03:04:27,357 [trainer.py] => NME new curve: [0, 74.29]
2022-09-28 03:04:27,357 [trainer.py] => NME compound curve: [0, 74.29]
2022-09-28 03:04:27,586 [foster.py] => Learning on 10-13
2022-09-28 03:04:27,587 [foster.py] => All params: 22378148
2022-09-28 03:04:27,587 [foster.py] => Trainable params: 11196506
2022-09-28 03:04:27,607 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 03:04:30,434 [foster.py] => Task 2, Epoch 1/34 => Loss 5.527, Loss_clf 2.262, Loss_fe 2.107, Loss_kd 0.891, Train_accy 38.36, Test_accy 51.62
2022-09-28 03:04:32,389 [foster.py] => Task 2, Epoch 2/34 => Loss 3.241, Loss_clf 0.741, Loss_fe 1.347, Loss_kd 0.887, Train_accy 62.61
2022-09-28 03:04:34,325 [foster.py] => Task 2, Epoch 3/34 => Loss 2.825, Loss_clf 0.567, Loss_fe 1.120, Loss_kd 0.875, Train_accy 42.34
2022-09-28 03:04:36,254 [foster.py] => Task 2, Epoch 4/34 => Loss 2.630, Loss_clf 0.485, Loss_fe 0.991, Loss_kd 0.887, Train_accy 50.06
2022-09-28 03:04:38,169 [foster.py] => Task 2, Epoch 5/34 => Loss 2.518, Loss_clf 0.482, Loss_fe 0.898, Loss_kd 0.876, Train_accy 45.72
2022-09-28 03:04:41,026 [foster.py] => Task 2, Epoch 6/34 => Loss 2.405, Loss_clf 0.453, Loss_fe 0.807, Loss_kd 0.881, Train_accy 47.53, Test_accy 64.61
2022-09-28 03:04:42,963 [foster.py] => Task 2, Epoch 7/34 => Loss 2.348, Loss_clf 0.437, Loss_fe 0.767, Loss_kd 0.880, Train_accy 49.34
2022-09-28 03:04:44,922 [foster.py] => Task 2, Epoch 8/34 => Loss 2.287, Loss_clf 0.425, Loss_fe 0.720, Loss_kd 0.879, Train_accy 48.85
2022-09-28 03:04:46,895 [foster.py] => Task 2, Epoch 9/34 => Loss 2.255, Loss_clf 0.412, Loss_fe 0.685, Loss_kd 0.891, Train_accy 48.01
2022-09-28 03:04:48,858 [foster.py] => Task 2, Epoch 10/34 => Loss 2.171, Loss_clf 0.391, Loss_fe 0.635, Loss_kd 0.881, Train_accy 47.41
2022-09-28 03:04:51,698 [foster.py] => Task 2, Epoch 11/34 => Loss 2.164, Loss_clf 0.395, Loss_fe 0.618, Loss_kd 0.885, Train_accy 48.61, Test_accy 64.94
2022-09-28 03:04:53,706 [foster.py] => Task 2, Epoch 12/34 => Loss 2.135, Loss_clf 0.381, Loss_fe 0.607, Loss_kd 0.882, Train_accy 50.66
2022-09-28 03:04:55,672 [foster.py] => Task 2, Epoch 13/34 => Loss 2.081, Loss_clf 0.356, Loss_fe 0.567, Loss_kd 0.890, Train_accy 47.53
2022-09-28 03:04:57,626 [foster.py] => Task 2, Epoch 14/34 => Loss 2.053, Loss_clf 0.358, Loss_fe 0.548, Loss_kd 0.883, Train_accy 49.82
2022-09-28 03:04:59,570 [foster.py] => Task 2, Epoch 15/34 => Loss 2.073, Loss_clf 0.380, Loss_fe 0.550, Loss_kd 0.879, Train_accy 51.39
2022-09-28 03:05:02,461 [foster.py] => Task 2, Epoch 16/34 => Loss 2.026, Loss_clf 0.340, Loss_fe 0.525, Loss_kd 0.893, Train_accy 50.66, Test_accy 66.23
2022-09-28 03:05:04,398 [foster.py] => Task 2, Epoch 17/34 => Loss 2.003, Loss_clf 0.341, Loss_fe 0.505, Loss_kd 0.890, Train_accy 49.70
2022-09-28 03:05:06,403 [foster.py] => Task 2, Epoch 18/34 => Loss 2.002, Loss_clf 0.355, Loss_fe 0.500, Loss_kd 0.882, Train_accy 49.34
2022-09-28 03:05:08,345 [foster.py] => Task 2, Epoch 19/34 => Loss 1.974, Loss_clf 0.337, Loss_fe 0.484, Loss_kd 0.887, Train_accy 50.78
2022-09-28 03:05:10,317 [foster.py] => Task 2, Epoch 20/34 => Loss 1.987, Loss_clf 0.346, Loss_fe 0.490, Loss_kd 0.885, Train_accy 49.34
2022-09-28 03:05:13,177 [foster.py] => Task 2, Epoch 21/34 => Loss 1.980, Loss_clf 0.340, Loss_fe 0.485, Loss_kd 0.889, Train_accy 50.42, Test_accy 66.56
2022-09-28 03:05:15,129 [foster.py] => Task 2, Epoch 22/34 => Loss 1.960, Loss_clf 0.339, Loss_fe 0.466, Loss_kd 0.888, Train_accy 50.78
2022-09-28 03:05:17,062 [foster.py] => Task 2, Epoch 23/34 => Loss 1.923, Loss_clf 0.328, Loss_fe 0.453, Loss_kd 0.878, Train_accy 50.66
2022-09-28 03:05:18,979 [foster.py] => Task 2, Epoch 24/34 => Loss 1.920, Loss_clf 0.320, Loss_fe 0.445, Loss_kd 0.888, Train_accy 51.27
2022-09-28 03:05:20,947 [foster.py] => Task 2, Epoch 25/34 => Loss 1.928, Loss_clf 0.329, Loss_fe 0.450, Loss_kd 0.884, Train_accy 51.15
2022-09-28 03:05:23,776 [foster.py] => Task 2, Epoch 26/34 => Loss 1.911, Loss_clf 0.318, Loss_fe 0.436, Loss_kd 0.890, Train_accy 51.03, Test_accy 65.91
2022-09-28 03:05:25,726 [foster.py] => Task 2, Epoch 27/34 => Loss 1.908, Loss_clf 0.309, Loss_fe 0.447, Loss_kd 0.887, Train_accy 51.99
2022-09-28 03:05:27,710 [foster.py] => Task 2, Epoch 28/34 => Loss 1.943, Loss_clf 0.330, Loss_fe 0.460, Loss_kd 0.887, Train_accy 50.90
2022-09-28 03:05:29,686 [foster.py] => Task 2, Epoch 29/34 => Loss 1.886, Loss_clf 0.307, Loss_fe 0.431, Loss_kd 0.883, Train_accy 49.22
2022-09-28 03:05:31,659 [foster.py] => Task 2, Epoch 30/34 => Loss 1.908, Loss_clf 0.313, Loss_fe 0.435, Loss_kd 0.892, Train_accy 49.58
2022-09-28 03:05:34,527 [foster.py] => Task 2, Epoch 31/34 => Loss 1.920, Loss_clf 0.326, Loss_fe 0.447, Loss_kd 0.883, Train_accy 48.25, Test_accy 66.23
2022-09-28 03:05:36,454 [foster.py] => Task 2, Epoch 32/34 => Loss 1.893, Loss_clf 0.311, Loss_fe 0.437, Loss_kd 0.880, Train_accy 51.39
2022-09-28 03:05:38,391 [foster.py] => Task 2, Epoch 33/34 => Loss 1.927, Loss_clf 0.323, Loss_fe 0.450, Loss_kd 0.887, Train_accy 49.82
2022-09-28 03:05:40,367 [foster.py] => Task 2, Epoch 34/34 => Loss 1.891, Loss_clf 0.308, Loss_fe 0.433, Loss_kd 0.884, Train_accy 50.30
2022-09-28 03:05:40,367 [foster.py] => do not weight align teacher!
2022-09-28 03:05:40,368 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 03:05:43,470 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.786,  Train_accy 16.77, Test_accy 49.35
2022-09-28 03:05:45,540 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.690,  Train_accy 17.37
2022-09-28 03:05:47,571 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.627,  Train_accy 17.73
2022-09-28 03:05:49,611 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.593,  Train_accy 17.97
2022-09-28 03:05:51,631 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.583,  Train_accy 18.46
2022-09-28 03:05:54,414 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.562,  Train_accy 18.82, Test_accy 55.19
2022-09-28 03:05:56,468 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.558,  Train_accy 19.30
2022-09-28 03:05:58,570 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.528,  Train_accy 19.30
2022-09-28 03:06:00,600 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.538,  Train_accy 19.78
2022-09-28 03:06:02,665 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.550,  Train_accy 20.14
2022-09-28 03:06:05,527 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.532,  Train_accy 20.99, Test_accy 56.49
2022-09-28 03:06:07,577 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.532,  Train_accy 21.35
2022-09-28 03:06:09,692 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.526,  Train_accy 21.23
2022-09-28 03:06:11,721 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.525,  Train_accy 21.83
2022-09-28 03:06:13,812 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.523,  Train_accy 21.35
2022-09-28 03:06:16,541 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.521,  Train_accy 22.20, Test_accy 57.79
2022-09-28 03:06:18,612 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.520,  Train_accy 22.68
2022-09-28 03:06:20,683 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.518,  Train_accy 21.23
2022-09-28 03:06:22,726 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.523,  Train_accy 22.20
2022-09-28 03:06:24,768 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.508,  Train_accy 21.23
2022-09-28 03:06:27,549 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.507,  Train_accy 21.47, Test_accy 57.79
2022-09-28 03:06:29,633 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.514,  Train_accy 22.44
2022-09-28 03:06:31,651 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.525,  Train_accy 22.80
2022-09-28 03:06:33,682 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.511,  Train_accy 23.04
2022-09-28 03:06:35,734 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.502,  Train_accy 23.04
2022-09-28 03:06:38,513 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.518,  Train_accy 22.80, Test_accy 57.79
2022-09-28 03:06:38,514 [foster.py] => do not weight align student!
2022-09-28 03:06:39,248 [foster.py] => darknet eval: 
2022-09-28 03:06:39,248 [foster.py] => CNN top1 curve: 57.79
2022-09-28 03:06:39,249 [foster.py] => CNN top5 curve: 94.81
2022-09-28 03:06:39,249 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 03:06:46,618 [foster.py] => Exemplar size: 260
2022-09-28 03:06:46,618 [trainer.py] => CNN: {'total': 66.23, 'old': 71.08, 'new': 45.76, 'base': 80.45, 'compound': 46.51}
2022-09-28 03:06:46,618 [trainer.py] => CNN top1 curve: [87.71, 76.31, 66.23]
2022-09-28 03:06:46,618 [trainer.py] => CNN base curve: [87.71, 85.47, 80.45]
2022-09-28 03:06:46,618 [trainer.py] => CNN old curve: [87.71, 85.47, 71.08]
2022-09-28 03:06:46,618 [trainer.py] => CNN new curve: [0, 52.86, 45.76]
2022-09-28 03:06:46,618 [trainer.py] => CNN compound curve: [0, 52.86, 46.51]
2022-09-28 03:06:46,618 [trainer.py] => NME: {'total': 70.78, 'old': 70.28, 'new': 72.88, 'base': 70.95, 'compound': 70.54}
2022-09-28 03:06:46,618 [trainer.py] => NME top1 curve: [86.59, 79.92, 70.78]
2022-09-28 03:06:46,618 [trainer.py] => NME base curve: [86.59, 82.12, 70.95]
2022-09-28 03:06:46,618 [trainer.py] => NME old curve: [86.59, 82.12, 70.28]
2022-09-28 03:06:46,618 [trainer.py] => NME new curve: [0, 74.29, 72.88]
2022-09-28 03:06:46,618 [trainer.py] => NME compound curve: [0, 74.29, 70.54]
2022-09-28 03:06:46,847 [foster.py] => Learning on 13-16
2022-09-28 03:06:46,847 [foster.py] => All params: 22384301
2022-09-28 03:06:46,847 [foster.py] => Trainable params: 11201120
2022-09-28 03:06:46,867 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 03:06:49,749 [foster.py] => Task 3, Epoch 1/34 => Loss 6.035, Loss_clf 2.077, Loss_fe 2.359, Loss_kd 1.299, Train_accy 37.50, Test_accy 44.41
2022-09-28 03:06:51,708 [foster.py] => Task 3, Epoch 2/34 => Loss 4.445, Loss_clf 1.111, Loss_fe 1.748, Loss_kd 1.288, Train_accy 37.95
2022-09-28 03:06:53,610 [foster.py] => Task 3, Epoch 3/34 => Loss 4.104, Loss_clf 0.986, Loss_fe 1.549, Loss_kd 1.275, Train_accy 40.57
2022-09-28 03:06:55,501 [foster.py] => Task 3, Epoch 4/34 => Loss 3.927, Loss_clf 0.927, Loss_fe 1.424, Loss_kd 1.281, Train_accy 40.11
2022-09-28 03:06:57,421 [foster.py] => Task 3, Epoch 5/34 => Loss 3.765, Loss_clf 0.879, Loss_fe 1.318, Loss_kd 1.273, Train_accy 40.57
2022-09-28 03:07:00,220 [foster.py] => Task 3, Epoch 6/34 => Loss 3.681, Loss_clf 0.860, Loss_fe 1.245, Loss_kd 1.280, Train_accy 39.77, Test_accy 58.51
2022-09-28 03:07:02,157 [foster.py] => Task 3, Epoch 7/34 => Loss 3.596, Loss_clf 0.827, Loss_fe 1.189, Loss_kd 1.284, Train_accy 41.59
2022-09-28 03:07:04,082 [foster.py] => Task 3, Epoch 8/34 => Loss 3.511, Loss_clf 0.832, Loss_fe 1.121, Loss_kd 1.266, Train_accy 41.93
2022-09-28 03:07:06,022 [foster.py] => Task 3, Epoch 9/34 => Loss 3.463, Loss_clf 0.815, Loss_fe 1.076, Loss_kd 1.277, Train_accy 41.02
2022-09-28 03:07:07,921 [foster.py] => Task 3, Epoch 10/34 => Loss 3.398, Loss_clf 0.783, Loss_fe 1.034, Loss_kd 1.285, Train_accy 41.02
2022-09-28 03:07:10,861 [foster.py] => Task 3, Epoch 11/34 => Loss 3.365, Loss_clf 0.786, Loss_fe 1.006, Loss_kd 1.278, Train_accy 44.89, Test_accy 58.51
2022-09-28 03:07:12,784 [foster.py] => Task 3, Epoch 12/34 => Loss 3.295, Loss_clf 0.760, Loss_fe 0.959, Loss_kd 1.281, Train_accy 43.41
2022-09-28 03:07:14,740 [foster.py] => Task 3, Epoch 13/34 => Loss 3.249, Loss_clf 0.735, Loss_fe 0.928, Loss_kd 1.288, Train_accy 43.86
2022-09-28 03:07:16,712 [foster.py] => Task 3, Epoch 14/34 => Loss 3.253, Loss_clf 0.742, Loss_fe 0.929, Loss_kd 1.285, Train_accy 43.41
2022-09-28 03:07:18,653 [foster.py] => Task 3, Epoch 15/34 => Loss 3.214, Loss_clf 0.729, Loss_fe 0.907, Loss_kd 1.282, Train_accy 46.25
2022-09-28 03:07:21,501 [foster.py] => Task 3, Epoch 16/34 => Loss 3.125, Loss_clf 0.700, Loss_fe 0.861, Loss_kd 1.271, Train_accy 45.11, Test_accy 58.51
2022-09-28 03:07:23,413 [foster.py] => Task 3, Epoch 17/34 => Loss 3.097, Loss_clf 0.667, Loss_fe 0.835, Loss_kd 1.296, Train_accy 48.52
2022-09-28 03:07:25,356 [foster.py] => Task 3, Epoch 18/34 => Loss 3.068, Loss_clf 0.660, Loss_fe 0.833, Loss_kd 1.280, Train_accy 45.00
2022-09-28 03:07:27,277 [foster.py] => Task 3, Epoch 19/34 => Loss 3.053, Loss_clf 0.663, Loss_fe 0.814, Loss_kd 1.280, Train_accy 45.80
2022-09-28 03:07:29,177 [foster.py] => Task 3, Epoch 20/34 => Loss 3.059, Loss_clf 0.669, Loss_fe 0.808, Loss_kd 1.285, Train_accy 47.95
2022-09-28 03:07:31,962 [foster.py] => Task 3, Epoch 21/34 => Loss 3.014, Loss_clf 0.642, Loss_fe 0.782, Loss_kd 1.292, Train_accy 48.64, Test_accy 58.78
2022-09-28 03:07:33,907 [foster.py] => Task 3, Epoch 22/34 => Loss 2.995, Loss_clf 0.640, Loss_fe 0.776, Loss_kd 1.283, Train_accy 47.39
2022-09-28 03:07:35,812 [foster.py] => Task 3, Epoch 23/34 => Loss 3.031, Loss_clf 0.648, Loss_fe 0.797, Loss_kd 1.289, Train_accy 48.98
2022-09-28 03:07:37,695 [foster.py] => Task 3, Epoch 24/34 => Loss 2.967, Loss_clf 0.623, Loss_fe 0.767, Loss_kd 1.281, Train_accy 49.32
2022-09-28 03:07:39,638 [foster.py] => Task 3, Epoch 25/34 => Loss 2.986, Loss_clf 0.641, Loss_fe 0.763, Loss_kd 1.285, Train_accy 47.95
2022-09-28 03:07:42,467 [foster.py] => Task 3, Epoch 26/34 => Loss 2.961, Loss_clf 0.625, Loss_fe 0.758, Loss_kd 1.282, Train_accy 49.43, Test_accy 57.71
2022-09-28 03:07:44,419 [foster.py] => Task 3, Epoch 27/34 => Loss 2.961, Loss_clf 0.621, Loss_fe 0.755, Loss_kd 1.288, Train_accy 49.89
2022-09-28 03:07:46,359 [foster.py] => Task 3, Epoch 28/34 => Loss 2.930, Loss_clf 0.608, Loss_fe 0.737, Loss_kd 1.288, Train_accy 50.11
2022-09-28 03:07:48,241 [foster.py] => Task 3, Epoch 29/34 => Loss 2.953, Loss_clf 0.617, Loss_fe 0.756, Loss_kd 1.283, Train_accy 48.18
2022-09-28 03:07:50,203 [foster.py] => Task 3, Epoch 30/34 => Loss 2.933, Loss_clf 0.616, Loss_fe 0.741, Loss_kd 1.281, Train_accy 47.39
2022-09-28 03:07:53,039 [foster.py] => Task 3, Epoch 31/34 => Loss 2.911, Loss_clf 0.599, Loss_fe 0.736, Loss_kd 1.281, Train_accy 49.77, Test_accy 58.51
2022-09-28 03:07:54,940 [foster.py] => Task 3, Epoch 32/34 => Loss 2.909, Loss_clf 0.597, Loss_fe 0.737, Loss_kd 1.280, Train_accy 48.30
2022-09-28 03:07:56,874 [foster.py] => Task 3, Epoch 33/34 => Loss 2.935, Loss_clf 0.611, Loss_fe 0.742, Loss_kd 1.285, Train_accy 50.34
2022-09-28 03:07:58,793 [foster.py] => Task 3, Epoch 34/34 => Loss 2.909, Loss_clf 0.610, Loss_fe 0.733, Loss_kd 1.273, Train_accy 50.00
2022-09-28 03:07:58,793 [foster.py] => do not weight align teacher!
2022-09-28 03:07:58,793 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 03:08:01,915 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.159,  Train_accy 17.95, Test_accy 46.01
2022-09-28 03:08:04,074 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.051,  Train_accy 19.20
2022-09-28 03:08:06,206 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 1.994,  Train_accy 19.43
2022-09-28 03:08:08,350 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 1.980,  Train_accy 19.55
2022-09-28 03:08:10,520 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.966,  Train_accy 19.66
2022-09-28 03:08:13,436 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.953,  Train_accy 20.11, Test_accy 48.67
2022-09-28 03:08:15,643 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.949,  Train_accy 20.11
2022-09-28 03:08:17,808 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.937,  Train_accy 20.34
2022-09-28 03:08:19,930 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.939,  Train_accy 20.68
2022-09-28 03:08:22,084 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.939,  Train_accy 20.34
2022-09-28 03:08:24,992 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.933,  Train_accy 20.23, Test_accy 48.40
2022-09-28 03:08:27,130 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.925,  Train_accy 20.91
2022-09-28 03:08:29,252 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.929,  Train_accy 20.00
2022-09-28 03:08:31,375 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.922,  Train_accy 21.25
2022-09-28 03:08:33,558 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.927,  Train_accy 20.91
2022-09-28 03:08:36,455 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.917,  Train_accy 21.36, Test_accy 49.73
2022-09-28 03:08:38,608 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.926,  Train_accy 20.11
2022-09-28 03:08:40,711 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.919,  Train_accy 21.93
2022-09-28 03:08:42,842 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.929,  Train_accy 20.80
2022-09-28 03:08:44,976 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.924,  Train_accy 21.59
2022-09-28 03:08:47,977 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.914,  Train_accy 21.02, Test_accy 50.80
2022-09-28 03:08:50,145 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.917,  Train_accy 20.91
2022-09-28 03:08:52,296 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.931,  Train_accy 21.25
2022-09-28 03:08:54,399 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.924,  Train_accy 21.36
2022-09-28 03:08:56,558 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.921,  Train_accy 21.36
2022-09-28 03:08:59,522 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.929,  Train_accy 20.91, Test_accy 49.73
2022-09-28 03:08:59,523 [foster.py] => do not weight align student!
2022-09-28 03:09:00,276 [foster.py] => darknet eval: 
2022-09-28 03:09:00,276 [foster.py] => CNN top1 curve: 49.73
2022-09-28 03:09:00,276 [foster.py] => CNN top5 curve: 90.96
2022-09-28 03:09:00,277 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 03:09:08,859 [foster.py] => Exemplar size: 320
2022-09-28 03:09:08,859 [trainer.py] => CNN: {'total': 58.51, 'old': 66.23, 'new': 23.53, 'base': 77.65, 'compound': 41.12}
2022-09-28 03:09:08,859 [trainer.py] => CNN top1 curve: [87.71, 76.31, 66.23, 58.51]
2022-09-28 03:09:08,859 [trainer.py] => CNN base curve: [87.71, 85.47, 80.45, 77.65]
2022-09-28 03:09:08,860 [trainer.py] => CNN old curve: [87.71, 85.47, 71.08, 66.23]
2022-09-28 03:09:08,860 [trainer.py] => CNN new curve: [0, 52.86, 45.76, 23.53]
2022-09-28 03:09:08,860 [trainer.py] => CNN compound curve: [0, 52.86, 46.51, 41.12]
2022-09-28 03:09:08,860 [trainer.py] => NME: {'total': 63.56, 'old': 67.86, 'new': 44.12, 'base': 67.6, 'compound': 59.9}
2022-09-28 03:09:08,860 [trainer.py] => NME top1 curve: [86.59, 79.92, 70.78, 63.56]
2022-09-28 03:09:08,860 [trainer.py] => NME base curve: [86.59, 82.12, 70.95, 67.6]
2022-09-28 03:09:08,860 [trainer.py] => NME old curve: [86.59, 82.12, 70.28, 67.86]
2022-09-28 03:09:08,860 [trainer.py] => NME new curve: [0, 74.29, 72.88, 44.12]
2022-09-28 03:09:08,860 [trainer.py] => NME compound curve: [0, 74.29, 70.54, 59.9]
2022-09-28 03:09:09,091 [foster.py] => Learning on 16-19
2022-09-28 03:09:09,091 [foster.py] => All params: 22390454
2022-09-28 03:09:09,092 [foster.py] => Trainable params: 11205734
2022-09-28 03:09:09,112 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 03:09:12,027 [foster.py] => Task 4, Epoch 1/34 => Loss 6.373, Loss_clf 1.937, Loss_fe 2.490, Loss_kd 1.639, Train_accy 39.85, Test_accy 40.42
2022-09-28 03:09:14,063 [foster.py] => Task 4, Epoch 2/34 => Loss 4.812, Loss_clf 1.090, Loss_fe 1.772, Loss_kd 1.643, Train_accy 37.33
2022-09-28 03:09:16,084 [foster.py] => Task 4, Epoch 3/34 => Loss 4.492, Loss_clf 0.974, Loss_fe 1.578, Loss_kd 1.634, Train_accy 40.59
2022-09-28 03:09:18,091 [foster.py] => Task 4, Epoch 4/34 => Loss 4.365, Loss_clf 0.955, Loss_fe 1.469, Loss_kd 1.634, Train_accy 38.38
2022-09-28 03:09:20,132 [foster.py] => Task 4, Epoch 5/34 => Loss 4.225, Loss_clf 0.916, Loss_fe 1.367, Loss_kd 1.635, Train_accy 38.28
2022-09-28 03:09:23,079 [foster.py] => Task 4, Epoch 6/34 => Loss 4.148, Loss_clf 0.901, Loss_fe 1.302, Loss_kd 1.638, Train_accy 40.69, Test_accy 48.27
2022-09-28 03:09:25,102 [foster.py] => Task 4, Epoch 7/34 => Loss 4.049, Loss_clf 0.871, Loss_fe 1.234, Loss_kd 1.637, Train_accy 41.22
2022-09-28 03:09:27,116 [foster.py] => Task 4, Epoch 8/34 => Loss 3.971, Loss_clf 0.844, Loss_fe 1.182, Loss_kd 1.637, Train_accy 42.27
2022-09-28 03:09:29,151 [foster.py] => Task 4, Epoch 9/34 => Loss 3.905, Loss_clf 0.838, Loss_fe 1.131, Loss_kd 1.631, Train_accy 42.48
2022-09-28 03:09:31,153 [foster.py] => Task 4, Epoch 10/34 => Loss 3.873, Loss_clf 0.832, Loss_fe 1.102, Loss_kd 1.632, Train_accy 41.43
2022-09-28 03:09:34,124 [foster.py] => Task 4, Epoch 11/34 => Loss 3.813, Loss_clf 0.817, Loss_fe 1.059, Loss_kd 1.631, Train_accy 42.59, Test_accy 49.65
2022-09-28 03:09:36,171 [foster.py] => Task 4, Epoch 12/34 => Loss 3.765, Loss_clf 0.797, Loss_fe 1.027, Loss_kd 1.634, Train_accy 42.90
2022-09-28 03:09:38,216 [foster.py] => Task 4, Epoch 13/34 => Loss 3.721, Loss_clf 0.780, Loss_fe 0.994, Loss_kd 1.639, Train_accy 43.11
2022-09-28 03:09:40,255 [foster.py] => Task 4, Epoch 14/34 => Loss 3.684, Loss_clf 0.767, Loss_fe 0.967, Loss_kd 1.642, Train_accy 42.48
2022-09-28 03:09:42,286 [foster.py] => Task 4, Epoch 15/34 => Loss 3.665, Loss_clf 0.762, Loss_fe 0.954, Loss_kd 1.641, Train_accy 41.54
2022-09-28 03:09:45,236 [foster.py] => Task 4, Epoch 16/34 => Loss 3.645, Loss_clf 0.758, Loss_fe 0.934, Loss_kd 1.645, Train_accy 44.37, Test_accy 50.12
2022-09-28 03:09:47,281 [foster.py] => Task 4, Epoch 17/34 => Loss 3.619, Loss_clf 0.757, Loss_fe 0.907, Loss_kd 1.646, Train_accy 43.74
2022-09-28 03:09:49,286 [foster.py] => Task 4, Epoch 18/34 => Loss 3.600, Loss_clf 0.732, Loss_fe 0.911, Loss_kd 1.648, Train_accy 45.64
2022-09-28 03:09:51,315 [foster.py] => Task 4, Epoch 19/34 => Loss 3.564, Loss_clf 0.732, Loss_fe 0.893, Loss_kd 1.632, Train_accy 43.01
2022-09-28 03:09:53,352 [foster.py] => Task 4, Epoch 20/34 => Loss 3.564, Loss_clf 0.729, Loss_fe 0.886, Loss_kd 1.641, Train_accy 46.69
2022-09-28 03:09:56,267 [foster.py] => Task 4, Epoch 21/34 => Loss 3.535, Loss_clf 0.718, Loss_fe 0.868, Loss_kd 1.642, Train_accy 42.90, Test_accy 51.04
2022-09-28 03:09:58,254 [foster.py] => Task 4, Epoch 22/34 => Loss 3.512, Loss_clf 0.703, Loss_fe 0.855, Loss_kd 1.646, Train_accy 44.58
2022-09-28 03:10:00,250 [foster.py] => Task 4, Epoch 23/34 => Loss 3.501, Loss_clf 0.708, Loss_fe 0.839, Loss_kd 1.645, Train_accy 45.85
2022-09-28 03:10:02,318 [foster.py] => Task 4, Epoch 24/34 => Loss 3.470, Loss_clf 0.698, Loss_fe 0.827, Loss_kd 1.637, Train_accy 45.22
2022-09-28 03:10:04,360 [foster.py] => Task 4, Epoch 25/34 => Loss 3.442, Loss_clf 0.681, Loss_fe 0.815, Loss_kd 1.639, Train_accy 46.06
2022-09-28 03:10:07,306 [foster.py] => Task 4, Epoch 26/34 => Loss 3.477, Loss_clf 0.704, Loss_fe 0.833, Loss_kd 1.634, Train_accy 46.16, Test_accy 50.58
2022-09-28 03:10:09,343 [foster.py] => Task 4, Epoch 27/34 => Loss 3.483, Loss_clf 0.702, Loss_fe 0.834, Loss_kd 1.639, Train_accy 45.22
2022-09-28 03:10:11,395 [foster.py] => Task 4, Epoch 28/34 => Loss 3.466, Loss_clf 0.691, Loss_fe 0.826, Loss_kd 1.642, Train_accy 46.06
2022-09-28 03:10:13,420 [foster.py] => Task 4, Epoch 29/34 => Loss 3.463, Loss_clf 0.692, Loss_fe 0.827, Loss_kd 1.637, Train_accy 45.53
2022-09-28 03:10:15,452 [foster.py] => Task 4, Epoch 30/34 => Loss 3.490, Loss_clf 0.692, Loss_fe 0.839, Loss_kd 1.649, Train_accy 45.32
2022-09-28 03:10:18,422 [foster.py] => Task 4, Epoch 31/34 => Loss 3.467, Loss_clf 0.699, Loss_fe 0.828, Loss_kd 1.634, Train_accy 45.85, Test_accy 50.81
2022-09-28 03:10:20,459 [foster.py] => Task 4, Epoch 32/34 => Loss 3.409, Loss_clf 0.659, Loss_fe 0.799, Loss_kd 1.642, Train_accy 45.11
2022-09-28 03:10:22,471 [foster.py] => Task 4, Epoch 33/34 => Loss 3.456, Loss_clf 0.689, Loss_fe 0.821, Loss_kd 1.639, Train_accy 46.16
2022-09-28 03:10:24,514 [foster.py] => Task 4, Epoch 34/34 => Loss 3.443, Loss_clf 0.674, Loss_fe 0.827, Loss_kd 1.635, Train_accy 45.53
2022-09-28 03:10:24,515 [foster.py] => do not weight align teacher!
2022-09-28 03:10:24,515 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 03:10:27,866 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.307,  Train_accy 19.24, Test_accy 44.57
2022-09-28 03:10:30,168 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.253,  Train_accy 19.35
2022-09-28 03:10:32,468 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.227,  Train_accy 20.82
2022-09-28 03:10:34,704 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.217,  Train_accy 20.29
2022-09-28 03:10:36,987 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.205,  Train_accy 19.98
2022-09-28 03:10:40,036 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.206,  Train_accy 20.08, Test_accy 44.80
2022-09-28 03:10:42,272 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.199,  Train_accy 20.40
2022-09-28 03:10:44,507 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.194,  Train_accy 19.87
2022-09-28 03:10:46,811 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.198,  Train_accy 20.93
2022-09-28 03:10:49,102 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.192,  Train_accy 20.72
2022-09-28 03:10:52,191 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.179,  Train_accy 20.93, Test_accy 46.65
2022-09-28 03:10:54,441 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.187,  Train_accy 20.40
2022-09-28 03:10:56,743 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.188,  Train_accy 21.87
2022-09-28 03:10:59,003 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.189,  Train_accy 21.56
2022-09-28 03:11:01,297 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.179,  Train_accy 21.56
2022-09-28 03:11:04,351 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.178,  Train_accy 20.82, Test_accy 46.88
2022-09-28 03:11:06,590 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.177,  Train_accy 21.03
2022-09-28 03:11:08,874 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.176,  Train_accy 21.24
2022-09-28 03:11:11,153 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.178,  Train_accy 21.14
2022-09-28 03:11:13,491 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.176,  Train_accy 20.82
2022-09-28 03:11:16,536 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.175,  Train_accy 21.35, Test_accy 46.42
2022-09-28 03:11:18,826 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.171,  Train_accy 21.24
2022-09-28 03:11:21,114 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.175,  Train_accy 20.93
2022-09-28 03:11:23,401 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.173,  Train_accy 21.66
2022-09-28 03:11:25,675 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.172,  Train_accy 20.72
2022-09-28 03:11:28,708 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.173,  Train_accy 20.93, Test_accy 47.11
2022-09-28 03:11:28,709 [foster.py] => do not weight align student!
2022-09-28 03:11:29,513 [foster.py] => darknet eval: 
2022-09-28 03:11:29,513 [foster.py] => CNN top1 curve: 47.11
2022-09-28 03:11:29,513 [foster.py] => CNN top5 curve: 84.3
2022-09-28 03:11:29,514 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 03:11:39,092 [foster.py] => Exemplar size: 380
2022-09-28 03:11:39,092 [trainer.py] => CNN: {'total': 50.81, 'old': 55.05, 'new': 22.81, 'base': 72.07, 'compound': 35.83}
2022-09-28 03:11:39,092 [trainer.py] => CNN top1 curve: [87.71, 76.31, 66.23, 58.51, 50.81]
2022-09-28 03:11:39,092 [trainer.py] => CNN base curve: [87.71, 85.47, 80.45, 77.65, 72.07]
2022-09-28 03:11:39,092 [trainer.py] => CNN old curve: [87.71, 85.47, 71.08, 66.23, 55.05]
2022-09-28 03:11:39,092 [trainer.py] => CNN new curve: [0, 52.86, 45.76, 23.53, 22.81]
2022-09-28 03:11:39,093 [trainer.py] => CNN compound curve: [0, 52.86, 46.51, 41.12, 35.83]
2022-09-28 03:11:39,093 [trainer.py] => NME: {'total': 56.81, 'old': 58.24, 'new': 47.37, 'base': 68.16, 'compound': 48.82}
2022-09-28 03:11:39,093 [trainer.py] => NME top1 curve: [86.59, 79.92, 70.78, 63.56, 56.81]
2022-09-28 03:11:39,093 [trainer.py] => NME base curve: [86.59, 82.12, 70.95, 67.6, 68.16]
2022-09-28 03:11:39,093 [trainer.py] => NME old curve: [86.59, 82.12, 70.28, 67.86, 58.24]
2022-09-28 03:11:39,093 [trainer.py] => NME new curve: [0, 74.29, 72.88, 44.12, 47.37]
2022-09-28 03:11:39,093 [trainer.py] => NME compound curve: [0, 74.29, 70.54, 59.9, 48.82]
2022-09-28 03:11:39,320 [foster.py] => Learning on 19-22
2022-09-28 03:11:39,321 [foster.py] => All params: 22396607
2022-09-28 03:11:39,321 [foster.py] => Trainable params: 11210348
2022-09-28 03:11:39,341 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 03:11:42,427 [foster.py] => Task 5, Epoch 1/34 => Loss 6.406, Loss_clf 1.860, Loss_fe 2.387, Loss_kd 1.864, Train_accy 36.55, Test_accy 44.16
2022-09-28 03:11:44,570 [foster.py] => Task 5, Epoch 2/34 => Loss 5.107, Loss_clf 1.103, Loss_fe 1.838, Loss_kd 1.871, Train_accy 33.63
2022-09-28 03:11:46,669 [foster.py] => Task 5, Epoch 3/34 => Loss 4.844, Loss_clf 1.009, Loss_fe 1.683, Loss_kd 1.859, Train_accy 38.65
2022-09-28 03:11:48,745 [foster.py] => Task 5, Epoch 4/34 => Loss 4.657, Loss_clf 0.966, Loss_fe 1.533, Loss_kd 1.864, Train_accy 38.15
2022-09-28 03:11:50,814 [foster.py] => Task 5, Epoch 5/34 => Loss 4.603, Loss_clf 0.951, Loss_fe 1.510, Loss_kd 1.850, Train_accy 41.06
2022-09-28 03:11:53,924 [foster.py] => Task 5, Epoch 6/34 => Loss 4.477, Loss_clf 0.946, Loss_fe 1.382, Loss_kd 1.856, Train_accy 40.16, Test_accy 47.13
2022-09-28 03:11:56,029 [foster.py] => Task 5, Epoch 7/34 => Loss 4.400, Loss_clf 0.924, Loss_fe 1.324, Loss_kd 1.858, Train_accy 42.57
2022-09-28 03:11:58,113 [foster.py] => Task 5, Epoch 8/34 => Loss 4.350, Loss_clf 0.895, Loss_fe 1.293, Loss_kd 1.867, Train_accy 41.27
2022-09-28 03:12:00,242 [foster.py] => Task 5, Epoch 9/34 => Loss 4.273, Loss_clf 0.876, Loss_fe 1.232, Loss_kd 1.870, Train_accy 45.68
2022-09-28 03:12:02,341 [foster.py] => Task 5, Epoch 10/34 => Loss 4.219, Loss_clf 0.880, Loss_fe 1.181, Loss_kd 1.864, Train_accy 42.67
2022-09-28 03:12:05,411 [foster.py] => Task 5, Epoch 11/34 => Loss 4.175, Loss_clf 0.867, Loss_fe 1.161, Loss_kd 1.854, Train_accy 45.08, Test_accy 48.71
2022-09-28 03:12:07,526 [foster.py] => Task 5, Epoch 12/34 => Loss 4.149, Loss_clf 0.865, Loss_fe 1.116, Loss_kd 1.872, Train_accy 41.47
2022-09-28 03:12:09,586 [foster.py] => Task 5, Epoch 13/34 => Loss 4.046, Loss_clf 0.815, Loss_fe 1.089, Loss_kd 1.850, Train_accy 45.98
2022-09-28 03:12:11,670 [foster.py] => Task 5, Epoch 14/34 => Loss 4.092, Loss_clf 0.833, Loss_fe 1.098, Loss_kd 1.867, Train_accy 46.49
2022-09-28 03:12:13,776 [foster.py] => Task 5, Epoch 15/34 => Loss 3.992, Loss_clf 0.796, Loss_fe 1.038, Loss_kd 1.864, Train_accy 42.47
2022-09-28 03:12:16,896 [foster.py] => Task 5, Epoch 16/34 => Loss 3.929, Loss_clf 0.783, Loss_fe 0.991, Loss_kd 1.861, Train_accy 49.10, Test_accy 49.90
2022-09-28 03:12:19,023 [foster.py] => Task 5, Epoch 17/34 => Loss 3.988, Loss_clf 0.803, Loss_fe 1.018, Loss_kd 1.871, Train_accy 47.59
2022-09-28 03:12:21,105 [foster.py] => Task 5, Epoch 18/34 => Loss 3.906, Loss_clf 0.767, Loss_fe 0.975, Loss_kd 1.869, Train_accy 46.18
2022-09-28 03:12:23,208 [foster.py] => Task 5, Epoch 19/34 => Loss 3.939, Loss_clf 0.781, Loss_fe 0.986, Loss_kd 1.876, Train_accy 46.18
2022-09-28 03:12:25,272 [foster.py] => Task 5, Epoch 20/34 => Loss 3.899, Loss_clf 0.774, Loss_fe 0.975, Loss_kd 1.857, Train_accy 45.98
2022-09-28 03:12:28,324 [foster.py] => Task 5, Epoch 21/34 => Loss 3.882, Loss_clf 0.752, Loss_fe 0.956, Loss_kd 1.878, Train_accy 45.88, Test_accy 50.10
2022-09-28 03:12:30,389 [foster.py] => Task 5, Epoch 22/34 => Loss 3.848, Loss_clf 0.746, Loss_fe 0.940, Loss_kd 1.868, Train_accy 46.08
2022-09-28 03:12:32,488 [foster.py] => Task 5, Epoch 23/34 => Loss 3.814, Loss_clf 0.742, Loss_fe 0.916, Loss_kd 1.862, Train_accy 48.59
2022-09-28 03:12:34,580 [foster.py] => Task 5, Epoch 24/34 => Loss 3.817, Loss_clf 0.735, Loss_fe 0.916, Loss_kd 1.870, Train_accy 49.80
2022-09-28 03:12:36,708 [foster.py] => Task 5, Epoch 25/34 => Loss 3.808, Loss_clf 0.744, Loss_fe 0.906, Loss_kd 1.864, Train_accy 47.89
2022-09-28 03:12:39,781 [foster.py] => Task 5, Epoch 26/34 => Loss 3.786, Loss_clf 0.723, Loss_fe 0.904, Loss_kd 1.865, Train_accy 48.09, Test_accy 49.70
2022-09-28 03:12:41,903 [foster.py] => Task 5, Epoch 27/34 => Loss 3.813, Loss_clf 0.737, Loss_fe 0.902, Loss_kd 1.876, Train_accy 47.49
2022-09-28 03:12:43,987 [foster.py] => Task 5, Epoch 28/34 => Loss 3.836, Loss_clf 0.738, Loss_fe 0.921, Loss_kd 1.880, Train_accy 47.69
2022-09-28 03:12:46,046 [foster.py] => Task 5, Epoch 29/34 => Loss 3.828, Loss_clf 0.741, Loss_fe 0.912, Loss_kd 1.878, Train_accy 48.19
2022-09-28 03:12:48,165 [foster.py] => Task 5, Epoch 30/34 => Loss 3.845, Loss_clf 0.760, Loss_fe 0.915, Loss_kd 1.874, Train_accy 47.89
2022-09-28 03:12:51,231 [foster.py] => Task 5, Epoch 31/34 => Loss 3.830, Loss_clf 0.735, Loss_fe 0.920, Loss_kd 1.878, Train_accy 48.59, Test_accy 50.10
2022-09-28 03:12:53,368 [foster.py] => Task 5, Epoch 32/34 => Loss 3.807, Loss_clf 0.722, Loss_fe 0.910, Loss_kd 1.878, Train_accy 48.39
2022-09-28 03:12:55,488 [foster.py] => Task 5, Epoch 33/34 => Loss 3.769, Loss_clf 0.731, Loss_fe 0.880, Loss_kd 1.864, Train_accy 47.49
2022-09-28 03:12:57,574 [foster.py] => Task 5, Epoch 34/34 => Loss 3.788, Loss_clf 0.734, Loss_fe 0.899, Loss_kd 1.862, Train_accy 47.39
2022-09-28 03:12:57,575 [foster.py] => do not weight align teacher!
2022-09-28 03:12:57,575 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 03:13:01,000 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.457,  Train_accy 19.88, Test_accy 39.60
2022-09-28 03:13:03,324 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.420,  Train_accy 20.48
2022-09-28 03:13:05,677 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.410,  Train_accy 20.78
2022-09-28 03:13:08,093 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.395,  Train_accy 20.48
2022-09-28 03:13:10,479 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.380,  Train_accy 21.99
2022-09-28 03:13:13,722 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.373,  Train_accy 21.89, Test_accy 41.19
2022-09-28 03:13:16,051 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.360,  Train_accy 21.49
2022-09-28 03:13:18,382 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.355,  Train_accy 20.38
2022-09-28 03:13:20,710 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.349,  Train_accy 21.49
2022-09-28 03:13:23,138 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.355,  Train_accy 20.78
2022-09-28 03:13:26,323 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.350,  Train_accy 21.39, Test_accy 42.18
2022-09-28 03:13:28,697 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.331,  Train_accy 21.89
2022-09-28 03:13:31,086 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.348,  Train_accy 22.39
2022-09-28 03:13:33,480 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.338,  Train_accy 22.29
2022-09-28 03:13:35,863 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.340,  Train_accy 21.49
2022-09-28 03:13:39,103 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.340,  Train_accy 22.09, Test_accy 42.18
2022-09-28 03:13:41,513 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.323,  Train_accy 22.29
2022-09-28 03:13:43,848 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.335,  Train_accy 21.79
2022-09-28 03:13:46,211 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.331,  Train_accy 20.78
2022-09-28 03:13:48,550 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.330,  Train_accy 21.49
2022-09-28 03:13:51,840 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.333,  Train_accy 21.99, Test_accy 41.39
2022-09-28 03:13:54,220 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.336,  Train_accy 22.79
2022-09-28 03:13:56,608 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.311,  Train_accy 21.79
2022-09-28 03:13:58,996 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.328,  Train_accy 22.09
2022-09-28 03:14:01,369 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.333,  Train_accy 21.59
2022-09-28 03:14:04,555 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.322,  Train_accy 21.08, Test_accy 42.57
2022-09-28 03:14:04,556 [foster.py] => do not weight align student!
2022-09-28 03:14:05,432 [foster.py] => darknet eval: 
2022-09-28 03:14:05,432 [foster.py] => CNN top1 curve: 42.57
2022-09-28 03:14:05,432 [foster.py] => CNN top5 curve: 82.57
2022-09-28 03:14:05,433 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 03:14:16,012 [foster.py] => Exemplar size: 440
2022-09-28 03:14:16,012 [trainer.py] => CNN: {'total': 49.9, 'old': 52.66, 'new': 33.33, 'base': 67.6, 'compound': 40.18}
2022-09-28 03:14:16,012 [trainer.py] => CNN top1 curve: [87.71, 76.31, 66.23, 58.51, 50.81, 49.9]
2022-09-28 03:14:16,012 [trainer.py] => CNN base curve: [87.71, 85.47, 80.45, 77.65, 72.07, 67.6]
2022-09-28 03:14:16,012 [trainer.py] => CNN old curve: [87.71, 85.47, 71.08, 66.23, 55.05, 52.66]
2022-09-28 03:14:16,012 [trainer.py] => CNN new curve: [0, 52.86, 45.76, 23.53, 22.81, 33.33]
2022-09-28 03:14:16,012 [trainer.py] => CNN compound curve: [0, 52.86, 46.51, 41.12, 35.83, 40.18]
2022-09-28 03:14:16,012 [trainer.py] => NME: {'total': 54.85, 'old': 55.66, 'new': 50.0, 'base': 64.25, 'compound': 49.69}
2022-09-28 03:14:16,012 [trainer.py] => NME top1 curve: [86.59, 79.92, 70.78, 63.56, 56.81, 54.85]
2022-09-28 03:14:16,012 [trainer.py] => NME base curve: [86.59, 82.12, 70.95, 67.6, 68.16, 64.25]
2022-09-28 03:14:16,012 [trainer.py] => NME old curve: [86.59, 82.12, 70.28, 67.86, 58.24, 55.66]
2022-09-28 03:14:16,012 [trainer.py] => NME new curve: [0, 74.29, 72.88, 44.12, 47.37, 50.0]
2022-09-28 03:14:16,012 [trainer.py] => NME compound curve: [0, 74.29, 70.54, 59.9, 48.82, 49.69]
2022-09-28 03:14:16,013 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 03:14:16,013 [trainer.py] => prefix: cil
2022-09-28 03:14:16,013 [trainer.py] => dataset: CFEE
2022-09-28 03:14:16,013 [trainer.py] => memory_size: 2000
2022-09-28 03:14:16,014 [trainer.py] => memory_per_class: 20
2022-09-28 03:14:16,014 [trainer.py] => fixed_memory: True
2022-09-28 03:14:16,014 [trainer.py] => shuffle: True
2022-09-28 03:14:16,014 [trainer.py] => init_cls: 7
2022-09-28 03:14:16,014 [trainer.py] => increment: 3
2022-09-28 03:14:16,014 [trainer.py] => model_name: foster
2022-09-28 03:14:16,014 [trainer.py] => convnet_type: resnet18
2022-09-28 03:14:16,014 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 03:14:16,014 [trainer.py] => seed: 1993
2022-09-28 03:14:16,014 [trainer.py] => beta1: 0.96
2022-09-28 03:14:16,014 [trainer.py] => beta2: 0.97
2022-09-28 03:14:16,014 [trainer.py] => oofc: ft
2022-09-28 03:14:16,014 [trainer.py] => is_teacher_wa: False
2022-09-28 03:14:16,014 [trainer.py] => is_student_wa: False
2022-09-28 03:14:16,014 [trainer.py] => lambda_okd: 1
2022-09-28 03:14:16,014 [trainer.py] => wa_value: 1
2022-09-28 03:14:16,014 [trainer.py] => init_epochs: 40
2022-09-28 03:14:16,014 [trainer.py] => init_lr: 0.01
2022-09-28 03:14:16,014 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 03:14:16,014 [trainer.py] => boosting_epochs: 34
2022-09-28 03:14:16,014 [trainer.py] => compression_epochs: 26
2022-09-28 03:14:16,014 [trainer.py] => lr: 0.001
2022-09-28 03:14:16,014 [trainer.py] => batch_size: 32
2022-09-28 03:14:16,014 [trainer.py] => weight_decay: 0.0005
2022-09-28 03:14:16,014 [trainer.py] => num_workers: 8
2022-09-28 03:14:16,014 [trainer.py] => T: 2
2022-09-28 03:14:16,014 [trainer.py] => nb_runs: 3
2022-09-28 03:14:16,014 [trainer.py] => fold: 10
2022-09-28 03:14:16,015 [data.py] => ========== Fold:4 ==========
2022-09-28 03:14:16,019 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 8, 15, 13, 17, 9, 11, 19, 21, 14, 10, 18, 12, 7, 16]
2022-09-28 03:14:16,236 [foster.py] => Learning on 0-7
2022-09-28 03:14:16,236 [foster.py] => All params: 11183694
2022-09-28 03:14:16,236 [foster.py] => Trainable params: 11183694
2022-09-28 03:14:18,647 [foster.py] => Task 0, Epoch 1/40 => Loss 1.363, Train_accy 48.26
2022-09-28 03:14:21,676 [foster.py] => Task 0, Epoch 2/40 => Loss 0.598, Train_accy 79.36, Test_accy 84.03
2022-09-28 03:14:24,673 [foster.py] => Task 0, Epoch 3/40 => Loss 0.385, Train_accy 86.47, Test_accy 86.11
2022-09-28 03:14:27,659 [foster.py] => Task 0, Epoch 4/40 => Loss 0.277, Train_accy 90.16, Test_accy 87.50
2022-09-28 03:14:30,673 [foster.py] => Task 0, Epoch 5/40 => Loss 0.235, Train_accy 91.80, Test_accy 86.11
2022-09-28 03:14:33,049 [foster.py] => Task 0, Epoch 6/40 => Loss 0.199, Train_accy 93.30
2022-09-28 03:14:36,059 [foster.py] => Task 0, Epoch 7/40 => Loss 0.153, Train_accy 94.94, Test_accy 85.42
2022-09-28 03:14:39,032 [foster.py] => Task 0, Epoch 8/40 => Loss 0.123, Train_accy 95.76, Test_accy 85.42
2022-09-28 03:14:42,038 [foster.py] => Task 0, Epoch 9/40 => Loss 0.104, Train_accy 96.51, Test_accy 87.50
2022-09-28 03:14:45,039 [foster.py] => Task 0, Epoch 10/40 => Loss 0.076, Train_accy 97.68, Test_accy 86.11
2022-09-28 03:14:47,435 [foster.py] => Task 0, Epoch 11/40 => Loss 0.077, Train_accy 97.74
2022-09-28 03:14:50,418 [foster.py] => Task 0, Epoch 12/40 => Loss 0.080, Train_accy 97.61, Test_accy 86.11
2022-09-28 03:14:53,387 [foster.py] => Task 0, Epoch 13/40 => Loss 0.058, Train_accy 98.29, Test_accy 86.81
2022-09-28 03:14:56,347 [foster.py] => Task 0, Epoch 14/40 => Loss 0.050, Train_accy 98.56, Test_accy 84.72
2022-09-28 03:14:59,351 [foster.py] => Task 0, Epoch 15/40 => Loss 0.048, Train_accy 98.77, Test_accy 86.81
2022-09-28 03:15:01,748 [foster.py] => Task 0, Epoch 16/40 => Loss 0.033, Train_accy 99.25
2022-09-28 03:15:04,710 [foster.py] => Task 0, Epoch 17/40 => Loss 0.041, Train_accy 98.77, Test_accy 85.42
2022-09-28 03:15:07,698 [foster.py] => Task 0, Epoch 18/40 => Loss 0.030, Train_accy 99.11, Test_accy 84.72
2022-09-28 03:15:10,656 [foster.py] => Task 0, Epoch 19/40 => Loss 0.032, Train_accy 99.32, Test_accy 85.42
2022-09-28 03:15:13,664 [foster.py] => Task 0, Epoch 20/40 => Loss 0.028, Train_accy 99.25, Test_accy 84.72
2022-09-28 03:15:16,027 [foster.py] => Task 0, Epoch 21/40 => Loss 0.019, Train_accy 99.86
2022-09-28 03:15:19,024 [foster.py] => Task 0, Epoch 22/40 => Loss 0.018, Train_accy 99.93, Test_accy 85.42
2022-09-28 03:15:21,994 [foster.py] => Task 0, Epoch 23/40 => Loss 0.016, Train_accy 99.73, Test_accy 84.72
2022-09-28 03:15:24,972 [foster.py] => Task 0, Epoch 24/40 => Loss 0.015, Train_accy 99.86, Test_accy 85.42
2022-09-28 03:15:27,965 [foster.py] => Task 0, Epoch 25/40 => Loss 0.017, Train_accy 99.73, Test_accy 86.11
2022-09-28 03:15:30,337 [foster.py] => Task 0, Epoch 26/40 => Loss 0.011, Train_accy 99.86
2022-09-28 03:15:33,333 [foster.py] => Task 0, Epoch 27/40 => Loss 0.015, Train_accy 99.79, Test_accy 85.42
2022-09-28 03:15:36,345 [foster.py] => Task 0, Epoch 28/40 => Loss 0.014, Train_accy 99.79, Test_accy 86.11
2022-09-28 03:15:39,339 [foster.py] => Task 0, Epoch 29/40 => Loss 0.017, Train_accy 99.52, Test_accy 86.11
2022-09-28 03:15:42,314 [foster.py] => Task 0, Epoch 30/40 => Loss 0.016, Train_accy 99.66, Test_accy 86.11
2022-09-28 03:15:44,710 [foster.py] => Task 0, Epoch 31/40 => Loss 0.016, Train_accy 99.86
2022-09-28 03:15:47,672 [foster.py] => Task 0, Epoch 32/40 => Loss 0.013, Train_accy 99.86, Test_accy 87.50
2022-09-28 03:15:50,708 [foster.py] => Task 0, Epoch 33/40 => Loss 0.010, Train_accy 99.93, Test_accy 85.42
2022-09-28 03:15:53,666 [foster.py] => Task 0, Epoch 34/40 => Loss 0.017, Train_accy 99.79, Test_accy 86.81
2022-09-28 03:15:56,648 [foster.py] => Task 0, Epoch 35/40 => Loss 0.017, Train_accy 99.59, Test_accy 86.81
2022-09-28 03:15:59,004 [foster.py] => Task 0, Epoch 36/40 => Loss 0.013, Train_accy 99.79
2022-09-28 03:16:01,994 [foster.py] => Task 0, Epoch 37/40 => Loss 0.014, Train_accy 99.79, Test_accy 86.11
2022-09-28 03:16:04,995 [foster.py] => Task 0, Epoch 38/40 => Loss 0.016, Train_accy 99.86, Test_accy 86.11
2022-09-28 03:16:08,007 [foster.py] => Task 0, Epoch 39/40 => Loss 0.014, Train_accy 99.86, Test_accy 85.42
2022-09-28 03:16:11,054 [foster.py] => Task 0, Epoch 40/40 => Loss 0.015, Train_accy 99.86, Test_accy 84.72
2022-09-28 03:16:11,055 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 03:16:17,860 [foster.py] => Exemplar size: 140
2022-09-28 03:16:17,860 [trainer.py] => CNN: {'total': 84.72, 'old': 84.72, 'new': 0, 'base': 84.72, 'compound': 0}
2022-09-28 03:16:17,860 [trainer.py] => CNN top1 curve: [84.72]
2022-09-28 03:16:17,860 [trainer.py] => CNN base curve: [84.72]
2022-09-28 03:16:17,860 [trainer.py] => CNN old curve: [84.72]
2022-09-28 03:16:17,860 [trainer.py] => CNN new curve: [0]
2022-09-28 03:16:17,860 [trainer.py] => CNN compound curve: [0]
2022-09-28 03:16:17,860 [trainer.py] => NME: {'total': 85.42, 'old': 85.42, 'new': 0, 'base': 85.42, 'compound': 0}
2022-09-28 03:16:17,860 [trainer.py] => NME top1 curve: [85.42]
2022-09-28 03:16:17,860 [trainer.py] => NME base curve: [85.42]
2022-09-28 03:16:17,861 [trainer.py] => NME old curve: [85.42]
2022-09-28 03:16:17,861 [trainer.py] => NME new curve: [0]
2022-09-28 03:16:17,861 [trainer.py] => NME compound curve: [0]
2022-09-28 03:16:18,089 [foster.py] => Learning on 7-10
2022-09-28 03:16:18,090 [foster.py] => All params: 22371995
2022-09-28 03:16:18,090 [foster.py] => Trainable params: 11191892
2022-09-28 03:16:18,110 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 03:16:20,562 [foster.py] => Task 1, Epoch 1/34 => Loss 4.366, Loss_clf 1.967, Loss_fe 1.723, Loss_kd 0.473, Train_accy 41.41, Test_accy 73.18
2022-09-28 03:16:22,329 [foster.py] => Task 1, Epoch 2/34 => Loss 2.436, Loss_clf 0.631, Loss_fe 1.128, Loss_kd 0.474, Train_accy 78.16
2022-09-28 03:16:24,067 [foster.py] => Task 1, Epoch 3/34 => Loss 1.992, Loss_clf 0.381, Loss_fe 0.964, Loss_kd 0.452, Train_accy 54.06
2022-09-28 03:16:25,756 [foster.py] => Task 1, Epoch 4/34 => Loss 1.826, Loss_clf 0.332, Loss_fe 0.840, Loss_kd 0.458, Train_accy 51.93
2022-09-28 03:16:27,472 [foster.py] => Task 1, Epoch 5/34 => Loss 1.706, Loss_clf 0.317, Loss_fe 0.743, Loss_kd 0.452, Train_accy 56.06
2022-09-28 03:16:29,931 [foster.py] => Task 1, Epoch 6/34 => Loss 1.626, Loss_clf 0.301, Loss_fe 0.681, Loss_kd 0.451, Train_accy 55.66, Test_accy 68.18
2022-09-28 03:16:31,633 [foster.py] => Task 1, Epoch 7/34 => Loss 1.522, Loss_clf 0.261, Loss_fe 0.613, Loss_kd 0.454, Train_accy 59.25
2022-09-28 03:16:33,327 [foster.py] => Task 1, Epoch 8/34 => Loss 1.495, Loss_clf 0.261, Loss_fe 0.582, Loss_kd 0.457, Train_accy 56.72
2022-09-28 03:16:35,058 [foster.py] => Task 1, Epoch 9/34 => Loss 1.416, Loss_clf 0.239, Loss_fe 0.530, Loss_kd 0.452, Train_accy 60.05
2022-09-28 03:16:36,860 [foster.py] => Task 1, Epoch 10/34 => Loss 1.404, Loss_clf 0.249, Loss_fe 0.513, Loss_kd 0.449, Train_accy 59.25
2022-09-28 03:16:39,273 [foster.py] => Task 1, Epoch 11/34 => Loss 1.396, Loss_clf 0.247, Loss_fe 0.486, Loss_kd 0.464, Train_accy 59.79, Test_accy 68.18
2022-09-28 03:16:40,967 [foster.py] => Task 1, Epoch 12/34 => Loss 1.327, Loss_clf 0.231, Loss_fe 0.452, Loss_kd 0.451, Train_accy 59.39
2022-09-28 03:16:42,700 [foster.py] => Task 1, Epoch 13/34 => Loss 1.324, Loss_clf 0.229, Loss_fe 0.450, Loss_kd 0.452, Train_accy 61.92
2022-09-28 03:16:44,404 [foster.py] => Task 1, Epoch 14/34 => Loss 1.298, Loss_clf 0.222, Loss_fe 0.427, Loss_kd 0.455, Train_accy 62.05
2022-09-28 03:16:46,128 [foster.py] => Task 1, Epoch 15/34 => Loss 1.218, Loss_clf 0.187, Loss_fe 0.379, Loss_kd 0.456, Train_accy 62.85
2022-09-28 03:16:48,572 [foster.py] => Task 1, Epoch 16/34 => Loss 1.263, Loss_clf 0.218, Loss_fe 0.401, Loss_kd 0.451, Train_accy 60.32, Test_accy 70.00
2022-09-28 03:16:50,315 [foster.py] => Task 1, Epoch 17/34 => Loss 1.235, Loss_clf 0.199, Loss_fe 0.388, Loss_kd 0.454, Train_accy 62.58
2022-09-28 03:16:52,035 [foster.py] => Task 1, Epoch 18/34 => Loss 1.198, Loss_clf 0.186, Loss_fe 0.360, Loss_kd 0.456, Train_accy 65.51
2022-09-28 03:16:53,740 [foster.py] => Task 1, Epoch 19/34 => Loss 1.176, Loss_clf 0.184, Loss_fe 0.343, Loss_kd 0.455, Train_accy 64.05
2022-09-28 03:16:55,449 [foster.py] => Task 1, Epoch 20/34 => Loss 1.187, Loss_clf 0.187, Loss_fe 0.353, Loss_kd 0.452, Train_accy 64.05
2022-09-28 03:16:57,954 [foster.py] => Task 1, Epoch 21/34 => Loss 1.156, Loss_clf 0.171, Loss_fe 0.334, Loss_kd 0.456, Train_accy 65.51, Test_accy 70.00
2022-09-28 03:16:59,709 [foster.py] => Task 1, Epoch 22/34 => Loss 1.163, Loss_clf 0.180, Loss_fe 0.343, Loss_kd 0.448, Train_accy 64.71
2022-09-28 03:17:01,463 [foster.py] => Task 1, Epoch 23/34 => Loss 1.145, Loss_clf 0.175, Loss_fe 0.324, Loss_kd 0.452, Train_accy 64.18
2022-09-28 03:17:03,211 [foster.py] => Task 1, Epoch 24/34 => Loss 1.159, Loss_clf 0.176, Loss_fe 0.326, Loss_kd 0.460, Train_accy 66.44
2022-09-28 03:17:04,935 [foster.py] => Task 1, Epoch 25/34 => Loss 1.131, Loss_clf 0.174, Loss_fe 0.322, Loss_kd 0.444, Train_accy 63.52
2022-09-28 03:17:07,389 [foster.py] => Task 1, Epoch 26/34 => Loss 1.127, Loss_clf 0.161, Loss_fe 0.313, Loss_kd 0.457, Train_accy 65.78, Test_accy 70.00
2022-09-28 03:17:09,101 [foster.py] => Task 1, Epoch 27/34 => Loss 1.153, Loss_clf 0.186, Loss_fe 0.327, Loss_kd 0.449, Train_accy 64.58
2022-09-28 03:17:10,845 [foster.py] => Task 1, Epoch 28/34 => Loss 1.118, Loss_clf 0.169, Loss_fe 0.309, Loss_kd 0.448, Train_accy 64.45
2022-09-28 03:17:12,566 [foster.py] => Task 1, Epoch 29/34 => Loss 1.120, Loss_clf 0.167, Loss_fe 0.314, Loss_kd 0.448, Train_accy 63.78
2022-09-28 03:17:14,289 [foster.py] => Task 1, Epoch 30/34 => Loss 1.123, Loss_clf 0.163, Loss_fe 0.307, Loss_kd 0.457, Train_accy 64.98
2022-09-28 03:17:16,740 [foster.py] => Task 1, Epoch 31/34 => Loss 1.137, Loss_clf 0.177, Loss_fe 0.315, Loss_kd 0.452, Train_accy 65.65, Test_accy 69.55
2022-09-28 03:17:18,446 [foster.py] => Task 1, Epoch 32/34 => Loss 1.141, Loss_clf 0.172, Loss_fe 0.322, Loss_kd 0.453, Train_accy 64.31
2022-09-28 03:17:20,144 [foster.py] => Task 1, Epoch 33/34 => Loss 1.174, Loss_clf 0.183, Loss_fe 0.339, Loss_kd 0.456, Train_accy 64.31
2022-09-28 03:17:21,844 [foster.py] => Task 1, Epoch 34/34 => Loss 1.147, Loss_clf 0.173, Loss_fe 0.326, Loss_kd 0.454, Train_accy 63.78
2022-09-28 03:17:21,844 [foster.py] => do not weight align teacher!
2022-09-28 03:17:21,845 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 03:17:24,659 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.597,  Train_accy 18.11, Test_accy 56.36
2022-09-28 03:17:26,582 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.448,  Train_accy 17.98
2022-09-28 03:17:28,518 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.365,  Train_accy 19.04
2022-09-28 03:17:30,459 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.319,  Train_accy 19.44
2022-09-28 03:17:32,385 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.288,  Train_accy 21.57
2022-09-28 03:17:34,971 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.262,  Train_accy 23.44, Test_accy 57.73
2022-09-28 03:17:36,880 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.253,  Train_accy 23.83
2022-09-28 03:17:38,873 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.249,  Train_accy 24.77
2022-09-28 03:17:40,767 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.225,  Train_accy 26.36
2022-09-28 03:17:42,698 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.236,  Train_accy 26.76
2022-09-28 03:17:45,253 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.234,  Train_accy 28.50, Test_accy 60.45
2022-09-28 03:17:47,156 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.222,  Train_accy 29.03
2022-09-28 03:17:49,094 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.202,  Train_accy 30.49
2022-09-28 03:17:51,072 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.220,  Train_accy 30.23
2022-09-28 03:17:53,035 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.204,  Train_accy 28.76
2022-09-28 03:17:55,648 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.195,  Train_accy 29.83, Test_accy 60.45
2022-09-28 03:17:57,581 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.199,  Train_accy 30.89
2022-09-28 03:17:59,518 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.204,  Train_accy 29.43
2022-09-28 03:18:01,454 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.206,  Train_accy 30.76
2022-09-28 03:18:03,352 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.190,  Train_accy 30.63
2022-09-28 03:18:06,013 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.188,  Train_accy 30.63, Test_accy 60.00
2022-09-28 03:18:07,911 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.195,  Train_accy 32.76
2022-09-28 03:18:09,794 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.194,  Train_accy 31.03
2022-09-28 03:18:11,719 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.193,  Train_accy 31.82
2022-09-28 03:18:13,647 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.198,  Train_accy 31.03
2022-09-28 03:18:16,207 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.192,  Train_accy 31.29, Test_accy 60.00
2022-09-28 03:18:16,207 [foster.py] => do not weight align student!
2022-09-28 03:18:16,863 [foster.py] => darknet eval: 
2022-09-28 03:18:16,863 [foster.py] => CNN top1 curve: 60.0
2022-09-28 03:18:16,863 [foster.py] => CNN top5 curve: 98.64
2022-09-28 03:18:16,863 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 03:18:23,077 [foster.py] => Exemplar size: 200
2022-09-28 03:18:23,077 [trainer.py] => CNN: {'total': 70.0, 'old': 81.94, 'new': 47.37, 'base': 81.94, 'compound': 47.37}
2022-09-28 03:18:23,077 [trainer.py] => CNN top1 curve: [84.72, 70.0]
2022-09-28 03:18:23,077 [trainer.py] => CNN base curve: [84.72, 81.94]
2022-09-28 03:18:23,077 [trainer.py] => CNN old curve: [84.72, 81.94]
2022-09-28 03:18:23,077 [trainer.py] => CNN new curve: [0, 47.37]
2022-09-28 03:18:23,077 [trainer.py] => CNN compound curve: [0, 47.37]
2022-09-28 03:18:23,078 [trainer.py] => NME: {'total': 84.09, 'old': 85.42, 'new': 81.58, 'base': 85.42, 'compound': 81.58}
2022-09-28 03:18:23,078 [trainer.py] => NME top1 curve: [85.42, 84.09]
2022-09-28 03:18:23,078 [trainer.py] => NME base curve: [85.42, 85.42]
2022-09-28 03:18:23,078 [trainer.py] => NME old curve: [85.42, 85.42]
2022-09-28 03:18:23,078 [trainer.py] => NME new curve: [0, 81.58]
2022-09-28 03:18:23,078 [trainer.py] => NME compound curve: [0, 81.58]
2022-09-28 03:18:23,308 [foster.py] => Learning on 10-13
2022-09-28 03:18:23,308 [foster.py] => All params: 22378148
2022-09-28 03:18:23,309 [foster.py] => Trainable params: 11196506
2022-09-28 03:18:23,329 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 03:18:25,949 [foster.py] => Task 2, Epoch 1/34 => Loss 5.507, Loss_clf 2.205, Loss_fe 2.130, Loss_kd 0.902, Train_accy 43.53, Test_accy 50.53
2022-09-28 03:18:27,762 [foster.py] => Task 2, Epoch 2/34 => Loss 3.308, Loss_clf 0.783, Loss_fe 1.344, Loss_kd 0.909, Train_accy 61.06
2022-09-28 03:18:29,587 [foster.py] => Task 2, Epoch 3/34 => Loss 2.845, Loss_clf 0.580, Loss_fe 1.116, Loss_kd 0.884, Train_accy 43.77
2022-09-28 03:18:31,428 [foster.py] => Task 2, Epoch 4/34 => Loss 2.655, Loss_clf 0.525, Loss_fe 0.988, Loss_kd 0.879, Train_accy 46.31
2022-09-28 03:18:33,263 [foster.py] => Task 2, Epoch 5/34 => Loss 2.519, Loss_clf 0.468, Loss_fe 0.897, Loss_kd 0.888, Train_accy 48.00
2022-09-28 03:18:35,872 [foster.py] => Task 2, Epoch 6/34 => Loss 2.409, Loss_clf 0.438, Loss_fe 0.827, Loss_kd 0.880, Train_accy 47.52, Test_accy 61.92
2022-09-28 03:18:37,753 [foster.py] => Task 2, Epoch 7/34 => Loss 2.370, Loss_clf 0.437, Loss_fe 0.778, Loss_kd 0.888, Train_accy 51.63
2022-09-28 03:18:39,570 [foster.py] => Task 2, Epoch 8/34 => Loss 2.338, Loss_clf 0.432, Loss_fe 0.743, Loss_kd 0.895, Train_accy 47.64
2022-09-28 03:18:41,404 [foster.py] => Task 2, Epoch 9/34 => Loss 2.267, Loss_clf 0.410, Loss_fe 0.697, Loss_kd 0.892, Train_accy 50.67
2022-09-28 03:18:43,235 [foster.py] => Task 2, Epoch 10/34 => Loss 2.188, Loss_clf 0.394, Loss_fe 0.642, Loss_kd 0.886, Train_accy 48.37
2022-09-28 03:18:45,884 [foster.py] => Task 2, Epoch 11/34 => Loss 2.180, Loss_clf 0.395, Loss_fe 0.633, Loss_kd 0.886, Train_accy 49.33, Test_accy 64.41
2022-09-28 03:18:47,713 [foster.py] => Task 2, Epoch 12/34 => Loss 2.145, Loss_clf 0.386, Loss_fe 0.607, Loss_kd 0.886, Train_accy 53.69
2022-09-28 03:18:49,508 [foster.py] => Task 2, Epoch 13/34 => Loss 2.128, Loss_clf 0.395, Loss_fe 0.589, Loss_kd 0.880, Train_accy 48.85
2022-09-28 03:18:51,404 [foster.py] => Task 2, Epoch 14/34 => Loss 2.077, Loss_clf 0.362, Loss_fe 0.565, Loss_kd 0.884, Train_accy 48.13
2022-09-28 03:18:53,260 [foster.py] => Task 2, Epoch 15/34 => Loss 2.061, Loss_clf 0.365, Loss_fe 0.549, Loss_kd 0.883, Train_accy 52.12
2022-09-28 03:18:55,922 [foster.py] => Task 2, Epoch 16/34 => Loss 2.066, Loss_clf 0.364, Loss_fe 0.548, Loss_kd 0.888, Train_accy 49.33, Test_accy 64.41
2022-09-28 03:18:57,793 [foster.py] => Task 2, Epoch 17/34 => Loss 2.050, Loss_clf 0.367, Loss_fe 0.530, Loss_kd 0.887, Train_accy 53.08
2022-09-28 03:18:59,619 [foster.py] => Task 2, Epoch 18/34 => Loss 1.998, Loss_clf 0.350, Loss_fe 0.499, Loss_kd 0.884, Train_accy 50.30
2022-09-28 03:19:01,431 [foster.py] => Task 2, Epoch 19/34 => Loss 2.049, Loss_clf 0.367, Loss_fe 0.521, Loss_kd 0.893, Train_accy 52.36
2022-09-28 03:19:03,253 [foster.py] => Task 2, Epoch 20/34 => Loss 1.999, Loss_clf 0.349, Loss_fe 0.507, Loss_kd 0.879, Train_accy 51.87
2022-09-28 03:19:05,901 [foster.py] => Task 2, Epoch 21/34 => Loss 1.994, Loss_clf 0.341, Loss_fe 0.491, Loss_kd 0.894, Train_accy 51.27, Test_accy 65.84
2022-09-28 03:19:07,734 [foster.py] => Task 2, Epoch 22/34 => Loss 1.953, Loss_clf 0.322, Loss_fe 0.475, Loss_kd 0.889, Train_accy 52.36
2022-09-28 03:19:09,523 [foster.py] => Task 2, Epoch 23/34 => Loss 1.991, Loss_clf 0.341, Loss_fe 0.491, Loss_kd 0.892, Train_accy 51.03
2022-09-28 03:19:11,379 [foster.py] => Task 2, Epoch 24/34 => Loss 1.962, Loss_clf 0.324, Loss_fe 0.475, Loss_kd 0.895, Train_accy 52.24
2022-09-28 03:19:13,218 [foster.py] => Task 2, Epoch 25/34 => Loss 1.951, Loss_clf 0.328, Loss_fe 0.476, Loss_kd 0.882, Train_accy 50.79
2022-09-28 03:19:15,842 [foster.py] => Task 2, Epoch 26/34 => Loss 1.898, Loss_clf 0.311, Loss_fe 0.444, Loss_kd 0.880, Train_accy 51.03, Test_accy 65.84
2022-09-28 03:19:17,680 [foster.py] => Task 2, Epoch 27/34 => Loss 1.894, Loss_clf 0.314, Loss_fe 0.442, Loss_kd 0.875, Train_accy 48.25
2022-09-28 03:19:19,495 [foster.py] => Task 2, Epoch 28/34 => Loss 1.925, Loss_clf 0.318, Loss_fe 0.459, Loss_kd 0.882, Train_accy 52.12
2022-09-28 03:19:21,356 [foster.py] => Task 2, Epoch 29/34 => Loss 1.938, Loss_clf 0.322, Loss_fe 0.463, Loss_kd 0.888, Train_accy 51.87
2022-09-28 03:19:23,208 [foster.py] => Task 2, Epoch 30/34 => Loss 1.967, Loss_clf 0.337, Loss_fe 0.475, Loss_kd 0.889, Train_accy 50.67
2022-09-28 03:19:25,847 [foster.py] => Task 2, Epoch 31/34 => Loss 1.940, Loss_clf 0.325, Loss_fe 0.456, Loss_kd 0.891, Train_accy 51.39, Test_accy 65.84
2022-09-28 03:19:27,691 [foster.py] => Task 2, Epoch 32/34 => Loss 1.925, Loss_clf 0.321, Loss_fe 0.450, Loss_kd 0.887, Train_accy 51.87
2022-09-28 03:19:29,545 [foster.py] => Task 2, Epoch 33/34 => Loss 1.942, Loss_clf 0.330, Loss_fe 0.457, Loss_kd 0.889, Train_accy 51.27
2022-09-28 03:19:31,402 [foster.py] => Task 2, Epoch 34/34 => Loss 1.930, Loss_clf 0.319, Loss_fe 0.451, Loss_kd 0.893, Train_accy 53.08
2022-09-28 03:19:31,403 [foster.py] => do not weight align teacher!
2022-09-28 03:19:31,403 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 03:19:34,372 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.803,  Train_accy 17.53, Test_accy 45.20
2022-09-28 03:19:36,487 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.701,  Train_accy 17.17
2022-09-28 03:19:38,557 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.647,  Train_accy 18.02
2022-09-28 03:19:40,580 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.617,  Train_accy 18.50
2022-09-28 03:19:42,627 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.595,  Train_accy 18.62
2022-09-28 03:19:45,390 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.589,  Train_accy 18.26, Test_accy 49.82
2022-09-28 03:19:47,474 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.570,  Train_accy 19.47
2022-09-28 03:19:49,496 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.569,  Train_accy 19.23
2022-09-28 03:19:51,533 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.553,  Train_accy 18.98
2022-09-28 03:19:53,552 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.559,  Train_accy 20.44
2022-09-28 03:19:56,360 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.545,  Train_accy 20.92, Test_accy 48.75
2022-09-28 03:19:58,389 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.530,  Train_accy 20.56
2022-09-28 03:20:00,459 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.538,  Train_accy 21.89
2022-09-28 03:20:02,525 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.533,  Train_accy 21.40
2022-09-28 03:20:04,548 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.533,  Train_accy 22.73
2022-09-28 03:20:07,328 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.524,  Train_accy 22.25, Test_accy 50.89
2022-09-28 03:20:09,379 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.533,  Train_accy 22.13
2022-09-28 03:20:11,450 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.545,  Train_accy 22.13
2022-09-28 03:20:13,557 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.529,  Train_accy 23.46
2022-09-28 03:20:15,587 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.512,  Train_accy 22.73
2022-09-28 03:20:18,314 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.533,  Train_accy 21.77, Test_accy 50.89
2022-09-28 03:20:20,344 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.537,  Train_accy 22.25
2022-09-28 03:20:22,393 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.520,  Train_accy 22.49
2022-09-28 03:20:24,461 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.520,  Train_accy 22.37
2022-09-28 03:20:26,525 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.508,  Train_accy 22.85
2022-09-28 03:20:29,269 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.539,  Train_accy 22.97, Test_accy 50.89
2022-09-28 03:20:29,269 [foster.py] => do not weight align student!
2022-09-28 03:20:29,992 [foster.py] => darknet eval: 
2022-09-28 03:20:29,992 [foster.py] => CNN top1 curve: 50.89
2022-09-28 03:20:29,992 [foster.py] => CNN top5 curve: 97.51
2022-09-28 03:20:29,992 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 03:20:37,370 [foster.py] => Exemplar size: 260
2022-09-28 03:20:37,370 [trainer.py] => CNN: {'total': 66.19, 'old': 71.82, 'new': 45.9, 'base': 81.25, 'compound': 50.36}
2022-09-28 03:20:37,370 [trainer.py] => CNN top1 curve: [84.72, 70.0, 66.19]
2022-09-28 03:20:37,370 [trainer.py] => CNN base curve: [84.72, 81.94, 81.25]
2022-09-28 03:20:37,370 [trainer.py] => CNN old curve: [84.72, 81.94, 71.82]
2022-09-28 03:20:37,370 [trainer.py] => CNN new curve: [0, 47.37, 45.9]
2022-09-28 03:20:37,370 [trainer.py] => CNN compound curve: [0, 47.37, 50.36]
2022-09-28 03:20:37,370 [trainer.py] => NME: {'total': 75.09, 'old': 76.36, 'new': 70.49, 'base': 80.56, 'compound': 69.34}
2022-09-28 03:20:37,370 [trainer.py] => NME top1 curve: [85.42, 84.09, 75.09]
2022-09-28 03:20:37,370 [trainer.py] => NME base curve: [85.42, 85.42, 80.56]
2022-09-28 03:20:37,370 [trainer.py] => NME old curve: [85.42, 85.42, 76.36]
2022-09-28 03:20:37,370 [trainer.py] => NME new curve: [0, 81.58, 70.49]
2022-09-28 03:20:37,370 [trainer.py] => NME compound curve: [0, 81.58, 69.34]
2022-09-28 03:20:37,599 [foster.py] => Learning on 13-16
2022-09-28 03:20:37,599 [foster.py] => All params: 22384301
2022-09-28 03:20:37,600 [foster.py] => Trainable params: 11201120
2022-09-28 03:20:37,620 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 03:20:40,386 [foster.py] => Task 3, Epoch 1/34 => Loss 5.778, Loss_clf 1.808, Loss_fe 2.375, Loss_kd 1.296, Train_accy 37.03, Test_accy 44.07
2022-09-28 03:20:42,319 [foster.py] => Task 3, Epoch 2/34 => Loss 4.366, Loss_clf 1.055, Loss_fe 1.718, Loss_kd 1.295, Train_accy 40.46
2022-09-28 03:20:44,248 [foster.py] => Task 3, Epoch 3/34 => Loss 4.037, Loss_clf 0.949, Loss_fe 1.530, Loss_kd 1.266, Train_accy 38.86
2022-09-28 03:20:46,146 [foster.py] => Task 3, Epoch 4/34 => Loss 3.901, Loss_clf 0.908, Loss_fe 1.409, Loss_kd 1.286, Train_accy 41.94
2022-09-28 03:20:48,105 [foster.py] => Task 3, Epoch 5/34 => Loss 3.766, Loss_clf 0.877, Loss_fe 1.307, Loss_kd 1.285, Train_accy 39.54
2022-09-28 03:20:50,909 [foster.py] => Task 3, Epoch 6/34 => Loss 3.687, Loss_clf 0.854, Loss_fe 1.247, Loss_kd 1.289, Train_accy 40.00, Test_accy 55.37
2022-09-28 03:20:52,853 [foster.py] => Task 3, Epoch 7/34 => Loss 3.605, Loss_clf 0.833, Loss_fe 1.183, Loss_kd 1.291, Train_accy 39.09
2022-09-28 03:20:54,791 [foster.py] => Task 3, Epoch 8/34 => Loss 3.534, Loss_clf 0.829, Loss_fe 1.131, Loss_kd 1.279, Train_accy 43.31
2022-09-28 03:20:56,676 [foster.py] => Task 3, Epoch 9/34 => Loss 3.491, Loss_clf 0.816, Loss_fe 1.098, Loss_kd 1.281, Train_accy 40.91
2022-09-28 03:20:58,597 [foster.py] => Task 3, Epoch 10/34 => Loss 3.401, Loss_clf 0.784, Loss_fe 1.031, Loss_kd 1.288, Train_accy 45.14
2022-09-28 03:21:01,355 [foster.py] => Task 3, Epoch 11/34 => Loss 3.374, Loss_clf 0.774, Loss_fe 1.018, Loss_kd 1.285, Train_accy 40.11, Test_accy 56.50
2022-09-28 03:21:03,294 [foster.py] => Task 3, Epoch 12/34 => Loss 3.336, Loss_clf 0.761, Loss_fe 0.984, Loss_kd 1.292, Train_accy 46.17
2022-09-28 03:21:05,177 [foster.py] => Task 3, Epoch 13/34 => Loss 3.275, Loss_clf 0.744, Loss_fe 0.949, Loss_kd 1.285, Train_accy 45.71
2022-09-28 03:21:07,098 [foster.py] => Task 3, Epoch 14/34 => Loss 3.207, Loss_clf 0.708, Loss_fe 0.910, Loss_kd 1.291, Train_accy 44.00
2022-09-28 03:21:09,004 [foster.py] => Task 3, Epoch 15/34 => Loss 3.203, Loss_clf 0.720, Loss_fe 0.897, Loss_kd 1.289, Train_accy 44.11
2022-09-28 03:21:11,763 [foster.py] => Task 3, Epoch 16/34 => Loss 3.201, Loss_clf 0.704, Loss_fe 0.905, Loss_kd 1.294, Train_accy 45.71, Test_accy 56.21
2022-09-28 03:21:13,673 [foster.py] => Task 3, Epoch 17/34 => Loss 3.121, Loss_clf 0.684, Loss_fe 0.846, Loss_kd 1.294, Train_accy 45.49
2022-09-28 03:21:15,580 [foster.py] => Task 3, Epoch 18/34 => Loss 3.120, Loss_clf 0.684, Loss_fe 0.844, Loss_kd 1.294, Train_accy 45.94
2022-09-28 03:21:17,457 [foster.py] => Task 3, Epoch 19/34 => Loss 3.096, Loss_clf 0.677, Loss_fe 0.836, Loss_kd 1.287, Train_accy 44.91
2022-09-28 03:21:19,384 [foster.py] => Task 3, Epoch 20/34 => Loss 3.093, Loss_clf 0.672, Loss_fe 0.829, Loss_kd 1.294, Train_accy 46.74
2022-09-28 03:21:22,187 [foster.py] => Task 3, Epoch 21/34 => Loss 3.062, Loss_clf 0.668, Loss_fe 0.811, Loss_kd 1.286, Train_accy 48.00, Test_accy 56.21
2022-09-28 03:21:24,069 [foster.py] => Task 3, Epoch 22/34 => Loss 3.064, Loss_clf 0.666, Loss_fe 0.809, Loss_kd 1.291, Train_accy 47.43
2022-09-28 03:21:25,956 [foster.py] => Task 3, Epoch 23/34 => Loss 3.039, Loss_clf 0.657, Loss_fe 0.792, Loss_kd 1.292, Train_accy 47.09
2022-09-28 03:21:27,874 [foster.py] => Task 3, Epoch 24/34 => Loss 3.018, Loss_clf 0.643, Loss_fe 0.781, Loss_kd 1.295, Train_accy 46.40
2022-09-28 03:21:29,761 [foster.py] => Task 3, Epoch 25/34 => Loss 3.016, Loss_clf 0.645, Loss_fe 0.785, Loss_kd 1.289, Train_accy 46.63
2022-09-28 03:21:32,488 [foster.py] => Task 3, Epoch 26/34 => Loss 2.979, Loss_clf 0.630, Loss_fe 0.762, Loss_kd 1.290, Train_accy 48.69, Test_accy 57.63
2022-09-28 03:21:34,377 [foster.py] => Task 3, Epoch 27/34 => Loss 3.039, Loss_clf 0.654, Loss_fe 0.795, Loss_kd 1.292, Train_accy 46.97
2022-09-28 03:21:36,286 [foster.py] => Task 3, Epoch 28/34 => Loss 2.987, Loss_clf 0.644, Loss_fe 0.766, Loss_kd 1.281, Train_accy 45.60
2022-09-28 03:21:38,172 [foster.py] => Task 3, Epoch 29/34 => Loss 2.994, Loss_clf 0.643, Loss_fe 0.778, Loss_kd 1.278, Train_accy 47.66
2022-09-28 03:21:40,056 [foster.py] => Task 3, Epoch 30/34 => Loss 3.027, Loss_clf 0.654, Loss_fe 0.794, Loss_kd 1.283, Train_accy 47.20
2022-09-28 03:21:42,850 [foster.py] => Task 3, Epoch 31/34 => Loss 2.987, Loss_clf 0.634, Loss_fe 0.761, Loss_kd 1.294, Train_accy 48.23, Test_accy 57.34
2022-09-28 03:21:44,752 [foster.py] => Task 3, Epoch 32/34 => Loss 2.973, Loss_clf 0.631, Loss_fe 0.761, Loss_kd 1.284, Train_accy 47.54
2022-09-28 03:21:46,652 [foster.py] => Task 3, Epoch 33/34 => Loss 2.985, Loss_clf 0.632, Loss_fe 0.766, Loss_kd 1.289, Train_accy 46.40
2022-09-28 03:21:48,540 [foster.py] => Task 3, Epoch 34/34 => Loss 2.951, Loss_clf 0.618, Loss_fe 0.741, Loss_kd 1.293, Train_accy 49.03
2022-09-28 03:21:48,541 [foster.py] => do not weight align teacher!
2022-09-28 03:21:48,541 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 03:21:51,640 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.153,  Train_accy 17.94, Test_accy 45.20
2022-09-28 03:21:53,795 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.049,  Train_accy 18.74
2022-09-28 03:21:55,958 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 1.995,  Train_accy 19.54
2022-09-28 03:21:58,077 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 1.978,  Train_accy 19.89
2022-09-28 03:22:00,210 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.968,  Train_accy 20.57
2022-09-28 03:22:03,059 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.956,  Train_accy 20.57, Test_accy 44.92
2022-09-28 03:22:05,205 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.942,  Train_accy 20.23
2022-09-28 03:22:07,359 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.946,  Train_accy 21.14
2022-09-28 03:22:09,508 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.946,  Train_accy 20.80
2022-09-28 03:22:11,633 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.940,  Train_accy 20.46
2022-09-28 03:22:14,605 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.941,  Train_accy 21.26, Test_accy 47.46
2022-09-28 03:22:16,717 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.940,  Train_accy 21.03
2022-09-28 03:22:18,900 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.927,  Train_accy 20.57
2022-09-28 03:22:21,041 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.929,  Train_accy 21.83
2022-09-28 03:22:23,189 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.933,  Train_accy 21.03
2022-09-28 03:22:26,113 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.923,  Train_accy 21.94, Test_accy 48.31
2022-09-28 03:22:28,240 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.931,  Train_accy 21.14
2022-09-28 03:22:30,395 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.924,  Train_accy 21.03
2022-09-28 03:22:32,498 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.932,  Train_accy 21.71
2022-09-28 03:22:34,653 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.934,  Train_accy 21.37
2022-09-28 03:22:37,569 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.921,  Train_accy 22.29, Test_accy 47.18
2022-09-28 03:22:39,684 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.909,  Train_accy 21.94
2022-09-28 03:22:41,831 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.922,  Train_accy 21.83
2022-09-28 03:22:43,963 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.915,  Train_accy 20.91
2022-09-28 03:22:46,126 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.928,  Train_accy 22.06
2022-09-28 03:22:49,045 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.926,  Train_accy 21.14, Test_accy 47.18
2022-09-28 03:22:49,046 [foster.py] => do not weight align student!
2022-09-28 03:22:49,794 [foster.py] => darknet eval: 
2022-09-28 03:22:49,794 [foster.py] => CNN top1 curve: 47.18
2022-09-28 03:22:49,794 [foster.py] => CNN top5 curve: 93.5
2022-09-28 03:22:49,795 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 03:22:58,277 [foster.py] => Exemplar size: 320
2022-09-28 03:22:58,278 [trainer.py] => CNN: {'total': 57.63, 'old': 67.26, 'new': 20.55, 'base': 81.25, 'compound': 41.43}
2022-09-28 03:22:58,278 [trainer.py] => CNN top1 curve: [84.72, 70.0, 66.19, 57.63]
2022-09-28 03:22:58,278 [trainer.py] => CNN base curve: [84.72, 81.94, 81.25, 81.25]
2022-09-28 03:22:58,278 [trainer.py] => CNN old curve: [84.72, 81.94, 71.82, 67.26]
2022-09-28 03:22:58,278 [trainer.py] => CNN new curve: [0, 47.37, 45.9, 20.55]
2022-09-28 03:22:58,278 [trainer.py] => CNN compound curve: [0, 47.37, 50.36, 41.43]
2022-09-28 03:22:58,278 [trainer.py] => NME: {'total': 65.82, 'old': 71.53, 'new': 43.84, 'base': 77.08, 'compound': 58.1}
2022-09-28 03:22:58,278 [trainer.py] => NME top1 curve: [85.42, 84.09, 75.09, 65.82]
2022-09-28 03:22:58,278 [trainer.py] => NME base curve: [85.42, 85.42, 80.56, 77.08]
2022-09-28 03:22:58,278 [trainer.py] => NME old curve: [85.42, 85.42, 76.36, 71.53]
2022-09-28 03:22:58,278 [trainer.py] => NME new curve: [0, 81.58, 70.49, 43.84]
2022-09-28 03:22:58,278 [trainer.py] => NME compound curve: [0, 81.58, 69.34, 58.1]
2022-09-28 03:22:58,508 [foster.py] => Learning on 16-19
2022-09-28 03:22:58,508 [foster.py] => All params: 22390454
2022-09-28 03:22:58,509 [foster.py] => Trainable params: 11205734
2022-09-28 03:22:58,529 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 03:23:01,437 [foster.py] => Task 4, Epoch 1/34 => Loss 6.221, Loss_clf 1.932, Loss_fe 2.333, Loss_kd 1.647, Train_accy 39.40, Test_accy 46.96
2022-09-28 03:23:03,451 [foster.py] => Task 4, Epoch 2/34 => Loss 4.751, Loss_clf 1.070, Loss_fe 1.738, Loss_kd 1.636, Train_accy 38.76
2022-09-28 03:23:05,471 [foster.py] => Task 4, Epoch 3/34 => Loss 4.456, Loss_clf 0.984, Loss_fe 1.536, Loss_kd 1.630, Train_accy 39.61
2022-09-28 03:23:07,524 [foster.py] => Task 4, Epoch 4/34 => Loss 4.357, Loss_clf 0.952, Loss_fe 1.459, Loss_kd 1.638, Train_accy 39.51
2022-09-28 03:23:09,502 [foster.py] => Task 4, Epoch 5/34 => Loss 4.217, Loss_clf 0.924, Loss_fe 1.343, Loss_kd 1.642, Train_accy 38.76
2022-09-28 03:23:12,437 [foster.py] => Task 4, Epoch 6/34 => Loss 4.121, Loss_clf 0.903, Loss_fe 1.274, Loss_kd 1.637, Train_accy 38.22, Test_accy 48.13
2022-09-28 03:23:14,448 [foster.py] => Task 4, Epoch 7/34 => Loss 4.097, Loss_clf 0.905, Loss_fe 1.236, Loss_kd 1.647, Train_accy 38.54
2022-09-28 03:23:16,459 [foster.py] => Task 4, Epoch 8/34 => Loss 4.018, Loss_clf 0.874, Loss_fe 1.187, Loss_kd 1.648, Train_accy 38.54
2022-09-28 03:23:18,453 [foster.py] => Task 4, Epoch 9/34 => Loss 4.007, Loss_clf 0.886, Loss_fe 1.169, Loss_kd 1.644, Train_accy 38.87
2022-09-28 03:23:20,461 [foster.py] => Task 4, Epoch 10/34 => Loss 3.933, Loss_clf 0.869, Loss_fe 1.123, Loss_kd 1.634, Train_accy 41.11
2022-09-28 03:23:23,408 [foster.py] => Task 4, Epoch 11/34 => Loss 3.862, Loss_clf 0.829, Loss_fe 1.076, Loss_kd 1.648, Train_accy 38.65, Test_accy 49.77
2022-09-28 03:23:25,410 [foster.py] => Task 4, Epoch 12/34 => Loss 3.809, Loss_clf 0.821, Loss_fe 1.042, Loss_kd 1.638, Train_accy 39.40
2022-09-28 03:23:27,441 [foster.py] => Task 4, Epoch 13/34 => Loss 3.753, Loss_clf 0.805, Loss_fe 1.006, Loss_kd 1.636, Train_accy 41.33
2022-09-28 03:23:29,445 [foster.py] => Task 4, Epoch 14/34 => Loss 3.755, Loss_clf 0.794, Loss_fe 0.998, Loss_kd 1.653, Train_accy 41.33
2022-09-28 03:23:31,441 [foster.py] => Task 4, Epoch 15/34 => Loss 3.715, Loss_clf 0.780, Loss_fe 0.985, Loss_kd 1.642, Train_accy 41.76
2022-09-28 03:23:34,348 [foster.py] => Task 4, Epoch 16/34 => Loss 3.664, Loss_clf 0.773, Loss_fe 0.947, Loss_kd 1.637, Train_accy 41.65, Test_accy 49.77
2022-09-28 03:23:36,338 [foster.py] => Task 4, Epoch 17/34 => Loss 3.650, Loss_clf 0.774, Loss_fe 0.935, Loss_kd 1.634, Train_accy 44.97
2022-09-28 03:23:38,370 [foster.py] => Task 4, Epoch 18/34 => Loss 3.696, Loss_clf 0.800, Loss_fe 0.948, Loss_kd 1.640, Train_accy 41.76
2022-09-28 03:23:40,367 [foster.py] => Task 4, Epoch 19/34 => Loss 3.669, Loss_clf 0.788, Loss_fe 0.931, Loss_kd 1.642, Train_accy 42.72
2022-09-28 03:23:42,420 [foster.py] => Task 4, Epoch 20/34 => Loss 3.620, Loss_clf 0.745, Loss_fe 0.918, Loss_kd 1.649, Train_accy 41.43
2022-09-28 03:23:45,412 [foster.py] => Task 4, Epoch 21/34 => Loss 3.573, Loss_clf 0.748, Loss_fe 0.879, Loss_kd 1.638, Train_accy 44.65, Test_accy 50.23
2022-09-28 03:23:47,421 [foster.py] => Task 4, Epoch 22/34 => Loss 3.568, Loss_clf 0.738, Loss_fe 0.868, Loss_kd 1.652, Train_accy 42.61
2022-09-28 03:23:49,386 [foster.py] => Task 4, Epoch 23/34 => Loss 3.522, Loss_clf 0.711, Loss_fe 0.860, Loss_kd 1.642, Train_accy 43.47
2022-09-28 03:23:51,375 [foster.py] => Task 4, Epoch 24/34 => Loss 3.567, Loss_clf 0.734, Loss_fe 0.875, Loss_kd 1.648, Train_accy 42.83
2022-09-28 03:23:53,390 [foster.py] => Task 4, Epoch 25/34 => Loss 3.544, Loss_clf 0.733, Loss_fe 0.856, Loss_kd 1.647, Train_accy 45.07
2022-09-28 03:23:56,263 [foster.py] => Task 4, Epoch 26/34 => Loss 3.575, Loss_clf 0.737, Loss_fe 0.890, Loss_kd 1.640, Train_accy 43.15, Test_accy 50.70
2022-09-28 03:23:58,231 [foster.py] => Task 4, Epoch 27/34 => Loss 3.522, Loss_clf 0.712, Loss_fe 0.847, Loss_kd 1.653, Train_accy 42.72
2022-09-28 03:24:00,233 [foster.py] => Task 4, Epoch 28/34 => Loss 3.536, Loss_clf 0.714, Loss_fe 0.854, Loss_kd 1.658, Train_accy 45.50
2022-09-28 03:24:02,258 [foster.py] => Task 4, Epoch 29/34 => Loss 3.539, Loss_clf 0.714, Loss_fe 0.869, Loss_kd 1.647, Train_accy 44.11
2022-09-28 03:24:04,328 [foster.py] => Task 4, Epoch 30/34 => Loss 3.513, Loss_clf 0.705, Loss_fe 0.847, Loss_kd 1.651, Train_accy 45.40
2022-09-28 03:24:07,233 [foster.py] => Task 4, Epoch 31/34 => Loss 3.499, Loss_clf 0.698, Loss_fe 0.840, Loss_kd 1.652, Train_accy 44.33, Test_accy 50.93
2022-09-28 03:24:09,224 [foster.py] => Task 4, Epoch 32/34 => Loss 3.487, Loss_clf 0.695, Loss_fe 0.830, Loss_kd 1.651, Train_accy 43.90
2022-09-28 03:24:11,197 [foster.py] => Task 4, Epoch 33/34 => Loss 3.497, Loss_clf 0.707, Loss_fe 0.841, Loss_kd 1.642, Train_accy 43.15
2022-09-28 03:24:13,184 [foster.py] => Task 4, Epoch 34/34 => Loss 3.531, Loss_clf 0.722, Loss_fe 0.856, Loss_kd 1.644, Train_accy 44.11
2022-09-28 03:24:13,184 [foster.py] => do not weight align teacher!
2022-09-28 03:24:13,184 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 03:24:16,419 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.278,  Train_accy 19.49, Test_accy 39.72
2022-09-28 03:24:18,654 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.248,  Train_accy 20.45
2022-09-28 03:24:20,912 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.223,  Train_accy 21.63
2022-09-28 03:24:23,174 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.213,  Train_accy 20.99
2022-09-28 03:24:25,439 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.201,  Train_accy 20.13
2022-09-28 03:24:28,504 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.196,  Train_accy 21.31, Test_accy 43.46
2022-09-28 03:24:30,724 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.204,  Train_accy 21.52
2022-09-28 03:24:32,979 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.202,  Train_accy 21.63
2022-09-28 03:24:35,274 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.187,  Train_accy 22.16
2022-09-28 03:24:37,525 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.197,  Train_accy 22.27
2022-09-28 03:24:40,647 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.189,  Train_accy 21.63, Test_accy 43.69
2022-09-28 03:24:42,870 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.193,  Train_accy 21.09
2022-09-28 03:24:45,154 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.190,  Train_accy 21.09
2022-09-28 03:24:47,414 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.180,  Train_accy 21.41
2022-09-28 03:24:49,678 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.184,  Train_accy 21.41
2022-09-28 03:24:52,689 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.182,  Train_accy 22.16, Test_accy 44.63
2022-09-28 03:24:54,957 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.167,  Train_accy 22.27
2022-09-28 03:24:57,183 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.172,  Train_accy 22.48
2022-09-28 03:24:59,428 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.179,  Train_accy 21.52
2022-09-28 03:25:01,701 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.183,  Train_accy 21.73
2022-09-28 03:25:04,758 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.175,  Train_accy 21.84, Test_accy 43.93
2022-09-28 03:25:07,033 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.173,  Train_accy 22.48
2022-09-28 03:25:09,257 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.175,  Train_accy 22.16
2022-09-28 03:25:11,495 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.176,  Train_accy 21.84
2022-09-28 03:25:13,745 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.193,  Train_accy 21.73
2022-09-28 03:25:16,814 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.175,  Train_accy 21.31, Test_accy 44.86
2022-09-28 03:25:16,815 [foster.py] => do not weight align student!
2022-09-28 03:25:17,620 [foster.py] => darknet eval: 
2022-09-28 03:25:17,620 [foster.py] => CNN top1 curve: 44.86
2022-09-28 03:25:17,620 [foster.py] => CNN top5 curve: 84.58
2022-09-28 03:25:17,620 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 03:25:27,150 [foster.py] => Exemplar size: 380
2022-09-28 03:25:27,151 [trainer.py] => CNN: {'total': 51.17, 'old': 56.78, 'new': 24.32, 'base': 79.17, 'compound': 36.97}
2022-09-28 03:25:27,151 [trainer.py] => CNN top1 curve: [84.72, 70.0, 66.19, 57.63, 51.17]
2022-09-28 03:25:27,151 [trainer.py] => CNN base curve: [84.72, 81.94, 81.25, 81.25, 79.17]
2022-09-28 03:25:27,151 [trainer.py] => CNN old curve: [84.72, 81.94, 71.82, 67.26, 56.78]
2022-09-28 03:25:27,151 [trainer.py] => CNN new curve: [0, 47.37, 45.9, 20.55, 24.32]
2022-09-28 03:25:27,151 [trainer.py] => CNN compound curve: [0, 47.37, 50.36, 41.43, 36.97]
2022-09-28 03:25:27,151 [trainer.py] => NME: {'total': 57.71, 'old': 60.45, 'new': 44.59, 'base': 76.39, 'compound': 48.24}
2022-09-28 03:25:27,151 [trainer.py] => NME top1 curve: [85.42, 84.09, 75.09, 65.82, 57.71]
2022-09-28 03:25:27,151 [trainer.py] => NME base curve: [85.42, 85.42, 80.56, 77.08, 76.39]
2022-09-28 03:25:27,151 [trainer.py] => NME old curve: [85.42, 85.42, 76.36, 71.53, 60.45]
2022-09-28 03:25:27,151 [trainer.py] => NME new curve: [0, 81.58, 70.49, 43.84, 44.59]
2022-09-28 03:25:27,151 [trainer.py] => NME compound curve: [0, 81.58, 69.34, 58.1, 48.24]
2022-09-28 03:25:27,385 [foster.py] => Learning on 19-22
2022-09-28 03:25:27,385 [foster.py] => All params: 22396607
2022-09-28 03:25:27,385 [foster.py] => Trainable params: 11210348
2022-09-28 03:25:27,405 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 03:25:30,449 [foster.py] => Task 5, Epoch 1/34 => Loss 6.834, Loss_clf 2.180, Loss_fe 2.481, Loss_kd 1.877, Train_accy 41.57, Test_accy 42.77
2022-09-28 03:25:32,542 [foster.py] => Task 5, Epoch 2/34 => Loss 5.172, Loss_clf 1.112, Loss_fe 1.875, Loss_kd 1.887, Train_accy 36.13
2022-09-28 03:25:34,630 [foster.py] => Task 5, Epoch 3/34 => Loss 4.859, Loss_clf 1.007, Loss_fe 1.676, Loss_kd 1.880, Train_accy 40.77
2022-09-28 03:25:36,701 [foster.py] => Task 5, Epoch 4/34 => Loss 4.711, Loss_clf 0.973, Loss_fe 1.567, Loss_kd 1.875, Train_accy 40.36
2022-09-28 03:25:38,803 [foster.py] => Task 5, Epoch 5/34 => Loss 4.573, Loss_clf 0.936, Loss_fe 1.468, Loss_kd 1.874, Train_accy 42.89
2022-09-28 03:25:41,837 [foster.py] => Task 5, Epoch 6/34 => Loss 4.486, Loss_clf 0.922, Loss_fe 1.395, Loss_kd 1.873, Train_accy 41.47, Test_accy 45.35
2022-09-28 03:25:43,929 [foster.py] => Task 5, Epoch 7/34 => Loss 4.394, Loss_clf 0.899, Loss_fe 1.317, Loss_kd 1.881, Train_accy 44.00
2022-09-28 03:25:46,042 [foster.py] => Task 5, Epoch 8/34 => Loss 4.333, Loss_clf 0.887, Loss_fe 1.264, Loss_kd 1.884, Train_accy 43.09
2022-09-28 03:25:48,106 [foster.py] => Task 5, Epoch 9/34 => Loss 4.257, Loss_clf 0.867, Loss_fe 1.222, Loss_kd 1.872, Train_accy 43.69
2022-09-28 03:25:50,206 [foster.py] => Task 5, Epoch 10/34 => Loss 4.217, Loss_clf 0.854, Loss_fe 1.186, Loss_kd 1.881, Train_accy 42.58
2022-09-28 03:25:53,248 [foster.py] => Task 5, Epoch 11/34 => Loss 4.176, Loss_clf 0.846, Loss_fe 1.148, Loss_kd 1.885, Train_accy 44.30, Test_accy 46.93
2022-09-28 03:25:55,303 [foster.py] => Task 5, Epoch 12/34 => Loss 4.123, Loss_clf 0.833, Loss_fe 1.112, Loss_kd 1.880, Train_accy 45.11
2022-09-28 03:25:57,390 [foster.py] => Task 5, Epoch 13/34 => Loss 4.095, Loss_clf 0.822, Loss_fe 1.096, Loss_kd 1.880, Train_accy 45.31
2022-09-28 03:25:59,489 [foster.py] => Task 5, Epoch 14/34 => Loss 4.044, Loss_clf 0.801, Loss_fe 1.061, Loss_kd 1.885, Train_accy 44.50
2022-09-28 03:26:01,642 [foster.py] => Task 5, Epoch 15/34 => Loss 4.018, Loss_clf 0.808, Loss_fe 1.038, Loss_kd 1.876, Train_accy 45.11
2022-09-28 03:26:04,686 [foster.py] => Task 5, Epoch 16/34 => Loss 3.991, Loss_clf 0.794, Loss_fe 1.020, Loss_kd 1.880, Train_accy 46.72, Test_accy 46.34
2022-09-28 03:26:06,745 [foster.py] => Task 5, Epoch 17/34 => Loss 3.950, Loss_clf 0.778, Loss_fe 0.992, Loss_kd 1.882, Train_accy 46.52
2022-09-28 03:26:08,806 [foster.py] => Task 5, Epoch 18/34 => Loss 3.957, Loss_clf 0.780, Loss_fe 0.997, Loss_kd 1.883, Train_accy 46.52
2022-09-28 03:26:10,864 [foster.py] => Task 5, Epoch 19/34 => Loss 3.892, Loss_clf 0.751, Loss_fe 0.959, Loss_kd 1.885, Train_accy 46.92
2022-09-28 03:26:12,993 [foster.py] => Task 5, Epoch 20/34 => Loss 3.889, Loss_clf 0.753, Loss_fe 0.954, Loss_kd 1.884, Train_accy 46.62
2022-09-28 03:26:16,066 [foster.py] => Task 5, Epoch 21/34 => Loss 3.860, Loss_clf 0.744, Loss_fe 0.940, Loss_kd 1.879, Train_accy 48.03, Test_accy 48.12
2022-09-28 03:26:18,114 [foster.py] => Task 5, Epoch 22/34 => Loss 3.896, Loss_clf 0.766, Loss_fe 0.952, Loss_kd 1.880, Train_accy 45.51
2022-09-28 03:26:20,187 [foster.py] => Task 5, Epoch 23/34 => Loss 3.889, Loss_clf 0.754, Loss_fe 0.947, Loss_kd 1.890, Train_accy 48.44
2022-09-28 03:26:22,279 [foster.py] => Task 5, Epoch 24/34 => Loss 3.839, Loss_clf 0.731, Loss_fe 0.927, Loss_kd 1.884, Train_accy 47.53
2022-09-28 03:26:24,407 [foster.py] => Task 5, Epoch 25/34 => Loss 3.846, Loss_clf 0.741, Loss_fe 0.922, Loss_kd 1.886, Train_accy 47.12
2022-09-28 03:26:27,443 [foster.py] => Task 5, Epoch 26/34 => Loss 3.814, Loss_clf 0.732, Loss_fe 0.910, Loss_kd 1.876, Train_accy 47.63, Test_accy 48.12
2022-09-28 03:26:29,513 [foster.py] => Task 5, Epoch 27/34 => Loss 3.811, Loss_clf 0.715, Loss_fe 0.911, Loss_kd 1.887, Train_accy 47.33
2022-09-28 03:26:31,611 [foster.py] => Task 5, Epoch 28/34 => Loss 3.805, Loss_clf 0.728, Loss_fe 0.900, Loss_kd 1.880, Train_accy 48.13
2022-09-28 03:26:33,668 [foster.py] => Task 5, Epoch 29/34 => Loss 3.818, Loss_clf 0.732, Loss_fe 0.907, Loss_kd 1.882, Train_accy 47.43
2022-09-28 03:26:35,716 [foster.py] => Task 5, Epoch 30/34 => Loss 3.822, Loss_clf 0.731, Loss_fe 0.907, Loss_kd 1.886, Train_accy 47.73
2022-09-28 03:26:38,867 [foster.py] => Task 5, Epoch 31/34 => Loss 3.833, Loss_clf 0.732, Loss_fe 0.914, Loss_kd 1.888, Train_accy 47.33, Test_accy 47.72
2022-09-28 03:26:40,943 [foster.py] => Task 5, Epoch 32/34 => Loss 3.823, Loss_clf 0.726, Loss_fe 0.911, Loss_kd 1.888, Train_accy 45.61
2022-09-28 03:26:43,038 [foster.py] => Task 5, Epoch 33/34 => Loss 3.800, Loss_clf 0.714, Loss_fe 0.899, Loss_kd 1.889, Train_accy 48.44
2022-09-28 03:26:45,110 [foster.py] => Task 5, Epoch 34/34 => Loss 3.799, Loss_clf 0.714, Loss_fe 0.900, Loss_kd 1.887, Train_accy 47.73
2022-09-28 03:26:45,110 [foster.py] => do not weight align teacher!
2022-09-28 03:26:45,111 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 03:26:48,528 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.438,  Train_accy 19.37, Test_accy 38.02
2022-09-28 03:26:50,876 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.414,  Train_accy 19.88
2022-09-28 03:26:53,231 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.391,  Train_accy 20.48
2022-09-28 03:26:55,550 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.380,  Train_accy 21.29
2022-09-28 03:26:57,901 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.385,  Train_accy 21.70
2022-09-28 03:27:01,112 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.377,  Train_accy 21.29, Test_accy 39.80
2022-09-28 03:27:03,486 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.372,  Train_accy 21.39
2022-09-28 03:27:05,844 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.365,  Train_accy 21.59
2022-09-28 03:27:08,183 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.354,  Train_accy 21.59
2022-09-28 03:27:10,488 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.353,  Train_accy 22.81
2022-09-28 03:27:13,667 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.348,  Train_accy 22.40, Test_accy 40.79
2022-09-28 03:27:16,028 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.358,  Train_accy 21.59
2022-09-28 03:27:18,371 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.348,  Train_accy 22.00
2022-09-28 03:27:20,758 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.347,  Train_accy 22.70
2022-09-28 03:27:23,103 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.344,  Train_accy 22.91
2022-09-28 03:27:26,349 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.345,  Train_accy 23.81, Test_accy 40.79
2022-09-28 03:27:28,724 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.342,  Train_accy 21.19
2022-09-28 03:27:31,112 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.331,  Train_accy 22.10
2022-09-28 03:27:33,464 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.345,  Train_accy 23.11
2022-09-28 03:27:35,796 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.349,  Train_accy 23.81
2022-09-28 03:27:38,974 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.334,  Train_accy 22.20, Test_accy 41.39
2022-09-28 03:27:41,335 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.345,  Train_accy 23.51
2022-09-28 03:27:43,705 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.336,  Train_accy 22.20
2022-09-28 03:27:46,088 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.343,  Train_accy 23.31
2022-09-28 03:27:48,409 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.341,  Train_accy 23.31
2022-09-28 03:27:51,548 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.332,  Train_accy 23.31, Test_accy 41.19
2022-09-28 03:27:51,549 [foster.py] => do not weight align student!
2022-09-28 03:27:52,386 [foster.py] => darknet eval: 
2022-09-28 03:27:52,386 [foster.py] => CNN top1 curve: 41.19
2022-09-28 03:27:52,386 [foster.py] => CNN top5 curve: 81.98
2022-09-28 03:27:52,387 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 03:28:03,015 [foster.py] => Exemplar size: 440
2022-09-28 03:28:03,015 [trainer.py] => CNN: {'total': 47.92, 'old': 51.17, 'new': 29.87, 'base': 78.47, 'compound': 35.73}
2022-09-28 03:28:03,015 [trainer.py] => CNN top1 curve: [84.72, 70.0, 66.19, 57.63, 51.17, 47.92]
2022-09-28 03:28:03,015 [trainer.py] => CNN base curve: [84.72, 81.94, 81.25, 81.25, 79.17, 78.47]
2022-09-28 03:28:03,015 [trainer.py] => CNN old curve: [84.72, 81.94, 71.82, 67.26, 56.78, 51.17]
2022-09-28 03:28:03,015 [trainer.py] => CNN new curve: [0, 47.37, 45.9, 20.55, 24.32, 29.87]
2022-09-28 03:28:03,015 [trainer.py] => CNN compound curve: [0, 47.37, 50.36, 41.43, 36.97, 35.73]
2022-09-28 03:28:03,015 [trainer.py] => NME: {'total': 54.65, 'old': 56.78, 'new': 42.86, 'base': 76.39, 'compound': 45.98}
2022-09-28 03:28:03,015 [trainer.py] => NME top1 curve: [85.42, 84.09, 75.09, 65.82, 57.71, 54.65]
2022-09-28 03:28:03,015 [trainer.py] => NME base curve: [85.42, 85.42, 80.56, 77.08, 76.39, 76.39]
2022-09-28 03:28:03,015 [trainer.py] => NME old curve: [85.42, 85.42, 76.36, 71.53, 60.45, 56.78]
2022-09-28 03:28:03,015 [trainer.py] => NME new curve: [0, 81.58, 70.49, 43.84, 44.59, 42.86]
2022-09-28 03:28:03,015 [trainer.py] => NME compound curve: [0, 81.58, 69.34, 58.1, 48.24, 45.98]
2022-09-28 03:28:03,016 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 03:28:03,016 [trainer.py] => prefix: cil
2022-09-28 03:28:03,016 [trainer.py] => dataset: CFEE
2022-09-28 03:28:03,017 [trainer.py] => memory_size: 2000
2022-09-28 03:28:03,017 [trainer.py] => memory_per_class: 20
2022-09-28 03:28:03,017 [trainer.py] => fixed_memory: True
2022-09-28 03:28:03,017 [trainer.py] => shuffle: True
2022-09-28 03:28:03,017 [trainer.py] => init_cls: 7
2022-09-28 03:28:03,017 [trainer.py] => increment: 3
2022-09-28 03:28:03,017 [trainer.py] => model_name: foster
2022-09-28 03:28:03,017 [trainer.py] => convnet_type: resnet18
2022-09-28 03:28:03,017 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 03:28:03,017 [trainer.py] => seed: 1993
2022-09-28 03:28:03,017 [trainer.py] => beta1: 0.96
2022-09-28 03:28:03,017 [trainer.py] => beta2: 0.97
2022-09-28 03:28:03,017 [trainer.py] => oofc: ft
2022-09-28 03:28:03,017 [trainer.py] => is_teacher_wa: False
2022-09-28 03:28:03,017 [trainer.py] => is_student_wa: False
2022-09-28 03:28:03,017 [trainer.py] => lambda_okd: 1
2022-09-28 03:28:03,017 [trainer.py] => wa_value: 1
2022-09-28 03:28:03,017 [trainer.py] => init_epochs: 40
2022-09-28 03:28:03,017 [trainer.py] => init_lr: 0.01
2022-09-28 03:28:03,017 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 03:28:03,017 [trainer.py] => boosting_epochs: 34
2022-09-28 03:28:03,017 [trainer.py] => compression_epochs: 26
2022-09-28 03:28:03,017 [trainer.py] => lr: 0.001
2022-09-28 03:28:03,017 [trainer.py] => batch_size: 32
2022-09-28 03:28:03,017 [trainer.py] => weight_decay: 0.0005
2022-09-28 03:28:03,017 [trainer.py] => num_workers: 8
2022-09-28 03:28:03,017 [trainer.py] => T: 2
2022-09-28 03:28:03,017 [trainer.py] => nb_runs: 3
2022-09-28 03:28:03,017 [trainer.py] => fold: 10
2022-09-28 03:28:03,018 [data.py] => ========== Fold:5 ==========
2022-09-28 03:28:03,023 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 8, 15, 13, 17, 9, 11, 19, 21, 14, 10, 18, 12, 7, 16]
2022-09-28 03:28:03,236 [foster.py] => Learning on 0-7
2022-09-28 03:28:03,236 [foster.py] => All params: 11183694
2022-09-28 03:28:03,236 [foster.py] => Trainable params: 11183694
2022-09-28 03:28:05,598 [foster.py] => Task 0, Epoch 1/40 => Loss 1.382, Train_accy 48.47
2022-09-28 03:28:08,537 [foster.py] => Task 0, Epoch 2/40 => Loss 0.573, Train_accy 80.04, Test_accy 83.43
2022-09-28 03:28:11,478 [foster.py] => Task 0, Epoch 3/40 => Loss 0.353, Train_accy 88.46, Test_accy 88.76
2022-09-28 03:28:14,489 [foster.py] => Task 0, Epoch 4/40 => Loss 0.280, Train_accy 90.13, Test_accy 85.21
2022-09-28 03:28:17,441 [foster.py] => Task 0, Epoch 5/40 => Loss 0.219, Train_accy 91.86, Test_accy 86.98
2022-09-28 03:28:19,772 [foster.py] => Task 0, Epoch 6/40 => Loss 0.169, Train_accy 93.95
2022-09-28 03:28:22,723 [foster.py] => Task 0, Epoch 7/40 => Loss 0.152, Train_accy 95.13, Test_accy 86.39
2022-09-28 03:28:25,736 [foster.py] => Task 0, Epoch 8/40 => Loss 0.120, Train_accy 96.18, Test_accy 88.17
2022-09-28 03:28:28,720 [foster.py] => Task 0, Epoch 9/40 => Loss 0.118, Train_accy 96.11, Test_accy 91.12
2022-09-28 03:28:31,699 [foster.py] => Task 0, Epoch 10/40 => Loss 0.101, Train_accy 96.66, Test_accy 89.35
2022-09-28 03:28:34,033 [foster.py] => Task 0, Epoch 11/40 => Loss 0.073, Train_accy 97.84
2022-09-28 03:28:36,975 [foster.py] => Task 0, Epoch 12/40 => Loss 0.068, Train_accy 98.19, Test_accy 90.53
2022-09-28 03:28:39,997 [foster.py] => Task 0, Epoch 13/40 => Loss 0.060, Train_accy 98.40, Test_accy 92.31
2022-09-28 03:28:42,963 [foster.py] => Task 0, Epoch 14/40 => Loss 0.058, Train_accy 98.33, Test_accy 92.31
2022-09-28 03:28:45,931 [foster.py] => Task 0, Epoch 15/40 => Loss 0.044, Train_accy 98.82, Test_accy 89.94
2022-09-28 03:28:48,258 [foster.py] => Task 0, Epoch 16/40 => Loss 0.063, Train_accy 97.91
2022-09-28 03:28:51,240 [foster.py] => Task 0, Epoch 17/40 => Loss 0.034, Train_accy 99.03, Test_accy 91.12
2022-09-28 03:28:54,189 [foster.py] => Task 0, Epoch 18/40 => Loss 0.029, Train_accy 99.58, Test_accy 90.53
2022-09-28 03:28:57,208 [foster.py] => Task 0, Epoch 19/40 => Loss 0.028, Train_accy 99.51, Test_accy 90.53
2022-09-28 03:29:00,221 [foster.py] => Task 0, Epoch 20/40 => Loss 0.031, Train_accy 99.44, Test_accy 89.35
2022-09-28 03:29:02,589 [foster.py] => Task 0, Epoch 21/40 => Loss 0.023, Train_accy 99.58
2022-09-28 03:29:05,553 [foster.py] => Task 0, Epoch 22/40 => Loss 0.020, Train_accy 99.72, Test_accy 91.12
2022-09-28 03:29:08,518 [foster.py] => Task 0, Epoch 23/40 => Loss 0.019, Train_accy 99.58, Test_accy 90.53
2022-09-28 03:29:11,525 [foster.py] => Task 0, Epoch 24/40 => Loss 0.020, Train_accy 99.51, Test_accy 91.12
2022-09-28 03:29:14,506 [foster.py] => Task 0, Epoch 25/40 => Loss 0.017, Train_accy 99.93, Test_accy 90.53
2022-09-28 03:29:16,874 [foster.py] => Task 0, Epoch 26/40 => Loss 0.016, Train_accy 99.79
2022-09-28 03:29:19,841 [foster.py] => Task 0, Epoch 27/40 => Loss 0.017, Train_accy 99.72, Test_accy 90.53
2022-09-28 03:29:22,789 [foster.py] => Task 0, Epoch 28/40 => Loss 0.020, Train_accy 99.58, Test_accy 90.53
2022-09-28 03:29:25,742 [foster.py] => Task 0, Epoch 29/40 => Loss 0.013, Train_accy 99.79, Test_accy 89.94
2022-09-28 03:29:28,717 [foster.py] => Task 0, Epoch 30/40 => Loss 0.014, Train_accy 99.86, Test_accy 90.53
2022-09-28 03:29:31,078 [foster.py] => Task 0, Epoch 31/40 => Loss 0.018, Train_accy 99.72
2022-09-28 03:29:34,032 [foster.py] => Task 0, Epoch 32/40 => Loss 0.019, Train_accy 99.79, Test_accy 89.94
2022-09-28 03:29:37,033 [foster.py] => Task 0, Epoch 33/40 => Loss 0.014, Train_accy 99.65, Test_accy 90.53
2022-09-28 03:29:39,988 [foster.py] => Task 0, Epoch 34/40 => Loss 0.011, Train_accy 99.93, Test_accy 90.53
2022-09-28 03:29:43,006 [foster.py] => Task 0, Epoch 35/40 => Loss 0.017, Train_accy 99.51, Test_accy 90.53
2022-09-28 03:29:45,379 [foster.py] => Task 0, Epoch 36/40 => Loss 0.010, Train_accy 100.00
2022-09-28 03:29:48,412 [foster.py] => Task 0, Epoch 37/40 => Loss 0.014, Train_accy 99.72, Test_accy 90.53
2022-09-28 03:29:51,389 [foster.py] => Task 0, Epoch 38/40 => Loss 0.019, Train_accy 99.51, Test_accy 90.53
2022-09-28 03:29:54,342 [foster.py] => Task 0, Epoch 39/40 => Loss 0.013, Train_accy 99.86, Test_accy 90.53
2022-09-28 03:29:57,319 [foster.py] => Task 0, Epoch 40/40 => Loss 0.013, Train_accy 99.86, Test_accy 91.12
2022-09-28 03:29:57,320 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 03:30:04,164 [foster.py] => Exemplar size: 140
2022-09-28 03:30:04,164 [trainer.py] => CNN: {'total': 91.12, 'old': 91.12, 'new': 0, 'base': 91.12, 'compound': 0}
2022-09-28 03:30:04,164 [trainer.py] => CNN top1 curve: [91.12]
2022-09-28 03:30:04,164 [trainer.py] => CNN base curve: [91.12]
2022-09-28 03:30:04,164 [trainer.py] => CNN old curve: [91.12]
2022-09-28 03:30:04,164 [trainer.py] => CNN new curve: [0]
2022-09-28 03:30:04,164 [trainer.py] => CNN compound curve: [0]
2022-09-28 03:30:04,164 [trainer.py] => NME: {'total': 88.17, 'old': 88.17, 'new': 0, 'base': 88.17, 'compound': 0}
2022-09-28 03:30:04,164 [trainer.py] => NME top1 curve: [88.17]
2022-09-28 03:30:04,164 [trainer.py] => NME base curve: [88.17]
2022-09-28 03:30:04,164 [trainer.py] => NME old curve: [88.17]
2022-09-28 03:30:04,164 [trainer.py] => NME new curve: [0]
2022-09-28 03:30:04,164 [trainer.py] => NME compound curve: [0]
2022-09-28 03:30:04,395 [foster.py] => Learning on 7-10
2022-09-28 03:30:04,396 [foster.py] => All params: 22371995
2022-09-28 03:30:04,396 [foster.py] => Trainable params: 11191892
2022-09-28 03:30:04,416 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 03:30:06,887 [foster.py] => Task 1, Epoch 1/34 => Loss 4.619, Loss_clf 2.074, Loss_fe 1.873, Loss_kd 0.470, Train_accy 37.60, Test_accy 71.54
2022-09-28 03:30:08,605 [foster.py] => Task 1, Epoch 2/34 => Loss 2.491, Loss_clf 0.651, Loss_fe 1.159, Loss_kd 0.477, Train_accy 72.40
2022-09-28 03:30:10,321 [foster.py] => Task 1, Epoch 3/34 => Loss 1.937, Loss_clf 0.369, Loss_fe 0.935, Loss_kd 0.443, Train_accy 47.87
2022-09-28 03:30:12,023 [foster.py] => Task 1, Epoch 4/34 => Loss 1.757, Loss_clf 0.323, Loss_fe 0.796, Loss_kd 0.446, Train_accy 50.27
2022-09-28 03:30:13,705 [foster.py] => Task 1, Epoch 5/34 => Loss 1.659, Loss_clf 0.321, Loss_fe 0.712, Loss_kd 0.438, Train_accy 49.33
2022-09-28 03:30:16,158 [foster.py] => Task 1, Epoch 6/34 => Loss 1.563, Loss_clf 0.284, Loss_fe 0.640, Loss_kd 0.447, Train_accy 54.00, Test_accy 77.24
2022-09-28 03:30:17,882 [foster.py] => Task 1, Epoch 7/34 => Loss 1.495, Loss_clf 0.273, Loss_fe 0.581, Loss_kd 0.448, Train_accy 57.07
2022-09-28 03:30:19,582 [foster.py] => Task 1, Epoch 8/34 => Loss 1.447, Loss_clf 0.262, Loss_fe 0.559, Loss_kd 0.439, Train_accy 52.00
2022-09-28 03:30:21,261 [foster.py] => Task 1, Epoch 9/34 => Loss 1.395, Loss_clf 0.252, Loss_fe 0.505, Loss_kd 0.446, Train_accy 55.73
2022-09-28 03:30:22,973 [foster.py] => Task 1, Epoch 10/34 => Loss 1.316, Loss_clf 0.231, Loss_fe 0.459, Loss_kd 0.439, Train_accy 56.13
2022-09-28 03:30:25,428 [foster.py] => Task 1, Epoch 11/34 => Loss 1.294, Loss_clf 0.226, Loss_fe 0.443, Loss_kd 0.438, Train_accy 56.27, Test_accy 77.24
2022-09-28 03:30:27,147 [foster.py] => Task 1, Epoch 12/34 => Loss 1.241, Loss_clf 0.210, Loss_fe 0.404, Loss_kd 0.439, Train_accy 58.00
2022-09-28 03:30:28,882 [foster.py] => Task 1, Epoch 13/34 => Loss 1.216, Loss_clf 0.215, Loss_fe 0.395, Loss_kd 0.424, Train_accy 57.20
2022-09-28 03:30:30,630 [foster.py] => Task 1, Epoch 14/34 => Loss 1.195, Loss_clf 0.193, Loss_fe 0.371, Loss_kd 0.442, Train_accy 56.93
2022-09-28 03:30:32,358 [foster.py] => Task 1, Epoch 15/34 => Loss 1.176, Loss_clf 0.186, Loss_fe 0.364, Loss_kd 0.438, Train_accy 56.67
2022-09-28 03:30:34,830 [foster.py] => Task 1, Epoch 16/34 => Loss 1.186, Loss_clf 0.189, Loss_fe 0.360, Loss_kd 0.446, Train_accy 59.07, Test_accy 77.64
2022-09-28 03:30:36,569 [foster.py] => Task 1, Epoch 17/34 => Loss 1.136, Loss_clf 0.174, Loss_fe 0.339, Loss_kd 0.436, Train_accy 58.27
2022-09-28 03:30:38,270 [foster.py] => Task 1, Epoch 18/34 => Loss 1.137, Loss_clf 0.178, Loss_fe 0.334, Loss_kd 0.438, Train_accy 57.87
2022-09-28 03:30:40,017 [foster.py] => Task 1, Epoch 19/34 => Loss 1.139, Loss_clf 0.177, Loss_fe 0.324, Loss_kd 0.447, Train_accy 58.80
2022-09-28 03:30:41,753 [foster.py] => Task 1, Epoch 20/34 => Loss 1.115, Loss_clf 0.170, Loss_fe 0.318, Loss_kd 0.438, Train_accy 59.33
2022-09-28 03:30:44,198 [foster.py] => Task 1, Epoch 21/34 => Loss 1.098, Loss_clf 0.160, Loss_fe 0.300, Loss_kd 0.447, Train_accy 58.93, Test_accy 77.64
2022-09-28 03:30:45,904 [foster.py] => Task 1, Epoch 22/34 => Loss 1.112, Loss_clf 0.171, Loss_fe 0.317, Loss_kd 0.437, Train_accy 59.60
2022-09-28 03:30:47,629 [foster.py] => Task 1, Epoch 23/34 => Loss 1.073, Loss_clf 0.155, Loss_fe 0.290, Loss_kd 0.439, Train_accy 61.87
2022-09-28 03:30:49,325 [foster.py] => Task 1, Epoch 24/34 => Loss 1.084, Loss_clf 0.160, Loss_fe 0.298, Loss_kd 0.439, Train_accy 60.13
2022-09-28 03:30:51,008 [foster.py] => Task 1, Epoch 25/34 => Loss 1.078, Loss_clf 0.156, Loss_fe 0.289, Loss_kd 0.444, Train_accy 61.87
2022-09-28 03:30:53,462 [foster.py] => Task 1, Epoch 26/34 => Loss 1.088, Loss_clf 0.160, Loss_fe 0.290, Loss_kd 0.446, Train_accy 61.33, Test_accy 77.64
2022-09-28 03:30:55,172 [foster.py] => Task 1, Epoch 27/34 => Loss 1.052, Loss_clf 0.152, Loss_fe 0.272, Loss_kd 0.440, Train_accy 62.00
2022-09-28 03:30:56,919 [foster.py] => Task 1, Epoch 28/34 => Loss 1.060, Loss_clf 0.151, Loss_fe 0.285, Loss_kd 0.437, Train_accy 60.27
2022-09-28 03:30:58,653 [foster.py] => Task 1, Epoch 29/34 => Loss 1.070, Loss_clf 0.162, Loss_fe 0.282, Loss_kd 0.438, Train_accy 59.33
2022-09-28 03:31:00,348 [foster.py] => Task 1, Epoch 30/34 => Loss 1.095, Loss_clf 0.163, Loss_fe 0.299, Loss_kd 0.444, Train_accy 58.67
2022-09-28 03:31:02,760 [foster.py] => Task 1, Epoch 31/34 => Loss 1.078, Loss_clf 0.160, Loss_fe 0.284, Loss_kd 0.444, Train_accy 60.40, Test_accy 77.24
2022-09-28 03:31:04,473 [foster.py] => Task 1, Epoch 32/34 => Loss 1.070, Loss_clf 0.159, Loss_fe 0.284, Loss_kd 0.438, Train_accy 60.67
2022-09-28 03:31:06,160 [foster.py] => Task 1, Epoch 33/34 => Loss 1.056, Loss_clf 0.154, Loss_fe 0.281, Loss_kd 0.435, Train_accy 60.40
2022-09-28 03:31:07,925 [foster.py] => Task 1, Epoch 34/34 => Loss 1.070, Loss_clf 0.152, Loss_fe 0.278, Loss_kd 0.448, Train_accy 60.27
2022-09-28 03:31:07,926 [foster.py] => do not weight align teacher!
2022-09-28 03:31:07,927 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 03:31:10,749 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.568,  Train_accy 18.00, Test_accy 59.76
2022-09-28 03:31:12,674 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.441,  Train_accy 18.67
2022-09-28 03:31:14,599 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.361,  Train_accy 19.20
2022-09-28 03:31:16,540 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.298,  Train_accy 20.27
2022-09-28 03:31:18,472 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.265,  Train_accy 21.87
2022-09-28 03:31:21,056 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.247,  Train_accy 22.00, Test_accy 62.20
2022-09-28 03:31:22,964 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.224,  Train_accy 22.40
2022-09-28 03:31:24,906 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.225,  Train_accy 24.00
2022-09-28 03:31:26,800 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.219,  Train_accy 23.87
2022-09-28 03:31:28,698 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.191,  Train_accy 24.40
2022-09-28 03:31:31,284 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.200,  Train_accy 25.73, Test_accy 64.23
2022-09-28 03:31:33,210 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.195,  Train_accy 26.13
2022-09-28 03:31:35,090 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.190,  Train_accy 27.07
2022-09-28 03:31:36,996 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.199,  Train_accy 27.33
2022-09-28 03:31:38,945 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.188,  Train_accy 26.93
2022-09-28 03:31:41,540 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.187,  Train_accy 28.00, Test_accy 65.04
2022-09-28 03:31:43,452 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.177,  Train_accy 27.87
2022-09-28 03:31:45,398 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.184,  Train_accy 28.13
2022-09-28 03:31:47,314 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.178,  Train_accy 29.33
2022-09-28 03:31:49,240 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.164,  Train_accy 27.33
2022-09-28 03:31:51,834 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.174,  Train_accy 28.93, Test_accy 65.04
2022-09-28 03:31:53,804 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.178,  Train_accy 29.33
2022-09-28 03:31:55,757 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.174,  Train_accy 28.53
2022-09-28 03:31:57,648 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.167,  Train_accy 28.93
2022-09-28 03:31:59,562 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.179,  Train_accy 28.93
2022-09-28 03:32:02,137 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.171,  Train_accy 27.33, Test_accy 65.45
2022-09-28 03:32:02,137 [foster.py] => do not weight align student!
2022-09-28 03:32:02,829 [foster.py] => darknet eval: 
2022-09-28 03:32:02,829 [foster.py] => CNN top1 curve: 65.45
2022-09-28 03:32:02,829 [foster.py] => CNN top5 curve: 98.37
2022-09-28 03:32:02,829 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 03:32:09,146 [foster.py] => Exemplar size: 200
2022-09-28 03:32:09,146 [trainer.py] => CNN: {'total': 77.24, 'old': 89.35, 'new': 50.65, 'base': 89.35, 'compound': 50.65}
2022-09-28 03:32:09,146 [trainer.py] => CNN top1 curve: [91.12, 77.24]
2022-09-28 03:32:09,146 [trainer.py] => CNN base curve: [91.12, 89.35]
2022-09-28 03:32:09,146 [trainer.py] => CNN old curve: [91.12, 89.35]
2022-09-28 03:32:09,146 [trainer.py] => CNN new curve: [0, 50.65]
2022-09-28 03:32:09,146 [trainer.py] => CNN compound curve: [0, 50.65]
2022-09-28 03:32:09,146 [trainer.py] => NME: {'total': 82.93, 'old': 86.39, 'new': 75.32, 'base': 86.39, 'compound': 75.32}
2022-09-28 03:32:09,146 [trainer.py] => NME top1 curve: [88.17, 82.93]
2022-09-28 03:32:09,146 [trainer.py] => NME base curve: [88.17, 86.39]
2022-09-28 03:32:09,146 [trainer.py] => NME old curve: [88.17, 86.39]
2022-09-28 03:32:09,146 [trainer.py] => NME new curve: [0, 75.32]
2022-09-28 03:32:09,146 [trainer.py] => NME compound curve: [0, 75.32]
2022-09-28 03:32:09,376 [foster.py] => Learning on 10-13
2022-09-28 03:32:09,377 [foster.py] => All params: 22378148
2022-09-28 03:32:09,377 [foster.py] => Trainable params: 11196506
2022-09-28 03:32:09,397 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 03:32:12,067 [foster.py] => Task 2, Epoch 1/34 => Loss 5.412, Loss_clf 2.199, Loss_fe 2.069, Loss_kd 0.880, Train_accy 41.76, Test_accy 54.29
2022-09-28 03:32:13,928 [foster.py] => Task 2, Epoch 2/34 => Loss 3.233, Loss_clf 0.728, Loss_fe 1.356, Loss_kd 0.884, Train_accy 55.80
2022-09-28 03:32:15,747 [foster.py] => Task 2, Epoch 3/34 => Loss 2.820, Loss_clf 0.566, Loss_fe 1.132, Loss_kd 0.863, Train_accy 43.47
2022-09-28 03:32:17,541 [foster.py] => Task 2, Epoch 4/34 => Loss 2.610, Loss_clf 0.501, Loss_fe 0.986, Loss_kd 0.863, Train_accy 47.01
2022-09-28 03:32:19,351 [foster.py] => Task 2, Epoch 5/34 => Loss 2.525, Loss_clf 0.487, Loss_fe 0.912, Loss_kd 0.867, Train_accy 45.91
2022-09-28 03:32:21,991 [foster.py] => Task 2, Epoch 6/34 => Loss 2.402, Loss_clf 0.460, Loss_fe 0.827, Loss_kd 0.858, Train_accy 47.99, Test_accy 62.54
2022-09-28 03:32:23,801 [foster.py] => Task 2, Epoch 7/34 => Loss 2.350, Loss_clf 0.454, Loss_fe 0.777, Loss_kd 0.861, Train_accy 47.13
2022-09-28 03:32:25,583 [foster.py] => Task 2, Epoch 8/34 => Loss 2.321, Loss_clf 0.449, Loss_fe 0.745, Loss_kd 0.867, Train_accy 46.40
2022-09-28 03:32:27,411 [foster.py] => Task 2, Epoch 9/34 => Loss 2.214, Loss_clf 0.410, Loss_fe 0.688, Loss_kd 0.859, Train_accy 47.99
2022-09-28 03:32:29,257 [foster.py] => Task 2, Epoch 10/34 => Loss 2.195, Loss_clf 0.423, Loss_fe 0.651, Loss_kd 0.863, Train_accy 48.23
2022-09-28 03:32:31,912 [foster.py] => Task 2, Epoch 11/34 => Loss 2.119, Loss_clf 0.386, Loss_fe 0.624, Loss_kd 0.853, Train_accy 47.74, Test_accy 65.71
2022-09-28 03:32:33,730 [foster.py] => Task 2, Epoch 12/34 => Loss 2.080, Loss_clf 0.377, Loss_fe 0.587, Loss_kd 0.858, Train_accy 47.86
2022-09-28 03:32:35,551 [foster.py] => Task 2, Epoch 13/34 => Loss 2.089, Loss_clf 0.384, Loss_fe 0.572, Loss_kd 0.872, Train_accy 48.35
2022-09-28 03:32:37,445 [foster.py] => Task 2, Epoch 14/34 => Loss 2.052, Loss_clf 0.363, Loss_fe 0.559, Loss_kd 0.869, Train_accy 50.06
2022-09-28 03:32:39,292 [foster.py] => Task 2, Epoch 15/34 => Loss 2.037, Loss_clf 0.382, Loss_fe 0.539, Loss_kd 0.859, Train_accy 47.62
2022-09-28 03:32:41,875 [foster.py] => Task 2, Epoch 16/34 => Loss 2.011, Loss_clf 0.361, Loss_fe 0.529, Loss_kd 0.863, Train_accy 50.92, Test_accy 66.35
2022-09-28 03:32:43,665 [foster.py] => Task 2, Epoch 17/34 => Loss 1.982, Loss_clf 0.347, Loss_fe 0.501, Loss_kd 0.872, Train_accy 48.11
2022-09-28 03:32:45,464 [foster.py] => Task 2, Epoch 18/34 => Loss 1.980, Loss_clf 0.354, Loss_fe 0.498, Loss_kd 0.867, Train_accy 50.55
2022-09-28 03:32:47,281 [foster.py] => Task 2, Epoch 19/34 => Loss 1.975, Loss_clf 0.350, Loss_fe 0.499, Loss_kd 0.866, Train_accy 47.62
2022-09-28 03:32:49,073 [foster.py] => Task 2, Epoch 20/34 => Loss 1.946, Loss_clf 0.342, Loss_fe 0.486, Loss_kd 0.860, Train_accy 49.45
2022-09-28 03:32:51,663 [foster.py] => Task 2, Epoch 21/34 => Loss 1.930, Loss_clf 0.329, Loss_fe 0.478, Loss_kd 0.864, Train_accy 50.43, Test_accy 66.98
2022-09-28 03:32:53,484 [foster.py] => Task 2, Epoch 22/34 => Loss 1.931, Loss_clf 0.332, Loss_fe 0.477, Loss_kd 0.863, Train_accy 50.31
2022-09-28 03:32:55,311 [foster.py] => Task 2, Epoch 23/34 => Loss 1.911, Loss_clf 0.322, Loss_fe 0.467, Loss_kd 0.864, Train_accy 50.18
2022-09-28 03:32:57,100 [foster.py] => Task 2, Epoch 24/34 => Loss 1.899, Loss_clf 0.317, Loss_fe 0.455, Loss_kd 0.867, Train_accy 49.45
2022-09-28 03:32:58,922 [foster.py] => Task 2, Epoch 25/34 => Loss 1.937, Loss_clf 0.342, Loss_fe 0.471, Loss_kd 0.865, Train_accy 48.96
2022-09-28 03:33:01,568 [foster.py] => Task 2, Epoch 26/34 => Loss 1.888, Loss_clf 0.325, Loss_fe 0.444, Loss_kd 0.861, Train_accy 50.92, Test_accy 66.98
2022-09-28 03:33:03,373 [foster.py] => Task 2, Epoch 27/34 => Loss 1.891, Loss_clf 0.318, Loss_fe 0.442, Loss_kd 0.869, Train_accy 50.92
2022-09-28 03:33:05,160 [foster.py] => Task 2, Epoch 28/34 => Loss 1.884, Loss_clf 0.312, Loss_fe 0.445, Loss_kd 0.867, Train_accy 50.67
2022-09-28 03:33:06,973 [foster.py] => Task 2, Epoch 29/34 => Loss 1.930, Loss_clf 0.344, Loss_fe 0.470, Loss_kd 0.859, Train_accy 49.45
2022-09-28 03:33:08,761 [foster.py] => Task 2, Epoch 30/34 => Loss 1.876, Loss_clf 0.309, Loss_fe 0.440, Loss_kd 0.867, Train_accy 49.08
2022-09-28 03:33:11,447 [foster.py] => Task 2, Epoch 31/34 => Loss 1.886, Loss_clf 0.319, Loss_fe 0.441, Loss_kd 0.867, Train_accy 48.84, Test_accy 67.30
2022-09-28 03:33:13,266 [foster.py] => Task 2, Epoch 32/34 => Loss 1.897, Loss_clf 0.331, Loss_fe 0.440, Loss_kd 0.866, Train_accy 50.79
2022-09-28 03:33:15,128 [foster.py] => Task 2, Epoch 33/34 => Loss 1.878, Loss_clf 0.313, Loss_fe 0.437, Loss_kd 0.868, Train_accy 49.45
2022-09-28 03:33:16,905 [foster.py] => Task 2, Epoch 34/34 => Loss 1.914, Loss_clf 0.323, Loss_fe 0.453, Loss_kd 0.875, Train_accy 50.55
2022-09-28 03:33:16,906 [foster.py] => do not weight align teacher!
2022-09-28 03:33:16,906 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 03:33:19,852 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.748,  Train_accy 17.46, Test_accy 49.21
2022-09-28 03:33:21,894 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.654,  Train_accy 17.95
2022-09-28 03:33:23,930 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.611,  Train_accy 18.32
2022-09-28 03:33:25,961 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.581,  Train_accy 18.32
2022-09-28 03:33:27,998 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.557,  Train_accy 18.56
2022-09-28 03:33:30,722 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.544,  Train_accy 19.29, Test_accy 51.43
2022-09-28 03:33:32,726 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.539,  Train_accy 18.80
2022-09-28 03:33:34,744 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.528,  Train_accy 19.54
2022-09-28 03:33:36,809 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.529,  Train_accy 19.78
2022-09-28 03:33:38,805 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.532,  Train_accy 20.15
2022-09-28 03:33:41,557 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.513,  Train_accy 21.61, Test_accy 53.33
2022-09-28 03:33:43,573 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.532,  Train_accy 21.98
2022-09-28 03:33:45,581 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.510,  Train_accy 22.34
2022-09-28 03:33:47,567 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.521,  Train_accy 22.95
2022-09-28 03:33:49,588 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.493,  Train_accy 23.08
2022-09-28 03:33:52,366 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.488,  Train_accy 24.18, Test_accy 53.65
2022-09-28 03:33:54,400 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.510,  Train_accy 23.93
2022-09-28 03:33:56,412 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.505,  Train_accy 24.79
2022-09-28 03:33:58,415 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.505,  Train_accy 23.69
2022-09-28 03:34:00,468 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.509,  Train_accy 24.79
2022-09-28 03:34:03,225 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.502,  Train_accy 25.40, Test_accy 53.97
2022-09-28 03:34:05,218 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.499,  Train_accy 25.15
2022-09-28 03:34:07,263 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.507,  Train_accy 25.03
2022-09-28 03:34:09,306 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.488,  Train_accy 23.81
2022-09-28 03:34:11,326 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.504,  Train_accy 25.76
2022-09-28 03:34:14,119 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.505,  Train_accy 23.32, Test_accy 53.97
2022-09-28 03:34:14,120 [foster.py] => do not weight align student!
2022-09-28 03:34:14,828 [foster.py] => darknet eval: 
2022-09-28 03:34:14,828 [foster.py] => CNN top1 curve: 53.97
2022-09-28 03:34:14,828 [foster.py] => CNN top5 curve: 97.14
2022-09-28 03:34:14,828 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 03:34:22,181 [foster.py] => Exemplar size: 260
2022-09-28 03:34:22,181 [trainer.py] => CNN: {'total': 67.62, 'old': 75.2, 'new': 40.58, 'base': 86.39, 'compound': 45.89}
2022-09-28 03:34:22,181 [trainer.py] => CNN top1 curve: [91.12, 77.24, 67.62]
2022-09-28 03:34:22,181 [trainer.py] => CNN base curve: [91.12, 89.35, 86.39]
2022-09-28 03:34:22,181 [trainer.py] => CNN old curve: [91.12, 89.35, 75.2]
2022-09-28 03:34:22,181 [trainer.py] => CNN new curve: [0, 50.65, 40.58]
2022-09-28 03:34:22,181 [trainer.py] => CNN compound curve: [0, 50.65, 45.89]
2022-09-28 03:34:22,181 [trainer.py] => NME: {'total': 71.75, 'old': 73.17, 'new': 66.67, 'base': 78.11, 'compound': 64.38}
2022-09-28 03:34:22,181 [trainer.py] => NME top1 curve: [88.17, 82.93, 71.75]
2022-09-28 03:34:22,181 [trainer.py] => NME base curve: [88.17, 86.39, 78.11]
2022-09-28 03:34:22,181 [trainer.py] => NME old curve: [88.17, 86.39, 73.17]
2022-09-28 03:34:22,181 [trainer.py] => NME new curve: [0, 75.32, 66.67]
2022-09-28 03:34:22,181 [trainer.py] => NME compound curve: [0, 75.32, 64.38]
2022-09-28 03:34:22,411 [foster.py] => Learning on 13-16
2022-09-28 03:34:22,412 [foster.py] => All params: 22384301
2022-09-28 03:34:22,412 [foster.py] => Trainable params: 11201120
2022-09-28 03:34:22,433 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 03:34:25,261 [foster.py] => Task 3, Epoch 1/34 => Loss 6.175, Loss_clf 2.251, Loss_fe 2.324, Loss_kd 1.300, Train_accy 36.75, Test_accy 39.63
2022-09-28 03:34:27,174 [foster.py] => Task 3, Epoch 2/34 => Loss 4.440, Loss_clf 1.116, Loss_fe 1.756, Loss_kd 1.274, Train_accy 39.80
2022-09-28 03:34:29,119 [foster.py] => Task 3, Epoch 3/34 => Loss 4.066, Loss_clf 0.964, Loss_fe 1.543, Loss_kd 1.267, Train_accy 40.47
2022-09-28 03:34:31,041 [foster.py] => Task 3, Epoch 4/34 => Loss 3.868, Loss_clf 0.916, Loss_fe 1.392, Loss_kd 1.267, Train_accy 39.23
2022-09-28 03:34:32,963 [foster.py] => Task 3, Epoch 5/34 => Loss 3.742, Loss_clf 0.880, Loss_fe 1.305, Loss_kd 1.264, Train_accy 40.47
2022-09-28 03:34:35,754 [foster.py] => Task 3, Epoch 6/34 => Loss 3.631, Loss_clf 0.864, Loss_fe 1.218, Loss_kd 1.259, Train_accy 39.23, Test_accy 55.59
2022-09-28 03:34:37,712 [foster.py] => Task 3, Epoch 7/34 => Loss 3.551, Loss_clf 0.829, Loss_fe 1.162, Loss_kd 1.268, Train_accy 41.49
2022-09-28 03:34:39,670 [foster.py] => Task 3, Epoch 8/34 => Loss 3.460, Loss_clf 0.807, Loss_fe 1.100, Loss_kd 1.262, Train_accy 40.25
2022-09-28 03:34:41,587 [foster.py] => Task 3, Epoch 9/34 => Loss 3.395, Loss_clf 0.786, Loss_fe 1.057, Loss_kd 1.261, Train_accy 42.28
2022-09-28 03:34:43,493 [foster.py] => Task 3, Epoch 10/34 => Loss 3.343, Loss_clf 0.768, Loss_fe 1.026, Loss_kd 1.259, Train_accy 42.39
2022-09-28 03:34:46,336 [foster.py] => Task 3, Epoch 11/34 => Loss 3.322, Loss_clf 0.769, Loss_fe 0.995, Loss_kd 1.266, Train_accy 43.74, Test_accy 56.91
2022-09-28 03:34:48,253 [foster.py] => Task 3, Epoch 12/34 => Loss 3.261, Loss_clf 0.750, Loss_fe 0.953, Loss_kd 1.266, Train_accy 43.07
2022-09-28 03:34:50,170 [foster.py] => Task 3, Epoch 13/34 => Loss 3.165, Loss_clf 0.702, Loss_fe 0.916, Loss_kd 1.257, Train_accy 43.86
2022-09-28 03:34:52,066 [foster.py] => Task 3, Epoch 14/34 => Loss 3.212, Loss_clf 0.730, Loss_fe 0.920, Loss_kd 1.269, Train_accy 44.64
2022-09-28 03:34:53,991 [foster.py] => Task 3, Epoch 15/34 => Loss 3.161, Loss_clf 0.712, Loss_fe 0.877, Loss_kd 1.277, Train_accy 46.79
2022-09-28 03:34:56,832 [foster.py] => Task 3, Epoch 16/34 => Loss 3.137, Loss_clf 0.709, Loss_fe 0.866, Loss_kd 1.269, Train_accy 44.98, Test_accy 57.45
2022-09-28 03:34:58,761 [foster.py] => Task 3, Epoch 17/34 => Loss 3.098, Loss_clf 0.691, Loss_fe 0.845, Loss_kd 1.270, Train_accy 45.55
2022-09-28 03:35:00,662 [foster.py] => Task 3, Epoch 18/34 => Loss 3.037, Loss_clf 0.662, Loss_fe 0.818, Loss_kd 1.265, Train_accy 46.56
2022-09-28 03:35:02,573 [foster.py] => Task 3, Epoch 19/34 => Loss 3.043, Loss_clf 0.680, Loss_fe 0.812, Loss_kd 1.260, Train_accy 45.21
2022-09-28 03:35:04,460 [foster.py] => Task 3, Epoch 20/34 => Loss 3.017, Loss_clf 0.662, Loss_fe 0.792, Loss_kd 1.270, Train_accy 46.11
2022-09-28 03:35:07,276 [foster.py] => Task 3, Epoch 21/34 => Loss 3.021, Loss_clf 0.668, Loss_fe 0.799, Loss_kd 1.262, Train_accy 46.56, Test_accy 57.18
2022-09-28 03:35:09,169 [foster.py] => Task 3, Epoch 22/34 => Loss 2.987, Loss_clf 0.652, Loss_fe 0.776, Loss_kd 1.267, Train_accy 48.48
2022-09-28 03:35:11,086 [foster.py] => Task 3, Epoch 23/34 => Loss 3.006, Loss_clf 0.656, Loss_fe 0.789, Loss_kd 1.269, Train_accy 46.34
2022-09-28 03:35:13,047 [foster.py] => Task 3, Epoch 24/34 => Loss 3.005, Loss_clf 0.651, Loss_fe 0.789, Loss_kd 1.272, Train_accy 45.66
2022-09-28 03:35:14,964 [foster.py] => Task 3, Epoch 25/34 => Loss 2.954, Loss_clf 0.634, Loss_fe 0.759, Loss_kd 1.269, Train_accy 48.03
2022-09-28 03:35:17,744 [foster.py] => Task 3, Epoch 26/34 => Loss 2.926, Loss_clf 0.626, Loss_fe 0.750, Loss_kd 1.258, Train_accy 48.03, Test_accy 57.18
2022-09-28 03:35:19,671 [foster.py] => Task 3, Epoch 27/34 => Loss 2.955, Loss_clf 0.629, Loss_fe 0.762, Loss_kd 1.271, Train_accy 48.25
2022-09-28 03:35:21,614 [foster.py] => Task 3, Epoch 28/34 => Loss 2.953, Loss_clf 0.626, Loss_fe 0.757, Loss_kd 1.276, Train_accy 49.15
2022-09-28 03:35:23,602 [foster.py] => Task 3, Epoch 29/34 => Loss 2.977, Loss_clf 0.639, Loss_fe 0.765, Loss_kd 1.278, Train_accy 46.79
2022-09-28 03:35:25,539 [foster.py] => Task 3, Epoch 30/34 => Loss 2.922, Loss_clf 0.624, Loss_fe 0.742, Loss_kd 1.264, Train_accy 49.27
2022-09-28 03:35:28,381 [foster.py] => Task 3, Epoch 31/34 => Loss 2.918, Loss_clf 0.621, Loss_fe 0.747, Loss_kd 1.259, Train_accy 46.67, Test_accy 56.91
2022-09-28 03:35:30,324 [foster.py] => Task 3, Epoch 32/34 => Loss 2.909, Loss_clf 0.611, Loss_fe 0.733, Loss_kd 1.272, Train_accy 47.80
2022-09-28 03:35:32,286 [foster.py] => Task 3, Epoch 33/34 => Loss 2.906, Loss_clf 0.613, Loss_fe 0.732, Loss_kd 1.268, Train_accy 47.58
2022-09-28 03:35:34,203 [foster.py] => Task 3, Epoch 34/34 => Loss 2.890, Loss_clf 0.605, Loss_fe 0.729, Loss_kd 1.264, Train_accy 49.61
2022-09-28 03:35:34,203 [foster.py] => do not weight align teacher!
2022-09-28 03:35:34,204 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 03:35:37,353 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.154,  Train_accy 18.83, Test_accy 45.21
2022-09-28 03:35:39,500 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.041,  Train_accy 19.05
2022-09-28 03:35:41,651 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 1.981,  Train_accy 19.73
2022-09-28 03:35:43,797 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 1.961,  Train_accy 18.60
2022-09-28 03:35:45,934 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.954,  Train_accy 19.95
2022-09-28 03:35:48,847 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.953,  Train_accy 19.17, Test_accy 47.34
2022-09-28 03:35:51,018 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.929,  Train_accy 19.95
2022-09-28 03:35:53,148 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.947,  Train_accy 20.29
2022-09-28 03:35:55,314 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.916,  Train_accy 19.28
2022-09-28 03:35:57,463 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.934,  Train_accy 20.41
2022-09-28 03:36:00,385 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.920,  Train_accy 19.84, Test_accy 48.14
2022-09-28 03:36:02,551 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.917,  Train_accy 20.41
2022-09-28 03:36:04,766 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.916,  Train_accy 19.95
2022-09-28 03:36:06,935 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.916,  Train_accy 20.07
2022-09-28 03:36:09,159 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.909,  Train_accy 20.74
2022-09-28 03:36:12,080 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.915,  Train_accy 20.29, Test_accy 50.00
2022-09-28 03:36:14,241 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.908,  Train_accy 20.29
2022-09-28 03:36:16,399 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.909,  Train_accy 20.41
2022-09-28 03:36:18,534 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.914,  Train_accy 20.18
2022-09-28 03:36:20,716 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.915,  Train_accy 20.29
2022-09-28 03:36:23,613 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.902,  Train_accy 20.52, Test_accy 50.27
2022-09-28 03:36:25,779 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.905,  Train_accy 21.20
2022-09-28 03:36:27,905 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.910,  Train_accy 21.20
2022-09-28 03:36:30,048 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.907,  Train_accy 21.42
2022-09-28 03:36:32,210 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.903,  Train_accy 21.20
2022-09-28 03:36:35,151 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.913,  Train_accy 20.29, Test_accy 50.80
2022-09-28 03:36:35,152 [foster.py] => do not weight align student!
2022-09-28 03:36:35,927 [foster.py] => darknet eval: 
2022-09-28 03:36:35,927 [foster.py] => CNN top1 curve: 50.8
2022-09-28 03:36:35,927 [foster.py] => CNN top5 curve: 92.02
2022-09-28 03:36:35,928 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 03:36:44,493 [foster.py] => Exemplar size: 320
2022-09-28 03:36:44,494 [trainer.py] => CNN: {'total': 57.45, 'old': 64.76, 'new': 19.67, 'base': 82.84, 'compound': 36.71}
2022-09-28 03:36:44,494 [trainer.py] => CNN top1 curve: [91.12, 77.24, 67.62, 57.45]
2022-09-28 03:36:44,494 [trainer.py] => CNN base curve: [91.12, 89.35, 86.39, 82.84]
2022-09-28 03:36:44,494 [trainer.py] => CNN old curve: [91.12, 89.35, 75.2, 64.76]
2022-09-28 03:36:44,494 [trainer.py] => CNN new curve: [0, 50.65, 40.58, 19.67]
2022-09-28 03:36:44,494 [trainer.py] => CNN compound curve: [0, 50.65, 45.89, 36.71]
2022-09-28 03:36:44,494 [trainer.py] => NME: {'total': 62.77, 'old': 68.25, 'new': 34.43, 'base': 73.37, 'compound': 54.11}
2022-09-28 03:36:44,494 [trainer.py] => NME top1 curve: [88.17, 82.93, 71.75, 62.77]
2022-09-28 03:36:44,494 [trainer.py] => NME base curve: [88.17, 86.39, 78.11, 73.37]
2022-09-28 03:36:44,494 [trainer.py] => NME old curve: [88.17, 86.39, 73.17, 68.25]
2022-09-28 03:36:44,494 [trainer.py] => NME new curve: [0, 75.32, 66.67, 34.43]
2022-09-28 03:36:44,494 [trainer.py] => NME compound curve: [0, 75.32, 64.38, 54.11]
2022-09-28 03:36:44,725 [foster.py] => Learning on 16-19
2022-09-28 03:36:44,725 [foster.py] => All params: 22390454
2022-09-28 03:36:44,726 [foster.py] => Trainable params: 11205734
2022-09-28 03:36:44,746 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 03:36:47,655 [foster.py] => Task 4, Epoch 1/34 => Loss 6.477, Loss_clf 2.015, Loss_fe 2.504, Loss_kd 1.648, Train_accy 41.16, Test_accy 44.47
2022-09-28 03:36:49,662 [foster.py] => Task 4, Epoch 2/34 => Loss 4.803, Loss_clf 1.039, Loss_fe 1.822, Loss_kd 1.635, Train_accy 36.63
2022-09-28 03:36:51,655 [foster.py] => Task 4, Epoch 3/34 => Loss 4.551, Loss_clf 0.973, Loss_fe 1.636, Loss_kd 1.635, Train_accy 42.11
2022-09-28 03:36:53,653 [foster.py] => Task 4, Epoch 4/34 => Loss 4.376, Loss_clf 0.938, Loss_fe 1.502, Loss_kd 1.630, Train_accy 42.11
2022-09-28 03:36:55,716 [foster.py] => Task 4, Epoch 5/34 => Loss 4.295, Loss_clf 0.926, Loss_fe 1.416, Loss_kd 1.644, Train_accy 39.79
2022-09-28 03:36:58,733 [foster.py] => Task 4, Epoch 6/34 => Loss 4.167, Loss_clf 0.895, Loss_fe 1.333, Loss_kd 1.633, Train_accy 40.11, Test_accy 48.16
2022-09-28 03:37:00,764 [foster.py] => Task 4, Epoch 7/34 => Loss 4.099, Loss_clf 0.889, Loss_fe 1.272, Loss_kd 1.631, Train_accy 41.47
2022-09-28 03:37:02,767 [foster.py] => Task 4, Epoch 8/34 => Loss 4.017, Loss_clf 0.865, Loss_fe 1.209, Loss_kd 1.636, Train_accy 41.68
2022-09-28 03:37:04,796 [foster.py] => Task 4, Epoch 9/34 => Loss 3.966, Loss_clf 0.847, Loss_fe 1.163, Loss_kd 1.647, Train_accy 43.16
2022-09-28 03:37:06,833 [foster.py] => Task 4, Epoch 10/34 => Loss 3.881, Loss_clf 0.821, Loss_fe 1.115, Loss_kd 1.638, Train_accy 42.84
2022-09-28 03:37:09,832 [foster.py] => Task 4, Epoch 11/34 => Loss 3.853, Loss_clf 0.825, Loss_fe 1.080, Loss_kd 1.642, Train_accy 42.21, Test_accy 49.77
2022-09-28 03:37:11,819 [foster.py] => Task 4, Epoch 12/34 => Loss 3.813, Loss_clf 0.823, Loss_fe 1.053, Loss_kd 1.631, Train_accy 41.47
2022-09-28 03:37:13,852 [foster.py] => Task 4, Epoch 13/34 => Loss 3.789, Loss_clf 0.803, Loss_fe 1.040, Loss_kd 1.639, Train_accy 39.68
2022-09-28 03:37:15,835 [foster.py] => Task 4, Epoch 14/34 => Loss 3.746, Loss_clf 0.803, Loss_fe 0.999, Loss_kd 1.637, Train_accy 44.00
2022-09-28 03:37:17,871 [foster.py] => Task 4, Epoch 15/34 => Loss 3.690, Loss_clf 0.765, Loss_fe 0.976, Loss_kd 1.642, Train_accy 43.89
2022-09-28 03:37:20,767 [foster.py] => Task 4, Epoch 16/34 => Loss 3.686, Loss_clf 0.768, Loss_fe 0.966, Loss_kd 1.644, Train_accy 44.32, Test_accy 50.46
2022-09-28 03:37:22,769 [foster.py] => Task 4, Epoch 17/34 => Loss 3.638, Loss_clf 0.751, Loss_fe 0.939, Loss_kd 1.641, Train_accy 46.00
2022-09-28 03:37:24,795 [foster.py] => Task 4, Epoch 18/34 => Loss 3.624, Loss_clf 0.754, Loss_fe 0.922, Loss_kd 1.640, Train_accy 45.26
2022-09-28 03:37:26,820 [foster.py] => Task 4, Epoch 19/34 => Loss 3.569, Loss_clf 0.726, Loss_fe 0.893, Loss_kd 1.642, Train_accy 44.95
2022-09-28 03:37:28,803 [foster.py] => Task 4, Epoch 20/34 => Loss 3.567, Loss_clf 0.719, Loss_fe 0.893, Loss_kd 1.647, Train_accy 45.05
2022-09-28 03:37:31,733 [foster.py] => Task 4, Epoch 21/34 => Loss 3.563, Loss_clf 0.726, Loss_fe 0.880, Loss_kd 1.647, Train_accy 46.84, Test_accy 52.07
2022-09-28 03:37:33,759 [foster.py] => Task 4, Epoch 22/34 => Loss 3.553, Loss_clf 0.720, Loss_fe 0.877, Loss_kd 1.646, Train_accy 43.68
2022-09-28 03:37:35,751 [foster.py] => Task 4, Epoch 23/34 => Loss 3.552, Loss_clf 0.726, Loss_fe 0.875, Loss_kd 1.643, Train_accy 44.95
2022-09-28 03:37:37,732 [foster.py] => Task 4, Epoch 24/34 => Loss 3.512, Loss_clf 0.704, Loss_fe 0.857, Loss_kd 1.643, Train_accy 47.68
2022-09-28 03:37:39,714 [foster.py] => Task 4, Epoch 25/34 => Loss 3.503, Loss_clf 0.706, Loss_fe 0.847, Loss_kd 1.642, Train_accy 46.11
2022-09-28 03:37:42,668 [foster.py] => Task 4, Epoch 26/34 => Loss 3.508, Loss_clf 0.703, Loss_fe 0.852, Loss_kd 1.645, Train_accy 46.63, Test_accy 51.84
2022-09-28 03:37:44,672 [foster.py] => Task 4, Epoch 27/34 => Loss 3.511, Loss_clf 0.706, Loss_fe 0.854, Loss_kd 1.643, Train_accy 45.26
2022-09-28 03:37:46,761 [foster.py] => Task 4, Epoch 28/34 => Loss 3.467, Loss_clf 0.683, Loss_fe 0.833, Loss_kd 1.642, Train_accy 46.84
2022-09-28 03:37:48,796 [foster.py] => Task 4, Epoch 29/34 => Loss 3.486, Loss_clf 0.700, Loss_fe 0.833, Loss_kd 1.645, Train_accy 44.74
2022-09-28 03:37:50,835 [foster.py] => Task 4, Epoch 30/34 => Loss 3.481, Loss_clf 0.688, Loss_fe 0.837, Loss_kd 1.648, Train_accy 46.11
2022-09-28 03:37:53,766 [foster.py] => Task 4, Epoch 31/34 => Loss 3.499, Loss_clf 0.693, Loss_fe 0.840, Loss_kd 1.656, Train_accy 45.47, Test_accy 51.38
2022-09-28 03:37:55,780 [foster.py] => Task 4, Epoch 32/34 => Loss 3.481, Loss_clf 0.693, Loss_fe 0.830, Loss_kd 1.648, Train_accy 47.37
2022-09-28 03:37:57,782 [foster.py] => Task 4, Epoch 33/34 => Loss 3.498, Loss_clf 0.701, Loss_fe 0.842, Loss_kd 1.646, Train_accy 46.63
2022-09-28 03:37:59,850 [foster.py] => Task 4, Epoch 34/34 => Loss 3.489, Loss_clf 0.688, Loss_fe 0.851, Loss_kd 1.642, Train_accy 44.84
2022-09-28 03:37:59,851 [foster.py] => do not weight align teacher!
2022-09-28 03:37:59,851 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 03:38:03,127 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.286,  Train_accy 18.21, Test_accy 45.85
2022-09-28 03:38:05,348 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.233,  Train_accy 19.68
2022-09-28 03:38:07,610 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.231,  Train_accy 20.63
2022-09-28 03:38:09,839 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.216,  Train_accy 20.42
2022-09-28 03:38:12,079 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.205,  Train_accy 20.53
2022-09-28 03:38:15,159 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.210,  Train_accy 20.74, Test_accy 45.39
2022-09-28 03:38:17,439 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.192,  Train_accy 20.21
2022-09-28 03:38:19,701 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.200,  Train_accy 21.47
2022-09-28 03:38:21,949 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.190,  Train_accy 20.84
2022-09-28 03:38:24,186 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.186,  Train_accy 21.05
2022-09-28 03:38:27,294 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.195,  Train_accy 20.32, Test_accy 46.31
2022-09-28 03:38:29,528 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.194,  Train_accy 20.84
2022-09-28 03:38:31,848 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.189,  Train_accy 21.05
2022-09-28 03:38:34,116 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.180,  Train_accy 21.37
2022-09-28 03:38:36,438 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.172,  Train_accy 20.53
2022-09-28 03:38:39,571 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.187,  Train_accy 20.32, Test_accy 46.08
2022-09-28 03:38:41,839 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.185,  Train_accy 20.95
2022-09-28 03:38:44,174 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.184,  Train_accy 21.16
2022-09-28 03:38:46,446 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.180,  Train_accy 20.95
2022-09-28 03:38:48,703 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.180,  Train_accy 21.79
2022-09-28 03:38:51,771 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.183,  Train_accy 21.58, Test_accy 46.08
2022-09-28 03:38:54,122 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.184,  Train_accy 21.26
2022-09-28 03:38:56,357 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.170,  Train_accy 20.95
2022-09-28 03:38:58,637 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.172,  Train_accy 21.26
2022-09-28 03:39:00,910 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.183,  Train_accy 20.00
2022-09-28 03:39:04,008 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.172,  Train_accy 21.26, Test_accy 46.31
2022-09-28 03:39:04,009 [foster.py] => do not weight align student!
2022-09-28 03:39:04,848 [foster.py] => darknet eval: 
2022-09-28 03:39:04,848 [foster.py] => CNN top1 curve: 46.31
2022-09-28 03:39:04,848 [foster.py] => CNN top5 curve: 85.71
2022-09-28 03:39:04,848 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 03:39:14,366 [foster.py] => Exemplar size: 380
2022-09-28 03:39:14,366 [trainer.py] => CNN: {'total': 51.61, 'old': 55.85, 'new': 24.14, 'base': 81.07, 'compound': 32.83}
2022-09-28 03:39:14,366 [trainer.py] => CNN top1 curve: [91.12, 77.24, 67.62, 57.45, 51.61]
2022-09-28 03:39:14,366 [trainer.py] => CNN base curve: [91.12, 89.35, 86.39, 82.84, 81.07]
2022-09-28 03:39:14,366 [trainer.py] => CNN old curve: [91.12, 89.35, 75.2, 64.76, 55.85]
2022-09-28 03:39:14,366 [trainer.py] => CNN new curve: [0, 50.65, 40.58, 19.67, 24.14]
2022-09-28 03:39:14,366 [trainer.py] => CNN compound curve: [0, 50.65, 45.89, 36.71, 32.83]
2022-09-28 03:39:14,366 [trainer.py] => NME: {'total': 55.07, 'old': 56.65, 'new': 44.83, 'base': 72.78, 'compound': 43.77}
2022-09-28 03:39:14,366 [trainer.py] => NME top1 curve: [88.17, 82.93, 71.75, 62.77, 55.07]
2022-09-28 03:39:14,366 [trainer.py] => NME base curve: [88.17, 86.39, 78.11, 73.37, 72.78]
2022-09-28 03:39:14,367 [trainer.py] => NME old curve: [88.17, 86.39, 73.17, 68.25, 56.65]
2022-09-28 03:39:14,367 [trainer.py] => NME new curve: [0, 75.32, 66.67, 34.43, 44.83]
2022-09-28 03:39:14,367 [trainer.py] => NME compound curve: [0, 75.32, 64.38, 54.11, 43.77]
2022-09-28 03:39:14,595 [foster.py] => Learning on 19-22
2022-09-28 03:39:14,596 [foster.py] => All params: 22396607
2022-09-28 03:39:14,596 [foster.py] => Trainable params: 11210348
2022-09-28 03:39:14,616 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 03:39:17,690 [foster.py] => Task 5, Epoch 1/34 => Loss 6.809, Loss_clf 2.218, Loss_fe 2.451, Loss_kd 1.848, Train_accy 36.31, Test_accy 44.36
2022-09-28 03:39:19,758 [foster.py] => Task 5, Epoch 2/34 => Loss 5.165, Loss_clf 1.128, Loss_fe 1.879, Loss_kd 1.863, Train_accy 34.70
2022-09-28 03:39:21,847 [foster.py] => Task 5, Epoch 3/34 => Loss 4.822, Loss_clf 0.999, Loss_fe 1.672, Loss_kd 1.858, Train_accy 37.51
2022-09-28 03:39:23,972 [foster.py] => Task 5, Epoch 4/34 => Loss 4.770, Loss_clf 1.008, Loss_fe 1.609, Loss_kd 1.860, Train_accy 38.72
2022-09-28 03:39:26,101 [foster.py] => Task 5, Epoch 5/34 => Loss 4.573, Loss_clf 0.942, Loss_fe 1.482, Loss_kd 1.856, Train_accy 38.52
2022-09-28 03:39:29,242 [foster.py] => Task 5, Epoch 6/34 => Loss 4.557, Loss_clf 0.979, Loss_fe 1.439, Loss_kd 1.848, Train_accy 39.92, Test_accy 45.35
2022-09-28 03:39:31,350 [foster.py] => Task 5, Epoch 7/34 => Loss 4.405, Loss_clf 0.915, Loss_fe 1.337, Loss_kd 1.859, Train_accy 40.52
2022-09-28 03:39:33,471 [foster.py] => Task 5, Epoch 8/34 => Loss 4.309, Loss_clf 0.883, Loss_fe 1.275, Loss_kd 1.857, Train_accy 42.63
2022-09-28 03:39:35,569 [foster.py] => Task 5, Epoch 9/34 => Loss 4.360, Loss_clf 0.933, Loss_fe 1.285, Loss_kd 1.850, Train_accy 42.03
2022-09-28 03:39:37,648 [foster.py] => Task 5, Epoch 10/34 => Loss 4.247, Loss_clf 0.882, Loss_fe 1.221, Loss_kd 1.852, Train_accy 41.52
2022-09-28 03:39:40,771 [foster.py] => Task 5, Epoch 11/34 => Loss 4.154, Loss_clf 0.841, Loss_fe 1.159, Loss_kd 1.860, Train_accy 41.42, Test_accy 47.52
2022-09-28 03:39:42,900 [foster.py] => Task 5, Epoch 12/34 => Loss 4.118, Loss_clf 0.844, Loss_fe 1.130, Loss_kd 1.852, Train_accy 41.93
2022-09-28 03:39:45,022 [foster.py] => Task 5, Epoch 13/34 => Loss 4.057, Loss_clf 0.810, Loss_fe 1.096, Loss_kd 1.857, Train_accy 43.23
2022-09-28 03:39:47,169 [foster.py] => Task 5, Epoch 14/34 => Loss 4.044, Loss_clf 0.796, Loss_fe 1.092, Loss_kd 1.861, Train_accy 43.73
2022-09-28 03:39:49,251 [foster.py] => Task 5, Epoch 15/34 => Loss 4.025, Loss_clf 0.806, Loss_fe 1.068, Loss_kd 1.858, Train_accy 42.73
2022-09-28 03:39:52,314 [foster.py] => Task 5, Epoch 16/34 => Loss 4.042, Loss_clf 0.825, Loss_fe 1.063, Loss_kd 1.860, Train_accy 44.93, Test_accy 48.91
2022-09-28 03:39:54,407 [foster.py] => Task 5, Epoch 17/34 => Loss 3.980, Loss_clf 0.794, Loss_fe 1.020, Loss_kd 1.871, Train_accy 43.83
2022-09-28 03:39:56,499 [foster.py] => Task 5, Epoch 18/34 => Loss 3.991, Loss_clf 0.815, Loss_fe 1.022, Loss_kd 1.861, Train_accy 44.33
2022-09-28 03:39:58,600 [foster.py] => Task 5, Epoch 19/34 => Loss 3.966, Loss_clf 0.802, Loss_fe 1.025, Loss_kd 1.847, Train_accy 43.23
2022-09-28 03:40:00,686 [foster.py] => Task 5, Epoch 20/34 => Loss 3.915, Loss_clf 0.771, Loss_fe 0.990, Loss_kd 1.860, Train_accy 41.62
2022-09-28 03:40:03,729 [foster.py] => Task 5, Epoch 21/34 => Loss 3.870, Loss_clf 0.774, Loss_fe 0.955, Loss_kd 1.850, Train_accy 44.63, Test_accy 48.91
2022-09-28 03:40:05,853 [foster.py] => Task 5, Epoch 22/34 => Loss 3.817, Loss_clf 0.740, Loss_fe 0.929, Loss_kd 1.855, Train_accy 47.34
2022-09-28 03:40:07,920 [foster.py] => Task 5, Epoch 23/34 => Loss 3.805, Loss_clf 0.722, Loss_fe 0.926, Loss_kd 1.863, Train_accy 46.04
2022-09-28 03:40:10,047 [foster.py] => Task 5, Epoch 24/34 => Loss 3.833, Loss_clf 0.740, Loss_fe 0.937, Loss_kd 1.862, Train_accy 45.74
2022-09-28 03:40:12,125 [foster.py] => Task 5, Epoch 25/34 => Loss 3.822, Loss_clf 0.735, Loss_fe 0.922, Loss_kd 1.870, Train_accy 45.04
2022-09-28 03:40:15,261 [foster.py] => Task 5, Epoch 26/34 => Loss 3.907, Loss_clf 0.778, Loss_fe 0.980, Loss_kd 1.856, Train_accy 45.04, Test_accy 49.11
2022-09-28 03:40:17,334 [foster.py] => Task 5, Epoch 27/34 => Loss 3.775, Loss_clf 0.719, Loss_fe 0.902, Loss_kd 1.860, Train_accy 45.04
2022-09-28 03:40:19,456 [foster.py] => Task 5, Epoch 28/34 => Loss 3.826, Loss_clf 0.741, Loss_fe 0.930, Loss_kd 1.861, Train_accy 46.04
2022-09-28 03:40:21,555 [foster.py] => Task 5, Epoch 29/34 => Loss 3.845, Loss_clf 0.740, Loss_fe 0.942, Loss_kd 1.868, Train_accy 47.54
2022-09-28 03:40:23,661 [foster.py] => Task 5, Epoch 30/34 => Loss 3.794, Loss_clf 0.732, Loss_fe 0.913, Loss_kd 1.857, Train_accy 46.14
2022-09-28 03:40:26,784 [foster.py] => Task 5, Epoch 31/34 => Loss 3.819, Loss_clf 0.743, Loss_fe 0.923, Loss_kd 1.859, Train_accy 45.04, Test_accy 49.11
2022-09-28 03:40:28,875 [foster.py] => Task 5, Epoch 32/34 => Loss 3.804, Loss_clf 0.727, Loss_fe 0.920, Loss_kd 1.863, Train_accy 45.44
2022-09-28 03:40:30,970 [foster.py] => Task 5, Epoch 33/34 => Loss 3.821, Loss_clf 0.742, Loss_fe 0.924, Loss_kd 1.862, Train_accy 46.64
2022-09-28 03:40:33,083 [foster.py] => Task 5, Epoch 34/34 => Loss 3.863, Loss_clf 0.765, Loss_fe 0.957, Loss_kd 1.850, Train_accy 45.44
2022-09-28 03:40:33,083 [foster.py] => do not weight align teacher!
2022-09-28 03:40:33,084 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 03:40:36,544 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.453,  Train_accy 20.16, Test_accy 40.00
2022-09-28 03:40:38,911 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.418,  Train_accy 20.26
2022-09-28 03:40:41,253 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.398,  Train_accy 21.26
2022-09-28 03:40:43,584 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.385,  Train_accy 20.36
2022-09-28 03:40:45,924 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.366,  Train_accy 21.46
2022-09-28 03:40:49,111 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.370,  Train_accy 20.96, Test_accy 40.40
2022-09-28 03:40:51,445 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.355,  Train_accy 20.16
2022-09-28 03:40:53,795 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.348,  Train_accy 20.56
2022-09-28 03:40:56,165 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.340,  Train_accy 21.36
2022-09-28 03:40:58,511 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.343,  Train_accy 21.77
2022-09-28 03:41:01,747 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.323,  Train_accy 21.87, Test_accy 41.39
2022-09-28 03:41:04,144 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.331,  Train_accy 20.36
2022-09-28 03:41:06,507 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.326,  Train_accy 21.16
2022-09-28 03:41:08,868 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.323,  Train_accy 22.57
2022-09-28 03:41:11,198 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.345,  Train_accy 22.17
2022-09-28 03:41:14,414 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.333,  Train_accy 21.77, Test_accy 41.98
2022-09-28 03:41:16,784 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.330,  Train_accy 21.87
2022-09-28 03:41:19,123 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.321,  Train_accy 23.07
2022-09-28 03:41:21,469 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.314,  Train_accy 22.67
2022-09-28 03:41:23,831 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.323,  Train_accy 23.37
2022-09-28 03:41:27,067 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.327,  Train_accy 22.27, Test_accy 42.57
2022-09-28 03:41:29,475 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.318,  Train_accy 22.67
2022-09-28 03:41:31,810 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.306,  Train_accy 22.57
2022-09-28 03:41:34,191 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.326,  Train_accy 22.37
2022-09-28 03:41:36,554 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.311,  Train_accy 21.97
2022-09-28 03:41:39,832 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.323,  Train_accy 22.07, Test_accy 41.58
2022-09-28 03:41:39,832 [foster.py] => do not weight align student!
2022-09-28 03:41:40,683 [foster.py] => darknet eval: 
2022-09-28 03:41:40,683 [foster.py] => CNN top1 curve: 41.58
2022-09-28 03:41:40,683 [foster.py] => CNN top5 curve: 81.58
2022-09-28 03:41:40,683 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 03:41:51,317 [foster.py] => Exemplar size: 440
2022-09-28 03:41:51,317 [trainer.py] => CNN: {'total': 49.9, 'old': 53.23, 'new': 29.58, 'base': 76.33, 'compound': 36.61}
2022-09-28 03:41:51,317 [trainer.py] => CNN top1 curve: [91.12, 77.24, 67.62, 57.45, 51.61, 49.9]
2022-09-28 03:41:51,317 [trainer.py] => CNN base curve: [91.12, 89.35, 86.39, 82.84, 81.07, 76.33]
2022-09-28 03:41:51,317 [trainer.py] => CNN old curve: [91.12, 89.35, 75.2, 64.76, 55.85, 53.23]
2022-09-28 03:41:51,317 [trainer.py] => CNN new curve: [0, 50.65, 40.58, 19.67, 24.14, 29.58]
2022-09-28 03:41:51,317 [trainer.py] => CNN compound curve: [0, 50.65, 45.89, 36.71, 32.83, 36.61]
2022-09-28 03:41:51,317 [trainer.py] => NME: {'total': 52.67, 'old': 53.69, 'new': 46.48, 'base': 70.41, 'compound': 43.75}
2022-09-28 03:41:51,317 [trainer.py] => NME top1 curve: [88.17, 82.93, 71.75, 62.77, 55.07, 52.67]
2022-09-28 03:41:51,317 [trainer.py] => NME base curve: [88.17, 86.39, 78.11, 73.37, 72.78, 70.41]
2022-09-28 03:41:51,317 [trainer.py] => NME old curve: [88.17, 86.39, 73.17, 68.25, 56.65, 53.69]
2022-09-28 03:41:51,317 [trainer.py] => NME new curve: [0, 75.32, 66.67, 34.43, 44.83, 46.48]
2022-09-28 03:41:51,317 [trainer.py] => NME compound curve: [0, 75.32, 64.38, 54.11, 43.77, 43.75]
2022-09-28 03:41:51,319 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 03:41:51,319 [trainer.py] => prefix: cil
2022-09-28 03:41:51,319 [trainer.py] => dataset: CFEE
2022-09-28 03:41:51,319 [trainer.py] => memory_size: 2000
2022-09-28 03:41:51,319 [trainer.py] => memory_per_class: 20
2022-09-28 03:41:51,319 [trainer.py] => fixed_memory: True
2022-09-28 03:41:51,319 [trainer.py] => shuffle: True
2022-09-28 03:41:51,319 [trainer.py] => init_cls: 7
2022-09-28 03:41:51,319 [trainer.py] => increment: 3
2022-09-28 03:41:51,319 [trainer.py] => model_name: foster
2022-09-28 03:41:51,319 [trainer.py] => convnet_type: resnet18
2022-09-28 03:41:51,319 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 03:41:51,319 [trainer.py] => seed: 1993
2022-09-28 03:41:51,319 [trainer.py] => beta1: 0.96
2022-09-28 03:41:51,319 [trainer.py] => beta2: 0.97
2022-09-28 03:41:51,319 [trainer.py] => oofc: ft
2022-09-28 03:41:51,319 [trainer.py] => is_teacher_wa: False
2022-09-28 03:41:51,319 [trainer.py] => is_student_wa: False
2022-09-28 03:41:51,319 [trainer.py] => lambda_okd: 1
2022-09-28 03:41:51,319 [trainer.py] => wa_value: 1
2022-09-28 03:41:51,319 [trainer.py] => init_epochs: 40
2022-09-28 03:41:51,319 [trainer.py] => init_lr: 0.01
2022-09-28 03:41:51,319 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 03:41:51,319 [trainer.py] => boosting_epochs: 34
2022-09-28 03:41:51,319 [trainer.py] => compression_epochs: 26
2022-09-28 03:41:51,319 [trainer.py] => lr: 0.001
2022-09-28 03:41:51,319 [trainer.py] => batch_size: 32
2022-09-28 03:41:51,319 [trainer.py] => weight_decay: 0.0005
2022-09-28 03:41:51,320 [trainer.py] => num_workers: 8
2022-09-28 03:41:51,320 [trainer.py] => T: 2
2022-09-28 03:41:51,320 [trainer.py] => nb_runs: 3
2022-09-28 03:41:51,320 [trainer.py] => fold: 10
2022-09-28 03:41:51,320 [data.py] => ========== Fold:6 ==========
2022-09-28 03:41:51,325 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 8, 15, 13, 17, 9, 11, 19, 21, 14, 10, 18, 12, 7, 16]
2022-09-28 03:41:51,538 [foster.py] => Learning on 0-7
2022-09-28 03:41:51,538 [foster.py] => All params: 11183694
2022-09-28 03:41:51,538 [foster.py] => Trainable params: 11183694
2022-09-28 03:41:53,949 [foster.py] => Task 0, Epoch 1/40 => Loss 1.357, Train_accy 49.45
2022-09-28 03:41:56,951 [foster.py] => Task 0, Epoch 2/40 => Loss 0.555, Train_accy 81.26, Test_accy 88.20
2022-09-28 03:41:59,910 [foster.py] => Task 0, Epoch 3/40 => Loss 0.372, Train_accy 87.00, Test_accy 85.71
2022-09-28 03:42:02,881 [foster.py] => Task 0, Epoch 4/40 => Loss 0.300, Train_accy 89.83, Test_accy 85.09
2022-09-28 03:42:05,905 [foster.py] => Task 0, Epoch 5/40 => Loss 0.222, Train_accy 92.95, Test_accy 87.58
2022-09-28 03:42:08,271 [foster.py] => Task 0, Epoch 6/40 => Loss 0.188, Train_accy 93.91
2022-09-28 03:42:11,289 [foster.py] => Task 0, Epoch 7/40 => Loss 0.168, Train_accy 94.40, Test_accy 86.34
2022-09-28 03:42:14,321 [foster.py] => Task 0, Epoch 8/40 => Loss 0.152, Train_accy 95.16, Test_accy 87.58
2022-09-28 03:42:17,341 [foster.py] => Task 0, Epoch 9/40 => Loss 0.129, Train_accy 96.06, Test_accy 86.96
2022-09-28 03:42:20,380 [foster.py] => Task 0, Epoch 10/40 => Loss 0.105, Train_accy 96.47, Test_accy 88.20
2022-09-28 03:42:22,760 [foster.py] => Task 0, Epoch 11/40 => Loss 0.082, Train_accy 97.58
2022-09-28 03:42:25,725 [foster.py] => Task 0, Epoch 12/40 => Loss 0.083, Train_accy 97.65, Test_accy 91.93
2022-09-28 03:42:28,710 [foster.py] => Task 0, Epoch 13/40 => Loss 0.085, Train_accy 97.51, Test_accy 86.34
2022-09-28 03:42:31,699 [foster.py] => Task 0, Epoch 14/40 => Loss 0.061, Train_accy 98.48, Test_accy 87.58
2022-09-28 03:42:34,753 [foster.py] => Task 0, Epoch 15/40 => Loss 0.061, Train_accy 98.69, Test_accy 88.82
2022-09-28 03:42:37,131 [foster.py] => Task 0, Epoch 16/40 => Loss 0.084, Train_accy 97.72
2022-09-28 03:42:40,114 [foster.py] => Task 0, Epoch 17/40 => Loss 0.059, Train_accy 98.34, Test_accy 88.82
2022-09-28 03:42:43,182 [foster.py] => Task 0, Epoch 18/40 => Loss 0.050, Train_accy 98.62, Test_accy 88.82
2022-09-28 03:42:46,178 [foster.py] => Task 0, Epoch 19/40 => Loss 0.053, Train_accy 98.76, Test_accy 87.58
2022-09-28 03:42:49,177 [foster.py] => Task 0, Epoch 20/40 => Loss 0.035, Train_accy 99.03, Test_accy 87.58
2022-09-28 03:42:51,568 [foster.py] => Task 0, Epoch 21/40 => Loss 0.037, Train_accy 99.38
2022-09-28 03:42:54,551 [foster.py] => Task 0, Epoch 22/40 => Loss 0.027, Train_accy 99.38, Test_accy 89.44
2022-09-28 03:42:57,612 [foster.py] => Task 0, Epoch 23/40 => Loss 0.030, Train_accy 99.31, Test_accy 89.44
2022-09-28 03:43:00,660 [foster.py] => Task 0, Epoch 24/40 => Loss 0.017, Train_accy 99.93, Test_accy 90.06
2022-09-28 03:43:03,658 [foster.py] => Task 0, Epoch 25/40 => Loss 0.024, Train_accy 99.52, Test_accy 88.82
2022-09-28 03:43:06,030 [foster.py] => Task 0, Epoch 26/40 => Loss 0.034, Train_accy 99.45
2022-09-28 03:43:08,986 [foster.py] => Task 0, Epoch 27/40 => Loss 0.031, Train_accy 99.03, Test_accy 89.44
2022-09-28 03:43:12,019 [foster.py] => Task 0, Epoch 28/40 => Loss 0.018, Train_accy 99.79, Test_accy 88.82
2022-09-28 03:43:14,968 [foster.py] => Task 0, Epoch 29/40 => Loss 0.015, Train_accy 99.86, Test_accy 90.06
2022-09-28 03:43:17,926 [foster.py] => Task 0, Epoch 30/40 => Loss 0.019, Train_accy 99.72, Test_accy 88.82
2022-09-28 03:43:20,303 [foster.py] => Task 0, Epoch 31/40 => Loss 0.029, Train_accy 99.79
2022-09-28 03:43:23,306 [foster.py] => Task 0, Epoch 32/40 => Loss 0.018, Train_accy 99.79, Test_accy 88.82
2022-09-28 03:43:26,288 [foster.py] => Task 0, Epoch 33/40 => Loss 0.014, Train_accy 99.86, Test_accy 89.44
2022-09-28 03:43:29,271 [foster.py] => Task 0, Epoch 34/40 => Loss 0.019, Train_accy 99.72, Test_accy 88.20
2022-09-28 03:43:32,243 [foster.py] => Task 0, Epoch 35/40 => Loss 0.016, Train_accy 99.79, Test_accy 88.20
2022-09-28 03:43:34,648 [foster.py] => Task 0, Epoch 36/40 => Loss 0.015, Train_accy 99.79
2022-09-28 03:43:37,610 [foster.py] => Task 0, Epoch 37/40 => Loss 0.025, Train_accy 99.86, Test_accy 89.44
2022-09-28 03:43:40,585 [foster.py] => Task 0, Epoch 38/40 => Loss 0.020, Train_accy 99.86, Test_accy 88.82
2022-09-28 03:43:43,577 [foster.py] => Task 0, Epoch 39/40 => Loss 0.017, Train_accy 99.79, Test_accy 90.68
2022-09-28 03:43:46,565 [foster.py] => Task 0, Epoch 40/40 => Loss 0.016, Train_accy 99.72, Test_accy 89.44
2022-09-28 03:43:46,565 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 03:43:53,469 [foster.py] => Exemplar size: 140
2022-09-28 03:43:53,469 [trainer.py] => CNN: {'total': 89.44, 'old': 89.44, 'new': 0, 'base': 89.44, 'compound': 0}
2022-09-28 03:43:53,469 [trainer.py] => CNN top1 curve: [89.44]
2022-09-28 03:43:53,469 [trainer.py] => CNN base curve: [89.44]
2022-09-28 03:43:53,469 [trainer.py] => CNN old curve: [89.44]
2022-09-28 03:43:53,469 [trainer.py] => CNN new curve: [0]
2022-09-28 03:43:53,469 [trainer.py] => CNN compound curve: [0]
2022-09-28 03:43:53,469 [trainer.py] => NME: {'total': 87.58, 'old': 87.58, 'new': 0, 'base': 87.58, 'compound': 0}
2022-09-28 03:43:53,469 [trainer.py] => NME top1 curve: [87.58]
2022-09-28 03:43:53,470 [trainer.py] => NME base curve: [87.58]
2022-09-28 03:43:53,470 [trainer.py] => NME old curve: [87.58]
2022-09-28 03:43:53,470 [trainer.py] => NME new curve: [0]
2022-09-28 03:43:53,470 [trainer.py] => NME compound curve: [0]
2022-09-28 03:43:53,698 [foster.py] => Learning on 7-10
2022-09-28 03:43:53,698 [foster.py] => All params: 22371995
2022-09-28 03:43:53,698 [foster.py] => Trainable params: 11191892
2022-09-28 03:43:53,718 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 03:43:56,194 [foster.py] => Task 1, Epoch 1/34 => Loss 4.892, Loss_clf 2.172, Loss_fe 2.015, Loss_kd 0.493, Train_accy 40.82, Test_accy 75.32
2022-09-28 03:43:57,889 [foster.py] => Task 1, Epoch 2/34 => Loss 2.509, Loss_clf 0.649, Loss_fe 1.141, Loss_kd 0.503, Train_accy 80.98
2022-09-28 03:43:59,639 [foster.py] => Task 1, Epoch 3/34 => Loss 1.972, Loss_clf 0.374, Loss_fe 0.923, Loss_kd 0.473, Train_accy 53.24
2022-09-28 03:44:01,413 [foster.py] => Task 1, Epoch 4/34 => Loss 1.799, Loss_clf 0.314, Loss_fe 0.801, Loss_kd 0.479, Train_accy 56.80
2022-09-28 03:44:03,144 [foster.py] => Task 1, Epoch 5/34 => Loss 1.698, Loss_clf 0.297, Loss_fe 0.718, Loss_kd 0.478, Train_accy 56.54
2022-09-28 03:44:05,610 [foster.py] => Task 1, Epoch 6/34 => Loss 1.577, Loss_clf 0.267, Loss_fe 0.643, Loss_kd 0.467, Train_accy 57.33, Test_accy 71.43
2022-09-28 03:44:07,394 [foster.py] => Task 1, Epoch 7/34 => Loss 1.523, Loss_clf 0.265, Loss_fe 0.596, Loss_kd 0.464, Train_accy 59.18
2022-09-28 03:44:09,158 [foster.py] => Task 1, Epoch 8/34 => Loss 1.473, Loss_clf 0.251, Loss_fe 0.539, Loss_kd 0.478, Train_accy 60.11
2022-09-28 03:44:10,870 [foster.py] => Task 1, Epoch 9/34 => Loss 1.438, Loss_clf 0.250, Loss_fe 0.513, Loss_kd 0.473, Train_accy 58.92
2022-09-28 03:44:12,610 [foster.py] => Task 1, Epoch 10/34 => Loss 1.351, Loss_clf 0.219, Loss_fe 0.461, Loss_kd 0.469, Train_accy 59.97
2022-09-28 03:44:15,048 [foster.py] => Task 1, Epoch 11/34 => Loss 1.373, Loss_clf 0.230, Loss_fe 0.469, Loss_kd 0.472, Train_accy 63.67, Test_accy 74.03
2022-09-28 03:44:16,793 [foster.py] => Task 1, Epoch 12/34 => Loss 1.359, Loss_clf 0.232, Loss_fe 0.446, Loss_kd 0.477, Train_accy 64.46
2022-09-28 03:44:18,565 [foster.py] => Task 1, Epoch 13/34 => Loss 1.299, Loss_clf 0.206, Loss_fe 0.410, Loss_kd 0.478, Train_accy 62.35
2022-09-28 03:44:20,287 [foster.py] => Task 1, Epoch 14/34 => Loss 1.296, Loss_clf 0.212, Loss_fe 0.413, Loss_kd 0.470, Train_accy 62.48
2022-09-28 03:44:22,014 [foster.py] => Task 1, Epoch 15/34 => Loss 1.264, Loss_clf 0.209, Loss_fe 0.376, Loss_kd 0.476, Train_accy 62.22
2022-09-28 03:44:24,559 [foster.py] => Task 1, Epoch 16/34 => Loss 1.270, Loss_clf 0.213, Loss_fe 0.381, Loss_kd 0.473, Train_accy 62.62, Test_accy 74.89
2022-09-28 03:44:26,296 [foster.py] => Task 1, Epoch 17/34 => Loss 1.205, Loss_clf 0.188, Loss_fe 0.343, Loss_kd 0.471, Train_accy 62.88
2022-09-28 03:44:28,045 [foster.py] => Task 1, Epoch 18/34 => Loss 1.171, Loss_clf 0.178, Loss_fe 0.337, Loss_kd 0.460, Train_accy 61.69
2022-09-28 03:44:29,777 [foster.py] => Task 1, Epoch 19/34 => Loss 1.188, Loss_clf 0.184, Loss_fe 0.332, Loss_kd 0.470, Train_accy 62.75
2022-09-28 03:44:31,518 [foster.py] => Task 1, Epoch 20/34 => Loss 1.161, Loss_clf 0.170, Loss_fe 0.318, Loss_kd 0.471, Train_accy 64.86
2022-09-28 03:44:33,967 [foster.py] => Task 1, Epoch 21/34 => Loss 1.196, Loss_clf 0.186, Loss_fe 0.336, Loss_kd 0.471, Train_accy 66.31, Test_accy 75.32
2022-09-28 03:44:35,718 [foster.py] => Task 1, Epoch 22/34 => Loss 1.164, Loss_clf 0.175, Loss_fe 0.316, Loss_kd 0.471, Train_accy 65.13
2022-09-28 03:44:37,464 [foster.py] => Task 1, Epoch 23/34 => Loss 1.198, Loss_clf 0.195, Loss_fe 0.330, Loss_kd 0.471, Train_accy 64.60
2022-09-28 03:44:39,198 [foster.py] => Task 1, Epoch 24/34 => Loss 1.185, Loss_clf 0.188, Loss_fe 0.327, Loss_kd 0.469, Train_accy 65.13
2022-09-28 03:44:40,943 [foster.py] => Task 1, Epoch 25/34 => Loss 1.136, Loss_clf 0.166, Loss_fe 0.293, Loss_kd 0.474, Train_accy 66.84
2022-09-28 03:44:43,444 [foster.py] => Task 1, Epoch 26/34 => Loss 1.147, Loss_clf 0.173, Loss_fe 0.300, Loss_kd 0.472, Train_accy 64.33, Test_accy 75.32
2022-09-28 03:44:45,145 [foster.py] => Task 1, Epoch 27/34 => Loss 1.116, Loss_clf 0.159, Loss_fe 0.289, Loss_kd 0.468, Train_accy 63.14
2022-09-28 03:44:46,886 [foster.py] => Task 1, Epoch 28/34 => Loss 1.139, Loss_clf 0.161, Loss_fe 0.297, Loss_kd 0.477, Train_accy 66.71
2022-09-28 03:44:48,600 [foster.py] => Task 1, Epoch 29/34 => Loss 1.157, Loss_clf 0.167, Loss_fe 0.304, Loss_kd 0.480, Train_accy 65.39
2022-09-28 03:44:50,321 [foster.py] => Task 1, Epoch 30/34 => Loss 1.136, Loss_clf 0.169, Loss_fe 0.283, Loss_kd 0.479, Train_accy 67.24
2022-09-28 03:44:52,787 [foster.py] => Task 1, Epoch 31/34 => Loss 1.136, Loss_clf 0.172, Loss_fe 0.294, Loss_kd 0.469, Train_accy 65.39, Test_accy 75.76
2022-09-28 03:44:54,528 [foster.py] => Task 1, Epoch 32/34 => Loss 1.150, Loss_clf 0.165, Loss_fe 0.298, Loss_kd 0.481, Train_accy 66.45
2022-09-28 03:44:56,263 [foster.py] => Task 1, Epoch 33/34 => Loss 1.108, Loss_clf 0.158, Loss_fe 0.282, Loss_kd 0.468, Train_accy 64.07
2022-09-28 03:44:58,005 [foster.py] => Task 1, Epoch 34/34 => Loss 1.130, Loss_clf 0.164, Loss_fe 0.297, Loss_kd 0.469, Train_accy 65.65
2022-09-28 03:44:58,005 [foster.py] => do not weight align teacher!
2022-09-28 03:44:58,006 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 03:45:00,817 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.608,  Train_accy 17.70, Test_accy 61.47
2022-09-28 03:45:02,717 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.479,  Train_accy 18.36
2022-09-28 03:45:04,615 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.373,  Train_accy 18.63
2022-09-28 03:45:06,528 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.330,  Train_accy 19.15
2022-09-28 03:45:08,417 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.303,  Train_accy 20.34
2022-09-28 03:45:10,988 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.295,  Train_accy 22.19, Test_accy 64.94
2022-09-28 03:45:12,890 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.270,  Train_accy 22.72
2022-09-28 03:45:14,833 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.259,  Train_accy 24.31
2022-09-28 03:45:16,743 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.252,  Train_accy 24.04
2022-09-28 03:45:18,643 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.238,  Train_accy 23.78
2022-09-28 03:45:21,234 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.234,  Train_accy 25.63, Test_accy 67.10
2022-09-28 03:45:23,177 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.238,  Train_accy 27.34
2022-09-28 03:45:25,126 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.230,  Train_accy 27.48
2022-09-28 03:45:27,097 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.239,  Train_accy 28.67
2022-09-28 03:45:28,985 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.235,  Train_accy 27.74
2022-09-28 03:45:31,655 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.236,  Train_accy 29.06, Test_accy 68.40
2022-09-28 03:45:33,599 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.215,  Train_accy 29.46
2022-09-28 03:45:35,518 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.226,  Train_accy 29.19
2022-09-28 03:45:37,463 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.216,  Train_accy 28.93
2022-09-28 03:45:39,417 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.218,  Train_accy 29.06
2022-09-28 03:45:42,034 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.231,  Train_accy 28.67, Test_accy 68.83
2022-09-28 03:45:43,931 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.214,  Train_accy 30.91
2022-09-28 03:45:45,868 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.213,  Train_accy 30.12
2022-09-28 03:45:47,792 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.211,  Train_accy 28.80
2022-09-28 03:45:49,727 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.225,  Train_accy 31.70
2022-09-28 03:45:52,291 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.218,  Train_accy 29.72, Test_accy 68.83
2022-09-28 03:45:52,292 [foster.py] => do not weight align student!
2022-09-28 03:45:52,958 [foster.py] => darknet eval: 
2022-09-28 03:45:52,959 [foster.py] => CNN top1 curve: 68.83
2022-09-28 03:45:52,959 [foster.py] => CNN top5 curve: 99.13
2022-09-28 03:45:52,959 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 03:45:59,429 [foster.py] => Exemplar size: 200
2022-09-28 03:45:59,429 [trainer.py] => CNN: {'total': 76.19, 'old': 86.34, 'new': 52.86, 'base': 86.34, 'compound': 52.86}
2022-09-28 03:45:59,429 [trainer.py] => CNN top1 curve: [89.44, 76.19]
2022-09-28 03:45:59,429 [trainer.py] => CNN base curve: [89.44, 86.34]
2022-09-28 03:45:59,429 [trainer.py] => CNN old curve: [89.44, 86.34]
2022-09-28 03:45:59,429 [trainer.py] => CNN new curve: [0, 52.86]
2022-09-28 03:45:59,429 [trainer.py] => CNN compound curve: [0, 52.86]
2022-09-28 03:45:59,429 [trainer.py] => NME: {'total': 82.25, 'old': 83.85, 'new': 78.57, 'base': 83.85, 'compound': 78.57}
2022-09-28 03:45:59,429 [trainer.py] => NME top1 curve: [87.58, 82.25]
2022-09-28 03:45:59,429 [trainer.py] => NME base curve: [87.58, 83.85]
2022-09-28 03:45:59,429 [trainer.py] => NME old curve: [87.58, 83.85]
2022-09-28 03:45:59,429 [trainer.py] => NME new curve: [0, 78.57]
2022-09-28 03:45:59,429 [trainer.py] => NME compound curve: [0, 78.57]
2022-09-28 03:45:59,658 [foster.py] => Learning on 10-13
2022-09-28 03:45:59,659 [foster.py] => All params: 22378148
2022-09-28 03:45:59,659 [foster.py] => Trainable params: 11196506
2022-09-28 03:45:59,679 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 03:46:02,282 [foster.py] => Task 2, Epoch 1/34 => Loss 5.674, Loss_clf 2.195, Loss_fe 2.330, Loss_kd 0.884, Train_accy 41.20, Test_accy 52.16
2022-09-28 03:46:04,098 [foster.py] => Task 2, Epoch 2/34 => Loss 3.330, Loss_clf 0.768, Loss_fe 1.425, Loss_kd 0.875, Train_accy 57.70
2022-09-28 03:46:05,891 [foster.py] => Task 2, Epoch 3/34 => Loss 2.859, Loss_clf 0.564, Loss_fe 1.165, Loss_kd 0.869, Train_accy 47.31
2022-09-28 03:46:07,711 [foster.py] => Task 2, Epoch 4/34 => Loss 2.639, Loss_clf 0.505, Loss_fe 1.014, Loss_kd 0.861, Train_accy 46.82
2022-09-28 03:46:09,544 [foster.py] => Task 2, Epoch 5/34 => Loss 2.568, Loss_clf 0.498, Loss_fe 0.942, Loss_kd 0.867, Train_accy 50.49
2022-09-28 03:46:12,168 [foster.py] => Task 2, Epoch 6/34 => Loss 2.466, Loss_clf 0.487, Loss_fe 0.860, Loss_kd 0.861, Train_accy 47.31, Test_accy 64.78
2022-09-28 03:46:13,963 [foster.py] => Task 2, Epoch 7/34 => Loss 2.358, Loss_clf 0.455, Loss_fe 0.793, Loss_kd 0.854, Train_accy 47.80
2022-09-28 03:46:15,754 [foster.py] => Task 2, Epoch 8/34 => Loss 2.319, Loss_clf 0.447, Loss_fe 0.755, Loss_kd 0.859, Train_accy 48.90
2022-09-28 03:46:17,602 [foster.py] => Task 2, Epoch 9/34 => Loss 2.259, Loss_clf 0.433, Loss_fe 0.697, Loss_kd 0.869, Train_accy 48.53
2022-09-28 03:46:19,407 [foster.py] => Task 2, Epoch 10/34 => Loss 2.209, Loss_clf 0.418, Loss_fe 0.669, Loss_kd 0.863, Train_accy 48.17
2022-09-28 03:46:22,050 [foster.py] => Task 2, Epoch 11/34 => Loss 2.158, Loss_clf 0.396, Loss_fe 0.642, Loss_kd 0.861, Train_accy 48.53, Test_accy 64.12
2022-09-28 03:46:23,925 [foster.py] => Task 2, Epoch 12/34 => Loss 2.168, Loss_clf 0.409, Loss_fe 0.635, Loss_kd 0.865, Train_accy 48.41
2022-09-28 03:46:25,762 [foster.py] => Task 2, Epoch 13/34 => Loss 2.066, Loss_clf 0.362, Loss_fe 0.583, Loss_kd 0.862, Train_accy 50.00
2022-09-28 03:46:27,607 [foster.py] => Task 2, Epoch 14/34 => Loss 2.069, Loss_clf 0.384, Loss_fe 0.574, Loss_kd 0.855, Train_accy 48.66
2022-09-28 03:46:29,411 [foster.py] => Task 2, Epoch 15/34 => Loss 2.091, Loss_clf 0.383, Loss_fe 0.581, Loss_kd 0.867, Train_accy 50.12
2022-09-28 03:46:32,048 [foster.py] => Task 2, Epoch 16/34 => Loss 2.051, Loss_clf 0.365, Loss_fe 0.550, Loss_kd 0.874, Train_accy 49.51, Test_accy 64.45
2022-09-28 03:46:33,857 [foster.py] => Task 2, Epoch 17/34 => Loss 2.019, Loss_clf 0.365, Loss_fe 0.539, Loss_kd 0.857, Train_accy 48.53
2022-09-28 03:46:35,651 [foster.py] => Task 2, Epoch 18/34 => Loss 1.982, Loss_clf 0.345, Loss_fe 0.512, Loss_kd 0.865, Train_accy 50.24
2022-09-28 03:46:37,484 [foster.py] => Task 2, Epoch 19/34 => Loss 2.002, Loss_clf 0.370, Loss_fe 0.519, Loss_kd 0.856, Train_accy 49.14
2022-09-28 03:46:39,271 [foster.py] => Task 2, Epoch 20/34 => Loss 1.986, Loss_clf 0.343, Loss_fe 0.511, Loss_kd 0.871, Train_accy 51.83
2022-09-28 03:46:41,968 [foster.py] => Task 2, Epoch 21/34 => Loss 1.983, Loss_clf 0.351, Loss_fe 0.508, Loss_kd 0.865, Train_accy 48.53, Test_accy 65.45
2022-09-28 03:46:43,766 [foster.py] => Task 2, Epoch 22/34 => Loss 1.972, Loss_clf 0.355, Loss_fe 0.504, Loss_kd 0.856, Train_accy 48.17
2022-09-28 03:46:45,617 [foster.py] => Task 2, Epoch 23/34 => Loss 1.950, Loss_clf 0.343, Loss_fe 0.476, Loss_kd 0.870, Train_accy 51.47
2022-09-28 03:46:47,486 [foster.py] => Task 2, Epoch 24/34 => Loss 1.949, Loss_clf 0.330, Loss_fe 0.487, Loss_kd 0.871, Train_accy 51.34
2022-09-28 03:46:49,305 [foster.py] => Task 2, Epoch 25/34 => Loss 1.948, Loss_clf 0.343, Loss_fe 0.473, Loss_kd 0.871, Train_accy 51.47
2022-09-28 03:46:51,983 [foster.py] => Task 2, Epoch 26/34 => Loss 1.930, Loss_clf 0.327, Loss_fe 0.476, Loss_kd 0.867, Train_accy 50.61, Test_accy 66.11
2022-09-28 03:46:53,823 [foster.py] => Task 2, Epoch 27/34 => Loss 1.950, Loss_clf 0.337, Loss_fe 0.485, Loss_kd 0.868, Train_accy 51.59
2022-09-28 03:46:55,652 [foster.py] => Task 2, Epoch 28/34 => Loss 1.903, Loss_clf 0.323, Loss_fe 0.457, Loss_kd 0.863, Train_accy 50.49
2022-09-28 03:46:57,477 [foster.py] => Task 2, Epoch 29/34 => Loss 1.928, Loss_clf 0.326, Loss_fe 0.469, Loss_kd 0.871, Train_accy 51.71
2022-09-28 03:46:59,316 [foster.py] => Task 2, Epoch 30/34 => Loss 1.919, Loss_clf 0.334, Loss_fe 0.465, Loss_kd 0.861, Train_accy 50.37
2022-09-28 03:47:01,919 [foster.py] => Task 2, Epoch 31/34 => Loss 1.919, Loss_clf 0.335, Loss_fe 0.469, Loss_kd 0.858, Train_accy 48.53, Test_accy 66.45
2022-09-28 03:47:03,719 [foster.py] => Task 2, Epoch 32/34 => Loss 1.933, Loss_clf 0.337, Loss_fe 0.477, Loss_kd 0.860, Train_accy 49.14
2022-09-28 03:47:05,537 [foster.py] => Task 2, Epoch 33/34 => Loss 1.938, Loss_clf 0.332, Loss_fe 0.478, Loss_kd 0.868, Train_accy 49.88
2022-09-28 03:47:07,315 [foster.py] => Task 2, Epoch 34/34 => Loss 1.949, Loss_clf 0.344, Loss_fe 0.487, Loss_kd 0.860, Train_accy 49.14
2022-09-28 03:47:07,316 [foster.py] => do not weight align teacher!
2022-09-28 03:47:07,316 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 03:47:10,256 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.737,  Train_accy 17.48, Test_accy 49.83
2022-09-28 03:47:12,269 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.659,  Train_accy 17.85
2022-09-28 03:47:14,295 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.607,  Train_accy 18.22
2022-09-28 03:47:16,327 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.595,  Train_accy 18.46
2022-09-28 03:47:18,360 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.576,  Train_accy 19.07
2022-09-28 03:47:21,116 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.559,  Train_accy 18.58, Test_accy 53.16
2022-09-28 03:47:23,144 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.544,  Train_accy 19.07
2022-09-28 03:47:25,157 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.524,  Train_accy 19.44
2022-09-28 03:47:27,179 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.521,  Train_accy 19.32
2022-09-28 03:47:29,216 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.531,  Train_accy 19.68
2022-09-28 03:47:32,050 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.518,  Train_accy 19.68, Test_accy 53.49
2022-09-28 03:47:34,100 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.518,  Train_accy 20.54
2022-09-28 03:47:36,167 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.527,  Train_accy 20.90
2022-09-28 03:47:38,207 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.506,  Train_accy 21.03
2022-09-28 03:47:40,220 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.520,  Train_accy 20.90
2022-09-28 03:47:42,948 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.498,  Train_accy 22.49, Test_accy 54.49
2022-09-28 03:47:44,942 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.513,  Train_accy 21.52
2022-09-28 03:47:46,943 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.516,  Train_accy 21.03
2022-09-28 03:47:48,969 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.511,  Train_accy 21.03
2022-09-28 03:47:50,995 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.496,  Train_accy 21.39
2022-09-28 03:47:53,778 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.503,  Train_accy 22.37, Test_accy 55.15
2022-09-28 03:47:55,867 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.503,  Train_accy 21.15
2022-09-28 03:47:57,961 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.499,  Train_accy 21.52
2022-09-28 03:48:00,030 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.504,  Train_accy 21.76
2022-09-28 03:48:02,076 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.509,  Train_accy 22.74
2022-09-28 03:48:04,814 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.519,  Train_accy 21.64, Test_accy 53.16
2022-09-28 03:48:04,815 [foster.py] => do not weight align student!
2022-09-28 03:48:05,528 [foster.py] => darknet eval: 
2022-09-28 03:48:05,528 [foster.py] => CNN top1 curve: 53.16
2022-09-28 03:48:05,528 [foster.py] => CNN top5 curve: 96.01
2022-09-28 03:48:05,528 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 03:48:13,011 [foster.py] => Exemplar size: 260
2022-09-28 03:48:13,011 [trainer.py] => CNN: {'total': 66.45, 'old': 71.86, 'new': 48.57, 'base': 83.85, 'compound': 46.43}
2022-09-28 03:48:13,011 [trainer.py] => CNN top1 curve: [89.44, 76.19, 66.45]
2022-09-28 03:48:13,011 [trainer.py] => CNN base curve: [89.44, 86.34, 83.85]
2022-09-28 03:48:13,011 [trainer.py] => CNN old curve: [89.44, 86.34, 71.86]
2022-09-28 03:48:13,011 [trainer.py] => CNN new curve: [0, 52.86, 48.57]
2022-09-28 03:48:13,011 [trainer.py] => CNN compound curve: [0, 52.86, 46.43]
2022-09-28 03:48:13,011 [trainer.py] => NME: {'total': 76.08, 'old': 75.76, 'new': 77.14, 'base': 76.4, 'compound': 75.71}
2022-09-28 03:48:13,011 [trainer.py] => NME top1 curve: [87.58, 82.25, 76.08]
2022-09-28 03:48:13,011 [trainer.py] => NME base curve: [87.58, 83.85, 76.4]
2022-09-28 03:48:13,011 [trainer.py] => NME old curve: [87.58, 83.85, 75.76]
2022-09-28 03:48:13,011 [trainer.py] => NME new curve: [0, 78.57, 77.14]
2022-09-28 03:48:13,011 [trainer.py] => NME compound curve: [0, 78.57, 75.71]
2022-09-28 03:48:13,239 [foster.py] => Learning on 13-16
2022-09-28 03:48:13,240 [foster.py] => All params: 22384301
2022-09-28 03:48:13,240 [foster.py] => Trainable params: 11201120
2022-09-28 03:48:13,260 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 03:48:16,034 [foster.py] => Task 3, Epoch 1/34 => Loss 5.942, Loss_clf 2.016, Loss_fe 2.323, Loss_kd 1.302, Train_accy 34.78, Test_accy 46.77
2022-09-28 03:48:17,925 [foster.py] => Task 3, Epoch 2/34 => Loss 4.444, Loss_clf 1.100, Loss_fe 1.771, Loss_kd 1.278, Train_accy 35.35
2022-09-28 03:48:19,818 [foster.py] => Task 3, Epoch 3/34 => Loss 4.107, Loss_clf 0.983, Loss_fe 1.545, Loss_kd 1.283, Train_accy 36.26
2022-09-28 03:48:21,714 [foster.py] => Task 3, Epoch 4/34 => Loss 3.919, Loss_clf 0.935, Loss_fe 1.422, Loss_kd 1.269, Train_accy 38.77
2022-09-28 03:48:23,647 [foster.py] => Task 3, Epoch 5/34 => Loss 3.807, Loss_clf 0.900, Loss_fe 1.339, Loss_kd 1.274, Train_accy 39.22
2022-09-28 03:48:26,419 [foster.py] => Task 3, Epoch 6/34 => Loss 3.664, Loss_clf 0.873, Loss_fe 1.242, Loss_kd 1.259, Train_accy 38.20, Test_accy 55.11
2022-09-28 03:48:28,345 [foster.py] => Task 3, Epoch 7/34 => Loss 3.610, Loss_clf 0.852, Loss_fe 1.183, Loss_kd 1.279, Train_accy 39.91
2022-09-28 03:48:30,234 [foster.py] => Task 3, Epoch 8/34 => Loss 3.507, Loss_clf 0.819, Loss_fe 1.124, Loss_kd 1.271, Train_accy 40.02
2022-09-28 03:48:32,109 [foster.py] => Task 3, Epoch 9/34 => Loss 3.482, Loss_clf 0.838, Loss_fe 1.074, Loss_kd 1.275, Train_accy 40.71
2022-09-28 03:48:33,997 [foster.py] => Task 3, Epoch 10/34 => Loss 3.441, Loss_clf 0.826, Loss_fe 1.049, Loss_kd 1.273, Train_accy 42.30
2022-09-28 03:48:36,809 [foster.py] => Task 3, Epoch 11/34 => Loss 3.326, Loss_clf 0.773, Loss_fe 0.982, Loss_kd 1.277, Train_accy 41.05, Test_accy 56.45
2022-09-28 03:48:38,736 [foster.py] => Task 3, Epoch 12/34 => Loss 3.282, Loss_clf 0.759, Loss_fe 0.963, Loss_kd 1.267, Train_accy 43.10
2022-09-28 03:48:40,673 [foster.py] => Task 3, Epoch 13/34 => Loss 3.218, Loss_clf 0.739, Loss_fe 0.922, Loss_kd 1.265, Train_accy 40.36
2022-09-28 03:48:42,607 [foster.py] => Task 3, Epoch 14/34 => Loss 3.206, Loss_clf 0.729, Loss_fe 0.912, Loss_kd 1.272, Train_accy 42.76
2022-09-28 03:48:44,558 [foster.py] => Task 3, Epoch 15/34 => Loss 3.221, Loss_clf 0.741, Loss_fe 0.909, Loss_kd 1.277, Train_accy 40.71
2022-09-28 03:48:47,299 [foster.py] => Task 3, Epoch 16/34 => Loss 3.145, Loss_clf 0.712, Loss_fe 0.866, Loss_kd 1.273, Train_accy 42.53, Test_accy 56.99
2022-09-28 03:48:49,202 [foster.py] => Task 3, Epoch 17/34 => Loss 3.104, Loss_clf 0.690, Loss_fe 0.846, Loss_kd 1.274, Train_accy 42.99
2022-09-28 03:48:51,117 [foster.py] => Task 3, Epoch 18/34 => Loss 3.145, Loss_clf 0.726, Loss_fe 0.855, Loss_kd 1.271, Train_accy 44.70
2022-09-28 03:48:53,020 [foster.py] => Task 3, Epoch 19/34 => Loss 3.073, Loss_clf 0.687, Loss_fe 0.824, Loss_kd 1.269, Train_accy 44.01
2022-09-28 03:48:55,021 [foster.py] => Task 3, Epoch 20/34 => Loss 3.051, Loss_clf 0.687, Loss_fe 0.802, Loss_kd 1.269, Train_accy 43.44
2022-09-28 03:48:57,796 [foster.py] => Task 3, Epoch 21/34 => Loss 3.070, Loss_clf 0.691, Loss_fe 0.814, Loss_kd 1.272, Train_accy 45.04, Test_accy 58.33
2022-09-28 03:48:59,710 [foster.py] => Task 3, Epoch 22/34 => Loss 3.021, Loss_clf 0.676, Loss_fe 0.784, Loss_kd 1.268, Train_accy 42.99
2022-09-28 03:49:01,641 [foster.py] => Task 3, Epoch 23/34 => Loss 3.014, Loss_clf 0.669, Loss_fe 0.780, Loss_kd 1.271, Train_accy 46.41
2022-09-28 03:49:03,545 [foster.py] => Task 3, Epoch 24/34 => Loss 3.040, Loss_clf 0.670, Loss_fe 0.794, Loss_kd 1.281, Train_accy 44.13
2022-09-28 03:49:05,468 [foster.py] => Task 3, Epoch 25/34 => Loss 2.988, Loss_clf 0.647, Loss_fe 0.767, Loss_kd 1.278, Train_accy 44.36
2022-09-28 03:49:08,236 [foster.py] => Task 3, Epoch 26/34 => Loss 2.975, Loss_clf 0.659, Loss_fe 0.757, Loss_kd 1.267, Train_accy 43.67, Test_accy 57.26
2022-09-28 03:49:10,226 [foster.py] => Task 3, Epoch 27/34 => Loss 3.017, Loss_clf 0.663, Loss_fe 0.784, Loss_kd 1.276, Train_accy 45.95
2022-09-28 03:49:12,142 [foster.py] => Task 3, Epoch 28/34 => Loss 3.048, Loss_clf 0.682, Loss_fe 0.801, Loss_kd 1.271, Train_accy 46.07
2022-09-28 03:49:14,109 [foster.py] => Task 3, Epoch 29/34 => Loss 3.013, Loss_clf 0.667, Loss_fe 0.774, Loss_kd 1.278, Train_accy 44.70
2022-09-28 03:49:16,040 [foster.py] => Task 3, Epoch 30/34 => Loss 3.023, Loss_clf 0.664, Loss_fe 0.785, Loss_kd 1.278, Train_accy 44.81
2022-09-28 03:49:18,839 [foster.py] => Task 3, Epoch 31/34 => Loss 2.959, Loss_clf 0.634, Loss_fe 0.753, Loss_kd 1.278, Train_accy 44.93, Test_accy 58.06
2022-09-28 03:49:20,723 [foster.py] => Task 3, Epoch 32/34 => Loss 2.958, Loss_clf 0.640, Loss_fe 0.759, Loss_kd 1.267, Train_accy 46.07
2022-09-28 03:49:22,684 [foster.py] => Task 3, Epoch 33/34 => Loss 2.943, Loss_clf 0.630, Loss_fe 0.747, Loss_kd 1.273, Train_accy 44.36
2022-09-28 03:49:24,600 [foster.py] => Task 3, Epoch 34/34 => Loss 2.953, Loss_clf 0.640, Loss_fe 0.743, Loss_kd 1.276, Train_accy 44.13
2022-09-28 03:49:24,600 [foster.py] => do not weight align teacher!
2022-09-28 03:49:24,601 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 03:49:27,706 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.138,  Train_accy 17.90, Test_accy 42.74
2022-09-28 03:49:29,839 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.038,  Train_accy 18.24
2022-09-28 03:49:31,994 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 1.993,  Train_accy 19.04
2022-09-28 03:49:34,141 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 1.962,  Train_accy 19.38
2022-09-28 03:49:36,258 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.943,  Train_accy 19.61
2022-09-28 03:49:39,221 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.941,  Train_accy 20.18, Test_accy 48.39
2022-09-28 03:49:41,389 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.938,  Train_accy 19.84
2022-09-28 03:49:43,543 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.936,  Train_accy 19.27
2022-09-28 03:49:45,686 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.911,  Train_accy 20.41
2022-09-28 03:49:47,808 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.926,  Train_accy 20.30
2022-09-28 03:49:50,681 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.930,  Train_accy 19.95, Test_accy 48.92
2022-09-28 03:49:52,833 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.910,  Train_accy 19.73
2022-09-28 03:49:54,982 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.915,  Train_accy 20.98
2022-09-28 03:49:57,146 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.912,  Train_accy 20.87
2022-09-28 03:49:59,303 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.917,  Train_accy 21.32
2022-09-28 03:50:02,198 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.907,  Train_accy 21.21, Test_accy 48.92
2022-09-28 03:50:04,347 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.910,  Train_accy 20.30
2022-09-28 03:50:06,482 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.913,  Train_accy 19.50
2022-09-28 03:50:08,611 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.911,  Train_accy 21.66
2022-09-28 03:50:10,731 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.922,  Train_accy 20.41
2022-09-28 03:50:13,638 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.906,  Train_accy 21.21, Test_accy 48.92
2022-09-28 03:50:15,766 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.908,  Train_accy 20.98
2022-09-28 03:50:17,921 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.909,  Train_accy 21.21
2022-09-28 03:50:20,125 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.910,  Train_accy 21.21
2022-09-28 03:50:22,309 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.904,  Train_accy 20.64
2022-09-28 03:50:25,198 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.906,  Train_accy 20.75, Test_accy 49.46
2022-09-28 03:50:25,198 [foster.py] => do not weight align student!
2022-09-28 03:50:25,993 [foster.py] => darknet eval: 
2022-09-28 03:50:25,993 [foster.py] => CNN top1 curve: 49.46
2022-09-28 03:50:25,993 [foster.py] => CNN top5 curve: 92.74
2022-09-28 03:50:25,994 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 03:50:34,442 [foster.py] => Exemplar size: 320
2022-09-28 03:50:34,442 [trainer.py] => CNN: {'total': 58.06, 'old': 65.12, 'new': 28.17, 'base': 78.88, 'compound': 42.18}
2022-09-28 03:50:34,442 [trainer.py] => CNN top1 curve: [89.44, 76.19, 66.45, 58.06]
2022-09-28 03:50:34,442 [trainer.py] => CNN base curve: [89.44, 86.34, 83.85, 78.88]
2022-09-28 03:50:34,442 [trainer.py] => CNN old curve: [89.44, 86.34, 71.86, 65.12]
2022-09-28 03:50:34,442 [trainer.py] => CNN new curve: [0, 52.86, 48.57, 28.17]
2022-09-28 03:50:34,442 [trainer.py] => CNN compound curve: [0, 52.86, 46.43, 42.18]
2022-09-28 03:50:34,442 [trainer.py] => NME: {'total': 64.52, 'old': 69.44, 'new': 43.66, 'base': 71.43, 'compound': 59.24}
2022-09-28 03:50:34,442 [trainer.py] => NME top1 curve: [87.58, 82.25, 76.08, 64.52]
2022-09-28 03:50:34,442 [trainer.py] => NME base curve: [87.58, 83.85, 76.4, 71.43]
2022-09-28 03:50:34,442 [trainer.py] => NME old curve: [87.58, 83.85, 75.76, 69.44]
2022-09-28 03:50:34,442 [trainer.py] => NME new curve: [0, 78.57, 77.14, 43.66]
2022-09-28 03:50:34,442 [trainer.py] => NME compound curve: [0, 78.57, 75.71, 59.24]
2022-09-28 03:50:34,672 [foster.py] => Learning on 16-19
2022-09-28 03:50:34,673 [foster.py] => All params: 22390454
2022-09-28 03:50:34,673 [foster.py] => Trainable params: 11205734
2022-09-28 03:50:34,693 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 03:50:37,645 [foster.py] => Task 4, Epoch 1/34 => Loss 6.382, Loss_clf 1.874, Loss_fe 2.603, Loss_kd 1.604, Train_accy 36.15, Test_accy 46.08
2022-09-28 03:50:39,720 [foster.py] => Task 4, Epoch 2/34 => Loss 4.807, Loss_clf 1.092, Loss_fe 1.805, Loss_kd 1.609, Train_accy 36.05
2022-09-28 03:50:41,731 [foster.py] => Task 4, Epoch 3/34 => Loss 4.475, Loss_clf 0.979, Loss_fe 1.598, Loss_kd 1.598, Train_accy 36.36
2022-09-28 03:50:43,755 [foster.py] => Task 4, Epoch 4/34 => Loss 4.306, Loss_clf 0.945, Loss_fe 1.463, Loss_kd 1.599, Train_accy 38.37
2022-09-28 03:50:45,819 [foster.py] => Task 4, Epoch 5/34 => Loss 4.183, Loss_clf 0.915, Loss_fe 1.367, Loss_kd 1.601, Train_accy 37.84
2022-09-28 03:50:48,772 [foster.py] => Task 4, Epoch 6/34 => Loss 4.126, Loss_clf 0.922, Loss_fe 1.317, Loss_kd 1.589, Train_accy 40.06, Test_accy 48.85
2022-09-28 03:50:50,771 [foster.py] => Task 4, Epoch 7/34 => Loss 4.023, Loss_clf 0.878, Loss_fe 1.245, Loss_kd 1.600, Train_accy 36.68
2022-09-28 03:50:52,795 [foster.py] => Task 4, Epoch 8/34 => Loss 3.921, Loss_clf 0.845, Loss_fe 1.179, Loss_kd 1.598, Train_accy 37.95
2022-09-28 03:50:54,791 [foster.py] => Task 4, Epoch 9/34 => Loss 3.943, Loss_clf 0.877, Loss_fe 1.167, Loss_kd 1.599, Train_accy 40.59
2022-09-28 03:50:56,790 [foster.py] => Task 4, Epoch 10/34 => Loss 3.882, Loss_clf 0.861, Loss_fe 1.122, Loss_kd 1.600, Train_accy 38.90
2022-09-28 03:50:59,700 [foster.py] => Task 4, Epoch 11/34 => Loss 3.782, Loss_clf 0.810, Loss_fe 1.076, Loss_kd 1.596, Train_accy 37.74, Test_accy 53.00
2022-09-28 03:51:01,711 [foster.py] => Task 4, Epoch 12/34 => Loss 3.738, Loss_clf 0.800, Loss_fe 1.037, Loss_kd 1.601, Train_accy 41.01
2022-09-28 03:51:03,695 [foster.py] => Task 4, Epoch 13/34 => Loss 3.701, Loss_clf 0.790, Loss_fe 1.008, Loss_kd 1.603, Train_accy 42.18
2022-09-28 03:51:05,727 [foster.py] => Task 4, Epoch 14/34 => Loss 3.718, Loss_clf 0.798, Loss_fe 1.005, Loss_kd 1.612, Train_accy 40.49
2022-09-28 03:51:07,751 [foster.py] => Task 4, Epoch 15/34 => Loss 3.670, Loss_clf 0.789, Loss_fe 0.980, Loss_kd 1.600, Train_accy 39.85
2022-09-28 03:51:10,721 [foster.py] => Task 4, Epoch 16/34 => Loss 3.629, Loss_clf 0.770, Loss_fe 0.963, Loss_kd 1.597, Train_accy 41.97, Test_accy 52.30
2022-09-28 03:51:12,787 [foster.py] => Task 4, Epoch 17/34 => Loss 3.587, Loss_clf 0.754, Loss_fe 0.951, Loss_kd 1.585, Train_accy 38.79
2022-09-28 03:51:14,841 [foster.py] => Task 4, Epoch 18/34 => Loss 3.540, Loss_clf 0.741, Loss_fe 0.906, Loss_kd 1.594, Train_accy 42.49
2022-09-28 03:51:16,839 [foster.py] => Task 4, Epoch 19/34 => Loss 3.537, Loss_clf 0.742, Loss_fe 0.900, Loss_kd 1.596, Train_accy 39.64
2022-09-28 03:51:18,844 [foster.py] => Task 4, Epoch 20/34 => Loss 3.532, Loss_clf 0.725, Loss_fe 0.903, Loss_kd 1.604, Train_accy 42.71
2022-09-28 03:51:21,799 [foster.py] => Task 4, Epoch 21/34 => Loss 3.546, Loss_clf 0.750, Loss_fe 0.897, Loss_kd 1.598, Train_accy 39.11, Test_accy 52.53
2022-09-28 03:51:23,787 [foster.py] => Task 4, Epoch 22/34 => Loss 3.468, Loss_clf 0.699, Loss_fe 0.865, Loss_kd 1.603, Train_accy 44.08
2022-09-28 03:51:25,829 [foster.py] => Task 4, Epoch 23/34 => Loss 3.475, Loss_clf 0.715, Loss_fe 0.861, Loss_kd 1.599, Train_accy 40.59
2022-09-28 03:51:27,843 [foster.py] => Task 4, Epoch 24/34 => Loss 3.459, Loss_clf 0.703, Loss_fe 0.862, Loss_kd 1.595, Train_accy 42.60
2022-09-28 03:51:29,870 [foster.py] => Task 4, Epoch 25/34 => Loss 3.442, Loss_clf 0.697, Loss_fe 0.848, Loss_kd 1.597, Train_accy 43.45
2022-09-28 03:51:32,855 [foster.py] => Task 4, Epoch 26/34 => Loss 3.452, Loss_clf 0.706, Loss_fe 0.845, Loss_kd 1.600, Train_accy 42.18, Test_accy 52.53
2022-09-28 03:51:34,982 [foster.py] => Task 4, Epoch 27/34 => Loss 3.445, Loss_clf 0.695, Loss_fe 0.845, Loss_kd 1.604, Train_accy 43.02
2022-09-28 03:51:36,964 [foster.py] => Task 4, Epoch 28/34 => Loss 3.425, Loss_clf 0.692, Loss_fe 0.833, Loss_kd 1.600, Train_accy 41.54
2022-09-28 03:51:38,984 [foster.py] => Task 4, Epoch 29/34 => Loss 3.434, Loss_clf 0.698, Loss_fe 0.835, Loss_kd 1.602, Train_accy 44.40
2022-09-28 03:51:41,019 [foster.py] => Task 4, Epoch 30/34 => Loss 3.437, Loss_clf 0.697, Loss_fe 0.839, Loss_kd 1.601, Train_accy 43.13
2022-09-28 03:51:43,995 [foster.py] => Task 4, Epoch 31/34 => Loss 3.437, Loss_clf 0.693, Loss_fe 0.832, Loss_kd 1.610, Train_accy 43.45, Test_accy 52.07
2022-09-28 03:51:46,034 [foster.py] => Task 4, Epoch 32/34 => Loss 3.438, Loss_clf 0.693, Loss_fe 0.837, Loss_kd 1.607, Train_accy 43.02
2022-09-28 03:51:48,062 [foster.py] => Task 4, Epoch 33/34 => Loss 3.482, Loss_clf 0.719, Loss_fe 0.852, Loss_kd 1.609, Train_accy 42.18
2022-09-28 03:51:50,078 [foster.py] => Task 4, Epoch 34/34 => Loss 3.437, Loss_clf 0.698, Loss_fe 0.842, Loss_kd 1.597, Train_accy 43.45
2022-09-28 03:51:50,079 [foster.py] => do not weight align teacher!
2022-09-28 03:51:50,079 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 03:51:53,336 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.260,  Train_accy 18.60, Test_accy 42.63
2022-09-28 03:51:55,562 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.212,  Train_accy 19.77
2022-09-28 03:51:57,848 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.208,  Train_accy 19.66
2022-09-28 03:52:00,084 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.194,  Train_accy 19.98
2022-09-28 03:52:02,341 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.181,  Train_accy 20.08
2022-09-28 03:52:05,371 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.191,  Train_accy 20.19, Test_accy 43.55
2022-09-28 03:52:07,634 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.173,  Train_accy 19.77
2022-09-28 03:52:09,907 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.170,  Train_accy 20.51
2022-09-28 03:52:12,209 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.167,  Train_accy 19.56
2022-09-28 03:52:14,461 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.177,  Train_accy 20.30
2022-09-28 03:52:17,509 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.151,  Train_accy 20.51, Test_accy 44.93
2022-09-28 03:52:19,741 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.156,  Train_accy 20.30
2022-09-28 03:52:22,015 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.152,  Train_accy 19.98
2022-09-28 03:52:24,299 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.145,  Train_accy 20.30
2022-09-28 03:52:26,541 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.146,  Train_accy 20.61
2022-09-28 03:52:29,630 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.145,  Train_accy 19.87, Test_accy 45.39
2022-09-28 03:52:31,886 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.150,  Train_accy 21.14
2022-09-28 03:52:34,140 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.156,  Train_accy 20.72
2022-09-28 03:52:36,367 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.153,  Train_accy 20.19
2022-09-28 03:52:38,617 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.154,  Train_accy 20.72
2022-09-28 03:52:41,691 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.146,  Train_accy 20.82, Test_accy 45.16
2022-09-28 03:52:43,969 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.144,  Train_accy 19.87
2022-09-28 03:52:46,237 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.157,  Train_accy 20.51
2022-09-28 03:52:48,495 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.151,  Train_accy 21.46
2022-09-28 03:52:50,771 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.143,  Train_accy 20.82
2022-09-28 03:52:53,855 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.149,  Train_accy 21.78, Test_accy 45.39
2022-09-28 03:52:53,855 [foster.py] => do not weight align student!
2022-09-28 03:52:54,664 [foster.py] => darknet eval: 
2022-09-28 03:52:54,664 [foster.py] => CNN top1 curve: 45.39
2022-09-28 03:52:54,664 [foster.py] => CNN top5 curve: 83.64
2022-09-28 03:52:54,664 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 03:53:04,191 [foster.py] => Exemplar size: 380
2022-09-28 03:53:04,191 [trainer.py] => CNN: {'total': 53.0, 'old': 56.72, 'new': 30.65, 'base': 78.88, 'compound': 37.73}
2022-09-28 03:53:04,191 [trainer.py] => CNN top1 curve: [89.44, 76.19, 66.45, 58.06, 53.0]
2022-09-28 03:53:04,191 [trainer.py] => CNN base curve: [89.44, 86.34, 83.85, 78.88, 78.88]
2022-09-28 03:53:04,191 [trainer.py] => CNN old curve: [89.44, 86.34, 71.86, 65.12, 56.72]
2022-09-28 03:53:04,191 [trainer.py] => CNN new curve: [0, 52.86, 48.57, 28.17, 30.65]
2022-09-28 03:53:04,191 [trainer.py] => CNN compound curve: [0, 52.86, 46.43, 42.18, 37.73]
2022-09-28 03:53:04,191 [trainer.py] => NME: {'total': 58.06, 'old': 59.68, 'new': 48.39, 'base': 69.57, 'compound': 51.28}
2022-09-28 03:53:04,191 [trainer.py] => NME top1 curve: [87.58, 82.25, 76.08, 64.52, 58.06]
2022-09-28 03:53:04,191 [trainer.py] => NME base curve: [87.58, 83.85, 76.4, 71.43, 69.57]
2022-09-28 03:53:04,191 [trainer.py] => NME old curve: [87.58, 83.85, 75.76, 69.44, 59.68]
2022-09-28 03:53:04,191 [trainer.py] => NME new curve: [0, 78.57, 77.14, 43.66, 48.39]
2022-09-28 03:53:04,191 [trainer.py] => NME compound curve: [0, 78.57, 75.71, 59.24, 51.28]
2022-09-28 03:53:04,420 [foster.py] => Learning on 19-22
2022-09-28 03:53:04,421 [foster.py] => All params: 22396607
2022-09-28 03:53:04,421 [foster.py] => Trainable params: 11210348
2022-09-28 03:53:04,441 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 03:53:07,555 [foster.py] => Task 5, Epoch 1/34 => Loss 6.681, Loss_clf 2.091, Loss_fe 2.457, Loss_kd 1.842, Train_accy 38.38, Test_accy 45.83
2022-09-28 03:53:09,620 [foster.py] => Task 5, Epoch 2/34 => Loss 5.105, Loss_clf 1.105, Loss_fe 1.868, Loss_kd 1.842, Train_accy 35.07
2022-09-28 03:53:11,777 [foster.py] => Task 5, Epoch 3/34 => Loss 4.826, Loss_clf 1.029, Loss_fe 1.687, Loss_kd 1.822, Train_accy 39.68
2022-09-28 03:53:13,854 [foster.py] => Task 5, Epoch 4/34 => Loss 4.655, Loss_clf 0.976, Loss_fe 1.559, Loss_kd 1.831, Train_accy 40.78
2022-09-28 03:53:15,926 [foster.py] => Task 5, Epoch 5/34 => Loss 4.572, Loss_clf 0.984, Loss_fe 1.459, Loss_kd 1.838, Train_accy 42.18
2022-09-28 03:53:19,036 [foster.py] => Task 5, Epoch 6/34 => Loss 4.442, Loss_clf 0.935, Loss_fe 1.386, Loss_kd 1.832, Train_accy 40.38, Test_accy 45.83
2022-09-28 03:53:21,128 [foster.py] => Task 5, Epoch 7/34 => Loss 4.323, Loss_clf 0.885, Loss_fe 1.311, Loss_kd 1.838, Train_accy 43.19
2022-09-28 03:53:23,229 [foster.py] => Task 5, Epoch 8/34 => Loss 4.286, Loss_clf 0.885, Loss_fe 1.269, Loss_kd 1.841, Train_accy 42.69
2022-09-28 03:53:25,341 [foster.py] => Task 5, Epoch 9/34 => Loss 4.228, Loss_clf 0.877, Loss_fe 1.220, Loss_kd 1.841, Train_accy 43.89
2022-09-28 03:53:27,470 [foster.py] => Task 5, Epoch 10/34 => Loss 4.192, Loss_clf 0.887, Loss_fe 1.181, Loss_kd 1.834, Train_accy 42.79
2022-09-28 03:53:30,595 [foster.py] => Task 5, Epoch 11/34 => Loss 4.088, Loss_clf 0.838, Loss_fe 1.116, Loss_kd 1.843, Train_accy 45.69, Test_accy 47.22
2022-09-28 03:53:32,664 [foster.py] => Task 5, Epoch 12/34 => Loss 4.068, Loss_clf 0.826, Loss_fe 1.106, Loss_kd 1.844, Train_accy 44.59
2022-09-28 03:53:34,743 [foster.py] => Task 5, Epoch 13/34 => Loss 4.059, Loss_clf 0.833, Loss_fe 1.096, Loss_kd 1.840, Train_accy 46.39
2022-09-28 03:53:36,836 [foster.py] => Task 5, Epoch 14/34 => Loss 3.963, Loss_clf 0.789, Loss_fe 1.036, Loss_kd 1.847, Train_accy 43.39
2022-09-28 03:53:38,958 [foster.py] => Task 5, Epoch 15/34 => Loss 3.932, Loss_clf 0.792, Loss_fe 1.017, Loss_kd 1.833, Train_accy 44.99
2022-09-28 03:53:42,038 [foster.py] => Task 5, Epoch 16/34 => Loss 3.920, Loss_clf 0.783, Loss_fe 1.018, Loss_kd 1.830, Train_accy 46.09, Test_accy 49.40
2022-09-28 03:53:44,140 [foster.py] => Task 5, Epoch 17/34 => Loss 3.972, Loss_clf 0.805, Loss_fe 1.025, Loss_kd 1.850, Train_accy 50.30
2022-09-28 03:53:46,259 [foster.py] => Task 5, Epoch 18/34 => Loss 3.915, Loss_clf 0.796, Loss_fe 0.991, Loss_kd 1.838, Train_accy 45.59
2022-09-28 03:53:48,374 [foster.py] => Task 5, Epoch 19/34 => Loss 3.868, Loss_clf 0.775, Loss_fe 0.956, Loss_kd 1.846, Train_accy 43.49
2022-09-28 03:53:50,470 [foster.py] => Task 5, Epoch 20/34 => Loss 3.841, Loss_clf 0.759, Loss_fe 0.956, Loss_kd 1.836, Train_accy 48.10
2022-09-28 03:53:53,506 [foster.py] => Task 5, Epoch 21/34 => Loss 3.812, Loss_clf 0.755, Loss_fe 0.936, Loss_kd 1.832, Train_accy 47.09, Test_accy 49.21
2022-09-28 03:53:55,615 [foster.py] => Task 5, Epoch 22/34 => Loss 3.823, Loss_clf 0.745, Loss_fe 0.949, Loss_kd 1.838, Train_accy 45.69
2022-09-28 03:53:57,690 [foster.py] => Task 5, Epoch 23/34 => Loss 3.830, Loss_clf 0.749, Loss_fe 0.932, Loss_kd 1.855, Train_accy 46.59
2022-09-28 03:53:59,779 [foster.py] => Task 5, Epoch 24/34 => Loss 3.800, Loss_clf 0.758, Loss_fe 0.926, Loss_kd 1.828, Train_accy 45.79
2022-09-28 03:54:01,892 [foster.py] => Task 5, Epoch 25/34 => Loss 3.759, Loss_clf 0.723, Loss_fe 0.901, Loss_kd 1.843, Train_accy 48.10
2022-09-28 03:54:04,965 [foster.py] => Task 5, Epoch 26/34 => Loss 3.803, Loss_clf 0.753, Loss_fe 0.919, Loss_kd 1.841, Train_accy 47.90, Test_accy 49.80
2022-09-28 03:54:07,039 [foster.py] => Task 5, Epoch 27/34 => Loss 3.764, Loss_clf 0.726, Loss_fe 0.912, Loss_kd 1.836, Train_accy 45.79
2022-09-28 03:54:09,133 [foster.py] => Task 5, Epoch 28/34 => Loss 3.779, Loss_clf 0.739, Loss_fe 0.900, Loss_kd 1.848, Train_accy 47.19
2022-09-28 03:54:11,199 [foster.py] => Task 5, Epoch 29/34 => Loss 3.806, Loss_clf 0.757, Loss_fe 0.921, Loss_kd 1.838, Train_accy 46.99
2022-09-28 03:54:13,330 [foster.py] => Task 5, Epoch 30/34 => Loss 3.761, Loss_clf 0.730, Loss_fe 0.895, Loss_kd 1.845, Train_accy 46.99
2022-09-28 03:54:16,466 [foster.py] => Task 5, Epoch 31/34 => Loss 3.757, Loss_clf 0.732, Loss_fe 0.896, Loss_kd 1.838, Train_accy 45.99, Test_accy 50.00
2022-09-28 03:54:18,556 [foster.py] => Task 5, Epoch 32/34 => Loss 3.743, Loss_clf 0.715, Loss_fe 0.887, Loss_kd 1.849, Train_accy 48.50
2022-09-28 03:54:20,701 [foster.py] => Task 5, Epoch 33/34 => Loss 3.733, Loss_clf 0.715, Loss_fe 0.875, Loss_kd 1.850, Train_accy 45.99
2022-09-28 03:54:22,781 [foster.py] => Task 5, Epoch 34/34 => Loss 3.789, Loss_clf 0.749, Loss_fe 0.916, Loss_kd 1.834, Train_accy 46.09
2022-09-28 03:54:22,782 [foster.py] => do not weight align teacher!
2022-09-28 03:54:22,782 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 03:54:26,260 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.423,  Train_accy 19.44, Test_accy 39.48
2022-09-28 03:54:28,588 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.398,  Train_accy 20.44
2022-09-28 03:54:30,954 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.356,  Train_accy 20.14
2022-09-28 03:54:33,300 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.369,  Train_accy 19.94
2022-09-28 03:54:35,698 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.360,  Train_accy 21.04
2022-09-28 03:54:38,888 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.341,  Train_accy 20.04, Test_accy 40.48
2022-09-28 03:54:41,231 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.337,  Train_accy 20.34
2022-09-28 03:54:43,549 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.331,  Train_accy 21.04
2022-09-28 03:54:45,927 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.308,  Train_accy 21.04
2022-09-28 03:54:48,310 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.319,  Train_accy 21.84
2022-09-28 03:54:51,567 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.317,  Train_accy 21.64, Test_accy 41.87
2022-09-28 03:54:53,958 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.327,  Train_accy 22.34
2022-09-28 03:54:56,323 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.309,  Train_accy 21.34
2022-09-28 03:54:58,705 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.307,  Train_accy 23.15
2022-09-28 03:55:01,102 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.308,  Train_accy 23.05
2022-09-28 03:55:04,356 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.315,  Train_accy 23.25, Test_accy 42.86
2022-09-28 03:55:06,724 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.301,  Train_accy 22.85
2022-09-28 03:55:09,096 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.311,  Train_accy 23.85
2022-09-28 03:55:11,470 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.313,  Train_accy 23.45
2022-09-28 03:55:13,850 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.301,  Train_accy 23.05
2022-09-28 03:55:17,086 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.314,  Train_accy 24.15, Test_accy 42.46
2022-09-28 03:55:19,415 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.311,  Train_accy 23.15
2022-09-28 03:55:21,759 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.306,  Train_accy 23.55
2022-09-28 03:55:24,133 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.294,  Train_accy 22.04
2022-09-28 03:55:26,515 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.308,  Train_accy 23.65
2022-09-28 03:55:29,754 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.307,  Train_accy 23.15, Test_accy 42.46
2022-09-28 03:55:29,754 [foster.py] => do not weight align student!
2022-09-28 03:55:30,599 [foster.py] => darknet eval: 
2022-09-28 03:55:30,599 [foster.py] => CNN top1 curve: 42.46
2022-09-28 03:55:30,599 [foster.py] => CNN top5 curve: 82.94
2022-09-28 03:55:30,599 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 03:55:41,241 [foster.py] => Exemplar size: 440
2022-09-28 03:55:41,241 [trainer.py] => CNN: {'total': 50.0, 'old': 52.76, 'new': 32.86, 'base': 73.91, 'compound': 38.78}
2022-09-28 03:55:41,241 [trainer.py] => CNN top1 curve: [89.44, 76.19, 66.45, 58.06, 53.0, 50.0]
2022-09-28 03:55:41,241 [trainer.py] => CNN base curve: [89.44, 86.34, 83.85, 78.88, 78.88, 73.91]
2022-09-28 03:55:41,241 [trainer.py] => CNN old curve: [89.44, 86.34, 71.86, 65.12, 56.72, 52.76]
2022-09-28 03:55:41,241 [trainer.py] => CNN new curve: [0, 52.86, 48.57, 28.17, 30.65, 32.86]
2022-09-28 03:55:41,242 [trainer.py] => CNN compound curve: [0, 52.86, 46.43, 42.18, 37.73, 38.78]
2022-09-28 03:55:41,242 [trainer.py] => NME: {'total': 56.35, 'old': 56.91, 'new': 52.86, 'base': 65.84, 'compound': 51.9}
2022-09-28 03:55:41,242 [trainer.py] => NME top1 curve: [87.58, 82.25, 76.08, 64.52, 58.06, 56.35]
2022-09-28 03:55:41,242 [trainer.py] => NME base curve: [87.58, 83.85, 76.4, 71.43, 69.57, 65.84]
2022-09-28 03:55:41,242 [trainer.py] => NME old curve: [87.58, 83.85, 75.76, 69.44, 59.68, 56.91]
2022-09-28 03:55:41,242 [trainer.py] => NME new curve: [0, 78.57, 77.14, 43.66, 48.39, 52.86]
2022-09-28 03:55:41,242 [trainer.py] => NME compound curve: [0, 78.57, 75.71, 59.24, 51.28, 51.9]
2022-09-28 03:55:41,243 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 03:55:41,243 [trainer.py] => prefix: cil
2022-09-28 03:55:41,243 [trainer.py] => dataset: CFEE
2022-09-28 03:55:41,243 [trainer.py] => memory_size: 2000
2022-09-28 03:55:41,243 [trainer.py] => memory_per_class: 20
2022-09-28 03:55:41,243 [trainer.py] => fixed_memory: True
2022-09-28 03:55:41,243 [trainer.py] => shuffle: True
2022-09-28 03:55:41,243 [trainer.py] => init_cls: 7
2022-09-28 03:55:41,243 [trainer.py] => increment: 3
2022-09-28 03:55:41,243 [trainer.py] => model_name: foster
2022-09-28 03:55:41,243 [trainer.py] => convnet_type: resnet18
2022-09-28 03:55:41,243 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 03:55:41,243 [trainer.py] => seed: 1993
2022-09-28 03:55:41,244 [trainer.py] => beta1: 0.96
2022-09-28 03:55:41,244 [trainer.py] => beta2: 0.97
2022-09-28 03:55:41,244 [trainer.py] => oofc: ft
2022-09-28 03:55:41,244 [trainer.py] => is_teacher_wa: False
2022-09-28 03:55:41,244 [trainer.py] => is_student_wa: False
2022-09-28 03:55:41,244 [trainer.py] => lambda_okd: 1
2022-09-28 03:55:41,244 [trainer.py] => wa_value: 1
2022-09-28 03:55:41,244 [trainer.py] => init_epochs: 40
2022-09-28 03:55:41,244 [trainer.py] => init_lr: 0.01
2022-09-28 03:55:41,244 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 03:55:41,244 [trainer.py] => boosting_epochs: 34
2022-09-28 03:55:41,244 [trainer.py] => compression_epochs: 26
2022-09-28 03:55:41,244 [trainer.py] => lr: 0.001
2022-09-28 03:55:41,244 [trainer.py] => batch_size: 32
2022-09-28 03:55:41,244 [trainer.py] => weight_decay: 0.0005
2022-09-28 03:55:41,244 [trainer.py] => num_workers: 8
2022-09-28 03:55:41,244 [trainer.py] => T: 2
2022-09-28 03:55:41,244 [trainer.py] => nb_runs: 3
2022-09-28 03:55:41,244 [trainer.py] => fold: 10
2022-09-28 03:55:41,244 [data.py] => ========== Fold:7 ==========
2022-09-28 03:55:41,249 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 8, 15, 13, 17, 9, 11, 19, 21, 14, 10, 18, 12, 7, 16]
2022-09-28 03:55:41,462 [foster.py] => Learning on 0-7
2022-09-28 03:55:41,463 [foster.py] => All params: 11183694
2022-09-28 03:55:41,463 [foster.py] => Trainable params: 11183694
2022-09-28 03:55:43,843 [foster.py] => Task 0, Epoch 1/40 => Loss 1.326, Train_accy 50.82
2022-09-28 03:55:46,843 [foster.py] => Task 0, Epoch 2/40 => Loss 0.533, Train_accy 80.66, Test_accy 89.26
2022-09-28 03:55:49,836 [foster.py] => Task 0, Epoch 3/40 => Loss 0.340, Train_accy 87.59, Test_accy 87.25
2022-09-28 03:55:52,811 [foster.py] => Task 0, Epoch 4/40 => Loss 0.273, Train_accy 90.47, Test_accy 91.28
2022-09-28 03:55:55,770 [foster.py] => Task 0, Epoch 5/40 => Loss 0.239, Train_accy 91.70, Test_accy 85.91
2022-09-28 03:55:58,198 [foster.py] => Task 0, Epoch 6/40 => Loss 0.189, Train_accy 93.48
2022-09-28 03:56:01,205 [foster.py] => Task 0, Epoch 7/40 => Loss 0.155, Train_accy 95.40, Test_accy 85.91
2022-09-28 03:56:04,221 [foster.py] => Task 0, Epoch 8/40 => Loss 0.134, Train_accy 95.40, Test_accy 85.91
2022-09-28 03:56:07,227 [foster.py] => Task 0, Epoch 9/40 => Loss 0.114, Train_accy 96.64, Test_accy 88.59
2022-09-28 03:56:10,204 [foster.py] => Task 0, Epoch 10/40 => Loss 0.101, Train_accy 96.71, Test_accy 87.25
2022-09-28 03:56:12,580 [foster.py] => Task 0, Epoch 11/40 => Loss 0.077, Train_accy 97.87
2022-09-28 03:56:15,621 [foster.py] => Task 0, Epoch 12/40 => Loss 0.076, Train_accy 97.81, Test_accy 87.25
2022-09-28 03:56:18,623 [foster.py] => Task 0, Epoch 13/40 => Loss 0.063, Train_accy 97.87, Test_accy 85.91
2022-09-28 03:56:21,601 [foster.py] => Task 0, Epoch 14/40 => Loss 0.047, Train_accy 98.83, Test_accy 88.59
2022-09-28 03:56:24,564 [foster.py] => Task 0, Epoch 15/40 => Loss 0.045, Train_accy 99.04, Test_accy 89.26
2022-09-28 03:56:26,970 [foster.py] => Task 0, Epoch 16/40 => Loss 0.041, Train_accy 99.04
2022-09-28 03:56:29,923 [foster.py] => Task 0, Epoch 17/40 => Loss 0.033, Train_accy 99.31, Test_accy 86.58
2022-09-28 03:56:32,940 [foster.py] => Task 0, Epoch 18/40 => Loss 0.033, Train_accy 99.45, Test_accy 87.25
2022-09-28 03:56:35,965 [foster.py] => Task 0, Epoch 19/40 => Loss 0.029, Train_accy 99.66, Test_accy 87.92
2022-09-28 03:56:39,022 [foster.py] => Task 0, Epoch 20/40 => Loss 0.023, Train_accy 99.59, Test_accy 88.59
2022-09-28 03:56:41,423 [foster.py] => Task 0, Epoch 21/40 => Loss 0.022, Train_accy 99.45
2022-09-28 03:56:44,440 [foster.py] => Task 0, Epoch 22/40 => Loss 0.022, Train_accy 99.31, Test_accy 87.25
2022-09-28 03:56:47,510 [foster.py] => Task 0, Epoch 23/40 => Loss 0.022, Train_accy 99.79, Test_accy 88.59
2022-09-28 03:56:50,528 [foster.py] => Task 0, Epoch 24/40 => Loss 0.017, Train_accy 99.79, Test_accy 87.92
2022-09-28 03:56:53,535 [foster.py] => Task 0, Epoch 25/40 => Loss 0.016, Train_accy 99.73, Test_accy 88.59
2022-09-28 03:56:55,905 [foster.py] => Task 0, Epoch 26/40 => Loss 0.016, Train_accy 99.79
2022-09-28 03:56:58,958 [foster.py] => Task 0, Epoch 27/40 => Loss 0.019, Train_accy 99.73, Test_accy 87.92
2022-09-28 03:57:01,950 [foster.py] => Task 0, Epoch 28/40 => Loss 0.015, Train_accy 99.86, Test_accy 87.92
2022-09-28 03:57:04,948 [foster.py] => Task 0, Epoch 29/40 => Loss 0.017, Train_accy 99.73, Test_accy 88.59
2022-09-28 03:57:08,028 [foster.py] => Task 0, Epoch 30/40 => Loss 0.016, Train_accy 99.79, Test_accy 89.93
2022-09-28 03:57:10,390 [foster.py] => Task 0, Epoch 31/40 => Loss 0.018, Train_accy 99.66
2022-09-28 03:57:13,350 [foster.py] => Task 0, Epoch 32/40 => Loss 0.015, Train_accy 99.86, Test_accy 89.26
2022-09-28 03:57:16,415 [foster.py] => Task 0, Epoch 33/40 => Loss 0.015, Train_accy 99.73, Test_accy 89.26
2022-09-28 03:57:19,392 [foster.py] => Task 0, Epoch 34/40 => Loss 0.012, Train_accy 99.86, Test_accy 87.92
2022-09-28 03:57:22,394 [foster.py] => Task 0, Epoch 35/40 => Loss 0.014, Train_accy 99.79, Test_accy 88.59
2022-09-28 03:57:24,846 [foster.py] => Task 0, Epoch 36/40 => Loss 0.016, Train_accy 99.79
2022-09-28 03:57:27,855 [foster.py] => Task 0, Epoch 37/40 => Loss 0.010, Train_accy 100.00, Test_accy 87.92
2022-09-28 03:57:30,842 [foster.py] => Task 0, Epoch 38/40 => Loss 0.017, Train_accy 99.79, Test_accy 89.93
2022-09-28 03:57:33,853 [foster.py] => Task 0, Epoch 39/40 => Loss 0.015, Train_accy 99.86, Test_accy 88.59
2022-09-28 03:57:36,848 [foster.py] => Task 0, Epoch 40/40 => Loss 0.010, Train_accy 99.93, Test_accy 87.92
2022-09-28 03:57:36,849 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 03:57:43,677 [foster.py] => Exemplar size: 140
2022-09-28 03:57:43,677 [trainer.py] => CNN: {'total': 87.92, 'old': 87.92, 'new': 0, 'base': 87.92, 'compound': 0}
2022-09-28 03:57:43,677 [trainer.py] => CNN top1 curve: [87.92]
2022-09-28 03:57:43,677 [trainer.py] => CNN base curve: [87.92]
2022-09-28 03:57:43,677 [trainer.py] => CNN old curve: [87.92]
2022-09-28 03:57:43,677 [trainer.py] => CNN new curve: [0]
2022-09-28 03:57:43,678 [trainer.py] => CNN compound curve: [0]
2022-09-28 03:57:43,678 [trainer.py] => NME: {'total': 88.59, 'old': 88.59, 'new': 0, 'base': 88.59, 'compound': 0}
2022-09-28 03:57:43,678 [trainer.py] => NME top1 curve: [88.59]
2022-09-28 03:57:43,678 [trainer.py] => NME base curve: [88.59]
2022-09-28 03:57:43,678 [trainer.py] => NME old curve: [88.59]
2022-09-28 03:57:43,678 [trainer.py] => NME new curve: [0]
2022-09-28 03:57:43,678 [trainer.py] => NME compound curve: [0]
2022-09-28 03:57:43,908 [foster.py] => Learning on 7-10
2022-09-28 03:57:43,908 [foster.py] => All params: 22371995
2022-09-28 03:57:43,909 [foster.py] => Trainable params: 11191892
2022-09-28 03:57:43,929 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 03:57:46,433 [foster.py] => Task 1, Epoch 1/34 => Loss 4.579, Loss_clf 2.004, Loss_fe 1.887, Loss_kd 0.482, Train_accy 42.26, Test_accy 71.96
2022-09-28 03:57:48,214 [foster.py] => Task 1, Epoch 2/34 => Loss 2.411, Loss_clf 0.603, Loss_fe 1.120, Loss_kd 0.482, Train_accy 79.40
2022-09-28 03:57:49,944 [foster.py] => Task 1, Epoch 3/34 => Loss 1.984, Loss_clf 0.380, Loss_fe 0.936, Loss_kd 0.467, Train_accy 55.77
2022-09-28 03:57:51,668 [foster.py] => Task 1, Epoch 4/34 => Loss 1.783, Loss_clf 0.318, Loss_fe 0.804, Loss_kd 0.463, Train_accy 56.96
2022-09-28 03:57:53,387 [foster.py] => Task 1, Epoch 5/34 => Loss 1.694, Loss_clf 0.317, Loss_fe 0.721, Loss_kd 0.459, Train_accy 54.86
2022-09-28 03:57:55,873 [foster.py] => Task 1, Epoch 6/34 => Loss 1.648, Loss_clf 0.302, Loss_fe 0.686, Loss_kd 0.462, Train_accy 56.43, Test_accy 77.10
2022-09-28 03:57:57,654 [foster.py] => Task 1, Epoch 7/34 => Loss 1.551, Loss_clf 0.279, Loss_fe 0.615, Loss_kd 0.460, Train_accy 58.79
2022-09-28 03:57:59,420 [foster.py] => Task 1, Epoch 8/34 => Loss 1.492, Loss_clf 0.259, Loss_fe 0.570, Loss_kd 0.464, Train_accy 58.01
2022-09-28 03:58:01,174 [foster.py] => Task 1, Epoch 9/34 => Loss 1.435, Loss_clf 0.244, Loss_fe 0.526, Loss_kd 0.465, Train_accy 61.29
2022-09-28 03:58:02,898 [foster.py] => Task 1, Epoch 10/34 => Loss 1.395, Loss_clf 0.233, Loss_fe 0.490, Loss_kd 0.470, Train_accy 63.39
2022-09-28 03:58:05,354 [foster.py] => Task 1, Epoch 11/34 => Loss 1.356, Loss_clf 0.227, Loss_fe 0.473, Loss_kd 0.459, Train_accy 60.37, Test_accy 78.04
2022-09-28 03:58:07,104 [foster.py] => Task 1, Epoch 12/34 => Loss 1.325, Loss_clf 0.221, Loss_fe 0.437, Loss_kd 0.467, Train_accy 60.89
2022-09-28 03:58:08,894 [foster.py] => Task 1, Epoch 13/34 => Loss 1.329, Loss_clf 0.235, Loss_fe 0.434, Loss_kd 0.462, Train_accy 62.73
2022-09-28 03:58:10,647 [foster.py] => Task 1, Epoch 14/34 => Loss 1.271, Loss_clf 0.210, Loss_fe 0.400, Loss_kd 0.463, Train_accy 62.99
2022-09-28 03:58:12,381 [foster.py] => Task 1, Epoch 15/34 => Loss 1.274, Loss_clf 0.214, Loss_fe 0.397, Loss_kd 0.464, Train_accy 62.07
2022-09-28 03:58:14,816 [foster.py] => Task 1, Epoch 16/34 => Loss 1.241, Loss_clf 0.205, Loss_fe 0.378, Loss_kd 0.460, Train_accy 62.47, Test_accy 78.50
2022-09-28 03:58:16,571 [foster.py] => Task 1, Epoch 17/34 => Loss 1.216, Loss_clf 0.194, Loss_fe 0.368, Loss_kd 0.458, Train_accy 63.39
2022-09-28 03:58:18,345 [foster.py] => Task 1, Epoch 18/34 => Loss 1.223, Loss_clf 0.208, Loss_fe 0.369, Loss_kd 0.452, Train_accy 62.34
2022-09-28 03:58:20,086 [foster.py] => Task 1, Epoch 19/34 => Loss 1.187, Loss_clf 0.189, Loss_fe 0.341, Loss_kd 0.460, Train_accy 62.47
2022-09-28 03:58:21,835 [foster.py] => Task 1, Epoch 20/34 => Loss 1.178, Loss_clf 0.178, Loss_fe 0.335, Loss_kd 0.465, Train_accy 65.09
2022-09-28 03:58:24,252 [foster.py] => Task 1, Epoch 21/34 => Loss 1.148, Loss_clf 0.175, Loss_fe 0.321, Loss_kd 0.457, Train_accy 66.54, Test_accy 79.44
2022-09-28 03:58:25,994 [foster.py] => Task 1, Epoch 22/34 => Loss 1.170, Loss_clf 0.180, Loss_fe 0.334, Loss_kd 0.459, Train_accy 66.14
2022-09-28 03:58:27,734 [foster.py] => Task 1, Epoch 23/34 => Loss 1.146, Loss_clf 0.173, Loss_fe 0.322, Loss_kd 0.456, Train_accy 64.96
2022-09-28 03:58:29,452 [foster.py] => Task 1, Epoch 24/34 => Loss 1.140, Loss_clf 0.166, Loss_fe 0.313, Loss_kd 0.462, Train_accy 65.62
2022-09-28 03:58:31,160 [foster.py] => Task 1, Epoch 25/34 => Loss 1.155, Loss_clf 0.178, Loss_fe 0.315, Loss_kd 0.464, Train_accy 64.96
2022-09-28 03:58:33,613 [foster.py] => Task 1, Epoch 26/34 => Loss 1.165, Loss_clf 0.182, Loss_fe 0.323, Loss_kd 0.463, Train_accy 65.09, Test_accy 79.44
2022-09-28 03:58:35,351 [foster.py] => Task 1, Epoch 27/34 => Loss 1.115, Loss_clf 0.161, Loss_fe 0.301, Loss_kd 0.457, Train_accy 65.88
2022-09-28 03:58:37,093 [foster.py] => Task 1, Epoch 28/34 => Loss 1.136, Loss_clf 0.170, Loss_fe 0.311, Loss_kd 0.458, Train_accy 66.27
2022-09-28 03:58:38,815 [foster.py] => Task 1, Epoch 29/34 => Loss 1.128, Loss_clf 0.167, Loss_fe 0.303, Loss_kd 0.460, Train_accy 66.54
2022-09-28 03:58:40,579 [foster.py] => Task 1, Epoch 30/34 => Loss 1.118, Loss_clf 0.164, Loss_fe 0.299, Loss_kd 0.459, Train_accy 67.06
2022-09-28 03:58:43,013 [foster.py] => Task 1, Epoch 31/34 => Loss 1.126, Loss_clf 0.167, Loss_fe 0.303, Loss_kd 0.459, Train_accy 65.22, Test_accy 79.91
2022-09-28 03:58:44,746 [foster.py] => Task 1, Epoch 32/34 => Loss 1.118, Loss_clf 0.163, Loss_fe 0.291, Loss_kd 0.465, Train_accy 66.93
2022-09-28 03:58:46,471 [foster.py] => Task 1, Epoch 33/34 => Loss 1.151, Loss_clf 0.176, Loss_fe 0.322, Loss_kd 0.457, Train_accy 66.01
2022-09-28 03:58:48,227 [foster.py] => Task 1, Epoch 34/34 => Loss 1.123, Loss_clf 0.168, Loss_fe 0.303, Loss_kd 0.457, Train_accy 65.75
2022-09-28 03:58:48,227 [foster.py] => do not weight align teacher!
2022-09-28 03:58:48,228 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 03:58:51,051 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.605,  Train_accy 17.85, Test_accy 59.35
2022-09-28 03:58:52,962 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.450,  Train_accy 18.11
2022-09-28 03:58:54,870 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.380,  Train_accy 18.37
2022-09-28 03:58:56,807 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.311,  Train_accy 20.08
2022-09-28 03:58:58,764 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.286,  Train_accy 22.70
2022-09-28 03:59:01,375 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.267,  Train_accy 22.57, Test_accy 62.62
2022-09-28 03:59:03,313 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.261,  Train_accy 26.51
2022-09-28 03:59:05,227 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.253,  Train_accy 27.17
2022-09-28 03:59:07,153 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.242,  Train_accy 27.95
2022-09-28 03:59:09,101 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.231,  Train_accy 28.08
2022-09-28 03:59:11,691 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.231,  Train_accy 28.61, Test_accy 67.76
2022-09-28 03:59:13,602 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.224,  Train_accy 30.84
2022-09-28 03:59:15,508 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.217,  Train_accy 31.36
2022-09-28 03:59:17,438 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.219,  Train_accy 30.97
2022-09-28 03:59:19,338 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.212,  Train_accy 31.63
2022-09-28 03:59:21,938 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.208,  Train_accy 31.76, Test_accy 69.16
2022-09-28 03:59:23,876 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.213,  Train_accy 31.63
2022-09-28 03:59:25,818 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.211,  Train_accy 31.63
2022-09-28 03:59:27,769 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.208,  Train_accy 32.68
2022-09-28 03:59:29,705 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.210,  Train_accy 30.97
2022-09-28 03:59:32,365 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.197,  Train_accy 31.63, Test_accy 69.63
2022-09-28 03:59:34,317 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.191,  Train_accy 32.68
2022-09-28 03:59:36,266 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.204,  Train_accy 32.68
2022-09-28 03:59:38,190 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.203,  Train_accy 32.68
2022-09-28 03:59:40,105 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.209,  Train_accy 32.02
2022-09-28 03:59:42,690 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.203,  Train_accy 33.46, Test_accy 70.09
2022-09-28 03:59:42,691 [foster.py] => do not weight align student!
2022-09-28 03:59:43,355 [foster.py] => darknet eval: 
2022-09-28 03:59:43,355 [foster.py] => CNN top1 curve: 70.09
2022-09-28 03:59:43,355 [foster.py] => CNN top5 curve: 97.66
2022-09-28 03:59:43,356 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 03:59:49,615 [foster.py] => Exemplar size: 200
2022-09-28 03:59:49,615 [trainer.py] => CNN: {'total': 80.37, 'old': 87.92, 'new': 63.08, 'base': 87.92, 'compound': 63.08}
2022-09-28 03:59:49,615 [trainer.py] => CNN top1 curve: [87.92, 80.37]
2022-09-28 03:59:49,615 [trainer.py] => CNN base curve: [87.92, 87.92]
2022-09-28 03:59:49,615 [trainer.py] => CNN old curve: [87.92, 87.92]
2022-09-28 03:59:49,615 [trainer.py] => CNN new curve: [0, 63.08]
2022-09-28 03:59:49,615 [trainer.py] => CNN compound curve: [0, 63.08]
2022-09-28 03:59:49,615 [trainer.py] => NME: {'total': 84.11, 'old': 85.91, 'new': 80.0, 'base': 85.91, 'compound': 80.0}
2022-09-28 03:59:49,615 [trainer.py] => NME top1 curve: [88.59, 84.11]
2022-09-28 03:59:49,615 [trainer.py] => NME base curve: [88.59, 85.91]
2022-09-28 03:59:49,615 [trainer.py] => NME old curve: [88.59, 85.91]
2022-09-28 03:59:49,615 [trainer.py] => NME new curve: [0, 80.0]
2022-09-28 03:59:49,615 [trainer.py] => NME compound curve: [0, 80.0]
2022-09-28 03:59:49,848 [foster.py] => Learning on 10-13
2022-09-28 03:59:49,848 [foster.py] => All params: 22378148
2022-09-28 03:59:49,848 [foster.py] => Trainable params: 11196506
2022-09-28 03:59:49,868 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 03:59:52,503 [foster.py] => Task 2, Epoch 1/34 => Loss 5.174, Loss_clf 1.974, Loss_fe 2.031, Loss_kd 0.899, Train_accy 40.62, Test_accy 53.08
2022-09-28 03:59:54,334 [foster.py] => Task 2, Epoch 2/34 => Loss 3.259, Loss_clf 0.743, Loss_fe 1.350, Loss_kd 0.896, Train_accy 59.01
2022-09-28 03:59:56,151 [foster.py] => Task 2, Epoch 3/34 => Loss 2.840, Loss_clf 0.543, Loss_fe 1.143, Loss_kd 0.888, Train_accy 48.40
2022-09-28 03:59:57,934 [foster.py] => Task 2, Epoch 4/34 => Loss 2.613, Loss_clf 0.466, Loss_fe 0.980, Loss_kd 0.897, Train_accy 52.35
2022-09-28 03:59:59,726 [foster.py] => Task 2, Epoch 5/34 => Loss 2.485, Loss_clf 0.431, Loss_fe 0.876, Loss_kd 0.906, Train_accy 52.47
2022-09-28 04:00:02,371 [foster.py] => Task 2, Epoch 6/34 => Loss 2.441, Loss_clf 0.436, Loss_fe 0.826, Loss_kd 0.907, Train_accy 53.83, Test_accy 65.07
2022-09-28 04:00:04,221 [foster.py] => Task 2, Epoch 7/34 => Loss 2.356, Loss_clf 0.420, Loss_fe 0.768, Loss_kd 0.898, Train_accy 51.36
2022-09-28 04:00:05,994 [foster.py] => Task 2, Epoch 8/34 => Loss 2.295, Loss_clf 0.420, Loss_fe 0.718, Loss_kd 0.891, Train_accy 53.33
2022-09-28 04:00:07,781 [foster.py] => Task 2, Epoch 9/34 => Loss 2.246, Loss_clf 0.412, Loss_fe 0.680, Loss_kd 0.888, Train_accy 51.36
2022-09-28 04:00:09,589 [foster.py] => Task 2, Epoch 10/34 => Loss 2.174, Loss_clf 0.369, Loss_fe 0.634, Loss_kd 0.900, Train_accy 52.84
2022-09-28 04:00:12,220 [foster.py] => Task 2, Epoch 11/34 => Loss 2.153, Loss_clf 0.367, Loss_fe 0.613, Loss_kd 0.902, Train_accy 52.35, Test_accy 66.78
2022-09-28 04:00:14,010 [foster.py] => Task 2, Epoch 12/34 => Loss 2.140, Loss_clf 0.378, Loss_fe 0.602, Loss_kd 0.893, Train_accy 52.59
2022-09-28 04:00:15,808 [foster.py] => Task 2, Epoch 13/34 => Loss 2.101, Loss_clf 0.365, Loss_fe 0.572, Loss_kd 0.895, Train_accy 54.57
2022-09-28 04:00:17,631 [foster.py] => Task 2, Epoch 14/34 => Loss 2.040, Loss_clf 0.336, Loss_fe 0.536, Loss_kd 0.899, Train_accy 53.21
2022-09-28 04:00:19,423 [foster.py] => Task 2, Epoch 15/34 => Loss 2.041, Loss_clf 0.358, Loss_fe 0.527, Loss_kd 0.888, Train_accy 52.72
2022-09-28 04:00:22,083 [foster.py] => Task 2, Epoch 16/34 => Loss 2.033, Loss_clf 0.347, Loss_fe 0.530, Loss_kd 0.889, Train_accy 53.33, Test_accy 67.81
2022-09-28 04:00:23,868 [foster.py] => Task 2, Epoch 17/34 => Loss 2.034, Loss_clf 0.356, Loss_fe 0.520, Loss_kd 0.891, Train_accy 54.94
2022-09-28 04:00:25,698 [foster.py] => Task 2, Epoch 18/34 => Loss 1.978, Loss_clf 0.335, Loss_fe 0.491, Loss_kd 0.887, Train_accy 53.21
2022-09-28 04:00:27,559 [foster.py] => Task 2, Epoch 19/34 => Loss 1.970, Loss_clf 0.316, Loss_fe 0.482, Loss_kd 0.902, Train_accy 56.91
2022-09-28 04:00:29,363 [foster.py] => Task 2, Epoch 20/34 => Loss 1.964, Loss_clf 0.321, Loss_fe 0.465, Loss_kd 0.906, Train_accy 55.19
2022-09-28 04:00:31,975 [foster.py] => Task 2, Epoch 21/34 => Loss 1.935, Loss_clf 0.310, Loss_fe 0.459, Loss_kd 0.898, Train_accy 53.70, Test_accy 67.81
2022-09-28 04:00:33,770 [foster.py] => Task 2, Epoch 22/34 => Loss 1.966, Loss_clf 0.338, Loss_fe 0.484, Loss_kd 0.881, Train_accy 51.48
2022-09-28 04:00:35,562 [foster.py] => Task 2, Epoch 23/34 => Loss 1.961, Loss_clf 0.332, Loss_fe 0.462, Loss_kd 0.898, Train_accy 54.69
2022-09-28 04:00:37,378 [foster.py] => Task 2, Epoch 24/34 => Loss 1.944, Loss_clf 0.327, Loss_fe 0.463, Loss_kd 0.887, Train_accy 51.36
2022-09-28 04:00:39,184 [foster.py] => Task 2, Epoch 25/34 => Loss 1.932, Loss_clf 0.313, Loss_fe 0.457, Loss_kd 0.894, Train_accy 55.31
2022-09-28 04:00:41,868 [foster.py] => Task 2, Epoch 26/34 => Loss 1.946, Loss_clf 0.325, Loss_fe 0.459, Loss_kd 0.894, Train_accy 55.19, Test_accy 68.15
2022-09-28 04:00:43,645 [foster.py] => Task 2, Epoch 27/34 => Loss 1.927, Loss_clf 0.312, Loss_fe 0.446, Loss_kd 0.899, Train_accy 55.80
2022-09-28 04:00:45,524 [foster.py] => Task 2, Epoch 28/34 => Loss 1.895, Loss_clf 0.301, Loss_fe 0.436, Loss_kd 0.891, Train_accy 55.80
2022-09-28 04:00:47,334 [foster.py] => Task 2, Epoch 29/34 => Loss 1.940, Loss_clf 0.319, Loss_fe 0.452, Loss_kd 0.900, Train_accy 55.80
2022-09-28 04:00:49,111 [foster.py] => Task 2, Epoch 30/34 => Loss 1.896, Loss_clf 0.301, Loss_fe 0.437, Loss_kd 0.891, Train_accy 53.83
2022-09-28 04:00:51,736 [foster.py] => Task 2, Epoch 31/34 => Loss 1.909, Loss_clf 0.315, Loss_fe 0.440, Loss_kd 0.887, Train_accy 53.33, Test_accy 67.47
2022-09-28 04:00:53,534 [foster.py] => Task 2, Epoch 32/34 => Loss 1.942, Loss_clf 0.320, Loss_fe 0.458, Loss_kd 0.895, Train_accy 54.07
2022-09-28 04:00:55,327 [foster.py] => Task 2, Epoch 33/34 => Loss 1.930, Loss_clf 0.329, Loss_fe 0.443, Loss_kd 0.891, Train_accy 55.43
2022-09-28 04:00:57,204 [foster.py] => Task 2, Epoch 34/34 => Loss 1.911, Loss_clf 0.309, Loss_fe 0.449, Loss_kd 0.887, Train_accy 54.81
2022-09-28 04:00:57,205 [foster.py] => do not weight align teacher!
2022-09-28 04:00:57,205 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 04:01:00,147 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.761,  Train_accy 17.04, Test_accy 48.97
2022-09-28 04:01:02,205 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.677,  Train_accy 17.41
2022-09-28 04:01:04,203 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.635,  Train_accy 18.15
2022-09-28 04:01:06,330 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.605,  Train_accy 18.89
2022-09-28 04:01:08,340 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.592,  Train_accy 18.64
2022-09-28 04:01:11,085 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.576,  Train_accy 18.77, Test_accy 52.40
2022-09-28 04:01:13,122 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.568,  Train_accy 18.64
2022-09-28 04:01:15,127 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.577,  Train_accy 19.38
2022-09-28 04:01:17,157 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.572,  Train_accy 19.14
2022-09-28 04:01:19,135 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.558,  Train_accy 19.75
2022-09-28 04:01:21,855 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.560,  Train_accy 20.74, Test_accy 54.79
2022-09-28 04:01:23,845 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.547,  Train_accy 20.99
2022-09-28 04:01:25,883 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.554,  Train_accy 21.36
2022-09-28 04:01:27,950 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.530,  Train_accy 21.98
2022-09-28 04:01:29,965 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.535,  Train_accy 21.85
2022-09-28 04:01:32,693 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.540,  Train_accy 21.73, Test_accy 55.14
2022-09-28 04:01:34,679 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.537,  Train_accy 22.59
2022-09-28 04:01:36,725 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.531,  Train_accy 21.48
2022-09-28 04:01:38,739 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.537,  Train_accy 21.85
2022-09-28 04:01:40,779 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.533,  Train_accy 22.59
2022-09-28 04:01:43,489 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.529,  Train_accy 22.35, Test_accy 56.51
2022-09-28 04:01:45,507 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.529,  Train_accy 22.59
2022-09-28 04:01:47,495 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.534,  Train_accy 22.22
2022-09-28 04:01:49,508 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.525,  Train_accy 21.85
2022-09-28 04:01:51,531 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.527,  Train_accy 22.22
2022-09-28 04:01:54,295 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.528,  Train_accy 21.23, Test_accy 56.51
2022-09-28 04:01:54,295 [foster.py] => do not weight align student!
2022-09-28 04:01:55,045 [foster.py] => darknet eval: 
2022-09-28 04:01:55,045 [foster.py] => CNN top1 curve: 56.51
2022-09-28 04:01:55,045 [foster.py] => CNN top5 curve: 97.26
2022-09-28 04:01:55,046 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 04:02:02,379 [foster.py] => Exemplar size: 260
2022-09-28 04:02:02,379 [trainer.py] => CNN: {'total': 68.15, 'old': 76.64, 'new': 44.87, 'base': 84.56, 'compound': 51.05}
2022-09-28 04:02:02,379 [trainer.py] => CNN top1 curve: [87.92, 80.37, 68.15]
2022-09-28 04:02:02,379 [trainer.py] => CNN base curve: [87.92, 87.92, 84.56]
2022-09-28 04:02:02,379 [trainer.py] => CNN old curve: [87.92, 87.92, 76.64]
2022-09-28 04:02:02,379 [trainer.py] => CNN new curve: [0, 63.08, 44.87]
2022-09-28 04:02:02,379 [trainer.py] => CNN compound curve: [0, 63.08, 51.05]
2022-09-28 04:02:02,379 [trainer.py] => NME: {'total': 74.66, 'old': 75.23, 'new': 73.08, 'base': 76.51, 'compound': 72.73}
2022-09-28 04:02:02,379 [trainer.py] => NME top1 curve: [88.59, 84.11, 74.66]
2022-09-28 04:02:02,379 [trainer.py] => NME base curve: [88.59, 85.91, 76.51]
2022-09-28 04:02:02,379 [trainer.py] => NME old curve: [88.59, 85.91, 75.23]
2022-09-28 04:02:02,379 [trainer.py] => NME new curve: [0, 80.0, 73.08]
2022-09-28 04:02:02,379 [trainer.py] => NME compound curve: [0, 80.0, 72.73]
2022-09-28 04:02:02,607 [foster.py] => Learning on 13-16
2022-09-28 04:02:02,607 [foster.py] => All params: 22384301
2022-09-28 04:02:02,607 [foster.py] => Trainable params: 11201120
2022-09-28 04:02:02,628 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 04:02:05,401 [foster.py] => Task 3, Epoch 1/34 => Loss 6.305, Loss_clf 2.264, Loss_fe 2.446, Loss_kd 1.296, Train_accy 35.10, Test_accy 45.99
2022-09-28 04:02:07,325 [foster.py] => Task 3, Epoch 2/34 => Loss 4.393, Loss_clf 1.051, Loss_fe 1.752, Loss_kd 1.292, Train_accy 35.68
2022-09-28 04:02:09,246 [foster.py] => Task 3, Epoch 3/34 => Loss 4.151, Loss_clf 0.963, Loss_fe 1.615, Loss_kd 1.278, Train_accy 36.72
2022-09-28 04:02:11,130 [foster.py] => Task 3, Epoch 4/34 => Loss 3.903, Loss_clf 0.907, Loss_fe 1.464, Loss_kd 1.245, Train_accy 36.03
2022-09-28 04:02:13,068 [foster.py] => Task 3, Epoch 5/34 => Loss 3.790, Loss_clf 0.883, Loss_fe 1.318, Loss_kd 1.291, Train_accy 38.57
2022-09-28 04:02:15,787 [foster.py] => Task 3, Epoch 6/34 => Loss 3.703, Loss_clf 0.846, Loss_fe 1.286, Loss_kd 1.277, Train_accy 39.49, Test_accy 54.81
2022-09-28 04:02:17,703 [foster.py] => Task 3, Epoch 7/34 => Loss 3.605, Loss_clf 0.829, Loss_fe 1.239, Loss_kd 1.249, Train_accy 37.99
2022-09-28 04:02:19,592 [foster.py] => Task 3, Epoch 8/34 => Loss 3.579, Loss_clf 0.868, Loss_fe 1.147, Loss_kd 1.272, Train_accy 39.61
2022-09-28 04:02:21,478 [foster.py] => Task 3, Epoch 9/34 => Loss 3.481, Loss_clf 0.783, Loss_fe 1.141, Loss_kd 1.265, Train_accy 40.30
2022-09-28 04:02:23,381 [foster.py] => Task 3, Epoch 10/34 => Loss 3.443, Loss_clf 0.774, Loss_fe 1.094, Loss_kd 1.280, Train_accy 41.69
2022-09-28 04:02:26,164 [foster.py] => Task 3, Epoch 11/34 => Loss 3.448, Loss_clf 0.824, Loss_fe 1.054, Loss_kd 1.276, Train_accy 37.64, Test_accy 57.22
2022-09-28 04:02:28,085 [foster.py] => Task 3, Epoch 12/34 => Loss 3.387, Loss_clf 0.770, Loss_fe 1.023, Loss_kd 1.295, Train_accy 40.30
2022-09-28 04:02:29,966 [foster.py] => Task 3, Epoch 13/34 => Loss 3.342, Loss_clf 0.760, Loss_fe 1.032, Loss_kd 1.259, Train_accy 41.22
2022-09-28 04:02:31,844 [foster.py] => Task 3, Epoch 14/34 => Loss 3.243, Loss_clf 0.715, Loss_fe 0.952, Loss_kd 1.281, Train_accy 39.84
2022-09-28 04:02:33,721 [foster.py] => Task 3, Epoch 15/34 => Loss 3.213, Loss_clf 0.731, Loss_fe 0.916, Loss_kd 1.273, Train_accy 43.53
2022-09-28 04:02:36,470 [foster.py] => Task 3, Epoch 16/34 => Loss 3.204, Loss_clf 0.728, Loss_fe 0.901, Loss_kd 1.279, Train_accy 42.73, Test_accy 56.42
2022-09-28 04:02:38,346 [foster.py] => Task 3, Epoch 17/34 => Loss 3.144, Loss_clf 0.688, Loss_fe 0.867, Loss_kd 1.292, Train_accy 43.19
2022-09-28 04:02:40,273 [foster.py] => Task 3, Epoch 18/34 => Loss 3.234, Loss_clf 0.744, Loss_fe 0.920, Loss_kd 1.275, Train_accy 44.46
2022-09-28 04:02:42,212 [foster.py] => Task 3, Epoch 19/34 => Loss 3.112, Loss_clf 0.703, Loss_fe 0.842, Loss_kd 1.273, Train_accy 43.88
2022-09-28 04:02:44,085 [foster.py] => Task 3, Epoch 20/34 => Loss 3.185, Loss_clf 0.716, Loss_fe 0.895, Loss_kd 1.279, Train_accy 43.88
2022-09-28 04:02:46,871 [foster.py] => Task 3, Epoch 21/34 => Loss 3.101, Loss_clf 0.677, Loss_fe 0.860, Loss_kd 1.270, Train_accy 46.65, Test_accy 58.29
2022-09-28 04:02:48,769 [foster.py] => Task 3, Epoch 22/34 => Loss 3.120, Loss_clf 0.676, Loss_fe 0.852, Loss_kd 1.293, Train_accy 45.27
2022-09-28 04:02:50,725 [foster.py] => Task 3, Epoch 23/34 => Loss 3.042, Loss_clf 0.662, Loss_fe 0.829, Loss_kd 1.260, Train_accy 41.80
2022-09-28 04:02:52,640 [foster.py] => Task 3, Epoch 24/34 => Loss 3.071, Loss_clf 0.632, Loss_fe 0.850, Loss_kd 1.291, Train_accy 43.76
2022-09-28 04:02:54,552 [foster.py] => Task 3, Epoch 25/34 => Loss 3.120, Loss_clf 0.655, Loss_fe 0.900, Loss_kd 1.271, Train_accy 45.84
2022-09-28 04:02:57,314 [foster.py] => Task 3, Epoch 26/34 => Loss 2.995, Loss_clf 0.608, Loss_fe 0.820, Loss_kd 1.273, Train_accy 44.69, Test_accy 57.75
2022-09-28 04:02:59,223 [foster.py] => Task 3, Epoch 27/34 => Loss 2.975, Loss_clf 0.626, Loss_fe 0.776, Loss_kd 1.278, Train_accy 44.57
2022-09-28 04:03:01,123 [foster.py] => Task 3, Epoch 28/34 => Loss 2.973, Loss_clf 0.627, Loss_fe 0.775, Loss_kd 1.276, Train_accy 43.88
2022-09-28 04:03:02,989 [foster.py] => Task 3, Epoch 29/34 => Loss 3.039, Loss_clf 0.664, Loss_fe 0.809, Loss_kd 1.272, Train_accy 45.61
2022-09-28 04:03:04,869 [foster.py] => Task 3, Epoch 30/34 => Loss 3.081, Loss_clf 0.676, Loss_fe 0.825, Loss_kd 1.284, Train_accy 45.50
2022-09-28 04:03:07,612 [foster.py] => Task 3, Epoch 31/34 => Loss 2.982, Loss_clf 0.605, Loss_fe 0.811, Loss_kd 1.272, Train_accy 44.69, Test_accy 57.22
2022-09-28 04:03:09,479 [foster.py] => Task 3, Epoch 32/34 => Loss 3.046, Loss_clf 0.628, Loss_fe 0.847, Loss_kd 1.277, Train_accy 45.96
2022-09-28 04:03:11,411 [foster.py] => Task 3, Epoch 33/34 => Loss 3.101, Loss_clf 0.677, Loss_fe 0.839, Loss_kd 1.288, Train_accy 44.11
2022-09-28 04:03:13,293 [foster.py] => Task 3, Epoch 34/34 => Loss 2.943, Loss_clf 0.599, Loss_fe 0.766, Loss_kd 1.282, Train_accy 44.57
2022-09-28 04:03:13,293 [foster.py] => do not weight align teacher!
2022-09-28 04:03:13,294 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 04:03:16,413 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.173,  Train_accy 19.05, Test_accy 42.78
2022-09-28 04:03:18,548 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.041,  Train_accy 19.40
2022-09-28 04:03:20,693 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 1.996,  Train_accy 20.79
2022-09-28 04:03:22,831 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.008,  Train_accy 19.75
2022-09-28 04:03:24,929 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.952,  Train_accy 20.32
2022-09-28 04:03:27,871 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.979,  Train_accy 20.32, Test_accy 45.99
2022-09-28 04:03:30,024 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.946,  Train_accy 20.67
2022-09-28 04:03:32,129 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.937,  Train_accy 20.55
2022-09-28 04:03:34,245 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.941,  Train_accy 21.02
2022-09-28 04:03:36,347 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.936,  Train_accy 20.21
2022-09-28 04:03:39,203 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.943,  Train_accy 21.25, Test_accy 47.33
2022-09-28 04:03:41,341 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.929,  Train_accy 20.90
2022-09-28 04:03:43,494 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.929,  Train_accy 20.79
2022-09-28 04:03:45,654 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.908,  Train_accy 22.52
2022-09-28 04:03:47,818 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.941,  Train_accy 20.90
2022-09-28 04:03:50,712 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.916,  Train_accy 21.13, Test_accy 49.20
2022-09-28 04:03:52,809 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.906,  Train_accy 20.67
2022-09-28 04:03:54,905 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.912,  Train_accy 21.13
2022-09-28 04:03:57,041 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.931,  Train_accy 20.90
2022-09-28 04:03:59,155 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.931,  Train_accy 21.94
2022-09-28 04:04:02,120 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.910,  Train_accy 22.06, Test_accy 47.59
2022-09-28 04:04:04,216 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.906,  Train_accy 21.82
2022-09-28 04:04:06,352 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.927,  Train_accy 20.79
2022-09-28 04:04:08,468 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.898,  Train_accy 19.98
2022-09-28 04:04:10,610 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.924,  Train_accy 21.36
2022-09-28 04:04:13,490 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.920,  Train_accy 21.13, Test_accy 48.40
2022-09-28 04:04:13,491 [foster.py] => do not weight align student!
2022-09-28 04:04:14,310 [foster.py] => darknet eval: 
2022-09-28 04:04:14,310 [foster.py] => CNN top1 curve: 48.4
2022-09-28 04:04:14,310 [foster.py] => CNN top5 curve: 88.77
2022-09-28 04:04:14,311 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 04:04:22,854 [foster.py] => Exemplar size: 320
2022-09-28 04:04:22,854 [trainer.py] => CNN: {'total': 57.49, 'old': 67.81, 'new': 20.73, 'base': 77.18, 'compound': 44.44}
2022-09-28 04:04:22,854 [trainer.py] => CNN top1 curve: [87.92, 80.37, 68.15, 57.49]
2022-09-28 04:04:22,854 [trainer.py] => CNN base curve: [87.92, 87.92, 84.56, 77.18]
2022-09-28 04:04:22,854 [trainer.py] => CNN old curve: [87.92, 87.92, 76.64, 67.81]
2022-09-28 04:04:22,854 [trainer.py] => CNN new curve: [0, 63.08, 44.87, 20.73]
2022-09-28 04:04:22,854 [trainer.py] => CNN compound curve: [0, 63.08, 51.05, 44.44]
2022-09-28 04:04:22,854 [trainer.py] => NME: {'total': 63.37, 'old': 68.49, 'new': 45.12, 'base': 70.47, 'compound': 58.67}
2022-09-28 04:04:22,854 [trainer.py] => NME top1 curve: [88.59, 84.11, 74.66, 63.37]
2022-09-28 04:04:22,854 [trainer.py] => NME base curve: [88.59, 85.91, 76.51, 70.47]
2022-09-28 04:04:22,854 [trainer.py] => NME old curve: [88.59, 85.91, 75.23, 68.49]
2022-09-28 04:04:22,854 [trainer.py] => NME new curve: [0, 80.0, 73.08, 45.12]
2022-09-28 04:04:22,854 [trainer.py] => NME compound curve: [0, 80.0, 72.73, 58.67]
2022-09-28 04:04:23,083 [foster.py] => Learning on 16-19
2022-09-28 04:04:23,083 [foster.py] => All params: 22390454
2022-09-28 04:04:23,083 [foster.py] => Trainable params: 11205734
2022-09-28 04:04:23,104 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 04:04:26,075 [foster.py] => Task 4, Epoch 1/34 => Loss 6.221, Loss_clf 1.957, Loss_fe 2.329, Loss_kd 1.629, Train_accy 37.38, Test_accy 40.41
2022-09-28 04:04:28,109 [foster.py] => Task 4, Epoch 2/34 => Loss 4.742, Loss_clf 1.068, Loss_fe 1.744, Loss_kd 1.625, Train_accy 38.76
2022-09-28 04:04:30,101 [foster.py] => Task 4, Epoch 3/34 => Loss 4.442, Loss_clf 0.975, Loss_fe 1.537, Loss_kd 1.625, Train_accy 40.26
2022-09-28 04:04:32,097 [foster.py] => Task 4, Epoch 4/34 => Loss 4.304, Loss_clf 0.958, Loss_fe 1.424, Loss_kd 1.619, Train_accy 38.98
2022-09-28 04:04:34,074 [foster.py] => Task 4, Epoch 5/34 => Loss 4.187, Loss_clf 0.933, Loss_fe 1.340, Loss_kd 1.612, Train_accy 39.83
2022-09-28 04:04:37,105 [foster.py] => Task 4, Epoch 6/34 => Loss 4.061, Loss_clf 0.884, Loss_fe 1.268, Loss_kd 1.608, Train_accy 39.40, Test_accy 45.37
2022-09-28 04:04:39,069 [foster.py] => Task 4, Epoch 7/34 => Loss 4.044, Loss_clf 0.897, Loss_fe 1.225, Loss_kd 1.618, Train_accy 40.15
2022-09-28 04:04:41,066 [foster.py] => Task 4, Epoch 8/34 => Loss 3.949, Loss_clf 0.857, Loss_fe 1.160, Loss_kd 1.626, Train_accy 42.28
2022-09-28 04:04:43,077 [foster.py] => Task 4, Epoch 9/34 => Loss 3.925, Loss_clf 0.871, Loss_fe 1.133, Loss_kd 1.617, Train_accy 40.47
2022-09-28 04:04:45,054 [foster.py] => Task 4, Epoch 10/34 => Loss 3.849, Loss_clf 0.839, Loss_fe 1.074, Loss_kd 1.630, Train_accy 39.51
2022-09-28 04:04:47,984 [foster.py] => Task 4, Epoch 11/34 => Loss 3.814, Loss_clf 0.831, Loss_fe 1.055, Loss_kd 1.624, Train_accy 41.21, Test_accy 46.28
2022-09-28 04:04:49,972 [foster.py] => Task 4, Epoch 12/34 => Loss 3.733, Loss_clf 0.800, Loss_fe 1.002, Loss_kd 1.626, Train_accy 39.19
2022-09-28 04:04:51,996 [foster.py] => Task 4, Epoch 13/34 => Loss 3.727, Loss_clf 0.809, Loss_fe 0.990, Loss_kd 1.624, Train_accy 42.17
2022-09-28 04:04:54,002 [foster.py] => Task 4, Epoch 14/34 => Loss 3.711, Loss_clf 0.799, Loss_fe 0.976, Loss_kd 1.631, Train_accy 41.75
2022-09-28 04:04:55,987 [foster.py] => Task 4, Epoch 15/34 => Loss 3.658, Loss_clf 0.774, Loss_fe 0.949, Loss_kd 1.630, Train_accy 43.56
2022-09-28 04:04:58,928 [foster.py] => Task 4, Epoch 16/34 => Loss 3.668, Loss_clf 0.801, Loss_fe 0.946, Loss_kd 1.618, Train_accy 41.96, Test_accy 46.95
2022-09-28 04:05:00,938 [foster.py] => Task 4, Epoch 17/34 => Loss 3.670, Loss_clf 0.785, Loss_fe 0.941, Loss_kd 1.637, Train_accy 41.64
2022-09-28 04:05:02,923 [foster.py] => Task 4, Epoch 18/34 => Loss 3.598, Loss_clf 0.763, Loss_fe 0.914, Loss_kd 1.618, Train_accy 41.85
2022-09-28 04:05:04,938 [foster.py] => Task 4, Epoch 19/34 => Loss 3.593, Loss_clf 0.757, Loss_fe 0.900, Loss_kd 1.630, Train_accy 43.24
2022-09-28 04:05:07,016 [foster.py] => Task 4, Epoch 20/34 => Loss 3.608, Loss_clf 0.768, Loss_fe 0.907, Loss_kd 1.628, Train_accy 44.41
2022-09-28 04:05:10,000 [foster.py] => Task 4, Epoch 21/34 => Loss 3.555, Loss_clf 0.760, Loss_fe 0.869, Loss_kd 1.622, Train_accy 40.47, Test_accy 46.95
2022-09-28 04:05:12,026 [foster.py] => Task 4, Epoch 22/34 => Loss 3.543, Loss_clf 0.723, Loss_fe 0.870, Loss_kd 1.642, Train_accy 43.56
2022-09-28 04:05:14,062 [foster.py] => Task 4, Epoch 23/34 => Loss 3.582, Loss_clf 0.760, Loss_fe 0.886, Loss_kd 1.631, Train_accy 43.77
2022-09-28 04:05:16,096 [foster.py] => Task 4, Epoch 24/34 => Loss 3.506, Loss_clf 0.728, Loss_fe 0.846, Loss_kd 1.627, Train_accy 42.71
2022-09-28 04:05:18,169 [foster.py] => Task 4, Epoch 25/34 => Loss 3.515, Loss_clf 0.738, Loss_fe 0.847, Loss_kd 1.626, Train_accy 44.30
2022-09-28 04:05:21,100 [foster.py] => Task 4, Epoch 26/34 => Loss 3.482, Loss_clf 0.711, Loss_fe 0.831, Loss_kd 1.633, Train_accy 44.83, Test_accy 47.63
2022-09-28 04:05:23,086 [foster.py] => Task 4, Epoch 27/34 => Loss 3.483, Loss_clf 0.714, Loss_fe 0.830, Loss_kd 1.633, Train_accy 44.52
2022-09-28 04:05:25,088 [foster.py] => Task 4, Epoch 28/34 => Loss 3.480, Loss_clf 0.716, Loss_fe 0.828, Loss_kd 1.630, Train_accy 45.37
2022-09-28 04:05:27,071 [foster.py] => Task 4, Epoch 29/34 => Loss 3.508, Loss_clf 0.730, Loss_fe 0.841, Loss_kd 1.631, Train_accy 44.73
2022-09-28 04:05:29,066 [foster.py] => Task 4, Epoch 30/34 => Loss 3.454, Loss_clf 0.718, Loss_fe 0.813, Loss_kd 1.620, Train_accy 42.92
2022-09-28 04:05:32,063 [foster.py] => Task 4, Epoch 31/34 => Loss 3.493, Loss_clf 0.720, Loss_fe 0.837, Loss_kd 1.629, Train_accy 42.49, Test_accy 47.40
2022-09-28 04:05:34,073 [foster.py] => Task 4, Epoch 32/34 => Loss 3.448, Loss_clf 0.695, Loss_fe 0.819, Loss_kd 1.628, Train_accy 44.41
2022-09-28 04:05:36,079 [foster.py] => Task 4, Epoch 33/34 => Loss 3.475, Loss_clf 0.715, Loss_fe 0.830, Loss_kd 1.625, Train_accy 44.83
2022-09-28 04:05:38,097 [foster.py] => Task 4, Epoch 34/34 => Loss 3.448, Loss_clf 0.695, Loss_fe 0.816, Loss_kd 1.631, Train_accy 45.69
2022-09-28 04:05:38,097 [foster.py] => do not weight align teacher!
2022-09-28 04:05:38,098 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 04:05:41,409 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.293,  Train_accy 18.64, Test_accy 42.66
2022-09-28 04:05:43,664 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.250,  Train_accy 19.91
2022-09-28 04:05:45,918 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.215,  Train_accy 19.81
2022-09-28 04:05:48,145 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.204,  Train_accy 20.77
2022-09-28 04:05:50,367 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.202,  Train_accy 20.77
2022-09-28 04:05:53,418 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.201,  Train_accy 21.62, Test_accy 43.12
2022-09-28 04:05:55,680 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.186,  Train_accy 20.45
2022-09-28 04:05:57,905 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.185,  Train_accy 21.19
2022-09-28 04:06:00,145 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.178,  Train_accy 20.87
2022-09-28 04:06:02,380 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.180,  Train_accy 20.98
2022-09-28 04:06:05,527 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.168,  Train_accy 21.51, Test_accy 42.66
2022-09-28 04:06:07,773 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.181,  Train_accy 20.77
2022-09-28 04:06:10,002 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.186,  Train_accy 21.19
2022-09-28 04:06:12,255 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.173,  Train_accy 21.19
2022-09-28 04:06:14,526 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.183,  Train_accy 21.30
2022-09-28 04:06:17,596 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.174,  Train_accy 21.62, Test_accy 44.47
2022-09-28 04:06:19,806 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.168,  Train_accy 20.98
2022-09-28 04:06:22,066 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.177,  Train_accy 20.77
2022-09-28 04:06:24,328 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.163,  Train_accy 21.51
2022-09-28 04:06:26,565 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.164,  Train_accy 21.41
2022-09-28 04:06:29,664 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.166,  Train_accy 21.09, Test_accy 44.47
2022-09-28 04:06:31,933 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.165,  Train_accy 21.73
2022-09-28 04:06:34,177 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.171,  Train_accy 21.62
2022-09-28 04:06:36,415 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.159,  Train_accy 22.04
2022-09-28 04:06:38,669 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.166,  Train_accy 20.77
2022-09-28 04:06:41,710 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.164,  Train_accy 21.09, Test_accy 44.70
2022-09-28 04:06:41,711 [foster.py] => do not weight align student!
2022-09-28 04:06:42,556 [foster.py] => darknet eval: 
2022-09-28 04:06:42,556 [foster.py] => CNN top1 curve: 44.7
2022-09-28 04:06:42,556 [foster.py] => CNN top5 curve: 83.07
2022-09-28 04:06:42,557 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 04:06:52,188 [foster.py] => Exemplar size: 380
2022-09-28 04:06:52,188 [trainer.py] => CNN: {'total': 47.18, 'old': 51.6, 'new': 23.19, 'base': 72.48, 'compound': 34.35}
2022-09-28 04:06:52,188 [trainer.py] => CNN top1 curve: [87.92, 80.37, 68.15, 57.49, 47.18]
2022-09-28 04:06:52,188 [trainer.py] => CNN base curve: [87.92, 87.92, 84.56, 77.18, 72.48]
2022-09-28 04:06:52,188 [trainer.py] => CNN old curve: [87.92, 87.92, 76.64, 67.81, 51.6]
2022-09-28 04:06:52,188 [trainer.py] => CNN new curve: [0, 63.08, 44.87, 20.73, 23.19]
2022-09-28 04:06:52,188 [trainer.py] => CNN compound curve: [0, 63.08, 51.05, 44.44, 34.35]
2022-09-28 04:06:52,188 [trainer.py] => NME: {'total': 57.34, 'old': 59.63, 'new': 44.93, 'base': 66.44, 'compound': 52.72}
2022-09-28 04:06:52,188 [trainer.py] => NME top1 curve: [88.59, 84.11, 74.66, 63.37, 57.34]
2022-09-28 04:06:52,188 [trainer.py] => NME base curve: [88.59, 85.91, 76.51, 70.47, 66.44]
2022-09-28 04:06:52,188 [trainer.py] => NME old curve: [88.59, 85.91, 75.23, 68.49, 59.63]
2022-09-28 04:06:52,188 [trainer.py] => NME new curve: [0, 80.0, 73.08, 45.12, 44.93]
2022-09-28 04:06:52,188 [trainer.py] => NME compound curve: [0, 80.0, 72.73, 58.67, 52.72]
2022-09-28 04:06:52,421 [foster.py] => Learning on 19-22
2022-09-28 04:06:52,421 [foster.py] => All params: 22396607
2022-09-28 04:06:52,422 [foster.py] => Trainable params: 11210348
2022-09-28 04:06:52,442 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 04:06:55,529 [foster.py] => Task 5, Epoch 1/34 => Loss 6.533, Loss_clf 1.862, Loss_fe 2.541, Loss_kd 1.840, Train_accy 34.16, Test_accy 43.85
2022-09-28 04:06:57,631 [foster.py] => Task 5, Epoch 2/34 => Loss 5.064, Loss_clf 1.072, Loss_fe 1.849, Loss_kd 1.851, Train_accy 33.96
2022-09-28 04:06:59,699 [foster.py] => Task 5, Epoch 3/34 => Loss 4.795, Loss_clf 0.986, Loss_fe 1.670, Loss_kd 1.847, Train_accy 35.15
2022-09-28 04:07:01,814 [foster.py] => Task 5, Epoch 4/34 => Loss 4.636, Loss_clf 0.953, Loss_fe 1.551, Loss_kd 1.841, Train_accy 38.03
2022-09-28 04:07:03,919 [foster.py] => Task 5, Epoch 5/34 => Loss 4.520, Loss_clf 0.938, Loss_fe 1.446, Loss_kd 1.845, Train_accy 38.83
2022-09-28 04:07:06,991 [foster.py] => Task 5, Epoch 6/34 => Loss 4.411, Loss_clf 0.903, Loss_fe 1.371, Loss_kd 1.845, Train_accy 39.82, Test_accy 44.84
2022-09-28 04:07:09,152 [foster.py] => Task 5, Epoch 7/34 => Loss 4.326, Loss_clf 0.878, Loss_fe 1.315, Loss_kd 1.842, Train_accy 40.32
2022-09-28 04:07:11,333 [foster.py] => Task 5, Epoch 8/34 => Loss 4.250, Loss_clf 0.868, Loss_fe 1.242, Loss_kd 1.849, Train_accy 41.61
2022-09-28 04:07:13,455 [foster.py] => Task 5, Epoch 9/34 => Loss 4.190, Loss_clf 0.848, Loss_fe 1.206, Loss_kd 1.845, Train_accy 40.91
2022-09-28 04:07:15,545 [foster.py] => Task 5, Epoch 10/34 => Loss 4.142, Loss_clf 0.834, Loss_fe 1.166, Loss_kd 1.849, Train_accy 41.91
2022-09-28 04:07:18,651 [foster.py] => Task 5, Epoch 11/34 => Loss 4.082, Loss_clf 0.823, Loss_fe 1.127, Loss_kd 1.842, Train_accy 41.51, Test_accy 46.23
2022-09-28 04:07:20,778 [foster.py] => Task 5, Epoch 12/34 => Loss 4.072, Loss_clf 0.829, Loss_fe 1.111, Loss_kd 1.841, Train_accy 42.11
2022-09-28 04:07:22,875 [foster.py] => Task 5, Epoch 13/34 => Loss 4.017, Loss_clf 0.795, Loss_fe 1.079, Loss_kd 1.851, Train_accy 44.09
2022-09-28 04:07:24,999 [foster.py] => Task 5, Epoch 14/34 => Loss 3.968, Loss_clf 0.788, Loss_fe 1.055, Loss_kd 1.835, Train_accy 41.91
2022-09-28 04:07:27,077 [foster.py] => Task 5, Epoch 15/34 => Loss 3.943, Loss_clf 0.788, Loss_fe 1.013, Loss_kd 1.850, Train_accy 43.99
2022-09-28 04:07:30,204 [foster.py] => Task 5, Epoch 16/34 => Loss 3.932, Loss_clf 0.777, Loss_fe 1.014, Loss_kd 1.849, Train_accy 43.30, Test_accy 47.02
2022-09-28 04:07:32,298 [foster.py] => Task 5, Epoch 17/34 => Loss 3.930, Loss_clf 0.783, Loss_fe 1.001, Loss_kd 1.854, Train_accy 44.89
2022-09-28 04:07:34,445 [foster.py] => Task 5, Epoch 18/34 => Loss 3.880, Loss_clf 0.760, Loss_fe 0.970, Loss_kd 1.856, Train_accy 45.28
2022-09-28 04:07:36,537 [foster.py] => Task 5, Epoch 19/34 => Loss 3.867, Loss_clf 0.764, Loss_fe 0.965, Loss_kd 1.846, Train_accy 43.99
2022-09-28 04:07:38,627 [foster.py] => Task 5, Epoch 20/34 => Loss 3.858, Loss_clf 0.755, Loss_fe 0.958, Loss_kd 1.852, Train_accy 44.19
2022-09-28 04:07:41,721 [foster.py] => Task 5, Epoch 21/34 => Loss 3.848, Loss_clf 0.755, Loss_fe 0.957, Loss_kd 1.844, Train_accy 43.50, Test_accy 46.43
2022-09-28 04:07:43,853 [foster.py] => Task 5, Epoch 22/34 => Loss 3.801, Loss_clf 0.734, Loss_fe 0.925, Loss_kd 1.850, Train_accy 43.79
2022-09-28 04:07:45,961 [foster.py] => Task 5, Epoch 23/34 => Loss 3.818, Loss_clf 0.750, Loss_fe 0.924, Loss_kd 1.851, Train_accy 47.37
2022-09-28 04:07:48,078 [foster.py] => Task 5, Epoch 24/34 => Loss 3.780, Loss_clf 0.728, Loss_fe 0.906, Loss_kd 1.854, Train_accy 44.49
2022-09-28 04:07:50,192 [foster.py] => Task 5, Epoch 25/34 => Loss 3.763, Loss_clf 0.721, Loss_fe 0.901, Loss_kd 1.849, Train_accy 47.47
2022-09-28 04:07:53,286 [foster.py] => Task 5, Epoch 26/34 => Loss 3.809, Loss_clf 0.747, Loss_fe 0.925, Loss_kd 1.846, Train_accy 45.38, Test_accy 47.22
2022-09-28 04:07:55,408 [foster.py] => Task 5, Epoch 27/34 => Loss 3.755, Loss_clf 0.727, Loss_fe 0.892, Loss_kd 1.846, Train_accy 45.58
2022-09-28 04:07:57,494 [foster.py] => Task 5, Epoch 28/34 => Loss 3.761, Loss_clf 0.718, Loss_fe 0.899, Loss_kd 1.852, Train_accy 45.08
2022-09-28 04:07:59,583 [foster.py] => Task 5, Epoch 29/34 => Loss 3.776, Loss_clf 0.730, Loss_fe 0.902, Loss_kd 1.852, Train_accy 45.48
2022-09-28 04:08:01,716 [foster.py] => Task 5, Epoch 30/34 => Loss 3.803, Loss_clf 0.738, Loss_fe 0.913, Loss_kd 1.858, Train_accy 45.28
2022-09-28 04:08:04,779 [foster.py] => Task 5, Epoch 31/34 => Loss 3.757, Loss_clf 0.716, Loss_fe 0.902, Loss_kd 1.847, Train_accy 45.78, Test_accy 46.43
2022-09-28 04:08:06,891 [foster.py] => Task 5, Epoch 32/34 => Loss 3.777, Loss_clf 0.730, Loss_fe 0.896, Loss_kd 1.857, Train_accy 45.28
2022-09-28 04:08:09,001 [foster.py] => Task 5, Epoch 33/34 => Loss 3.783, Loss_clf 0.723, Loss_fe 0.905, Loss_kd 1.861, Train_accy 45.88
2022-09-28 04:08:11,081 [foster.py] => Task 5, Epoch 34/34 => Loss 3.736, Loss_clf 0.715, Loss_fe 0.877, Loss_kd 1.851, Train_accy 43.99
2022-09-28 04:08:11,081 [foster.py] => do not weight align teacher!
2022-09-28 04:08:11,082 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 04:08:14,528 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.406,  Train_accy 19.96, Test_accy 39.29
2022-09-28 04:08:16,882 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.373,  Train_accy 20.26
2022-09-28 04:08:19,219 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.368,  Train_accy 20.26
2022-09-28 04:08:21,587 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.348,  Train_accy 20.06
2022-09-28 04:08:23,955 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.342,  Train_accy 20.85
2022-09-28 04:08:27,236 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.343,  Train_accy 20.75, Test_accy 40.67
2022-09-28 04:08:29,612 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.347,  Train_accy 21.55
2022-09-28 04:08:31,997 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.326,  Train_accy 21.05
2022-09-28 04:08:34,379 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.326,  Train_accy 21.15
2022-09-28 04:08:36,759 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.317,  Train_accy 21.25
2022-09-28 04:08:39,937 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.322,  Train_accy 20.75, Test_accy 40.28
2022-09-28 04:08:42,358 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.324,  Train_accy 21.15
2022-09-28 04:08:44,728 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.310,  Train_accy 20.75
2022-09-28 04:08:47,129 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.306,  Train_accy 21.05
2022-09-28 04:08:49,504 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.313,  Train_accy 21.65
2022-09-28 04:08:52,700 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.314,  Train_accy 21.75, Test_accy 41.67
2022-09-28 04:08:55,075 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.306,  Train_accy 21.45
2022-09-28 04:08:57,459 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.308,  Train_accy 22.44
2022-09-28 04:08:59,815 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.302,  Train_accy 21.75
2022-09-28 04:09:02,191 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.307,  Train_accy 22.24
2022-09-28 04:09:05,417 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.312,  Train_accy 22.34, Test_accy 41.67
2022-09-28 04:09:07,790 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.301,  Train_accy 22.64
2022-09-28 04:09:10,148 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.310,  Train_accy 23.34
2022-09-28 04:09:12,558 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.300,  Train_accy 22.14
2022-09-28 04:09:14,937 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.306,  Train_accy 22.05
2022-09-28 04:09:18,224 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.313,  Train_accy 22.74, Test_accy 40.48
2022-09-28 04:09:18,224 [foster.py] => do not weight align student!
2022-09-28 04:09:19,066 [foster.py] => darknet eval: 
2022-09-28 04:09:19,066 [foster.py] => CNN top1 curve: 40.48
2022-09-28 04:09:19,066 [foster.py] => CNN top5 curve: 83.13
2022-09-28 04:09:19,067 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 04:09:29,704 [foster.py] => Exemplar size: 440
2022-09-28 04:09:29,704 [trainer.py] => CNN: {'total': 46.23, 'old': 49.66, 'new': 21.31, 'base': 71.14, 'compound': 35.77}
2022-09-28 04:09:29,704 [trainer.py] => CNN top1 curve: [87.92, 80.37, 68.15, 57.49, 47.18, 46.23]
2022-09-28 04:09:29,704 [trainer.py] => CNN base curve: [87.92, 87.92, 84.56, 77.18, 72.48, 71.14]
2022-09-28 04:09:29,704 [trainer.py] => CNN old curve: [87.92, 87.92, 76.64, 67.81, 51.6, 49.66]
2022-09-28 04:09:29,704 [trainer.py] => CNN new curve: [0, 63.08, 44.87, 20.73, 23.19, 21.31]
2022-09-28 04:09:29,704 [trainer.py] => CNN compound curve: [0, 63.08, 51.05, 44.44, 34.35, 35.77]
2022-09-28 04:09:29,704 [trainer.py] => NME: {'total': 54.17, 'old': 55.08, 'new': 47.54, 'base': 67.79, 'compound': 48.45}
2022-09-28 04:09:29,704 [trainer.py] => NME top1 curve: [88.59, 84.11, 74.66, 63.37, 57.34, 54.17]
2022-09-28 04:09:29,704 [trainer.py] => NME base curve: [88.59, 85.91, 76.51, 70.47, 66.44, 67.79]
2022-09-28 04:09:29,705 [trainer.py] => NME old curve: [88.59, 85.91, 75.23, 68.49, 59.63, 55.08]
2022-09-28 04:09:29,705 [trainer.py] => NME new curve: [0, 80.0, 73.08, 45.12, 44.93, 47.54]
2022-09-28 04:09:29,705 [trainer.py] => NME compound curve: [0, 80.0, 72.73, 58.67, 52.72, 48.45]
2022-09-28 04:09:29,706 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 04:09:29,706 [trainer.py] => prefix: cil
2022-09-28 04:09:29,706 [trainer.py] => dataset: CFEE
2022-09-28 04:09:29,706 [trainer.py] => memory_size: 2000
2022-09-28 04:09:29,706 [trainer.py] => memory_per_class: 20
2022-09-28 04:09:29,706 [trainer.py] => fixed_memory: True
2022-09-28 04:09:29,706 [trainer.py] => shuffle: True
2022-09-28 04:09:29,706 [trainer.py] => init_cls: 7
2022-09-28 04:09:29,706 [trainer.py] => increment: 3
2022-09-28 04:09:29,706 [trainer.py] => model_name: foster
2022-09-28 04:09:29,706 [trainer.py] => convnet_type: resnet18
2022-09-28 04:09:29,706 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 04:09:29,706 [trainer.py] => seed: 1993
2022-09-28 04:09:29,706 [trainer.py] => beta1: 0.96
2022-09-28 04:09:29,706 [trainer.py] => beta2: 0.97
2022-09-28 04:09:29,706 [trainer.py] => oofc: ft
2022-09-28 04:09:29,706 [trainer.py] => is_teacher_wa: False
2022-09-28 04:09:29,706 [trainer.py] => is_student_wa: False
2022-09-28 04:09:29,706 [trainer.py] => lambda_okd: 1
2022-09-28 04:09:29,706 [trainer.py] => wa_value: 1
2022-09-28 04:09:29,706 [trainer.py] => init_epochs: 40
2022-09-28 04:09:29,706 [trainer.py] => init_lr: 0.01
2022-09-28 04:09:29,706 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 04:09:29,707 [trainer.py] => boosting_epochs: 34
2022-09-28 04:09:29,707 [trainer.py] => compression_epochs: 26
2022-09-28 04:09:29,707 [trainer.py] => lr: 0.001
2022-09-28 04:09:29,707 [trainer.py] => batch_size: 32
2022-09-28 04:09:29,707 [trainer.py] => weight_decay: 0.0005
2022-09-28 04:09:29,707 [trainer.py] => num_workers: 8
2022-09-28 04:09:29,707 [trainer.py] => T: 2
2022-09-28 04:09:29,707 [trainer.py] => nb_runs: 3
2022-09-28 04:09:29,707 [trainer.py] => fold: 10
2022-09-28 04:09:29,707 [data.py] => ========== Fold:8 ==========
2022-09-28 04:09:29,712 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 8, 15, 13, 17, 9, 11, 19, 21, 14, 10, 18, 12, 7, 16]
2022-09-28 04:09:29,931 [foster.py] => Learning on 0-7
2022-09-28 04:09:29,931 [foster.py] => All params: 11183694
2022-09-28 04:09:29,931 [foster.py] => Trainable params: 11183694
2022-09-28 04:09:32,328 [foster.py] => Task 0, Epoch 1/40 => Loss 1.342, Train_accy 49.41
2022-09-28 04:09:35,296 [foster.py] => Task 0, Epoch 2/40 => Loss 0.543, Train_accy 80.81, Test_accy 89.24
2022-09-28 04:09:38,270 [foster.py] => Task 0, Epoch 3/40 => Loss 0.350, Train_accy 88.27, Test_accy 83.54
2022-09-28 04:09:41,264 [foster.py] => Task 0, Epoch 4/40 => Loss 0.318, Train_accy 89.23, Test_accy 83.54
2022-09-28 04:09:44,214 [foster.py] => Task 0, Epoch 5/40 => Loss 0.234, Train_accy 92.06, Test_accy 85.44
2022-09-28 04:09:46,672 [foster.py] => Task 0, Epoch 6/40 => Loss 0.190, Train_accy 93.51
2022-09-28 04:09:49,650 [foster.py] => Task 0, Epoch 7/40 => Loss 0.136, Train_accy 95.72, Test_accy 82.28
2022-09-28 04:09:52,647 [foster.py] => Task 0, Epoch 8/40 => Loss 0.139, Train_accy 95.24, Test_accy 87.97
2022-09-28 04:09:55,659 [foster.py] => Task 0, Epoch 9/40 => Loss 0.121, Train_accy 95.93, Test_accy 87.34
2022-09-28 04:09:58,709 [foster.py] => Task 0, Epoch 10/40 => Loss 0.079, Train_accy 98.21, Test_accy 85.44
2022-09-28 04:10:01,100 [foster.py] => Task 0, Epoch 11/40 => Loss 0.090, Train_accy 97.10
2022-09-28 04:10:04,160 [foster.py] => Task 0, Epoch 12/40 => Loss 0.079, Train_accy 97.17, Test_accy 87.34
2022-09-28 04:10:07,132 [foster.py] => Task 0, Epoch 13/40 => Loss 0.064, Train_accy 98.21, Test_accy 86.08
2022-09-28 04:10:10,105 [foster.py] => Task 0, Epoch 14/40 => Loss 0.056, Train_accy 98.21, Test_accy 85.44
2022-09-28 04:10:13,101 [foster.py] => Task 0, Epoch 15/40 => Loss 0.048, Train_accy 98.76, Test_accy 87.34
2022-09-28 04:10:15,461 [foster.py] => Task 0, Epoch 16/40 => Loss 0.036, Train_accy 99.03
2022-09-28 04:10:18,434 [foster.py] => Task 0, Epoch 17/40 => Loss 0.037, Train_accy 98.76, Test_accy 87.34
2022-09-28 04:10:21,522 [foster.py] => Task 0, Epoch 18/40 => Loss 0.034, Train_accy 99.17, Test_accy 86.71
2022-09-28 04:10:24,550 [foster.py] => Task 0, Epoch 19/40 => Loss 0.027, Train_accy 99.31, Test_accy 89.24
2022-09-28 04:10:27,560 [foster.py] => Task 0, Epoch 20/40 => Loss 0.028, Train_accy 99.59, Test_accy 86.71
2022-09-28 04:10:29,935 [foster.py] => Task 0, Epoch 21/40 => Loss 0.025, Train_accy 99.79
2022-09-28 04:10:32,908 [foster.py] => Task 0, Epoch 22/40 => Loss 0.018, Train_accy 99.86, Test_accy 88.61
2022-09-28 04:10:35,934 [foster.py] => Task 0, Epoch 23/40 => Loss 0.026, Train_accy 99.52, Test_accy 87.34
2022-09-28 04:10:38,908 [foster.py] => Task 0, Epoch 24/40 => Loss 0.021, Train_accy 99.52, Test_accy 87.97
2022-09-28 04:10:41,868 [foster.py] => Task 0, Epoch 25/40 => Loss 0.031, Train_accy 99.52, Test_accy 89.24
2022-09-28 04:10:44,237 [foster.py] => Task 0, Epoch 26/40 => Loss 0.019, Train_accy 99.79
2022-09-28 04:10:47,202 [foster.py] => Task 0, Epoch 27/40 => Loss 0.017, Train_accy 99.72, Test_accy 88.61
2022-09-28 04:10:50,215 [foster.py] => Task 0, Epoch 28/40 => Loss 0.019, Train_accy 99.65, Test_accy 87.97
2022-09-28 04:10:53,184 [foster.py] => Task 0, Epoch 29/40 => Loss 0.016, Train_accy 99.72, Test_accy 87.34
2022-09-28 04:10:56,155 [foster.py] => Task 0, Epoch 30/40 => Loss 0.014, Train_accy 99.86, Test_accy 88.61
2022-09-28 04:10:58,563 [foster.py] => Task 0, Epoch 31/40 => Loss 0.015, Train_accy 99.93
2022-09-28 04:11:01,605 [foster.py] => Task 0, Epoch 32/40 => Loss 0.013, Train_accy 100.00, Test_accy 87.97
2022-09-28 04:11:04,621 [foster.py] => Task 0, Epoch 33/40 => Loss 0.016, Train_accy 99.79, Test_accy 88.61
2022-09-28 04:11:07,608 [foster.py] => Task 0, Epoch 34/40 => Loss 0.019, Train_accy 99.79, Test_accy 88.61
2022-09-28 04:11:10,588 [foster.py] => Task 0, Epoch 35/40 => Loss 0.012, Train_accy 99.93, Test_accy 86.08
2022-09-28 04:11:12,988 [foster.py] => Task 0, Epoch 36/40 => Loss 0.011, Train_accy 99.93
2022-09-28 04:11:16,016 [foster.py] => Task 0, Epoch 37/40 => Loss 0.013, Train_accy 99.86, Test_accy 87.97
2022-09-28 04:11:18,960 [foster.py] => Task 0, Epoch 38/40 => Loss 0.013, Train_accy 99.93, Test_accy 88.61
2022-09-28 04:11:21,997 [foster.py] => Task 0, Epoch 39/40 => Loss 0.016, Train_accy 99.86, Test_accy 87.97
2022-09-28 04:11:24,977 [foster.py] => Task 0, Epoch 40/40 => Loss 0.016, Train_accy 99.59, Test_accy 88.61
2022-09-28 04:11:24,977 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 04:11:31,921 [foster.py] => Exemplar size: 140
2022-09-28 04:11:31,921 [trainer.py] => CNN: {'total': 88.61, 'old': 88.61, 'new': 0, 'base': 88.61, 'compound': 0}
2022-09-28 04:11:31,921 [trainer.py] => CNN top1 curve: [88.61]
2022-09-28 04:11:31,921 [trainer.py] => CNN base curve: [88.61]
2022-09-28 04:11:31,921 [trainer.py] => CNN old curve: [88.61]
2022-09-28 04:11:31,921 [trainer.py] => CNN new curve: [0]
2022-09-28 04:11:31,921 [trainer.py] => CNN compound curve: [0]
2022-09-28 04:11:31,921 [trainer.py] => NME: {'total': 85.44, 'old': 85.44, 'new': 0, 'base': 85.44, 'compound': 0}
2022-09-28 04:11:31,921 [trainer.py] => NME top1 curve: [85.44]
2022-09-28 04:11:31,921 [trainer.py] => NME base curve: [85.44]
2022-09-28 04:11:31,922 [trainer.py] => NME old curve: [85.44]
2022-09-28 04:11:31,922 [trainer.py] => NME new curve: [0]
2022-09-28 04:11:31,922 [trainer.py] => NME compound curve: [0]
2022-09-28 04:11:32,155 [foster.py] => Learning on 7-10
2022-09-28 04:11:32,155 [foster.py] => All params: 22371995
2022-09-28 04:11:32,155 [foster.py] => Trainable params: 11191892
2022-09-28 04:11:32,176 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 04:11:34,683 [foster.py] => Task 1, Epoch 1/34 => Loss 4.320, Loss_clf 1.914, Loss_fe 1.741, Loss_kd 0.466, Train_accy 39.08, Test_accy 66.36
2022-09-28 04:11:36,451 [foster.py] => Task 1, Epoch 2/34 => Loss 2.476, Loss_clf 0.645, Loss_fe 1.150, Loss_kd 0.476, Train_accy 75.29
2022-09-28 04:11:38,155 [foster.py] => Task 1, Epoch 3/34 => Loss 1.976, Loss_clf 0.402, Loss_fe 0.919, Loss_kd 0.458, Train_accy 50.46
2022-09-28 04:11:39,861 [foster.py] => Task 1, Epoch 4/34 => Loss 1.775, Loss_clf 0.341, Loss_fe 0.787, Loss_kd 0.453, Train_accy 52.03
2022-09-28 04:11:41,600 [foster.py] => Task 1, Epoch 5/34 => Loss 1.652, Loss_clf 0.304, Loss_fe 0.708, Loss_kd 0.449, Train_accy 54.25
2022-09-28 04:11:44,089 [foster.py] => Task 1, Epoch 6/34 => Loss 1.574, Loss_clf 0.293, Loss_fe 0.635, Loss_kd 0.452, Train_accy 53.46, Test_accy 75.00
2022-09-28 04:11:45,806 [foster.py] => Task 1, Epoch 7/34 => Loss 1.501, Loss_clf 0.278, Loss_fe 0.577, Loss_kd 0.452, Train_accy 53.33
2022-09-28 04:11:47,579 [foster.py] => Task 1, Epoch 8/34 => Loss 1.465, Loss_clf 0.269, Loss_fe 0.552, Loss_kd 0.451, Train_accy 53.20
2022-09-28 04:11:49,331 [foster.py] => Task 1, Epoch 9/34 => Loss 1.415, Loss_clf 0.249, Loss_fe 0.517, Loss_kd 0.454, Train_accy 56.99
2022-09-28 04:11:51,109 [foster.py] => Task 1, Epoch 10/34 => Loss 1.379, Loss_clf 0.249, Loss_fe 0.489, Loss_kd 0.449, Train_accy 58.04
2022-09-28 04:11:53,544 [foster.py] => Task 1, Epoch 11/34 => Loss 1.307, Loss_clf 0.222, Loss_fe 0.448, Loss_kd 0.445, Train_accy 54.77, Test_accy 76.36
2022-09-28 04:11:55,297 [foster.py] => Task 1, Epoch 12/34 => Loss 1.282, Loss_clf 0.220, Loss_fe 0.429, Loss_kd 0.444, Train_accy 57.52
2022-09-28 04:11:57,017 [foster.py] => Task 1, Epoch 13/34 => Loss 1.265, Loss_clf 0.222, Loss_fe 0.407, Loss_kd 0.446, Train_accy 57.52
2022-09-28 04:11:58,749 [foster.py] => Task 1, Epoch 14/34 => Loss 1.258, Loss_clf 0.208, Loss_fe 0.406, Loss_kd 0.451, Train_accy 59.87
2022-09-28 04:12:00,533 [foster.py] => Task 1, Epoch 15/34 => Loss 1.221, Loss_clf 0.199, Loss_fe 0.380, Loss_kd 0.450, Train_accy 59.22
2022-09-28 04:12:03,020 [foster.py] => Task 1, Epoch 16/34 => Loss 1.212, Loss_clf 0.203, Loss_fe 0.364, Loss_kd 0.452, Train_accy 60.52, Test_accy 75.91
2022-09-28 04:12:04,786 [foster.py] => Task 1, Epoch 17/34 => Loss 1.205, Loss_clf 0.198, Loss_fe 0.364, Loss_kd 0.450, Train_accy 61.31
2022-09-28 04:12:06,495 [foster.py] => Task 1, Epoch 18/34 => Loss 1.207, Loss_clf 0.203, Loss_fe 0.355, Loss_kd 0.454, Train_accy 60.13
2022-09-28 04:12:08,233 [foster.py] => Task 1, Epoch 19/34 => Loss 1.163, Loss_clf 0.176, Loss_fe 0.337, Loss_kd 0.455, Train_accy 61.96
2022-09-28 04:12:09,942 [foster.py] => Task 1, Epoch 20/34 => Loss 1.148, Loss_clf 0.183, Loss_fe 0.323, Loss_kd 0.450, Train_accy 60.39
2022-09-28 04:12:12,423 [foster.py] => Task 1, Epoch 21/34 => Loss 1.157, Loss_clf 0.184, Loss_fe 0.330, Loss_kd 0.450, Train_accy 60.26, Test_accy 76.82
2022-09-28 04:12:14,137 [foster.py] => Task 1, Epoch 22/34 => Loss 1.156, Loss_clf 0.187, Loss_fe 0.318, Loss_kd 0.456, Train_accy 62.61
2022-09-28 04:12:15,868 [foster.py] => Task 1, Epoch 23/34 => Loss 1.133, Loss_clf 0.175, Loss_fe 0.317, Loss_kd 0.448, Train_accy 63.01
2022-09-28 04:12:17,612 [foster.py] => Task 1, Epoch 24/34 => Loss 1.122, Loss_clf 0.169, Loss_fe 0.311, Loss_kd 0.449, Train_accy 61.44
2022-09-28 04:12:19,341 [foster.py] => Task 1, Epoch 25/34 => Loss 1.093, Loss_clf 0.159, Loss_fe 0.297, Loss_kd 0.446, Train_accy 61.18
2022-09-28 04:12:21,815 [foster.py] => Task 1, Epoch 26/34 => Loss 1.135, Loss_clf 0.176, Loss_fe 0.311, Loss_kd 0.454, Train_accy 62.61, Test_accy 77.27
2022-09-28 04:12:23,585 [foster.py] => Task 1, Epoch 27/34 => Loss 1.089, Loss_clf 0.155, Loss_fe 0.287, Loss_kd 0.452, Train_accy 62.61
2022-09-28 04:12:25,363 [foster.py] => Task 1, Epoch 28/34 => Loss 1.083, Loss_clf 0.153, Loss_fe 0.289, Loss_kd 0.449, Train_accy 63.79
2022-09-28 04:12:27,101 [foster.py] => Task 1, Epoch 29/34 => Loss 1.084, Loss_clf 0.165, Loss_fe 0.288, Loss_kd 0.442, Train_accy 61.96
2022-09-28 04:12:28,867 [foster.py] => Task 1, Epoch 30/34 => Loss 1.103, Loss_clf 0.172, Loss_fe 0.291, Loss_kd 0.448, Train_accy 62.09
2022-09-28 04:12:31,360 [foster.py] => Task 1, Epoch 31/34 => Loss 1.098, Loss_clf 0.158, Loss_fe 0.296, Loss_kd 0.451, Train_accy 63.14, Test_accy 77.27
2022-09-28 04:12:33,075 [foster.py] => Task 1, Epoch 32/34 => Loss 1.074, Loss_clf 0.154, Loss_fe 0.284, Loss_kd 0.445, Train_accy 63.27
2022-09-28 04:12:34,804 [foster.py] => Task 1, Epoch 33/34 => Loss 1.099, Loss_clf 0.173, Loss_fe 0.301, Loss_kd 0.437, Train_accy 60.65
2022-09-28 04:12:36,517 [foster.py] => Task 1, Epoch 34/34 => Loss 1.075, Loss_clf 0.148, Loss_fe 0.283, Loss_kd 0.450, Train_accy 63.14
2022-09-28 04:12:36,517 [foster.py] => do not weight align teacher!
2022-09-28 04:12:36,517 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 04:12:39,441 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.567,  Train_accy 17.39, Test_accy 56.82
2022-09-28 04:12:41,356 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.437,  Train_accy 18.04
2022-09-28 04:12:43,251 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.348,  Train_accy 18.95
2022-09-28 04:12:45,171 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.325,  Train_accy 20.39
2022-09-28 04:12:47,103 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.281,  Train_accy 21.05
2022-09-28 04:12:49,728 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.261,  Train_accy 22.09, Test_accy 63.64
2022-09-28 04:12:51,675 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.257,  Train_accy 23.01
2022-09-28 04:12:53,628 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.253,  Train_accy 24.97
2022-09-28 04:12:55,544 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.261,  Train_accy 25.10
2022-09-28 04:12:57,545 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.220,  Train_accy 24.84
2022-09-28 04:13:00,128 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.219,  Train_accy 25.75, Test_accy 65.00
2022-09-28 04:13:02,032 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.219,  Train_accy 26.27
2022-09-28 04:13:04,007 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.216,  Train_accy 27.19
2022-09-28 04:13:05,907 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.200,  Train_accy 27.71
2022-09-28 04:13:07,844 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.214,  Train_accy 27.45
2022-09-28 04:13:10,429 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.214,  Train_accy 29.54, Test_accy 66.82
2022-09-28 04:13:12,366 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.191,  Train_accy 27.06
2022-09-28 04:13:14,344 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.203,  Train_accy 28.89
2022-09-28 04:13:16,304 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.216,  Train_accy 30.07
2022-09-28 04:13:18,229 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.201,  Train_accy 28.63
2022-09-28 04:13:20,838 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.192,  Train_accy 29.54, Test_accy 65.00
2022-09-28 04:13:22,797 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.199,  Train_accy 30.07
2022-09-28 04:13:24,732 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.196,  Train_accy 28.63
2022-09-28 04:13:26,706 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.190,  Train_accy 29.93
2022-09-28 04:13:28,633 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.194,  Train_accy 30.85
2022-09-28 04:13:31,266 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.201,  Train_accy 28.63, Test_accy 65.00
2022-09-28 04:13:31,267 [foster.py] => do not weight align student!
2022-09-28 04:13:31,967 [foster.py] => darknet eval: 
2022-09-28 04:13:31,968 [foster.py] => CNN top1 curve: 65.0
2022-09-28 04:13:31,968 [foster.py] => CNN top5 curve: 97.73
2022-09-28 04:13:31,968 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 04:13:38,416 [foster.py] => Exemplar size: 200
2022-09-28 04:13:38,416 [trainer.py] => CNN: {'total': 77.27, 'old': 85.44, 'new': 56.45, 'base': 85.44, 'compound': 56.45}
2022-09-28 04:13:38,416 [trainer.py] => CNN top1 curve: [88.61, 77.27]
2022-09-28 04:13:38,416 [trainer.py] => CNN base curve: [88.61, 85.44]
2022-09-28 04:13:38,416 [trainer.py] => CNN old curve: [88.61, 85.44]
2022-09-28 04:13:38,416 [trainer.py] => CNN new curve: [0, 56.45]
2022-09-28 04:13:38,416 [trainer.py] => CNN compound curve: [0, 56.45]
2022-09-28 04:13:38,416 [trainer.py] => NME: {'total': 77.27, 'old': 79.75, 'new': 70.97, 'base': 79.75, 'compound': 70.97}
2022-09-28 04:13:38,416 [trainer.py] => NME top1 curve: [85.44, 77.27]
2022-09-28 04:13:38,416 [trainer.py] => NME base curve: [85.44, 79.75]
2022-09-28 04:13:38,416 [trainer.py] => NME old curve: [85.44, 79.75]
2022-09-28 04:13:38,416 [trainer.py] => NME new curve: [0, 70.97]
2022-09-28 04:13:38,416 [trainer.py] => NME compound curve: [0, 70.97]
2022-09-28 04:13:38,650 [foster.py] => Learning on 10-13
2022-09-28 04:13:38,650 [foster.py] => All params: 22378148
2022-09-28 04:13:38,650 [foster.py] => Trainable params: 11196506
2022-09-28 04:13:38,670 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 04:13:41,515 [foster.py] => Task 2, Epoch 1/34 => Loss 5.114, Loss_clf 1.953, Loss_fe 1.997, Loss_kd 0.896, Train_accy 42.31, Test_accy 55.30
2022-09-28 04:13:43,448 [foster.py] => Task 2, Epoch 2/34 => Loss 3.218, Loss_clf 0.717, Loss_fe 1.345, Loss_kd 0.889, Train_accy 57.94
2022-09-28 04:13:45,367 [foster.py] => Task 2, Epoch 3/34 => Loss 2.803, Loss_clf 0.562, Loss_fe 1.100, Loss_kd 0.878, Train_accy 46.77
2022-09-28 04:13:47,272 [foster.py] => Task 2, Epoch 4/34 => Loss 2.606, Loss_clf 0.508, Loss_fe 0.978, Loss_kd 0.861, Train_accy 47.27
2022-09-28 04:13:49,210 [foster.py] => Task 2, Epoch 5/34 => Loss 2.517, Loss_clf 0.480, Loss_fe 0.892, Loss_kd 0.880, Train_accy 50.50
2022-09-28 04:13:52,014 [foster.py] => Task 2, Epoch 6/34 => Loss 2.447, Loss_clf 0.469, Loss_fe 0.837, Loss_kd 0.877, Train_accy 48.39, Test_accy 62.25
2022-09-28 04:13:53,929 [foster.py] => Task 2, Epoch 7/34 => Loss 2.378, Loss_clf 0.469, Loss_fe 0.768, Loss_kd 0.878, Train_accy 50.50
2022-09-28 04:13:55,837 [foster.py] => Task 2, Epoch 8/34 => Loss 2.252, Loss_clf 0.413, Loss_fe 0.704, Loss_kd 0.872, Train_accy 50.74
2022-09-28 04:13:57,777 [foster.py] => Task 2, Epoch 9/34 => Loss 2.305, Loss_clf 0.447, Loss_fe 0.700, Loss_kd 0.892, Train_accy 50.12
2022-09-28 04:13:59,731 [foster.py] => Task 2, Epoch 10/34 => Loss 2.196, Loss_clf 0.400, Loss_fe 0.651, Loss_kd 0.881, Train_accy 51.49
2022-09-28 04:14:02,584 [foster.py] => Task 2, Epoch 11/34 => Loss 2.208, Loss_clf 0.422, Loss_fe 0.641, Loss_kd 0.881, Train_accy 51.36, Test_accy 62.58
2022-09-28 04:14:04,495 [foster.py] => Task 2, Epoch 12/34 => Loss 2.139, Loss_clf 0.394, Loss_fe 0.601, Loss_kd 0.880, Train_accy 51.12
2022-09-28 04:14:06,410 [foster.py] => Task 2, Epoch 13/34 => Loss 2.053, Loss_clf 0.368, Loss_fe 0.555, Loss_kd 0.870, Train_accy 49.50
2022-09-28 04:14:08,363 [foster.py] => Task 2, Epoch 14/34 => Loss 2.090, Loss_clf 0.369, Loss_fe 0.575, Loss_kd 0.882, Train_accy 52.11
2022-09-28 04:14:10,267 [foster.py] => Task 2, Epoch 15/34 => Loss 2.070, Loss_clf 0.371, Loss_fe 0.563, Loss_kd 0.874, Train_accy 51.74
2022-09-28 04:14:13,138 [foster.py] => Task 2, Epoch 16/34 => Loss 2.026, Loss_clf 0.374, Loss_fe 0.516, Loss_kd 0.874, Train_accy 52.73, Test_accy 63.25
2022-09-28 04:14:15,075 [foster.py] => Task 2, Epoch 17/34 => Loss 2.041, Loss_clf 0.370, Loss_fe 0.536, Loss_kd 0.873, Train_accy 52.11
2022-09-28 04:14:17,022 [foster.py] => Task 2, Epoch 18/34 => Loss 1.947, Loss_clf 0.327, Loss_fe 0.482, Loss_kd 0.875, Train_accy 48.39
2022-09-28 04:14:19,046 [foster.py] => Task 2, Epoch 19/34 => Loss 1.959, Loss_clf 0.337, Loss_fe 0.488, Loss_kd 0.873, Train_accy 53.97
2022-09-28 04:14:20,973 [foster.py] => Task 2, Epoch 20/34 => Loss 1.999, Loss_clf 0.353, Loss_fe 0.498, Loss_kd 0.883, Train_accy 52.98
2022-09-28 04:14:23,565 [foster.py] => Task 2, Epoch 21/34 => Loss 1.948, Loss_clf 0.338, Loss_fe 0.469, Loss_kd 0.878, Train_accy 52.36, Test_accy 63.25
2022-09-28 04:14:25,373 [foster.py] => Task 2, Epoch 22/34 => Loss 1.982, Loss_clf 0.353, Loss_fe 0.482, Loss_kd 0.883, Train_accy 50.00
2022-09-28 04:14:27,202 [foster.py] => Task 2, Epoch 23/34 => Loss 1.919, Loss_clf 0.328, Loss_fe 0.457, Loss_kd 0.872, Train_accy 51.49
2022-09-28 04:14:29,032 [foster.py] => Task 2, Epoch 24/34 => Loss 1.945, Loss_clf 0.344, Loss_fe 0.464, Loss_kd 0.874, Train_accy 53.23
2022-09-28 04:14:30,862 [foster.py] => Task 2, Epoch 25/34 => Loss 1.927, Loss_clf 0.323, Loss_fe 0.459, Loss_kd 0.880, Train_accy 53.35
2022-09-28 04:14:33,473 [foster.py] => Task 2, Epoch 26/34 => Loss 1.921, Loss_clf 0.322, Loss_fe 0.455, Loss_kd 0.880, Train_accy 51.86, Test_accy 63.58
2022-09-28 04:14:35,290 [foster.py] => Task 2, Epoch 27/34 => Loss 1.916, Loss_clf 0.316, Loss_fe 0.453, Loss_kd 0.882, Train_accy 52.61
2022-09-28 04:14:37,145 [foster.py] => Task 2, Epoch 28/34 => Loss 1.909, Loss_clf 0.325, Loss_fe 0.437, Loss_kd 0.883, Train_accy 51.86
2022-09-28 04:14:38,943 [foster.py] => Task 2, Epoch 29/34 => Loss 1.882, Loss_clf 0.297, Loss_fe 0.432, Loss_kd 0.887, Train_accy 53.47
2022-09-28 04:14:40,738 [foster.py] => Task 2, Epoch 30/34 => Loss 1.905, Loss_clf 0.314, Loss_fe 0.452, Loss_kd 0.876, Train_accy 52.73
2022-09-28 04:14:43,342 [foster.py] => Task 2, Epoch 31/34 => Loss 1.915, Loss_clf 0.328, Loss_fe 0.446, Loss_kd 0.878, Train_accy 52.85, Test_accy 63.25
2022-09-28 04:14:45,149 [foster.py] => Task 2, Epoch 32/34 => Loss 1.909, Loss_clf 0.324, Loss_fe 0.438, Loss_kd 0.882, Train_accy 51.99
2022-09-28 04:14:46,935 [foster.py] => Task 2, Epoch 33/34 => Loss 1.931, Loss_clf 0.328, Loss_fe 0.453, Loss_kd 0.885, Train_accy 52.23
2022-09-28 04:14:48,745 [foster.py] => Task 2, Epoch 34/34 => Loss 1.879, Loss_clf 0.303, Loss_fe 0.422, Loss_kd 0.887, Train_accy 53.97
2022-09-28 04:14:48,746 [foster.py] => do not weight align teacher!
2022-09-28 04:14:48,746 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 04:14:51,696 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.820,  Train_accy 17.25, Test_accy 45.36
2022-09-28 04:14:53,692 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.695,  Train_accy 17.99
2022-09-28 04:14:55,719 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.627,  Train_accy 17.87
2022-09-28 04:14:57,703 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.620,  Train_accy 18.11
2022-09-28 04:14:59,715 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.613,  Train_accy 18.98
2022-09-28 04:15:02,424 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.581,  Train_accy 18.36, Test_accy 47.68
2022-09-28 04:15:04,445 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.561,  Train_accy 18.61
2022-09-28 04:15:06,431 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.553,  Train_accy 19.48
2022-09-28 04:15:08,410 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.551,  Train_accy 19.48
2022-09-28 04:15:10,418 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.555,  Train_accy 19.85
2022-09-28 04:15:13,215 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.559,  Train_accy 20.84, Test_accy 50.66
2022-09-28 04:15:15,224 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.522,  Train_accy 20.22
2022-09-28 04:15:17,274 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.540,  Train_accy 21.96
2022-09-28 04:15:19,362 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.524,  Train_accy 21.96
2022-09-28 04:15:21,348 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.549,  Train_accy 21.84
2022-09-28 04:15:24,117 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.547,  Train_accy 22.83, Test_accy 50.99
2022-09-28 04:15:26,115 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.521,  Train_accy 22.21
2022-09-28 04:15:28,171 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.513,  Train_accy 22.21
2022-09-28 04:15:30,187 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.533,  Train_accy 24.07
2022-09-28 04:15:32,179 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.521,  Train_accy 23.08
2022-09-28 04:15:34,924 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.526,  Train_accy 22.83, Test_accy 51.32
2022-09-28 04:15:36,910 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.531,  Train_accy 22.08
2022-09-28 04:15:38,913 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.525,  Train_accy 23.08
2022-09-28 04:15:40,939 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.545,  Train_accy 22.95
2022-09-28 04:15:42,953 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.524,  Train_accy 22.21
2022-09-28 04:15:45,699 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.533,  Train_accy 22.70, Test_accy 52.32
2022-09-28 04:15:45,700 [foster.py] => do not weight align student!
2022-09-28 04:15:46,413 [foster.py] => darknet eval: 
2022-09-28 04:15:46,413 [foster.py] => CNN top1 curve: 52.32
2022-09-28 04:15:46,413 [foster.py] => CNN top5 curve: 97.35
2022-09-28 04:15:46,414 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 04:15:53,782 [foster.py] => Exemplar size: 260
2022-09-28 04:15:53,782 [trainer.py] => CNN: {'total': 63.91, 'old': 75.0, 'new': 34.15, 'base': 81.65, 'compound': 44.44}
2022-09-28 04:15:53,782 [trainer.py] => CNN top1 curve: [88.61, 77.27, 63.91]
2022-09-28 04:15:53,782 [trainer.py] => CNN base curve: [88.61, 85.44, 81.65]
2022-09-28 04:15:53,782 [trainer.py] => CNN old curve: [88.61, 85.44, 75.0]
2022-09-28 04:15:53,782 [trainer.py] => CNN new curve: [0, 56.45, 34.15]
2022-09-28 04:15:53,783 [trainer.py] => CNN compound curve: [0, 56.45, 44.44]
2022-09-28 04:15:53,783 [trainer.py] => NME: {'total': 69.54, 'old': 70.0, 'new': 68.29, 'base': 73.42, 'compound': 65.28}
2022-09-28 04:15:53,783 [trainer.py] => NME top1 curve: [85.44, 77.27, 69.54]
2022-09-28 04:15:53,783 [trainer.py] => NME base curve: [85.44, 79.75, 73.42]
2022-09-28 04:15:53,783 [trainer.py] => NME old curve: [85.44, 79.75, 70.0]
2022-09-28 04:15:53,783 [trainer.py] => NME new curve: [0, 70.97, 68.29]
2022-09-28 04:15:53,783 [trainer.py] => NME compound curve: [0, 70.97, 65.28]
2022-09-28 04:15:54,013 [foster.py] => Learning on 13-16
2022-09-28 04:15:54,014 [foster.py] => All params: 22384301
2022-09-28 04:15:54,014 [foster.py] => Trainable params: 11201120
2022-09-28 04:15:54,034 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 04:15:56,867 [foster.py] => Task 3, Epoch 1/34 => Loss 6.339, Loss_clf 2.230, Loss_fe 2.470, Loss_kd 1.332, Train_accy 35.79, Test_accy 40.87
2022-09-28 04:15:58,775 [foster.py] => Task 3, Epoch 2/34 => Loss 4.548, Loss_clf 1.203, Loss_fe 1.732, Loss_kd 1.311, Train_accy 35.11
2022-09-28 04:16:00,698 [foster.py] => Task 3, Epoch 3/34 => Loss 4.168, Loss_clf 1.018, Loss_fe 1.536, Loss_kd 1.311, Train_accy 36.58
2022-09-28 04:16:02,643 [foster.py] => Task 3, Epoch 4/34 => Loss 3.976, Loss_clf 0.961, Loss_fe 1.405, Loss_kd 1.308, Train_accy 39.98
2022-09-28 04:16:04,588 [foster.py] => Task 3, Epoch 5/34 => Loss 3.833, Loss_clf 0.929, Loss_fe 1.299, Loss_kd 1.304, Train_accy 37.71
2022-09-28 04:16:07,385 [foster.py] => Task 3, Epoch 6/34 => Loss 3.724, Loss_clf 0.900, Loss_fe 1.222, Loss_kd 1.302, Train_accy 36.69, Test_accy 53.13
2022-09-28 04:16:09,287 [foster.py] => Task 3, Epoch 7/34 => Loss 3.636, Loss_clf 0.865, Loss_fe 1.169, Loss_kd 1.301, Train_accy 42.36
2022-09-28 04:16:11,196 [foster.py] => Task 3, Epoch 8/34 => Loss 3.566, Loss_clf 0.840, Loss_fe 1.110, Loss_kd 1.313, Train_accy 38.96
2022-09-28 04:16:13,140 [foster.py] => Task 3, Epoch 9/34 => Loss 3.509, Loss_clf 0.823, Loss_fe 1.062, Loss_kd 1.320, Train_accy 42.13
2022-09-28 04:16:15,030 [foster.py] => Task 3, Epoch 10/34 => Loss 3.393, Loss_clf 0.785, Loss_fe 1.006, Loss_kd 1.301, Train_accy 41.11
2022-09-28 04:16:17,854 [foster.py] => Task 3, Epoch 11/34 => Loss 3.365, Loss_clf 0.790, Loss_fe 0.968, Loss_kd 1.305, Train_accy 43.60, Test_accy 54.77
2022-09-28 04:16:19,762 [foster.py] => Task 3, Epoch 12/34 => Loss 3.333, Loss_clf 0.777, Loss_fe 0.952, Loss_kd 1.303, Train_accy 43.26
2022-09-28 04:16:21,655 [foster.py] => Task 3, Epoch 13/34 => Loss 3.295, Loss_clf 0.752, Loss_fe 0.929, Loss_kd 1.311, Train_accy 44.05
2022-09-28 04:16:23,542 [foster.py] => Task 3, Epoch 14/34 => Loss 3.305, Loss_clf 0.771, Loss_fe 0.928, Loss_kd 1.305, Train_accy 41.22
2022-09-28 04:16:25,451 [foster.py] => Task 3, Epoch 15/34 => Loss 3.194, Loss_clf 0.714, Loss_fe 0.865, Loss_kd 1.312, Train_accy 45.53
2022-09-28 04:16:28,290 [foster.py] => Task 3, Epoch 16/34 => Loss 3.194, Loss_clf 0.710, Loss_fe 0.871, Loss_kd 1.311, Train_accy 44.51, Test_accy 54.50
2022-09-28 04:16:30,240 [foster.py] => Task 3, Epoch 17/34 => Loss 3.147, Loss_clf 0.704, Loss_fe 0.830, Loss_kd 1.310, Train_accy 45.30
2022-09-28 04:16:32,175 [foster.py] => Task 3, Epoch 18/34 => Loss 3.129, Loss_clf 0.695, Loss_fe 0.825, Loss_kd 1.308, Train_accy 43.26
2022-09-28 04:16:34,123 [foster.py] => Task 3, Epoch 19/34 => Loss 3.117, Loss_clf 0.693, Loss_fe 0.812, Loss_kd 1.310, Train_accy 46.09
2022-09-28 04:16:36,037 [foster.py] => Task 3, Epoch 20/34 => Loss 3.064, Loss_clf 0.651, Loss_fe 0.792, Loss_kd 1.317, Train_accy 46.77
2022-09-28 04:16:38,860 [foster.py] => Task 3, Epoch 21/34 => Loss 3.108, Loss_clf 0.689, Loss_fe 0.801, Loss_kd 1.315, Train_accy 45.19, Test_accy 54.50
2022-09-28 04:16:40,797 [foster.py] => Task 3, Epoch 22/34 => Loss 3.095, Loss_clf 0.687, Loss_fe 0.804, Loss_kd 1.304, Train_accy 45.53
2022-09-28 04:16:42,684 [foster.py] => Task 3, Epoch 23/34 => Loss 3.044, Loss_clf 0.649, Loss_fe 0.779, Loss_kd 1.313, Train_accy 46.66
2022-09-28 04:16:44,590 [foster.py] => Task 3, Epoch 24/34 => Loss 3.001, Loss_clf 0.630, Loss_fe 0.756, Loss_kd 1.313, Train_accy 48.24
2022-09-28 04:16:46,488 [foster.py] => Task 3, Epoch 25/34 => Loss 2.984, Loss_clf 0.626, Loss_fe 0.750, Loss_kd 1.306, Train_accy 45.87
2022-09-28 04:16:49,269 [foster.py] => Task 3, Epoch 26/34 => Loss 3.001, Loss_clf 0.636, Loss_fe 0.750, Loss_kd 1.312, Train_accy 46.89, Test_accy 54.50
2022-09-28 04:16:51,195 [foster.py] => Task 3, Epoch 27/34 => Loss 3.030, Loss_clf 0.646, Loss_fe 0.771, Loss_kd 1.310, Train_accy 46.77
2022-09-28 04:16:53,083 [foster.py] => Task 3, Epoch 28/34 => Loss 3.003, Loss_clf 0.640, Loss_fe 0.757, Loss_kd 1.305, Train_accy 46.09
2022-09-28 04:16:54,974 [foster.py] => Task 3, Epoch 29/34 => Loss 2.988, Loss_clf 0.638, Loss_fe 0.741, Loss_kd 1.308, Train_accy 45.30
2022-09-28 04:16:56,923 [foster.py] => Task 3, Epoch 30/34 => Loss 2.984, Loss_clf 0.626, Loss_fe 0.738, Loss_kd 1.316, Train_accy 46.43
2022-09-28 04:16:59,760 [foster.py] => Task 3, Epoch 31/34 => Loss 2.986, Loss_clf 0.629, Loss_fe 0.745, Loss_kd 1.309, Train_accy 47.57, Test_accy 54.22
2022-09-28 04:17:01,665 [foster.py] => Task 3, Epoch 32/34 => Loss 2.989, Loss_clf 0.624, Loss_fe 0.749, Loss_kd 1.313, Train_accy 47.34
2022-09-28 04:17:03,550 [foster.py] => Task 3, Epoch 33/34 => Loss 3.012, Loss_clf 0.647, Loss_fe 0.748, Loss_kd 1.314, Train_accy 47.34
2022-09-28 04:17:05,490 [foster.py] => Task 3, Epoch 34/34 => Loss 2.966, Loss_clf 0.623, Loss_fe 0.734, Loss_kd 1.308, Train_accy 47.57
2022-09-28 04:17:05,490 [foster.py] => do not weight align teacher!
2022-09-28 04:17:05,490 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 04:17:08,599 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.191,  Train_accy 18.46, Test_accy 42.78
2022-09-28 04:17:10,721 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.076,  Train_accy 19.37
2022-09-28 04:17:12,922 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.011,  Train_accy 19.71
2022-09-28 04:17:15,075 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 2.001,  Train_accy 19.48
2022-09-28 04:17:17,189 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.980,  Train_accy 19.82
2022-09-28 04:17:20,075 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.977,  Train_accy 20.05, Test_accy 47.14
2022-09-28 04:17:22,251 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.977,  Train_accy 20.16
2022-09-28 04:17:24,414 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.968,  Train_accy 19.82
2022-09-28 04:17:26,566 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.978,  Train_accy 20.16
2022-09-28 04:17:28,738 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.965,  Train_accy 19.71
2022-09-28 04:17:31,667 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.958,  Train_accy 20.27, Test_accy 47.14
2022-09-28 04:17:33,803 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.961,  Train_accy 20.72
2022-09-28 04:17:35,954 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.962,  Train_accy 20.84
2022-09-28 04:17:38,112 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.964,  Train_accy 19.93
2022-09-28 04:17:40,231 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.955,  Train_accy 20.50
2022-09-28 04:17:43,160 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.955,  Train_accy 20.95, Test_accy 48.50
2022-09-28 04:17:45,278 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.951,  Train_accy 20.72
2022-09-28 04:17:47,406 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.947,  Train_accy 20.27
2022-09-28 04:17:49,613 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.936,  Train_accy 20.84
2022-09-28 04:17:51,732 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.940,  Train_accy 20.27
2022-09-28 04:17:54,640 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.939,  Train_accy 20.50, Test_accy 48.77
2022-09-28 04:17:56,774 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.946,  Train_accy 21.40
2022-09-28 04:17:58,912 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.957,  Train_accy 20.61
2022-09-28 04:18:01,082 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.947,  Train_accy 21.06
2022-09-28 04:18:03,207 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.950,  Train_accy 20.27
2022-09-28 04:18:06,152 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.949,  Train_accy 19.82, Test_accy 47.68
2022-09-28 04:18:06,153 [foster.py] => do not weight align student!
2022-09-28 04:18:06,901 [foster.py] => darknet eval: 
2022-09-28 04:18:06,901 [foster.py] => CNN top1 curve: 47.68
2022-09-28 04:18:06,901 [foster.py] => CNN top5 curve: 93.73
2022-09-28 04:18:06,902 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 04:18:15,369 [foster.py] => Exemplar size: 320
2022-09-28 04:18:15,369 [trainer.py] => CNN: {'total': 54.77, 'old': 61.26, 'new': 24.62, 'base': 73.42, 'compound': 40.67}
2022-09-28 04:18:15,369 [trainer.py] => CNN top1 curve: [88.61, 77.27, 63.91, 54.77]
2022-09-28 04:18:15,369 [trainer.py] => CNN base curve: [88.61, 85.44, 81.65, 73.42]
2022-09-28 04:18:15,369 [trainer.py] => CNN old curve: [88.61, 85.44, 75.0, 61.26]
2022-09-28 04:18:15,369 [trainer.py] => CNN new curve: [0, 56.45, 34.15, 24.62]
2022-09-28 04:18:15,369 [trainer.py] => CNN compound curve: [0, 56.45, 44.44, 40.67]
2022-09-28 04:18:15,369 [trainer.py] => NME: {'total': 61.85, 'old': 64.57, 'new': 49.23, 'base': 67.09, 'compound': 57.89}
2022-09-28 04:18:15,369 [trainer.py] => NME top1 curve: [85.44, 77.27, 69.54, 61.85]
2022-09-28 04:18:15,369 [trainer.py] => NME base curve: [85.44, 79.75, 73.42, 67.09]
2022-09-28 04:18:15,369 [trainer.py] => NME old curve: [85.44, 79.75, 70.0, 64.57]
2022-09-28 04:18:15,369 [trainer.py] => NME new curve: [0, 70.97, 68.29, 49.23]
2022-09-28 04:18:15,369 [trainer.py] => NME compound curve: [0, 70.97, 65.28, 57.89]
2022-09-28 04:18:15,602 [foster.py] => Learning on 16-19
2022-09-28 04:18:15,603 [foster.py] => All params: 22390454
2022-09-28 04:18:15,603 [foster.py] => Trainable params: 11205734
2022-09-28 04:18:15,623 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 04:18:18,533 [foster.py] => Task 4, Epoch 1/34 => Loss 6.366, Loss_clf 1.915, Loss_fe 2.502, Loss_kd 1.641, Train_accy 39.10, Test_accy 43.92
2022-09-28 04:18:20,582 [foster.py] => Task 4, Epoch 2/34 => Loss 4.781, Loss_clf 1.087, Loss_fe 1.731, Loss_kd 1.653, Train_accy 35.12
2022-09-28 04:18:22,594 [foster.py] => Task 4, Epoch 3/34 => Loss 4.605, Loss_clf 1.031, Loss_fe 1.589, Loss_kd 1.672, Train_accy 38.88
2022-09-28 04:18:24,594 [foster.py] => Task 4, Epoch 4/34 => Loss 4.369, Loss_clf 0.965, Loss_fe 1.442, Loss_kd 1.652, Train_accy 36.73
2022-09-28 04:18:26,624 [foster.py] => Task 4, Epoch 5/34 => Loss 4.322, Loss_clf 0.955, Loss_fe 1.390, Loss_kd 1.664, Train_accy 37.70
2022-09-28 04:18:29,559 [foster.py] => Task 4, Epoch 6/34 => Loss 4.206, Loss_clf 0.936, Loss_fe 1.312, Loss_kd 1.649, Train_accy 36.95, Test_accy 46.62
2022-09-28 04:18:31,533 [foster.py] => Task 4, Epoch 7/34 => Loss 4.072, Loss_clf 0.887, Loss_fe 1.239, Loss_kd 1.638, Train_accy 38.35
2022-09-28 04:18:33,539 [foster.py] => Task 4, Epoch 8/34 => Loss 4.046, Loss_clf 0.888, Loss_fe 1.181, Loss_kd 1.665, Train_accy 40.17
2022-09-28 04:18:35,502 [foster.py] => Task 4, Epoch 9/34 => Loss 4.040, Loss_clf 0.910, Loss_fe 1.166, Loss_kd 1.653, Train_accy 41.57
2022-09-28 04:18:37,519 [foster.py] => Task 4, Epoch 10/34 => Loss 3.895, Loss_clf 0.832, Loss_fe 1.084, Loss_kd 1.667, Train_accy 39.85
2022-09-28 04:18:40,490 [foster.py] => Task 4, Epoch 11/34 => Loss 3.898, Loss_clf 0.836, Loss_fe 1.093, Loss_kd 1.658, Train_accy 40.49, Test_accy 48.20
2022-09-28 04:18:42,520 [foster.py] => Task 4, Epoch 12/34 => Loss 3.842, Loss_clf 0.814, Loss_fe 1.051, Loss_kd 1.665, Train_accy 39.85
2022-09-28 04:18:44,524 [foster.py] => Task 4, Epoch 13/34 => Loss 3.839, Loss_clf 0.806, Loss_fe 1.055, Loss_kd 1.666, Train_accy 39.85
2022-09-28 04:18:46,537 [foster.py] => Task 4, Epoch 14/34 => Loss 3.845, Loss_clf 0.835, Loss_fe 1.028, Loss_kd 1.669, Train_accy 42.53
2022-09-28 04:18:48,526 [foster.py] => Task 4, Epoch 15/34 => Loss 3.807, Loss_clf 0.821, Loss_fe 1.014, Loss_kd 1.661, Train_accy 39.85
2022-09-28 04:18:51,469 [foster.py] => Task 4, Epoch 16/34 => Loss 3.830, Loss_clf 0.826, Loss_fe 1.019, Loss_kd 1.672, Train_accy 45.86, Test_accy 49.32
2022-09-28 04:18:53,466 [foster.py] => Task 4, Epoch 17/34 => Loss 3.783, Loss_clf 0.831, Loss_fe 0.978, Loss_kd 1.662, Train_accy 38.13
2022-09-28 04:18:55,471 [foster.py] => Task 4, Epoch 18/34 => Loss 3.753, Loss_clf 0.813, Loss_fe 0.961, Loss_kd 1.666, Train_accy 41.89
2022-09-28 04:18:57,472 [foster.py] => Task 4, Epoch 19/34 => Loss 3.602, Loss_clf 0.731, Loss_fe 0.899, Loss_kd 1.660, Train_accy 42.96
2022-09-28 04:18:59,440 [foster.py] => Task 4, Epoch 20/34 => Loss 3.619, Loss_clf 0.737, Loss_fe 0.919, Loss_kd 1.653, Train_accy 44.68
2022-09-28 04:19:02,403 [foster.py] => Task 4, Epoch 21/34 => Loss 3.564, Loss_clf 0.732, Loss_fe 0.872, Loss_kd 1.651, Train_accy 42.96, Test_accy 49.55
2022-09-28 04:19:04,447 [foster.py] => Task 4, Epoch 22/34 => Loss 3.616, Loss_clf 0.736, Loss_fe 0.902, Loss_kd 1.666, Train_accy 45.01
2022-09-28 04:19:06,448 [foster.py] => Task 4, Epoch 23/34 => Loss 3.549, Loss_clf 0.713, Loss_fe 0.864, Loss_kd 1.661, Train_accy 42.64
2022-09-28 04:19:08,447 [foster.py] => Task 4, Epoch 24/34 => Loss 3.540, Loss_clf 0.717, Loss_fe 0.863, Loss_kd 1.651, Train_accy 43.29
2022-09-28 04:19:10,516 [foster.py] => Task 4, Epoch 25/34 => Loss 3.622, Loss_clf 0.739, Loss_fe 0.897, Loss_kd 1.672, Train_accy 44.47
2022-09-28 04:19:13,465 [foster.py] => Task 4, Epoch 26/34 => Loss 3.515, Loss_clf 0.699, Loss_fe 0.841, Loss_kd 1.663, Train_accy 46.08, Test_accy 50.00
2022-09-28 04:19:15,512 [foster.py] => Task 4, Epoch 27/34 => Loss 3.567, Loss_clf 0.729, Loss_fe 0.851, Loss_kd 1.673, Train_accy 45.44
2022-09-28 04:19:17,503 [foster.py] => Task 4, Epoch 28/34 => Loss 3.519, Loss_clf 0.717, Loss_fe 0.851, Loss_kd 1.644, Train_accy 43.07
2022-09-28 04:19:19,514 [foster.py] => Task 4, Epoch 29/34 => Loss 3.546, Loss_clf 0.712, Loss_fe 0.867, Loss_kd 1.657, Train_accy 43.72
2022-09-28 04:19:21,498 [foster.py] => Task 4, Epoch 30/34 => Loss 3.560, Loss_clf 0.724, Loss_fe 0.861, Loss_kd 1.663, Train_accy 44.36
2022-09-28 04:19:24,440 [foster.py] => Task 4, Epoch 31/34 => Loss 3.528, Loss_clf 0.704, Loss_fe 0.840, Loss_kd 1.671, Train_accy 44.58, Test_accy 50.45
2022-09-28 04:19:26,458 [foster.py] => Task 4, Epoch 32/34 => Loss 3.577, Loss_clf 0.726, Loss_fe 0.872, Loss_kd 1.666, Train_accy 45.54
2022-09-28 04:19:28,483 [foster.py] => Task 4, Epoch 33/34 => Loss 3.585, Loss_clf 0.737, Loss_fe 0.862, Loss_kd 1.673, Train_accy 45.33
2022-09-28 04:19:30,496 [foster.py] => Task 4, Epoch 34/34 => Loss 3.568, Loss_clf 0.725, Loss_fe 0.860, Loss_kd 1.669, Train_accy 42.21
2022-09-28 04:19:30,497 [foster.py] => do not weight align teacher!
2022-09-28 04:19:30,497 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 04:19:33,812 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.327,  Train_accy 18.47, Test_accy 39.41
2022-09-28 04:19:36,046 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.278,  Train_accy 19.23
2022-09-28 04:19:38,253 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.264,  Train_accy 19.44
2022-09-28 04:19:40,531 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.242,  Train_accy 20.52
2022-09-28 04:19:42,789 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.229,  Train_accy 20.73
2022-09-28 04:19:45,835 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.237,  Train_accy 20.52, Test_accy 41.89
2022-09-28 04:19:48,069 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.229,  Train_accy 20.84
2022-09-28 04:19:50,331 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.216,  Train_accy 20.95
2022-09-28 04:19:52,560 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.228,  Train_accy 21.16
2022-09-28 04:19:54,809 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.221,  Train_accy 20.95
2022-09-28 04:19:57,868 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.204,  Train_accy 20.84, Test_accy 40.99
2022-09-28 04:20:00,178 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.203,  Train_accy 21.48
2022-09-28 04:20:02,406 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.212,  Train_accy 20.95
2022-09-28 04:20:04,738 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.212,  Train_accy 21.70
2022-09-28 04:20:06,970 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.200,  Train_accy 21.27
2022-09-28 04:20:09,984 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.216,  Train_accy 20.95, Test_accy 42.12
2022-09-28 04:20:12,196 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.196,  Train_accy 21.59
2022-09-28 04:20:14,469 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.212,  Train_accy 21.16
2022-09-28 04:20:16,737 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.202,  Train_accy 21.59
2022-09-28 04:20:18,999 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.206,  Train_accy 20.95
2022-09-28 04:20:22,011 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.206,  Train_accy 22.13, Test_accy 42.34
2022-09-28 04:20:24,257 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.195,  Train_accy 21.59
2022-09-28 04:20:26,483 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.193,  Train_accy 21.59
2022-09-28 04:20:28,698 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.201,  Train_accy 22.13
2022-09-28 04:20:30,918 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.203,  Train_accy 21.48
2022-09-28 04:20:34,032 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.196,  Train_accy 21.27, Test_accy 42.79
2022-09-28 04:20:34,032 [foster.py] => do not weight align student!
2022-09-28 04:20:34,843 [foster.py] => darknet eval: 
2022-09-28 04:20:34,843 [foster.py] => CNN top1 curve: 42.79
2022-09-28 04:20:34,843 [foster.py] => CNN top5 curve: 81.76
2022-09-28 04:20:34,844 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 04:20:44,436 [foster.py] => Exemplar size: 380
2022-09-28 04:20:44,436 [trainer.py] => CNN: {'total': 50.0, 'old': 54.5, 'new': 28.57, 'base': 72.15, 'compound': 37.76}
2022-09-28 04:20:44,436 [trainer.py] => CNN top1 curve: [88.61, 77.27, 63.91, 54.77, 50.0]
2022-09-28 04:20:44,436 [trainer.py] => CNN base curve: [88.61, 85.44, 81.65, 73.42, 72.15]
2022-09-28 04:20:44,436 [trainer.py] => CNN old curve: [88.61, 85.44, 75.0, 61.26, 54.5]
2022-09-28 04:20:44,436 [trainer.py] => CNN new curve: [0, 56.45, 34.15, 24.62, 28.57]
2022-09-28 04:20:44,437 [trainer.py] => CNN compound curve: [0, 56.45, 44.44, 40.67, 37.76]
2022-09-28 04:20:44,437 [trainer.py] => NME: {'total': 53.15, 'old': 55.59, 'new': 41.56, 'base': 63.92, 'compound': 47.2}
2022-09-28 04:20:44,437 [trainer.py] => NME top1 curve: [85.44, 77.27, 69.54, 61.85, 53.15]
2022-09-28 04:20:44,437 [trainer.py] => NME base curve: [85.44, 79.75, 73.42, 67.09, 63.92]
2022-09-28 04:20:44,437 [trainer.py] => NME old curve: [85.44, 79.75, 70.0, 64.57, 55.59]
2022-09-28 04:20:44,437 [trainer.py] => NME new curve: [0, 70.97, 68.29, 49.23, 41.56]
2022-09-28 04:20:44,437 [trainer.py] => NME compound curve: [0, 70.97, 65.28, 57.89, 47.2]
2022-09-28 04:20:44,670 [foster.py] => Learning on 19-22
2022-09-28 04:20:44,670 [foster.py] => All params: 22396607
2022-09-28 04:20:44,670 [foster.py] => Trainable params: 11210348
2022-09-28 04:20:44,691 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 04:20:47,797 [foster.py] => Task 5, Epoch 1/34 => Loss 6.667, Loss_clf 2.084, Loss_fe 2.429, Loss_kd 1.860, Train_accy 38.00, Test_accy 40.48
2022-09-28 04:20:49,961 [foster.py] => Task 5, Epoch 2/34 => Loss 5.061, Loss_clf 1.101, Loss_fe 1.813, Loss_kd 1.854, Train_accy 33.83
2022-09-28 04:20:52,092 [foster.py] => Task 5, Epoch 3/34 => Loss 4.811, Loss_clf 1.030, Loss_fe 1.632, Loss_kd 1.856, Train_accy 36.41
2022-09-28 04:20:54,236 [foster.py] => Task 5, Epoch 4/34 => Loss 4.666, Loss_clf 0.982, Loss_fe 1.524, Loss_kd 1.865, Train_accy 42.06
2022-09-28 04:20:56,320 [foster.py] => Task 5, Epoch 5/34 => Loss 4.556, Loss_clf 0.967, Loss_fe 1.444, Loss_kd 1.853, Train_accy 42.16
2022-09-28 04:20:59,413 [foster.py] => Task 5, Epoch 6/34 => Loss 4.426, Loss_clf 0.923, Loss_fe 1.352, Loss_kd 1.858, Train_accy 40.77, Test_accy 44.44
2022-09-28 04:21:01,544 [foster.py] => Task 5, Epoch 7/34 => Loss 4.344, Loss_clf 0.902, Loss_fe 1.290, Loss_kd 1.859, Train_accy 41.77
2022-09-28 04:21:03,613 [foster.py] => Task 5, Epoch 8/34 => Loss 4.305, Loss_clf 0.886, Loss_fe 1.254, Loss_kd 1.869, Train_accy 45.24
2022-09-28 04:21:05,698 [foster.py] => Task 5, Epoch 9/34 => Loss 4.250, Loss_clf 0.887, Loss_fe 1.209, Loss_kd 1.860, Train_accy 41.57
2022-09-28 04:21:07,790 [foster.py] => Task 5, Epoch 10/34 => Loss 4.147, Loss_clf 0.846, Loss_fe 1.153, Loss_kd 1.856, Train_accy 43.65
2022-09-28 04:21:10,892 [foster.py] => Task 5, Epoch 11/34 => Loss 4.133, Loss_clf 0.846, Loss_fe 1.125, Loss_kd 1.867, Train_accy 44.74, Test_accy 45.44
2022-09-28 04:21:12,989 [foster.py] => Task 5, Epoch 12/34 => Loss 4.101, Loss_clf 0.838, Loss_fe 1.103, Loss_kd 1.865, Train_accy 46.33
2022-09-28 04:21:15,107 [foster.py] => Task 5, Epoch 13/34 => Loss 4.044, Loss_clf 0.820, Loss_fe 1.079, Loss_kd 1.853, Train_accy 46.03
2022-09-28 04:21:17,223 [foster.py] => Task 5, Epoch 14/34 => Loss 3.998, Loss_clf 0.804, Loss_fe 1.034, Loss_kd 1.866, Train_accy 46.83
2022-09-28 04:21:19,306 [foster.py] => Task 5, Epoch 15/34 => Loss 3.954, Loss_clf 0.785, Loss_fe 1.006, Loss_kd 1.868, Train_accy 45.44
2022-09-28 04:21:22,396 [foster.py] => Task 5, Epoch 16/34 => Loss 3.964, Loss_clf 0.805, Loss_fe 1.004, Loss_kd 1.861, Train_accy 45.44, Test_accy 46.23
2022-09-28 04:21:24,476 [foster.py] => Task 5, Epoch 17/34 => Loss 3.931, Loss_clf 0.782, Loss_fe 0.983, Loss_kd 1.871, Train_accy 46.73
2022-09-28 04:21:26,585 [foster.py] => Task 5, Epoch 18/34 => Loss 3.950, Loss_clf 0.804, Loss_fe 0.989, Loss_kd 1.863, Train_accy 43.25
2022-09-28 04:21:28,739 [foster.py] => Task 5, Epoch 19/34 => Loss 3.873, Loss_clf 0.761, Loss_fe 0.952, Loss_kd 1.865, Train_accy 45.44
2022-09-28 04:21:30,858 [foster.py] => Task 5, Epoch 20/34 => Loss 3.887, Loss_clf 0.774, Loss_fe 0.955, Loss_kd 1.864, Train_accy 47.82
2022-09-28 04:21:33,943 [foster.py] => Task 5, Epoch 21/34 => Loss 3.818, Loss_clf 0.745, Loss_fe 0.912, Loss_kd 1.867, Train_accy 48.41, Test_accy 47.82
2022-09-28 04:21:36,044 [foster.py] => Task 5, Epoch 22/34 => Loss 3.799, Loss_clf 0.734, Loss_fe 0.906, Loss_kd 1.865, Train_accy 46.92
2022-09-28 04:21:38,171 [foster.py] => Task 5, Epoch 23/34 => Loss 3.818, Loss_clf 0.738, Loss_fe 0.910, Loss_kd 1.874, Train_accy 48.81
2022-09-28 04:21:40,287 [foster.py] => Task 5, Epoch 24/34 => Loss 3.790, Loss_clf 0.733, Loss_fe 0.898, Loss_kd 1.864, Train_accy 47.32
2022-09-28 04:21:42,462 [foster.py] => Task 5, Epoch 25/34 => Loss 3.805, Loss_clf 0.751, Loss_fe 0.902, Loss_kd 1.859, Train_accy 47.22
2022-09-28 04:21:45,593 [foster.py] => Task 5, Epoch 26/34 => Loss 3.838, Loss_clf 0.757, Loss_fe 0.917, Loss_kd 1.870, Train_accy 47.52, Test_accy 47.62
2022-09-28 04:21:47,686 [foster.py] => Task 5, Epoch 27/34 => Loss 3.851, Loss_clf 0.760, Loss_fe 0.926, Loss_kd 1.870, Train_accy 46.03
2022-09-28 04:21:49,813 [foster.py] => Task 5, Epoch 28/34 => Loss 3.789, Loss_clf 0.732, Loss_fe 0.898, Loss_kd 1.864, Train_accy 46.73
2022-09-28 04:21:51,898 [foster.py] => Task 5, Epoch 29/34 => Loss 3.753, Loss_clf 0.713, Loss_fe 0.877, Loss_kd 1.869, Train_accy 48.02
2022-09-28 04:21:54,007 [foster.py] => Task 5, Epoch 30/34 => Loss 3.771, Loss_clf 0.719, Loss_fe 0.882, Loss_kd 1.874, Train_accy 48.81
2022-09-28 04:21:57,111 [foster.py] => Task 5, Epoch 31/34 => Loss 3.739, Loss_clf 0.712, Loss_fe 0.878, Loss_kd 1.856, Train_accy 47.62, Test_accy 47.22
2022-09-28 04:21:59,297 [foster.py] => Task 5, Epoch 32/34 => Loss 3.770, Loss_clf 0.724, Loss_fe 0.888, Loss_kd 1.864, Train_accy 48.02
2022-09-28 04:22:01,421 [foster.py] => Task 5, Epoch 33/34 => Loss 3.786, Loss_clf 0.730, Loss_fe 0.900, Loss_kd 1.862, Train_accy 47.32
2022-09-28 04:22:03,512 [foster.py] => Task 5, Epoch 34/34 => Loss 3.736, Loss_clf 0.707, Loss_fe 0.874, Loss_kd 1.861, Train_accy 47.82
2022-09-28 04:22:03,512 [foster.py] => do not weight align teacher!
2022-09-28 04:22:03,513 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 04:22:06,980 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.449,  Train_accy 19.44, Test_accy 36.71
2022-09-28 04:22:09,339 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.432,  Train_accy 20.24
2022-09-28 04:22:11,745 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.407,  Train_accy 20.34
2022-09-28 04:22:14,120 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.385,  Train_accy 20.24
2022-09-28 04:22:16,507 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.365,  Train_accy 20.24
2022-09-28 04:22:19,766 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.358,  Train_accy 21.13, Test_accy 38.10
2022-09-28 04:22:22,114 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.361,  Train_accy 21.73
2022-09-28 04:22:24,459 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.346,  Train_accy 21.03
2022-09-28 04:22:26,842 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.353,  Train_accy 21.73
2022-09-28 04:22:29,205 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.338,  Train_accy 22.32
2022-09-28 04:22:32,482 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.332,  Train_accy 22.42, Test_accy 39.09
2022-09-28 04:22:34,861 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.336,  Train_accy 23.21
2022-09-28 04:22:37,213 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.331,  Train_accy 24.11
2022-09-28 04:22:39,620 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.334,  Train_accy 23.41
2022-09-28 04:22:41,977 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.323,  Train_accy 23.61
2022-09-28 04:22:45,165 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.324,  Train_accy 24.50, Test_accy 40.67
2022-09-28 04:22:47,552 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.317,  Train_accy 25.79
2022-09-28 04:22:49,922 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.334,  Train_accy 25.30
2022-09-28 04:22:52,281 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.325,  Train_accy 23.81
2022-09-28 04:22:54,662 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.321,  Train_accy 25.10
2022-09-28 04:22:57,887 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.322,  Train_accy 25.20, Test_accy 40.08
2022-09-28 04:23:00,282 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.323,  Train_accy 25.10
2022-09-28 04:23:02,643 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.315,  Train_accy 24.60
2022-09-28 04:23:05,016 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.318,  Train_accy 25.20
2022-09-28 04:23:07,410 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.325,  Train_accy 25.10
2022-09-28 04:23:10,672 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.320,  Train_accy 25.69, Test_accy 40.48
2022-09-28 04:23:10,672 [foster.py] => do not weight align student!
2022-09-28 04:23:11,508 [foster.py] => darknet eval: 
2022-09-28 04:23:11,508 [foster.py] => CNN top1 curve: 40.48
2022-09-28 04:23:11,508 [foster.py] => CNN top5 curve: 84.52
2022-09-28 04:23:11,508 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 04:23:22,124 [foster.py] => Exemplar size: 440
2022-09-28 04:23:22,125 [trainer.py] => CNN: {'total': 47.22, 'old': 48.2, 'new': 40.0, 'base': 65.19, 'compound': 39.02}
2022-09-28 04:23:22,125 [trainer.py] => CNN top1 curve: [88.61, 77.27, 63.91, 54.77, 50.0, 47.22]
2022-09-28 04:23:22,125 [trainer.py] => CNN base curve: [88.61, 85.44, 81.65, 73.42, 72.15, 65.19]
2022-09-28 04:23:22,125 [trainer.py] => CNN old curve: [88.61, 85.44, 75.0, 61.26, 54.5, 48.2]
2022-09-28 04:23:22,125 [trainer.py] => CNN new curve: [0, 56.45, 34.15, 24.62, 28.57, 40.0]
2022-09-28 04:23:22,125 [trainer.py] => CNN compound curve: [0, 56.45, 44.44, 40.67, 37.76, 39.02]
2022-09-28 04:23:22,125 [trainer.py] => NME: {'total': 53.77, 'old': 53.15, 'new': 58.33, 'base': 63.92, 'compound': 49.13}
2022-09-28 04:23:22,125 [trainer.py] => NME top1 curve: [85.44, 77.27, 69.54, 61.85, 53.15, 53.77]
2022-09-28 04:23:22,125 [trainer.py] => NME base curve: [85.44, 79.75, 73.42, 67.09, 63.92, 63.92]
2022-09-28 04:23:22,125 [trainer.py] => NME old curve: [85.44, 79.75, 70.0, 64.57, 55.59, 53.15]
2022-09-28 04:23:22,125 [trainer.py] => NME new curve: [0, 70.97, 68.29, 49.23, 41.56, 58.33]
2022-09-28 04:23:22,125 [trainer.py] => NME compound curve: [0, 70.97, 65.28, 57.89, 47.2, 49.13]
2022-09-28 04:23:22,126 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 04:23:22,126 [trainer.py] => prefix: cil
2022-09-28 04:23:22,126 [trainer.py] => dataset: CFEE
2022-09-28 04:23:22,126 [trainer.py] => memory_size: 2000
2022-09-28 04:23:22,126 [trainer.py] => memory_per_class: 20
2022-09-28 04:23:22,126 [trainer.py] => fixed_memory: True
2022-09-28 04:23:22,126 [trainer.py] => shuffle: True
2022-09-28 04:23:22,126 [trainer.py] => init_cls: 7
2022-09-28 04:23:22,127 [trainer.py] => increment: 3
2022-09-28 04:23:22,127 [trainer.py] => model_name: foster
2022-09-28 04:23:22,127 [trainer.py] => convnet_type: resnet18
2022-09-28 04:23:22,127 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 04:23:22,127 [trainer.py] => seed: 1993
2022-09-28 04:23:22,127 [trainer.py] => beta1: 0.96
2022-09-28 04:23:22,127 [trainer.py] => beta2: 0.97
2022-09-28 04:23:22,127 [trainer.py] => oofc: ft
2022-09-28 04:23:22,127 [trainer.py] => is_teacher_wa: False
2022-09-28 04:23:22,127 [trainer.py] => is_student_wa: False
2022-09-28 04:23:22,127 [trainer.py] => lambda_okd: 1
2022-09-28 04:23:22,127 [trainer.py] => wa_value: 1
2022-09-28 04:23:22,127 [trainer.py] => init_epochs: 40
2022-09-28 04:23:22,127 [trainer.py] => init_lr: 0.01
2022-09-28 04:23:22,127 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 04:23:22,127 [trainer.py] => boosting_epochs: 34
2022-09-28 04:23:22,127 [trainer.py] => compression_epochs: 26
2022-09-28 04:23:22,127 [trainer.py] => lr: 0.001
2022-09-28 04:23:22,127 [trainer.py] => batch_size: 32
2022-09-28 04:23:22,127 [trainer.py] => weight_decay: 0.0005
2022-09-28 04:23:22,127 [trainer.py] => num_workers: 8
2022-09-28 04:23:22,127 [trainer.py] => T: 2
2022-09-28 04:23:22,127 [trainer.py] => nb_runs: 3
2022-09-28 04:23:22,127 [trainer.py] => fold: 10
2022-09-28 04:23:22,127 [data.py] => ========== Fold:9 ==========
2022-09-28 04:23:22,132 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 8, 15, 13, 17, 9, 11, 19, 21, 14, 10, 18, 12, 7, 16]
2022-09-28 04:23:22,349 [foster.py] => Learning on 0-7
2022-09-28 04:23:22,349 [foster.py] => All params: 11183694
2022-09-28 04:23:22,350 [foster.py] => Trainable params: 11183694
2022-09-28 04:23:24,711 [foster.py] => Task 0, Epoch 1/40 => Loss 1.344, Train_accy 51.35
2022-09-28 04:23:27,700 [foster.py] => Task 0, Epoch 2/40 => Loss 0.543, Train_accy 81.15, Test_accy 80.49
2022-09-28 04:23:30,657 [foster.py] => Task 0, Epoch 3/40 => Loss 0.388, Train_accy 87.46, Test_accy 81.71
2022-09-28 04:23:33,673 [foster.py] => Task 0, Epoch 4/40 => Loss 0.325, Train_accy 89.67, Test_accy 84.15
2022-09-28 04:23:36,631 [foster.py] => Task 0, Epoch 5/40 => Loss 0.282, Train_accy 90.64, Test_accy 84.15
2022-09-28 04:23:39,009 [foster.py] => Task 0, Epoch 6/40 => Loss 0.237, Train_accy 91.20
2022-09-28 04:23:42,037 [foster.py] => Task 0, Epoch 7/40 => Loss 0.199, Train_accy 92.79, Test_accy 82.93
2022-09-28 04:23:45,023 [foster.py] => Task 0, Epoch 8/40 => Loss 0.169, Train_accy 95.36, Test_accy 84.76
2022-09-28 04:23:48,003 [foster.py] => Task 0, Epoch 9/40 => Loss 0.171, Train_accy 95.43, Test_accy 85.37
2022-09-28 04:23:50,967 [foster.py] => Task 0, Epoch 10/40 => Loss 0.176, Train_accy 94.32, Test_accy 82.93
2022-09-28 04:23:53,355 [foster.py] => Task 0, Epoch 11/40 => Loss 0.113, Train_accy 96.81
2022-09-28 04:23:56,329 [foster.py] => Task 0, Epoch 12/40 => Loss 0.077, Train_accy 97.37, Test_accy 84.76
2022-09-28 04:23:59,297 [foster.py] => Task 0, Epoch 13/40 => Loss 0.065, Train_accy 98.54, Test_accy 85.98
2022-09-28 04:24:02,292 [foster.py] => Task 0, Epoch 14/40 => Loss 0.054, Train_accy 98.82, Test_accy 86.59
2022-09-28 04:24:05,313 [foster.py] => Task 0, Epoch 15/40 => Loss 0.059, Train_accy 99.17, Test_accy 88.41
2022-09-28 04:24:07,707 [foster.py] => Task 0, Epoch 16/40 => Loss 0.094, Train_accy 98.20
2022-09-28 04:24:10,674 [foster.py] => Task 0, Epoch 17/40 => Loss 0.093, Train_accy 97.30, Test_accy 84.15
2022-09-28 04:24:13,678 [foster.py] => Task 0, Epoch 18/40 => Loss 0.060, Train_accy 98.41, Test_accy 85.37
2022-09-28 04:24:16,765 [foster.py] => Task 0, Epoch 19/40 => Loss 0.060, Train_accy 98.41, Test_accy 84.15
2022-09-28 04:24:19,760 [foster.py] => Task 0, Epoch 20/40 => Loss 0.034, Train_accy 99.17, Test_accy 85.37
2022-09-28 04:24:22,153 [foster.py] => Task 0, Epoch 21/40 => Loss 0.045, Train_accy 99.38
2022-09-28 04:24:25,110 [foster.py] => Task 0, Epoch 22/40 => Loss 0.065, Train_accy 98.06, Test_accy 86.59
2022-09-28 04:24:28,127 [foster.py] => Task 0, Epoch 23/40 => Loss 0.066, Train_accy 98.96, Test_accy 85.37
2022-09-28 04:24:31,137 [foster.py] => Task 0, Epoch 24/40 => Loss 0.091, Train_accy 98.54, Test_accy 85.98
2022-09-28 04:24:34,138 [foster.py] => Task 0, Epoch 25/40 => Loss 0.036, Train_accy 98.89, Test_accy 83.54
2022-09-28 04:24:36,509 [foster.py] => Task 0, Epoch 26/40 => Loss 0.036, Train_accy 99.10
2022-09-28 04:24:39,523 [foster.py] => Task 0, Epoch 27/40 => Loss 0.028, Train_accy 99.38, Test_accy 83.54
2022-09-28 04:24:42,572 [foster.py] => Task 0, Epoch 28/40 => Loss 0.022, Train_accy 99.58, Test_accy 84.76
2022-09-28 04:24:45,541 [foster.py] => Task 0, Epoch 29/40 => Loss 0.025, Train_accy 99.58, Test_accy 86.59
2022-09-28 04:24:48,499 [foster.py] => Task 0, Epoch 30/40 => Loss 0.022, Train_accy 99.51, Test_accy 83.54
2022-09-28 04:24:50,869 [foster.py] => Task 0, Epoch 31/40 => Loss 0.023, Train_accy 99.38
2022-09-28 04:24:53,864 [foster.py] => Task 0, Epoch 32/40 => Loss 0.026, Train_accy 99.45, Test_accy 84.15
2022-09-28 04:24:56,883 [foster.py] => Task 0, Epoch 33/40 => Loss 0.026, Train_accy 99.17, Test_accy 84.76
2022-09-28 04:24:59,884 [foster.py] => Task 0, Epoch 34/40 => Loss 0.031, Train_accy 99.79, Test_accy 85.98
2022-09-28 04:25:02,867 [foster.py] => Task 0, Epoch 35/40 => Loss 0.016, Train_accy 99.86, Test_accy 84.15
2022-09-28 04:25:05,225 [foster.py] => Task 0, Epoch 36/40 => Loss 0.024, Train_accy 99.65
2022-09-28 04:25:08,243 [foster.py] => Task 0, Epoch 37/40 => Loss 0.030, Train_accy 99.45, Test_accy 84.15
2022-09-28 04:25:11,246 [foster.py] => Task 0, Epoch 38/40 => Loss 0.015, Train_accy 99.72, Test_accy 84.76
2022-09-28 04:25:14,215 [foster.py] => Task 0, Epoch 39/40 => Loss 0.017, Train_accy 99.79, Test_accy 84.76
2022-09-28 04:25:17,239 [foster.py] => Task 0, Epoch 40/40 => Loss 0.017, Train_accy 99.79, Test_accy 83.54
2022-09-28 04:25:17,240 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 04:25:24,089 [foster.py] => Exemplar size: 140
2022-09-28 04:25:24,089 [trainer.py] => CNN: {'total': 83.54, 'old': 83.54, 'new': 0, 'base': 83.54, 'compound': 0}
2022-09-28 04:25:24,089 [trainer.py] => CNN top1 curve: [83.54]
2022-09-28 04:25:24,089 [trainer.py] => CNN base curve: [83.54]
2022-09-28 04:25:24,089 [trainer.py] => CNN old curve: [83.54]
2022-09-28 04:25:24,089 [trainer.py] => CNN new curve: [0]
2022-09-28 04:25:24,089 [trainer.py] => CNN compound curve: [0]
2022-09-28 04:25:24,089 [trainer.py] => NME: {'total': 85.37, 'old': 85.37, 'new': 0, 'base': 85.37, 'compound': 0}
2022-09-28 04:25:24,089 [trainer.py] => NME top1 curve: [85.37]
2022-09-28 04:25:24,089 [trainer.py] => NME base curve: [85.37]
2022-09-28 04:25:24,089 [trainer.py] => NME old curve: [85.37]
2022-09-28 04:25:24,090 [trainer.py] => NME new curve: [0]
2022-09-28 04:25:24,090 [trainer.py] => NME compound curve: [0]
2022-09-28 04:25:24,322 [foster.py] => Learning on 7-10
2022-09-28 04:25:24,322 [foster.py] => All params: 22371995
2022-09-28 04:25:24,322 [foster.py] => Trainable params: 11191892
2022-09-28 04:25:24,343 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 04:25:26,801 [foster.py] => Task 1, Epoch 1/34 => Loss 4.569, Loss_clf 1.977, Loss_fe 1.945, Loss_kd 0.453, Train_accy 39.47, Test_accy 69.49
2022-09-28 04:25:28,522 [foster.py] => Task 1, Epoch 2/34 => Loss 2.430, Loss_clf 0.615, Loss_fe 1.174, Loss_kd 0.448, Train_accy 70.99
2022-09-28 04:25:30,227 [foster.py] => Task 1, Epoch 3/34 => Loss 1.983, Loss_clf 0.406, Loss_fe 0.958, Loss_kd 0.434, Train_accy 48.34
2022-09-28 04:25:31,928 [foster.py] => Task 1, Epoch 4/34 => Loss 1.763, Loss_clf 0.335, Loss_fe 0.809, Loss_kd 0.434, Train_accy 52.72
2022-09-28 04:25:33,644 [foster.py] => Task 1, Epoch 5/34 => Loss 1.682, Loss_clf 0.329, Loss_fe 0.733, Loss_kd 0.434, Train_accy 53.11
2022-09-28 04:25:36,073 [foster.py] => Task 1, Epoch 6/34 => Loss 1.592, Loss_clf 0.311, Loss_fe 0.666, Loss_kd 0.430, Train_accy 51.13, Test_accy 72.03
2022-09-28 04:25:37,826 [foster.py] => Task 1, Epoch 7/34 => Loss 1.528, Loss_clf 0.309, Loss_fe 0.599, Loss_kd 0.434, Train_accy 52.85
2022-09-28 04:25:39,523 [foster.py] => Task 1, Epoch 8/34 => Loss 1.452, Loss_clf 0.273, Loss_fe 0.559, Loss_kd 0.434, Train_accy 56.95
2022-09-28 04:25:41,230 [foster.py] => Task 1, Epoch 9/34 => Loss 1.406, Loss_clf 0.270, Loss_fe 0.528, Loss_kd 0.426, Train_accy 56.03
2022-09-28 04:25:42,967 [foster.py] => Task 1, Epoch 10/34 => Loss 1.349, Loss_clf 0.254, Loss_fe 0.485, Loss_kd 0.427, Train_accy 57.09
2022-09-28 04:25:45,464 [foster.py] => Task 1, Epoch 11/34 => Loss 1.324, Loss_clf 0.254, Loss_fe 0.453, Loss_kd 0.433, Train_accy 56.29, Test_accy 74.15
2022-09-28 04:25:47,222 [foster.py] => Task 1, Epoch 12/34 => Loss 1.291, Loss_clf 0.239, Loss_fe 0.440, Loss_kd 0.428, Train_accy 55.63
2022-09-28 04:25:48,976 [foster.py] => Task 1, Epoch 13/34 => Loss 1.264, Loss_clf 0.234, Loss_fe 0.409, Loss_kd 0.435, Train_accy 60.00
2022-09-28 04:25:50,694 [foster.py] => Task 1, Epoch 14/34 => Loss 1.236, Loss_clf 0.225, Loss_fe 0.388, Loss_kd 0.435, Train_accy 60.00
2022-09-28 04:25:52,423 [foster.py] => Task 1, Epoch 15/34 => Loss 1.250, Loss_clf 0.232, Loss_fe 0.397, Loss_kd 0.435, Train_accy 58.28
2022-09-28 04:25:54,896 [foster.py] => Task 1, Epoch 16/34 => Loss 1.196, Loss_clf 0.211, Loss_fe 0.374, Loss_kd 0.428, Train_accy 58.54, Test_accy 75.00
2022-09-28 04:25:56,669 [foster.py] => Task 1, Epoch 17/34 => Loss 1.178, Loss_clf 0.211, Loss_fe 0.359, Loss_kd 0.425, Train_accy 57.75
2022-09-28 04:25:58,396 [foster.py] => Task 1, Epoch 18/34 => Loss 1.171, Loss_clf 0.206, Loss_fe 0.352, Loss_kd 0.429, Train_accy 60.40
2022-09-28 04:26:00,097 [foster.py] => Task 1, Epoch 19/34 => Loss 1.160, Loss_clf 0.198, Loss_fe 0.346, Loss_kd 0.432, Train_accy 59.87
2022-09-28 04:26:01,796 [foster.py] => Task 1, Epoch 20/34 => Loss 1.177, Loss_clf 0.209, Loss_fe 0.352, Loss_kd 0.431, Train_accy 59.07
2022-09-28 04:26:04,320 [foster.py] => Task 1, Epoch 21/34 => Loss 1.151, Loss_clf 0.200, Loss_fe 0.340, Loss_kd 0.427, Train_accy 60.93, Test_accy 75.00
2022-09-28 04:26:06,008 [foster.py] => Task 1, Epoch 22/34 => Loss 1.116, Loss_clf 0.186, Loss_fe 0.316, Loss_kd 0.430, Train_accy 63.05
2022-09-28 04:26:07,699 [foster.py] => Task 1, Epoch 23/34 => Loss 1.107, Loss_clf 0.183, Loss_fe 0.308, Loss_kd 0.431, Train_accy 61.72
2022-09-28 04:26:09,482 [foster.py] => Task 1, Epoch 24/34 => Loss 1.123, Loss_clf 0.190, Loss_fe 0.318, Loss_kd 0.430, Train_accy 59.34
2022-09-28 04:26:11,221 [foster.py] => Task 1, Epoch 25/34 => Loss 1.142, Loss_clf 0.193, Loss_fe 0.335, Loss_kd 0.430, Train_accy 60.13
2022-09-28 04:26:13,686 [foster.py] => Task 1, Epoch 26/34 => Loss 1.126, Loss_clf 0.186, Loss_fe 0.310, Loss_kd 0.441, Train_accy 61.46, Test_accy 75.42
2022-09-28 04:26:15,434 [foster.py] => Task 1, Epoch 27/34 => Loss 1.138, Loss_clf 0.201, Loss_fe 0.322, Loss_kd 0.430, Train_accy 60.40
2022-09-28 04:26:17,154 [foster.py] => Task 1, Epoch 28/34 => Loss 1.120, Loss_clf 0.188, Loss_fe 0.312, Loss_kd 0.434, Train_accy 60.13
2022-09-28 04:26:18,856 [foster.py] => Task 1, Epoch 29/34 => Loss 1.085, Loss_clf 0.166, Loss_fe 0.297, Loss_kd 0.435, Train_accy 60.79
2022-09-28 04:26:20,551 [foster.py] => Task 1, Epoch 30/34 => Loss 1.081, Loss_clf 0.177, Loss_fe 0.288, Loss_kd 0.431, Train_accy 61.99
2022-09-28 04:26:23,048 [foster.py] => Task 1, Epoch 31/34 => Loss 1.115, Loss_clf 0.188, Loss_fe 0.314, Loss_kd 0.429, Train_accy 60.26, Test_accy 75.85
2022-09-28 04:26:24,782 [foster.py] => Task 1, Epoch 32/34 => Loss 1.096, Loss_clf 0.174, Loss_fe 0.297, Loss_kd 0.438, Train_accy 62.12
2022-09-28 04:26:26,485 [foster.py] => Task 1, Epoch 33/34 => Loss 1.088, Loss_clf 0.180, Loss_fe 0.293, Loss_kd 0.431, Train_accy 61.06
2022-09-28 04:26:28,218 [foster.py] => Task 1, Epoch 34/34 => Loss 1.097, Loss_clf 0.172, Loss_fe 0.301, Loss_kd 0.437, Train_accy 61.85
2022-09-28 04:26:28,219 [foster.py] => do not weight align teacher!
2022-09-28 04:26:28,219 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 04:26:31,054 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.576,  Train_accy 18.01, Test_accy 59.32
2022-09-28 04:26:32,941 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.423,  Train_accy 18.54
2022-09-28 04:26:34,830 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.340,  Train_accy 18.54
2022-09-28 04:26:36,754 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.279,  Train_accy 20.00
2022-09-28 04:26:38,687 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.250,  Train_accy 20.53
2022-09-28 04:26:41,270 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.226,  Train_accy 22.52, Test_accy 61.44
2022-09-28 04:26:43,199 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.233,  Train_accy 23.58
2022-09-28 04:26:45,087 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.206,  Train_accy 23.44
2022-09-28 04:26:46,997 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.201,  Train_accy 24.90
2022-09-28 04:26:48,904 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.191,  Train_accy 26.23
2022-09-28 04:26:51,466 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.190,  Train_accy 26.36, Test_accy 61.86
2022-09-28 04:26:53,416 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.179,  Train_accy 26.75
2022-09-28 04:26:55,311 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.166,  Train_accy 27.68
2022-09-28 04:26:57,238 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.172,  Train_accy 29.01
2022-09-28 04:26:59,165 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.158,  Train_accy 29.27
2022-09-28 04:27:01,768 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.156,  Train_accy 29.27, Test_accy 62.29
2022-09-28 04:27:03,720 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.174,  Train_accy 28.74
2022-09-28 04:27:05,676 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.157,  Train_accy 29.54
2022-09-28 04:27:07,647 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.153,  Train_accy 27.55
2022-09-28 04:27:09,553 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.163,  Train_accy 30.07
2022-09-28 04:27:12,155 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.155,  Train_accy 29.54, Test_accy 63.98
2022-09-28 04:27:14,079 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.149,  Train_accy 28.34
2022-09-28 04:27:15,962 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.157,  Train_accy 30.73
2022-09-28 04:27:17,869 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.150,  Train_accy 30.46
2022-09-28 04:27:19,762 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.161,  Train_accy 29.54
2022-09-28 04:27:22,381 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.154,  Train_accy 29.93, Test_accy 63.14
2022-09-28 04:27:22,382 [foster.py] => do not weight align student!
2022-09-28 04:27:23,097 [foster.py] => darknet eval: 
2022-09-28 04:27:23,097 [foster.py] => CNN top1 curve: 63.14
2022-09-28 04:27:23,097 [foster.py] => CNN top5 curve: 97.88
2022-09-28 04:27:23,097 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 04:27:29,451 [foster.py] => Exemplar size: 200
2022-09-28 04:27:29,451 [trainer.py] => CNN: {'total': 75.85, 'old': 83.54, 'new': 58.33, 'base': 83.54, 'compound': 58.33}
2022-09-28 04:27:29,451 [trainer.py] => CNN top1 curve: [83.54, 75.85]
2022-09-28 04:27:29,451 [trainer.py] => CNN base curve: [83.54, 83.54]
2022-09-28 04:27:29,452 [trainer.py] => CNN old curve: [83.54, 83.54]
2022-09-28 04:27:29,452 [trainer.py] => CNN new curve: [0, 58.33]
2022-09-28 04:27:29,452 [trainer.py] => CNN compound curve: [0, 58.33]
2022-09-28 04:27:29,452 [trainer.py] => NME: {'total': 81.78, 'old': 83.54, 'new': 77.78, 'base': 83.54, 'compound': 77.78}
2022-09-28 04:27:29,452 [trainer.py] => NME top1 curve: [85.37, 81.78]
2022-09-28 04:27:29,452 [trainer.py] => NME base curve: [85.37, 83.54]
2022-09-28 04:27:29,452 [trainer.py] => NME old curve: [85.37, 83.54]
2022-09-28 04:27:29,452 [trainer.py] => NME new curve: [0, 77.78]
2022-09-28 04:27:29,452 [trainer.py] => NME compound curve: [0, 77.78]
2022-09-28 04:27:29,686 [foster.py] => Learning on 10-13
2022-09-28 04:27:29,686 [foster.py] => All params: 22378148
2022-09-28 04:27:29,687 [foster.py] => Trainable params: 11196506
2022-09-28 04:27:29,707 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 04:27:32,338 [foster.py] => Task 2, Epoch 1/34 => Loss 5.486, Loss_clf 2.188, Loss_fe 2.146, Loss_kd 0.886, Train_accy 41.65, Test_accy 46.50
2022-09-28 04:27:34,205 [foster.py] => Task 2, Epoch 2/34 => Loss 3.198, Loss_clf 0.745, Loss_fe 1.305, Loss_kd 0.883, Train_accy 61.93
2022-09-28 04:27:36,062 [foster.py] => Task 2, Epoch 3/34 => Loss 2.774, Loss_clf 0.552, Loss_fe 1.072, Loss_kd 0.885, Train_accy 45.94
2022-09-28 04:27:37,953 [foster.py] => Task 2, Epoch 4/34 => Loss 2.652, Loss_clf 0.521, Loss_fe 0.982, Loss_kd 0.884, Train_accy 51.91
2022-09-28 04:27:39,799 [foster.py] => Task 2, Epoch 5/34 => Loss 2.526, Loss_clf 0.499, Loss_fe 0.909, Loss_kd 0.859, Train_accy 45.58
2022-09-28 04:27:42,440 [foster.py] => Task 2, Epoch 6/34 => Loss 2.401, Loss_clf 0.462, Loss_fe 0.800, Loss_kd 0.877, Train_accy 48.21, Test_accy 64.34
2022-09-28 04:27:44,315 [foster.py] => Task 2, Epoch 7/34 => Loss 2.339, Loss_clf 0.442, Loss_fe 0.752, Loss_kd 0.881, Train_accy 51.43
2022-09-28 04:27:46,173 [foster.py] => Task 2, Epoch 8/34 => Loss 2.307, Loss_clf 0.445, Loss_fe 0.715, Loss_kd 0.882, Train_accy 48.93
2022-09-28 04:27:48,023 [foster.py] => Task 2, Epoch 9/34 => Loss 2.249, Loss_clf 0.429, Loss_fe 0.675, Loss_kd 0.881, Train_accy 46.66
2022-09-28 04:27:49,971 [foster.py] => Task 2, Epoch 10/34 => Loss 2.212, Loss_clf 0.424, Loss_fe 0.651, Loss_kd 0.875, Train_accy 49.88
2022-09-28 04:27:52,605 [foster.py] => Task 2, Epoch 11/34 => Loss 2.151, Loss_clf 0.400, Loss_fe 0.616, Loss_kd 0.873, Train_accy 47.97, Test_accy 65.73
2022-09-28 04:27:54,480 [foster.py] => Task 2, Epoch 12/34 => Loss 2.100, Loss_clf 0.377, Loss_fe 0.570, Loss_kd 0.887, Train_accy 52.39
2022-09-28 04:27:56,318 [foster.py] => Task 2, Epoch 13/34 => Loss 2.089, Loss_clf 0.379, Loss_fe 0.562, Loss_kd 0.883, Train_accy 50.12
2022-09-28 04:27:58,145 [foster.py] => Task 2, Epoch 14/34 => Loss 2.084, Loss_clf 0.382, Loss_fe 0.548, Loss_kd 0.888, Train_accy 51.19
2022-09-28 04:28:00,024 [foster.py] => Task 2, Epoch 15/34 => Loss 2.021, Loss_clf 0.365, Loss_fe 0.521, Loss_kd 0.873, Train_accy 51.79
2022-09-28 04:28:02,677 [foster.py] => Task 2, Epoch 16/34 => Loss 2.030, Loss_clf 0.372, Loss_fe 0.519, Loss_kd 0.876, Train_accy 51.79, Test_accy 65.38
2022-09-28 04:28:04,505 [foster.py] => Task 2, Epoch 17/34 => Loss 2.055, Loss_clf 0.383, Loss_fe 0.526, Loss_kd 0.881, Train_accy 50.36
2022-09-28 04:28:06,365 [foster.py] => Task 2, Epoch 18/34 => Loss 2.020, Loss_clf 0.381, Loss_fe 0.509, Loss_kd 0.869, Train_accy 50.36
2022-09-28 04:28:08,238 [foster.py] => Task 2, Epoch 19/34 => Loss 1.983, Loss_clf 0.356, Loss_fe 0.496, Loss_kd 0.870, Train_accy 51.07
2022-09-28 04:28:10,121 [foster.py] => Task 2, Epoch 20/34 => Loss 1.950, Loss_clf 0.345, Loss_fe 0.474, Loss_kd 0.871, Train_accy 51.31
2022-09-28 04:28:12,760 [foster.py] => Task 2, Epoch 21/34 => Loss 1.995, Loss_clf 0.364, Loss_fe 0.491, Loss_kd 0.877, Train_accy 51.31, Test_accy 65.38
2022-09-28 04:28:14,621 [foster.py] => Task 2, Epoch 22/34 => Loss 1.990, Loss_clf 0.359, Loss_fe 0.474, Loss_kd 0.890, Train_accy 51.55
2022-09-28 04:28:16,477 [foster.py] => Task 2, Epoch 23/34 => Loss 1.936, Loss_clf 0.338, Loss_fe 0.455, Loss_kd 0.879, Train_accy 50.36
2022-09-28 04:28:18,319 [foster.py] => Task 2, Epoch 24/34 => Loss 1.942, Loss_clf 0.335, Loss_fe 0.459, Loss_kd 0.884, Train_accy 52.51
2022-09-28 04:28:20,181 [foster.py] => Task 2, Epoch 25/34 => Loss 1.923, Loss_clf 0.334, Loss_fe 0.453, Loss_kd 0.874, Train_accy 50.95
2022-09-28 04:28:22,806 [foster.py] => Task 2, Epoch 26/34 => Loss 1.925, Loss_clf 0.330, Loss_fe 0.450, Loss_kd 0.881, Train_accy 51.67, Test_accy 66.78
2022-09-28 04:28:24,646 [foster.py] => Task 2, Epoch 27/34 => Loss 1.935, Loss_clf 0.339, Loss_fe 0.450, Loss_kd 0.881, Train_accy 52.51
2022-09-28 04:28:26,505 [foster.py] => Task 2, Epoch 28/34 => Loss 1.909, Loss_clf 0.327, Loss_fe 0.436, Loss_kd 0.882, Train_accy 52.63
2022-09-28 04:28:28,351 [foster.py] => Task 2, Epoch 29/34 => Loss 1.913, Loss_clf 0.333, Loss_fe 0.441, Loss_kd 0.876, Train_accy 50.95
2022-09-28 04:28:30,219 [foster.py] => Task 2, Epoch 30/34 => Loss 1.898, Loss_clf 0.336, Loss_fe 0.428, Loss_kd 0.873, Train_accy 51.79
2022-09-28 04:28:32,840 [foster.py] => Task 2, Epoch 31/34 => Loss 1.942, Loss_clf 0.352, Loss_fe 0.458, Loss_kd 0.870, Train_accy 50.95, Test_accy 66.43
2022-09-28 04:28:34,695 [foster.py] => Task 2, Epoch 32/34 => Loss 1.906, Loss_clf 0.325, Loss_fe 0.436, Loss_kd 0.881, Train_accy 52.39
2022-09-28 04:28:36,614 [foster.py] => Task 2, Epoch 33/34 => Loss 1.921, Loss_clf 0.336, Loss_fe 0.433, Loss_kd 0.886, Train_accy 52.03
2022-09-28 04:28:38,442 [foster.py] => Task 2, Epoch 34/34 => Loss 1.921, Loss_clf 0.330, Loss_fe 0.450, Loss_kd 0.877, Train_accy 52.39
2022-09-28 04:28:38,442 [foster.py] => do not weight align teacher!
2022-09-28 04:28:38,443 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 04:28:41,475 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.800,  Train_accy 16.71, Test_accy 51.05
2022-09-28 04:28:43,554 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.670,  Train_accy 17.18
2022-09-28 04:28:45,587 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.623,  Train_accy 17.42
2022-09-28 04:28:47,721 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.597,  Train_accy 18.14
2022-09-28 04:28:49,794 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.599,  Train_accy 18.62
2022-09-28 04:28:52,603 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.574,  Train_accy 19.09, Test_accy 53.50
2022-09-28 04:28:54,695 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.570,  Train_accy 19.09
2022-09-28 04:28:56,795 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.566,  Train_accy 20.53
2022-09-28 04:28:58,839 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.555,  Train_accy 20.64
2022-09-28 04:29:00,929 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.534,  Train_accy 21.48
2022-09-28 04:29:03,685 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.538,  Train_accy 22.43, Test_accy 55.59
2022-09-28 04:29:05,778 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.522,  Train_accy 21.48
2022-09-28 04:29:07,849 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.531,  Train_accy 23.15
2022-09-28 04:29:09,939 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.529,  Train_accy 23.75
2022-09-28 04:29:12,032 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.505,  Train_accy 22.91
2022-09-28 04:29:14,867 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.538,  Train_accy 23.15, Test_accy 58.04
2022-09-28 04:29:16,923 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.527,  Train_accy 22.20
2022-09-28 04:29:18,997 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.519,  Train_accy 25.06
2022-09-28 04:29:21,046 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.520,  Train_accy 24.11
2022-09-28 04:29:23,142 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.521,  Train_accy 24.34
2022-09-28 04:29:25,982 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.523,  Train_accy 23.63, Test_accy 58.74
2022-09-28 04:29:28,030 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.514,  Train_accy 25.42
2022-09-28 04:29:30,110 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.518,  Train_accy 24.82
2022-09-28 04:29:32,192 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.536,  Train_accy 24.70
2022-09-28 04:29:34,241 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.517,  Train_accy 24.94
2022-09-28 04:29:37,004 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.517,  Train_accy 24.82, Test_accy 58.74
2022-09-28 04:29:37,004 [foster.py] => do not weight align student!
2022-09-28 04:29:37,706 [foster.py] => darknet eval: 
2022-09-28 04:29:37,706 [foster.py] => CNN top1 curve: 58.74
2022-09-28 04:29:37,707 [foster.py] => CNN top5 curve: 96.5
2022-09-28 04:29:37,707 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 04:29:45,085 [foster.py] => Exemplar size: 260
2022-09-28 04:29:45,085 [trainer.py] => CNN: {'total': 65.38, 'old': 72.46, 'new': 32.0, 'base': 78.66, 'compound': 47.54}
2022-09-28 04:29:45,085 [trainer.py] => CNN top1 curve: [83.54, 75.85, 65.38]
2022-09-28 04:29:45,085 [trainer.py] => CNN base curve: [83.54, 83.54, 78.66]
2022-09-28 04:29:45,086 [trainer.py] => CNN old curve: [83.54, 83.54, 72.46]
2022-09-28 04:29:45,086 [trainer.py] => CNN new curve: [0, 58.33, 32.0]
2022-09-28 04:29:45,086 [trainer.py] => CNN compound curve: [0, 58.33, 47.54]
2022-09-28 04:29:45,086 [trainer.py] => NME: {'total': 72.03, 'old': 74.15, 'new': 62.0, 'base': 75.0, 'compound': 68.03}
2022-09-28 04:29:45,086 [trainer.py] => NME top1 curve: [85.37, 81.78, 72.03]
2022-09-28 04:29:45,086 [trainer.py] => NME base curve: [85.37, 83.54, 75.0]
2022-09-28 04:29:45,086 [trainer.py] => NME old curve: [85.37, 83.54, 74.15]
2022-09-28 04:29:45,086 [trainer.py] => NME new curve: [0, 77.78, 62.0]
2022-09-28 04:29:45,086 [trainer.py] => NME compound curve: [0, 77.78, 68.03]
2022-09-28 04:29:45,319 [foster.py] => Learning on 13-16
2022-09-28 04:29:45,319 [foster.py] => All params: 22384301
2022-09-28 04:29:45,319 [foster.py] => Trainable params: 11201120
2022-09-28 04:29:45,340 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 04:29:48,088 [foster.py] => Task 3, Epoch 1/34 => Loss 6.312, Loss_clf 2.306, Loss_fe 2.426, Loss_kd 1.284, Train_accy 36.42, Test_accy 47.21
2022-09-28 04:29:49,982 [foster.py] => Task 3, Epoch 2/34 => Loss 4.481, Loss_clf 1.159, Loss_fe 1.756, Loss_kd 1.273, Train_accy 37.90
2022-09-28 04:29:51,947 [foster.py] => Task 3, Epoch 3/34 => Loss 4.090, Loss_clf 0.983, Loss_fe 1.556, Loss_kd 1.260, Train_accy 35.39
2022-09-28 04:29:53,869 [foster.py] => Task 3, Epoch 4/34 => Loss 3.922, Loss_clf 0.941, Loss_fe 1.426, Loss_kd 1.264, Train_accy 35.73
2022-09-28 04:29:55,801 [foster.py] => Task 3, Epoch 5/34 => Loss 3.767, Loss_clf 0.892, Loss_fe 1.331, Loss_kd 1.255, Train_accy 38.01
2022-09-28 04:29:58,524 [foster.py] => Task 3, Epoch 6/34 => Loss 3.653, Loss_clf 0.869, Loss_fe 1.241, Loss_kd 1.254, Train_accy 37.67, Test_accy 57.54
2022-09-28 04:30:00,433 [foster.py] => Task 3, Epoch 7/34 => Loss 3.612, Loss_clf 0.871, Loss_fe 1.195, Loss_kd 1.257, Train_accy 40.30
2022-09-28 04:30:02,364 [foster.py] => Task 3, Epoch 8/34 => Loss 3.488, Loss_clf 0.829, Loss_fe 1.114, Loss_kd 1.255, Train_accy 38.47
2022-09-28 04:30:04,291 [foster.py] => Task 3, Epoch 9/34 => Loss 3.446, Loss_clf 0.823, Loss_fe 1.084, Loss_kd 1.250, Train_accy 39.73
2022-09-28 04:30:06,284 [foster.py] => Task 3, Epoch 10/34 => Loss 3.399, Loss_clf 0.811, Loss_fe 1.045, Loss_kd 1.253, Train_accy 39.38
2022-09-28 04:30:09,113 [foster.py] => Task 3, Epoch 11/34 => Loss 3.357, Loss_clf 0.797, Loss_fe 1.009, Loss_kd 1.260, Train_accy 38.93, Test_accy 56.15
2022-09-28 04:30:11,044 [foster.py] => Task 3, Epoch 12/34 => Loss 3.325, Loss_clf 0.801, Loss_fe 0.992, Loss_kd 1.245, Train_accy 39.61
2022-09-28 04:30:12,955 [foster.py] => Task 3, Epoch 13/34 => Loss 3.272, Loss_clf 0.766, Loss_fe 0.957, Loss_kd 1.259, Train_accy 39.84
2022-09-28 04:30:14,907 [foster.py] => Task 3, Epoch 14/34 => Loss 3.206, Loss_clf 0.750, Loss_fe 0.916, Loss_kd 1.251, Train_accy 40.64
2022-09-28 04:30:16,787 [foster.py] => Task 3, Epoch 15/34 => Loss 3.221, Loss_clf 0.745, Loss_fe 0.917, Loss_kd 1.267, Train_accy 42.47
2022-09-28 04:30:19,551 [foster.py] => Task 3, Epoch 16/34 => Loss 3.155, Loss_clf 0.728, Loss_fe 0.884, Loss_kd 1.254, Train_accy 41.78, Test_accy 56.15
2022-09-28 04:30:21,470 [foster.py] => Task 3, Epoch 17/34 => Loss 3.121, Loss_clf 0.707, Loss_fe 0.865, Loss_kd 1.258, Train_accy 45.21
2022-09-28 04:30:23,397 [foster.py] => Task 3, Epoch 18/34 => Loss 3.098, Loss_clf 0.700, Loss_fe 0.850, Loss_kd 1.257, Train_accy 41.55
2022-09-28 04:30:25,300 [foster.py] => Task 3, Epoch 19/34 => Loss 3.113, Loss_clf 0.714, Loss_fe 0.858, Loss_kd 1.252, Train_accy 41.10
2022-09-28 04:30:27,216 [foster.py] => Task 3, Epoch 20/34 => Loss 3.101, Loss_clf 0.694, Loss_fe 0.847, Loss_kd 1.267, Train_accy 44.98
2022-09-28 04:30:29,985 [foster.py] => Task 3, Epoch 21/34 => Loss 3.029, Loss_clf 0.680, Loss_fe 0.806, Loss_kd 1.254, Train_accy 40.41, Test_accy 55.87
2022-09-28 04:30:31,921 [foster.py] => Task 3, Epoch 22/34 => Loss 3.034, Loss_clf 0.681, Loss_fe 0.807, Loss_kd 1.256, Train_accy 44.41
2022-09-28 04:30:33,816 [foster.py] => Task 3, Epoch 23/34 => Loss 3.026, Loss_clf 0.667, Loss_fe 0.807, Loss_kd 1.261, Train_accy 45.89
2022-09-28 04:30:35,778 [foster.py] => Task 3, Epoch 24/34 => Loss 2.986, Loss_clf 0.647, Loss_fe 0.782, Loss_kd 1.265, Train_accy 43.38
2022-09-28 04:30:37,662 [foster.py] => Task 3, Epoch 25/34 => Loss 3.021, Loss_clf 0.674, Loss_fe 0.797, Loss_kd 1.260, Train_accy 43.49
2022-09-28 04:30:40,413 [foster.py] => Task 3, Epoch 26/34 => Loss 2.980, Loss_clf 0.645, Loss_fe 0.785, Loss_kd 1.260, Train_accy 42.69, Test_accy 56.70
2022-09-28 04:30:42,304 [foster.py] => Task 3, Epoch 27/34 => Loss 2.995, Loss_clf 0.663, Loss_fe 0.785, Loss_kd 1.257, Train_accy 42.81
2022-09-28 04:30:44,230 [foster.py] => Task 3, Epoch 28/34 => Loss 3.025, Loss_clf 0.665, Loss_fe 0.806, Loss_kd 1.263, Train_accy 44.18
2022-09-28 04:30:46,130 [foster.py] => Task 3, Epoch 29/34 => Loss 2.983, Loss_clf 0.658, Loss_fe 0.778, Loss_kd 1.257, Train_accy 42.47
2022-09-28 04:30:48,027 [foster.py] => Task 3, Epoch 30/34 => Loss 2.967, Loss_clf 0.649, Loss_fe 0.773, Loss_kd 1.255, Train_accy 43.95
2022-09-28 04:30:50,821 [foster.py] => Task 3, Epoch 31/34 => Loss 3.011, Loss_clf 0.660, Loss_fe 0.799, Loss_kd 1.261, Train_accy 42.69, Test_accy 55.31
2022-09-28 04:30:52,774 [foster.py] => Task 3, Epoch 32/34 => Loss 2.986, Loss_clf 0.658, Loss_fe 0.783, Loss_kd 1.256, Train_accy 45.21
2022-09-28 04:30:54,731 [foster.py] => Task 3, Epoch 33/34 => Loss 2.955, Loss_clf 0.649, Loss_fe 0.771, Loss_kd 1.247, Train_accy 43.95
2022-09-28 04:30:56,636 [foster.py] => Task 3, Epoch 34/34 => Loss 2.953, Loss_clf 0.644, Loss_fe 0.770, Loss_kd 1.251, Train_accy 44.41
2022-09-28 04:30:56,636 [foster.py] => do not weight align teacher!
2022-09-28 04:30:56,637 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 04:30:59,747 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.133,  Train_accy 17.81, Test_accy 47.49
2022-09-28 04:31:01,919 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.015,  Train_accy 18.95
2022-09-28 04:31:04,057 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 1.965,  Train_accy 19.18
2022-09-28 04:31:06,155 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 1.951,  Train_accy 19.75
2022-09-28 04:31:08,276 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.938,  Train_accy 20.21
2022-09-28 04:31:11,199 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.921,  Train_accy 19.29, Test_accy 50.56
2022-09-28 04:31:13,355 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.915,  Train_accy 20.66
2022-09-28 04:31:15,463 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.907,  Train_accy 20.21
2022-09-28 04:31:17,625 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.901,  Train_accy 20.66
2022-09-28 04:31:19,752 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.903,  Train_accy 21.58
2022-09-28 04:31:22,652 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.901,  Train_accy 20.66, Test_accy 51.12
2022-09-28 04:31:24,755 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.896,  Train_accy 20.89
2022-09-28 04:31:26,936 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.893,  Train_accy 21.23
2022-09-28 04:31:29,063 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.896,  Train_accy 19.98
2022-09-28 04:31:31,223 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.901,  Train_accy 20.43
2022-09-28 04:31:34,202 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.891,  Train_accy 20.32, Test_accy 51.40
2022-09-28 04:31:36,356 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.902,  Train_accy 20.78
2022-09-28 04:31:38,477 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.894,  Train_accy 20.66
2022-09-28 04:31:40,672 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.886,  Train_accy 20.55
2022-09-28 04:31:42,839 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.883,  Train_accy 21.00
2022-09-28 04:31:45,740 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.890,  Train_accy 20.89, Test_accy 51.12
2022-09-28 04:31:47,886 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.887,  Train_accy 20.43
2022-09-28 04:31:50,017 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.885,  Train_accy 20.78
2022-09-28 04:31:52,143 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.888,  Train_accy 21.12
2022-09-28 04:31:54,284 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.887,  Train_accy 21.58
2022-09-28 04:31:57,187 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.881,  Train_accy 21.58, Test_accy 50.28
2022-09-28 04:31:57,187 [foster.py] => do not weight align student!
2022-09-28 04:31:57,945 [foster.py] => darknet eval: 
2022-09-28 04:31:57,945 [foster.py] => CNN top1 curve: 50.28
2022-09-28 04:31:57,945 [foster.py] => CNN top5 curve: 90.78
2022-09-28 04:31:57,946 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 04:32:06,385 [foster.py] => Exemplar size: 320
2022-09-28 04:32:06,385 [trainer.py] => CNN: {'total': 56.7, 'old': 64.34, 'new': 26.39, 'base': 73.78, 'compound': 42.27}
2022-09-28 04:32:06,385 [trainer.py] => CNN top1 curve: [83.54, 75.85, 65.38, 56.7]
2022-09-28 04:32:06,385 [trainer.py] => CNN base curve: [83.54, 83.54, 78.66, 73.78]
2022-09-28 04:32:06,385 [trainer.py] => CNN old curve: [83.54, 83.54, 72.46, 64.34]
2022-09-28 04:32:06,385 [trainer.py] => CNN new curve: [0, 58.33, 32.0, 26.39]
2022-09-28 04:32:06,385 [trainer.py] => CNN compound curve: [0, 58.33, 47.54, 42.27]
2022-09-28 04:32:06,385 [trainer.py] => NME: {'total': 65.08, 'old': 69.93, 'new': 45.83, 'base': 71.95, 'compound': 59.28}
2022-09-28 04:32:06,385 [trainer.py] => NME top1 curve: [85.37, 81.78, 72.03, 65.08]
2022-09-28 04:32:06,385 [trainer.py] => NME base curve: [85.37, 83.54, 75.0, 71.95]
2022-09-28 04:32:06,385 [trainer.py] => NME old curve: [85.37, 83.54, 74.15, 69.93]
2022-09-28 04:32:06,385 [trainer.py] => NME new curve: [0, 77.78, 62.0, 45.83]
2022-09-28 04:32:06,386 [trainer.py] => NME compound curve: [0, 77.78, 68.03, 59.28]
2022-09-28 04:32:06,617 [foster.py] => Learning on 16-19
2022-09-28 04:32:06,618 [foster.py] => All params: 22390454
2022-09-28 04:32:06,618 [foster.py] => Trainable params: 11205734
2022-09-28 04:32:06,638 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 04:32:09,602 [foster.py] => Task 4, Epoch 1/34 => Loss 6.580, Loss_clf 2.279, Loss_fe 2.379, Loss_kd 1.619, Train_accy 41.21, Test_accy 45.10
2022-09-28 04:32:11,664 [foster.py] => Task 4, Epoch 2/34 => Loss 4.794, Loss_clf 1.076, Loss_fe 1.795, Loss_kd 1.620, Train_accy 38.94
2022-09-28 04:32:13,658 [foster.py] => Task 4, Epoch 3/34 => Loss 4.543, Loss_clf 0.997, Loss_fe 1.627, Loss_kd 1.616, Train_accy 41.53
2022-09-28 04:32:15,667 [foster.py] => Task 4, Epoch 4/34 => Loss 4.346, Loss_clf 0.941, Loss_fe 1.489, Loss_kd 1.614, Train_accy 38.83
2022-09-28 04:32:17,653 [foster.py] => Task 4, Epoch 5/34 => Loss 4.209, Loss_clf 0.912, Loss_fe 1.390, Loss_kd 1.606, Train_accy 39.81
2022-09-28 04:32:20,616 [foster.py] => Task 4, Epoch 6/34 => Loss 4.115, Loss_clf 0.888, Loss_fe 1.308, Loss_kd 1.616, Train_accy 38.94, Test_accy 46.92
2022-09-28 04:32:22,609 [foster.py] => Task 4, Epoch 7/34 => Loss 4.035, Loss_clf 0.874, Loss_fe 1.255, Loss_kd 1.604, Train_accy 39.59
2022-09-28 04:32:24,600 [foster.py] => Task 4, Epoch 8/34 => Loss 4.000, Loss_clf 0.864, Loss_fe 1.213, Loss_kd 1.619, Train_accy 40.56
2022-09-28 04:32:26,599 [foster.py] => Task 4, Epoch 9/34 => Loss 3.913, Loss_clf 0.841, Loss_fe 1.157, Loss_kd 1.612, Train_accy 40.88
2022-09-28 04:32:28,574 [foster.py] => Task 4, Epoch 10/34 => Loss 3.875, Loss_clf 0.835, Loss_fe 1.120, Loss_kd 1.616, Train_accy 43.80
2022-09-28 04:32:31,478 [foster.py] => Task 4, Epoch 11/34 => Loss 3.794, Loss_clf 0.812, Loss_fe 1.065, Loss_kd 1.615, Train_accy 43.37, Test_accy 47.38
2022-09-28 04:32:33,466 [foster.py] => Task 4, Epoch 12/34 => Loss 3.784, Loss_clf 0.812, Loss_fe 1.051, Loss_kd 1.619, Train_accy 41.64
2022-09-28 04:32:35,443 [foster.py] => Task 4, Epoch 13/34 => Loss 3.760, Loss_clf 0.809, Loss_fe 1.034, Loss_kd 1.614, Train_accy 40.99
2022-09-28 04:32:37,406 [foster.py] => Task 4, Epoch 14/34 => Loss 3.722, Loss_clf 0.795, Loss_fe 1.009, Loss_kd 1.615, Train_accy 40.35
2022-09-28 04:32:39,359 [foster.py] => Task 4, Epoch 15/34 => Loss 3.656, Loss_clf 0.782, Loss_fe 0.964, Loss_kd 1.608, Train_accy 42.83
2022-09-28 04:32:42,338 [foster.py] => Task 4, Epoch 16/34 => Loss 3.654, Loss_clf 0.775, Loss_fe 0.958, Loss_kd 1.618, Train_accy 43.26, Test_accy 48.06
2022-09-28 04:32:44,299 [foster.py] => Task 4, Epoch 17/34 => Loss 3.609, Loss_clf 0.758, Loss_fe 0.930, Loss_kd 1.618, Train_accy 43.58
2022-09-28 04:32:46,270 [foster.py] => Task 4, Epoch 18/34 => Loss 3.650, Loss_clf 0.776, Loss_fe 0.948, Loss_kd 1.622, Train_accy 41.53
2022-09-28 04:32:48,239 [foster.py] => Task 4, Epoch 19/34 => Loss 3.599, Loss_clf 0.753, Loss_fe 0.921, Loss_kd 1.621, Train_accy 43.15
2022-09-28 04:32:50,256 [foster.py] => Task 4, Epoch 20/34 => Loss 3.572, Loss_clf 0.742, Loss_fe 0.907, Loss_kd 1.620, Train_accy 42.18
2022-09-28 04:32:53,177 [foster.py] => Task 4, Epoch 21/34 => Loss 3.553, Loss_clf 0.737, Loss_fe 0.887, Loss_kd 1.624, Train_accy 43.58, Test_accy 48.29
2022-09-28 04:32:55,171 [foster.py] => Task 4, Epoch 22/34 => Loss 3.564, Loss_clf 0.741, Loss_fe 0.901, Loss_kd 1.619, Train_accy 42.72
2022-09-28 04:32:57,151 [foster.py] => Task 4, Epoch 23/34 => Loss 3.526, Loss_clf 0.734, Loss_fe 0.875, Loss_kd 1.615, Train_accy 42.93
2022-09-28 04:32:59,124 [foster.py] => Task 4, Epoch 24/34 => Loss 3.475, Loss_clf 0.709, Loss_fe 0.848, Loss_kd 1.615, Train_accy 44.98
2022-09-28 04:33:01,107 [foster.py] => Task 4, Epoch 25/34 => Loss 3.508, Loss_clf 0.718, Loss_fe 0.869, Loss_kd 1.618, Train_accy 43.04
2022-09-28 04:33:03,987 [foster.py] => Task 4, Epoch 26/34 => Loss 3.500, Loss_clf 0.728, Loss_fe 0.854, Loss_kd 1.615, Train_accy 43.37, Test_accy 48.75
2022-09-28 04:33:05,997 [foster.py] => Task 4, Epoch 27/34 => Loss 3.492, Loss_clf 0.714, Loss_fe 0.853, Loss_kd 1.620, Train_accy 45.20
2022-09-28 04:33:08,000 [foster.py] => Task 4, Epoch 28/34 => Loss 3.496, Loss_clf 0.720, Loss_fe 0.854, Loss_kd 1.618, Train_accy 43.37
2022-09-28 04:33:09,952 [foster.py] => Task 4, Epoch 29/34 => Loss 3.489, Loss_clf 0.717, Loss_fe 0.847, Loss_kd 1.622, Train_accy 44.55
2022-09-28 04:33:11,952 [foster.py] => Task 4, Epoch 30/34 => Loss 3.467, Loss_clf 0.708, Loss_fe 0.850, Loss_kd 1.608, Train_accy 43.58
2022-09-28 04:33:14,828 [foster.py] => Task 4, Epoch 31/34 => Loss 3.443, Loss_clf 0.690, Loss_fe 0.832, Loss_kd 1.618, Train_accy 43.26, Test_accy 49.66
2022-09-28 04:33:16,795 [foster.py] => Task 4, Epoch 32/34 => Loss 3.516, Loss_clf 0.735, Loss_fe 0.863, Loss_kd 1.615, Train_accy 43.91
2022-09-28 04:33:18,811 [foster.py] => Task 4, Epoch 33/34 => Loss 3.440, Loss_clf 0.702, Loss_fe 0.828, Loss_kd 1.608, Train_accy 43.15
2022-09-28 04:33:20,775 [foster.py] => Task 4, Epoch 34/34 => Loss 3.459, Loss_clf 0.706, Loss_fe 0.836, Loss_kd 1.615, Train_accy 44.34
2022-09-28 04:33:20,775 [foster.py] => do not weight align teacher!
2022-09-28 04:33:20,775 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 04:33:24,113 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.259,  Train_accy 19.53, Test_accy 40.55
2022-09-28 04:33:26,342 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.204,  Train_accy 21.14
2022-09-28 04:33:28,571 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.190,  Train_accy 20.60
2022-09-28 04:33:30,764 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.188,  Train_accy 20.50
2022-09-28 04:33:33,059 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.170,  Train_accy 21.36
2022-09-28 04:33:36,117 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.179,  Train_accy 21.79, Test_accy 42.82
2022-09-28 04:33:38,312 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.177,  Train_accy 21.57
2022-09-28 04:33:40,547 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.167,  Train_accy 21.90
2022-09-28 04:33:42,792 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.163,  Train_accy 21.04
2022-09-28 04:33:44,987 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.166,  Train_accy 21.47
2022-09-28 04:33:48,024 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.164,  Train_accy 21.14, Test_accy 43.05
2022-09-28 04:33:50,242 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.149,  Train_accy 21.47
2022-09-28 04:33:52,483 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.151,  Train_accy 21.79
2022-09-28 04:33:54,685 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.149,  Train_accy 21.14
2022-09-28 04:33:56,902 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.155,  Train_accy 21.25
2022-09-28 04:33:59,933 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.147,  Train_accy 21.68, Test_accy 43.05
2022-09-28 04:34:02,197 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.149,  Train_accy 21.90
2022-09-28 04:34:04,419 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.148,  Train_accy 22.01
2022-09-28 04:34:06,662 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.145,  Train_accy 21.68
2022-09-28 04:34:08,911 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.150,  Train_accy 20.71
2022-09-28 04:34:12,064 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.141,  Train_accy 21.36, Test_accy 43.05
2022-09-28 04:34:14,273 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.143,  Train_accy 22.22
2022-09-28 04:34:16,486 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.152,  Train_accy 21.57
2022-09-28 04:34:18,762 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.150,  Train_accy 21.36
2022-09-28 04:34:21,069 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.144,  Train_accy 21.90
2022-09-28 04:34:24,088 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.138,  Train_accy 21.57, Test_accy 43.28
2022-09-28 04:34:24,088 [foster.py] => do not weight align student!
2022-09-28 04:34:24,880 [foster.py] => darknet eval: 
2022-09-28 04:34:24,880 [foster.py] => CNN top1 curve: 43.28
2022-09-28 04:34:24,880 [foster.py] => CNN top5 curve: 82.23
2022-09-28 04:34:24,881 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 04:34:34,390 [foster.py] => Exemplar size: 380
2022-09-28 04:34:34,390 [trainer.py] => CNN: {'total': 49.66, 'old': 55.03, 'new': 25.93, 'base': 71.34, 'compound': 36.73}
2022-09-28 04:34:34,391 [trainer.py] => CNN top1 curve: [83.54, 75.85, 65.38, 56.7, 49.66]
2022-09-28 04:34:34,391 [trainer.py] => CNN base curve: [83.54, 83.54, 78.66, 73.78, 71.34]
2022-09-28 04:34:34,391 [trainer.py] => CNN old curve: [83.54, 83.54, 72.46, 64.34, 55.03]
2022-09-28 04:34:34,391 [trainer.py] => CNN new curve: [0, 58.33, 32.0, 26.39, 25.93]
2022-09-28 04:34:34,391 [trainer.py] => CNN compound curve: [0, 58.33, 47.54, 42.27, 36.73]
2022-09-28 04:34:34,391 [trainer.py] => NME: {'total': 55.35, 'old': 57.82, 'new': 44.44, 'base': 67.68, 'compound': 48.0}
2022-09-28 04:34:34,391 [trainer.py] => NME top1 curve: [85.37, 81.78, 72.03, 65.08, 55.35]
2022-09-28 04:34:34,391 [trainer.py] => NME base curve: [85.37, 83.54, 75.0, 71.95, 67.68]
2022-09-28 04:34:34,391 [trainer.py] => NME old curve: [85.37, 83.54, 74.15, 69.93, 57.82]
2022-09-28 04:34:34,391 [trainer.py] => NME new curve: [0, 77.78, 62.0, 45.83, 44.44]
2022-09-28 04:34:34,391 [trainer.py] => NME compound curve: [0, 77.78, 68.03, 59.28, 48.0]
2022-09-28 04:34:34,624 [foster.py] => Learning on 19-22
2022-09-28 04:34:34,624 [foster.py] => All params: 22396607
2022-09-28 04:34:34,625 [foster.py] => Trainable params: 11210348
2022-09-28 04:34:34,645 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 04:34:37,767 [foster.py] => Task 5, Epoch 1/34 => Loss 6.730, Loss_clf 2.040, Loss_fe 2.532, Loss_kd 1.864, Train_accy 37.89, Test_accy 41.47
2022-09-28 04:34:39,891 [foster.py] => Task 5, Epoch 2/34 => Loss 5.111, Loss_clf 1.101, Loss_fe 1.860, Loss_kd 1.856, Train_accy 33.90
2022-09-28 04:34:42,010 [foster.py] => Task 5, Epoch 3/34 => Loss 4.864, Loss_clf 1.020, Loss_fe 1.688, Loss_kd 1.862, Train_accy 36.19
2022-09-28 04:34:44,132 [foster.py] => Task 5, Epoch 4/34 => Loss 4.727, Loss_clf 0.997, Loss_fe 1.575, Loss_kd 1.862, Train_accy 40.48
2022-09-28 04:34:46,268 [foster.py] => Task 5, Epoch 5/34 => Loss 4.582, Loss_clf 0.949, Loss_fe 1.481, Loss_kd 1.859, Train_accy 39.88
2022-09-28 04:34:49,358 [foster.py] => Task 5, Epoch 6/34 => Loss 4.484, Loss_clf 0.937, Loss_fe 1.393, Loss_kd 1.860, Train_accy 39.08, Test_accy 42.06
2022-09-28 04:34:51,485 [foster.py] => Task 5, Epoch 7/34 => Loss 4.376, Loss_clf 0.899, Loss_fe 1.319, Loss_kd 1.864, Train_accy 40.98
2022-09-28 04:34:53,593 [foster.py] => Task 5, Epoch 8/34 => Loss 4.310, Loss_clf 0.890, Loss_fe 1.270, Loss_kd 1.857, Train_accy 42.17
2022-09-28 04:34:55,743 [foster.py] => Task 5, Epoch 9/34 => Loss 4.266, Loss_clf 0.879, Loss_fe 1.232, Loss_kd 1.861, Train_accy 44.37
2022-09-28 04:34:57,854 [foster.py] => Task 5, Epoch 10/34 => Loss 4.207, Loss_clf 0.868, Loss_fe 1.189, Loss_kd 1.857, Train_accy 41.87
2022-09-28 04:35:00,895 [foster.py] => Task 5, Epoch 11/34 => Loss 4.123, Loss_clf 0.831, Loss_fe 1.134, Loss_kd 1.864, Train_accy 46.16, Test_accy 44.64
2022-09-28 04:35:02,968 [foster.py] => Task 5, Epoch 12/34 => Loss 4.100, Loss_clf 0.831, Loss_fe 1.106, Loss_kd 1.868, Train_accy 41.97
2022-09-28 04:35:05,039 [foster.py] => Task 5, Epoch 13/34 => Loss 4.078, Loss_clf 0.824, Loss_fe 1.090, Loss_kd 1.869, Train_accy 44.07
2022-09-28 04:35:07,110 [foster.py] => Task 5, Epoch 14/34 => Loss 4.031, Loss_clf 0.818, Loss_fe 1.050, Loss_kd 1.868, Train_accy 44.87
2022-09-28 04:35:09,247 [foster.py] => Task 5, Epoch 15/34 => Loss 4.014, Loss_clf 0.808, Loss_fe 1.048, Loss_kd 1.863, Train_accy 45.46
2022-09-28 04:35:12,293 [foster.py] => Task 5, Epoch 16/34 => Loss 3.971, Loss_clf 0.789, Loss_fe 1.017, Loss_kd 1.870, Train_accy 44.87, Test_accy 44.64
2022-09-28 04:35:14,387 [foster.py] => Task 5, Epoch 17/34 => Loss 3.932, Loss_clf 0.779, Loss_fe 0.995, Loss_kd 1.865, Train_accy 47.76
2022-09-28 04:35:16,481 [foster.py] => Task 5, Epoch 18/34 => Loss 3.938, Loss_clf 0.785, Loss_fe 0.993, Loss_kd 1.865, Train_accy 43.87
2022-09-28 04:35:18,595 [foster.py] => Task 5, Epoch 19/34 => Loss 3.953, Loss_clf 0.795, Loss_fe 0.994, Loss_kd 1.868, Train_accy 48.35
2022-09-28 04:35:20,731 [foster.py] => Task 5, Epoch 20/34 => Loss 3.911, Loss_clf 0.771, Loss_fe 0.970, Loss_kd 1.874, Train_accy 45.76
2022-09-28 04:35:23,848 [foster.py] => Task 5, Epoch 21/34 => Loss 3.887, Loss_clf 0.768, Loss_fe 0.948, Loss_kd 1.875, Train_accy 45.86, Test_accy 44.84
2022-09-28 04:35:25,958 [foster.py] => Task 5, Epoch 22/34 => Loss 3.892, Loss_clf 0.779, Loss_fe 0.953, Loss_kd 1.865, Train_accy 47.36
2022-09-28 04:35:28,062 [foster.py] => Task 5, Epoch 23/34 => Loss 3.867, Loss_clf 0.756, Loss_fe 0.929, Loss_kd 1.884, Train_accy 47.26
2022-09-28 04:35:30,171 [foster.py] => Task 5, Epoch 24/34 => Loss 3.835, Loss_clf 0.752, Loss_fe 0.924, Loss_kd 1.864, Train_accy 45.76
2022-09-28 04:35:32,308 [foster.py] => Task 5, Epoch 25/34 => Loss 3.788, Loss_clf 0.716, Loss_fe 0.903, Loss_kd 1.874, Train_accy 47.86
2022-09-28 04:35:35,444 [foster.py] => Task 5, Epoch 26/34 => Loss 3.825, Loss_clf 0.747, Loss_fe 0.913, Loss_kd 1.869, Train_accy 46.96, Test_accy 45.04
2022-09-28 04:35:37,508 [foster.py] => Task 5, Epoch 27/34 => Loss 3.800, Loss_clf 0.738, Loss_fe 0.906, Loss_kd 1.863, Train_accy 47.06
2022-09-28 04:35:39,627 [foster.py] => Task 5, Epoch 28/34 => Loss 3.783, Loss_clf 0.725, Loss_fe 0.898, Loss_kd 1.866, Train_accy 47.46
2022-09-28 04:35:41,704 [foster.py] => Task 5, Epoch 29/34 => Loss 3.801, Loss_clf 0.739, Loss_fe 0.899, Loss_kd 1.868, Train_accy 47.26
2022-09-28 04:35:43,786 [foster.py] => Task 5, Epoch 30/34 => Loss 3.814, Loss_clf 0.740, Loss_fe 0.915, Loss_kd 1.865, Train_accy 48.06
2022-09-28 04:35:46,900 [foster.py] => Task 5, Epoch 31/34 => Loss 3.818, Loss_clf 0.744, Loss_fe 0.917, Loss_kd 1.863, Train_accy 46.96, Test_accy 46.03
2022-09-28 04:35:48,984 [foster.py] => Task 5, Epoch 32/34 => Loss 3.782, Loss_clf 0.726, Loss_fe 0.890, Loss_kd 1.870, Train_accy 48.55
2022-09-28 04:35:51,057 [foster.py] => Task 5, Epoch 33/34 => Loss 3.795, Loss_clf 0.735, Loss_fe 0.901, Loss_kd 1.864, Train_accy 46.46
2022-09-28 04:35:53,209 [foster.py] => Task 5, Epoch 34/34 => Loss 3.791, Loss_clf 0.734, Loss_fe 0.897, Loss_kd 1.865, Train_accy 45.66
2022-09-28 04:35:53,210 [foster.py] => do not weight align teacher!
2022-09-28 04:35:53,210 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 04:35:56,678 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.437,  Train_accy 20.64, Test_accy 37.30
2022-09-28 04:35:59,046 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.406,  Train_accy 21.04
2022-09-28 04:36:01,380 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.382,  Train_accy 20.34
2022-09-28 04:36:03,715 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.377,  Train_accy 21.04
2022-09-28 04:36:06,104 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.364,  Train_accy 21.54
2022-09-28 04:36:09,280 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.355,  Train_accy 21.24, Test_accy 39.09
2022-09-28 04:36:11,613 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.359,  Train_accy 20.94
2022-09-28 04:36:14,018 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.345,  Train_accy 20.64
2022-09-28 04:36:16,357 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.338,  Train_accy 20.54
2022-09-28 04:36:18,758 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.344,  Train_accy 20.94
2022-09-28 04:36:22,003 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.330,  Train_accy 21.24, Test_accy 39.68
2022-09-28 04:36:24,392 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.341,  Train_accy 21.64
2022-09-28 04:36:26,751 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.332,  Train_accy 22.13
2022-09-28 04:36:29,150 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.334,  Train_accy 22.33
2022-09-28 04:36:31,531 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.332,  Train_accy 23.03
2022-09-28 04:36:34,790 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.323,  Train_accy 22.53, Test_accy 40.08
2022-09-28 04:36:37,174 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.329,  Train_accy 22.63
2022-09-28 04:36:39,547 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.317,  Train_accy 23.73
2022-09-28 04:36:41,891 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.326,  Train_accy 23.33
2022-09-28 04:36:44,221 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.324,  Train_accy 21.83
2022-09-28 04:36:47,389 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.329,  Train_accy 23.33, Test_accy 39.88
2022-09-28 04:36:49,761 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.327,  Train_accy 21.73
2022-09-28 04:36:52,099 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.327,  Train_accy 24.13
2022-09-28 04:36:54,482 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.323,  Train_accy 22.53
2022-09-28 04:36:56,857 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.327,  Train_accy 22.13
2022-09-28 04:37:00,048 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.332,  Train_accy 22.83, Test_accy 39.09
2022-09-28 04:37:00,048 [foster.py] => do not weight align student!
2022-09-28 04:37:00,886 [foster.py] => darknet eval: 
2022-09-28 04:37:00,886 [foster.py] => CNN top1 curve: 39.09
2022-09-28 04:37:00,886 [foster.py] => CNN top5 curve: 83.53
2022-09-28 04:37:00,887 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 04:37:11,516 [foster.py] => Exemplar size: 440
2022-09-28 04:37:11,516 [trainer.py] => CNN: {'total': 45.44, 'old': 47.61, 'new': 30.77, 'base': 65.85, 'compound': 35.59}
2022-09-28 04:37:11,516 [trainer.py] => CNN top1 curve: [83.54, 75.85, 65.38, 56.7, 49.66, 45.44]
2022-09-28 04:37:11,516 [trainer.py] => CNN base curve: [83.54, 83.54, 78.66, 73.78, 71.34, 65.85]
2022-09-28 04:37:11,516 [trainer.py] => CNN old curve: [83.54, 83.54, 72.46, 64.34, 55.03, 47.61]
2022-09-28 04:37:11,516 [trainer.py] => CNN new curve: [0, 58.33, 32.0, 26.39, 25.93, 30.77]
2022-09-28 04:37:11,516 [trainer.py] => CNN compound curve: [0, 58.33, 47.54, 42.27, 36.73, 35.59]
2022-09-28 04:37:11,516 [trainer.py] => NME: {'total': 54.76, 'old': 54.44, 'new': 56.92, 'base': 71.34, 'compound': 46.76}
2022-09-28 04:37:11,517 [trainer.py] => NME top1 curve: [85.37, 81.78, 72.03, 65.08, 55.35, 54.76]
2022-09-28 04:37:11,517 [trainer.py] => NME base curve: [85.37, 83.54, 75.0, 71.95, 67.68, 71.34]
2022-09-28 04:37:11,517 [trainer.py] => NME old curve: [85.37, 83.54, 74.15, 69.93, 57.82, 54.44]
2022-09-28 04:37:11,517 [trainer.py] => NME new curve: [0, 77.78, 62.0, 45.83, 44.44, 56.92]
2022-09-28 04:37:11,517 [trainer.py] => NME compound curve: [0, 77.78, 68.03, 59.28, 48.0, 46.76]
2022-09-28 04:37:11,518 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 04:37:11,518 [trainer.py] => prefix: cil
2022-09-28 04:37:11,518 [trainer.py] => dataset: CFEE
2022-09-28 04:37:11,518 [trainer.py] => memory_size: 2000
2022-09-28 04:37:11,518 [trainer.py] => memory_per_class: 20
2022-09-28 04:37:11,518 [trainer.py] => fixed_memory: True
2022-09-28 04:37:11,518 [trainer.py] => shuffle: True
2022-09-28 04:37:11,518 [trainer.py] => init_cls: 7
2022-09-28 04:37:11,518 [trainer.py] => increment: 3
2022-09-28 04:37:11,518 [trainer.py] => model_name: foster
2022-09-28 04:37:11,518 [trainer.py] => convnet_type: resnet18
2022-09-28 04:37:11,518 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 04:37:11,518 [trainer.py] => seed: 1993
2022-09-28 04:37:11,518 [trainer.py] => beta1: 0.96
2022-09-28 04:37:11,519 [trainer.py] => beta2: 0.97
2022-09-28 04:37:11,519 [trainer.py] => oofc: ft
2022-09-28 04:37:11,519 [trainer.py] => is_teacher_wa: False
2022-09-28 04:37:11,519 [trainer.py] => is_student_wa: False
2022-09-28 04:37:11,519 [trainer.py] => lambda_okd: 1
2022-09-28 04:37:11,519 [trainer.py] => wa_value: 1
2022-09-28 04:37:11,519 [trainer.py] => init_epochs: 40
2022-09-28 04:37:11,519 [trainer.py] => init_lr: 0.01
2022-09-28 04:37:11,519 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 04:37:11,519 [trainer.py] => boosting_epochs: 34
2022-09-28 04:37:11,519 [trainer.py] => compression_epochs: 26
2022-09-28 04:37:11,519 [trainer.py] => lr: 0.001
2022-09-28 04:37:11,519 [trainer.py] => batch_size: 32
2022-09-28 04:37:11,519 [trainer.py] => weight_decay: 0.0005
2022-09-28 04:37:11,519 [trainer.py] => num_workers: 8
2022-09-28 04:37:11,519 [trainer.py] => T: 2
2022-09-28 04:37:11,519 [trainer.py] => nb_runs: 3
2022-09-28 04:37:11,519 [trainer.py] => fold: 10
2022-09-28 04:37:11,519 [data.py] => ========== Fold:0 ==========
2022-09-28 04:37:11,524 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 12, 10, 19, 21, 17, 18, 8, 7, 9, 14, 15, 13, 11, 16]
2022-09-28 04:37:11,742 [foster.py] => Learning on 0-7
2022-09-28 04:37:11,742 [foster.py] => All params: 11183694
2022-09-28 04:37:11,742 [foster.py] => Trainable params: 11183694
2022-09-28 04:37:14,105 [foster.py] => Task 0, Epoch 1/40 => Loss 1.343, Train_accy 49.09
2022-09-28 04:37:17,109 [foster.py] => Task 0, Epoch 2/40 => Loss 0.529, Train_accy 82.52, Test_accy 83.05
2022-09-28 04:37:20,074 [foster.py] => Task 0, Epoch 3/40 => Loss 0.381, Train_accy 86.92, Test_accy 88.14
2022-09-28 04:37:23,046 [foster.py] => Task 0, Epoch 4/40 => Loss 0.263, Train_accy 90.77, Test_accy 88.14
2022-09-28 04:37:26,031 [foster.py] => Task 0, Epoch 5/40 => Loss 0.236, Train_accy 91.47, Test_accy 87.57
2022-09-28 04:37:28,367 [foster.py] => Task 0, Epoch 6/40 => Loss 0.201, Train_accy 93.08
2022-09-28 04:37:31,368 [foster.py] => Task 0, Epoch 7/40 => Loss 0.157, Train_accy 94.76, Test_accy 88.14
2022-09-28 04:37:34,353 [foster.py] => Task 0, Epoch 8/40 => Loss 0.119, Train_accy 96.29, Test_accy 88.14
2022-09-28 04:37:37,375 [foster.py] => Task 0, Epoch 9/40 => Loss 0.107, Train_accy 96.43, Test_accy 89.83
2022-09-28 04:37:40,365 [foster.py] => Task 0, Epoch 10/40 => Loss 0.106, Train_accy 96.92, Test_accy 92.09
2022-09-28 04:37:42,723 [foster.py] => Task 0, Epoch 11/40 => Loss 0.077, Train_accy 98.04
2022-09-28 04:37:45,712 [foster.py] => Task 0, Epoch 12/40 => Loss 0.054, Train_accy 99.23, Test_accy 88.70
2022-09-28 04:37:48,669 [foster.py] => Task 0, Epoch 13/40 => Loss 0.066, Train_accy 98.18, Test_accy 88.70
2022-09-28 04:37:51,639 [foster.py] => Task 0, Epoch 14/40 => Loss 0.060, Train_accy 98.25, Test_accy 89.27
2022-09-28 04:37:54,675 [foster.py] => Task 0, Epoch 15/40 => Loss 0.047, Train_accy 98.74, Test_accy 88.70
2022-09-28 04:37:57,012 [foster.py] => Task 0, Epoch 16/40 => Loss 0.043, Train_accy 98.67
2022-09-28 04:37:59,997 [foster.py] => Task 0, Epoch 17/40 => Loss 0.038, Train_accy 99.09, Test_accy 89.27
2022-09-28 04:38:02,984 [foster.py] => Task 0, Epoch 18/40 => Loss 0.040, Train_accy 98.67, Test_accy 88.70
2022-09-28 04:38:05,922 [foster.py] => Task 0, Epoch 19/40 => Loss 0.036, Train_accy 99.23, Test_accy 88.70
2022-09-28 04:38:08,935 [foster.py] => Task 0, Epoch 20/40 => Loss 0.041, Train_accy 98.74, Test_accy 89.83
2022-09-28 04:38:11,290 [foster.py] => Task 0, Epoch 21/40 => Loss 0.034, Train_accy 99.30
2022-09-28 04:38:14,266 [foster.py] => Task 0, Epoch 22/40 => Loss 0.032, Train_accy 99.09, Test_accy 89.27
2022-09-28 04:38:17,305 [foster.py] => Task 0, Epoch 23/40 => Loss 0.021, Train_accy 99.72, Test_accy 91.53
2022-09-28 04:38:20,332 [foster.py] => Task 0, Epoch 24/40 => Loss 0.019, Train_accy 99.79, Test_accy 90.40
2022-09-28 04:38:23,342 [foster.py] => Task 0, Epoch 25/40 => Loss 0.021, Train_accy 99.58, Test_accy 90.96
2022-09-28 04:38:25,672 [foster.py] => Task 0, Epoch 26/40 => Loss 0.022, Train_accy 99.65
2022-09-28 04:38:28,620 [foster.py] => Task 0, Epoch 27/40 => Loss 0.023, Train_accy 99.65, Test_accy 90.40
2022-09-28 04:38:31,585 [foster.py] => Task 0, Epoch 28/40 => Loss 0.014, Train_accy 99.93, Test_accy 88.14
2022-09-28 04:38:34,602 [foster.py] => Task 0, Epoch 29/40 => Loss 0.020, Train_accy 99.30, Test_accy 89.27
2022-09-28 04:38:37,597 [foster.py] => Task 0, Epoch 30/40 => Loss 0.015, Train_accy 99.93, Test_accy 89.83
2022-09-28 04:38:39,912 [foster.py] => Task 0, Epoch 31/40 => Loss 0.014, Train_accy 99.79
2022-09-28 04:38:42,968 [foster.py] => Task 0, Epoch 32/40 => Loss 0.015, Train_accy 99.86, Test_accy 89.83
2022-09-28 04:38:45,991 [foster.py] => Task 0, Epoch 33/40 => Loss 0.013, Train_accy 99.93, Test_accy 89.83
2022-09-28 04:38:48,967 [foster.py] => Task 0, Epoch 34/40 => Loss 0.012, Train_accy 99.79, Test_accy 89.83
2022-09-28 04:38:51,971 [foster.py] => Task 0, Epoch 35/40 => Loss 0.013, Train_accy 100.00, Test_accy 88.70
2022-09-28 04:38:54,349 [foster.py] => Task 0, Epoch 36/40 => Loss 0.016, Train_accy 99.79
2022-09-28 04:38:57,309 [foster.py] => Task 0, Epoch 37/40 => Loss 0.014, Train_accy 99.86, Test_accy 88.70
2022-09-28 04:39:00,274 [foster.py] => Task 0, Epoch 38/40 => Loss 0.013, Train_accy 99.79, Test_accy 89.27
2022-09-28 04:39:03,290 [foster.py] => Task 0, Epoch 39/40 => Loss 0.012, Train_accy 99.93, Test_accy 89.27
2022-09-28 04:39:06,279 [foster.py] => Task 0, Epoch 40/40 => Loss 0.017, Train_accy 99.65, Test_accy 88.70
2022-09-28 04:39:06,280 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 04:39:13,229 [foster.py] => Exemplar size: 140
2022-09-28 04:39:13,229 [trainer.py] => CNN: {'total': 88.7, 'old': 88.7, 'new': 0, 'base': 88.7, 'compound': 0}
2022-09-28 04:39:13,229 [trainer.py] => CNN top1 curve: [88.7]
2022-09-28 04:39:13,230 [trainer.py] => CNN base curve: [88.7]
2022-09-28 04:39:13,230 [trainer.py] => CNN old curve: [88.7]
2022-09-28 04:39:13,230 [trainer.py] => CNN new curve: [0]
2022-09-28 04:39:13,230 [trainer.py] => CNN compound curve: [0]
2022-09-28 04:39:13,230 [trainer.py] => NME: {'total': 91.53, 'old': 91.53, 'new': 0, 'base': 91.53, 'compound': 0}
2022-09-28 04:39:13,230 [trainer.py] => NME top1 curve: [91.53]
2022-09-28 04:39:13,230 [trainer.py] => NME base curve: [91.53]
2022-09-28 04:39:13,230 [trainer.py] => NME old curve: [91.53]
2022-09-28 04:39:13,230 [trainer.py] => NME new curve: [0]
2022-09-28 04:39:13,230 [trainer.py] => NME compound curve: [0]
2022-09-28 04:39:13,462 [foster.py] => Learning on 7-10
2022-09-28 04:39:13,462 [foster.py] => All params: 22371995
2022-09-28 04:39:13,463 [foster.py] => Trainable params: 11191892
2022-09-28 04:39:13,483 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 04:39:15,984 [foster.py] => Task 1, Epoch 1/34 => Loss 4.675, Loss_clf 2.281, Loss_fe 1.835, Loss_kd 0.391, Train_accy 35.87, Test_accy 62.61
2022-09-28 04:39:17,765 [foster.py] => Task 1, Epoch 2/34 => Loss 2.815, Loss_clf 0.943, Loss_fe 1.298, Loss_kd 0.402, Train_accy 61.94
2022-09-28 04:39:19,541 [foster.py] => Task 1, Epoch 3/34 => Loss 2.298, Loss_clf 0.647, Loss_fe 1.119, Loss_kd 0.372, Train_accy 40.39
2022-09-28 04:39:21,287 [foster.py] => Task 1, Epoch 4/34 => Loss 2.168, Loss_clf 0.642, Loss_fe 0.994, Loss_kd 0.372, Train_accy 36.52
2022-09-28 04:39:23,070 [foster.py] => Task 1, Epoch 5/34 => Loss 2.052, Loss_clf 0.619, Loss_fe 0.912, Loss_kd 0.365, Train_accy 44.39
2022-09-28 04:39:25,545 [foster.py] => Task 1, Epoch 6/34 => Loss 1.990, Loss_clf 0.602, Loss_fe 0.866, Loss_kd 0.366, Train_accy 40.77, Test_accy 68.70
2022-09-28 04:39:27,305 [foster.py] => Task 1, Epoch 7/34 => Loss 1.889, Loss_clf 0.554, Loss_fe 0.813, Loss_kd 0.366, Train_accy 42.45
2022-09-28 04:39:29,087 [foster.py] => Task 1, Epoch 8/34 => Loss 1.843, Loss_clf 0.544, Loss_fe 0.774, Loss_kd 0.368, Train_accy 43.61
2022-09-28 04:39:30,876 [foster.py] => Task 1, Epoch 9/34 => Loss 1.804, Loss_clf 0.536, Loss_fe 0.750, Loss_kd 0.362, Train_accy 40.13
2022-09-28 04:39:32,613 [foster.py] => Task 1, Epoch 10/34 => Loss 1.815, Loss_clf 0.538, Loss_fe 0.755, Loss_kd 0.365, Train_accy 42.45
2022-09-28 04:39:35,160 [foster.py] => Task 1, Epoch 11/34 => Loss 1.759, Loss_clf 0.517, Loss_fe 0.705, Loss_kd 0.376, Train_accy 43.23, Test_accy 67.83
2022-09-28 04:39:36,909 [foster.py] => Task 1, Epoch 12/34 => Loss 1.775, Loss_clf 0.538, Loss_fe 0.715, Loss_kd 0.366, Train_accy 42.97
2022-09-28 04:39:38,695 [foster.py] => Task 1, Epoch 13/34 => Loss 1.739, Loss_clf 0.532, Loss_fe 0.692, Loss_kd 0.361, Train_accy 43.10
2022-09-28 04:39:40,482 [foster.py] => Task 1, Epoch 14/34 => Loss 1.705, Loss_clf 0.519, Loss_fe 0.674, Loss_kd 0.359, Train_accy 42.84
2022-09-28 04:39:42,278 [foster.py] => Task 1, Epoch 15/34 => Loss 1.720, Loss_clf 0.534, Loss_fe 0.673, Loss_kd 0.359, Train_accy 43.87
2022-09-28 04:39:44,803 [foster.py] => Task 1, Epoch 16/34 => Loss 1.660, Loss_clf 0.502, Loss_fe 0.646, Loss_kd 0.358, Train_accy 44.13, Test_accy 68.70
2022-09-28 04:39:46,552 [foster.py] => Task 1, Epoch 17/34 => Loss 1.669, Loss_clf 0.492, Loss_fe 0.652, Loss_kd 0.368, Train_accy 43.35
2022-09-28 04:39:48,295 [foster.py] => Task 1, Epoch 18/34 => Loss 1.608, Loss_clf 0.468, Loss_fe 0.620, Loss_kd 0.364, Train_accy 44.52
2022-09-28 04:39:50,136 [foster.py] => Task 1, Epoch 19/34 => Loss 1.610, Loss_clf 0.466, Loss_fe 0.611, Loss_kd 0.372, Train_accy 42.58
2022-09-28 04:39:51,900 [foster.py] => Task 1, Epoch 20/34 => Loss 1.560, Loss_clf 0.455, Loss_fe 0.594, Loss_kd 0.358, Train_accy 43.48
2022-09-28 04:39:54,395 [foster.py] => Task 1, Epoch 21/34 => Loss 1.552, Loss_clf 0.449, Loss_fe 0.582, Loss_kd 0.364, Train_accy 46.19, Test_accy 69.57
2022-09-28 04:39:56,150 [foster.py] => Task 1, Epoch 22/34 => Loss 1.639, Loss_clf 0.489, Loss_fe 0.627, Loss_kd 0.367, Train_accy 46.45
2022-09-28 04:39:57,969 [foster.py] => Task 1, Epoch 23/34 => Loss 1.566, Loss_clf 0.453, Loss_fe 0.589, Loss_kd 0.367, Train_accy 47.10
2022-09-28 04:39:59,749 [foster.py] => Task 1, Epoch 24/34 => Loss 1.550, Loss_clf 0.444, Loss_fe 0.577, Loss_kd 0.370, Train_accy 46.06
2022-09-28 04:40:01,531 [foster.py] => Task 1, Epoch 25/34 => Loss 1.506, Loss_clf 0.419, Loss_fe 0.569, Loss_kd 0.363, Train_accy 45.68
2022-09-28 04:40:04,009 [foster.py] => Task 1, Epoch 26/34 => Loss 1.515, Loss_clf 0.426, Loss_fe 0.573, Loss_kd 0.361, Train_accy 47.48, Test_accy 69.57
2022-09-28 04:40:05,791 [foster.py] => Task 1, Epoch 27/34 => Loss 1.541, Loss_clf 0.441, Loss_fe 0.576, Loss_kd 0.367, Train_accy 45.81
2022-09-28 04:40:07,528 [foster.py] => Task 1, Epoch 28/34 => Loss 1.515, Loss_clf 0.424, Loss_fe 0.576, Loss_kd 0.360, Train_accy 44.65
2022-09-28 04:40:09,342 [foster.py] => Task 1, Epoch 29/34 => Loss 1.529, Loss_clf 0.432, Loss_fe 0.575, Loss_kd 0.365, Train_accy 46.97
2022-09-28 04:40:11,105 [foster.py] => Task 1, Epoch 30/34 => Loss 1.492, Loss_clf 0.425, Loss_fe 0.556, Loss_kd 0.357, Train_accy 45.29
2022-09-28 04:40:13,670 [foster.py] => Task 1, Epoch 31/34 => Loss 1.541, Loss_clf 0.436, Loss_fe 0.588, Loss_kd 0.362, Train_accy 46.71, Test_accy 69.13
2022-09-28 04:40:15,453 [foster.py] => Task 1, Epoch 32/34 => Loss 1.467, Loss_clf 0.407, Loss_fe 0.541, Loss_kd 0.364, Train_accy 47.35
2022-09-28 04:40:17,221 [foster.py] => Task 1, Epoch 33/34 => Loss 1.512, Loss_clf 0.428, Loss_fe 0.574, Loss_kd 0.356, Train_accy 46.97
2022-09-28 04:40:18,993 [foster.py] => Task 1, Epoch 34/34 => Loss 1.551, Loss_clf 0.445, Loss_fe 0.577, Loss_kd 0.371, Train_accy 47.10
2022-09-28 04:40:18,993 [foster.py] => do not weight align teacher!
2022-09-28 04:40:18,994 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 04:40:21,879 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.554,  Train_accy 17.29, Test_accy 66.52
2022-09-28 04:40:23,853 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.386,  Train_accy 17.68
2022-09-28 04:40:25,808 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.286,  Train_accy 18.45
2022-09-28 04:40:27,786 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.251,  Train_accy 18.84
2022-09-28 04:40:29,742 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.247,  Train_accy 19.23
2022-09-28 04:40:32,403 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.206,  Train_accy 20.13, Test_accy 68.26
2022-09-28 04:40:34,346 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.234,  Train_accy 20.39
2022-09-28 04:40:36,293 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.191,  Train_accy 21.68
2022-09-28 04:40:38,259 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.218,  Train_accy 22.84
2022-09-28 04:40:40,203 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.182,  Train_accy 21.94
2022-09-28 04:40:42,884 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.191,  Train_accy 22.32, Test_accy 70.43
2022-09-28 04:40:44,868 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.179,  Train_accy 22.58
2022-09-28 04:40:46,805 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.171,  Train_accy 21.81
2022-09-28 04:40:48,790 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.169,  Train_accy 23.48
2022-09-28 04:40:50,759 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.166,  Train_accy 22.71
2022-09-28 04:40:53,423 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.176,  Train_accy 23.10, Test_accy 69.57
2022-09-28 04:40:55,445 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.165,  Train_accy 22.84
2022-09-28 04:40:57,380 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.178,  Train_accy 24.00
2022-09-28 04:40:59,354 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.174,  Train_accy 23.48
2022-09-28 04:41:01,284 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.184,  Train_accy 24.13
2022-09-28 04:41:04,008 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.194,  Train_accy 23.48, Test_accy 69.57
2022-09-28 04:41:05,988 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.180,  Train_accy 23.87
2022-09-28 04:41:08,000 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.171,  Train_accy 23.48
2022-09-28 04:41:09,934 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.167,  Train_accy 23.87
2022-09-28 04:41:11,915 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.156,  Train_accy 24.26
2022-09-28 04:41:14,526 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.167,  Train_accy 23.10, Test_accy 70.00
2022-09-28 04:41:14,527 [foster.py] => do not weight align student!
2022-09-28 04:41:15,210 [foster.py] => darknet eval: 
2022-09-28 04:41:15,210 [foster.py] => CNN top1 curve: 70.0
2022-09-28 04:41:15,210 [foster.py] => CNN top5 curve: 98.26
2022-09-28 04:41:15,210 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 04:41:21,567 [foster.py] => Exemplar size: 200
2022-09-28 04:41:21,567 [trainer.py] => CNN: {'total': 70.43, 'old': 84.18, 'new': 24.53, 'base': 84.18, 'compound': 24.53}
2022-09-28 04:41:21,567 [trainer.py] => CNN top1 curve: [88.7, 70.43]
2022-09-28 04:41:21,567 [trainer.py] => CNN base curve: [88.7, 84.18]
2022-09-28 04:41:21,567 [trainer.py] => CNN old curve: [88.7, 84.18]
2022-09-28 04:41:21,567 [trainer.py] => CNN new curve: [0, 24.53]
2022-09-28 04:41:21,567 [trainer.py] => CNN compound curve: [0, 24.53]
2022-09-28 04:41:21,567 [trainer.py] => NME: {'total': 75.22, 'old': 82.49, 'new': 50.94, 'base': 82.49, 'compound': 50.94}
2022-09-28 04:41:21,567 [trainer.py] => NME top1 curve: [91.53, 75.22]
2022-09-28 04:41:21,567 [trainer.py] => NME base curve: [91.53, 82.49]
2022-09-28 04:41:21,567 [trainer.py] => NME old curve: [91.53, 82.49]
2022-09-28 04:41:21,567 [trainer.py] => NME new curve: [0, 50.94]
2022-09-28 04:41:21,567 [trainer.py] => NME compound curve: [0, 50.94]
2022-09-28 04:41:21,802 [foster.py] => Learning on 10-13
2022-09-28 04:41:21,803 [foster.py] => All params: 22378148
2022-09-28 04:41:21,803 [foster.py] => Trainable params: 11196506
2022-09-28 04:41:21,823 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 04:41:24,431 [foster.py] => Task 2, Epoch 1/34 => Loss 5.056, Loss_clf 1.852, Loss_fe 2.036, Loss_kd 0.899, Train_accy 37.21, Test_accy 56.33
2022-09-28 04:41:26,296 [foster.py] => Task 2, Epoch 2/34 => Loss 3.551, Loss_clf 0.907, Loss_fe 1.508, Loss_kd 0.873, Train_accy 41.37
2022-09-28 04:41:28,152 [foster.py] => Task 2, Epoch 3/34 => Loss 3.217, Loss_clf 0.762, Loss_fe 1.327, Loss_kd 0.868, Train_accy 42.96
2022-09-28 04:41:29,945 [foster.py] => Task 2, Epoch 4/34 => Loss 3.055, Loss_clf 0.731, Loss_fe 1.203, Loss_kd 0.863, Train_accy 41.00
2022-09-28 04:41:31,797 [foster.py] => Task 2, Epoch 5/34 => Loss 2.938, Loss_clf 0.709, Loss_fe 1.109, Loss_kd 0.861, Train_accy 38.43
2022-09-28 04:41:34,464 [foster.py] => Task 2, Epoch 6/34 => Loss 2.855, Loss_clf 0.693, Loss_fe 1.035, Loss_kd 0.867, Train_accy 41.74, Test_accy 55.67
2022-09-28 04:41:36,333 [foster.py] => Task 2, Epoch 7/34 => Loss 2.827, Loss_clf 0.685, Loss_fe 1.014, Loss_kd 0.868, Train_accy 40.51
2022-09-28 04:41:38,155 [foster.py] => Task 2, Epoch 8/34 => Loss 2.697, Loss_clf 0.655, Loss_fe 0.932, Loss_kd 0.853, Train_accy 40.64
2022-09-28 04:41:39,991 [foster.py] => Task 2, Epoch 9/34 => Loss 2.647, Loss_clf 0.644, Loss_fe 0.881, Loss_kd 0.864, Train_accy 43.33
2022-09-28 04:41:41,837 [foster.py] => Task 2, Epoch 10/34 => Loss 2.602, Loss_clf 0.626, Loss_fe 0.856, Loss_kd 0.862, Train_accy 38.56
2022-09-28 04:41:44,510 [foster.py] => Task 2, Epoch 11/34 => Loss 2.577, Loss_clf 0.605, Loss_fe 0.848, Loss_kd 0.864, Train_accy 41.00, Test_accy 58.00
2022-09-28 04:41:46,354 [foster.py] => Task 2, Epoch 12/34 => Loss 2.553, Loss_clf 0.606, Loss_fe 0.826, Loss_kd 0.862, Train_accy 40.76
2022-09-28 04:41:48,159 [foster.py] => Task 2, Epoch 13/34 => Loss 2.504, Loss_clf 0.599, Loss_fe 0.785, Loss_kd 0.862, Train_accy 40.15
2022-09-28 04:41:49,971 [foster.py] => Task 2, Epoch 14/34 => Loss 2.457, Loss_clf 0.575, Loss_fe 0.753, Loss_kd 0.869, Train_accy 43.33
2022-09-28 04:41:51,756 [foster.py] => Task 2, Epoch 15/34 => Loss 2.411, Loss_clf 0.566, Loss_fe 0.728, Loss_kd 0.859, Train_accy 44.31
2022-09-28 04:41:54,367 [foster.py] => Task 2, Epoch 16/34 => Loss 2.406, Loss_clf 0.563, Loss_fe 0.722, Loss_kd 0.863, Train_accy 43.45, Test_accy 59.00
2022-09-28 04:41:56,203 [foster.py] => Task 2, Epoch 17/34 => Loss 2.405, Loss_clf 0.555, Loss_fe 0.720, Loss_kd 0.869, Train_accy 43.70
2022-09-28 04:41:58,026 [foster.py] => Task 2, Epoch 18/34 => Loss 2.355, Loss_clf 0.542, Loss_fe 0.691, Loss_kd 0.863, Train_accy 43.94
2022-09-28 04:41:59,836 [foster.py] => Task 2, Epoch 19/34 => Loss 2.384, Loss_clf 0.557, Loss_fe 0.704, Loss_kd 0.864, Train_accy 43.45
2022-09-28 04:42:01,678 [foster.py] => Task 2, Epoch 20/34 => Loss 2.321, Loss_clf 0.529, Loss_fe 0.676, Loss_kd 0.858, Train_accy 45.29
2022-09-28 04:42:04,296 [foster.py] => Task 2, Epoch 21/34 => Loss 2.344, Loss_clf 0.539, Loss_fe 0.680, Loss_kd 0.865, Train_accy 43.70, Test_accy 58.67
2022-09-28 04:42:06,160 [foster.py] => Task 2, Epoch 22/34 => Loss 2.336, Loss_clf 0.538, Loss_fe 0.678, Loss_kd 0.862, Train_accy 43.08
2022-09-28 04:42:08,004 [foster.py] => Task 2, Epoch 23/34 => Loss 2.332, Loss_clf 0.526, Loss_fe 0.666, Loss_kd 0.877, Train_accy 46.02
2022-09-28 04:42:09,809 [foster.py] => Task 2, Epoch 24/34 => Loss 2.301, Loss_clf 0.522, Loss_fe 0.663, Loss_kd 0.859, Train_accy 44.31
2022-09-28 04:42:11,663 [foster.py] => Task 2, Epoch 25/34 => Loss 2.285, Loss_clf 0.512, Loss_fe 0.642, Loss_kd 0.869, Train_accy 44.55
2022-09-28 04:42:14,321 [foster.py] => Task 2, Epoch 26/34 => Loss 2.279, Loss_clf 0.503, Loss_fe 0.644, Loss_kd 0.871, Train_accy 46.88, Test_accy 58.00
2022-09-28 04:42:16,125 [foster.py] => Task 2, Epoch 27/34 => Loss 2.271, Loss_clf 0.515, Loss_fe 0.634, Loss_kd 0.863, Train_accy 43.70
2022-09-28 04:42:17,918 [foster.py] => Task 2, Epoch 28/34 => Loss 2.263, Loss_clf 0.507, Loss_fe 0.637, Loss_kd 0.860, Train_accy 44.68
2022-09-28 04:42:19,718 [foster.py] => Task 2, Epoch 29/34 => Loss 2.255, Loss_clf 0.504, Loss_fe 0.629, Loss_kd 0.863, Train_accy 43.94
2022-09-28 04:42:21,567 [foster.py] => Task 2, Epoch 30/34 => Loss 2.279, Loss_clf 0.522, Loss_fe 0.634, Loss_kd 0.864, Train_accy 43.82
2022-09-28 04:42:24,212 [foster.py] => Task 2, Epoch 31/34 => Loss 2.250, Loss_clf 0.499, Loss_fe 0.630, Loss_kd 0.863, Train_accy 44.68, Test_accy 58.00
2022-09-28 04:42:26,015 [foster.py] => Task 2, Epoch 32/34 => Loss 2.284, Loss_clf 0.513, Loss_fe 0.642, Loss_kd 0.868, Train_accy 44.92
2022-09-28 04:42:27,815 [foster.py] => Task 2, Epoch 33/34 => Loss 2.260, Loss_clf 0.510, Loss_fe 0.636, Loss_kd 0.857, Train_accy 44.68
2022-09-28 04:42:29,623 [foster.py] => Task 2, Epoch 34/34 => Loss 2.264, Loss_clf 0.509, Loss_fe 0.629, Loss_kd 0.866, Train_accy 44.92
2022-09-28 04:42:29,623 [foster.py] => do not weight align teacher!
2022-09-28 04:42:29,623 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 04:42:32,640 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.833,  Train_accy 17.26, Test_accy 52.33
2022-09-28 04:42:34,654 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.697,  Train_accy 17.75
2022-09-28 04:42:36,672 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.655,  Train_accy 17.75
2022-09-28 04:42:38,707 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.631,  Train_accy 17.63
2022-09-28 04:42:40,709 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.612,  Train_accy 18.36
2022-09-28 04:42:43,463 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.600,  Train_accy 18.48, Test_accy 54.00
2022-09-28 04:42:45,470 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.593,  Train_accy 18.85
2022-09-28 04:42:47,520 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.582,  Train_accy 18.97
2022-09-28 04:42:49,550 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.584,  Train_accy 19.71
2022-09-28 04:42:51,541 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.572,  Train_accy 18.48
2022-09-28 04:42:54,375 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.583,  Train_accy 18.48, Test_accy 54.33
2022-09-28 04:42:56,409 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.572,  Train_accy 19.58
2022-09-28 04:42:58,463 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.576,  Train_accy 19.34
2022-09-28 04:43:00,478 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.568,  Train_accy 19.22
2022-09-28 04:43:02,514 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.584,  Train_accy 19.46
2022-09-28 04:43:05,315 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.582,  Train_accy 19.83, Test_accy 53.33
2022-09-28 04:43:07,356 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.565,  Train_accy 18.97
2022-09-28 04:43:09,407 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.560,  Train_accy 20.20
2022-09-28 04:43:11,430 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.567,  Train_accy 19.22
2022-09-28 04:43:13,425 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.563,  Train_accy 20.07
2022-09-28 04:43:16,162 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.565,  Train_accy 18.73, Test_accy 54.33
2022-09-28 04:43:18,198 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.574,  Train_accy 20.32
2022-09-28 04:43:20,250 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.553,  Train_accy 19.83
2022-09-28 04:43:22,273 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.567,  Train_accy 19.58
2022-09-28 04:43:24,359 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.574,  Train_accy 20.07
2022-09-28 04:43:27,115 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.562,  Train_accy 19.46, Test_accy 53.00
2022-09-28 04:43:27,116 [foster.py] => do not weight align student!
2022-09-28 04:43:27,829 [foster.py] => darknet eval: 
2022-09-28 04:43:27,829 [foster.py] => CNN top1 curve: 53.0
2022-09-28 04:43:27,829 [foster.py] => CNN top5 curve: 95.67
2022-09-28 04:43:27,830 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 04:43:35,215 [foster.py] => Exemplar size: 260
2022-09-28 04:43:35,215 [trainer.py] => CNN: {'total': 58.0, 'old': 66.96, 'new': 28.57, 'base': 81.92, 'compound': 23.58}
2022-09-28 04:43:35,215 [trainer.py] => CNN top1 curve: [88.7, 70.43, 58.0]
2022-09-28 04:43:35,215 [trainer.py] => CNN base curve: [88.7, 84.18, 81.92]
2022-09-28 04:43:35,215 [trainer.py] => CNN old curve: [88.7, 84.18, 66.96]
2022-09-28 04:43:35,215 [trainer.py] => CNN new curve: [0, 24.53, 28.57]
2022-09-28 04:43:35,215 [trainer.py] => CNN compound curve: [0, 24.53, 23.58]
2022-09-28 04:43:35,215 [trainer.py] => NME: {'total': 64.33, 'old': 71.3, 'new': 41.43, 'base': 77.97, 'compound': 44.72}
2022-09-28 04:43:35,215 [trainer.py] => NME top1 curve: [91.53, 75.22, 64.33]
2022-09-28 04:43:35,215 [trainer.py] => NME base curve: [91.53, 82.49, 77.97]
2022-09-28 04:43:35,215 [trainer.py] => NME old curve: [91.53, 82.49, 71.3]
2022-09-28 04:43:35,215 [trainer.py] => NME new curve: [0, 50.94, 41.43]
2022-09-28 04:43:35,215 [trainer.py] => NME compound curve: [0, 50.94, 44.72]
2022-09-28 04:43:35,449 [foster.py] => Learning on 13-16
2022-09-28 04:43:35,449 [foster.py] => All params: 22384301
2022-09-28 04:43:35,450 [foster.py] => Trainable params: 11201120
2022-09-28 04:43:35,470 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 04:43:38,266 [foster.py] => Task 3, Epoch 1/34 => Loss 5.889, Loss_clf 2.020, Loss_fe 2.248, Loss_kd 1.318, Train_accy 44.04, Test_accy 47.73
2022-09-28 04:43:40,178 [foster.py] => Task 3, Epoch 2/34 => Loss 3.987, Loss_clf 0.881, Loss_fe 1.505, Loss_kd 1.301, Train_accy 45.53
2022-09-28 04:43:42,058 [foster.py] => Task 3, Epoch 3/34 => Loss 3.650, Loss_clf 0.740, Loss_fe 1.300, Loss_kd 1.308, Train_accy 47.36
2022-09-28 04:43:44,027 [foster.py] => Task 3, Epoch 4/34 => Loss 3.438, Loss_clf 0.660, Loss_fe 1.163, Loss_kd 1.312, Train_accy 44.38
2022-09-28 04:43:45,914 [foster.py] => Task 3, Epoch 5/34 => Loss 3.339, Loss_clf 0.652, Loss_fe 1.086, Loss_kd 1.301, Train_accy 47.13
2022-09-28 04:43:48,715 [foster.py] => Task 3, Epoch 6/34 => Loss 3.222, Loss_clf 0.622, Loss_fe 1.001, Loss_kd 1.299, Train_accy 47.25, Test_accy 49.60
2022-09-28 04:43:50,628 [foster.py] => Task 3, Epoch 7/34 => Loss 3.163, Loss_clf 0.607, Loss_fe 0.952, Loss_kd 1.303, Train_accy 49.31
2022-09-28 04:43:52,537 [foster.py] => Task 3, Epoch 8/34 => Loss 3.114, Loss_clf 0.606, Loss_fe 0.904, Loss_kd 1.304, Train_accy 49.43
2022-09-28 04:43:54,426 [foster.py] => Task 3, Epoch 9/34 => Loss 3.022, Loss_clf 0.563, Loss_fe 0.861, Loss_kd 1.299, Train_accy 54.24
2022-09-28 04:43:56,300 [foster.py] => Task 3, Epoch 10/34 => Loss 3.010, Loss_clf 0.567, Loss_fe 0.833, Loss_kd 1.308, Train_accy 47.48
2022-09-28 04:43:59,075 [foster.py] => Task 3, Epoch 11/34 => Loss 2.954, Loss_clf 0.546, Loss_fe 0.802, Loss_kd 1.305, Train_accy 49.66, Test_accy 50.93
2022-09-28 04:44:00,962 [foster.py] => Task 3, Epoch 12/34 => Loss 2.898, Loss_clf 0.530, Loss_fe 0.763, Loss_kd 1.304, Train_accy 52.98
2022-09-28 04:44:02,871 [foster.py] => Task 3, Epoch 13/34 => Loss 2.899, Loss_clf 0.537, Loss_fe 0.756, Loss_kd 1.304, Train_accy 52.29
2022-09-28 04:44:04,770 [foster.py] => Task 3, Epoch 14/34 => Loss 2.810, Loss_clf 0.499, Loss_fe 0.712, Loss_kd 1.299, Train_accy 52.29
2022-09-28 04:44:06,671 [foster.py] => Task 3, Epoch 15/34 => Loss 2.819, Loss_clf 0.520, Loss_fe 0.697, Loss_kd 1.301, Train_accy 51.03
2022-09-28 04:44:09,463 [foster.py] => Task 3, Epoch 16/34 => Loss 2.785, Loss_clf 0.497, Loss_fe 0.686, Loss_kd 1.302, Train_accy 52.98, Test_accy 52.00
2022-09-28 04:44:11,378 [foster.py] => Task 3, Epoch 17/34 => Loss 2.730, Loss_clf 0.488, Loss_fe 0.659, Loss_kd 1.286, Train_accy 52.75
2022-09-28 04:44:13,252 [foster.py] => Task 3, Epoch 18/34 => Loss 2.770, Loss_clf 0.487, Loss_fe 0.660, Loss_kd 1.319, Train_accy 52.75
2022-09-28 04:44:15,137 [foster.py] => Task 3, Epoch 19/34 => Loss 2.746, Loss_clf 0.500, Loss_fe 0.656, Loss_kd 1.292, Train_accy 53.67
2022-09-28 04:44:17,027 [foster.py] => Task 3, Epoch 20/34 => Loss 2.719, Loss_clf 0.474, Loss_fe 0.634, Loss_kd 1.309, Train_accy 52.98
2022-09-28 04:44:19,795 [foster.py] => Task 3, Epoch 21/34 => Loss 2.716, Loss_clf 0.473, Loss_fe 0.644, Loss_kd 1.300, Train_accy 54.47, Test_accy 52.00
2022-09-28 04:44:21,728 [foster.py] => Task 3, Epoch 22/34 => Loss 2.683, Loss_clf 0.467, Loss_fe 0.618, Loss_kd 1.298, Train_accy 54.93
2022-09-28 04:44:23,653 [foster.py] => Task 3, Epoch 23/34 => Loss 2.696, Loss_clf 0.476, Loss_fe 0.607, Loss_kd 1.311, Train_accy 54.24
2022-09-28 04:44:25,582 [foster.py] => Task 3, Epoch 24/34 => Loss 2.748, Loss_clf 0.493, Loss_fe 0.648, Loss_kd 1.306, Train_accy 55.50
2022-09-28 04:44:27,500 [foster.py] => Task 3, Epoch 25/34 => Loss 2.661, Loss_clf 0.463, Loss_fe 0.599, Loss_kd 1.299, Train_accy 55.73
2022-09-28 04:44:30,271 [foster.py] => Task 3, Epoch 26/34 => Loss 2.680, Loss_clf 0.456, Loss_fe 0.616, Loss_kd 1.307, Train_accy 54.82, Test_accy 52.80
2022-09-28 04:44:32,164 [foster.py] => Task 3, Epoch 27/34 => Loss 2.711, Loss_clf 0.485, Loss_fe 0.615, Loss_kd 1.309, Train_accy 56.19
2022-09-28 04:44:34,053 [foster.py] => Task 3, Epoch 28/34 => Loss 2.746, Loss_clf 0.505, Loss_fe 0.632, Loss_kd 1.307, Train_accy 53.67
2022-09-28 04:44:35,945 [foster.py] => Task 3, Epoch 29/34 => Loss 2.657, Loss_clf 0.456, Loss_fe 0.595, Loss_kd 1.305, Train_accy 55.39
2022-09-28 04:44:37,865 [foster.py] => Task 3, Epoch 30/34 => Loss 2.737, Loss_clf 0.503, Loss_fe 0.632, Loss_kd 1.302, Train_accy 54.47
2022-09-28 04:44:40,668 [foster.py] => Task 3, Epoch 31/34 => Loss 2.622, Loss_clf 0.437, Loss_fe 0.593, Loss_kd 1.293, Train_accy 54.59, Test_accy 52.27
2022-09-28 04:44:42,600 [foster.py] => Task 3, Epoch 32/34 => Loss 2.686, Loss_clf 0.469, Loss_fe 0.595, Loss_kd 1.318, Train_accy 54.93
2022-09-28 04:44:44,472 [foster.py] => Task 3, Epoch 33/34 => Loss 2.632, Loss_clf 0.438, Loss_fe 0.582, Loss_kd 1.309, Train_accy 55.85
2022-09-28 04:44:46,377 [foster.py] => Task 3, Epoch 34/34 => Loss 2.695, Loss_clf 0.467, Loss_fe 0.623, Loss_kd 1.304, Train_accy 55.16
2022-09-28 04:44:46,378 [foster.py] => do not weight align teacher!
2022-09-28 04:44:46,378 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 04:44:49,539 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.130,  Train_accy 16.97, Test_accy 42.67
2022-09-28 04:44:51,719 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.041,  Train_accy 17.55
2022-09-28 04:44:53,820 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.013,  Train_accy 17.55
2022-09-28 04:44:55,946 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 1.979,  Train_accy 17.32
2022-09-28 04:44:58,153 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.971,  Train_accy 18.46
2022-09-28 04:45:01,052 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.953,  Train_accy 17.89, Test_accy 41.33
2022-09-28 04:45:03,197 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.944,  Train_accy 18.46
2022-09-28 04:45:05,379 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.958,  Train_accy 18.12
2022-09-28 04:45:07,518 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.934,  Train_accy 18.92
2022-09-28 04:45:09,627 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.934,  Train_accy 19.04
2022-09-28 04:45:12,488 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.944,  Train_accy 19.04, Test_accy 42.67
2022-09-28 04:45:14,622 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.929,  Train_accy 19.61
2022-09-28 04:45:16,767 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.923,  Train_accy 19.61
2022-09-28 04:45:18,859 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.940,  Train_accy 20.76
2022-09-28 04:45:20,955 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.913,  Train_accy 20.41
2022-09-28 04:45:23,808 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.911,  Train_accy 20.41, Test_accy 42.13
2022-09-28 04:45:25,962 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.935,  Train_accy 20.64
2022-09-28 04:45:28,069 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.915,  Train_accy 21.33
2022-09-28 04:45:30,230 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.935,  Train_accy 21.22
2022-09-28 04:45:32,385 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.913,  Train_accy 20.41
2022-09-28 04:45:35,336 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.911,  Train_accy 21.79, Test_accy 41.87
2022-09-28 04:45:37,456 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.923,  Train_accy 20.76
2022-09-28 04:45:39,573 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.915,  Train_accy 21.33
2022-09-28 04:45:41,680 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.915,  Train_accy 21.56
2022-09-28 04:45:43,783 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.915,  Train_accy 20.99
2022-09-28 04:45:46,716 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.913,  Train_accy 21.79, Test_accy 41.60
2022-09-28 04:45:46,716 [foster.py] => do not weight align student!
2022-09-28 04:45:47,490 [foster.py] => darknet eval: 
2022-09-28 04:45:47,490 [foster.py] => CNN top1 curve: 41.6
2022-09-28 04:45:47,491 [foster.py] => CNN top5 curve: 92.8
2022-09-28 04:45:47,491 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 04:45:56,011 [foster.py] => Exemplar size: 320
2022-09-28 04:45:56,012 [trainer.py] => CNN: {'total': 52.8, 'old': 55.33, 'new': 42.67, 'base': 76.84, 'compound': 31.31}
2022-09-28 04:45:56,012 [trainer.py] => CNN top1 curve: [88.7, 70.43, 58.0, 52.8]
2022-09-28 04:45:56,012 [trainer.py] => CNN base curve: [88.7, 84.18, 81.92, 76.84]
2022-09-28 04:45:56,012 [trainer.py] => CNN old curve: [88.7, 84.18, 66.96, 55.33]
2022-09-28 04:45:56,012 [trainer.py] => CNN new curve: [0, 24.53, 28.57, 42.67]
2022-09-28 04:45:56,012 [trainer.py] => CNN compound curve: [0, 24.53, 23.58, 31.31]
2022-09-28 04:45:56,012 [trainer.py] => NME: {'total': 61.33, 'old': 60.0, 'new': 66.67, 'base': 75.14, 'compound': 48.99}
2022-09-28 04:45:56,012 [trainer.py] => NME top1 curve: [91.53, 75.22, 64.33, 61.33]
2022-09-28 04:45:56,012 [trainer.py] => NME base curve: [91.53, 82.49, 77.97, 75.14]
2022-09-28 04:45:56,012 [trainer.py] => NME old curve: [91.53, 82.49, 71.3, 60.0]
2022-09-28 04:45:56,012 [trainer.py] => NME new curve: [0, 50.94, 41.43, 66.67]
2022-09-28 04:45:56,012 [trainer.py] => NME compound curve: [0, 50.94, 44.72, 48.99]
2022-09-28 04:45:56,243 [foster.py] => Learning on 16-19
2022-09-28 04:45:56,243 [foster.py] => All params: 22390454
2022-09-28 04:45:56,244 [foster.py] => Trainable params: 11205734
2022-09-28 04:45:56,264 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 04:45:59,240 [foster.py] => Task 4, Epoch 1/34 => Loss 6.540, Loss_clf 1.851, Loss_fe 2.652, Loss_kd 1.716, Train_accy 42.71, Test_accy 44.82
2022-09-28 04:46:01,273 [foster.py] => Task 4, Epoch 2/34 => Loss 4.782, Loss_clf 0.936, Loss_fe 1.807, Loss_kd 1.717, Train_accy 49.31
2022-09-28 04:46:03,307 [foster.py] => Task 4, Epoch 3/34 => Loss 4.426, Loss_clf 0.847, Loss_fe 1.547, Loss_kd 1.711, Train_accy 53.46
2022-09-28 04:46:05,295 [foster.py] => Task 4, Epoch 4/34 => Loss 4.261, Loss_clf 0.798, Loss_fe 1.418, Loss_kd 1.722, Train_accy 53.67
2022-09-28 04:46:07,310 [foster.py] => Task 4, Epoch 5/34 => Loss 4.097, Loss_clf 0.771, Loss_fe 1.284, Loss_kd 1.719, Train_accy 52.72
2022-09-28 04:46:10,252 [foster.py] => Task 4, Epoch 6/34 => Loss 3.991, Loss_clf 0.742, Loss_fe 1.197, Loss_kd 1.728, Train_accy 53.46, Test_accy 54.95
2022-09-28 04:46:12,259 [foster.py] => Task 4, Epoch 7/34 => Loss 3.895, Loss_clf 0.716, Loss_fe 1.125, Loss_kd 1.730, Train_accy 56.44
2022-09-28 04:46:14,277 [foster.py] => Task 4, Epoch 8/34 => Loss 3.803, Loss_clf 0.700, Loss_fe 1.059, Loss_kd 1.722, Train_accy 55.48
2022-09-28 04:46:16,304 [foster.py] => Task 4, Epoch 9/34 => Loss 3.777, Loss_clf 0.707, Loss_fe 1.031, Loss_kd 1.717, Train_accy 55.38
2022-09-28 04:46:18,309 [foster.py] => Task 4, Epoch 10/34 => Loss 3.730, Loss_clf 0.698, Loss_fe 0.997, Loss_kd 1.713, Train_accy 55.80
2022-09-28 04:46:21,307 [foster.py] => Task 4, Epoch 11/34 => Loss 3.668, Loss_clf 0.670, Loss_fe 0.954, Loss_kd 1.722, Train_accy 57.19, Test_accy 55.86
2022-09-28 04:46:23,307 [foster.py] => Task 4, Epoch 12/34 => Loss 3.625, Loss_clf 0.669, Loss_fe 0.917, Loss_kd 1.718, Train_accy 55.91
2022-09-28 04:46:25,325 [foster.py] => Task 4, Epoch 13/34 => Loss 3.593, Loss_clf 0.659, Loss_fe 0.890, Loss_kd 1.721, Train_accy 58.15
2022-09-28 04:46:27,346 [foster.py] => Task 4, Epoch 14/34 => Loss 3.499, Loss_clf 0.610, Loss_fe 0.842, Loss_kd 1.723, Train_accy 56.55
2022-09-28 04:46:29,337 [foster.py] => Task 4, Epoch 15/34 => Loss 3.469, Loss_clf 0.612, Loss_fe 0.813, Loss_kd 1.721, Train_accy 59.00
2022-09-28 04:46:32,271 [foster.py] => Task 4, Epoch 16/34 => Loss 3.505, Loss_clf 0.620, Loss_fe 0.827, Loss_kd 1.732, Train_accy 59.64, Test_accy 56.31
2022-09-28 04:46:34,283 [foster.py] => Task 4, Epoch 17/34 => Loss 3.410, Loss_clf 0.589, Loss_fe 0.774, Loss_kd 1.725, Train_accy 58.04
2022-09-28 04:46:36,334 [foster.py] => Task 4, Epoch 18/34 => Loss 3.443, Loss_clf 0.608, Loss_fe 0.783, Loss_kd 1.728, Train_accy 59.74
2022-09-28 04:46:38,351 [foster.py] => Task 4, Epoch 19/34 => Loss 3.397, Loss_clf 0.581, Loss_fe 0.755, Loss_kd 1.735, Train_accy 60.60
2022-09-28 04:46:40,331 [foster.py] => Task 4, Epoch 20/34 => Loss 3.388, Loss_clf 0.580, Loss_fe 0.749, Loss_kd 1.734, Train_accy 60.92
2022-09-28 04:46:43,270 [foster.py] => Task 4, Epoch 21/34 => Loss 3.387, Loss_clf 0.591, Loss_fe 0.748, Loss_kd 1.725, Train_accy 58.57, Test_accy 56.31
2022-09-28 04:46:45,249 [foster.py] => Task 4, Epoch 22/34 => Loss 3.354, Loss_clf 0.564, Loss_fe 0.748, Loss_kd 1.720, Train_accy 59.11
2022-09-28 04:46:47,242 [foster.py] => Task 4, Epoch 23/34 => Loss 3.356, Loss_clf 0.583, Loss_fe 0.719, Loss_kd 1.729, Train_accy 59.32
2022-09-28 04:46:49,237 [foster.py] => Task 4, Epoch 24/34 => Loss 3.325, Loss_clf 0.559, Loss_fe 0.716, Loss_kd 1.727, Train_accy 60.81
2022-09-28 04:46:51,210 [foster.py] => Task 4, Epoch 25/34 => Loss 3.336, Loss_clf 0.558, Loss_fe 0.719, Loss_kd 1.734, Train_accy 61.87
2022-09-28 04:46:54,167 [foster.py] => Task 4, Epoch 26/34 => Loss 3.317, Loss_clf 0.559, Loss_fe 0.711, Loss_kd 1.724, Train_accy 59.53, Test_accy 55.86
2022-09-28 04:46:56,160 [foster.py] => Task 4, Epoch 27/34 => Loss 3.340, Loss_clf 0.564, Loss_fe 0.714, Loss_kd 1.737, Train_accy 62.30
2022-09-28 04:46:58,206 [foster.py] => Task 4, Epoch 28/34 => Loss 3.289, Loss_clf 0.543, Loss_fe 0.693, Loss_kd 1.729, Train_accy 60.70
2022-09-28 04:47:00,210 [foster.py] => Task 4, Epoch 29/34 => Loss 3.295, Loss_clf 0.556, Loss_fe 0.695, Loss_kd 1.721, Train_accy 60.06
2022-09-28 04:47:02,223 [foster.py] => Task 4, Epoch 30/34 => Loss 3.266, Loss_clf 0.539, Loss_fe 0.675, Loss_kd 1.729, Train_accy 60.81
2022-09-28 04:47:05,196 [foster.py] => Task 4, Epoch 31/34 => Loss 3.325, Loss_clf 0.557, Loss_fe 0.713, Loss_kd 1.730, Train_accy 58.89, Test_accy 56.98
2022-09-28 04:47:07,196 [foster.py] => Task 4, Epoch 32/34 => Loss 3.311, Loss_clf 0.558, Loss_fe 0.697, Loss_kd 1.732, Train_accy 62.09
2022-09-28 04:47:09,212 [foster.py] => Task 4, Epoch 33/34 => Loss 3.300, Loss_clf 0.556, Loss_fe 0.701, Loss_kd 1.721, Train_accy 61.45
2022-09-28 04:47:11,258 [foster.py] => Task 4, Epoch 34/34 => Loss 3.277, Loss_clf 0.530, Loss_fe 0.687, Loss_kd 1.734, Train_accy 61.55
2022-09-28 04:47:11,258 [foster.py] => do not weight align teacher!
2022-09-28 04:47:11,258 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 04:47:14,557 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.435,  Train_accy 15.76, Test_accy 35.36
2022-09-28 04:47:16,859 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.351,  Train_accy 17.04
2022-09-28 04:47:19,206 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.300,  Train_accy 18.00
2022-09-28 04:47:21,453 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.283,  Train_accy 18.42
2022-09-28 04:47:23,739 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.276,  Train_accy 18.42
2022-09-28 04:47:26,798 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.259,  Train_accy 19.81, Test_accy 38.29
2022-09-28 04:47:29,107 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.265,  Train_accy 19.49
2022-09-28 04:47:31,325 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.247,  Train_accy 19.38
2022-09-28 04:47:33,558 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.244,  Train_accy 20.13
2022-09-28 04:47:35,832 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.240,  Train_accy 22.04
2022-09-28 04:47:38,910 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.245,  Train_accy 23.96, Test_accy 40.54
2022-09-28 04:47:41,147 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.237,  Train_accy 22.36
2022-09-28 04:47:43,381 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.234,  Train_accy 23.43
2022-09-28 04:47:45,619 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.233,  Train_accy 24.60
2022-09-28 04:47:47,849 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.236,  Train_accy 24.39
2022-09-28 04:47:50,893 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.218,  Train_accy 23.96, Test_accy 40.99
2022-09-28 04:47:53,119 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.217,  Train_accy 23.43
2022-09-28 04:47:55,368 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.219,  Train_accy 25.03
2022-09-28 04:47:57,599 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.223,  Train_accy 24.49
2022-09-28 04:47:59,872 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.223,  Train_accy 25.88
2022-09-28 04:48:02,944 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.214,  Train_accy 25.99, Test_accy 42.12
2022-09-28 04:48:05,167 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.221,  Train_accy 26.30
2022-09-28 04:48:07,417 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.218,  Train_accy 24.49
2022-09-28 04:48:09,647 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.207,  Train_accy 24.39
2022-09-28 04:48:11,919 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.221,  Train_accy 25.03
2022-09-28 04:48:14,984 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.223,  Train_accy 25.03, Test_accy 42.57
2022-09-28 04:48:14,984 [foster.py] => do not weight align student!
2022-09-28 04:48:15,850 [foster.py] => darknet eval: 
2022-09-28 04:48:15,850 [foster.py] => CNN top1 curve: 42.57
2022-09-28 04:48:15,850 [foster.py] => CNN top5 curve: 90.54
2022-09-28 04:48:15,850 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 04:48:25,411 [foster.py] => Exemplar size: 380
2022-09-28 04:48:25,411 [trainer.py] => CNN: {'total': 56.53, 'old': 56.0, 'new': 59.42, 'base': 73.45, 'compound': 45.32}
2022-09-28 04:48:25,411 [trainer.py] => CNN top1 curve: [88.7, 70.43, 58.0, 52.8, 56.53]
2022-09-28 04:48:25,411 [trainer.py] => CNN base curve: [88.7, 84.18, 81.92, 76.84, 73.45]
2022-09-28 04:48:25,411 [trainer.py] => CNN old curve: [88.7, 84.18, 66.96, 55.33, 56.0]
2022-09-28 04:48:25,411 [trainer.py] => CNN new curve: [0, 24.53, 28.57, 42.67, 59.42]
2022-09-28 04:48:25,411 [trainer.py] => CNN compound curve: [0, 24.53, 23.58, 31.31, 45.32]
2022-09-28 04:48:25,411 [trainer.py] => NME: {'total': 63.96, 'old': 61.07, 'new': 79.71, 'base': 71.19, 'compound': 59.18}
2022-09-28 04:48:25,411 [trainer.py] => NME top1 curve: [91.53, 75.22, 64.33, 61.33, 63.96]
2022-09-28 04:48:25,411 [trainer.py] => NME base curve: [91.53, 82.49, 77.97, 75.14, 71.19]
2022-09-28 04:48:25,411 [trainer.py] => NME old curve: [91.53, 82.49, 71.3, 60.0, 61.07]
2022-09-28 04:48:25,411 [trainer.py] => NME new curve: [0, 50.94, 41.43, 66.67, 79.71]
2022-09-28 04:48:25,411 [trainer.py] => NME compound curve: [0, 50.94, 44.72, 48.99, 59.18]
2022-09-28 04:48:25,641 [foster.py] => Learning on 19-22
2022-09-28 04:48:25,642 [foster.py] => All params: 22396607
2022-09-28 04:48:25,642 [foster.py] => Trainable params: 11210348
2022-09-28 04:48:25,662 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 04:48:28,767 [foster.py] => Task 5, Epoch 1/34 => Loss 6.602, Loss_clf 1.831, Loss_fe 2.512, Loss_kd 1.952, Train_accy 41.96, Test_accy 41.98
2022-09-28 04:48:30,881 [foster.py] => Task 5, Epoch 2/34 => Loss 5.219, Loss_clf 1.113, Loss_fe 1.842, Loss_kd 1.956, Train_accy 40.38
2022-09-28 04:48:33,021 [foster.py] => Task 5, Epoch 3/34 => Loss 4.943, Loss_clf 1.041, Loss_fe 1.640, Loss_kd 1.954, Train_accy 42.16
2022-09-28 04:48:35,109 [foster.py] => Task 5, Epoch 4/34 => Loss 4.764, Loss_clf 0.990, Loss_fe 1.508, Loss_kd 1.957, Train_accy 41.27
2022-09-28 04:48:37,246 [foster.py] => Task 5, Epoch 5/34 => Loss 4.664, Loss_clf 0.978, Loss_fe 1.421, Loss_kd 1.956, Train_accy 41.87
2022-09-28 04:48:40,351 [foster.py] => Task 5, Epoch 6/34 => Loss 4.541, Loss_clf 0.942, Loss_fe 1.341, Loss_kd 1.950, Train_accy 42.56, Test_accy 49.90
2022-09-28 04:48:42,493 [foster.py] => Task 5, Epoch 7/34 => Loss 4.478, Loss_clf 0.930, Loss_fe 1.286, Loss_kd 1.954, Train_accy 45.63
2022-09-28 04:48:44,618 [foster.py] => Task 5, Epoch 8/34 => Loss 4.418, Loss_clf 0.914, Loss_fe 1.228, Loss_kd 1.966, Train_accy 45.14
2022-09-28 04:48:46,764 [foster.py] => Task 5, Epoch 9/34 => Loss 4.351, Loss_clf 0.894, Loss_fe 1.186, Loss_kd 1.961, Train_accy 43.45
2022-09-28 04:48:48,861 [foster.py] => Task 5, Epoch 10/34 => Loss 4.292, Loss_clf 0.888, Loss_fe 1.138, Loss_kd 1.957, Train_accy 44.74
2022-09-28 04:48:51,950 [foster.py] => Task 5, Epoch 11/34 => Loss 4.268, Loss_clf 0.885, Loss_fe 1.120, Loss_kd 1.955, Train_accy 44.84, Test_accy 51.49
2022-09-28 04:48:54,036 [foster.py] => Task 5, Epoch 12/34 => Loss 4.199, Loss_clf 0.854, Loss_fe 1.076, Loss_kd 1.959, Train_accy 45.34
2022-09-28 04:48:56,189 [foster.py] => Task 5, Epoch 13/34 => Loss 4.167, Loss_clf 0.846, Loss_fe 1.056, Loss_kd 1.956, Train_accy 45.14
2022-09-28 04:48:58,314 [foster.py] => Task 5, Epoch 14/34 => Loss 4.140, Loss_clf 0.834, Loss_fe 1.030, Loss_kd 1.965, Train_accy 45.73
2022-09-28 04:49:00,482 [foster.py] => Task 5, Epoch 15/34 => Loss 4.135, Loss_clf 0.839, Loss_fe 1.019, Loss_kd 1.966, Train_accy 43.85
2022-09-28 04:49:03,570 [foster.py] => Task 5, Epoch 16/34 => Loss 4.087, Loss_clf 0.815, Loss_fe 0.990, Loss_kd 1.970, Train_accy 44.15, Test_accy 51.68
2022-09-28 04:49:05,686 [foster.py] => Task 5, Epoch 17/34 => Loss 4.046, Loss_clf 0.810, Loss_fe 0.972, Loss_kd 1.955, Train_accy 47.02
2022-09-28 04:49:07,811 [foster.py] => Task 5, Epoch 18/34 => Loss 4.060, Loss_clf 0.816, Loss_fe 0.977, Loss_kd 1.958, Train_accy 45.73
2022-09-28 04:49:09,981 [foster.py] => Task 5, Epoch 19/34 => Loss 3.998, Loss_clf 0.794, Loss_fe 0.942, Loss_kd 1.954, Train_accy 47.12
2022-09-28 04:49:12,108 [foster.py] => Task 5, Epoch 20/34 => Loss 3.993, Loss_clf 0.780, Loss_fe 0.935, Loss_kd 1.968, Train_accy 46.83
2022-09-28 04:49:15,194 [foster.py] => Task 5, Epoch 21/34 => Loss 3.972, Loss_clf 0.768, Loss_fe 0.926, Loss_kd 1.968, Train_accy 46.13, Test_accy 53.47
2022-09-28 04:49:17,324 [foster.py] => Task 5, Epoch 22/34 => Loss 3.976, Loss_clf 0.771, Loss_fe 0.925, Loss_kd 1.970, Train_accy 46.63
2022-09-28 04:49:19,469 [foster.py] => Task 5, Epoch 23/34 => Loss 3.946, Loss_clf 0.762, Loss_fe 0.913, Loss_kd 1.961, Train_accy 47.02
2022-09-28 04:49:21,556 [foster.py] => Task 5, Epoch 24/34 => Loss 3.946, Loss_clf 0.763, Loss_fe 0.905, Loss_kd 1.967, Train_accy 46.33
2022-09-28 04:49:23,661 [foster.py] => Task 5, Epoch 25/34 => Loss 3.959, Loss_clf 0.773, Loss_fe 0.910, Loss_kd 1.965, Train_accy 46.33
2022-09-28 04:49:26,784 [foster.py] => Task 5, Epoch 26/34 => Loss 3.943, Loss_clf 0.771, Loss_fe 0.903, Loss_kd 1.960, Train_accy 47.02, Test_accy 52.48
2022-09-28 04:49:28,914 [foster.py] => Task 5, Epoch 27/34 => Loss 3.990, Loss_clf 0.792, Loss_fe 0.921, Loss_kd 1.966, Train_accy 46.63
2022-09-28 04:49:31,035 [foster.py] => Task 5, Epoch 28/34 => Loss 3.931, Loss_clf 0.759, Loss_fe 0.895, Loss_kd 1.966, Train_accy 46.03
2022-09-28 04:49:33,151 [foster.py] => Task 5, Epoch 29/34 => Loss 3.911, Loss_clf 0.751, Loss_fe 0.890, Loss_kd 1.960, Train_accy 46.53
2022-09-28 04:49:35,246 [foster.py] => Task 5, Epoch 30/34 => Loss 3.955, Loss_clf 0.777, Loss_fe 0.898, Loss_kd 1.970, Train_accy 46.23
2022-09-28 04:49:38,360 [foster.py] => Task 5, Epoch 31/34 => Loss 3.907, Loss_clf 0.754, Loss_fe 0.877, Loss_kd 1.965, Train_accy 47.22, Test_accy 52.67
2022-09-28 04:49:40,488 [foster.py] => Task 5, Epoch 32/34 => Loss 3.932, Loss_clf 0.765, Loss_fe 0.888, Loss_kd 1.968, Train_accy 46.63
2022-09-28 04:49:42,622 [foster.py] => Task 5, Epoch 33/34 => Loss 3.941, Loss_clf 0.759, Loss_fe 0.903, Loss_kd 1.968, Train_accy 48.31
2022-09-28 04:49:44,729 [foster.py] => Task 5, Epoch 34/34 => Loss 3.927, Loss_clf 0.757, Loss_fe 0.902, Loss_kd 1.959, Train_accy 47.02
2022-09-28 04:49:44,730 [foster.py] => do not weight align teacher!
2022-09-28 04:49:44,731 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 04:49:48,198 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.478,  Train_accy 19.35, Test_accy 38.02
2022-09-28 04:49:50,565 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.464,  Train_accy 20.63
2022-09-28 04:49:52,938 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.442,  Train_accy 20.83
2022-09-28 04:49:55,287 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.440,  Train_accy 20.73
2022-09-28 04:49:57,673 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.438,  Train_accy 20.63
2022-09-28 04:50:00,868 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.440,  Train_accy 20.54, Test_accy 39.60
2022-09-28 04:50:03,234 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.432,  Train_accy 21.03
2022-09-28 04:50:05,646 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.428,  Train_accy 20.14
2022-09-28 04:50:08,061 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.425,  Train_accy 21.43
2022-09-28 04:50:10,480 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.411,  Train_accy 21.92
2022-09-28 04:50:13,753 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.408,  Train_accy 21.43, Test_accy 41.58
2022-09-28 04:50:16,125 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.411,  Train_accy 21.43
2022-09-28 04:50:18,506 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.412,  Train_accy 21.92
2022-09-28 04:50:20,915 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.410,  Train_accy 21.63
2022-09-28 04:50:23,311 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.403,  Train_accy 21.92
2022-09-28 04:50:26,516 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.403,  Train_accy 21.63, Test_accy 41.78
2022-09-28 04:50:28,903 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.403,  Train_accy 22.12
2022-09-28 04:50:31,289 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.402,  Train_accy 21.83
2022-09-28 04:50:33,667 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.409,  Train_accy 22.72
2022-09-28 04:50:36,061 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.405,  Train_accy 21.83
2022-09-28 04:50:39,266 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.413,  Train_accy 22.12, Test_accy 41.98
2022-09-28 04:50:41,617 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.400,  Train_accy 22.22
2022-09-28 04:50:43,999 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.409,  Train_accy 21.13
2022-09-28 04:50:46,375 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.404,  Train_accy 22.12
2022-09-28 04:50:48,715 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.401,  Train_accy 22.22
2022-09-28 04:50:51,913 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.407,  Train_accy 21.73, Test_accy 41.39
2022-09-28 04:50:51,914 [foster.py] => do not weight align student!
2022-09-28 04:50:52,742 [foster.py] => darknet eval: 
2022-09-28 04:50:52,743 [foster.py] => CNN top1 curve: 41.39
2022-09-28 04:50:52,743 [foster.py] => CNN top5 curve: 86.14
2022-09-28 04:50:52,743 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 04:51:03,513 [foster.py] => Exemplar size: 440
2022-09-28 04:51:03,513 [trainer.py] => CNN: {'total': 52.67, 'old': 54.73, 'new': 37.7, 'base': 71.75, 'compound': 42.38}
2022-09-28 04:51:03,514 [trainer.py] => CNN top1 curve: [88.7, 70.43, 58.0, 52.8, 56.53, 52.67]
2022-09-28 04:51:03,514 [trainer.py] => CNN base curve: [88.7, 84.18, 81.92, 76.84, 73.45, 71.75]
2022-09-28 04:51:03,514 [trainer.py] => CNN old curve: [88.7, 84.18, 66.96, 55.33, 56.0, 54.73]
2022-09-28 04:51:03,514 [trainer.py] => CNN new curve: [0, 24.53, 28.57, 42.67, 59.42, 37.7]
2022-09-28 04:51:03,514 [trainer.py] => CNN compound curve: [0, 24.53, 23.58, 31.31, 45.32, 42.38]
2022-09-28 04:51:03,514 [trainer.py] => NME: {'total': 56.63, 'old': 58.11, 'new': 45.9, 'base': 70.62, 'compound': 49.09}
2022-09-28 04:51:03,514 [trainer.py] => NME top1 curve: [91.53, 75.22, 64.33, 61.33, 63.96, 56.63]
2022-09-28 04:51:03,514 [trainer.py] => NME base curve: [91.53, 82.49, 77.97, 75.14, 71.19, 70.62]
2022-09-28 04:51:03,514 [trainer.py] => NME old curve: [91.53, 82.49, 71.3, 60.0, 61.07, 58.11]
2022-09-28 04:51:03,514 [trainer.py] => NME new curve: [0, 50.94, 41.43, 66.67, 79.71, 45.9]
2022-09-28 04:51:03,514 [trainer.py] => NME compound curve: [0, 50.94, 44.72, 48.99, 59.18, 49.09]
2022-09-28 04:51:03,515 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 04:51:03,515 [trainer.py] => prefix: cil
2022-09-28 04:51:03,515 [trainer.py] => dataset: CFEE
2022-09-28 04:51:03,515 [trainer.py] => memory_size: 2000
2022-09-28 04:51:03,515 [trainer.py] => memory_per_class: 20
2022-09-28 04:51:03,515 [trainer.py] => fixed_memory: True
2022-09-28 04:51:03,515 [trainer.py] => shuffle: True
2022-09-28 04:51:03,515 [trainer.py] => init_cls: 7
2022-09-28 04:51:03,515 [trainer.py] => increment: 3
2022-09-28 04:51:03,515 [trainer.py] => model_name: foster
2022-09-28 04:51:03,515 [trainer.py] => convnet_type: resnet18
2022-09-28 04:51:03,515 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 04:51:03,515 [trainer.py] => seed: 1993
2022-09-28 04:51:03,516 [trainer.py] => beta1: 0.96
2022-09-28 04:51:03,516 [trainer.py] => beta2: 0.97
2022-09-28 04:51:03,516 [trainer.py] => oofc: ft
2022-09-28 04:51:03,516 [trainer.py] => is_teacher_wa: False
2022-09-28 04:51:03,516 [trainer.py] => is_student_wa: False
2022-09-28 04:51:03,516 [trainer.py] => lambda_okd: 1
2022-09-28 04:51:03,516 [trainer.py] => wa_value: 1
2022-09-28 04:51:03,516 [trainer.py] => init_epochs: 40
2022-09-28 04:51:03,516 [trainer.py] => init_lr: 0.01
2022-09-28 04:51:03,516 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 04:51:03,516 [trainer.py] => boosting_epochs: 34
2022-09-28 04:51:03,516 [trainer.py] => compression_epochs: 26
2022-09-28 04:51:03,516 [trainer.py] => lr: 0.001
2022-09-28 04:51:03,516 [trainer.py] => batch_size: 32
2022-09-28 04:51:03,516 [trainer.py] => weight_decay: 0.0005
2022-09-28 04:51:03,516 [trainer.py] => num_workers: 8
2022-09-28 04:51:03,516 [trainer.py] => T: 2
2022-09-28 04:51:03,516 [trainer.py] => nb_runs: 3
2022-09-28 04:51:03,516 [trainer.py] => fold: 10
2022-09-28 04:51:03,516 [data.py] => ========== Fold:1 ==========
2022-09-28 04:51:03,521 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 12, 10, 19, 21, 17, 18, 8, 7, 9, 14, 15, 13, 11, 16]
2022-09-28 04:51:03,737 [foster.py] => Learning on 0-7
2022-09-28 04:51:03,737 [foster.py] => All params: 11183694
2022-09-28 04:51:03,737 [foster.py] => Trainable params: 11183694
2022-09-28 04:51:06,110 [foster.py] => Task 0, Epoch 1/40 => Loss 1.340, Train_accy 50.93
2022-09-28 04:51:09,067 [foster.py] => Task 0, Epoch 2/40 => Loss 0.540, Train_accy 80.88, Test_accy 83.78
2022-09-28 04:51:12,092 [foster.py] => Task 0, Epoch 3/40 => Loss 0.352, Train_accy 87.53, Test_accy 88.51
2022-09-28 04:51:15,077 [foster.py] => Task 0, Epoch 4/40 => Loss 0.276, Train_accy 90.61, Test_accy 85.81
2022-09-28 04:51:18,102 [foster.py] => Task 0, Epoch 5/40 => Loss 0.237, Train_accy 90.95, Test_accy 88.51
2022-09-28 04:51:20,484 [foster.py] => Task 0, Epoch 6/40 => Loss 0.187, Train_accy 93.56
2022-09-28 04:51:23,488 [foster.py] => Task 0, Epoch 7/40 => Loss 0.165, Train_accy 94.24, Test_accy 86.49
2022-09-28 04:51:26,500 [foster.py] => Task 0, Epoch 8/40 => Loss 0.140, Train_accy 95.41, Test_accy 86.49
2022-09-28 04:51:29,507 [foster.py] => Task 0, Epoch 9/40 => Loss 0.103, Train_accy 96.64, Test_accy 85.81
2022-09-28 04:51:32,481 [foster.py] => Task 0, Epoch 10/40 => Loss 0.088, Train_accy 97.19, Test_accy 89.86
2022-09-28 04:51:34,864 [foster.py] => Task 0, Epoch 11/40 => Loss 0.086, Train_accy 97.60
2022-09-28 04:51:37,902 [foster.py] => Task 0, Epoch 12/40 => Loss 0.061, Train_accy 98.42, Test_accy 88.51
2022-09-28 04:51:40,906 [foster.py] => Task 0, Epoch 13/40 => Loss 0.062, Train_accy 98.49, Test_accy 85.14
2022-09-28 04:51:43,937 [foster.py] => Task 0, Epoch 14/40 => Loss 0.054, Train_accy 98.42, Test_accy 85.81
2022-09-28 04:51:46,906 [foster.py] => Task 0, Epoch 15/40 => Loss 0.051, Train_accy 98.49, Test_accy 85.81
2022-09-28 04:51:49,258 [foster.py] => Task 0, Epoch 16/40 => Loss 0.048, Train_accy 98.77
2022-09-28 04:51:52,260 [foster.py] => Task 0, Epoch 17/40 => Loss 0.038, Train_accy 98.97, Test_accy 87.84
2022-09-28 04:51:55,262 [foster.py] => Task 0, Epoch 18/40 => Loss 0.032, Train_accy 99.31, Test_accy 86.49
2022-09-28 04:51:58,290 [foster.py] => Task 0, Epoch 19/40 => Loss 0.034, Train_accy 99.18, Test_accy 87.84
2022-09-28 04:52:01,244 [foster.py] => Task 0, Epoch 20/40 => Loss 0.032, Train_accy 99.11, Test_accy 87.84
2022-09-28 04:52:03,633 [foster.py] => Task 0, Epoch 21/40 => Loss 0.035, Train_accy 99.18
2022-09-28 04:52:06,680 [foster.py] => Task 0, Epoch 22/40 => Loss 0.028, Train_accy 99.25, Test_accy 87.16
2022-09-28 04:52:09,700 [foster.py] => Task 0, Epoch 23/40 => Loss 0.023, Train_accy 99.52, Test_accy 84.46
2022-09-28 04:52:12,703 [foster.py] => Task 0, Epoch 24/40 => Loss 0.023, Train_accy 99.38, Test_accy 86.49
2022-09-28 04:52:15,688 [foster.py] => Task 0, Epoch 25/40 => Loss 0.025, Train_accy 99.25, Test_accy 87.16
2022-09-28 04:52:18,075 [foster.py] => Task 0, Epoch 26/40 => Loss 0.020, Train_accy 99.79
2022-09-28 04:52:21,078 [foster.py] => Task 0, Epoch 27/40 => Loss 0.018, Train_accy 99.73, Test_accy 86.49
2022-09-28 04:52:24,111 [foster.py] => Task 0, Epoch 28/40 => Loss 0.016, Train_accy 99.79, Test_accy 86.49
2022-09-28 04:52:27,134 [foster.py] => Task 0, Epoch 29/40 => Loss 0.015, Train_accy 99.73, Test_accy 85.81
2022-09-28 04:52:30,100 [foster.py] => Task 0, Epoch 30/40 => Loss 0.018, Train_accy 99.86, Test_accy 87.16
2022-09-28 04:52:32,469 [foster.py] => Task 0, Epoch 31/40 => Loss 0.013, Train_accy 100.00
2022-09-28 04:52:35,483 [foster.py] => Task 0, Epoch 32/40 => Loss 0.014, Train_accy 99.79, Test_accy 85.81
2022-09-28 04:52:38,457 [foster.py] => Task 0, Epoch 33/40 => Loss 0.014, Train_accy 99.86, Test_accy 87.84
2022-09-28 04:52:41,430 [foster.py] => Task 0, Epoch 34/40 => Loss 0.013, Train_accy 99.93, Test_accy 87.84
2022-09-28 04:52:44,487 [foster.py] => Task 0, Epoch 35/40 => Loss 0.013, Train_accy 99.86, Test_accy 85.81
2022-09-28 04:52:46,844 [foster.py] => Task 0, Epoch 36/40 => Loss 0.012, Train_accy 99.86
2022-09-28 04:52:49,827 [foster.py] => Task 0, Epoch 37/40 => Loss 0.012, Train_accy 100.00, Test_accy 85.81
2022-09-28 04:52:52,843 [foster.py] => Task 0, Epoch 38/40 => Loss 0.012, Train_accy 99.86, Test_accy 87.16
2022-09-28 04:52:55,895 [foster.py] => Task 0, Epoch 39/40 => Loss 0.014, Train_accy 99.79, Test_accy 85.81
2022-09-28 04:52:58,932 [foster.py] => Task 0, Epoch 40/40 => Loss 0.020, Train_accy 99.52, Test_accy 85.14
2022-09-28 04:52:58,933 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 04:53:05,846 [foster.py] => Exemplar size: 140
2022-09-28 04:53:05,846 [trainer.py] => CNN: {'total': 85.14, 'old': 85.14, 'new': 0, 'base': 85.14, 'compound': 0}
2022-09-28 04:53:05,846 [trainer.py] => CNN top1 curve: [85.14]
2022-09-28 04:53:05,847 [trainer.py] => CNN base curve: [85.14]
2022-09-28 04:53:05,847 [trainer.py] => CNN old curve: [85.14]
2022-09-28 04:53:05,847 [trainer.py] => CNN new curve: [0]
2022-09-28 04:53:05,847 [trainer.py] => CNN compound curve: [0]
2022-09-28 04:53:05,847 [trainer.py] => NME: {'total': 88.51, 'old': 88.51, 'new': 0, 'base': 88.51, 'compound': 0}
2022-09-28 04:53:05,847 [trainer.py] => NME top1 curve: [88.51]
2022-09-28 04:53:05,847 [trainer.py] => NME base curve: [88.51]
2022-09-28 04:53:05,847 [trainer.py] => NME old curve: [88.51]
2022-09-28 04:53:05,847 [trainer.py] => NME new curve: [0]
2022-09-28 04:53:05,847 [trainer.py] => NME compound curve: [0]
2022-09-28 04:53:06,077 [foster.py] => Learning on 7-10
2022-09-28 04:53:06,078 [foster.py] => All params: 22371995
2022-09-28 04:53:06,078 [foster.py] => Trainable params: 11191892
2022-09-28 04:53:06,098 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 04:53:08,561 [foster.py] => Task 1, Epoch 1/34 => Loss 5.221, Loss_clf 2.588, Loss_fe 2.098, Loss_kd 0.374, Train_accy 32.22, Test_accy 57.46
2022-09-28 04:53:10,297 [foster.py] => Task 1, Epoch 2/34 => Loss 2.938, Loss_clf 1.018, Loss_fe 1.363, Loss_kd 0.390, Train_accy 59.09
2022-09-28 04:53:12,027 [foster.py] => Task 1, Epoch 3/34 => Loss 2.385, Loss_clf 0.708, Loss_fe 1.162, Loss_kd 0.360, Train_accy 35.03
2022-09-28 04:53:13,833 [foster.py] => Task 1, Epoch 4/34 => Loss 2.160, Loss_clf 0.629, Loss_fe 1.027, Loss_kd 0.352, Train_accy 35.16
2022-09-28 04:53:15,526 [foster.py] => Task 1, Epoch 5/34 => Loss 2.094, Loss_clf 0.631, Loss_fe 0.965, Loss_kd 0.349, Train_accy 34.76
2022-09-28 04:53:18,009 [foster.py] => Task 1, Epoch 6/34 => Loss 2.018, Loss_clf 0.613, Loss_fe 0.908, Loss_kd 0.348, Train_accy 37.03, Test_accy 63.16
2022-09-28 04:53:19,762 [foster.py] => Task 1, Epoch 7/34 => Loss 1.941, Loss_clf 0.597, Loss_fe 0.863, Loss_kd 0.336, Train_accy 36.76
2022-09-28 04:53:21,495 [foster.py] => Task 1, Epoch 8/34 => Loss 1.923, Loss_clf 0.599, Loss_fe 0.833, Loss_kd 0.344, Train_accy 37.70
2022-09-28 04:53:23,246 [foster.py] => Task 1, Epoch 9/34 => Loss 1.883, Loss_clf 0.582, Loss_fe 0.814, Loss_kd 0.341, Train_accy 38.24
2022-09-28 04:53:25,016 [foster.py] => Task 1, Epoch 10/34 => Loss 1.784, Loss_clf 0.542, Loss_fe 0.758, Loss_kd 0.339, Train_accy 34.89
2022-09-28 04:53:27,497 [foster.py] => Task 1, Epoch 11/34 => Loss 1.763, Loss_clf 0.540, Loss_fe 0.743, Loss_kd 0.336, Train_accy 37.17, Test_accy 63.16
2022-09-28 04:53:29,242 [foster.py] => Task 1, Epoch 12/34 => Loss 1.701, Loss_clf 0.504, Loss_fe 0.708, Loss_kd 0.342, Train_accy 37.83
2022-09-28 04:53:30,958 [foster.py] => Task 1, Epoch 13/34 => Loss 1.735, Loss_clf 0.528, Loss_fe 0.711, Loss_kd 0.347, Train_accy 38.10
2022-09-28 04:53:32,674 [foster.py] => Task 1, Epoch 14/34 => Loss 1.679, Loss_clf 0.517, Loss_fe 0.685, Loss_kd 0.334, Train_accy 37.30
2022-09-28 04:53:34,366 [foster.py] => Task 1, Epoch 15/34 => Loss 1.643, Loss_clf 0.486, Loss_fe 0.677, Loss_kd 0.336, Train_accy 39.84
2022-09-28 04:53:36,863 [foster.py] => Task 1, Epoch 16/34 => Loss 1.671, Loss_clf 0.514, Loss_fe 0.670, Loss_kd 0.341, Train_accy 38.10, Test_accy 64.47
2022-09-28 04:53:38,559 [foster.py] => Task 1, Epoch 17/34 => Loss 1.650, Loss_clf 0.500, Loss_fe 0.664, Loss_kd 0.341, Train_accy 38.10
2022-09-28 04:53:40,259 [foster.py] => Task 1, Epoch 18/34 => Loss 1.641, Loss_clf 0.500, Loss_fe 0.653, Loss_kd 0.341, Train_accy 39.04
2022-09-28 04:53:41,966 [foster.py] => Task 1, Epoch 19/34 => Loss 1.615, Loss_clf 0.489, Loss_fe 0.636, Loss_kd 0.343, Train_accy 39.57
2022-09-28 04:53:43,711 [foster.py] => Task 1, Epoch 20/34 => Loss 1.550, Loss_clf 0.456, Loss_fe 0.612, Loss_kd 0.338, Train_accy 39.71
2022-09-28 04:53:46,130 [foster.py] => Task 1, Epoch 21/34 => Loss 1.541, Loss_clf 0.449, Loss_fe 0.609, Loss_kd 0.338, Train_accy 39.04, Test_accy 64.04
2022-09-28 04:53:47,824 [foster.py] => Task 1, Epoch 22/34 => Loss 1.541, Loss_clf 0.440, Loss_fe 0.614, Loss_kd 0.341, Train_accy 40.37
2022-09-28 04:53:49,547 [foster.py] => Task 1, Epoch 23/34 => Loss 1.517, Loss_clf 0.438, Loss_fe 0.596, Loss_kd 0.338, Train_accy 39.57
2022-09-28 04:53:51,250 [foster.py] => Task 1, Epoch 24/34 => Loss 1.517, Loss_clf 0.443, Loss_fe 0.594, Loss_kd 0.336, Train_accy 40.24
2022-09-28 04:53:52,958 [foster.py] => Task 1, Epoch 25/34 => Loss 1.541, Loss_clf 0.452, Loss_fe 0.600, Loss_kd 0.343, Train_accy 41.98
2022-09-28 04:53:55,367 [foster.py] => Task 1, Epoch 26/34 => Loss 1.524, Loss_clf 0.438, Loss_fe 0.592, Loss_kd 0.345, Train_accy 41.04, Test_accy 64.04
2022-09-28 04:53:57,105 [foster.py] => Task 1, Epoch 27/34 => Loss 1.502, Loss_clf 0.436, Loss_fe 0.578, Loss_kd 0.341, Train_accy 40.64
2022-09-28 04:53:58,811 [foster.py] => Task 1, Epoch 28/34 => Loss 1.507, Loss_clf 0.431, Loss_fe 0.590, Loss_kd 0.340, Train_accy 39.57
2022-09-28 04:54:00,527 [foster.py] => Task 1, Epoch 29/34 => Loss 1.475, Loss_clf 0.418, Loss_fe 0.571, Loss_kd 0.340, Train_accy 39.84
2022-09-28 04:54:02,262 [foster.py] => Task 1, Epoch 30/34 => Loss 1.493, Loss_clf 0.425, Loss_fe 0.572, Loss_kd 0.347, Train_accy 41.04
2022-09-28 04:54:04,769 [foster.py] => Task 1, Epoch 31/34 => Loss 1.491, Loss_clf 0.428, Loss_fe 0.582, Loss_kd 0.337, Train_accy 41.04, Test_accy 64.47
2022-09-28 04:54:06,479 [foster.py] => Task 1, Epoch 32/34 => Loss 1.506, Loss_clf 0.436, Loss_fe 0.582, Loss_kd 0.341, Train_accy 40.37
2022-09-28 04:54:08,217 [foster.py] => Task 1, Epoch 33/34 => Loss 1.540, Loss_clf 0.445, Loss_fe 0.596, Loss_kd 0.349, Train_accy 42.11
2022-09-28 04:54:09,955 [foster.py] => Task 1, Epoch 34/34 => Loss 1.542, Loss_clf 0.454, Loss_fe 0.598, Loss_kd 0.343, Train_accy 40.37
2022-09-28 04:54:09,956 [foster.py] => do not weight align teacher!
2022-09-28 04:54:09,956 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 04:54:12,770 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.464,  Train_accy 17.51, Test_accy 53.95
2022-09-28 04:54:14,683 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.297,  Train_accy 18.32
2022-09-28 04:54:16,611 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.242,  Train_accy 18.72
2022-09-28 04:54:18,494 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.195,  Train_accy 19.39
2022-09-28 04:54:20,371 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.169,  Train_accy 19.65
2022-09-28 04:54:22,962 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.182,  Train_accy 19.65, Test_accy 54.82
2022-09-28 04:54:24,895 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.134,  Train_accy 19.79
2022-09-28 04:54:26,776 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.131,  Train_accy 19.52
2022-09-28 04:54:28,712 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.144,  Train_accy 20.59
2022-09-28 04:54:30,629 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.148,  Train_accy 20.59
2022-09-28 04:54:33,187 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.126,  Train_accy 20.45, Test_accy 55.70
2022-09-28 04:54:35,059 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.125,  Train_accy 20.72
2022-09-28 04:54:36,965 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.107,  Train_accy 20.86
2022-09-28 04:54:38,889 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.116,  Train_accy 21.66
2022-09-28 04:54:40,785 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.107,  Train_accy 20.45
2022-09-28 04:54:43,420 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.113,  Train_accy 21.12, Test_accy 56.14
2022-09-28 04:54:45,330 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.116,  Train_accy 20.45
2022-09-28 04:54:47,267 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.125,  Train_accy 20.86
2022-09-28 04:54:49,185 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.113,  Train_accy 21.79
2022-09-28 04:54:51,118 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.121,  Train_accy 21.79
2022-09-28 04:54:53,649 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.098,  Train_accy 20.86, Test_accy 56.58
2022-09-28 04:54:55,583 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.119,  Train_accy 21.26
2022-09-28 04:54:57,464 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.096,  Train_accy 20.86
2022-09-28 04:54:59,339 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.108,  Train_accy 21.52
2022-09-28 04:55:01,284 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.123,  Train_accy 21.39
2022-09-28 04:55:03,842 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.101,  Train_accy 21.26, Test_accy 56.58
2022-09-28 04:55:03,842 [foster.py] => do not weight align student!
2022-09-28 04:55:04,500 [foster.py] => darknet eval: 
2022-09-28 04:55:04,500 [foster.py] => CNN top1 curve: 56.58
2022-09-28 04:55:04,501 [foster.py] => CNN top5 curve: 97.37
2022-09-28 04:55:04,501 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 04:55:10,794 [foster.py] => Exemplar size: 200
2022-09-28 04:55:10,794 [trainer.py] => CNN: {'total': 64.04, 'old': 86.49, 'new': 22.5, 'base': 86.49, 'compound': 22.5}
2022-09-28 04:55:10,794 [trainer.py] => CNN top1 curve: [85.14, 64.04]
2022-09-28 04:55:10,794 [trainer.py] => CNN base curve: [85.14, 86.49]
2022-09-28 04:55:10,794 [trainer.py] => CNN old curve: [85.14, 86.49]
2022-09-28 04:55:10,794 [trainer.py] => CNN new curve: [0, 22.5]
2022-09-28 04:55:10,794 [trainer.py] => CNN compound curve: [0, 22.5]
2022-09-28 04:55:10,794 [trainer.py] => NME: {'total': 68.42, 'old': 78.38, 'new': 50.0, 'base': 78.38, 'compound': 50.0}
2022-09-28 04:55:10,794 [trainer.py] => NME top1 curve: [88.51, 68.42]
2022-09-28 04:55:10,794 [trainer.py] => NME base curve: [88.51, 78.38]
2022-09-28 04:55:10,795 [trainer.py] => NME old curve: [88.51, 78.38]
2022-09-28 04:55:10,795 [trainer.py] => NME new curve: [0, 50.0]
2022-09-28 04:55:10,795 [trainer.py] => NME compound curve: [0, 50.0]
2022-09-28 04:55:11,029 [foster.py] => Learning on 10-13
2022-09-28 04:55:11,029 [foster.py] => All params: 22378148
2022-09-28 04:55:11,029 [foster.py] => Trainable params: 11196506
2022-09-28 04:55:11,050 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 04:55:13,678 [foster.py] => Task 2, Epoch 1/34 => Loss 5.551, Loss_clf 2.267, Loss_fe 2.165, Loss_kd 0.861, Train_accy 38.83, Test_accy 46.28
2022-09-28 04:55:15,461 [foster.py] => Task 2, Epoch 2/34 => Loss 3.642, Loss_clf 1.009, Loss_fe 1.543, Loss_kd 0.838, Train_accy 48.26
2022-09-28 04:55:17,255 [foster.py] => Task 2, Epoch 3/34 => Loss 3.237, Loss_clf 0.858, Loss_fe 1.323, Loss_kd 0.812, Train_accy 37.34
2022-09-28 04:55:19,092 [foster.py] => Task 2, Epoch 4/34 => Loss 3.018, Loss_clf 0.773, Loss_fe 1.178, Loss_kd 0.821, Train_accy 36.48
2022-09-28 04:55:20,941 [foster.py] => Task 2, Epoch 5/34 => Loss 2.999, Loss_clf 0.806, Loss_fe 1.136, Loss_kd 0.813, Train_accy 39.95
2022-09-28 04:55:23,576 [foster.py] => Task 2, Epoch 6/34 => Loss 2.852, Loss_clf 0.740, Loss_fe 1.060, Loss_kd 0.810, Train_accy 37.10, Test_accy 45.95
2022-09-28 04:55:25,391 [foster.py] => Task 2, Epoch 7/34 => Loss 2.714, Loss_clf 0.699, Loss_fe 0.971, Loss_kd 0.803, Train_accy 37.22
2022-09-28 04:55:27,206 [foster.py] => Task 2, Epoch 8/34 => Loss 2.645, Loss_clf 0.671, Loss_fe 0.913, Loss_kd 0.816, Train_accy 39.08
2022-09-28 04:55:29,066 [foster.py] => Task 2, Epoch 9/34 => Loss 2.587, Loss_clf 0.662, Loss_fe 0.865, Loss_kd 0.815, Train_accy 40.69
2022-09-28 04:55:30,887 [foster.py] => Task 2, Epoch 10/34 => Loss 2.593, Loss_clf 0.654, Loss_fe 0.881, Loss_kd 0.814, Train_accy 40.94
2022-09-28 04:55:33,476 [foster.py] => Task 2, Epoch 11/34 => Loss 2.517, Loss_clf 0.643, Loss_fe 0.822, Loss_kd 0.809, Train_accy 37.72, Test_accy 47.90
2022-09-28 04:55:35,292 [foster.py] => Task 2, Epoch 12/34 => Loss 2.519, Loss_clf 0.634, Loss_fe 0.825, Loss_kd 0.816, Train_accy 42.06
2022-09-28 04:55:37,126 [foster.py] => Task 2, Epoch 13/34 => Loss 2.449, Loss_clf 0.615, Loss_fe 0.764, Loss_kd 0.822, Train_accy 40.07
2022-09-28 04:55:38,956 [foster.py] => Task 2, Epoch 14/34 => Loss 2.424, Loss_clf 0.609, Loss_fe 0.766, Loss_kd 0.806, Train_accy 40.57
2022-09-28 04:55:40,795 [foster.py] => Task 2, Epoch 15/34 => Loss 2.349, Loss_clf 0.578, Loss_fe 0.718, Loss_kd 0.810, Train_accy 40.20
2022-09-28 04:55:43,431 [foster.py] => Task 2, Epoch 16/34 => Loss 2.396, Loss_clf 0.598, Loss_fe 0.721, Loss_kd 0.828, Train_accy 43.30, Test_accy 49.19
2022-09-28 04:55:45,256 [foster.py] => Task 2, Epoch 17/34 => Loss 2.361, Loss_clf 0.600, Loss_fe 0.700, Loss_kd 0.816, Train_accy 40.20
2022-09-28 04:55:47,090 [foster.py] => Task 2, Epoch 18/34 => Loss 2.420, Loss_clf 0.622, Loss_fe 0.721, Loss_kd 0.829, Train_accy 41.07
2022-09-28 04:55:48,871 [foster.py] => Task 2, Epoch 19/34 => Loss 2.354, Loss_clf 0.579, Loss_fe 0.711, Loss_kd 0.819, Train_accy 42.68
2022-09-28 04:55:50,686 [foster.py] => Task 2, Epoch 20/34 => Loss 2.284, Loss_clf 0.548, Loss_fe 0.667, Loss_kd 0.823, Train_accy 42.43
2022-09-28 04:55:53,314 [foster.py] => Task 2, Epoch 21/34 => Loss 2.325, Loss_clf 0.556, Loss_fe 0.685, Loss_kd 0.833, Train_accy 41.56, Test_accy 50.16
2022-09-28 04:55:55,134 [foster.py] => Task 2, Epoch 22/34 => Loss 2.274, Loss_clf 0.553, Loss_fe 0.658, Loss_kd 0.818, Train_accy 43.42
2022-09-28 04:55:56,974 [foster.py] => Task 2, Epoch 23/34 => Loss 2.214, Loss_clf 0.519, Loss_fe 0.625, Loss_kd 0.824, Train_accy 44.17
2022-09-28 04:55:58,794 [foster.py] => Task 2, Epoch 24/34 => Loss 2.202, Loss_clf 0.508, Loss_fe 0.645, Loss_kd 0.807, Train_accy 42.93
2022-09-28 04:56:00,673 [foster.py] => Task 2, Epoch 25/34 => Loss 2.271, Loss_clf 0.547, Loss_fe 0.657, Loss_kd 0.822, Train_accy 43.42
2022-09-28 04:56:03,338 [foster.py] => Task 2, Epoch 26/34 => Loss 2.216, Loss_clf 0.525, Loss_fe 0.628, Loss_kd 0.818, Train_accy 44.17, Test_accy 50.49
2022-09-28 04:56:05,173 [foster.py] => Task 2, Epoch 27/34 => Loss 2.287, Loss_clf 0.562, Loss_fe 0.664, Loss_kd 0.816, Train_accy 42.31
2022-09-28 04:56:06,991 [foster.py] => Task 2, Epoch 28/34 => Loss 2.230, Loss_clf 0.531, Loss_fe 0.632, Loss_kd 0.820, Train_accy 44.42
2022-09-28 04:56:08,789 [foster.py] => Task 2, Epoch 29/34 => Loss 2.183, Loss_clf 0.513, Loss_fe 0.609, Loss_kd 0.815, Train_accy 43.67
2022-09-28 04:56:10,579 [foster.py] => Task 2, Epoch 30/34 => Loss 2.226, Loss_clf 0.533, Loss_fe 0.627, Loss_kd 0.819, Train_accy 44.91
2022-09-28 04:56:13,214 [foster.py] => Task 2, Epoch 31/34 => Loss 2.294, Loss_clf 0.561, Loss_fe 0.657, Loss_kd 0.828, Train_accy 43.42, Test_accy 50.81
2022-09-28 04:56:14,988 [foster.py] => Task 2, Epoch 32/34 => Loss 2.243, Loss_clf 0.533, Loss_fe 0.641, Loss_kd 0.823, Train_accy 44.04
2022-09-28 04:56:16,821 [foster.py] => Task 2, Epoch 33/34 => Loss 2.215, Loss_clf 0.516, Loss_fe 0.636, Loss_kd 0.818, Train_accy 44.04
2022-09-28 04:56:18,652 [foster.py] => Task 2, Epoch 34/34 => Loss 2.239, Loss_clf 0.523, Loss_fe 0.650, Loss_kd 0.820, Train_accy 43.92
2022-09-28 04:56:18,653 [foster.py] => do not weight align teacher!
2022-09-28 04:56:18,653 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 04:56:21,633 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.859,  Train_accy 17.62, Test_accy 42.72
2022-09-28 04:56:23,672 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.691,  Train_accy 17.49
2022-09-28 04:56:25,703 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.632,  Train_accy 17.49
2022-09-28 04:56:27,697 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.608,  Train_accy 18.24
2022-09-28 04:56:29,775 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.599,  Train_accy 17.49
2022-09-28 04:56:32,589 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.565,  Train_accy 17.49, Test_accy 41.10
2022-09-28 04:56:34,591 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.556,  Train_accy 17.99
2022-09-28 04:56:36,599 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.565,  Train_accy 17.99
2022-09-28 04:56:38,611 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.550,  Train_accy 18.86
2022-09-28 04:56:40,674 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.558,  Train_accy 18.73
2022-09-28 04:56:43,435 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.559,  Train_accy 18.49, Test_accy 41.75
2022-09-28 04:56:45,431 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.553,  Train_accy 18.86
2022-09-28 04:56:47,422 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.522,  Train_accy 18.98
2022-09-28 04:56:49,428 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.550,  Train_accy 18.98
2022-09-28 04:56:51,460 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.540,  Train_accy 18.49
2022-09-28 04:56:54,156 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.547,  Train_accy 18.98, Test_accy 42.39
2022-09-28 04:56:56,217 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.520,  Train_accy 19.23
2022-09-28 04:56:58,232 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.535,  Train_accy 19.11
2022-09-28 04:57:00,279 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.530,  Train_accy 18.49
2022-09-28 04:57:02,286 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.551,  Train_accy 20.10
2022-09-28 04:57:05,054 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.551,  Train_accy 20.35, Test_accy 41.42
2022-09-28 04:57:07,084 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.528,  Train_accy 18.49
2022-09-28 04:57:09,064 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.546,  Train_accy 18.86
2022-09-28 04:57:11,058 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.546,  Train_accy 19.48
2022-09-28 04:57:13,047 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.536,  Train_accy 19.11
2022-09-28 04:57:15,846 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.545,  Train_accy 19.23, Test_accy 41.75
2022-09-28 04:57:15,847 [foster.py] => do not weight align student!
2022-09-28 04:57:16,577 [foster.py] => darknet eval: 
2022-09-28 04:57:16,577 [foster.py] => CNN top1 curve: 41.75
2022-09-28 04:57:16,577 [foster.py] => CNN top5 curve: 96.12
2022-09-28 04:57:16,577 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 04:57:23,950 [foster.py] => Exemplar size: 260
2022-09-28 04:57:23,950 [trainer.py] => CNN: {'total': 50.49, 'old': 59.65, 'new': 24.69, 'base': 81.76, 'compound': 21.74}
2022-09-28 04:57:23,950 [trainer.py] => CNN top1 curve: [85.14, 64.04, 50.49]
2022-09-28 04:57:23,951 [trainer.py] => CNN base curve: [85.14, 86.49, 81.76]
2022-09-28 04:57:23,951 [trainer.py] => CNN old curve: [85.14, 86.49, 59.65]
2022-09-28 04:57:23,951 [trainer.py] => CNN new curve: [0, 22.5, 24.69]
2022-09-28 04:57:23,951 [trainer.py] => CNN compound curve: [0, 22.5, 21.74]
2022-09-28 04:57:23,951 [trainer.py] => NME: {'total': 61.49, 'old': 61.84, 'new': 60.49, 'base': 73.65, 'compound': 50.31}
2022-09-28 04:57:23,951 [trainer.py] => NME top1 curve: [88.51, 68.42, 61.49]
2022-09-28 04:57:23,951 [trainer.py] => NME base curve: [88.51, 78.38, 73.65]
2022-09-28 04:57:23,951 [trainer.py] => NME old curve: [88.51, 78.38, 61.84]
2022-09-28 04:57:23,951 [trainer.py] => NME new curve: [0, 50.0, 60.49]
2022-09-28 04:57:23,951 [trainer.py] => NME compound curve: [0, 50.0, 50.31]
2022-09-28 04:57:24,185 [foster.py] => Learning on 13-16
2022-09-28 04:57:24,185 [foster.py] => All params: 22384301
2022-09-28 04:57:24,185 [foster.py] => Trainable params: 11201120
2022-09-28 04:57:24,205 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 04:57:26,999 [foster.py] => Task 3, Epoch 1/34 => Loss 5.866, Loss_clf 2.041, Loss_fe 2.243, Loss_kd 1.285, Train_accy 42.37, Test_accy 39.89
2022-09-28 04:57:28,897 [foster.py] => Task 3, Epoch 2/34 => Loss 3.966, Loss_clf 0.858, Loss_fe 1.554, Loss_kd 1.263, Train_accy 46.10
2022-09-28 04:57:30,799 [foster.py] => Task 3, Epoch 3/34 => Loss 3.588, Loss_clf 0.734, Loss_fe 1.314, Loss_kd 1.252, Train_accy 45.42
2022-09-28 04:57:32,695 [foster.py] => Task 3, Epoch 4/34 => Loss 3.383, Loss_clf 0.668, Loss_fe 1.172, Loss_kd 1.253, Train_accy 43.50
2022-09-28 04:57:34,631 [foster.py] => Task 3, Epoch 5/34 => Loss 3.299, Loss_clf 0.663, Loss_fe 1.089, Loss_kd 1.257, Train_accy 45.88
2022-09-28 04:57:37,387 [foster.py] => Task 3, Epoch 6/34 => Loss 3.195, Loss_clf 0.642, Loss_fe 1.009, Loss_kd 1.254, Train_accy 48.02, Test_accy 45.28
2022-09-28 04:57:39,343 [foster.py] => Task 3, Epoch 7/34 => Loss 3.113, Loss_clf 0.608, Loss_fe 0.955, Loss_kd 1.260, Train_accy 44.75
2022-09-28 04:57:41,239 [foster.py] => Task 3, Epoch 8/34 => Loss 3.032, Loss_clf 0.599, Loss_fe 0.891, Loss_kd 1.253, Train_accy 48.25
2022-09-28 04:57:43,171 [foster.py] => Task 3, Epoch 9/34 => Loss 3.000, Loss_clf 0.604, Loss_fe 0.865, Loss_kd 1.244, Train_accy 46.55
2022-09-28 04:57:45,110 [foster.py] => Task 3, Epoch 10/34 => Loss 2.957, Loss_clf 0.574, Loss_fe 0.836, Loss_kd 1.258, Train_accy 48.93
2022-09-28 04:57:47,943 [foster.py] => Task 3, Epoch 11/34 => Loss 2.888, Loss_clf 0.547, Loss_fe 0.797, Loss_kd 1.254, Train_accy 52.20, Test_accy 45.55
2022-09-28 04:57:49,866 [foster.py] => Task 3, Epoch 12/34 => Loss 2.870, Loss_clf 0.564, Loss_fe 0.772, Loss_kd 1.246, Train_accy 49.49
2022-09-28 04:57:51,833 [foster.py] => Task 3, Epoch 13/34 => Loss 2.822, Loss_clf 0.536, Loss_fe 0.738, Loss_kd 1.258, Train_accy 50.62
2022-09-28 04:57:53,732 [foster.py] => Task 3, Epoch 14/34 => Loss 2.785, Loss_clf 0.533, Loss_fe 0.711, Loss_kd 1.252, Train_accy 51.98
2022-09-28 04:57:55,687 [foster.py] => Task 3, Epoch 15/34 => Loss 2.776, Loss_clf 0.526, Loss_fe 0.702, Loss_kd 1.258, Train_accy 51.75
2022-09-28 04:57:58,481 [foster.py] => Task 3, Epoch 16/34 => Loss 2.713, Loss_clf 0.503, Loss_fe 0.661, Loss_kd 1.258, Train_accy 51.75, Test_accy 45.01
2022-09-28 04:58:00,390 [foster.py] => Task 3, Epoch 17/34 => Loss 2.710, Loss_clf 0.505, Loss_fe 0.661, Loss_kd 1.255, Train_accy 52.77
2022-09-28 04:58:02,337 [foster.py] => Task 3, Epoch 18/34 => Loss 2.668, Loss_clf 0.488, Loss_fe 0.640, Loss_kd 1.251, Train_accy 49.94
2022-09-28 04:58:04,274 [foster.py] => Task 3, Epoch 19/34 => Loss 2.693, Loss_clf 0.495, Loss_fe 0.652, Loss_kd 1.256, Train_accy 54.01
2022-09-28 04:58:06,204 [foster.py] => Task 3, Epoch 20/34 => Loss 2.682, Loss_clf 0.495, Loss_fe 0.639, Loss_kd 1.258, Train_accy 52.43
2022-09-28 04:58:08,995 [foster.py] => Task 3, Epoch 21/34 => Loss 2.661, Loss_clf 0.492, Loss_fe 0.627, Loss_kd 1.253, Train_accy 53.45, Test_accy 45.01
2022-09-28 04:58:10,899 [foster.py] => Task 3, Epoch 22/34 => Loss 2.669, Loss_clf 0.491, Loss_fe 0.633, Loss_kd 1.256, Train_accy 53.22
2022-09-28 04:58:12,822 [foster.py] => Task 3, Epoch 23/34 => Loss 2.634, Loss_clf 0.473, Loss_fe 0.606, Loss_kd 1.263, Train_accy 53.56
2022-09-28 04:58:14,730 [foster.py] => Task 3, Epoch 24/34 => Loss 2.608, Loss_clf 0.469, Loss_fe 0.595, Loss_kd 1.255, Train_accy 53.11
2022-09-28 04:58:16,639 [foster.py] => Task 3, Epoch 25/34 => Loss 2.643, Loss_clf 0.473, Loss_fe 0.611, Loss_kd 1.267, Train_accy 52.99
2022-09-28 04:58:19,430 [foster.py] => Task 3, Epoch 26/34 => Loss 2.628, Loss_clf 0.476, Loss_fe 0.605, Loss_kd 1.257, Train_accy 51.41, Test_accy 45.55
2022-09-28 04:58:21,358 [foster.py] => Task 3, Epoch 27/34 => Loss 2.573, Loss_clf 0.452, Loss_fe 0.579, Loss_kd 1.253, Train_accy 53.90
2022-09-28 04:58:23,249 [foster.py] => Task 3, Epoch 28/34 => Loss 2.608, Loss_clf 0.468, Loss_fe 0.595, Loss_kd 1.256, Train_accy 54.24
2022-09-28 04:58:25,154 [foster.py] => Task 3, Epoch 29/34 => Loss 2.604, Loss_clf 0.471, Loss_fe 0.589, Loss_kd 1.254, Train_accy 52.88
2022-09-28 04:58:27,052 [foster.py] => Task 3, Epoch 30/34 => Loss 2.604, Loss_clf 0.467, Loss_fe 0.591, Loss_kd 1.256, Train_accy 52.20
2022-09-28 04:58:29,826 [foster.py] => Task 3, Epoch 31/34 => Loss 2.603, Loss_clf 0.469, Loss_fe 0.590, Loss_kd 1.254, Train_accy 51.98, Test_accy 46.09
2022-09-28 04:58:31,811 [foster.py] => Task 3, Epoch 32/34 => Loss 2.599, Loss_clf 0.459, Loss_fe 0.589, Loss_kd 1.260, Train_accy 53.33
2022-09-28 04:58:33,729 [foster.py] => Task 3, Epoch 33/34 => Loss 2.597, Loss_clf 0.456, Loss_fe 0.580, Loss_kd 1.268, Train_accy 54.35
2022-09-28 04:58:35,658 [foster.py] => Task 3, Epoch 34/34 => Loss 2.601, Loss_clf 0.469, Loss_fe 0.588, Loss_kd 1.254, Train_accy 52.09
2022-09-28 04:58:35,658 [foster.py] => do not weight align teacher!
2022-09-28 04:58:35,659 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 04:58:38,799 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.102,  Train_accy 15.93, Test_accy 35.04
2022-09-28 04:58:40,943 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.008,  Train_accy 16.84
2022-09-28 04:58:43,111 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 1.967,  Train_accy 16.72
2022-09-28 04:58:45,241 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 1.943,  Train_accy 16.50
2022-09-28 04:58:47,387 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.932,  Train_accy 16.72
2022-09-28 04:58:50,306 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.932,  Train_accy 17.40, Test_accy 37.74
2022-09-28 04:58:52,510 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.919,  Train_accy 17.74
2022-09-28 04:58:54,705 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.902,  Train_accy 17.51
2022-09-28 04:58:56,856 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.894,  Train_accy 17.85
2022-09-28 04:58:59,052 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.908,  Train_accy 18.08
2022-09-28 04:59:01,986 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.886,  Train_accy 17.51, Test_accy 38.27
2022-09-28 04:59:04,152 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.885,  Train_accy 18.64
2022-09-28 04:59:06,292 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.884,  Train_accy 19.44
2022-09-28 04:59:08,418 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.889,  Train_accy 20.34
2022-09-28 04:59:10,559 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.873,  Train_accy 18.76
2022-09-28 04:59:13,480 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.883,  Train_accy 19.66, Test_accy 38.54
2022-09-28 04:59:15,639 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.884,  Train_accy 19.44
2022-09-28 04:59:17,821 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.879,  Train_accy 19.66
2022-09-28 04:59:19,994 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.880,  Train_accy 18.98
2022-09-28 04:59:22,156 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.883,  Train_accy 20.68
2022-09-28 04:59:25,148 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.860,  Train_accy 19.89, Test_accy 40.43
2022-09-28 04:59:27,268 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.870,  Train_accy 19.44
2022-09-28 04:59:29,398 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.875,  Train_accy 21.24
2022-09-28 04:59:31,569 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.870,  Train_accy 19.89
2022-09-28 04:59:33,729 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.863,  Train_accy 20.00
2022-09-28 04:59:36,681 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.862,  Train_accy 19.21, Test_accy 39.89
2022-09-28 04:59:36,681 [foster.py] => do not weight align student!
2022-09-28 04:59:37,434 [foster.py] => darknet eval: 
2022-09-28 04:59:37,434 [foster.py] => CNN top1 curve: 39.89
2022-09-28 04:59:37,434 [foster.py] => CNN top5 curve: 95.15
2022-09-28 04:59:37,434 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 04:59:46,000 [foster.py] => Exemplar size: 320
2022-09-28 04:59:46,000 [trainer.py] => CNN: {'total': 45.82, 'old': 47.25, 'new': 38.71, 'base': 76.35, 'compound': 25.56}
2022-09-28 04:59:46,000 [trainer.py] => CNN top1 curve: [85.14, 64.04, 50.49, 45.82]
2022-09-28 04:59:46,000 [trainer.py] => CNN base curve: [85.14, 86.49, 81.76, 76.35]
2022-09-28 04:59:46,000 [trainer.py] => CNN old curve: [85.14, 86.49, 59.65, 47.25]
2022-09-28 04:59:46,000 [trainer.py] => CNN new curve: [0, 22.5, 24.69, 38.71]
2022-09-28 04:59:46,000 [trainer.py] => CNN compound curve: [0, 22.5, 21.74, 25.56]
2022-09-28 04:59:46,000 [trainer.py] => NME: {'total': 57.95, 'old': 55.34, 'new': 70.97, 'base': 67.57, 'compound': 51.57}
2022-09-28 04:59:46,000 [trainer.py] => NME top1 curve: [88.51, 68.42, 61.49, 57.95]
2022-09-28 04:59:46,000 [trainer.py] => NME base curve: [88.51, 78.38, 73.65, 67.57]
2022-09-28 04:59:46,000 [trainer.py] => NME old curve: [88.51, 78.38, 61.84, 55.34]
2022-09-28 04:59:46,000 [trainer.py] => NME new curve: [0, 50.0, 60.49, 70.97]
2022-09-28 04:59:46,001 [trainer.py] => NME compound curve: [0, 50.0, 50.31, 51.57]
2022-09-28 04:59:46,232 [foster.py] => Learning on 16-19
2022-09-28 04:59:46,233 [foster.py] => All params: 22390454
2022-09-28 04:59:46,233 [foster.py] => Trainable params: 11205734
2022-09-28 04:59:46,253 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 04:59:49,251 [foster.py] => Task 4, Epoch 1/34 => Loss 6.422, Loss_clf 1.875, Loss_fe 2.495, Loss_kd 1.728, Train_accy 38.80, Test_accy 39.95
2022-09-28 04:59:51,292 [foster.py] => Task 4, Epoch 2/34 => Loss 4.778, Loss_clf 0.965, Loss_fe 1.757, Loss_kd 1.731, Train_accy 41.01
2022-09-28 04:59:53,337 [foster.py] => Task 4, Epoch 3/34 => Loss 4.437, Loss_clf 0.849, Loss_fe 1.525, Loss_kd 1.737, Train_accy 51.00
2022-09-28 04:59:55,342 [foster.py] => Task 4, Epoch 4/34 => Loss 4.271, Loss_clf 0.827, Loss_fe 1.391, Loss_kd 1.728, Train_accy 50.79
2022-09-28 04:59:57,361 [foster.py] => Task 4, Epoch 5/34 => Loss 4.117, Loss_clf 0.785, Loss_fe 1.274, Loss_kd 1.732, Train_accy 49.84
2022-09-28 05:00:00,302 [foster.py] => Task 4, Epoch 6/34 => Loss 4.010, Loss_clf 0.759, Loss_fe 1.192, Loss_kd 1.734, Train_accy 49.63, Test_accy 46.73
2022-09-28 05:00:02,319 [foster.py] => Task 4, Epoch 7/34 => Loss 3.907, Loss_clf 0.728, Loss_fe 1.115, Loss_kd 1.738, Train_accy 52.05
2022-09-28 05:00:04,322 [foster.py] => Task 4, Epoch 8/34 => Loss 3.856, Loss_clf 0.721, Loss_fe 1.076, Loss_kd 1.734, Train_accy 51.63
2022-09-28 05:00:06,346 [foster.py] => Task 4, Epoch 9/34 => Loss 3.790, Loss_clf 0.704, Loss_fe 1.025, Loss_kd 1.735, Train_accy 53.00
2022-09-28 05:00:08,341 [foster.py] => Task 4, Epoch 10/34 => Loss 3.713, Loss_clf 0.680, Loss_fe 0.978, Loss_kd 1.731, Train_accy 53.63
2022-09-28 05:00:11,281 [foster.py] => Task 4, Epoch 11/34 => Loss 3.685, Loss_clf 0.680, Loss_fe 0.945, Loss_kd 1.735, Train_accy 53.21, Test_accy 47.66
2022-09-28 05:00:13,411 [foster.py] => Task 4, Epoch 12/34 => Loss 3.673, Loss_clf 0.677, Loss_fe 0.932, Loss_kd 1.738, Train_accy 54.26
2022-09-28 05:00:15,461 [foster.py] => Task 4, Epoch 13/34 => Loss 3.604, Loss_clf 0.656, Loss_fe 0.883, Loss_kd 1.739, Train_accy 55.42
2022-09-28 05:00:17,493 [foster.py] => Task 4, Epoch 14/34 => Loss 3.566, Loss_clf 0.641, Loss_fe 0.861, Loss_kd 1.738, Train_accy 54.15
2022-09-28 05:00:19,503 [foster.py] => Task 4, Epoch 15/34 => Loss 3.541, Loss_clf 0.640, Loss_fe 0.841, Loss_kd 1.735, Train_accy 57.52
2022-09-28 05:00:22,489 [foster.py] => Task 4, Epoch 16/34 => Loss 3.525, Loss_clf 0.633, Loss_fe 0.834, Loss_kd 1.733, Train_accy 55.94, Test_accy 47.43
2022-09-28 05:00:24,487 [foster.py] => Task 4, Epoch 17/34 => Loss 3.468, Loss_clf 0.615, Loss_fe 0.797, Loss_kd 1.731, Train_accy 55.84
2022-09-28 05:00:26,525 [foster.py] => Task 4, Epoch 18/34 => Loss 3.454, Loss_clf 0.616, Loss_fe 0.774, Loss_kd 1.739, Train_accy 58.15
2022-09-28 05:00:28,554 [foster.py] => Task 4, Epoch 19/34 => Loss 3.433, Loss_clf 0.599, Loss_fe 0.765, Loss_kd 1.741, Train_accy 55.42
2022-09-28 05:00:30,540 [foster.py] => Task 4, Epoch 20/34 => Loss 3.433, Loss_clf 0.597, Loss_fe 0.765, Loss_kd 1.744, Train_accy 55.84
2022-09-28 05:00:33,494 [foster.py] => Task 4, Epoch 21/34 => Loss 3.420, Loss_clf 0.595, Loss_fe 0.756, Loss_kd 1.743, Train_accy 58.57, Test_accy 48.36
2022-09-28 05:00:35,566 [foster.py] => Task 4, Epoch 22/34 => Loss 3.389, Loss_clf 0.590, Loss_fe 0.742, Loss_kd 1.732, Train_accy 56.26
2022-09-28 05:00:37,626 [foster.py] => Task 4, Epoch 23/34 => Loss 3.369, Loss_clf 0.572, Loss_fe 0.731, Loss_kd 1.740, Train_accy 58.25
2022-09-28 05:00:39,629 [foster.py] => Task 4, Epoch 24/34 => Loss 3.381, Loss_clf 0.581, Loss_fe 0.734, Loss_kd 1.740, Train_accy 56.68
2022-09-28 05:00:41,617 [foster.py] => Task 4, Epoch 25/34 => Loss 3.358, Loss_clf 0.573, Loss_fe 0.715, Loss_kd 1.743, Train_accy 57.94
2022-09-28 05:00:44,542 [foster.py] => Task 4, Epoch 26/34 => Loss 3.358, Loss_clf 0.570, Loss_fe 0.720, Loss_kd 1.742, Train_accy 57.41, Test_accy 48.36
2022-09-28 05:00:46,583 [foster.py] => Task 4, Epoch 27/34 => Loss 3.339, Loss_clf 0.566, Loss_fe 0.710, Loss_kd 1.738, Train_accy 57.73
2022-09-28 05:00:48,642 [foster.py] => Task 4, Epoch 28/34 => Loss 3.353, Loss_clf 0.566, Loss_fe 0.719, Loss_kd 1.742, Train_accy 58.89
2022-09-28 05:00:50,677 [foster.py] => Task 4, Epoch 29/34 => Loss 3.352, Loss_clf 0.573, Loss_fe 0.715, Loss_kd 1.738, Train_accy 57.10
2022-09-28 05:00:52,722 [foster.py] => Task 4, Epoch 30/34 => Loss 3.324, Loss_clf 0.556, Loss_fe 0.695, Loss_kd 1.745, Train_accy 58.46
2022-09-28 05:00:55,687 [foster.py] => Task 4, Epoch 31/34 => Loss 3.335, Loss_clf 0.569, Loss_fe 0.706, Loss_kd 1.734, Train_accy 57.83, Test_accy 49.30
2022-09-28 05:00:57,738 [foster.py] => Task 4, Epoch 32/34 => Loss 3.370, Loss_clf 0.577, Loss_fe 0.722, Loss_kd 1.744, Train_accy 57.83
2022-09-28 05:00:59,807 [foster.py] => Task 4, Epoch 33/34 => Loss 3.331, Loss_clf 0.560, Loss_fe 0.703, Loss_kd 1.741, Train_accy 56.99
2022-09-28 05:01:01,830 [foster.py] => Task 4, Epoch 34/34 => Loss 3.352, Loss_clf 0.569, Loss_fe 0.714, Loss_kd 1.743, Train_accy 58.25
2022-09-28 05:01:01,831 [foster.py] => do not weight align teacher!
2022-09-28 05:01:01,831 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 05:01:05,161 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.457,  Train_accy 15.25, Test_accy 32.94
2022-09-28 05:01:07,407 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.374,  Train_accy 15.56
2022-09-28 05:01:09,682 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.331,  Train_accy 17.77
2022-09-28 05:01:11,962 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.309,  Train_accy 17.14
2022-09-28 05:01:14,246 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.294,  Train_accy 17.46
2022-09-28 05:01:17,347 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.280,  Train_accy 17.56, Test_accy 37.85
2022-09-28 05:01:19,631 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.276,  Train_accy 18.09
2022-09-28 05:01:21,903 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.264,  Train_accy 19.87
2022-09-28 05:01:24,193 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.265,  Train_accy 18.72
2022-09-28 05:01:26,456 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.265,  Train_accy 20.19
2022-09-28 05:01:29,599 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.253,  Train_accy 19.56, Test_accy 40.19
2022-09-28 05:01:31,884 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.258,  Train_accy 21.45
2022-09-28 05:01:34,182 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.255,  Train_accy 19.14
2022-09-28 05:01:36,468 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.253,  Train_accy 21.35
2022-09-28 05:01:38,760 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.246,  Train_accy 20.61
2022-09-28 05:01:41,828 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.253,  Train_accy 20.82, Test_accy 40.42
2022-09-28 05:01:44,124 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.248,  Train_accy 22.29
2022-09-28 05:01:46,390 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.245,  Train_accy 21.35
2022-09-28 05:01:48,653 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.236,  Train_accy 20.82
2022-09-28 05:01:50,991 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.242,  Train_accy 22.29
2022-09-28 05:01:54,068 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.248,  Train_accy 22.08, Test_accy 39.72
2022-09-28 05:01:56,340 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.243,  Train_accy 21.66
2022-09-28 05:01:58,634 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.250,  Train_accy 21.98
2022-09-28 05:02:00,890 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.251,  Train_accy 22.82
2022-09-28 05:02:03,226 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.238,  Train_accy 22.29
2022-09-28 05:02:06,412 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.250,  Train_accy 22.61, Test_accy 41.12
2022-09-28 05:02:06,413 [foster.py] => do not weight align student!
2022-09-28 05:02:07,257 [foster.py] => darknet eval: 
2022-09-28 05:02:07,257 [foster.py] => CNN top1 curve: 41.12
2022-09-28 05:02:07,257 [foster.py] => CNN top5 curve: 88.79
2022-09-28 05:02:07,257 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 05:02:16,832 [foster.py] => Exemplar size: 380
2022-09-28 05:02:16,832 [trainer.py] => CNN: {'total': 49.3, 'old': 47.71, 'new': 59.65, 'base': 68.92, 'compound': 38.93}
2022-09-28 05:02:16,832 [trainer.py] => CNN top1 curve: [85.14, 64.04, 50.49, 45.82, 49.3]
2022-09-28 05:02:16,832 [trainer.py] => CNN base curve: [85.14, 86.49, 81.76, 76.35, 68.92]
2022-09-28 05:02:16,832 [trainer.py] => CNN old curve: [85.14, 86.49, 59.65, 47.25, 47.71]
2022-09-28 05:02:16,832 [trainer.py] => CNN new curve: [0, 22.5, 24.69, 38.71, 59.65]
2022-09-28 05:02:16,832 [trainer.py] => CNN compound curve: [0, 22.5, 21.74, 25.56, 38.93]
2022-09-28 05:02:16,832 [trainer.py] => NME: {'total': 56.54, 'old': 54.99, 'new': 66.67, 'base': 62.84, 'compound': 53.21}
2022-09-28 05:02:16,832 [trainer.py] => NME top1 curve: [88.51, 68.42, 61.49, 57.95, 56.54]
2022-09-28 05:02:16,832 [trainer.py] => NME base curve: [88.51, 78.38, 73.65, 67.57, 62.84]
2022-09-28 05:02:16,833 [trainer.py] => NME old curve: [88.51, 78.38, 61.84, 55.34, 54.99]
2022-09-28 05:02:16,833 [trainer.py] => NME new curve: [0, 50.0, 60.49, 70.97, 66.67]
2022-09-28 05:02:16,833 [trainer.py] => NME compound curve: [0, 50.0, 50.31, 51.57, 53.21]
2022-09-28 05:02:17,064 [foster.py] => Learning on 19-22
2022-09-28 05:02:17,065 [foster.py] => All params: 22396607
2022-09-28 05:02:17,065 [foster.py] => Trainable params: 11210348
2022-09-28 05:02:17,085 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 05:02:20,135 [foster.py] => Task 5, Epoch 1/34 => Loss 6.883, Loss_clf 1.973, Loss_fe 2.622, Loss_kd 1.976, Train_accy 38.31, Test_accy 37.43
2022-09-28 05:02:22,201 [foster.py] => Task 5, Epoch 2/34 => Loss 5.339, Loss_clf 1.131, Loss_fe 1.915, Loss_kd 1.980, Train_accy 37.60
2022-09-28 05:02:24,293 [foster.py] => Task 5, Epoch 3/34 => Loss 5.025, Loss_clf 1.046, Loss_fe 1.689, Loss_kd 1.978, Train_accy 40.52
2022-09-28 05:02:26,409 [foster.py] => Task 5, Epoch 4/34 => Loss 4.878, Loss_clf 1.012, Loss_fe 1.570, Loss_kd 1.983, Train_accy 42.24
2022-09-28 05:02:28,524 [foster.py] => Task 5, Epoch 5/34 => Loss 4.741, Loss_clf 0.980, Loss_fe 1.477, Loss_kd 1.973, Train_accy 43.35
2022-09-28 05:02:31,584 [foster.py] => Task 5, Epoch 6/34 => Loss 4.646, Loss_clf 0.953, Loss_fe 1.402, Loss_kd 1.979, Train_accy 43.85, Test_accy 42.97
2022-09-28 05:02:33,633 [foster.py] => Task 5, Epoch 7/34 => Loss 4.586, Loss_clf 0.952, Loss_fe 1.344, Loss_kd 1.978, Train_accy 42.44
2022-09-28 05:02:35,793 [foster.py] => Task 5, Epoch 8/34 => Loss 4.498, Loss_clf 0.928, Loss_fe 1.272, Loss_kd 1.985, Train_accy 43.15
2022-09-28 05:02:37,862 [foster.py] => Task 5, Epoch 9/34 => Loss 4.443, Loss_clf 0.907, Loss_fe 1.241, Loss_kd 1.981, Train_accy 42.84
2022-09-28 05:02:40,017 [foster.py] => Task 5, Epoch 10/34 => Loss 4.367, Loss_clf 0.891, Loss_fe 1.190, Loss_kd 1.975, Train_accy 43.65
2022-09-28 05:02:43,152 [foster.py] => Task 5, Epoch 11/34 => Loss 4.329, Loss_clf 0.888, Loss_fe 1.143, Loss_kd 1.984, Train_accy 44.05, Test_accy 42.57
2022-09-28 05:02:45,244 [foster.py] => Task 5, Epoch 12/34 => Loss 4.287, Loss_clf 0.871, Loss_fe 1.119, Loss_kd 1.983, Train_accy 45.16
2022-09-28 05:02:47,294 [foster.py] => Task 5, Epoch 13/34 => Loss 4.258, Loss_clf 0.860, Loss_fe 1.097, Loss_kd 1.986, Train_accy 40.62
2022-09-28 05:02:49,388 [foster.py] => Task 5, Epoch 14/34 => Loss 4.187, Loss_clf 0.833, Loss_fe 1.059, Loss_kd 1.982, Train_accy 45.56
2022-09-28 05:02:51,503 [foster.py] => Task 5, Epoch 15/34 => Loss 4.219, Loss_clf 0.856, Loss_fe 1.068, Loss_kd 1.983, Train_accy 45.46
2022-09-28 05:02:54,576 [foster.py] => Task 5, Epoch 16/34 => Loss 4.188, Loss_clf 0.841, Loss_fe 1.045, Loss_kd 1.988, Train_accy 45.46, Test_accy 42.77
2022-09-28 05:02:56,696 [foster.py] => Task 5, Epoch 17/34 => Loss 4.124, Loss_clf 0.816, Loss_fe 1.014, Loss_kd 1.981, Train_accy 47.88
2022-09-28 05:02:58,787 [foster.py] => Task 5, Epoch 18/34 => Loss 4.120, Loss_clf 0.815, Loss_fe 0.998, Loss_kd 1.992, Train_accy 45.36
2022-09-28 05:03:00,861 [foster.py] => Task 5, Epoch 19/34 => Loss 4.100, Loss_clf 0.803, Loss_fe 0.992, Loss_kd 1.991, Train_accy 44.46
2022-09-28 05:03:02,936 [foster.py] => Task 5, Epoch 20/34 => Loss 4.082, Loss_clf 0.807, Loss_fe 0.979, Loss_kd 1.983, Train_accy 46.27
2022-09-28 05:03:05,993 [foster.py] => Task 5, Epoch 21/34 => Loss 4.074, Loss_clf 0.798, Loss_fe 0.970, Loss_kd 1.991, Train_accy 44.66, Test_accy 43.37
2022-09-28 05:03:08,090 [foster.py] => Task 5, Epoch 22/34 => Loss 4.057, Loss_clf 0.800, Loss_fe 0.961, Loss_kd 1.984, Train_accy 45.36
2022-09-28 05:03:10,152 [foster.py] => Task 5, Epoch 23/34 => Loss 4.045, Loss_clf 0.788, Loss_fe 0.954, Loss_kd 1.989, Train_accy 46.67
2022-09-28 05:03:12,235 [foster.py] => Task 5, Epoch 24/34 => Loss 4.030, Loss_clf 0.781, Loss_fe 0.943, Loss_kd 1.992, Train_accy 47.38
2022-09-28 05:03:14,339 [foster.py] => Task 5, Epoch 25/34 => Loss 4.026, Loss_clf 0.785, Loss_fe 0.940, Loss_kd 1.987, Train_accy 45.46
2022-09-28 05:03:17,446 [foster.py] => Task 5, Epoch 26/34 => Loss 4.010, Loss_clf 0.785, Loss_fe 0.932, Loss_kd 1.981, Train_accy 47.08, Test_accy 43.76
2022-09-28 05:03:19,506 [foster.py] => Task 5, Epoch 27/34 => Loss 3.995, Loss_clf 0.781, Loss_fe 0.920, Loss_kd 1.981, Train_accy 46.77
2022-09-28 05:03:21,572 [foster.py] => Task 5, Epoch 28/34 => Loss 4.016, Loss_clf 0.784, Loss_fe 0.929, Loss_kd 1.989, Train_accy 48.08
2022-09-28 05:03:23,617 [foster.py] => Task 5, Epoch 29/34 => Loss 3.972, Loss_clf 0.763, Loss_fe 0.919, Loss_kd 1.978, Train_accy 46.77
2022-09-28 05:03:25,678 [foster.py] => Task 5, Epoch 30/34 => Loss 4.001, Loss_clf 0.777, Loss_fe 0.923, Loss_kd 1.987, Train_accy 45.97
2022-09-28 05:03:28,766 [foster.py] => Task 5, Epoch 31/34 => Loss 3.999, Loss_clf 0.777, Loss_fe 0.922, Loss_kd 1.987, Train_accy 46.07, Test_accy 43.56
2022-09-28 05:03:30,862 [foster.py] => Task 5, Epoch 32/34 => Loss 4.000, Loss_clf 0.765, Loss_fe 0.930, Loss_kd 1.991, Train_accy 48.39
2022-09-28 05:03:32,965 [foster.py] => Task 5, Epoch 33/34 => Loss 3.998, Loss_clf 0.768, Loss_fe 0.928, Loss_kd 1.989, Train_accy 46.77
2022-09-28 05:03:35,061 [foster.py] => Task 5, Epoch 34/34 => Loss 3.978, Loss_clf 0.761, Loss_fe 0.916, Loss_kd 1.987, Train_accy 47.88
2022-09-28 05:03:35,061 [foster.py] => do not weight align teacher!
2022-09-28 05:03:35,062 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 05:03:38,553 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.489,  Train_accy 20.56, Test_accy 35.25
2022-09-28 05:03:40,900 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.479,  Train_accy 19.96
2022-09-28 05:03:43,265 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.461,  Train_accy 19.96
2022-09-28 05:03:45,660 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.452,  Train_accy 20.77
2022-09-28 05:03:47,987 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.454,  Train_accy 20.26
2022-09-28 05:03:51,247 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.454,  Train_accy 20.67, Test_accy 37.43
2022-09-28 05:03:53,605 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.437,  Train_accy 21.47
2022-09-28 05:03:55,938 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.436,  Train_accy 21.98
2022-09-28 05:03:58,270 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.430,  Train_accy 21.57
2022-09-28 05:04:00,613 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.438,  Train_accy 21.27
2022-09-28 05:04:03,820 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.436,  Train_accy 21.57, Test_accy 37.82
2022-09-28 05:04:06,167 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.428,  Train_accy 22.08
2022-09-28 05:04:08,525 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.437,  Train_accy 21.88
2022-09-28 05:04:10,863 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.426,  Train_accy 21.17
2022-09-28 05:04:13,193 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.427,  Train_accy 21.37
2022-09-28 05:04:16,419 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.423,  Train_accy 21.67, Test_accy 38.22
2022-09-28 05:04:18,758 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.431,  Train_accy 22.78
2022-09-28 05:04:21,101 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.425,  Train_accy 21.98
2022-09-28 05:04:23,484 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.420,  Train_accy 21.17
2022-09-28 05:04:25,872 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.420,  Train_accy 21.17
2022-09-28 05:04:29,060 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.417,  Train_accy 22.48, Test_accy 38.02
2022-09-28 05:04:31,364 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.417,  Train_accy 20.67
2022-09-28 05:04:33,691 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.427,  Train_accy 21.37
2022-09-28 05:04:36,049 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.425,  Train_accy 21.67
2022-09-28 05:04:38,438 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.415,  Train_accy 21.77
2022-09-28 05:04:41,622 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.420,  Train_accy 22.08, Test_accy 38.02
2022-09-28 05:04:41,622 [foster.py] => do not weight align student!
2022-09-28 05:04:42,475 [foster.py] => darknet eval: 
2022-09-28 05:04:42,475 [foster.py] => CNN top1 curve: 38.02
2022-09-28 05:04:42,475 [foster.py] => CNN top5 curve: 81.98
2022-09-28 05:04:42,475 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 05:04:53,178 [foster.py] => Exemplar size: 440
2022-09-28 05:04:53,178 [trainer.py] => CNN: {'total': 43.17, 'old': 45.79, 'new': 28.57, 'base': 62.84, 'compound': 35.01}
2022-09-28 05:04:53,178 [trainer.py] => CNN top1 curve: [85.14, 64.04, 50.49, 45.82, 49.3, 43.17]
2022-09-28 05:04:53,178 [trainer.py] => CNN base curve: [85.14, 86.49, 81.76, 76.35, 68.92, 62.84]
2022-09-28 05:04:53,178 [trainer.py] => CNN old curve: [85.14, 86.49, 59.65, 47.25, 47.71, 45.79]
2022-09-28 05:04:53,178 [trainer.py] => CNN new curve: [0, 22.5, 24.69, 38.71, 59.65, 28.57]
2022-09-28 05:04:53,178 [trainer.py] => CNN compound curve: [0, 22.5, 21.74, 25.56, 38.93, 35.01]
2022-09-28 05:04:53,178 [trainer.py] => NME: {'total': 47.92, 'old': 49.53, 'new': 38.96, 'base': 60.81, 'compound': 42.58}
2022-09-28 05:04:53,178 [trainer.py] => NME top1 curve: [88.51, 68.42, 61.49, 57.95, 56.54, 47.92]
2022-09-28 05:04:53,178 [trainer.py] => NME base curve: [88.51, 78.38, 73.65, 67.57, 62.84, 60.81]
2022-09-28 05:04:53,178 [trainer.py] => NME old curve: [88.51, 78.38, 61.84, 55.34, 54.99, 49.53]
2022-09-28 05:04:53,179 [trainer.py] => NME new curve: [0, 50.0, 60.49, 70.97, 66.67, 38.96]
2022-09-28 05:04:53,179 [trainer.py] => NME compound curve: [0, 50.0, 50.31, 51.57, 53.21, 42.58]
2022-09-28 05:04:53,180 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 05:04:53,180 [trainer.py] => prefix: cil
2022-09-28 05:04:53,180 [trainer.py] => dataset: CFEE
2022-09-28 05:04:53,180 [trainer.py] => memory_size: 2000
2022-09-28 05:04:53,180 [trainer.py] => memory_per_class: 20
2022-09-28 05:04:53,180 [trainer.py] => fixed_memory: True
2022-09-28 05:04:53,180 [trainer.py] => shuffle: True
2022-09-28 05:04:53,180 [trainer.py] => init_cls: 7
2022-09-28 05:04:53,180 [trainer.py] => increment: 3
2022-09-28 05:04:53,180 [trainer.py] => model_name: foster
2022-09-28 05:04:53,180 [trainer.py] => convnet_type: resnet18
2022-09-28 05:04:53,180 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 05:04:53,180 [trainer.py] => seed: 1993
2022-09-28 05:04:53,180 [trainer.py] => beta1: 0.96
2022-09-28 05:04:53,180 [trainer.py] => beta2: 0.97
2022-09-28 05:04:53,180 [trainer.py] => oofc: ft
2022-09-28 05:04:53,180 [trainer.py] => is_teacher_wa: False
2022-09-28 05:04:53,181 [trainer.py] => is_student_wa: False
2022-09-28 05:04:53,181 [trainer.py] => lambda_okd: 1
2022-09-28 05:04:53,181 [trainer.py] => wa_value: 1
2022-09-28 05:04:53,181 [trainer.py] => init_epochs: 40
2022-09-28 05:04:53,181 [trainer.py] => init_lr: 0.01
2022-09-28 05:04:53,181 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 05:04:53,181 [trainer.py] => boosting_epochs: 34
2022-09-28 05:04:53,181 [trainer.py] => compression_epochs: 26
2022-09-28 05:04:53,181 [trainer.py] => lr: 0.001
2022-09-28 05:04:53,181 [trainer.py] => batch_size: 32
2022-09-28 05:04:53,181 [trainer.py] => weight_decay: 0.0005
2022-09-28 05:04:53,181 [trainer.py] => num_workers: 8
2022-09-28 05:04:53,181 [trainer.py] => T: 2
2022-09-28 05:04:53,181 [trainer.py] => nb_runs: 3
2022-09-28 05:04:53,181 [trainer.py] => fold: 10
2022-09-28 05:04:53,181 [data.py] => ========== Fold:2 ==========
2022-09-28 05:04:53,186 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 12, 10, 19, 21, 17, 18, 8, 7, 9, 14, 15, 13, 11, 16]
2022-09-28 05:04:53,402 [foster.py] => Learning on 0-7
2022-09-28 05:04:53,403 [foster.py] => All params: 11183694
2022-09-28 05:04:53,403 [foster.py] => Trainable params: 11183694
2022-09-28 05:04:55,813 [foster.py] => Task 0, Epoch 1/40 => Loss 1.311, Train_accy 52.31
2022-09-28 05:04:58,832 [foster.py] => Task 0, Epoch 2/40 => Loss 0.533, Train_accy 81.23, Test_accy 86.71
2022-09-28 05:05:01,811 [foster.py] => Task 0, Epoch 3/40 => Loss 0.371, Train_accy 86.20, Test_accy 86.08
2022-09-28 05:05:04,831 [foster.py] => Task 0, Epoch 4/40 => Loss 0.274, Train_accy 91.10, Test_accy 84.18
2022-09-28 05:05:07,840 [foster.py] => Task 0, Epoch 5/40 => Loss 0.219, Train_accy 92.27, Test_accy 86.71
2022-09-28 05:05:10,260 [foster.py] => Task 0, Epoch 6/40 => Loss 0.179, Train_accy 93.72
2022-09-28 05:05:13,255 [foster.py] => Task 0, Epoch 7/40 => Loss 0.153, Train_accy 94.41, Test_accy 84.18
2022-09-28 05:05:16,215 [foster.py] => Task 0, Epoch 8/40 => Loss 0.126, Train_accy 95.79, Test_accy 86.71
2022-09-28 05:05:19,205 [foster.py] => Task 0, Epoch 9/40 => Loss 0.131, Train_accy 95.65, Test_accy 85.44
2022-09-28 05:05:22,185 [foster.py] => Task 0, Epoch 10/40 => Loss 0.098, Train_accy 97.79, Test_accy 86.08
2022-09-28 05:05:24,572 [foster.py] => Task 0, Epoch 11/40 => Loss 0.109, Train_accy 96.48
2022-09-28 05:05:27,542 [foster.py] => Task 0, Epoch 12/40 => Loss 0.092, Train_accy 97.24, Test_accy 86.08
2022-09-28 05:05:30,535 [foster.py] => Task 0, Epoch 13/40 => Loss 0.085, Train_accy 97.45, Test_accy 84.81
2022-09-28 05:05:33,608 [foster.py] => Task 0, Epoch 14/40 => Loss 0.067, Train_accy 97.72, Test_accy 84.81
2022-09-28 05:05:36,594 [foster.py] => Task 0, Epoch 15/40 => Loss 0.046, Train_accy 99.03, Test_accy 85.44
2022-09-28 05:05:38,948 [foster.py] => Task 0, Epoch 16/40 => Loss 0.054, Train_accy 98.27
2022-09-28 05:05:41,913 [foster.py] => Task 0, Epoch 17/40 => Loss 0.042, Train_accy 99.03, Test_accy 87.34
2022-09-28 05:05:44,908 [foster.py] => Task 0, Epoch 18/40 => Loss 0.051, Train_accy 98.41, Test_accy 87.34
2022-09-28 05:05:47,871 [foster.py] => Task 0, Epoch 19/40 => Loss 0.050, Train_accy 98.41, Test_accy 87.34
2022-09-28 05:05:50,859 [foster.py] => Task 0, Epoch 20/40 => Loss 0.028, Train_accy 99.38, Test_accy 88.61
2022-09-28 05:05:53,234 [foster.py] => Task 0, Epoch 21/40 => Loss 0.030, Train_accy 99.17
2022-09-28 05:05:56,191 [foster.py] => Task 0, Epoch 22/40 => Loss 0.034, Train_accy 99.03, Test_accy 87.97
2022-09-28 05:05:59,169 [foster.py] => Task 0, Epoch 23/40 => Loss 0.026, Train_accy 99.38, Test_accy 86.08
2022-09-28 05:06:02,191 [foster.py] => Task 0, Epoch 24/40 => Loss 0.023, Train_accy 99.59, Test_accy 85.44
2022-09-28 05:06:05,231 [foster.py] => Task 0, Epoch 25/40 => Loss 0.019, Train_accy 99.79, Test_accy 87.34
2022-09-28 05:06:07,594 [foster.py] => Task 0, Epoch 26/40 => Loss 0.019, Train_accy 99.79
2022-09-28 05:06:10,603 [foster.py] => Task 0, Epoch 27/40 => Loss 0.016, Train_accy 99.93, Test_accy 87.34
2022-09-28 05:06:13,565 [foster.py] => Task 0, Epoch 28/40 => Loss 0.018, Train_accy 99.72, Test_accy 86.71
2022-09-28 05:06:16,513 [foster.py] => Task 0, Epoch 29/40 => Loss 0.016, Train_accy 99.79, Test_accy 86.71
2022-09-28 05:06:19,515 [foster.py] => Task 0, Epoch 30/40 => Loss 0.019, Train_accy 99.86, Test_accy 85.44
2022-09-28 05:06:21,957 [foster.py] => Task 0, Epoch 31/40 => Loss 0.015, Train_accy 99.79
2022-09-28 05:06:24,910 [foster.py] => Task 0, Epoch 32/40 => Loss 0.017, Train_accy 99.65, Test_accy 86.71
2022-09-28 05:06:27,891 [foster.py] => Task 0, Epoch 33/40 => Loss 0.021, Train_accy 99.72, Test_accy 85.44
2022-09-28 05:06:30,921 [foster.py] => Task 0, Epoch 34/40 => Loss 0.013, Train_accy 99.93, Test_accy 86.08
2022-09-28 05:06:33,918 [foster.py] => Task 0, Epoch 35/40 => Loss 0.016, Train_accy 99.65, Test_accy 85.44
2022-09-28 05:06:36,299 [foster.py] => Task 0, Epoch 36/40 => Loss 0.017, Train_accy 99.79
2022-09-28 05:06:39,322 [foster.py] => Task 0, Epoch 37/40 => Loss 0.011, Train_accy 99.93, Test_accy 86.71
2022-09-28 05:06:42,277 [foster.py] => Task 0, Epoch 38/40 => Loss 0.019, Train_accy 99.79, Test_accy 86.08
2022-09-28 05:06:45,251 [foster.py] => Task 0, Epoch 39/40 => Loss 0.016, Train_accy 99.79, Test_accy 86.71
2022-09-28 05:06:48,275 [foster.py] => Task 0, Epoch 40/40 => Loss 0.015, Train_accy 99.86, Test_accy 86.71
2022-09-28 05:06:48,276 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 05:06:55,138 [foster.py] => Exemplar size: 140
2022-09-28 05:06:55,138 [trainer.py] => CNN: {'total': 86.71, 'old': 86.71, 'new': 0, 'base': 86.71, 'compound': 0}
2022-09-28 05:06:55,139 [trainer.py] => CNN top1 curve: [86.71]
2022-09-28 05:06:55,139 [trainer.py] => CNN base curve: [86.71]
2022-09-28 05:06:55,139 [trainer.py] => CNN old curve: [86.71]
2022-09-28 05:06:55,139 [trainer.py] => CNN new curve: [0]
2022-09-28 05:06:55,139 [trainer.py] => CNN compound curve: [0]
2022-09-28 05:06:55,139 [trainer.py] => NME: {'total': 87.34, 'old': 87.34, 'new': 0, 'base': 87.34, 'compound': 0}
2022-09-28 05:06:55,139 [trainer.py] => NME top1 curve: [87.34]
2022-09-28 05:06:55,139 [trainer.py] => NME base curve: [87.34]
2022-09-28 05:06:55,139 [trainer.py] => NME old curve: [87.34]
2022-09-28 05:06:55,139 [trainer.py] => NME new curve: [0]
2022-09-28 05:06:55,139 [trainer.py] => NME compound curve: [0]
2022-09-28 05:06:55,373 [foster.py] => Learning on 7-10
2022-09-28 05:06:55,373 [foster.py] => All params: 22371995
2022-09-28 05:06:55,374 [foster.py] => Trainable params: 11191892
2022-09-28 05:06:55,394 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 05:06:57,930 [foster.py] => Task 1, Epoch 1/34 => Loss 5.042, Loss_clf 2.569, Loss_fe 1.911, Loss_kd 0.393, Train_accy 33.60, Test_accy 61.23
2022-09-28 05:06:59,716 [foster.py] => Task 1, Epoch 2/34 => Loss 2.851, Loss_clf 0.945, Loss_fe 1.325, Loss_kd 0.407, Train_accy 62.85
2022-09-28 05:07:01,427 [foster.py] => Task 1, Epoch 3/34 => Loss 2.360, Loss_clf 0.674, Loss_fe 1.140, Loss_kd 0.382, Train_accy 40.32
2022-09-28 05:07:03,150 [foster.py] => Task 1, Epoch 4/34 => Loss 2.190, Loss_clf 0.620, Loss_fe 1.034, Loss_kd 0.374, Train_accy 38.74
2022-09-28 05:07:04,867 [foster.py] => Task 1, Epoch 5/34 => Loss 2.126, Loss_clf 0.620, Loss_fe 0.970, Loss_kd 0.376, Train_accy 41.37
2022-09-28 05:07:07,336 [foster.py] => Task 1, Epoch 6/34 => Loss 2.054, Loss_clf 0.603, Loss_fe 0.916, Loss_kd 0.374, Train_accy 38.74, Test_accy 63.00
2022-09-28 05:07:09,118 [foster.py] => Task 1, Epoch 7/34 => Loss 1.999, Loss_clf 0.596, Loss_fe 0.871, Loss_kd 0.372, Train_accy 40.97
2022-09-28 05:07:10,861 [foster.py] => Task 1, Epoch 8/34 => Loss 1.942, Loss_clf 0.576, Loss_fe 0.837, Loss_kd 0.370, Train_accy 39.26
2022-09-28 05:07:12,623 [foster.py] => Task 1, Epoch 9/34 => Loss 1.906, Loss_clf 0.571, Loss_fe 0.805, Loss_kd 0.371, Train_accy 41.11
2022-09-28 05:07:14,344 [foster.py] => Task 1, Epoch 10/34 => Loss 1.845, Loss_clf 0.552, Loss_fe 0.770, Loss_kd 0.366, Train_accy 40.45
2022-09-28 05:07:16,789 [foster.py] => Task 1, Epoch 11/34 => Loss 1.806, Loss_clf 0.536, Loss_fe 0.741, Loss_kd 0.370, Train_accy 40.18, Test_accy 62.11
2022-09-28 05:07:18,508 [foster.py] => Task 1, Epoch 12/34 => Loss 1.798, Loss_clf 0.542, Loss_fe 0.733, Loss_kd 0.367, Train_accy 43.21
2022-09-28 05:07:20,210 [foster.py] => Task 1, Epoch 13/34 => Loss 1.774, Loss_clf 0.522, Loss_fe 0.719, Loss_kd 0.373, Train_accy 42.29
2022-09-28 05:07:21,974 [foster.py] => Task 1, Epoch 14/34 => Loss 1.763, Loss_clf 0.528, Loss_fe 0.702, Loss_kd 0.373, Train_accy 42.95
2022-09-28 05:07:23,686 [foster.py] => Task 1, Epoch 15/34 => Loss 1.709, Loss_clf 0.503, Loss_fe 0.679, Loss_kd 0.369, Train_accy 42.56
2022-09-28 05:07:26,162 [foster.py] => Task 1, Epoch 16/34 => Loss 1.706, Loss_clf 0.505, Loss_fe 0.673, Loss_kd 0.370, Train_accy 46.77, Test_accy 63.00
2022-09-28 05:07:27,902 [foster.py] => Task 1, Epoch 17/34 => Loss 1.682, Loss_clf 0.487, Loss_fe 0.666, Loss_kd 0.370, Train_accy 43.61
2022-09-28 05:07:29,653 [foster.py] => Task 1, Epoch 18/34 => Loss 1.647, Loss_clf 0.479, Loss_fe 0.642, Loss_kd 0.368, Train_accy 43.48
2022-09-28 05:07:31,408 [foster.py] => Task 1, Epoch 19/34 => Loss 1.678, Loss_clf 0.491, Loss_fe 0.650, Loss_kd 0.377, Train_accy 46.25
2022-09-28 05:07:33,138 [foster.py] => Task 1, Epoch 20/34 => Loss 1.660, Loss_clf 0.490, Loss_fe 0.639, Loss_kd 0.371, Train_accy 42.69
2022-09-28 05:07:35,645 [foster.py] => Task 1, Epoch 21/34 => Loss 1.657, Loss_clf 0.488, Loss_fe 0.634, Loss_kd 0.374, Train_accy 43.74, Test_accy 63.00
2022-09-28 05:07:37,383 [foster.py] => Task 1, Epoch 22/34 => Loss 1.630, Loss_clf 0.472, Loss_fe 0.629, Loss_kd 0.371, Train_accy 44.40
2022-09-28 05:07:39,144 [foster.py] => Task 1, Epoch 23/34 => Loss 1.655, Loss_clf 0.491, Loss_fe 0.635, Loss_kd 0.370, Train_accy 42.69
2022-09-28 05:07:40,896 [foster.py] => Task 1, Epoch 24/34 => Loss 1.592, Loss_clf 0.457, Loss_fe 0.611, Loss_kd 0.367, Train_accy 44.66
2022-09-28 05:07:42,659 [foster.py] => Task 1, Epoch 25/34 => Loss 1.600, Loss_clf 0.469, Loss_fe 0.616, Loss_kd 0.361, Train_accy 44.40
2022-09-28 05:07:45,097 [foster.py] => Task 1, Epoch 26/34 => Loss 1.606, Loss_clf 0.470, Loss_fe 0.606, Loss_kd 0.371, Train_accy 45.32, Test_accy 62.56
2022-09-28 05:07:46,866 [foster.py] => Task 1, Epoch 27/34 => Loss 1.588, Loss_clf 0.458, Loss_fe 0.605, Loss_kd 0.368, Train_accy 44.40
2022-09-28 05:07:48,617 [foster.py] => Task 1, Epoch 28/34 => Loss 1.563, Loss_clf 0.437, Loss_fe 0.595, Loss_kd 0.372, Train_accy 45.59
2022-09-28 05:07:50,348 [foster.py] => Task 1, Epoch 29/34 => Loss 1.585, Loss_clf 0.453, Loss_fe 0.600, Loss_kd 0.373, Train_accy 45.72
2022-09-28 05:07:52,087 [foster.py] => Task 1, Epoch 30/34 => Loss 1.589, Loss_clf 0.459, Loss_fe 0.600, Loss_kd 0.371, Train_accy 45.45
2022-09-28 05:07:54,556 [foster.py] => Task 1, Epoch 31/34 => Loss 1.609, Loss_clf 0.470, Loss_fe 0.617, Loss_kd 0.366, Train_accy 45.32, Test_accy 63.44
2022-09-28 05:07:56,373 [foster.py] => Task 1, Epoch 32/34 => Loss 1.562, Loss_clf 0.445, Loss_fe 0.589, Loss_kd 0.370, Train_accy 45.19
2022-09-28 05:07:58,089 [foster.py] => Task 1, Epoch 33/34 => Loss 1.611, Loss_clf 0.469, Loss_fe 0.612, Loss_kd 0.372, Train_accy 44.01
2022-09-28 05:07:59,830 [foster.py] => Task 1, Epoch 34/34 => Loss 1.551, Loss_clf 0.447, Loss_fe 0.587, Loss_kd 0.362, Train_accy 45.45
2022-09-28 05:07:59,831 [foster.py] => do not weight align teacher!
2022-09-28 05:07:59,831 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 05:08:02,675 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.535,  Train_accy 17.00, Test_accy 58.15
2022-09-28 05:08:04,615 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.390,  Train_accy 18.18
2022-09-28 05:08:06,529 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.297,  Train_accy 18.84
2022-09-28 05:08:08,513 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.264,  Train_accy 19.10
2022-09-28 05:08:10,445 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.235,  Train_accy 19.50
2022-09-28 05:08:13,103 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.222,  Train_accy 19.50, Test_accy 58.59
2022-09-28 05:08:15,087 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.225,  Train_accy 20.95
2022-09-28 05:08:17,079 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.204,  Train_accy 20.82
2022-09-28 05:08:18,983 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.205,  Train_accy 21.21
2022-09-28 05:08:20,962 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.193,  Train_accy 21.21
2022-09-28 05:08:23,567 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.185,  Train_accy 22.13, Test_accy 58.15
2022-09-28 05:08:25,477 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.198,  Train_accy 20.95
2022-09-28 05:08:27,381 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.182,  Train_accy 22.79
2022-09-28 05:08:29,318 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.178,  Train_accy 22.53
2022-09-28 05:08:31,229 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.184,  Train_accy 22.66
2022-09-28 05:08:33,858 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.183,  Train_accy 22.13, Test_accy 58.59
2022-09-28 05:08:35,806 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.189,  Train_accy 22.66
2022-09-28 05:08:37,773 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.175,  Train_accy 22.00
2022-09-28 05:08:39,679 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.178,  Train_accy 21.61
2022-09-28 05:08:41,631 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.178,  Train_accy 22.53
2022-09-28 05:08:44,308 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.159,  Train_accy 22.66, Test_accy 58.59
2022-09-28 05:08:46,281 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.196,  Train_accy 23.58
2022-09-28 05:08:48,198 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.190,  Train_accy 21.87
2022-09-28 05:08:50,178 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.170,  Train_accy 22.27
2022-09-28 05:08:52,118 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.183,  Train_accy 23.58
2022-09-28 05:08:54,749 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.165,  Train_accy 21.61, Test_accy 58.15
2022-09-28 05:08:54,750 [foster.py] => do not weight align student!
2022-09-28 05:08:55,420 [foster.py] => darknet eval: 
2022-09-28 05:08:55,420 [foster.py] => CNN top1 curve: 58.15
2022-09-28 05:08:55,420 [foster.py] => CNN top5 curve: 98.68
2022-09-28 05:08:55,420 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 05:09:01,713 [foster.py] => Exemplar size: 200
2022-09-28 05:09:01,713 [trainer.py] => CNN: {'total': 63.44, 'old': 80.38, 'new': 24.64, 'base': 80.38, 'compound': 24.64}
2022-09-28 05:09:01,713 [trainer.py] => CNN top1 curve: [86.71, 63.44]
2022-09-28 05:09:01,713 [trainer.py] => CNN base curve: [86.71, 80.38]
2022-09-28 05:09:01,713 [trainer.py] => CNN old curve: [86.71, 80.38]
2022-09-28 05:09:01,713 [trainer.py] => CNN new curve: [0, 24.64]
2022-09-28 05:09:01,713 [trainer.py] => CNN compound curve: [0, 24.64]
2022-09-28 05:09:01,713 [trainer.py] => NME: {'total': 71.37, 'old': 79.75, 'new': 52.17, 'base': 79.75, 'compound': 52.17}
2022-09-28 05:09:01,713 [trainer.py] => NME top1 curve: [87.34, 71.37]
2022-09-28 05:09:01,713 [trainer.py] => NME base curve: [87.34, 79.75]
2022-09-28 05:09:01,713 [trainer.py] => NME old curve: [87.34, 79.75]
2022-09-28 05:09:01,713 [trainer.py] => NME new curve: [0, 52.17]
2022-09-28 05:09:01,713 [trainer.py] => NME compound curve: [0, 52.17]
2022-09-28 05:09:01,949 [foster.py] => Learning on 10-13
2022-09-28 05:09:01,949 [foster.py] => All params: 22378148
2022-09-28 05:09:01,949 [foster.py] => Trainable params: 11196506
2022-09-28 05:09:01,970 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 05:09:04,657 [foster.py] => Task 2, Epoch 1/34 => Loss 5.673, Loss_clf 2.317, Loss_fe 2.169, Loss_kd 0.913, Train_accy 37.82, Test_accy 52.25
2022-09-28 05:09:06,501 [foster.py] => Task 2, Epoch 2/34 => Loss 3.575, Loss_clf 0.952, Loss_fe 1.489, Loss_kd 0.873, Train_accy 44.85
2022-09-28 05:09:08,303 [foster.py] => Task 2, Epoch 3/34 => Loss 3.213, Loss_clf 0.806, Loss_fe 1.285, Loss_kd 0.863, Train_accy 36.00
2022-09-28 05:09:10,119 [foster.py] => Task 2, Epoch 4/34 => Loss 3.021, Loss_clf 0.729, Loss_fe 1.178, Loss_kd 0.857, Train_accy 34.30
2022-09-28 05:09:11,954 [foster.py] => Task 2, Epoch 5/34 => Loss 2.930, Loss_clf 0.715, Loss_fe 1.095, Loss_kd 0.861, Train_accy 39.88
2022-09-28 05:09:14,598 [foster.py] => Task 2, Epoch 6/34 => Loss 2.807, Loss_clf 0.683, Loss_fe 1.007, Loss_kd 0.859, Train_accy 38.67, Test_accy 51.56
2022-09-28 05:09:16,416 [foster.py] => Task 2, Epoch 7/34 => Loss 2.742, Loss_clf 0.662, Loss_fe 0.957, Loss_kd 0.865, Train_accy 36.85
2022-09-28 05:09:18,265 [foster.py] => Task 2, Epoch 8/34 => Loss 2.719, Loss_clf 0.665, Loss_fe 0.943, Loss_kd 0.854, Train_accy 37.33
2022-09-28 05:09:20,093 [foster.py] => Task 2, Epoch 9/34 => Loss 2.626, Loss_clf 0.639, Loss_fe 0.869, Loss_kd 0.861, Train_accy 39.52
2022-09-28 05:09:21,942 [foster.py] => Task 2, Epoch 10/34 => Loss 2.639, Loss_clf 0.665, Loss_fe 0.865, Loss_kd 0.853, Train_accy 37.94
2022-09-28 05:09:24,599 [foster.py] => Task 2, Epoch 11/34 => Loss 2.579, Loss_clf 0.644, Loss_fe 0.822, Loss_kd 0.856, Train_accy 36.61, Test_accy 52.25
2022-09-28 05:09:26,405 [foster.py] => Task 2, Epoch 12/34 => Loss 2.511, Loss_clf 0.604, Loss_fe 0.786, Loss_kd 0.863, Train_accy 37.82
2022-09-28 05:09:28,208 [foster.py] => Task 2, Epoch 13/34 => Loss 2.483, Loss_clf 0.605, Loss_fe 0.760, Loss_kd 0.859, Train_accy 40.85
2022-09-28 05:09:30,067 [foster.py] => Task 2, Epoch 14/34 => Loss 2.452, Loss_clf 0.585, Loss_fe 0.748, Loss_kd 0.861, Train_accy 39.88
2022-09-28 05:09:31,927 [foster.py] => Task 2, Epoch 15/34 => Loss 2.419, Loss_clf 0.581, Loss_fe 0.734, Loss_kd 0.849, Train_accy 42.18
2022-09-28 05:09:34,583 [foster.py] => Task 2, Epoch 16/34 => Loss 2.421, Loss_clf 0.575, Loss_fe 0.723, Loss_kd 0.864, Train_accy 42.55, Test_accy 51.90
2022-09-28 05:09:36,435 [foster.py] => Task 2, Epoch 17/34 => Loss 2.391, Loss_clf 0.572, Loss_fe 0.701, Loss_kd 0.860, Train_accy 39.88
2022-09-28 05:09:38,319 [foster.py] => Task 2, Epoch 18/34 => Loss 2.389, Loss_clf 0.562, Loss_fe 0.701, Loss_kd 0.866, Train_accy 40.61
2022-09-28 05:09:40,159 [foster.py] => Task 2, Epoch 19/34 => Loss 2.336, Loss_clf 0.544, Loss_fe 0.674, Loss_kd 0.859, Train_accy 42.30
2022-09-28 05:09:41,970 [foster.py] => Task 2, Epoch 20/34 => Loss 2.349, Loss_clf 0.552, Loss_fe 0.672, Loss_kd 0.866, Train_accy 40.48
2022-09-28 05:09:44,619 [foster.py] => Task 2, Epoch 21/34 => Loss 2.308, Loss_clf 0.535, Loss_fe 0.655, Loss_kd 0.860, Train_accy 41.82, Test_accy 52.25
2022-09-28 05:09:46,488 [foster.py] => Task 2, Epoch 22/34 => Loss 2.303, Loss_clf 0.528, Loss_fe 0.650, Loss_kd 0.865, Train_accy 43.88
2022-09-28 05:09:48,371 [foster.py] => Task 2, Epoch 23/34 => Loss 2.334, Loss_clf 0.539, Loss_fe 0.668, Loss_kd 0.867, Train_accy 39.64
2022-09-28 05:09:50,177 [foster.py] => Task 2, Epoch 24/34 => Loss 2.306, Loss_clf 0.530, Loss_fe 0.647, Loss_kd 0.868, Train_accy 42.06
2022-09-28 05:09:51,990 [foster.py] => Task 2, Epoch 25/34 => Loss 2.261, Loss_clf 0.515, Loss_fe 0.632, Loss_kd 0.858, Train_accy 40.97
2022-09-28 05:09:54,610 [foster.py] => Task 2, Epoch 26/34 => Loss 2.263, Loss_clf 0.511, Loss_fe 0.625, Loss_kd 0.866, Train_accy 42.18, Test_accy 52.60
2022-09-28 05:09:56,407 [foster.py] => Task 2, Epoch 27/34 => Loss 2.225, Loss_clf 0.497, Loss_fe 0.608, Loss_kd 0.862, Train_accy 42.55
2022-09-28 05:09:58,247 [foster.py] => Task 2, Epoch 28/34 => Loss 2.256, Loss_clf 0.508, Loss_fe 0.625, Loss_kd 0.863, Train_accy 42.06
2022-09-28 05:10:00,092 [foster.py] => Task 2, Epoch 29/34 => Loss 2.254, Loss_clf 0.509, Loss_fe 0.624, Loss_kd 0.862, Train_accy 42.18
2022-09-28 05:10:01,922 [foster.py] => Task 2, Epoch 30/34 => Loss 2.222, Loss_clf 0.493, Loss_fe 0.606, Loss_kd 0.863, Train_accy 43.03
2022-09-28 05:10:04,631 [foster.py] => Task 2, Epoch 31/34 => Loss 2.271, Loss_clf 0.516, Loss_fe 0.626, Loss_kd 0.869, Train_accy 41.82, Test_accy 52.25
2022-09-28 05:10:06,441 [foster.py] => Task 2, Epoch 32/34 => Loss 2.246, Loss_clf 0.512, Loss_fe 0.623, Loss_kd 0.855, Train_accy 42.55
2022-09-28 05:10:08,288 [foster.py] => Task 2, Epoch 33/34 => Loss 2.272, Loss_clf 0.523, Loss_fe 0.622, Loss_kd 0.867, Train_accy 42.91
2022-09-28 05:10:10,119 [foster.py] => Task 2, Epoch 34/34 => Loss 2.210, Loss_clf 0.491, Loss_fe 0.595, Loss_kd 0.865, Train_accy 42.55
2022-09-28 05:10:10,119 [foster.py] => do not weight align teacher!
2022-09-28 05:10:10,119 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 05:10:13,099 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.870,  Train_accy 16.24, Test_accy 46.02
2022-09-28 05:10:15,126 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.718,  Train_accy 16.85
2022-09-28 05:10:17,182 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.634,  Train_accy 17.33
2022-09-28 05:10:19,247 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.621,  Train_accy 17.58
2022-09-28 05:10:21,288 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.601,  Train_accy 17.94
2022-09-28 05:10:24,076 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.596,  Train_accy 18.30, Test_accy 47.06
2022-09-28 05:10:26,114 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.593,  Train_accy 17.45
2022-09-28 05:10:28,119 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.584,  Train_accy 17.82
2022-09-28 05:10:30,178 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.578,  Train_accy 18.06
2022-09-28 05:10:32,253 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.589,  Train_accy 18.42
2022-09-28 05:10:35,007 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.562,  Train_accy 18.30, Test_accy 47.40
2022-09-28 05:10:37,088 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.567,  Train_accy 18.55
2022-09-28 05:10:39,162 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.571,  Train_accy 18.91
2022-09-28 05:10:41,188 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.572,  Train_accy 18.67
2022-09-28 05:10:43,245 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.564,  Train_accy 18.67
2022-09-28 05:10:46,046 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.562,  Train_accy 19.15, Test_accy 47.40
2022-09-28 05:10:48,065 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.560,  Train_accy 19.15
2022-09-28 05:10:50,096 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.576,  Train_accy 20.36
2022-09-28 05:10:52,153 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.558,  Train_accy 19.15
2022-09-28 05:10:54,257 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.560,  Train_accy 19.15
2022-09-28 05:10:57,035 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.551,  Train_accy 18.67, Test_accy 47.40
2022-09-28 05:10:59,092 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.555,  Train_accy 19.39
2022-09-28 05:11:01,162 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.555,  Train_accy 18.67
2022-09-28 05:11:03,222 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.553,  Train_accy 18.91
2022-09-28 05:11:05,297 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.553,  Train_accy 18.18
2022-09-28 05:11:08,120 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.563,  Train_accy 19.39, Test_accy 47.40
2022-09-28 05:11:08,121 [foster.py] => do not weight align student!
2022-09-28 05:11:08,851 [foster.py] => darknet eval: 
2022-09-28 05:11:08,851 [foster.py] => CNN top1 curve: 47.4
2022-09-28 05:11:08,851 [foster.py] => CNN top5 curve: 96.89
2022-09-28 05:11:08,851 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 05:11:16,209 [foster.py] => Exemplar size: 260
2022-09-28 05:11:16,209 [trainer.py] => CNN: {'total': 52.25, 'old': 59.03, 'new': 27.42, 'base': 77.85, 'compound': 21.37}
2022-09-28 05:11:16,209 [trainer.py] => CNN top1 curve: [86.71, 63.44, 52.25]
2022-09-28 05:11:16,209 [trainer.py] => CNN base curve: [86.71, 80.38, 77.85]
2022-09-28 05:11:16,209 [trainer.py] => CNN old curve: [86.71, 80.38, 59.03]
2022-09-28 05:11:16,209 [trainer.py] => CNN new curve: [0, 24.64, 27.42]
2022-09-28 05:11:16,209 [trainer.py] => CNN compound curve: [0, 24.64, 21.37]
2022-09-28 05:11:16,209 [trainer.py] => NME: {'total': 61.94, 'old': 63.0, 'new': 58.06, 'base': 75.32, 'compound': 45.8}
2022-09-28 05:11:16,209 [trainer.py] => NME top1 curve: [87.34, 71.37, 61.94]
2022-09-28 05:11:16,209 [trainer.py] => NME base curve: [87.34, 79.75, 75.32]
2022-09-28 05:11:16,209 [trainer.py] => NME old curve: [87.34, 79.75, 63.0]
2022-09-28 05:11:16,209 [trainer.py] => NME new curve: [0, 52.17, 58.06]
2022-09-28 05:11:16,209 [trainer.py] => NME compound curve: [0, 52.17, 45.8]
2022-09-28 05:11:16,441 [foster.py] => Learning on 13-16
2022-09-28 05:11:16,442 [foster.py] => All params: 22384301
2022-09-28 05:11:16,442 [foster.py] => Trainable params: 11201120
2022-09-28 05:11:16,462 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 05:11:19,243 [foster.py] => Task 3, Epoch 1/34 => Loss 6.015, Loss_clf 2.110, Loss_fe 2.297, Loss_kd 1.307, Train_accy 43.52, Test_accy 46.91
2022-09-28 05:11:21,170 [foster.py] => Task 3, Epoch 2/34 => Loss 3.974, Loss_clf 0.866, Loss_fe 1.518, Loss_kd 1.292, Train_accy 48.41
2022-09-28 05:11:23,105 [foster.py] => Task 3, Epoch 3/34 => Loss 3.640, Loss_clf 0.753, Loss_fe 1.304, Loss_kd 1.286, Train_accy 47.39
2022-09-28 05:11:25,016 [foster.py] => Task 3, Epoch 4/34 => Loss 3.451, Loss_clf 0.709, Loss_fe 1.166, Loss_kd 1.280, Train_accy 47.16
2022-09-28 05:11:26,924 [foster.py] => Task 3, Epoch 5/34 => Loss 3.337, Loss_clf 0.684, Loss_fe 1.079, Loss_kd 1.278, Train_accy 48.41
2022-09-28 05:11:29,747 [foster.py] => Task 3, Epoch 6/34 => Loss 3.221, Loss_clf 0.649, Loss_fe 0.992, Loss_kd 1.284, Train_accy 48.41, Test_accy 46.35
2022-09-28 05:11:31,669 [foster.py] => Task 3, Epoch 7/34 => Loss 3.159, Loss_clf 0.628, Loss_fe 0.939, Loss_kd 1.294, Train_accy 48.41
2022-09-28 05:11:33,574 [foster.py] => Task 3, Epoch 8/34 => Loss 3.085, Loss_clf 0.616, Loss_fe 0.897, Loss_kd 1.277, Train_accy 48.07
2022-09-28 05:11:35,474 [foster.py] => Task 3, Epoch 9/34 => Loss 3.046, Loss_clf 0.612, Loss_fe 0.856, Loss_kd 1.282, Train_accy 53.18
2022-09-28 05:11:37,427 [foster.py] => Task 3, Epoch 10/34 => Loss 2.973, Loss_clf 0.596, Loss_fe 0.802, Loss_kd 1.280, Train_accy 51.93
2022-09-28 05:11:40,155 [foster.py] => Task 3, Epoch 11/34 => Loss 2.931, Loss_clf 0.575, Loss_fe 0.770, Loss_kd 1.289, Train_accy 54.09, Test_accy 47.47
2022-09-28 05:11:42,056 [foster.py] => Task 3, Epoch 12/34 => Loss 2.938, Loss_clf 0.583, Loss_fe 0.768, Loss_kd 1.289, Train_accy 49.20
2022-09-28 05:11:44,016 [foster.py] => Task 3, Epoch 13/34 => Loss 2.861, Loss_clf 0.558, Loss_fe 0.714, Loss_kd 1.291, Train_accy 53.18
2022-09-28 05:11:45,933 [foster.py] => Task 3, Epoch 14/34 => Loss 2.862, Loss_clf 0.568, Loss_fe 0.715, Loss_kd 1.283, Train_accy 52.27
2022-09-28 05:11:47,894 [foster.py] => Task 3, Epoch 15/34 => Loss 2.803, Loss_clf 0.534, Loss_fe 0.687, Loss_kd 1.286, Train_accy 54.20
2022-09-28 05:11:50,653 [foster.py] => Task 3, Epoch 16/34 => Loss 2.779, Loss_clf 0.533, Loss_fe 0.670, Loss_kd 1.281, Train_accy 54.20, Test_accy 47.47
2022-09-28 05:11:52,587 [foster.py] => Task 3, Epoch 17/34 => Loss 2.748, Loss_clf 0.516, Loss_fe 0.646, Loss_kd 1.288, Train_accy 54.66
2022-09-28 05:11:54,490 [foster.py] => Task 3, Epoch 18/34 => Loss 2.724, Loss_clf 0.508, Loss_fe 0.630, Loss_kd 1.288, Train_accy 54.55
2022-09-28 05:11:56,382 [foster.py] => Task 3, Epoch 19/34 => Loss 2.715, Loss_clf 0.503, Loss_fe 0.629, Loss_kd 1.286, Train_accy 55.11
2022-09-28 05:11:58,303 [foster.py] => Task 3, Epoch 20/34 => Loss 2.693, Loss_clf 0.503, Loss_fe 0.615, Loss_kd 1.280, Train_accy 56.93
2022-09-28 05:12:01,054 [foster.py] => Task 3, Epoch 21/34 => Loss 2.712, Loss_clf 0.510, Loss_fe 0.617, Loss_kd 1.287, Train_accy 57.16, Test_accy 48.31
2022-09-28 05:12:02,982 [foster.py] => Task 3, Epoch 22/34 => Loss 2.729, Loss_clf 0.515, Loss_fe 0.627, Loss_kd 1.289, Train_accy 55.00
2022-09-28 05:12:04,885 [foster.py] => Task 3, Epoch 23/34 => Loss 2.657, Loss_clf 0.485, Loss_fe 0.593, Loss_kd 1.283, Train_accy 56.36
2022-09-28 05:12:06,764 [foster.py] => Task 3, Epoch 24/34 => Loss 2.681, Loss_clf 0.494, Loss_fe 0.609, Loss_kd 1.282, Train_accy 55.23
2022-09-28 05:12:08,699 [foster.py] => Task 3, Epoch 25/34 => Loss 2.680, Loss_clf 0.498, Loss_fe 0.602, Loss_kd 1.284, Train_accy 57.05
2022-09-28 05:12:11,505 [foster.py] => Task 3, Epoch 26/34 => Loss 2.678, Loss_clf 0.499, Loss_fe 0.600, Loss_kd 1.283, Train_accy 54.32, Test_accy 48.31
2022-09-28 05:12:13,429 [foster.py] => Task 3, Epoch 27/34 => Loss 2.676, Loss_clf 0.510, Loss_fe 0.590, Loss_kd 1.280, Train_accy 56.36
2022-09-28 05:12:15,383 [foster.py] => Task 3, Epoch 28/34 => Loss 2.651, Loss_clf 0.492, Loss_fe 0.588, Loss_kd 1.277, Train_accy 54.43
2022-09-28 05:12:17,308 [foster.py] => Task 3, Epoch 29/34 => Loss 2.643, Loss_clf 0.489, Loss_fe 0.584, Loss_kd 1.276, Train_accy 56.82
2022-09-28 05:12:19,239 [foster.py] => Task 3, Epoch 30/34 => Loss 2.669, Loss_clf 0.492, Loss_fe 0.593, Loss_kd 1.287, Train_accy 56.25
2022-09-28 05:12:22,029 [foster.py] => Task 3, Epoch 31/34 => Loss 2.635, Loss_clf 0.474, Loss_fe 0.573, Loss_kd 1.290, Train_accy 56.82, Test_accy 48.31
2022-09-28 05:12:23,964 [foster.py] => Task 3, Epoch 32/34 => Loss 2.671, Loss_clf 0.492, Loss_fe 0.588, Loss_kd 1.293, Train_accy 54.66
2022-09-28 05:12:25,834 [foster.py] => Task 3, Epoch 33/34 => Loss 2.651, Loss_clf 0.486, Loss_fe 0.587, Loss_kd 1.282, Train_accy 55.11
2022-09-28 05:12:27,718 [foster.py] => Task 3, Epoch 34/34 => Loss 2.664, Loss_clf 0.492, Loss_fe 0.588, Loss_kd 1.287, Train_accy 57.16
2022-09-28 05:12:27,719 [foster.py] => do not weight align teacher!
2022-09-28 05:12:27,719 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 05:12:30,825 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.145,  Train_accy 16.93, Test_accy 38.76
2022-09-28 05:12:32,982 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.063,  Train_accy 17.16
2022-09-28 05:12:35,103 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.009,  Train_accy 17.61
2022-09-28 05:12:37,234 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 1.997,  Train_accy 17.61
2022-09-28 05:12:39,402 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.966,  Train_accy 17.50
2022-09-28 05:12:42,314 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.966,  Train_accy 17.50, Test_accy 39.33
2022-09-28 05:12:44,468 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.952,  Train_accy 18.52
2022-09-28 05:12:46,586 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.959,  Train_accy 17.95
2022-09-28 05:12:48,714 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.938,  Train_accy 19.09
2022-09-28 05:12:50,849 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.929,  Train_accy 19.20
2022-09-28 05:12:53,727 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.936,  Train_accy 18.98, Test_accy 39.04
2022-09-28 05:12:55,883 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.929,  Train_accy 20.34
2022-09-28 05:12:58,007 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.922,  Train_accy 19.89
2022-09-28 05:13:00,171 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.920,  Train_accy 19.77
2022-09-28 05:13:02,383 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.917,  Train_accy 21.48
2022-09-28 05:13:05,310 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.917,  Train_accy 21.25, Test_accy 40.17
2022-09-28 05:13:07,472 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.919,  Train_accy 21.59
2022-09-28 05:13:09,602 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.920,  Train_accy 22.39
2022-09-28 05:13:11,770 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.906,  Train_accy 22.39
2022-09-28 05:13:13,921 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.912,  Train_accy 21.59
2022-09-28 05:13:16,812 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.900,  Train_accy 21.59, Test_accy 40.45
2022-09-28 05:13:18,936 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.908,  Train_accy 21.70
2022-09-28 05:13:21,079 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.918,  Train_accy 21.36
2022-09-28 05:13:23,230 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.902,  Train_accy 21.14
2022-09-28 05:13:25,352 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.914,  Train_accy 21.48
2022-09-28 05:13:28,281 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.901,  Train_accy 22.16, Test_accy 40.17
2022-09-28 05:13:28,281 [foster.py] => do not weight align student!
2022-09-28 05:13:29,045 [foster.py] => darknet eval: 
2022-09-28 05:13:29,046 [foster.py] => CNN top1 curve: 40.17
2022-09-28 05:13:29,046 [foster.py] => CNN top5 curve: 93.26
2022-09-28 05:13:29,046 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 05:13:37,551 [foster.py] => Exemplar size: 320
2022-09-28 05:13:37,552 [trainer.py] => CNN: {'total': 48.31, 'old': 50.52, 'new': 38.81, 'base': 76.58, 'compound': 25.76}
2022-09-28 05:13:37,552 [trainer.py] => CNN top1 curve: [86.71, 63.44, 52.25, 48.31]
2022-09-28 05:13:37,552 [trainer.py] => CNN base curve: [86.71, 80.38, 77.85, 76.58]
2022-09-28 05:13:37,552 [trainer.py] => CNN old curve: [86.71, 80.38, 59.03, 50.52]
2022-09-28 05:13:37,552 [trainer.py] => CNN new curve: [0, 24.64, 27.42, 38.81]
2022-09-28 05:13:37,552 [trainer.py] => CNN compound curve: [0, 24.64, 21.37, 25.76]
2022-09-28 05:13:37,552 [trainer.py] => NME: {'total': 61.52, 'old': 58.13, 'new': 76.12, 'base': 72.78, 'compound': 52.53}
2022-09-28 05:13:37,552 [trainer.py] => NME top1 curve: [87.34, 71.37, 61.94, 61.52]
2022-09-28 05:13:37,552 [trainer.py] => NME base curve: [87.34, 79.75, 75.32, 72.78]
2022-09-28 05:13:37,552 [trainer.py] => NME old curve: [87.34, 79.75, 63.0, 58.13]
2022-09-28 05:13:37,552 [trainer.py] => NME new curve: [0, 52.17, 58.06, 76.12]
2022-09-28 05:13:37,552 [trainer.py] => NME compound curve: [0, 52.17, 45.8, 52.53]
2022-09-28 05:13:37,785 [foster.py] => Learning on 16-19
2022-09-28 05:13:37,785 [foster.py] => All params: 22390454
2022-09-28 05:13:37,786 [foster.py] => Trainable params: 11205734
2022-09-28 05:13:37,806 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 05:13:40,706 [foster.py] => Task 4, Epoch 1/34 => Loss 6.561, Loss_clf 2.003, Loss_fe 2.513, Loss_kd 1.722, Train_accy 39.31, Test_accy 43.15
2022-09-28 05:13:42,713 [foster.py] => Task 4, Epoch 2/34 => Loss 4.872, Loss_clf 0.984, Loss_fe 1.828, Loss_kd 1.735, Train_accy 46.98
2022-09-28 05:13:44,662 [foster.py] => Task 4, Epoch 3/34 => Loss 4.522, Loss_clf 0.885, Loss_fe 1.579, Loss_kd 1.734, Train_accy 52.70
2022-09-28 05:13:46,648 [foster.py] => Task 4, Epoch 4/34 => Loss 4.292, Loss_clf 0.821, Loss_fe 1.409, Loss_kd 1.737, Train_accy 54.43
2022-09-28 05:13:48,679 [foster.py] => Task 4, Epoch 5/34 => Loss 4.156, Loss_clf 0.806, Loss_fe 1.303, Loss_kd 1.724, Train_accy 52.81
2022-09-28 05:13:51,568 [foster.py] => Task 4, Epoch 6/34 => Loss 4.029, Loss_clf 0.766, Loss_fe 1.208, Loss_kd 1.730, Train_accy 56.05, Test_accy 50.00
2022-09-28 05:13:53,534 [foster.py] => Task 4, Epoch 7/34 => Loss 3.962, Loss_clf 0.759, Loss_fe 1.134, Loss_kd 1.743, Train_accy 57.02
2022-09-28 05:13:55,524 [foster.py] => Task 4, Epoch 8/34 => Loss 3.850, Loss_clf 0.725, Loss_fe 1.065, Loss_kd 1.734, Train_accy 54.64
2022-09-28 05:13:57,489 [foster.py] => Task 4, Epoch 9/34 => Loss 3.803, Loss_clf 0.720, Loss_fe 1.023, Loss_kd 1.734, Train_accy 56.70
2022-09-28 05:13:59,487 [foster.py] => Task 4, Epoch 10/34 => Loss 3.741, Loss_clf 0.689, Loss_fe 0.979, Loss_kd 1.746, Train_accy 57.02
2022-09-28 05:14:02,473 [foster.py] => Task 4, Epoch 11/34 => Loss 3.684, Loss_clf 0.679, Loss_fe 0.938, Loss_kd 1.740, Train_accy 56.70, Test_accy 51.37
2022-09-28 05:14:04,452 [foster.py] => Task 4, Epoch 12/34 => Loss 3.669, Loss_clf 0.682, Loss_fe 0.915, Loss_kd 1.745, Train_accy 57.02
2022-09-28 05:14:06,458 [foster.py] => Task 4, Epoch 13/34 => Loss 3.582, Loss_clf 0.646, Loss_fe 0.873, Loss_kd 1.737, Train_accy 57.67
2022-09-28 05:14:08,459 [foster.py] => Task 4, Epoch 14/34 => Loss 3.522, Loss_clf 0.625, Loss_fe 0.829, Loss_kd 1.742, Train_accy 60.80
2022-09-28 05:14:10,506 [foster.py] => Task 4, Epoch 15/34 => Loss 3.525, Loss_clf 0.631, Loss_fe 0.834, Loss_kd 1.734, Train_accy 58.42
2022-09-28 05:14:13,374 [foster.py] => Task 4, Epoch 16/34 => Loss 3.518, Loss_clf 0.631, Loss_fe 0.818, Loss_kd 1.742, Train_accy 60.37, Test_accy 51.37
2022-09-28 05:14:15,420 [foster.py] => Task 4, Epoch 17/34 => Loss 3.510, Loss_clf 0.631, Loss_fe 0.805, Loss_kd 1.747, Train_accy 58.96
2022-09-28 05:14:17,414 [foster.py] => Task 4, Epoch 18/34 => Loss 3.442, Loss_clf 0.611, Loss_fe 0.768, Loss_kd 1.737, Train_accy 60.37
2022-09-28 05:14:19,447 [foster.py] => Task 4, Epoch 19/34 => Loss 3.445, Loss_clf 0.606, Loss_fe 0.766, Loss_kd 1.745, Train_accy 60.04
2022-09-28 05:14:21,443 [foster.py] => Task 4, Epoch 20/34 => Loss 3.404, Loss_clf 0.589, Loss_fe 0.757, Loss_kd 1.733, Train_accy 61.34
2022-09-28 05:14:24,376 [foster.py] => Task 4, Epoch 21/34 => Loss 3.386, Loss_clf 0.582, Loss_fe 0.729, Loss_kd 1.747, Train_accy 61.02, Test_accy 51.60
2022-09-28 05:14:26,387 [foster.py] => Task 4, Epoch 22/34 => Loss 3.399, Loss_clf 0.586, Loss_fe 0.737, Loss_kd 1.749, Train_accy 60.58
2022-09-28 05:14:28,351 [foster.py] => Task 4, Epoch 23/34 => Loss 3.372, Loss_clf 0.581, Loss_fe 0.728, Loss_kd 1.737, Train_accy 61.23
2022-09-28 05:14:30,334 [foster.py] => Task 4, Epoch 24/34 => Loss 3.366, Loss_clf 0.576, Loss_fe 0.718, Loss_kd 1.746, Train_accy 61.77
2022-09-28 05:14:32,326 [foster.py] => Task 4, Epoch 25/34 => Loss 3.380, Loss_clf 0.589, Loss_fe 0.719, Loss_kd 1.745, Train_accy 60.26
2022-09-28 05:14:35,214 [foster.py] => Task 4, Epoch 26/34 => Loss 3.349, Loss_clf 0.578, Loss_fe 0.700, Loss_kd 1.744, Train_accy 58.32, Test_accy 51.60
2022-09-28 05:14:37,216 [foster.py] => Task 4, Epoch 27/34 => Loss 3.357, Loss_clf 0.577, Loss_fe 0.703, Loss_kd 1.749, Train_accy 62.10
2022-09-28 05:14:39,257 [foster.py] => Task 4, Epoch 28/34 => Loss 3.319, Loss_clf 0.553, Loss_fe 0.690, Loss_kd 1.748, Train_accy 62.63
2022-09-28 05:14:41,252 [foster.py] => Task 4, Epoch 29/34 => Loss 3.346, Loss_clf 0.571, Loss_fe 0.705, Loss_kd 1.743, Train_accy 60.91
2022-09-28 05:14:43,236 [foster.py] => Task 4, Epoch 30/34 => Loss 3.360, Loss_clf 0.586, Loss_fe 0.702, Loss_kd 1.745, Train_accy 61.99
2022-09-28 05:14:46,162 [foster.py] => Task 4, Epoch 31/34 => Loss 3.325, Loss_clf 0.567, Loss_fe 0.684, Loss_kd 1.747, Train_accy 60.80, Test_accy 51.37
2022-09-28 05:14:48,141 [foster.py] => Task 4, Epoch 32/34 => Loss 3.325, Loss_clf 0.559, Loss_fe 0.695, Loss_kd 1.744, Train_accy 60.58
2022-09-28 05:14:50,146 [foster.py] => Task 4, Epoch 33/34 => Loss 3.303, Loss_clf 0.557, Loss_fe 0.683, Loss_kd 1.738, Train_accy 61.45
2022-09-28 05:14:52,138 [foster.py] => Task 4, Epoch 34/34 => Loss 3.340, Loss_clf 0.566, Loss_fe 0.702, Loss_kd 1.745, Train_accy 62.31
2022-09-28 05:14:52,138 [foster.py] => do not weight align teacher!
2022-09-28 05:14:52,139 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 05:14:55,459 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.459,  Train_accy 15.44, Test_accy 30.82
2022-09-28 05:14:57,656 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.393,  Train_accy 16.74
2022-09-28 05:14:59,900 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.338,  Train_accy 17.93
2022-09-28 05:15:02,140 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.317,  Train_accy 17.71
2022-09-28 05:15:04,345 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.314,  Train_accy 18.03
2022-09-28 05:15:07,358 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.292,  Train_accy 18.68, Test_accy 36.07
2022-09-28 05:15:09,592 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.291,  Train_accy 18.68
2022-09-28 05:15:11,794 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.287,  Train_accy 18.79
2022-09-28 05:15:14,056 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.284,  Train_accy 18.68
2022-09-28 05:15:16,273 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.279,  Train_accy 18.90
2022-09-28 05:15:19,356 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.268,  Train_accy 19.22, Test_accy 36.30
2022-09-28 05:15:21,599 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.281,  Train_accy 20.63
2022-09-28 05:15:23,816 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.267,  Train_accy 19.55
2022-09-28 05:15:26,033 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.264,  Train_accy 20.63
2022-09-28 05:15:28,273 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.264,  Train_accy 20.63
2022-09-28 05:15:31,317 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.265,  Train_accy 20.84, Test_accy 38.13
2022-09-28 05:15:33,547 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.257,  Train_accy 21.92
2022-09-28 05:15:35,797 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.258,  Train_accy 20.09
2022-09-28 05:15:38,038 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.254,  Train_accy 21.27
2022-09-28 05:15:40,325 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.265,  Train_accy 20.84
2022-09-28 05:15:43,390 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.256,  Train_accy 22.03, Test_accy 38.36
2022-09-28 05:15:45,583 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.251,  Train_accy 21.92
2022-09-28 05:15:47,865 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.258,  Train_accy 21.92
2022-09-28 05:15:50,155 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.258,  Train_accy 21.38
2022-09-28 05:15:52,387 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.261,  Train_accy 20.73
2022-09-28 05:15:55,398 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.256,  Train_accy 21.81, Test_accy 37.44
2022-09-28 05:15:55,398 [foster.py] => do not weight align student!
2022-09-28 05:15:56,253 [foster.py] => darknet eval: 
2022-09-28 05:15:56,253 [foster.py] => CNN top1 curve: 37.44
2022-09-28 05:15:56,253 [foster.py] => CNN top5 curve: 84.7
2022-09-28 05:15:56,254 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 05:16:05,785 [foster.py] => Exemplar size: 380
2022-09-28 05:16:05,785 [trainer.py] => CNN: {'total': 51.37, 'old': 49.72, 'new': 58.54, 'base': 70.25, 'compound': 40.71}
2022-09-28 05:16:05,785 [trainer.py] => CNN top1 curve: [86.71, 63.44, 52.25, 48.31, 51.37]
2022-09-28 05:16:05,785 [trainer.py] => CNN base curve: [86.71, 80.38, 77.85, 76.58, 70.25]
2022-09-28 05:16:05,785 [trainer.py] => CNN old curve: [86.71, 80.38, 59.03, 50.52, 49.72]
2022-09-28 05:16:05,785 [trainer.py] => CNN new curve: [0, 24.64, 27.42, 38.81, 58.54]
2022-09-28 05:16:05,785 [trainer.py] => CNN compound curve: [0, 24.64, 21.37, 25.76, 40.71]
2022-09-28 05:16:05,785 [trainer.py] => NME: {'total': 61.42, 'old': 59.55, 'new': 69.51, 'base': 69.62, 'compound': 56.79}
2022-09-28 05:16:05,785 [trainer.py] => NME top1 curve: [87.34, 71.37, 61.94, 61.52, 61.42]
2022-09-28 05:16:05,785 [trainer.py] => NME base curve: [87.34, 79.75, 75.32, 72.78, 69.62]
2022-09-28 05:16:05,785 [trainer.py] => NME old curve: [87.34, 79.75, 63.0, 58.13, 59.55]
2022-09-28 05:16:05,785 [trainer.py] => NME new curve: [0, 52.17, 58.06, 76.12, 69.51]
2022-09-28 05:16:05,785 [trainer.py] => NME compound curve: [0, 52.17, 45.8, 52.53, 56.79]
2022-09-28 05:16:06,020 [foster.py] => Learning on 19-22
2022-09-28 05:16:06,020 [foster.py] => All params: 22396607
2022-09-28 05:16:06,021 [foster.py] => Trainable params: 11210348
2022-09-28 05:16:06,042 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 05:16:09,126 [foster.py] => Task 5, Epoch 1/34 => Loss 6.573, Loss_clf 1.821, Loss_fe 2.454, Loss_kd 1.985, Train_accy 38.12, Test_accy 39.41
2022-09-28 05:16:11,199 [foster.py] => Task 5, Epoch 2/34 => Loss 5.353, Loss_clf 1.154, Loss_fe 1.881, Loss_kd 2.002, Train_accy 40.52
2022-09-28 05:16:13,287 [foster.py] => Task 5, Epoch 3/34 => Loss 5.047, Loss_clf 1.067, Loss_fe 1.676, Loss_kd 1.990, Train_accy 41.72
2022-09-28 05:16:15,401 [foster.py] => Task 5, Epoch 4/34 => Loss 4.901, Loss_clf 1.025, Loss_fe 1.561, Loss_kd 1.999, Train_accy 43.31
2022-09-28 05:16:17,525 [foster.py] => Task 5, Epoch 5/34 => Loss 4.745, Loss_clf 1.008, Loss_fe 1.438, Loss_kd 1.985, Train_accy 42.61
2022-09-28 05:16:20,602 [foster.py] => Task 5, Epoch 6/34 => Loss 4.649, Loss_clf 0.970, Loss_fe 1.377, Loss_kd 1.988, Train_accy 44.91, Test_accy 42.77
2022-09-28 05:16:22,673 [foster.py] => Task 5, Epoch 7/34 => Loss 4.571, Loss_clf 0.954, Loss_fe 1.313, Loss_kd 1.990, Train_accy 40.92
2022-09-28 05:16:24,792 [foster.py] => Task 5, Epoch 8/34 => Loss 4.537, Loss_clf 0.955, Loss_fe 1.270, Loss_kd 1.997, Train_accy 43.41
2022-09-28 05:16:26,883 [foster.py] => Task 5, Epoch 9/34 => Loss 4.424, Loss_clf 0.912, Loss_fe 1.196, Loss_kd 2.001, Train_accy 45.91
2022-09-28 05:16:28,976 [foster.py] => Task 5, Epoch 10/34 => Loss 4.376, Loss_clf 0.897, Loss_fe 1.162, Loss_kd 2.001, Train_accy 44.61
2022-09-28 05:16:32,050 [foster.py] => Task 5, Epoch 11/34 => Loss 4.338, Loss_clf 0.890, Loss_fe 1.140, Loss_kd 1.993, Train_accy 45.41, Test_accy 44.75
2022-09-28 05:16:34,153 [foster.py] => Task 5, Epoch 12/34 => Loss 4.370, Loss_clf 0.916, Loss_fe 1.138, Loss_kd 2.000, Train_accy 44.61
2022-09-28 05:16:36,270 [foster.py] => Task 5, Epoch 13/34 => Loss 4.320, Loss_clf 0.901, Loss_fe 1.101, Loss_kd 2.002, Train_accy 44.61
2022-09-28 05:16:38,335 [foster.py] => Task 5, Epoch 14/34 => Loss 4.223, Loss_clf 0.852, Loss_fe 1.049, Loss_kd 2.005, Train_accy 46.01
2022-09-28 05:16:40,437 [foster.py] => Task 5, Epoch 15/34 => Loss 4.254, Loss_clf 0.875, Loss_fe 1.059, Loss_kd 2.003, Train_accy 45.61
2022-09-28 05:16:43,565 [foster.py] => Task 5, Epoch 16/34 => Loss 4.210, Loss_clf 0.858, Loss_fe 1.031, Loss_kd 2.004, Train_accy 44.41, Test_accy 44.55
2022-09-28 05:16:45,671 [foster.py] => Task 5, Epoch 17/34 => Loss 4.170, Loss_clf 0.839, Loss_fe 1.017, Loss_kd 1.999, Train_accy 46.61
2022-09-28 05:16:47,773 [foster.py] => Task 5, Epoch 18/34 => Loss 4.148, Loss_clf 0.842, Loss_fe 1.000, Loss_kd 1.992, Train_accy 43.81
2022-09-28 05:16:49,897 [foster.py] => Task 5, Epoch 19/34 => Loss 4.091, Loss_clf 0.810, Loss_fe 0.962, Loss_kd 2.003, Train_accy 46.41
2022-09-28 05:16:51,955 [foster.py] => Task 5, Epoch 20/34 => Loss 4.134, Loss_clf 0.829, Loss_fe 0.983, Loss_kd 2.005, Train_accy 45.11
2022-09-28 05:16:55,048 [foster.py] => Task 5, Epoch 21/34 => Loss 4.127, Loss_clf 0.831, Loss_fe 0.971, Loss_kd 2.008, Train_accy 47.01, Test_accy 44.95
2022-09-28 05:16:57,121 [foster.py] => Task 5, Epoch 22/34 => Loss 4.079, Loss_clf 0.809, Loss_fe 0.950, Loss_kd 2.004, Train_accy 46.11
2022-09-28 05:16:59,183 [foster.py] => Task 5, Epoch 23/34 => Loss 4.090, Loss_clf 0.816, Loss_fe 0.947, Loss_kd 2.009, Train_accy 46.41
2022-09-28 05:17:01,327 [foster.py] => Task 5, Epoch 24/34 => Loss 4.065, Loss_clf 0.803, Loss_fe 0.943, Loss_kd 2.003, Train_accy 47.90
2022-09-28 05:17:03,418 [foster.py] => Task 5, Epoch 25/34 => Loss 4.054, Loss_clf 0.805, Loss_fe 0.935, Loss_kd 1.998, Train_accy 45.51
2022-09-28 05:17:06,544 [foster.py] => Task 5, Epoch 26/34 => Loss 4.027, Loss_clf 0.788, Loss_fe 0.914, Loss_kd 2.008, Train_accy 47.90, Test_accy 45.94
2022-09-28 05:17:08,646 [foster.py] => Task 5, Epoch 27/34 => Loss 4.029, Loss_clf 0.784, Loss_fe 0.920, Loss_kd 2.008, Train_accy 47.31
2022-09-28 05:17:10,738 [foster.py] => Task 5, Epoch 28/34 => Loss 4.063, Loss_clf 0.799, Loss_fe 0.933, Loss_kd 2.013, Train_accy 47.60
2022-09-28 05:17:12,879 [foster.py] => Task 5, Epoch 29/34 => Loss 4.025, Loss_clf 0.789, Loss_fe 0.912, Loss_kd 2.007, Train_accy 46.91
2022-09-28 05:17:14,994 [foster.py] => Task 5, Epoch 30/34 => Loss 4.046, Loss_clf 0.803, Loss_fe 0.926, Loss_kd 2.002, Train_accy 46.81
2022-09-28 05:17:18,070 [foster.py] => Task 5, Epoch 31/34 => Loss 4.023, Loss_clf 0.779, Loss_fe 0.921, Loss_kd 2.006, Train_accy 47.31, Test_accy 45.15
2022-09-28 05:17:20,151 [foster.py] => Task 5, Epoch 32/34 => Loss 4.017, Loss_clf 0.791, Loss_fe 0.901, Loss_kd 2.008, Train_accy 47.70
2022-09-28 05:17:22,270 [foster.py] => Task 5, Epoch 33/34 => Loss 4.098, Loss_clf 0.820, Loss_fe 0.957, Loss_kd 2.004, Train_accy 46.91
2022-09-28 05:17:24,416 [foster.py] => Task 5, Epoch 34/34 => Loss 4.023, Loss_clf 0.795, Loss_fe 0.908, Loss_kd 2.004, Train_accy 47.90
2022-09-28 05:17:24,416 [foster.py] => do not weight align teacher!
2022-09-28 05:17:24,416 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 05:17:27,860 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.513,  Train_accy 18.66, Test_accy 34.85
2022-09-28 05:17:30,201 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.483,  Train_accy 19.36
2022-09-28 05:17:32,616 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.478,  Train_accy 19.56
2022-09-28 05:17:35,032 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.464,  Train_accy 19.46
2022-09-28 05:17:37,379 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.464,  Train_accy 20.16
2022-09-28 05:17:40,651 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.452,  Train_accy 19.96, Test_accy 35.25
2022-09-28 05:17:43,122 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.462,  Train_accy 20.36
2022-09-28 05:17:45,475 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.454,  Train_accy 19.86
2022-09-28 05:17:47,838 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.448,  Train_accy 19.66
2022-09-28 05:17:50,251 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.451,  Train_accy 20.56
2022-09-28 05:17:53,444 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.446,  Train_accy 20.36, Test_accy 38.42
2022-09-28 05:17:55,824 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.444,  Train_accy 20.26
2022-09-28 05:17:58,162 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.436,  Train_accy 20.66
2022-09-28 05:18:00,531 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.438,  Train_accy 20.96
2022-09-28 05:18:02,875 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.439,  Train_accy 21.16
2022-09-28 05:18:06,125 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.441,  Train_accy 21.06, Test_accy 38.81
2022-09-28 05:18:08,507 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.444,  Train_accy 19.46
2022-09-28 05:18:10,863 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.445,  Train_accy 20.56
2022-09-28 05:18:13,188 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.438,  Train_accy 20.56
2022-09-28 05:18:15,569 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.440,  Train_accy 21.46
2022-09-28 05:18:18,754 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.435,  Train_accy 20.56, Test_accy 38.42
2022-09-28 05:18:21,146 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.437,  Train_accy 19.66
2022-09-28 05:18:23,518 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.431,  Train_accy 20.16
2022-09-28 05:18:25,858 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.431,  Train_accy 20.76
2022-09-28 05:18:28,253 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.440,  Train_accy 20.86
2022-09-28 05:18:31,443 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.447,  Train_accy 20.66, Test_accy 39.80
2022-09-28 05:18:31,443 [foster.py] => do not weight align student!
2022-09-28 05:18:32,323 [foster.py] => darknet eval: 
2022-09-28 05:18:32,324 [foster.py] => CNN top1 curve: 39.8
2022-09-28 05:18:32,324 [foster.py] => CNN top5 curve: 82.77
2022-09-28 05:18:32,324 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 05:18:43,009 [foster.py] => Exemplar size: 440
2022-09-28 05:18:43,009 [trainer.py] => CNN: {'total': 45.94, 'old': 48.17, 'new': 31.34, 'base': 70.89, 'compound': 34.58}
2022-09-28 05:18:43,010 [trainer.py] => CNN top1 curve: [86.71, 63.44, 52.25, 48.31, 51.37, 45.94]
2022-09-28 05:18:43,010 [trainer.py] => CNN base curve: [86.71, 80.38, 77.85, 76.58, 70.25, 70.89]
2022-09-28 05:18:43,010 [trainer.py] => CNN old curve: [86.71, 80.38, 59.03, 50.52, 49.72, 48.17]
2022-09-28 05:18:43,010 [trainer.py] => CNN new curve: [0, 24.64, 27.42, 38.81, 58.54, 31.34]
2022-09-28 05:18:43,010 [trainer.py] => CNN compound curve: [0, 24.64, 21.37, 25.76, 40.71, 34.58]
2022-09-28 05:18:43,010 [trainer.py] => NME: {'total': 51.88, 'old': 53.65, 'new': 40.3, 'base': 67.09, 'compound': 44.96}
2022-09-28 05:18:43,010 [trainer.py] => NME top1 curve: [87.34, 71.37, 61.94, 61.52, 61.42, 51.88]
2022-09-28 05:18:43,010 [trainer.py] => NME base curve: [87.34, 79.75, 75.32, 72.78, 69.62, 67.09]
2022-09-28 05:18:43,010 [trainer.py] => NME old curve: [87.34, 79.75, 63.0, 58.13, 59.55, 53.65]
2022-09-28 05:18:43,010 [trainer.py] => NME new curve: [0, 52.17, 58.06, 76.12, 69.51, 40.3]
2022-09-28 05:18:43,010 [trainer.py] => NME compound curve: [0, 52.17, 45.8, 52.53, 56.79, 44.96]
2022-09-28 05:18:43,011 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 05:18:43,011 [trainer.py] => prefix: cil
2022-09-28 05:18:43,011 [trainer.py] => dataset: CFEE
2022-09-28 05:18:43,011 [trainer.py] => memory_size: 2000
2022-09-28 05:18:43,011 [trainer.py] => memory_per_class: 20
2022-09-28 05:18:43,011 [trainer.py] => fixed_memory: True
2022-09-28 05:18:43,011 [trainer.py] => shuffle: True
2022-09-28 05:18:43,011 [trainer.py] => init_cls: 7
2022-09-28 05:18:43,011 [trainer.py] => increment: 3
2022-09-28 05:18:43,012 [trainer.py] => model_name: foster
2022-09-28 05:18:43,012 [trainer.py] => convnet_type: resnet18
2022-09-28 05:18:43,012 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 05:18:43,012 [trainer.py] => seed: 1993
2022-09-28 05:18:43,012 [trainer.py] => beta1: 0.96
2022-09-28 05:18:43,012 [trainer.py] => beta2: 0.97
2022-09-28 05:18:43,012 [trainer.py] => oofc: ft
2022-09-28 05:18:43,012 [trainer.py] => is_teacher_wa: False
2022-09-28 05:18:43,012 [trainer.py] => is_student_wa: False
2022-09-28 05:18:43,012 [trainer.py] => lambda_okd: 1
2022-09-28 05:18:43,012 [trainer.py] => wa_value: 1
2022-09-28 05:18:43,012 [trainer.py] => init_epochs: 40
2022-09-28 05:18:43,012 [trainer.py] => init_lr: 0.01
2022-09-28 05:18:43,012 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 05:18:43,012 [trainer.py] => boosting_epochs: 34
2022-09-28 05:18:43,012 [trainer.py] => compression_epochs: 26
2022-09-28 05:18:43,012 [trainer.py] => lr: 0.001
2022-09-28 05:18:43,012 [trainer.py] => batch_size: 32
2022-09-28 05:18:43,012 [trainer.py] => weight_decay: 0.0005
2022-09-28 05:18:43,012 [trainer.py] => num_workers: 8
2022-09-28 05:18:43,012 [trainer.py] => T: 2
2022-09-28 05:18:43,012 [trainer.py] => nb_runs: 3
2022-09-28 05:18:43,012 [trainer.py] => fold: 10
2022-09-28 05:18:43,012 [data.py] => ========== Fold:3 ==========
2022-09-28 05:18:43,067 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 12, 10, 19, 21, 17, 18, 8, 7, 9, 14, 15, 13, 11, 16]
2022-09-28 05:18:43,284 [foster.py] => Learning on 0-7
2022-09-28 05:18:43,284 [foster.py] => All params: 11183694
2022-09-28 05:18:43,284 [foster.py] => Trainable params: 11183694
2022-09-28 05:18:45,677 [foster.py] => Task 0, Epoch 1/40 => Loss 1.407, Train_accy 48.04
2022-09-28 05:18:48,716 [foster.py] => Task 0, Epoch 2/40 => Loss 0.559, Train_accy 81.16, Test_accy 83.80
2022-09-28 05:18:51,719 [foster.py] => Task 0, Epoch 3/40 => Loss 0.377, Train_accy 86.27, Test_accy 86.03
2022-09-28 05:18:54,695 [foster.py] => Task 0, Epoch 4/40 => Loss 0.260, Train_accy 91.11, Test_accy 85.47
2022-09-28 05:18:57,639 [foster.py] => Task 0, Epoch 5/40 => Loss 0.229, Train_accy 91.95, Test_accy 86.59
2022-09-28 05:18:59,976 [foster.py] => Task 0, Epoch 6/40 => Loss 0.190, Train_accy 94.05
2022-09-28 05:19:02,964 [foster.py] => Task 0, Epoch 7/40 => Loss 0.162, Train_accy 94.26, Test_accy 86.03
2022-09-28 05:19:05,926 [foster.py] => Task 0, Epoch 8/40 => Loss 0.131, Train_accy 95.31, Test_accy 86.03
2022-09-28 05:19:08,901 [foster.py] => Task 0, Epoch 9/40 => Loss 0.099, Train_accy 96.92, Test_accy 84.36
2022-09-28 05:19:11,898 [foster.py] => Task 0, Epoch 10/40 => Loss 0.085, Train_accy 97.20, Test_accy 86.59
2022-09-28 05:19:14,209 [foster.py] => Task 0, Epoch 11/40 => Loss 0.076, Train_accy 97.62
2022-09-28 05:19:17,219 [foster.py] => Task 0, Epoch 12/40 => Loss 0.085, Train_accy 97.20, Test_accy 87.15
2022-09-28 05:19:20,196 [foster.py] => Task 0, Epoch 13/40 => Loss 0.066, Train_accy 98.11, Test_accy 88.83
2022-09-28 05:19:23,172 [foster.py] => Task 0, Epoch 14/40 => Loss 0.056, Train_accy 98.25, Test_accy 87.71
2022-09-28 05:19:26,109 [foster.py] => Task 0, Epoch 15/40 => Loss 0.049, Train_accy 98.74, Test_accy 88.27
2022-09-28 05:19:28,450 [foster.py] => Task 0, Epoch 16/40 => Loss 0.044, Train_accy 98.88
2022-09-28 05:19:31,402 [foster.py] => Task 0, Epoch 17/40 => Loss 0.039, Train_accy 99.09, Test_accy 87.71
2022-09-28 05:19:34,444 [foster.py] => Task 0, Epoch 18/40 => Loss 0.037, Train_accy 98.95, Test_accy 86.59
2022-09-28 05:19:37,461 [foster.py] => Task 0, Epoch 19/40 => Loss 0.028, Train_accy 99.44, Test_accy 86.59
2022-09-28 05:19:40,436 [foster.py] => Task 0, Epoch 20/40 => Loss 0.032, Train_accy 99.30, Test_accy 86.59
2022-09-28 05:19:42,791 [foster.py] => Task 0, Epoch 21/40 => Loss 0.031, Train_accy 99.30
2022-09-28 05:19:45,768 [foster.py] => Task 0, Epoch 22/40 => Loss 0.024, Train_accy 99.58, Test_accy 88.27
2022-09-28 05:19:48,741 [foster.py] => Task 0, Epoch 23/40 => Loss 0.029, Train_accy 99.23, Test_accy 88.27
2022-09-28 05:19:51,741 [foster.py] => Task 0, Epoch 24/40 => Loss 0.018, Train_accy 99.72, Test_accy 88.83
2022-09-28 05:19:54,759 [foster.py] => Task 0, Epoch 25/40 => Loss 0.023, Train_accy 99.65, Test_accy 86.59
2022-09-28 05:19:57,109 [foster.py] => Task 0, Epoch 26/40 => Loss 0.017, Train_accy 99.79
2022-09-28 05:20:00,083 [foster.py] => Task 0, Epoch 27/40 => Loss 0.022, Train_accy 99.58, Test_accy 87.71
2022-09-28 05:20:03,089 [foster.py] => Task 0, Epoch 28/40 => Loss 0.018, Train_accy 99.79, Test_accy 87.71
2022-09-28 05:20:06,145 [foster.py] => Task 0, Epoch 29/40 => Loss 0.014, Train_accy 99.93, Test_accy 88.27
2022-09-28 05:20:09,112 [foster.py] => Task 0, Epoch 30/40 => Loss 0.018, Train_accy 99.72, Test_accy 88.27
2022-09-28 05:20:11,453 [foster.py] => Task 0, Epoch 31/40 => Loss 0.014, Train_accy 99.93
2022-09-28 05:20:14,405 [foster.py] => Task 0, Epoch 32/40 => Loss 0.017, Train_accy 99.86, Test_accy 88.83
2022-09-28 05:20:17,400 [foster.py] => Task 0, Epoch 33/40 => Loss 0.011, Train_accy 100.00, Test_accy 87.15
2022-09-28 05:20:20,382 [foster.py] => Task 0, Epoch 34/40 => Loss 0.015, Train_accy 99.79, Test_accy 87.15
2022-09-28 05:20:23,375 [foster.py] => Task 0, Epoch 35/40 => Loss 0.012, Train_accy 99.86, Test_accy 88.27
2022-09-28 05:20:25,768 [foster.py] => Task 0, Epoch 36/40 => Loss 0.017, Train_accy 99.65
2022-09-28 05:20:28,757 [foster.py] => Task 0, Epoch 37/40 => Loss 0.012, Train_accy 99.86, Test_accy 87.15
2022-09-28 05:20:31,700 [foster.py] => Task 0, Epoch 38/40 => Loss 0.013, Train_accy 100.00, Test_accy 87.15
2022-09-28 05:20:34,671 [foster.py] => Task 0, Epoch 39/40 => Loss 0.012, Train_accy 99.79, Test_accy 87.71
2022-09-28 05:20:37,608 [foster.py] => Task 0, Epoch 40/40 => Loss 0.015, Train_accy 99.79, Test_accy 87.71
2022-09-28 05:20:37,608 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 05:20:44,498 [foster.py] => Exemplar size: 140
2022-09-28 05:20:44,499 [trainer.py] => CNN: {'total': 87.71, 'old': 87.71, 'new': 0, 'base': 87.71, 'compound': 0}
2022-09-28 05:20:44,499 [trainer.py] => CNN top1 curve: [87.71]
2022-09-28 05:20:44,499 [trainer.py] => CNN base curve: [87.71]
2022-09-28 05:20:44,499 [trainer.py] => CNN old curve: [87.71]
2022-09-28 05:20:44,499 [trainer.py] => CNN new curve: [0]
2022-09-28 05:20:44,499 [trainer.py] => CNN compound curve: [0]
2022-09-28 05:20:44,499 [trainer.py] => NME: {'total': 87.71, 'old': 87.71, 'new': 0, 'base': 87.71, 'compound': 0}
2022-09-28 05:20:44,499 [trainer.py] => NME top1 curve: [87.71]
2022-09-28 05:20:44,499 [trainer.py] => NME base curve: [87.71]
2022-09-28 05:20:44,499 [trainer.py] => NME old curve: [87.71]
2022-09-28 05:20:44,499 [trainer.py] => NME new curve: [0]
2022-09-28 05:20:44,499 [trainer.py] => NME compound curve: [0]
2022-09-28 05:20:44,736 [foster.py] => Learning on 7-10
2022-09-28 05:20:44,737 [foster.py] => All params: 22371995
2022-09-28 05:20:44,737 [foster.py] => Trainable params: 11191892
2022-09-28 05:20:44,757 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 05:20:47,267 [foster.py] => Task 1, Epoch 1/34 => Loss 5.073, Loss_clf 2.428, Loss_fe 2.083, Loss_kd 0.393, Train_accy 33.64, Test_accy 58.23
2022-09-28 05:20:49,016 [foster.py] => Task 1, Epoch 2/34 => Loss 2.789, Loss_clf 0.893, Loss_fe 1.301, Loss_kd 0.416, Train_accy 59.50
2022-09-28 05:20:50,772 [foster.py] => Task 1, Epoch 3/34 => Loss 2.343, Loss_clf 0.702, Loss_fe 1.113, Loss_kd 0.370, Train_accy 40.63
2022-09-28 05:20:52,559 [foster.py] => Task 1, Epoch 4/34 => Loss 2.161, Loss_clf 0.634, Loss_fe 0.994, Loss_kd 0.372, Train_accy 45.78
2022-09-28 05:20:54,330 [foster.py] => Task 1, Epoch 5/34 => Loss 2.082, Loss_clf 0.633, Loss_fe 0.924, Loss_kd 0.367, Train_accy 42.88
2022-09-28 05:20:56,833 [foster.py] => Task 1, Epoch 6/34 => Loss 1.979, Loss_clf 0.587, Loss_fe 0.869, Loss_kd 0.366, Train_accy 41.42, Test_accy 68.27
2022-09-28 05:20:58,568 [foster.py] => Task 1, Epoch 7/34 => Loss 1.953, Loss_clf 0.581, Loss_fe 0.844, Loss_kd 0.370, Train_accy 42.74
2022-09-28 05:21:00,306 [foster.py] => Task 1, Epoch 8/34 => Loss 1.907, Loss_clf 0.576, Loss_fe 0.817, Loss_kd 0.360, Train_accy 42.22
2022-09-28 05:21:02,038 [foster.py] => Task 1, Epoch 9/34 => Loss 1.823, Loss_clf 0.545, Loss_fe 0.761, Loss_kd 0.362, Train_accy 44.59
2022-09-28 05:21:03,755 [foster.py] => Task 1, Epoch 10/34 => Loss 1.784, Loss_clf 0.523, Loss_fe 0.754, Loss_kd 0.355, Train_accy 42.61
2022-09-28 05:21:06,301 [foster.py] => Task 1, Epoch 11/34 => Loss 1.772, Loss_clf 0.528, Loss_fe 0.726, Loss_kd 0.363, Train_accy 43.54, Test_accy 68.27
2022-09-28 05:21:08,046 [foster.py] => Task 1, Epoch 12/34 => Loss 1.738, Loss_clf 0.518, Loss_fe 0.700, Loss_kd 0.363, Train_accy 44.46
2022-09-28 05:21:09,770 [foster.py] => Task 1, Epoch 13/34 => Loss 1.725, Loss_clf 0.508, Loss_fe 0.699, Loss_kd 0.362, Train_accy 46.70
2022-09-28 05:21:11,485 [foster.py] => Task 1, Epoch 14/34 => Loss 1.728, Loss_clf 0.521, Loss_fe 0.696, Loss_kd 0.358, Train_accy 42.08
2022-09-28 05:21:13,315 [foster.py] => Task 1, Epoch 15/34 => Loss 1.681, Loss_clf 0.495, Loss_fe 0.665, Loss_kd 0.365, Train_accy 44.72
2022-09-28 05:21:15,880 [foster.py] => Task 1, Epoch 16/34 => Loss 1.637, Loss_clf 0.474, Loss_fe 0.642, Loss_kd 0.365, Train_accy 45.25, Test_accy 68.27
2022-09-28 05:21:17,613 [foster.py] => Task 1, Epoch 17/34 => Loss 1.677, Loss_clf 0.494, Loss_fe 0.664, Loss_kd 0.363, Train_accy 43.67
2022-09-28 05:21:19,308 [foster.py] => Task 1, Epoch 18/34 => Loss 1.638, Loss_clf 0.482, Loss_fe 0.641, Loss_kd 0.360, Train_accy 43.40
2022-09-28 05:21:21,003 [foster.py] => Task 1, Epoch 19/34 => Loss 1.586, Loss_clf 0.449, Loss_fe 0.612, Loss_kd 0.368, Train_accy 46.44
2022-09-28 05:21:22,703 [foster.py] => Task 1, Epoch 20/34 => Loss 1.584, Loss_clf 0.465, Loss_fe 0.600, Loss_kd 0.364, Train_accy 46.44
2022-09-28 05:21:25,204 [foster.py] => Task 1, Epoch 21/34 => Loss 1.572, Loss_clf 0.452, Loss_fe 0.602, Loss_kd 0.363, Train_accy 46.17, Test_accy 68.67
2022-09-28 05:21:26,924 [foster.py] => Task 1, Epoch 22/34 => Loss 1.534, Loss_clf 0.436, Loss_fe 0.584, Loss_kd 0.360, Train_accy 46.44
2022-09-28 05:21:28,634 [foster.py] => Task 1, Epoch 23/34 => Loss 1.576, Loss_clf 0.459, Loss_fe 0.604, Loss_kd 0.360, Train_accy 46.70
2022-09-28 05:21:30,389 [foster.py] => Task 1, Epoch 24/34 => Loss 1.579, Loss_clf 0.461, Loss_fe 0.606, Loss_kd 0.358, Train_accy 45.51
2022-09-28 05:21:32,128 [foster.py] => Task 1, Epoch 25/34 => Loss 1.566, Loss_clf 0.442, Loss_fe 0.601, Loss_kd 0.366, Train_accy 45.51
2022-09-28 05:21:34,655 [foster.py] => Task 1, Epoch 26/34 => Loss 1.526, Loss_clf 0.431, Loss_fe 0.581, Loss_kd 0.359, Train_accy 47.89, Test_accy 68.67
2022-09-28 05:21:36,399 [foster.py] => Task 1, Epoch 27/34 => Loss 1.495, Loss_clf 0.415, Loss_fe 0.568, Loss_kd 0.359, Train_accy 46.17
2022-09-28 05:21:38,171 [foster.py] => Task 1, Epoch 28/34 => Loss 1.537, Loss_clf 0.439, Loss_fe 0.582, Loss_kd 0.361, Train_accy 47.49
2022-09-28 05:21:39,896 [foster.py] => Task 1, Epoch 29/34 => Loss 1.536, Loss_clf 0.425, Loss_fe 0.591, Loss_kd 0.365, Train_accy 47.49
2022-09-28 05:21:41,595 [foster.py] => Task 1, Epoch 30/34 => Loss 1.508, Loss_clf 0.421, Loss_fe 0.576, Loss_kd 0.357, Train_accy 46.70
2022-09-28 05:21:44,088 [foster.py] => Task 1, Epoch 31/34 => Loss 1.507, Loss_clf 0.425, Loss_fe 0.571, Loss_kd 0.358, Train_accy 45.78, Test_accy 68.67
2022-09-28 05:21:45,834 [foster.py] => Task 1, Epoch 32/34 => Loss 1.489, Loss_clf 0.417, Loss_fe 0.559, Loss_kd 0.360, Train_accy 45.78
2022-09-28 05:21:47,629 [foster.py] => Task 1, Epoch 33/34 => Loss 1.510, Loss_clf 0.428, Loss_fe 0.563, Loss_kd 0.363, Train_accy 47.63
2022-09-28 05:21:49,373 [foster.py] => Task 1, Epoch 34/34 => Loss 1.530, Loss_clf 0.429, Loss_fe 0.579, Loss_kd 0.366, Train_accy 46.31
2022-09-28 05:21:49,373 [foster.py] => do not weight align teacher!
2022-09-28 05:21:49,374 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 05:21:52,178 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.537,  Train_accy 17.15, Test_accy 58.63
2022-09-28 05:21:54,123 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.385,  Train_accy 18.47
2022-09-28 05:21:56,044 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.298,  Train_accy 18.73
2022-09-28 05:21:57,970 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.245,  Train_accy 19.00
2022-09-28 05:21:59,896 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.237,  Train_accy 19.79
2022-09-28 05:22:02,490 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.205,  Train_accy 20.32, Test_accy 61.85
2022-09-28 05:22:04,415 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.216,  Train_accy 20.71
2022-09-28 05:22:06,306 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.198,  Train_accy 21.37
2022-09-28 05:22:08,294 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.190,  Train_accy 20.71
2022-09-28 05:22:10,244 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.201,  Train_accy 21.11
2022-09-28 05:22:12,878 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.182,  Train_accy 22.16, Test_accy 63.05
2022-09-28 05:22:14,799 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.172,  Train_accy 22.82
2022-09-28 05:22:16,728 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.160,  Train_accy 22.43
2022-09-28 05:22:18,659 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.170,  Train_accy 22.16
2022-09-28 05:22:20,639 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.187,  Train_accy 23.75
2022-09-28 05:22:23,224 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.166,  Train_accy 23.75, Test_accy 63.05
2022-09-28 05:22:25,172 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.160,  Train_accy 23.61
2022-09-28 05:22:27,189 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.163,  Train_accy 21.77
2022-09-28 05:22:29,110 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.157,  Train_accy 22.56
2022-09-28 05:22:31,040 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.163,  Train_accy 23.35
2022-09-28 05:22:33,615 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.163,  Train_accy 25.20, Test_accy 63.05
2022-09-28 05:22:35,586 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.166,  Train_accy 23.48
2022-09-28 05:22:37,483 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.168,  Train_accy 22.96
2022-09-28 05:22:39,415 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.161,  Train_accy 23.61
2022-09-28 05:22:41,355 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.166,  Train_accy 23.88
2022-09-28 05:22:43,923 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.165,  Train_accy 23.75, Test_accy 63.86
2022-09-28 05:22:43,924 [foster.py] => do not weight align student!
2022-09-28 05:22:44,656 [foster.py] => darknet eval: 
2022-09-28 05:22:44,656 [foster.py] => CNN top1 curve: 63.86
2022-09-28 05:22:44,656 [foster.py] => CNN top5 curve: 96.79
2022-09-28 05:22:44,656 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 05:22:50,990 [foster.py] => Exemplar size: 200
2022-09-28 05:22:50,990 [trainer.py] => CNN: {'total': 68.67, 'old': 84.92, 'new': 27.14, 'base': 84.92, 'compound': 27.14}
2022-09-28 05:22:50,991 [trainer.py] => CNN top1 curve: [87.71, 68.67]
2022-09-28 05:22:50,991 [trainer.py] => CNN base curve: [87.71, 84.92]
2022-09-28 05:22:50,991 [trainer.py] => CNN old curve: [87.71, 84.92]
2022-09-28 05:22:50,991 [trainer.py] => CNN new curve: [0, 27.14]
2022-09-28 05:22:50,991 [trainer.py] => CNN compound curve: [0, 27.14]
2022-09-28 05:22:50,991 [trainer.py] => NME: {'total': 71.49, 'old': 77.09, 'new': 57.14, 'base': 77.09, 'compound': 57.14}
2022-09-28 05:22:50,991 [trainer.py] => NME top1 curve: [87.71, 71.49]
2022-09-28 05:22:50,991 [trainer.py] => NME base curve: [87.71, 77.09]
2022-09-28 05:22:50,991 [trainer.py] => NME old curve: [87.71, 77.09]
2022-09-28 05:22:50,991 [trainer.py] => NME new curve: [0, 57.14]
2022-09-28 05:22:50,991 [trainer.py] => NME compound curve: [0, 57.14]
2022-09-28 05:22:51,223 [foster.py] => Learning on 10-13
2022-09-28 05:22:51,224 [foster.py] => All params: 22378148
2022-09-28 05:22:51,224 [foster.py] => Trainable params: 11196506
2022-09-28 05:22:51,244 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 05:22:53,862 [foster.py] => Task 2, Epoch 1/34 => Loss 5.420, Loss_clf 2.064, Loss_fe 2.185, Loss_kd 0.901, Train_accy 39.83, Test_accy 49.35
2022-09-28 05:22:55,721 [foster.py] => Task 2, Epoch 2/34 => Loss 3.543, Loss_clf 0.949, Loss_fe 1.453, Loss_kd 0.877, Train_accy 42.74
2022-09-28 05:22:57,546 [foster.py] => Task 2, Epoch 3/34 => Loss 3.140, Loss_clf 0.753, Loss_fe 1.263, Loss_kd 0.864, Train_accy 39.83
2022-09-28 05:22:59,453 [foster.py] => Task 2, Epoch 4/34 => Loss 3.018, Loss_clf 0.733, Loss_fe 1.162, Loss_kd 0.864, Train_accy 43.34
2022-09-28 05:23:01,281 [foster.py] => Task 2, Epoch 5/34 => Loss 2.914, Loss_clf 0.720, Loss_fe 1.072, Loss_kd 0.864, Train_accy 39.10
2022-09-28 05:23:03,912 [foster.py] => Task 2, Epoch 6/34 => Loss 2.820, Loss_clf 0.688, Loss_fe 1.006, Loss_kd 0.866, Train_accy 41.40, Test_accy 55.48
2022-09-28 05:23:05,779 [foster.py] => Task 2, Epoch 7/34 => Loss 2.730, Loss_clf 0.663, Loss_fe 0.942, Loss_kd 0.866, Train_accy 43.22
2022-09-28 05:23:07,588 [foster.py] => Task 2, Epoch 8/34 => Loss 2.672, Loss_clf 0.654, Loss_fe 0.895, Loss_kd 0.864, Train_accy 42.62
2022-09-28 05:23:09,392 [foster.py] => Task 2, Epoch 9/34 => Loss 2.641, Loss_clf 0.652, Loss_fe 0.866, Loss_kd 0.864, Train_accy 42.62
2022-09-28 05:23:11,187 [foster.py] => Task 2, Epoch 10/34 => Loss 2.577, Loss_clf 0.634, Loss_fe 0.818, Loss_kd 0.865, Train_accy 45.04
2022-09-28 05:23:13,828 [foster.py] => Task 2, Epoch 11/34 => Loss 2.503, Loss_clf 0.606, Loss_fe 0.782, Loss_kd 0.857, Train_accy 44.19, Test_accy 58.39
2022-09-28 05:23:15,660 [foster.py] => Task 2, Epoch 12/34 => Loss 2.494, Loss_clf 0.593, Loss_fe 0.775, Loss_kd 0.867, Train_accy 46.13
2022-09-28 05:23:17,506 [foster.py] => Task 2, Epoch 13/34 => Loss 2.487, Loss_clf 0.604, Loss_fe 0.758, Loss_kd 0.865, Train_accy 42.62
2022-09-28 05:23:19,415 [foster.py] => Task 2, Epoch 14/34 => Loss 2.466, Loss_clf 0.595, Loss_fe 0.743, Loss_kd 0.867, Train_accy 43.22
2022-09-28 05:23:21,253 [foster.py] => Task 2, Epoch 15/34 => Loss 2.406, Loss_clf 0.563, Loss_fe 0.717, Loss_kd 0.866, Train_accy 46.00
2022-09-28 05:23:23,943 [foster.py] => Task 2, Epoch 16/34 => Loss 2.418, Loss_clf 0.572, Loss_fe 0.711, Loss_kd 0.874, Train_accy 45.52, Test_accy 56.77
2022-09-28 05:23:25,796 [foster.py] => Task 2, Epoch 17/34 => Loss 2.394, Loss_clf 0.564, Loss_fe 0.698, Loss_kd 0.871, Train_accy 46.00
2022-09-28 05:23:27,670 [foster.py] => Task 2, Epoch 18/34 => Loss 2.357, Loss_clf 0.549, Loss_fe 0.677, Loss_kd 0.870, Train_accy 45.64
2022-09-28 05:23:29,565 [foster.py] => Task 2, Epoch 19/34 => Loss 2.312, Loss_clf 0.529, Loss_fe 0.650, Loss_kd 0.872, Train_accy 47.34
2022-09-28 05:23:31,407 [foster.py] => Task 2, Epoch 20/34 => Loss 2.313, Loss_clf 0.531, Loss_fe 0.649, Loss_kd 0.872, Train_accy 47.22
2022-09-28 05:23:34,091 [foster.py] => Task 2, Epoch 21/34 => Loss 2.319, Loss_clf 0.536, Loss_fe 0.659, Loss_kd 0.864, Train_accy 47.58, Test_accy 57.42
2022-09-28 05:23:35,967 [foster.py] => Task 2, Epoch 22/34 => Loss 2.255, Loss_clf 0.500, Loss_fe 0.624, Loss_kd 0.870, Train_accy 47.46
2022-09-28 05:23:37,779 [foster.py] => Task 2, Epoch 23/34 => Loss 2.282, Loss_clf 0.515, Loss_fe 0.644, Loss_kd 0.863, Train_accy 46.97
2022-09-28 05:23:39,579 [foster.py] => Task 2, Epoch 24/34 => Loss 2.254, Loss_clf 0.514, Loss_fe 0.609, Loss_kd 0.870, Train_accy 48.31
2022-09-28 05:23:41,430 [foster.py] => Task 2, Epoch 25/34 => Loss 2.303, Loss_clf 0.529, Loss_fe 0.646, Loss_kd 0.868, Train_accy 45.64
2022-09-28 05:23:44,065 [foster.py] => Task 2, Epoch 26/34 => Loss 2.272, Loss_clf 0.509, Loss_fe 0.630, Loss_kd 0.872, Train_accy 46.97, Test_accy 58.06
2022-09-28 05:23:45,925 [foster.py] => Task 2, Epoch 27/34 => Loss 2.278, Loss_clf 0.526, Loss_fe 0.624, Loss_kd 0.868, Train_accy 46.97
2022-09-28 05:23:47,827 [foster.py] => Task 2, Epoch 28/34 => Loss 2.201, Loss_clf 0.486, Loss_fe 0.592, Loss_kd 0.865, Train_accy 47.22
2022-09-28 05:23:49,693 [foster.py] => Task 2, Epoch 29/34 => Loss 2.219, Loss_clf 0.506, Loss_fe 0.595, Loss_kd 0.860, Train_accy 46.73
2022-09-28 05:23:51,536 [foster.py] => Task 2, Epoch 30/34 => Loss 2.184, Loss_clf 0.482, Loss_fe 0.586, Loss_kd 0.858, Train_accy 47.70
2022-09-28 05:23:54,159 [foster.py] => Task 2, Epoch 31/34 => Loss 2.217, Loss_clf 0.489, Loss_fe 0.605, Loss_kd 0.864, Train_accy 48.18, Test_accy 57.74
2022-09-28 05:23:55,991 [foster.py] => Task 2, Epoch 32/34 => Loss 2.244, Loss_clf 0.498, Loss_fe 0.608, Loss_kd 0.875, Train_accy 47.82
2022-09-28 05:23:57,859 [foster.py] => Task 2, Epoch 33/34 => Loss 2.231, Loss_clf 0.496, Loss_fe 0.607, Loss_kd 0.868, Train_accy 48.31
2022-09-28 05:23:59,695 [foster.py] => Task 2, Epoch 34/34 => Loss 2.264, Loss_clf 0.511, Loss_fe 0.625, Loss_kd 0.868, Train_accy 47.58
2022-09-28 05:23:59,696 [foster.py] => do not weight align teacher!
2022-09-28 05:23:59,696 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 05:24:02,675 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.916,  Train_accy 16.59, Test_accy 51.29
2022-09-28 05:24:04,728 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.769,  Train_accy 17.31
2022-09-28 05:24:06,799 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.695,  Train_accy 17.80
2022-09-28 05:24:08,840 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.676,  Train_accy 17.31
2022-09-28 05:24:10,915 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.644,  Train_accy 17.92
2022-09-28 05:24:13,661 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.639,  Train_accy 17.80, Test_accy 50.65
2022-09-28 05:24:15,733 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.612,  Train_accy 17.31
2022-09-28 05:24:17,766 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.620,  Train_accy 17.92
2022-09-28 05:24:19,791 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.604,  Train_accy 18.04
2022-09-28 05:24:21,812 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.610,  Train_accy 18.40
2022-09-28 05:24:24,555 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.602,  Train_accy 18.04, Test_accy 51.29
2022-09-28 05:24:26,615 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.608,  Train_accy 18.04
2022-09-28 05:24:28,707 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.590,  Train_accy 18.28
2022-09-28 05:24:30,734 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.585,  Train_accy 18.52
2022-09-28 05:24:32,748 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.595,  Train_accy 18.77
2022-09-28 05:24:35,571 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.591,  Train_accy 18.64, Test_accy 51.29
2022-09-28 05:24:37,639 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.598,  Train_accy 18.52
2022-09-28 05:24:39,661 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.587,  Train_accy 18.28
2022-09-28 05:24:41,764 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.588,  Train_accy 18.64
2022-09-28 05:24:43,804 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.597,  Train_accy 18.77
2022-09-28 05:24:46,603 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.580,  Train_accy 18.28, Test_accy 50.97
2022-09-28 05:24:48,656 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.574,  Train_accy 18.77
2022-09-28 05:24:50,659 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.581,  Train_accy 19.85
2022-09-28 05:24:52,727 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.591,  Train_accy 18.89
2022-09-28 05:24:54,758 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.581,  Train_accy 19.13
2022-09-28 05:24:57,506 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.579,  Train_accy 19.37, Test_accy 51.29
2022-09-28 05:24:57,507 [foster.py] => do not weight align student!
2022-09-28 05:24:58,230 [foster.py] => darknet eval: 
2022-09-28 05:24:58,230 [foster.py] => CNN top1 curve: 51.29
2022-09-28 05:24:58,230 [foster.py] => CNN top5 curve: 95.48
2022-09-28 05:24:58,230 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 05:25:05,674 [foster.py] => Exemplar size: 260
2022-09-28 05:25:05,674 [trainer.py] => CNN: {'total': 57.74, 'old': 63.86, 'new': 32.79, 'base': 80.45, 'compound': 26.72}
2022-09-28 05:25:05,674 [trainer.py] => CNN top1 curve: [87.71, 68.67, 57.74]
2022-09-28 05:25:05,674 [trainer.py] => CNN base curve: [87.71, 84.92, 80.45]
2022-09-28 05:25:05,674 [trainer.py] => CNN old curve: [87.71, 84.92, 63.86]
2022-09-28 05:25:05,674 [trainer.py] => CNN new curve: [0, 27.14, 32.79]
2022-09-28 05:25:05,674 [trainer.py] => CNN compound curve: [0, 27.14, 26.72]
2022-09-28 05:25:05,674 [trainer.py] => NME: {'total': 61.61, 'old': 62.65, 'new': 57.38, 'base': 72.07, 'compound': 47.33}
2022-09-28 05:25:05,674 [trainer.py] => NME top1 curve: [87.71, 71.49, 61.61]
2022-09-28 05:25:05,674 [trainer.py] => NME base curve: [87.71, 77.09, 72.07]
2022-09-28 05:25:05,674 [trainer.py] => NME old curve: [87.71, 77.09, 62.65]
2022-09-28 05:25:05,674 [trainer.py] => NME new curve: [0, 57.14, 57.38]
2022-09-28 05:25:05,674 [trainer.py] => NME compound curve: [0, 57.14, 47.33]
2022-09-28 05:25:05,904 [foster.py] => Learning on 13-16
2022-09-28 05:25:05,905 [foster.py] => All params: 22384301
2022-09-28 05:25:05,905 [foster.py] => Trainable params: 11201120
2022-09-28 05:25:05,925 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 05:25:08,746 [foster.py] => Task 3, Epoch 1/34 => Loss 5.779, Loss_clf 1.763, Loss_fe 2.375, Loss_kd 1.332, Train_accy 46.50, Test_accy 47.71
2022-09-28 05:25:10,643 [foster.py] => Task 3, Epoch 2/34 => Loss 4.058, Loss_clf 0.866, Loss_fe 1.576, Loss_kd 1.313, Train_accy 46.73
2022-09-28 05:25:12,631 [foster.py] => Task 3, Epoch 3/34 => Loss 3.670, Loss_clf 0.736, Loss_fe 1.320, Loss_kd 1.311, Train_accy 50.56
2022-09-28 05:25:14,518 [foster.py] => Task 3, Epoch 4/34 => Loss 3.504, Loss_clf 0.690, Loss_fe 1.198, Loss_kd 1.313, Train_accy 48.08
2022-09-28 05:25:16,467 [foster.py] => Task 3, Epoch 5/34 => Loss 3.370, Loss_clf 0.669, Loss_fe 1.103, Loss_kd 1.298, Train_accy 46.95
2022-09-28 05:25:19,276 [foster.py] => Task 3, Epoch 6/34 => Loss 3.273, Loss_clf 0.635, Loss_fe 1.037, Loss_kd 1.301, Train_accy 51.13, Test_accy 51.75
2022-09-28 05:25:21,176 [foster.py] => Task 3, Epoch 7/34 => Loss 3.196, Loss_clf 0.618, Loss_fe 0.960, Loss_kd 1.314, Train_accy 52.71
2022-09-28 05:25:23,104 [foster.py] => Task 3, Epoch 8/34 => Loss 3.140, Loss_clf 0.610, Loss_fe 0.916, Loss_kd 1.312, Train_accy 49.55
2022-09-28 05:25:25,044 [foster.py] => Task 3, Epoch 9/34 => Loss 3.049, Loss_clf 0.581, Loss_fe 0.861, Loss_kd 1.306, Train_accy 54.18
2022-09-28 05:25:26,938 [foster.py] => Task 3, Epoch 10/34 => Loss 3.017, Loss_clf 0.568, Loss_fe 0.829, Loss_kd 1.316, Train_accy 49.89
2022-09-28 05:25:29,711 [foster.py] => Task 3, Epoch 11/34 => Loss 2.997, Loss_clf 0.576, Loss_fe 0.802, Loss_kd 1.316, Train_accy 55.30, Test_accy 53.64
2022-09-28 05:25:31,613 [foster.py] => Task 3, Epoch 12/34 => Loss 2.933, Loss_clf 0.547, Loss_fe 0.776, Loss_kd 1.309, Train_accy 52.14
2022-09-28 05:25:33,512 [foster.py] => Task 3, Epoch 13/34 => Loss 2.909, Loss_clf 0.545, Loss_fe 0.752, Loss_kd 1.310, Train_accy 52.48
2022-09-28 05:25:35,469 [foster.py] => Task 3, Epoch 14/34 => Loss 2.856, Loss_clf 0.529, Loss_fe 0.720, Loss_kd 1.306, Train_accy 53.27
2022-09-28 05:25:37,427 [foster.py] => Task 3, Epoch 15/34 => Loss 2.825, Loss_clf 0.517, Loss_fe 0.693, Loss_kd 1.313, Train_accy 55.08
2022-09-28 05:25:40,246 [foster.py] => Task 3, Epoch 16/34 => Loss 2.829, Loss_clf 0.526, Loss_fe 0.686, Loss_kd 1.315, Train_accy 54.85, Test_accy 52.56
2022-09-28 05:25:42,210 [foster.py] => Task 3, Epoch 17/34 => Loss 2.824, Loss_clf 0.528, Loss_fe 0.680, Loss_kd 1.313, Train_accy 53.72
2022-09-28 05:25:44,152 [foster.py] => Task 3, Epoch 18/34 => Loss 2.787, Loss_clf 0.506, Loss_fe 0.664, Loss_kd 1.315, Train_accy 54.51
2022-09-28 05:25:46,048 [foster.py] => Task 3, Epoch 19/34 => Loss 2.749, Loss_clf 0.497, Loss_fe 0.639, Loss_kd 1.311, Train_accy 54.40
2022-09-28 05:25:47,979 [foster.py] => Task 3, Epoch 20/34 => Loss 2.755, Loss_clf 0.502, Loss_fe 0.639, Loss_kd 1.311, Train_accy 57.22
2022-09-28 05:25:50,871 [foster.py] => Task 3, Epoch 21/34 => Loss 2.737, Loss_clf 0.489, Loss_fe 0.633, Loss_kd 1.312, Train_accy 54.29, Test_accy 53.64
2022-09-28 05:25:52,783 [foster.py] => Task 3, Epoch 22/34 => Loss 2.725, Loss_clf 0.485, Loss_fe 0.620, Loss_kd 1.317, Train_accy 57.00
2022-09-28 05:25:54,728 [foster.py] => Task 3, Epoch 23/34 => Loss 2.731, Loss_clf 0.492, Loss_fe 0.625, Loss_kd 1.311, Train_accy 55.64
2022-09-28 05:25:56,647 [foster.py] => Task 3, Epoch 24/34 => Loss 2.720, Loss_clf 0.480, Loss_fe 0.613, Loss_kd 1.322, Train_accy 55.42
2022-09-28 05:25:58,565 [foster.py] => Task 3, Epoch 25/34 => Loss 2.691, Loss_clf 0.474, Loss_fe 0.595, Loss_kd 1.317, Train_accy 57.00
2022-09-28 05:26:01,317 [foster.py] => Task 3, Epoch 26/34 => Loss 2.694, Loss_clf 0.472, Loss_fe 0.602, Loss_kd 1.317, Train_accy 58.24, Test_accy 54.45
2022-09-28 05:26:03,222 [foster.py] => Task 3, Epoch 27/34 => Loss 2.690, Loss_clf 0.479, Loss_fe 0.594, Loss_kd 1.313, Train_accy 57.00
2022-09-28 05:26:05,185 [foster.py] => Task 3, Epoch 28/34 => Loss 2.680, Loss_clf 0.472, Loss_fe 0.594, Loss_kd 1.311, Train_accy 56.43
2022-09-28 05:26:07,120 [foster.py] => Task 3, Epoch 29/34 => Loss 2.687, Loss_clf 0.476, Loss_fe 0.596, Loss_kd 1.312, Train_accy 57.90
2022-09-28 05:26:09,066 [foster.py] => Task 3, Epoch 30/34 => Loss 2.674, Loss_clf 0.471, Loss_fe 0.583, Loss_kd 1.316, Train_accy 57.56
2022-09-28 05:26:11,856 [foster.py] => Task 3, Epoch 31/34 => Loss 2.676, Loss_clf 0.467, Loss_fe 0.595, Loss_kd 1.311, Train_accy 56.09, Test_accy 54.45
2022-09-28 05:26:13,773 [foster.py] => Task 3, Epoch 32/34 => Loss 2.678, Loss_clf 0.462, Loss_fe 0.593, Loss_kd 1.319, Train_accy 55.98
2022-09-28 05:26:15,691 [foster.py] => Task 3, Epoch 33/34 => Loss 2.641, Loss_clf 0.447, Loss_fe 0.577, Loss_kd 1.314, Train_accy 57.11
2022-09-28 05:26:17,649 [foster.py] => Task 3, Epoch 34/34 => Loss 2.684, Loss_clf 0.473, Loss_fe 0.589, Loss_kd 1.318, Train_accy 56.55
2022-09-28 05:26:17,649 [foster.py] => do not weight align teacher!
2022-09-28 05:26:17,650 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 05:26:20,815 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.146,  Train_accy 16.48, Test_accy 43.40
2022-09-28 05:26:22,952 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.051,  Train_accy 17.16
2022-09-28 05:26:25,118 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.006,  Train_accy 17.04
2022-09-28 05:26:27,226 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 1.987,  Train_accy 17.04
2022-09-28 05:26:29,379 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.990,  Train_accy 17.49
2022-09-28 05:26:32,251 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.979,  Train_accy 18.06, Test_accy 43.13
2022-09-28 05:26:34,452 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.956,  Train_accy 17.72
2022-09-28 05:26:36,603 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.964,  Train_accy 18.40
2022-09-28 05:26:38,754 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.956,  Train_accy 17.61
2022-09-28 05:26:40,869 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.946,  Train_accy 18.74
2022-09-28 05:26:43,742 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.939,  Train_accy 17.83, Test_accy 45.01
2022-09-28 05:26:45,874 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.947,  Train_accy 18.62
2022-09-28 05:26:48,042 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.934,  Train_accy 18.51
2022-09-28 05:26:50,273 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.927,  Train_accy 19.86
2022-09-28 05:26:52,404 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.932,  Train_accy 19.30
2022-09-28 05:26:55,316 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.940,  Train_accy 19.98, Test_accy 45.82
2022-09-28 05:26:57,434 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.929,  Train_accy 18.85
2022-09-28 05:26:59,668 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.915,  Train_accy 20.54
2022-09-28 05:27:01,826 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.922,  Train_accy 19.41
2022-09-28 05:27:03,969 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.917,  Train_accy 19.75
2022-09-28 05:27:06,932 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.914,  Train_accy 20.32, Test_accy 46.09
2022-09-28 05:27:09,115 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.914,  Train_accy 19.75
2022-09-28 05:27:11,336 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.921,  Train_accy 20.43
2022-09-28 05:27:13,465 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.921,  Train_accy 19.64
2022-09-28 05:27:15,668 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.929,  Train_accy 20.77
2022-09-28 05:27:18,547 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.921,  Train_accy 19.75, Test_accy 45.55
2022-09-28 05:27:18,548 [foster.py] => do not weight align student!
2022-09-28 05:27:19,315 [foster.py] => darknet eval: 
2022-09-28 05:27:19,315 [foster.py] => CNN top1 curve: 45.55
2022-09-28 05:27:19,315 [foster.py] => CNN top5 curve: 92.45
2022-09-28 05:27:19,316 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 05:27:27,894 [foster.py] => Exemplar size: 320
2022-09-28 05:27:27,894 [trainer.py] => CNN: {'total': 53.91, 'old': 52.9, 'new': 59.02, 'base': 71.51, 'compound': 37.5}
2022-09-28 05:27:27,894 [trainer.py] => CNN top1 curve: [87.71, 68.67, 57.74, 53.91]
2022-09-28 05:27:27,894 [trainer.py] => CNN base curve: [87.71, 84.92, 80.45, 71.51]
2022-09-28 05:27:27,894 [trainer.py] => CNN old curve: [87.71, 84.92, 63.86, 52.9]
2022-09-28 05:27:27,894 [trainer.py] => CNN new curve: [0, 27.14, 32.79, 59.02]
2022-09-28 05:27:27,894 [trainer.py] => CNN compound curve: [0, 27.14, 26.72, 37.5]
2022-09-28 05:27:27,894 [trainer.py] => NME: {'total': 62.8, 'old': 59.03, 'new': 81.97, 'base': 68.72, 'compound': 57.29}
2022-09-28 05:27:27,894 [trainer.py] => NME top1 curve: [87.71, 71.49, 61.61, 62.8]
2022-09-28 05:27:27,894 [trainer.py] => NME base curve: [87.71, 77.09, 72.07, 68.72]
2022-09-28 05:27:27,894 [trainer.py] => NME old curve: [87.71, 77.09, 62.65, 59.03]
2022-09-28 05:27:27,894 [trainer.py] => NME new curve: [0, 57.14, 57.38, 81.97]
2022-09-28 05:27:27,894 [trainer.py] => NME compound curve: [0, 57.14, 47.33, 57.29]
2022-09-28 05:27:28,124 [foster.py] => Learning on 16-19
2022-09-28 05:27:28,124 [foster.py] => All params: 22390454
2022-09-28 05:27:28,124 [foster.py] => Trainable params: 11205734
2022-09-28 05:27:28,145 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 05:27:31,062 [foster.py] => Task 4, Epoch 1/34 => Loss 6.467, Loss_clf 2.019, Loss_fe 2.374, Loss_kd 1.747, Train_accy 42.18, Test_accy 44.11
2022-09-28 05:27:33,090 [foster.py] => Task 4, Epoch 2/34 => Loss 4.719, Loss_clf 0.934, Loss_fe 1.702, Loss_kd 1.754, Train_accy 53.59
2022-09-28 05:27:35,122 [foster.py] => Task 4, Epoch 3/34 => Loss 4.382, Loss_clf 0.832, Loss_fe 1.456, Loss_kd 1.764, Train_accy 58.77
2022-09-28 05:27:37,118 [foster.py] => Task 4, Epoch 4/34 => Loss 4.206, Loss_clf 0.791, Loss_fe 1.329, Loss_kd 1.757, Train_accy 60.25
2022-09-28 05:27:39,185 [foster.py] => Task 4, Epoch 5/34 => Loss 4.081, Loss_clf 0.773, Loss_fe 1.223, Loss_kd 1.756, Train_accy 60.36
2022-09-28 05:27:42,187 [foster.py] => Task 4, Epoch 6/34 => Loss 3.959, Loss_clf 0.733, Loss_fe 1.135, Loss_kd 1.760, Train_accy 62.58, Test_accy 52.89
2022-09-28 05:27:44,177 [foster.py] => Task 4, Epoch 7/34 => Loss 3.855, Loss_clf 0.703, Loss_fe 1.060, Loss_kd 1.761, Train_accy 61.10
2022-09-28 05:27:46,215 [foster.py] => Task 4, Epoch 8/34 => Loss 3.814, Loss_clf 0.704, Loss_fe 1.023, Loss_kd 1.757, Train_accy 62.79
2022-09-28 05:27:48,259 [foster.py] => Task 4, Epoch 9/34 => Loss 3.693, Loss_clf 0.664, Loss_fe 0.946, Loss_kd 1.754, Train_accy 63.11
2022-09-28 05:27:50,254 [foster.py] => Task 4, Epoch 10/34 => Loss 3.655, Loss_clf 0.661, Loss_fe 0.912, Loss_kd 1.754, Train_accy 63.53
2022-09-28 05:27:53,197 [foster.py] => Task 4, Epoch 11/34 => Loss 3.585, Loss_clf 0.632, Loss_fe 0.866, Loss_kd 1.758, Train_accy 63.85, Test_accy 54.50
2022-09-28 05:27:55,189 [foster.py] => Task 4, Epoch 12/34 => Loss 3.599, Loss_clf 0.650, Loss_fe 0.857, Loss_kd 1.762, Train_accy 64.48
2022-09-28 05:27:57,177 [foster.py] => Task 4, Epoch 13/34 => Loss 3.542, Loss_clf 0.629, Loss_fe 0.827, Loss_kd 1.757, Train_accy 64.69
2022-09-28 05:27:59,181 [foster.py] => Task 4, Epoch 14/34 => Loss 3.511, Loss_clf 0.613, Loss_fe 0.803, Loss_kd 1.764, Train_accy 65.64
2022-09-28 05:28:01,201 [foster.py] => Task 4, Epoch 15/34 => Loss 3.492, Loss_clf 0.615, Loss_fe 0.784, Loss_kd 1.762, Train_accy 65.22
2022-09-28 05:28:04,099 [foster.py] => Task 4, Epoch 16/34 => Loss 3.457, Loss_clf 0.600, Loss_fe 0.766, Loss_kd 1.761, Train_accy 64.90, Test_accy 56.81
2022-09-28 05:28:06,105 [foster.py] => Task 4, Epoch 17/34 => Loss 3.449, Loss_clf 0.600, Loss_fe 0.758, Loss_kd 1.760, Train_accy 65.96
2022-09-28 05:28:08,128 [foster.py] => Task 4, Epoch 18/34 => Loss 3.437, Loss_clf 0.591, Loss_fe 0.752, Loss_kd 1.763, Train_accy 66.28
2022-09-28 05:28:10,160 [foster.py] => Task 4, Epoch 19/34 => Loss 3.381, Loss_clf 0.569, Loss_fe 0.721, Loss_kd 1.761, Train_accy 66.60
2022-09-28 05:28:12,203 [foster.py] => Task 4, Epoch 20/34 => Loss 3.386, Loss_clf 0.570, Loss_fe 0.720, Loss_kd 1.765, Train_accy 65.86
2022-09-28 05:28:15,156 [foster.py] => Task 4, Epoch 21/34 => Loss 3.350, Loss_clf 0.561, Loss_fe 0.696, Loss_kd 1.763, Train_accy 66.17, Test_accy 57.04
2022-09-28 05:28:17,185 [foster.py] => Task 4, Epoch 22/34 => Loss 3.333, Loss_clf 0.553, Loss_fe 0.688, Loss_kd 1.762, Train_accy 67.55
2022-09-28 05:28:19,181 [foster.py] => Task 4, Epoch 23/34 => Loss 3.353, Loss_clf 0.558, Loss_fe 0.698, Loss_kd 1.766, Train_accy 66.49
2022-09-28 05:28:21,214 [foster.py] => Task 4, Epoch 24/34 => Loss 3.341, Loss_clf 0.559, Loss_fe 0.685, Loss_kd 1.765, Train_accy 65.96
2022-09-28 05:28:23,196 [foster.py] => Task 4, Epoch 25/34 => Loss 3.343, Loss_clf 0.560, Loss_fe 0.685, Loss_kd 1.767, Train_accy 67.44
2022-09-28 05:28:26,143 [foster.py] => Task 4, Epoch 26/34 => Loss 3.339, Loss_clf 0.558, Loss_fe 0.681, Loss_kd 1.769, Train_accy 69.03, Test_accy 57.04
2022-09-28 05:28:28,156 [foster.py] => Task 4, Epoch 27/34 => Loss 3.314, Loss_clf 0.546, Loss_fe 0.674, Loss_kd 1.763, Train_accy 65.54
2022-09-28 05:28:30,163 [foster.py] => Task 4, Epoch 28/34 => Loss 3.322, Loss_clf 0.558, Loss_fe 0.673, Loss_kd 1.760, Train_accy 65.54
2022-09-28 05:28:32,233 [foster.py] => Task 4, Epoch 29/34 => Loss 3.296, Loss_clf 0.537, Loss_fe 0.658, Loss_kd 1.770, Train_accy 66.28
2022-09-28 05:28:34,299 [foster.py] => Task 4, Epoch 30/34 => Loss 3.314, Loss_clf 0.547, Loss_fe 0.667, Loss_kd 1.768, Train_accy 68.29
2022-09-28 05:28:37,249 [foster.py] => Task 4, Epoch 31/34 => Loss 3.293, Loss_clf 0.539, Loss_fe 0.660, Loss_kd 1.763, Train_accy 68.08, Test_accy 57.04
2022-09-28 05:28:39,270 [foster.py] => Task 4, Epoch 32/34 => Loss 3.294, Loss_clf 0.535, Loss_fe 0.660, Loss_kd 1.768, Train_accy 67.86
2022-09-28 05:28:41,302 [foster.py] => Task 4, Epoch 33/34 => Loss 3.287, Loss_clf 0.531, Loss_fe 0.650, Loss_kd 1.774, Train_accy 66.38
2022-09-28 05:28:43,346 [foster.py] => Task 4, Epoch 34/34 => Loss 3.281, Loss_clf 0.539, Loss_fe 0.653, Loss_kd 1.759, Train_accy 66.38
2022-09-28 05:28:43,347 [foster.py] => do not weight align teacher!
2022-09-28 05:28:43,347 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 05:28:46,656 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.476,  Train_accy 15.01, Test_accy 36.03
2022-09-28 05:28:48,932 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.393,  Train_accy 16.38
2022-09-28 05:28:51,220 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.348,  Train_accy 18.18
2022-09-28 05:28:53,503 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.327,  Train_accy 18.60
2022-09-28 05:28:55,821 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.312,  Train_accy 18.71
2022-09-28 05:28:58,931 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.309,  Train_accy 19.45, Test_accy 42.03
2022-09-28 05:29:01,186 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.288,  Train_accy 20.72
2022-09-28 05:29:03,460 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.290,  Train_accy 21.67
2022-09-28 05:29:05,758 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.294,  Train_accy 22.83
2022-09-28 05:29:08,003 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.284,  Train_accy 21.56
2022-09-28 05:29:11,088 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.271,  Train_accy 23.47, Test_accy 43.42
2022-09-28 05:29:13,356 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.269,  Train_accy 23.36
2022-09-28 05:29:15,614 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.274,  Train_accy 24.31
2022-09-28 05:29:17,882 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.264,  Train_accy 23.68
2022-09-28 05:29:20,170 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.263,  Train_accy 24.95
2022-09-28 05:29:23,242 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.274,  Train_accy 25.58, Test_accy 44.34
2022-09-28 05:29:25,523 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.264,  Train_accy 25.58
2022-09-28 05:29:27,802 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.259,  Train_accy 26.74
2022-09-28 05:29:30,063 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.263,  Train_accy 26.11
2022-09-28 05:29:32,338 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.261,  Train_accy 26.32
2022-09-28 05:29:35,414 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.254,  Train_accy 25.90, Test_accy 44.80
2022-09-28 05:29:37,648 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.250,  Train_accy 26.85
2022-09-28 05:29:39,888 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.262,  Train_accy 26.11
2022-09-28 05:29:42,138 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.250,  Train_accy 25.58
2022-09-28 05:29:44,446 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.254,  Train_accy 25.79
2022-09-28 05:29:47,487 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.261,  Train_accy 26.32, Test_accy 44.34
2022-09-28 05:29:47,487 [foster.py] => do not weight align student!
2022-09-28 05:29:48,294 [foster.py] => darknet eval: 
2022-09-28 05:29:48,294 [foster.py] => CNN top1 curve: 44.34
2022-09-28 05:29:48,294 [foster.py] => CNN top5 curve: 88.91
2022-09-28 05:29:48,295 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 05:29:57,919 [foster.py] => Exemplar size: 380
2022-09-28 05:29:57,919 [trainer.py] => CNN: {'total': 57.04, 'old': 56.6, 'new': 59.68, 'base': 69.27, 'compound': 48.43}
2022-09-28 05:29:57,919 [trainer.py] => CNN top1 curve: [87.71, 68.67, 57.74, 53.91, 57.04]
2022-09-28 05:29:57,919 [trainer.py] => CNN base curve: [87.71, 84.92, 80.45, 71.51, 69.27]
2022-09-28 05:29:57,919 [trainer.py] => CNN old curve: [87.71, 84.92, 63.86, 52.9, 56.6]
2022-09-28 05:29:57,919 [trainer.py] => CNN new curve: [0, 27.14, 32.79, 59.02, 59.68]
2022-09-28 05:29:57,919 [trainer.py] => CNN compound curve: [0, 27.14, 26.72, 37.5, 48.43]
2022-09-28 05:29:57,919 [trainer.py] => NME: {'total': 58.43, 'old': 57.68, 'new': 62.9, 'base': 62.01, 'compound': 55.91}
2022-09-28 05:29:57,919 [trainer.py] => NME top1 curve: [87.71, 71.49, 61.61, 62.8, 58.43]
2022-09-28 05:29:57,919 [trainer.py] => NME base curve: [87.71, 77.09, 72.07, 68.72, 62.01]
2022-09-28 05:29:57,919 [trainer.py] => NME old curve: [87.71, 77.09, 62.65, 59.03, 57.68]
2022-09-28 05:29:57,919 [trainer.py] => NME new curve: [0, 57.14, 57.38, 81.97, 62.9]
2022-09-28 05:29:57,919 [trainer.py] => NME compound curve: [0, 57.14, 47.33, 57.29, 55.91]
2022-09-28 05:29:58,152 [foster.py] => Learning on 19-22
2022-09-28 05:29:58,153 [foster.py] => All params: 22396607
2022-09-28 05:29:58,153 [foster.py] => Trainable params: 11210348
2022-09-28 05:29:58,173 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 05:30:01,299 [foster.py] => Task 5, Epoch 1/34 => Loss 6.871, Loss_clf 1.947, Loss_fe 2.648, Loss_kd 1.966, Train_accy 37.61, Test_accy 45.94
2022-09-28 05:30:03,377 [foster.py] => Task 5, Epoch 2/34 => Loss 5.340, Loss_clf 1.127, Loss_fe 1.924, Loss_kd 1.977, Train_accy 47.04
2022-09-28 05:30:05,559 [foster.py] => Task 5, Epoch 3/34 => Loss 4.982, Loss_clf 1.047, Loss_fe 1.650, Loss_kd 1.974, Train_accy 46.74
2022-09-28 05:30:07,614 [foster.py] => Task 5, Epoch 4/34 => Loss 4.914, Loss_clf 1.023, Loss_fe 1.595, Loss_kd 1.983, Train_accy 47.44
2022-09-28 05:30:09,708 [foster.py] => Task 5, Epoch 5/34 => Loss 4.752, Loss_clf 0.988, Loss_fe 1.459, Loss_kd 1.991, Train_accy 49.25
2022-09-28 05:30:12,795 [foster.py] => Task 5, Epoch 6/34 => Loss 4.637, Loss_clf 0.965, Loss_fe 1.378, Loss_kd 1.981, Train_accy 48.55, Test_accy 48.71
2022-09-28 05:30:14,885 [foster.py] => Task 5, Epoch 7/34 => Loss 4.538, Loss_clf 0.935, Loss_fe 1.321, Loss_kd 1.971, Train_accy 48.65
2022-09-28 05:30:17,038 [foster.py] => Task 5, Epoch 8/34 => Loss 4.432, Loss_clf 0.908, Loss_fe 1.231, Loss_kd 1.980, Train_accy 49.45
2022-09-28 05:30:19,118 [foster.py] => Task 5, Epoch 9/34 => Loss 4.405, Loss_clf 0.894, Loss_fe 1.211, Loss_kd 1.986, Train_accy 47.54
2022-09-28 05:30:21,211 [foster.py] => Task 5, Epoch 10/34 => Loss 4.383, Loss_clf 0.900, Loss_fe 1.194, Loss_kd 1.977, Train_accy 48.35
2022-09-28 05:30:24,310 [foster.py] => Task 5, Epoch 11/34 => Loss 4.387, Loss_clf 0.911, Loss_fe 1.166, Loss_kd 1.995, Train_accy 48.55, Test_accy 49.50
2022-09-28 05:30:26,412 [foster.py] => Task 5, Epoch 12/34 => Loss 4.271, Loss_clf 0.860, Loss_fe 1.111, Loss_kd 1.987, Train_accy 49.45
2022-09-28 05:30:28,492 [foster.py] => Task 5, Epoch 13/34 => Loss 4.232, Loss_clf 0.865, Loss_fe 1.074, Loss_kd 1.981, Train_accy 50.95
2022-09-28 05:30:30,593 [foster.py] => Task 5, Epoch 14/34 => Loss 4.212, Loss_clf 0.850, Loss_fe 1.068, Loss_kd 1.981, Train_accy 48.04
2022-09-28 05:30:32,667 [foster.py] => Task 5, Epoch 15/34 => Loss 4.185, Loss_clf 0.850, Loss_fe 1.046, Loss_kd 1.978, Train_accy 50.75
2022-09-28 05:30:35,772 [foster.py] => Task 5, Epoch 16/34 => Loss 4.176, Loss_clf 0.829, Loss_fe 1.054, Loss_kd 1.981, Train_accy 50.05, Test_accy 50.30
2022-09-28 05:30:37,889 [foster.py] => Task 5, Epoch 17/34 => Loss 4.099, Loss_clf 0.824, Loss_fe 0.992, Loss_kd 1.972, Train_accy 50.35
2022-09-28 05:30:39,975 [foster.py] => Task 5, Epoch 18/34 => Loss 4.154, Loss_clf 0.827, Loss_fe 1.026, Loss_kd 1.988, Train_accy 50.25
2022-09-28 05:30:42,047 [foster.py] => Task 5, Epoch 19/34 => Loss 4.098, Loss_clf 0.806, Loss_fe 0.989, Loss_kd 1.989, Train_accy 51.25
2022-09-28 05:30:44,128 [foster.py] => Task 5, Epoch 20/34 => Loss 4.089, Loss_clf 0.814, Loss_fe 0.972, Loss_kd 1.989, Train_accy 49.65
2022-09-28 05:30:47,221 [foster.py] => Task 5, Epoch 21/34 => Loss 4.118, Loss_clf 0.820, Loss_fe 0.992, Loss_kd 1.992, Train_accy 50.05, Test_accy 49.50
2022-09-28 05:30:49,338 [foster.py] => Task 5, Epoch 22/34 => Loss 4.056, Loss_clf 0.798, Loss_fe 0.958, Loss_kd 1.987, Train_accy 49.85
2022-09-28 05:30:51,425 [foster.py] => Task 5, Epoch 23/34 => Loss 4.052, Loss_clf 0.780, Loss_fe 0.962, Loss_kd 1.994, Train_accy 52.16
2022-09-28 05:30:53,487 [foster.py] => Task 5, Epoch 24/34 => Loss 4.029, Loss_clf 0.789, Loss_fe 0.944, Loss_kd 1.983, Train_accy 49.85
2022-09-28 05:30:55,597 [foster.py] => Task 5, Epoch 25/34 => Loss 3.999, Loss_clf 0.773, Loss_fe 0.916, Loss_kd 1.996, Train_accy 50.55
2022-09-28 05:30:58,661 [foster.py] => Task 5, Epoch 26/34 => Loss 3.972, Loss_clf 0.763, Loss_fe 0.912, Loss_kd 1.984, Train_accy 51.45, Test_accy 50.89
2022-09-28 05:31:00,801 [foster.py] => Task 5, Epoch 27/34 => Loss 4.026, Loss_clf 0.799, Loss_fe 0.929, Loss_kd 1.985, Train_accy 52.76
2022-09-28 05:31:02,910 [foster.py] => Task 5, Epoch 28/34 => Loss 4.000, Loss_clf 0.778, Loss_fe 0.925, Loss_kd 1.984, Train_accy 51.55
2022-09-28 05:31:04,986 [foster.py] => Task 5, Epoch 29/34 => Loss 4.033, Loss_clf 0.785, Loss_fe 0.947, Loss_kd 1.988, Train_accy 50.85
2022-09-28 05:31:07,084 [foster.py] => Task 5, Epoch 30/34 => Loss 3.979, Loss_clf 0.766, Loss_fe 0.903, Loss_kd 1.995, Train_accy 53.66
2022-09-28 05:31:10,191 [foster.py] => Task 5, Epoch 31/34 => Loss 4.004, Loss_clf 0.777, Loss_fe 0.925, Loss_kd 1.987, Train_accy 50.15, Test_accy 51.29
2022-09-28 05:31:12,286 [foster.py] => Task 5, Epoch 32/34 => Loss 3.984, Loss_clf 0.770, Loss_fe 0.910, Loss_kd 1.989, Train_accy 52.46
2022-09-28 05:31:14,369 [foster.py] => Task 5, Epoch 33/34 => Loss 4.032, Loss_clf 0.795, Loss_fe 0.930, Loss_kd 1.992, Train_accy 52.16
2022-09-28 05:31:16,487 [foster.py] => Task 5, Epoch 34/34 => Loss 4.026, Loss_clf 0.780, Loss_fe 0.938, Loss_kd 1.993, Train_accy 50.05
2022-09-28 05:31:16,487 [foster.py] => do not weight align teacher!
2022-09-28 05:31:16,488 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 05:31:19,894 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.494,  Train_accy 19.16, Test_accy 38.22
2022-09-28 05:31:22,225 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.493,  Train_accy 20.86
2022-09-28 05:31:24,559 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.473,  Train_accy 20.56
2022-09-28 05:31:26,902 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.472,  Train_accy 20.86
2022-09-28 05:31:29,254 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.462,  Train_accy 20.66
2022-09-28 05:31:32,451 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.451,  Train_accy 21.26, Test_accy 38.61
2022-09-28 05:31:34,830 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.453,  Train_accy 22.07
2022-09-28 05:31:37,150 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.447,  Train_accy 20.36
2022-09-28 05:31:39,478 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.438,  Train_accy 21.26
2022-09-28 05:31:41,800 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.440,  Train_accy 21.36
2022-09-28 05:31:44,965 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.431,  Train_accy 22.07, Test_accy 40.79
2022-09-28 05:31:47,306 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.437,  Train_accy 21.06
2022-09-28 05:31:49,645 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.439,  Train_accy 22.27
2022-09-28 05:31:52,021 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.431,  Train_accy 22.17
2022-09-28 05:31:54,358 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.432,  Train_accy 21.06
2022-09-28 05:31:57,562 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.427,  Train_accy 21.26, Test_accy 40.99
2022-09-28 05:31:59,970 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.433,  Train_accy 21.77
2022-09-28 05:32:02,339 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.431,  Train_accy 21.06
2022-09-28 05:32:04,679 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.421,  Train_accy 21.97
2022-09-28 05:32:06,998 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.424,  Train_accy 22.47
2022-09-28 05:32:10,168 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.444,  Train_accy 21.97, Test_accy 40.59
2022-09-28 05:32:12,500 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.431,  Train_accy 22.17
2022-09-28 05:32:14,879 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.433,  Train_accy 21.16
2022-09-28 05:32:17,200 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.429,  Train_accy 22.17
2022-09-28 05:32:19,583 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.442,  Train_accy 21.36
2022-09-28 05:32:22,794 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.428,  Train_accy 22.07, Test_accy 40.99
2022-09-28 05:32:22,795 [foster.py] => do not weight align student!
2022-09-28 05:32:23,643 [foster.py] => darknet eval: 
2022-09-28 05:32:23,643 [foster.py] => CNN top1 curve: 40.99
2022-09-28 05:32:23,643 [foster.py] => CNN top5 curve: 82.38
2022-09-28 05:32:23,643 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 05:32:34,346 [foster.py] => Exemplar size: 440
2022-09-28 05:32:34,346 [trainer.py] => CNN: {'total': 51.09, 'old': 53.58, 'new': 36.11, 'base': 64.25, 'compound': 43.87}
2022-09-28 05:32:34,346 [trainer.py] => CNN top1 curve: [87.71, 68.67, 57.74, 53.91, 57.04, 51.09]
2022-09-28 05:32:34,346 [trainer.py] => CNN base curve: [87.71, 84.92, 80.45, 71.51, 69.27, 64.25]
2022-09-28 05:32:34,346 [trainer.py] => CNN old curve: [87.71, 84.92, 63.86, 52.9, 56.6, 53.58]
2022-09-28 05:32:34,346 [trainer.py] => CNN new curve: [0, 27.14, 32.79, 59.02, 59.68, 36.11]
2022-09-28 05:32:34,346 [trainer.py] => CNN compound curve: [0, 27.14, 26.72, 37.5, 48.43, 43.87]
2022-09-28 05:32:34,346 [trainer.py] => NME: {'total': 51.88, 'old': 53.81, 'new': 40.28, 'base': 59.22, 'compound': 47.85}
2022-09-28 05:32:34,346 [trainer.py] => NME top1 curve: [87.71, 71.49, 61.61, 62.8, 58.43, 51.88]
2022-09-28 05:32:34,346 [trainer.py] => NME base curve: [87.71, 77.09, 72.07, 68.72, 62.01, 59.22]
2022-09-28 05:32:34,346 [trainer.py] => NME old curve: [87.71, 77.09, 62.65, 59.03, 57.68, 53.81]
2022-09-28 05:32:34,346 [trainer.py] => NME new curve: [0, 57.14, 57.38, 81.97, 62.9, 40.28]
2022-09-28 05:32:34,346 [trainer.py] => NME compound curve: [0, 57.14, 47.33, 57.29, 55.91, 47.85]
2022-09-28 05:32:34,347 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 05:32:34,348 [trainer.py] => prefix: cil
2022-09-28 05:32:34,348 [trainer.py] => dataset: CFEE
2022-09-28 05:32:34,348 [trainer.py] => memory_size: 2000
2022-09-28 05:32:34,348 [trainer.py] => memory_per_class: 20
2022-09-28 05:32:34,348 [trainer.py] => fixed_memory: True
2022-09-28 05:32:34,348 [trainer.py] => shuffle: True
2022-09-28 05:32:34,348 [trainer.py] => init_cls: 7
2022-09-28 05:32:34,348 [trainer.py] => increment: 3
2022-09-28 05:32:34,348 [trainer.py] => model_name: foster
2022-09-28 05:32:34,348 [trainer.py] => convnet_type: resnet18
2022-09-28 05:32:34,348 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 05:32:34,348 [trainer.py] => seed: 1993
2022-09-28 05:32:34,348 [trainer.py] => beta1: 0.96
2022-09-28 05:32:34,348 [trainer.py] => beta2: 0.97
2022-09-28 05:32:34,348 [trainer.py] => oofc: ft
2022-09-28 05:32:34,348 [trainer.py] => is_teacher_wa: False
2022-09-28 05:32:34,348 [trainer.py] => is_student_wa: False
2022-09-28 05:32:34,348 [trainer.py] => lambda_okd: 1
2022-09-28 05:32:34,348 [trainer.py] => wa_value: 1
2022-09-28 05:32:34,348 [trainer.py] => init_epochs: 40
2022-09-28 05:32:34,348 [trainer.py] => init_lr: 0.01
2022-09-28 05:32:34,348 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 05:32:34,348 [trainer.py] => boosting_epochs: 34
2022-09-28 05:32:34,348 [trainer.py] => compression_epochs: 26
2022-09-28 05:32:34,348 [trainer.py] => lr: 0.001
2022-09-28 05:32:34,348 [trainer.py] => batch_size: 32
2022-09-28 05:32:34,348 [trainer.py] => weight_decay: 0.0005
2022-09-28 05:32:34,348 [trainer.py] => num_workers: 8
2022-09-28 05:32:34,348 [trainer.py] => T: 2
2022-09-28 05:32:34,348 [trainer.py] => nb_runs: 3
2022-09-28 05:32:34,348 [trainer.py] => fold: 10
2022-09-28 05:32:34,349 [data.py] => ========== Fold:4 ==========
2022-09-28 05:32:34,354 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 12, 10, 19, 21, 17, 18, 8, 7, 9, 14, 15, 13, 11, 16]
2022-09-28 05:32:34,570 [foster.py] => Learning on 0-7
2022-09-28 05:32:34,570 [foster.py] => All params: 11183694
2022-09-28 05:32:34,570 [foster.py] => Trainable params: 11183694
2022-09-28 05:32:36,999 [foster.py] => Task 0, Epoch 1/40 => Loss 1.277, Train_accy 54.68
2022-09-28 05:32:40,007 [foster.py] => Task 0, Epoch 2/40 => Loss 0.526, Train_accy 81.95, Test_accy 86.11
2022-09-28 05:32:43,029 [foster.py] => Task 0, Epoch 3/40 => Loss 0.349, Train_accy 87.76, Test_accy 85.42
2022-09-28 05:32:45,999 [foster.py] => Task 0, Epoch 4/40 => Loss 0.292, Train_accy 90.09, Test_accy 88.19
2022-09-28 05:32:49,028 [foster.py] => Task 0, Epoch 5/40 => Loss 0.221, Train_accy 92.14, Test_accy 89.58
2022-09-28 05:32:51,396 [foster.py] => Task 0, Epoch 6/40 => Loss 0.195, Train_accy 92.89
2022-09-28 05:32:54,360 [foster.py] => Task 0, Epoch 7/40 => Loss 0.150, Train_accy 94.60, Test_accy 83.33
2022-09-28 05:32:57,323 [foster.py] => Task 0, Epoch 8/40 => Loss 0.113, Train_accy 96.65, Test_accy 86.11
2022-09-28 05:33:00,290 [foster.py] => Task 0, Epoch 9/40 => Loss 0.097, Train_accy 97.47, Test_accy 85.42
2022-09-28 05:33:03,268 [foster.py] => Task 0, Epoch 10/40 => Loss 0.090, Train_accy 97.61, Test_accy 85.42
2022-09-28 05:33:05,655 [foster.py] => Task 0, Epoch 11/40 => Loss 0.074, Train_accy 97.54
2022-09-28 05:33:08,652 [foster.py] => Task 0, Epoch 12/40 => Loss 0.068, Train_accy 97.68, Test_accy 86.11
2022-09-28 05:33:11,678 [foster.py] => Task 0, Epoch 13/40 => Loss 0.060, Train_accy 98.22, Test_accy 83.33
2022-09-28 05:33:14,676 [foster.py] => Task 0, Epoch 14/40 => Loss 0.055, Train_accy 98.09, Test_accy 84.03
2022-09-28 05:33:17,687 [foster.py] => Task 0, Epoch 15/40 => Loss 0.047, Train_accy 98.84, Test_accy 86.81
2022-09-28 05:33:20,071 [foster.py] => Task 0, Epoch 16/40 => Loss 0.047, Train_accy 98.63
2022-09-28 05:33:23,035 [foster.py] => Task 0, Epoch 17/40 => Loss 0.033, Train_accy 99.18, Test_accy 85.42
2022-09-28 05:33:26,028 [foster.py] => Task 0, Epoch 18/40 => Loss 0.031, Train_accy 99.32, Test_accy 87.50
2022-09-28 05:33:28,995 [foster.py] => Task 0, Epoch 19/40 => Loss 0.039, Train_accy 98.91, Test_accy 86.81
2022-09-28 05:33:32,011 [foster.py] => Task 0, Epoch 20/40 => Loss 0.027, Train_accy 99.45, Test_accy 85.42
2022-09-28 05:33:34,394 [foster.py] => Task 0, Epoch 21/40 => Loss 0.026, Train_accy 99.45
2022-09-28 05:33:37,372 [foster.py] => Task 0, Epoch 22/40 => Loss 0.018, Train_accy 99.93, Test_accy 84.72
2022-09-28 05:33:40,364 [foster.py] => Task 0, Epoch 23/40 => Loss 0.019, Train_accy 99.73, Test_accy 87.50
2022-09-28 05:33:43,361 [foster.py] => Task 0, Epoch 24/40 => Loss 0.021, Train_accy 99.38, Test_accy 86.11
2022-09-28 05:33:46,337 [foster.py] => Task 0, Epoch 25/40 => Loss 0.014, Train_accy 99.93, Test_accy 84.72
2022-09-28 05:33:48,703 [foster.py] => Task 0, Epoch 26/40 => Loss 0.015, Train_accy 99.93
2022-09-28 05:33:51,699 [foster.py] => Task 0, Epoch 27/40 => Loss 0.015, Train_accy 99.79, Test_accy 85.42
2022-09-28 05:33:54,717 [foster.py] => Task 0, Epoch 28/40 => Loss 0.016, Train_accy 99.93, Test_accy 85.42
2022-09-28 05:33:57,730 [foster.py] => Task 0, Epoch 29/40 => Loss 0.015, Train_accy 99.73, Test_accy 85.42
2022-09-28 05:34:00,717 [foster.py] => Task 0, Epoch 30/40 => Loss 0.022, Train_accy 99.32, Test_accy 85.42
2022-09-28 05:34:03,075 [foster.py] => Task 0, Epoch 31/40 => Loss 0.017, Train_accy 99.66
2022-09-28 05:34:06,043 [foster.py] => Task 0, Epoch 32/40 => Loss 0.021, Train_accy 99.79, Test_accy 85.42
2022-09-28 05:34:09,023 [foster.py] => Task 0, Epoch 33/40 => Loss 0.017, Train_accy 99.79, Test_accy 86.11
2022-09-28 05:34:12,008 [foster.py] => Task 0, Epoch 34/40 => Loss 0.017, Train_accy 99.73, Test_accy 86.11
2022-09-28 05:34:15,062 [foster.py] => Task 0, Epoch 35/40 => Loss 0.013, Train_accy 99.86, Test_accy 84.72
2022-09-28 05:34:17,462 [foster.py] => Task 0, Epoch 36/40 => Loss 0.011, Train_accy 99.93
2022-09-28 05:34:20,526 [foster.py] => Task 0, Epoch 37/40 => Loss 0.014, Train_accy 100.00, Test_accy 85.42
2022-09-28 05:34:23,524 [foster.py] => Task 0, Epoch 38/40 => Loss 0.013, Train_accy 99.86, Test_accy 85.42
2022-09-28 05:34:26,503 [foster.py] => Task 0, Epoch 39/40 => Loss 0.012, Train_accy 99.86, Test_accy 85.42
2022-09-28 05:34:29,547 [foster.py] => Task 0, Epoch 40/40 => Loss 0.012, Train_accy 99.86, Test_accy 85.42
2022-09-28 05:34:29,548 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 05:34:36,434 [foster.py] => Exemplar size: 140
2022-09-28 05:34:36,434 [trainer.py] => CNN: {'total': 85.42, 'old': 85.42, 'new': 0, 'base': 85.42, 'compound': 0}
2022-09-28 05:34:36,434 [trainer.py] => CNN top1 curve: [85.42]
2022-09-28 05:34:36,434 [trainer.py] => CNN base curve: [85.42]
2022-09-28 05:34:36,434 [trainer.py] => CNN old curve: [85.42]
2022-09-28 05:34:36,434 [trainer.py] => CNN new curve: [0]
2022-09-28 05:34:36,434 [trainer.py] => CNN compound curve: [0]
2022-09-28 05:34:36,434 [trainer.py] => NME: {'total': 85.42, 'old': 85.42, 'new': 0, 'base': 85.42, 'compound': 0}
2022-09-28 05:34:36,434 [trainer.py] => NME top1 curve: [85.42]
2022-09-28 05:34:36,434 [trainer.py] => NME base curve: [85.42]
2022-09-28 05:34:36,434 [trainer.py] => NME old curve: [85.42]
2022-09-28 05:34:36,434 [trainer.py] => NME new curve: [0]
2022-09-28 05:34:36,434 [trainer.py] => NME compound curve: [0]
2022-09-28 05:34:36,667 [foster.py] => Learning on 7-10
2022-09-28 05:34:36,668 [foster.py] => All params: 22371995
2022-09-28 05:34:36,668 [foster.py] => Trainable params: 11191892
2022-09-28 05:34:36,688 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 05:34:39,191 [foster.py] => Task 1, Epoch 1/34 => Loss 4.991, Loss_clf 2.573, Loss_fe 1.880, Loss_kd 0.376, Train_accy 34.68, Test_accy 59.74
2022-09-28 05:34:40,885 [foster.py] => Task 1, Epoch 2/34 => Loss 2.797, Loss_clf 0.954, Loss_fe 1.300, Loss_kd 0.380, Train_accy 65.32
2022-09-28 05:34:42,611 [foster.py] => Task 1, Epoch 3/34 => Loss 2.255, Loss_clf 0.653, Loss_fe 1.117, Loss_kd 0.339, Train_accy 42.24
2022-09-28 05:34:44,317 [foster.py] => Task 1, Epoch 4/34 => Loss 2.098, Loss_clf 0.627, Loss_fe 0.997, Loss_kd 0.332, Train_accy 33.06
2022-09-28 05:34:46,084 [foster.py] => Task 1, Epoch 5/34 => Loss 2.015, Loss_clf 0.593, Loss_fe 0.938, Loss_kd 0.339, Train_accy 41.16
2022-09-28 05:34:48,506 [foster.py] => Task 1, Epoch 6/34 => Loss 1.949, Loss_clf 0.578, Loss_fe 0.899, Loss_kd 0.331, Train_accy 36.03, Test_accy 61.04
2022-09-28 05:34:50,227 [foster.py] => Task 1, Epoch 7/34 => Loss 1.886, Loss_clf 0.578, Loss_fe 0.830, Loss_kd 0.335, Train_accy 37.65
2022-09-28 05:34:51,962 [foster.py] => Task 1, Epoch 8/34 => Loss 1.843, Loss_clf 0.572, Loss_fe 0.808, Loss_kd 0.324, Train_accy 38.06
2022-09-28 05:34:53,644 [foster.py] => Task 1, Epoch 9/34 => Loss 1.814, Loss_clf 0.563, Loss_fe 0.782, Loss_kd 0.329, Train_accy 40.62
2022-09-28 05:34:55,383 [foster.py] => Task 1, Epoch 10/34 => Loss 1.795, Loss_clf 0.554, Loss_fe 0.747, Loss_kd 0.346, Train_accy 36.44
2022-09-28 05:34:57,840 [foster.py] => Task 1, Epoch 11/34 => Loss 1.740, Loss_clf 0.536, Loss_fe 0.718, Loss_kd 0.341, Train_accy 39.00, Test_accy 61.47
2022-09-28 05:34:59,567 [foster.py] => Task 1, Epoch 12/34 => Loss 1.664, Loss_clf 0.501, Loss_fe 0.688, Loss_kd 0.333, Train_accy 41.70
2022-09-28 05:35:01,254 [foster.py] => Task 1, Epoch 13/34 => Loss 1.648, Loss_clf 0.500, Loss_fe 0.687, Loss_kd 0.323, Train_accy 40.35
2022-09-28 05:35:02,956 [foster.py] => Task 1, Epoch 14/34 => Loss 1.653, Loss_clf 0.509, Loss_fe 0.675, Loss_kd 0.329, Train_accy 41.03
2022-09-28 05:35:04,652 [foster.py] => Task 1, Epoch 15/34 => Loss 1.629, Loss_clf 0.504, Loss_fe 0.651, Loss_kd 0.331, Train_accy 39.54
2022-09-28 05:35:07,087 [foster.py] => Task 1, Epoch 16/34 => Loss 1.542, Loss_clf 0.460, Loss_fe 0.609, Loss_kd 0.331, Train_accy 41.16, Test_accy 62.34
2022-09-28 05:35:08,776 [foster.py] => Task 1, Epoch 17/34 => Loss 1.562, Loss_clf 0.472, Loss_fe 0.615, Loss_kd 0.333, Train_accy 43.45
2022-09-28 05:35:10,547 [foster.py] => Task 1, Epoch 18/34 => Loss 1.575, Loss_clf 0.475, Loss_fe 0.617, Loss_kd 0.338, Train_accy 41.03
2022-09-28 05:35:12,244 [foster.py] => Task 1, Epoch 19/34 => Loss 1.607, Loss_clf 0.488, Loss_fe 0.634, Loss_kd 0.340, Train_accy 40.49
2022-09-28 05:35:13,919 [foster.py] => Task 1, Epoch 20/34 => Loss 1.533, Loss_clf 0.464, Loss_fe 0.595, Loss_kd 0.332, Train_accy 42.78
2022-09-28 05:35:16,389 [foster.py] => Task 1, Epoch 21/34 => Loss 1.514, Loss_clf 0.445, Loss_fe 0.597, Loss_kd 0.330, Train_accy 43.05, Test_accy 62.34
2022-09-28 05:35:18,085 [foster.py] => Task 1, Epoch 22/34 => Loss 1.459, Loss_clf 0.426, Loss_fe 0.556, Loss_kd 0.334, Train_accy 41.70
2022-09-28 05:35:19,840 [foster.py] => Task 1, Epoch 23/34 => Loss 1.531, Loss_clf 0.477, Loss_fe 0.584, Loss_kd 0.329, Train_accy 42.24
2022-09-28 05:35:21,571 [foster.py] => Task 1, Epoch 24/34 => Loss 1.499, Loss_clf 0.457, Loss_fe 0.582, Loss_kd 0.322, Train_accy 43.86
2022-09-28 05:35:23,302 [foster.py] => Task 1, Epoch 25/34 => Loss 1.488, Loss_clf 0.443, Loss_fe 0.582, Loss_kd 0.324, Train_accy 44.67
2022-09-28 05:35:25,737 [foster.py] => Task 1, Epoch 26/34 => Loss 1.449, Loss_clf 0.425, Loss_fe 0.551, Loss_kd 0.331, Train_accy 43.45, Test_accy 63.64
2022-09-28 05:35:27,450 [foster.py] => Task 1, Epoch 27/34 => Loss 1.464, Loss_clf 0.429, Loss_fe 0.560, Loss_kd 0.332, Train_accy 44.80
2022-09-28 05:35:29,162 [foster.py] => Task 1, Epoch 28/34 => Loss 1.489, Loss_clf 0.444, Loss_fe 0.576, Loss_kd 0.328, Train_accy 43.32
2022-09-28 05:35:30,930 [foster.py] => Task 1, Epoch 29/34 => Loss 1.458, Loss_clf 0.416, Loss_fe 0.554, Loss_kd 0.341, Train_accy 44.80
2022-09-28 05:35:32,635 [foster.py] => Task 1, Epoch 30/34 => Loss 1.514, Loss_clf 0.448, Loss_fe 0.592, Loss_kd 0.332, Train_accy 42.65
2022-09-28 05:35:35,123 [foster.py] => Task 1, Epoch 31/34 => Loss 1.452, Loss_clf 0.426, Loss_fe 0.559, Loss_kd 0.327, Train_accy 42.65, Test_accy 62.34
2022-09-28 05:35:36,855 [foster.py] => Task 1, Epoch 32/34 => Loss 1.490, Loss_clf 0.435, Loss_fe 0.563, Loss_kd 0.344, Train_accy 43.86
2022-09-28 05:35:38,541 [foster.py] => Task 1, Epoch 33/34 => Loss 1.467, Loss_clf 0.430, Loss_fe 0.559, Loss_kd 0.335, Train_accy 43.72
2022-09-28 05:35:40,249 [foster.py] => Task 1, Epoch 34/34 => Loss 1.472, Loss_clf 0.437, Loss_fe 0.566, Loss_kd 0.329, Train_accy 43.72
2022-09-28 05:35:40,249 [foster.py] => do not weight align teacher!
2022-09-28 05:35:40,249 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 05:35:43,064 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.468,  Train_accy 18.08, Test_accy 53.25
2022-09-28 05:35:44,941 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.326,  Train_accy 18.76
2022-09-28 05:35:46,860 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.265,  Train_accy 19.03
2022-09-28 05:35:48,787 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.208,  Train_accy 19.30
2022-09-28 05:35:50,682 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.190,  Train_accy 19.57
2022-09-28 05:35:53,280 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.168,  Train_accy 20.11, Test_accy 53.25
2022-09-28 05:35:55,182 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.141,  Train_accy 20.38
2022-09-28 05:35:57,052 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.151,  Train_accy 21.32
2022-09-28 05:35:58,994 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.141,  Train_accy 20.92
2022-09-28 05:36:00,867 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.152,  Train_accy 21.19
2022-09-28 05:36:03,434 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.141,  Train_accy 21.32, Test_accy 54.11
2022-09-28 05:36:05,342 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.168,  Train_accy 21.59
2022-09-28 05:36:07,285 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.168,  Train_accy 21.73
2022-09-28 05:36:09,234 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.127,  Train_accy 21.59
2022-09-28 05:36:11,105 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.134,  Train_accy 21.59
2022-09-28 05:36:13,693 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.162,  Train_accy 21.19, Test_accy 53.25
2022-09-28 05:36:15,570 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.133,  Train_accy 21.73
2022-09-28 05:36:17,478 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.107,  Train_accy 21.73
2022-09-28 05:36:19,432 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.147,  Train_accy 21.73
2022-09-28 05:36:21,353 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.124,  Train_accy 20.92
2022-09-28 05:36:23,910 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.120,  Train_accy 21.59, Test_accy 54.55
2022-09-28 05:36:25,809 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.114,  Train_accy 22.27
2022-09-28 05:36:27,772 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.135,  Train_accy 22.40
2022-09-28 05:36:29,713 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.113,  Train_accy 21.86
2022-09-28 05:36:31,633 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.114,  Train_accy 21.46
2022-09-28 05:36:34,241 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.104,  Train_accy 21.59, Test_accy 53.68
2022-09-28 05:36:34,242 [foster.py] => do not weight align student!
2022-09-28 05:36:34,907 [foster.py] => darknet eval: 
2022-09-28 05:36:34,908 [foster.py] => CNN top1 curve: 53.68
2022-09-28 05:36:34,908 [foster.py] => CNN top5 curve: 97.4
2022-09-28 05:36:34,908 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 05:36:41,255 [foster.py] => Exemplar size: 200
2022-09-28 05:36:41,255 [trainer.py] => CNN: {'total': 63.2, 'old': 84.72, 'new': 27.59, 'base': 84.72, 'compound': 27.59}
2022-09-28 05:36:41,255 [trainer.py] => CNN top1 curve: [85.42, 63.2]
2022-09-28 05:36:41,255 [trainer.py] => CNN base curve: [85.42, 84.72]
2022-09-28 05:36:41,255 [trainer.py] => CNN old curve: [85.42, 84.72]
2022-09-28 05:36:41,255 [trainer.py] => CNN new curve: [0, 27.59]
2022-09-28 05:36:41,255 [trainer.py] => CNN compound curve: [0, 27.59]
2022-09-28 05:36:41,255 [trainer.py] => NME: {'total': 73.59, 'old': 84.03, 'new': 56.32, 'base': 84.03, 'compound': 56.32}
2022-09-28 05:36:41,255 [trainer.py] => NME top1 curve: [85.42, 73.59]
2022-09-28 05:36:41,255 [trainer.py] => NME base curve: [85.42, 84.03]
2022-09-28 05:36:41,255 [trainer.py] => NME old curve: [85.42, 84.03]
2022-09-28 05:36:41,255 [trainer.py] => NME new curve: [0, 56.32]
2022-09-28 05:36:41,255 [trainer.py] => NME compound curve: [0, 56.32]
2022-09-28 05:36:41,486 [foster.py] => Learning on 10-13
2022-09-28 05:36:41,486 [foster.py] => All params: 22378148
2022-09-28 05:36:41,487 [foster.py] => Trainable params: 11196506
2022-09-28 05:36:41,507 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 05:36:44,172 [foster.py] => Task 2, Epoch 1/34 => Loss 5.531, Loss_clf 2.302, Loss_fe 2.082, Loss_kd 0.883, Train_accy 38.44, Test_accy 46.96
2022-09-28 05:36:45,968 [foster.py] => Task 2, Epoch 2/34 => Loss 3.497, Loss_clf 0.929, Loss_fe 1.460, Loss_kd 0.852, Train_accy 48.05
2022-09-28 05:36:47,842 [foster.py] => Task 2, Epoch 3/34 => Loss 3.160, Loss_clf 0.784, Loss_fe 1.292, Loss_kd 0.834, Train_accy 38.93
2022-09-28 05:36:49,674 [foster.py] => Task 2, Epoch 4/34 => Loss 2.975, Loss_clf 0.726, Loss_fe 1.163, Loss_kd 0.835, Train_accy 40.39
2022-09-28 05:36:51,503 [foster.py] => Task 2, Epoch 5/34 => Loss 2.857, Loss_clf 0.702, Loss_fe 1.076, Loss_kd 0.830, Train_accy 42.34
2022-09-28 05:36:54,143 [foster.py] => Task 2, Epoch 6/34 => Loss 2.795, Loss_clf 0.685, Loss_fe 1.020, Loss_kd 0.838, Train_accy 39.66, Test_accy 47.64
2022-09-28 05:36:55,984 [foster.py] => Task 2, Epoch 7/34 => Loss 2.710, Loss_clf 0.657, Loss_fe 0.967, Loss_kd 0.836, Train_accy 41.36
2022-09-28 05:36:57,788 [foster.py] => Task 2, Epoch 8/34 => Loss 2.622, Loss_clf 0.636, Loss_fe 0.905, Loss_kd 0.832, Train_accy 41.36
2022-09-28 05:36:59,593 [foster.py] => Task 2, Epoch 9/34 => Loss 2.609, Loss_clf 0.638, Loss_fe 0.880, Loss_kd 0.839, Train_accy 41.73
2022-09-28 05:37:01,438 [foster.py] => Task 2, Epoch 10/34 => Loss 2.553, Loss_clf 0.627, Loss_fe 0.840, Loss_kd 0.835, Train_accy 41.24
2022-09-28 05:37:04,095 [foster.py] => Task 2, Epoch 11/34 => Loss 2.497, Loss_clf 0.592, Loss_fe 0.799, Loss_kd 0.851, Train_accy 43.43, Test_accy 50.34
2022-09-28 05:37:05,897 [foster.py] => Task 2, Epoch 12/34 => Loss 2.503, Loss_clf 0.606, Loss_fe 0.805, Loss_kd 0.840, Train_accy 42.70
2022-09-28 05:37:07,714 [foster.py] => Task 2, Epoch 13/34 => Loss 2.481, Loss_clf 0.603, Loss_fe 0.785, Loss_kd 0.841, Train_accy 43.80
2022-09-28 05:37:09,560 [foster.py] => Task 2, Epoch 14/34 => Loss 2.431, Loss_clf 0.589, Loss_fe 0.749, Loss_kd 0.841, Train_accy 43.19
2022-09-28 05:37:11,362 [foster.py] => Task 2, Epoch 15/34 => Loss 2.398, Loss_clf 0.575, Loss_fe 0.734, Loss_kd 0.837, Train_accy 42.94
2022-09-28 05:37:13,966 [foster.py] => Task 2, Epoch 16/34 => Loss 2.381, Loss_clf 0.574, Loss_fe 0.718, Loss_kd 0.837, Train_accy 43.55, Test_accy 51.01
2022-09-28 05:37:15,784 [foster.py] => Task 2, Epoch 17/34 => Loss 2.376, Loss_clf 0.576, Loss_fe 0.720, Loss_kd 0.830, Train_accy 41.12
2022-09-28 05:37:17,611 [foster.py] => Task 2, Epoch 18/34 => Loss 2.314, Loss_clf 0.538, Loss_fe 0.688, Loss_kd 0.838, Train_accy 43.43
2022-09-28 05:37:19,420 [foster.py] => Task 2, Epoch 19/34 => Loss 2.309, Loss_clf 0.543, Loss_fe 0.682, Loss_kd 0.834, Train_accy 43.43
2022-09-28 05:37:21,283 [foster.py] => Task 2, Epoch 20/34 => Loss 2.280, Loss_clf 0.532, Loss_fe 0.661, Loss_kd 0.836, Train_accy 44.04
2022-09-28 05:37:23,885 [foster.py] => Task 2, Epoch 21/34 => Loss 2.261, Loss_clf 0.511, Loss_fe 0.648, Loss_kd 0.847, Train_accy 46.23, Test_accy 51.35
2022-09-28 05:37:25,720 [foster.py] => Task 2, Epoch 22/34 => Loss 2.283, Loss_clf 0.528, Loss_fe 0.656, Loss_kd 0.845, Train_accy 44.40
2022-09-28 05:37:27,599 [foster.py] => Task 2, Epoch 23/34 => Loss 2.273, Loss_clf 0.528, Loss_fe 0.652, Loss_kd 0.841, Train_accy 44.65
2022-09-28 05:37:29,464 [foster.py] => Task 2, Epoch 24/34 => Loss 2.264, Loss_clf 0.527, Loss_fe 0.643, Loss_kd 0.841, Train_accy 44.04
2022-09-28 05:37:31,347 [foster.py] => Task 2, Epoch 25/34 => Loss 2.245, Loss_clf 0.513, Loss_fe 0.637, Loss_kd 0.842, Train_accy 43.80
2022-09-28 05:37:34,047 [foster.py] => Task 2, Epoch 26/34 => Loss 2.232, Loss_clf 0.503, Loss_fe 0.632, Loss_kd 0.843, Train_accy 44.65, Test_accy 51.35
2022-09-28 05:37:35,869 [foster.py] => Task 2, Epoch 27/34 => Loss 2.205, Loss_clf 0.504, Loss_fe 0.609, Loss_kd 0.840, Train_accy 44.89
2022-09-28 05:37:37,698 [foster.py] => Task 2, Epoch 28/34 => Loss 2.225, Loss_clf 0.504, Loss_fe 0.626, Loss_kd 0.843, Train_accy 43.67
2022-09-28 05:37:39,505 [foster.py] => Task 2, Epoch 29/34 => Loss 2.229, Loss_clf 0.510, Loss_fe 0.621, Loss_kd 0.845, Train_accy 44.53
2022-09-28 05:37:41,357 [foster.py] => Task 2, Epoch 30/34 => Loss 2.229, Loss_clf 0.514, Loss_fe 0.619, Loss_kd 0.843, Train_accy 44.89
2022-09-28 05:37:43,972 [foster.py] => Task 2, Epoch 31/34 => Loss 2.222, Loss_clf 0.506, Loss_fe 0.623, Loss_kd 0.840, Train_accy 44.28, Test_accy 51.35
2022-09-28 05:37:45,817 [foster.py] => Task 2, Epoch 32/34 => Loss 2.218, Loss_clf 0.508, Loss_fe 0.619, Loss_kd 0.840, Train_accy 42.70
2022-09-28 05:37:47,667 [foster.py] => Task 2, Epoch 33/34 => Loss 2.228, Loss_clf 0.507, Loss_fe 0.620, Loss_kd 0.847, Train_accy 45.26
2022-09-28 05:37:49,534 [foster.py] => Task 2, Epoch 34/34 => Loss 2.218, Loss_clf 0.506, Loss_fe 0.619, Loss_kd 0.841, Train_accy 45.99
2022-09-28 05:37:49,534 [foster.py] => do not weight align teacher!
2022-09-28 05:37:49,535 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 05:37:52,549 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.852,  Train_accy 17.03, Test_accy 42.57
2022-09-28 05:37:54,614 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.703,  Train_accy 17.15
2022-09-28 05:37:56,681 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.645,  Train_accy 17.27
2022-09-28 05:37:58,692 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.617,  Train_accy 17.27
2022-09-28 05:38:00,702 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.599,  Train_accy 17.27
2022-09-28 05:38:03,450 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.594,  Train_accy 17.76, Test_accy 42.23
2022-09-28 05:38:05,496 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.576,  Train_accy 18.00
2022-09-28 05:38:07,543 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.576,  Train_accy 17.76
2022-09-28 05:38:09,563 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.569,  Train_accy 18.00
2022-09-28 05:38:11,638 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.566,  Train_accy 18.25
2022-09-28 05:38:14,407 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.556,  Train_accy 19.10, Test_accy 42.57
2022-09-28 05:38:16,503 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.559,  Train_accy 19.34
2022-09-28 05:38:18,548 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.555,  Train_accy 18.37
2022-09-28 05:38:20,556 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.548,  Train_accy 18.98
2022-09-28 05:38:22,599 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.556,  Train_accy 18.86
2022-09-28 05:38:25,368 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.556,  Train_accy 18.73, Test_accy 43.92
2022-09-28 05:38:27,415 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.541,  Train_accy 18.98
2022-09-28 05:38:29,516 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.552,  Train_accy 18.37
2022-09-28 05:38:31,581 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.541,  Train_accy 18.61
2022-09-28 05:38:33,597 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.539,  Train_accy 19.34
2022-09-28 05:38:36,372 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.545,  Train_accy 19.95, Test_accy 43.58
2022-09-28 05:38:38,404 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.547,  Train_accy 18.73
2022-09-28 05:38:40,408 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.551,  Train_accy 18.49
2022-09-28 05:38:42,437 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.542,  Train_accy 18.86
2022-09-28 05:38:44,492 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.542,  Train_accy 18.98
2022-09-28 05:38:47,262 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.542,  Train_accy 18.49, Test_accy 43.24
2022-09-28 05:38:47,263 [foster.py] => do not weight align student!
2022-09-28 05:38:47,992 [foster.py] => darknet eval: 
2022-09-28 05:38:47,993 [foster.py] => CNN top1 curve: 43.24
2022-09-28 05:38:47,993 [foster.py] => CNN top5 curve: 95.27
2022-09-28 05:38:47,993 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 05:38:55,452 [foster.py] => Exemplar size: 260
2022-09-28 05:38:55,452 [trainer.py] => CNN: {'total': 51.35, 'old': 59.74, 'new': 21.54, 'base': 82.64, 'compound': 21.71}
2022-09-28 05:38:55,452 [trainer.py] => CNN top1 curve: [85.42, 63.2, 51.35]
2022-09-28 05:38:55,452 [trainer.py] => CNN base curve: [85.42, 84.72, 82.64]
2022-09-28 05:38:55,452 [trainer.py] => CNN old curve: [85.42, 84.72, 59.74]
2022-09-28 05:38:55,452 [trainer.py] => CNN new curve: [0, 27.59, 21.54]
2022-09-28 05:38:55,452 [trainer.py] => CNN compound curve: [0, 27.59, 21.71]
2022-09-28 05:38:55,452 [trainer.py] => NME: {'total': 59.46, 'old': 63.2, 'new': 46.15, 'base': 77.08, 'compound': 42.76}
2022-09-28 05:38:55,452 [trainer.py] => NME top1 curve: [85.42, 73.59, 59.46]
2022-09-28 05:38:55,452 [trainer.py] => NME base curve: [85.42, 84.03, 77.08]
2022-09-28 05:38:55,452 [trainer.py] => NME old curve: [85.42, 84.03, 63.2]
2022-09-28 05:38:55,452 [trainer.py] => NME new curve: [0, 56.32, 46.15]
2022-09-28 05:38:55,452 [trainer.py] => NME compound curve: [0, 56.32, 42.76]
2022-09-28 05:38:55,684 [foster.py] => Learning on 13-16
2022-09-28 05:38:55,685 [foster.py] => All params: 22384301
2022-09-28 05:38:55,685 [foster.py] => Trainable params: 11201120
2022-09-28 05:38:55,705 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 05:38:58,463 [foster.py] => Task 3, Epoch 1/34 => Loss 5.683, Loss_clf 1.985, Loss_fe 2.106, Loss_kd 1.294, Train_accy 45.04, Test_accy 44.54
2022-09-28 05:39:00,381 [foster.py] => Task 3, Epoch 2/34 => Loss 3.905, Loss_clf 0.843, Loss_fe 1.504, Loss_kd 1.266, Train_accy 46.18
2022-09-28 05:39:02,291 [foster.py] => Task 3, Epoch 3/34 => Loss 3.543, Loss_clf 0.713, Loss_fe 1.285, Loss_kd 1.256, Train_accy 44.01
2022-09-28 05:39:04,237 [foster.py] => Task 3, Epoch 4/34 => Loss 3.401, Loss_clf 0.696, Loss_fe 1.168, Loss_kd 1.249, Train_accy 44.47
2022-09-28 05:39:06,123 [foster.py] => Task 3, Epoch 5/34 => Loss 3.262, Loss_clf 0.632, Loss_fe 1.074, Loss_kd 1.264, Train_accy 44.81
2022-09-28 05:39:08,931 [foster.py] => Task 3, Epoch 6/34 => Loss 3.148, Loss_clf 0.613, Loss_fe 0.987, Loss_kd 1.257, Train_accy 47.78, Test_accy 44.54
2022-09-28 05:39:10,835 [foster.py] => Task 3, Epoch 7/34 => Loss 3.085, Loss_clf 0.604, Loss_fe 0.934, Loss_kd 1.256, Train_accy 45.04
2022-09-28 05:39:12,750 [foster.py] => Task 3, Epoch 8/34 => Loss 3.022, Loss_clf 0.575, Loss_fe 0.896, Loss_kd 1.261, Train_accy 48.23
2022-09-28 05:39:14,645 [foster.py] => Task 3, Epoch 9/34 => Loss 2.984, Loss_clf 0.577, Loss_fe 0.860, Loss_kd 1.257, Train_accy 49.37
2022-09-28 05:39:16,538 [foster.py] => Task 3, Epoch 10/34 => Loss 2.966, Loss_clf 0.592, Loss_fe 0.835, Loss_kd 1.250, Train_accy 47.55
2022-09-28 05:39:19,300 [foster.py] => Task 3, Epoch 11/34 => Loss 2.920, Loss_clf 0.563, Loss_fe 0.810, Loss_kd 1.257, Train_accy 47.89, Test_accy 46.17
2022-09-28 05:39:21,226 [foster.py] => Task 3, Epoch 12/34 => Loss 2.865, Loss_clf 0.549, Loss_fe 0.761, Loss_kd 1.264, Train_accy 50.51
2022-09-28 05:39:23,167 [foster.py] => Task 3, Epoch 13/34 => Loss 2.814, Loss_clf 0.531, Loss_fe 0.740, Loss_kd 1.253, Train_accy 48.80
2022-09-28 05:39:25,093 [foster.py] => Task 3, Epoch 14/34 => Loss 2.813, Loss_clf 0.533, Loss_fe 0.725, Loss_kd 1.264, Train_accy 53.14
2022-09-28 05:39:26,973 [foster.py] => Task 3, Epoch 15/34 => Loss 2.760, Loss_clf 0.516, Loss_fe 0.696, Loss_kd 1.258, Train_accy 46.64
2022-09-28 05:39:29,707 [foster.py] => Task 3, Epoch 16/34 => Loss 2.734, Loss_clf 0.514, Loss_fe 0.675, Loss_kd 1.255, Train_accy 52.79, Test_accy 47.81
2022-09-28 05:39:31,618 [foster.py] => Task 3, Epoch 17/34 => Loss 2.716, Loss_clf 0.498, Loss_fe 0.668, Loss_kd 1.259, Train_accy 50.40
2022-09-28 05:39:33,515 [foster.py] => Task 3, Epoch 18/34 => Loss 2.719, Loss_clf 0.496, Loss_fe 0.673, Loss_kd 1.259, Train_accy 49.83
2022-09-28 05:39:35,455 [foster.py] => Task 3, Epoch 19/34 => Loss 2.741, Loss_clf 0.518, Loss_fe 0.675, Loss_kd 1.257, Train_accy 51.43
2022-09-28 05:39:37,352 [foster.py] => Task 3, Epoch 20/34 => Loss 2.669, Loss_clf 0.476, Loss_fe 0.635, Loss_kd 1.266, Train_accy 51.08
2022-09-28 05:39:40,151 [foster.py] => Task 3, Epoch 21/34 => Loss 2.677, Loss_clf 0.474, Loss_fe 0.635, Loss_kd 1.275, Train_accy 51.65, Test_accy 47.54
2022-09-28 05:39:42,081 [foster.py] => Task 3, Epoch 22/34 => Loss 2.664, Loss_clf 0.487, Loss_fe 0.625, Loss_kd 1.262, Train_accy 51.08
2022-09-28 05:39:43,956 [foster.py] => Task 3, Epoch 23/34 => Loss 2.662, Loss_clf 0.489, Loss_fe 0.625, Loss_kd 1.258, Train_accy 50.74
2022-09-28 05:39:45,847 [foster.py] => Task 3, Epoch 24/34 => Loss 2.609, Loss_clf 0.461, Loss_fe 0.605, Loss_kd 1.254, Train_accy 51.08
2022-09-28 05:39:47,779 [foster.py] => Task 3, Epoch 25/34 => Loss 2.634, Loss_clf 0.481, Loss_fe 0.611, Loss_kd 1.254, Train_accy 50.40
2022-09-28 05:39:50,557 [foster.py] => Task 3, Epoch 26/34 => Loss 2.622, Loss_clf 0.460, Loss_fe 0.598, Loss_kd 1.270, Train_accy 52.00, Test_accy 47.81
2022-09-28 05:39:52,442 [foster.py] => Task 3, Epoch 27/34 => Loss 2.612, Loss_clf 0.466, Loss_fe 0.601, Loss_kd 1.255, Train_accy 52.57
2022-09-28 05:39:54,362 [foster.py] => Task 3, Epoch 28/34 => Loss 2.596, Loss_clf 0.456, Loss_fe 0.588, Loss_kd 1.261, Train_accy 53.82
2022-09-28 05:39:56,280 [foster.py] => Task 3, Epoch 29/34 => Loss 2.601, Loss_clf 0.460, Loss_fe 0.590, Loss_kd 1.261, Train_accy 52.79
2022-09-28 05:39:58,187 [foster.py] => Task 3, Epoch 30/34 => Loss 2.572, Loss_clf 0.441, Loss_fe 0.583, Loss_kd 1.258, Train_accy 50.17
2022-09-28 05:40:00,960 [foster.py] => Task 3, Epoch 31/34 => Loss 2.588, Loss_clf 0.454, Loss_fe 0.588, Loss_kd 1.255, Train_accy 52.68, Test_accy 49.18
2022-09-28 05:40:02,903 [foster.py] => Task 3, Epoch 32/34 => Loss 2.598, Loss_clf 0.460, Loss_fe 0.587, Loss_kd 1.259, Train_accy 52.22
2022-09-28 05:40:04,790 [foster.py] => Task 3, Epoch 33/34 => Loss 2.579, Loss_clf 0.455, Loss_fe 0.582, Loss_kd 1.253, Train_accy 52.00
2022-09-28 05:40:06,687 [foster.py] => Task 3, Epoch 34/34 => Loss 2.579, Loss_clf 0.444, Loss_fe 0.581, Loss_kd 1.262, Train_accy 52.34
2022-09-28 05:40:06,687 [foster.py] => do not weight align teacher!
2022-09-28 05:40:06,687 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 05:40:09,877 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.086,  Train_accy 16.65, Test_accy 33.33
2022-09-28 05:40:12,023 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.006,  Train_accy 16.99
2022-09-28 05:40:14,136 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 1.969,  Train_accy 17.22
2022-09-28 05:40:16,302 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 1.940,  Train_accy 17.22
2022-09-28 05:40:18,447 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.930,  Train_accy 17.56
2022-09-28 05:40:21,352 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.904,  Train_accy 18.02, Test_accy 37.98
2022-09-28 05:40:23,473 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.915,  Train_accy 17.90
2022-09-28 05:40:25,623 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.907,  Train_accy 18.13
2022-09-28 05:40:27,791 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.896,  Train_accy 18.59
2022-09-28 05:40:29,945 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.892,  Train_accy 18.13
2022-09-28 05:40:32,874 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.893,  Train_accy 19.27, Test_accy 38.25
2022-09-28 05:40:34,987 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.890,  Train_accy 18.59
2022-09-28 05:40:37,109 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.874,  Train_accy 20.18
2022-09-28 05:40:39,217 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.897,  Train_accy 20.75
2022-09-28 05:40:41,392 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.877,  Train_accy 20.41
2022-09-28 05:40:44,304 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.872,  Train_accy 21.21, Test_accy 38.25
2022-09-28 05:40:46,450 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.869,  Train_accy 20.41
2022-09-28 05:40:48,563 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.867,  Train_accy 20.18
2022-09-28 05:40:50,699 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.857,  Train_accy 20.98
2022-09-28 05:40:52,837 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.855,  Train_accy 21.09
2022-09-28 05:40:55,740 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.871,  Train_accy 21.32, Test_accy 38.52
2022-09-28 05:40:57,843 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.865,  Train_accy 20.64
2022-09-28 05:40:59,962 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.855,  Train_accy 22.12
2022-09-28 05:41:02,060 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.883,  Train_accy 20.98
2022-09-28 05:41:04,191 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.863,  Train_accy 20.52
2022-09-28 05:41:07,065 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.872,  Train_accy 20.30, Test_accy 38.80
2022-09-28 05:41:07,065 [foster.py] => do not weight align student!
2022-09-28 05:41:07,810 [foster.py] => darknet eval: 
2022-09-28 05:41:07,810 [foster.py] => CNN top1 curve: 38.8
2022-09-28 05:41:07,810 [foster.py] => CNN top5 curve: 91.53
2022-09-28 05:41:07,811 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 05:41:16,232 [foster.py] => Exemplar size: 320
2022-09-28 05:41:16,232 [trainer.py] => CNN: {'total': 47.81, 'old': 51.35, 'new': 32.86, 'base': 79.17, 'compound': 27.48}
2022-09-28 05:41:16,232 [trainer.py] => CNN top1 curve: [85.42, 63.2, 51.35, 47.81]
2022-09-28 05:41:16,232 [trainer.py] => CNN base curve: [85.42, 84.72, 82.64, 79.17]
2022-09-28 05:41:16,232 [trainer.py] => CNN old curve: [85.42, 84.72, 59.74, 51.35]
2022-09-28 05:41:16,232 [trainer.py] => CNN new curve: [0, 27.59, 21.54, 32.86]
2022-09-28 05:41:16,232 [trainer.py] => CNN compound curve: [0, 27.59, 21.71, 27.48]
2022-09-28 05:41:16,232 [trainer.py] => NME: {'total': 58.2, 'old': 56.76, 'new': 64.29, 'base': 72.22, 'compound': 49.1}
2022-09-28 05:41:16,232 [trainer.py] => NME top1 curve: [85.42, 73.59, 59.46, 58.2]
2022-09-28 05:41:16,232 [trainer.py] => NME base curve: [85.42, 84.03, 77.08, 72.22]
2022-09-28 05:41:16,232 [trainer.py] => NME old curve: [85.42, 84.03, 63.2, 56.76]
2022-09-28 05:41:16,232 [trainer.py] => NME new curve: [0, 56.32, 46.15, 64.29]
2022-09-28 05:41:16,232 [trainer.py] => NME compound curve: [0, 56.32, 42.76, 49.1]
2022-09-28 05:41:16,464 [foster.py] => Learning on 16-19
2022-09-28 05:41:16,464 [foster.py] => All params: 22390454
2022-09-28 05:41:16,464 [foster.py] => Trainable params: 11205734
2022-09-28 05:41:16,485 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 05:41:19,501 [foster.py] => Task 4, Epoch 1/34 => Loss 6.692, Loss_clf 2.084, Loss_fe 2.604, Loss_kd 1.688, Train_accy 41.70, Test_accy 41.24
2022-09-28 05:41:21,514 [foster.py] => Task 4, Epoch 2/34 => Loss 4.783, Loss_clf 0.956, Loss_fe 1.815, Loss_kd 1.695, Train_accy 46.91
2022-09-28 05:41:23,575 [foster.py] => Task 4, Epoch 3/34 => Loss 4.396, Loss_clf 0.849, Loss_fe 1.531, Loss_kd 1.698, Train_accy 52.02
2022-09-28 05:41:25,584 [foster.py] => Task 4, Epoch 4/34 => Loss 4.222, Loss_clf 0.809, Loss_fe 1.403, Loss_kd 1.693, Train_accy 52.66
2022-09-28 05:41:27,619 [foster.py] => Task 4, Epoch 5/34 => Loss 4.085, Loss_clf 0.780, Loss_fe 1.289, Loss_kd 1.698, Train_accy 52.13
2022-09-28 05:41:30,552 [foster.py] => Task 4, Epoch 6/34 => Loss 3.932, Loss_clf 0.733, Loss_fe 1.192, Loss_kd 1.690, Train_accy 52.23, Test_accy 47.93
2022-09-28 05:41:32,574 [foster.py] => Task 4, Epoch 7/34 => Loss 3.846, Loss_clf 0.715, Loss_fe 1.120, Loss_kd 1.694, Train_accy 55.74
2022-09-28 05:41:34,596 [foster.py] => Task 4, Epoch 8/34 => Loss 3.774, Loss_clf 0.705, Loss_fe 1.055, Loss_kd 1.696, Train_accy 52.02
2022-09-28 05:41:36,603 [foster.py] => Task 4, Epoch 9/34 => Loss 3.742, Loss_clf 0.702, Loss_fe 1.022, Loss_kd 1.701, Train_accy 57.66
2022-09-28 05:41:38,593 [foster.py] => Task 4, Epoch 10/34 => Loss 3.668, Loss_clf 0.671, Loss_fe 0.983, Loss_kd 1.696, Train_accy 56.28
2022-09-28 05:41:41,511 [foster.py] => Task 4, Epoch 11/34 => Loss 3.641, Loss_clf 0.667, Loss_fe 0.955, Loss_kd 1.701, Train_accy 55.53, Test_accy 49.08
2022-09-28 05:41:43,523 [foster.py] => Task 4, Epoch 12/34 => Loss 3.549, Loss_clf 0.637, Loss_fe 0.899, Loss_kd 1.695, Train_accy 57.66
2022-09-28 05:41:45,545 [foster.py] => Task 4, Epoch 13/34 => Loss 3.525, Loss_clf 0.644, Loss_fe 0.864, Loss_kd 1.698, Train_accy 55.64
2022-09-28 05:41:47,544 [foster.py] => Task 4, Epoch 14/34 => Loss 3.479, Loss_clf 0.621, Loss_fe 0.845, Loss_kd 1.695, Train_accy 58.72
2022-09-28 05:41:49,541 [foster.py] => Task 4, Epoch 15/34 => Loss 3.469, Loss_clf 0.618, Loss_fe 0.829, Loss_kd 1.703, Train_accy 55.53
2022-09-28 05:41:52,506 [foster.py] => Task 4, Epoch 16/34 => Loss 3.477, Loss_clf 0.634, Loss_fe 0.817, Loss_kd 1.706, Train_accy 60.53, Test_accy 50.00
2022-09-28 05:41:54,524 [foster.py] => Task 4, Epoch 17/34 => Loss 3.417, Loss_clf 0.603, Loss_fe 0.794, Loss_kd 1.702, Train_accy 56.28
2022-09-28 05:41:56,543 [foster.py] => Task 4, Epoch 18/34 => Loss 3.348, Loss_clf 0.582, Loss_fe 0.755, Loss_kd 1.693, Train_accy 58.19
2022-09-28 05:41:58,522 [foster.py] => Task 4, Epoch 19/34 => Loss 3.381, Loss_clf 0.600, Loss_fe 0.763, Loss_kd 1.700, Train_accy 57.34
2022-09-28 05:42:00,555 [foster.py] => Task 4, Epoch 20/34 => Loss 3.353, Loss_clf 0.577, Loss_fe 0.754, Loss_kd 1.702, Train_accy 59.36
2022-09-28 05:42:03,455 [foster.py] => Task 4, Epoch 21/34 => Loss 3.333, Loss_clf 0.573, Loss_fe 0.740, Loss_kd 1.701, Train_accy 59.04, Test_accy 50.23
2022-09-28 05:42:05,465 [foster.py] => Task 4, Epoch 22/34 => Loss 3.321, Loss_clf 0.571, Loss_fe 0.730, Loss_kd 1.701, Train_accy 59.68
2022-09-28 05:42:07,448 [foster.py] => Task 4, Epoch 23/34 => Loss 3.302, Loss_clf 0.559, Loss_fe 0.710, Loss_kd 1.712, Train_accy 61.28
2022-09-28 05:42:09,496 [foster.py] => Task 4, Epoch 24/34 => Loss 3.335, Loss_clf 0.576, Loss_fe 0.737, Loss_kd 1.703, Train_accy 59.68
2022-09-28 05:42:11,480 [foster.py] => Task 4, Epoch 25/34 => Loss 3.288, Loss_clf 0.555, Loss_fe 0.710, Loss_kd 1.704, Train_accy 60.53
2022-09-28 05:42:14,378 [foster.py] => Task 4, Epoch 26/34 => Loss 3.340, Loss_clf 0.583, Loss_fe 0.730, Loss_kd 1.707, Train_accy 58.72, Test_accy 50.92
2022-09-28 05:42:16,383 [foster.py] => Task 4, Epoch 27/34 => Loss 3.270, Loss_clf 0.549, Loss_fe 0.702, Loss_kd 1.701, Train_accy 59.36
2022-09-28 05:42:18,440 [foster.py] => Task 4, Epoch 28/34 => Loss 3.256, Loss_clf 0.541, Loss_fe 0.690, Loss_kd 1.705, Train_accy 60.43
2022-09-28 05:42:20,456 [foster.py] => Task 4, Epoch 29/34 => Loss 3.256, Loss_clf 0.544, Loss_fe 0.678, Loss_kd 1.713, Train_accy 60.74
2022-09-28 05:42:22,489 [foster.py] => Task 4, Epoch 30/34 => Loss 3.255, Loss_clf 0.557, Loss_fe 0.683, Loss_kd 1.697, Train_accy 59.79
2022-09-28 05:42:25,436 [foster.py] => Task 4, Epoch 31/34 => Loss 3.284, Loss_clf 0.554, Loss_fe 0.702, Loss_kd 1.708, Train_accy 59.36, Test_accy 51.15
2022-09-28 05:42:27,415 [foster.py] => Task 4, Epoch 32/34 => Loss 3.280, Loss_clf 0.558, Loss_fe 0.695, Loss_kd 1.707, Train_accy 59.47
2022-09-28 05:42:29,446 [foster.py] => Task 4, Epoch 33/34 => Loss 3.271, Loss_clf 0.553, Loss_fe 0.692, Loss_kd 1.706, Train_accy 59.79
2022-09-28 05:42:31,431 [foster.py] => Task 4, Epoch 34/34 => Loss 3.273, Loss_clf 0.550, Loss_fe 0.690, Loss_kd 1.711, Train_accy 60.11
2022-09-28 05:42:31,431 [foster.py] => do not weight align teacher!
2022-09-28 05:42:31,432 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 05:42:34,701 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.423,  Train_accy 15.64, Test_accy 32.26
2022-09-28 05:42:36,950 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.340,  Train_accy 16.28
2022-09-28 05:42:39,224 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.296,  Train_accy 18.51
2022-09-28 05:42:41,471 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.276,  Train_accy 17.77
2022-09-28 05:42:43,710 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.265,  Train_accy 18.51
2022-09-28 05:42:46,816 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.258,  Train_accy 18.30, Test_accy 35.02
2022-09-28 05:42:49,075 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.238,  Train_accy 19.36
2022-09-28 05:42:51,295 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.245,  Train_accy 19.89
2022-09-28 05:42:53,533 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.241,  Train_accy 19.89
2022-09-28 05:42:55,805 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.230,  Train_accy 19.26
2022-09-28 05:42:58,861 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.230,  Train_accy 19.36, Test_accy 36.18
2022-09-28 05:43:01,104 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.232,  Train_accy 19.26
2022-09-28 05:43:03,379 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.216,  Train_accy 19.47
2022-09-28 05:43:05,601 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.213,  Train_accy 20.21
2022-09-28 05:43:07,828 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.216,  Train_accy 19.36
2022-09-28 05:43:10,912 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.216,  Train_accy 19.47, Test_accy 36.18
2022-09-28 05:43:13,155 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.225,  Train_accy 21.06
2022-09-28 05:43:15,381 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.210,  Train_accy 19.79
2022-09-28 05:43:17,649 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.219,  Train_accy 20.32
2022-09-28 05:43:19,906 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.207,  Train_accy 20.96
2022-09-28 05:43:22,938 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.212,  Train_accy 20.53, Test_accy 37.56
2022-09-28 05:43:25,171 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.215,  Train_accy 20.00
2022-09-28 05:43:27,443 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.208,  Train_accy 20.32
2022-09-28 05:43:29,715 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.215,  Train_accy 20.53
2022-09-28 05:43:31,962 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.206,  Train_accy 21.60
2022-09-28 05:43:34,987 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.209,  Train_accy 20.00, Test_accy 37.33
2022-09-28 05:43:34,988 [foster.py] => do not weight align student!
2022-09-28 05:43:35,817 [foster.py] => darknet eval: 
2022-09-28 05:43:35,817 [foster.py] => CNN top1 curve: 37.33
2022-09-28 05:43:35,817 [foster.py] => CNN top5 curve: 88.02
2022-09-28 05:43:35,817 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 05:43:45,396 [foster.py] => Exemplar size: 380
2022-09-28 05:43:45,397 [trainer.py] => CNN: {'total': 50.92, 'old': 49.73, 'new': 57.35, 'base': 74.31, 'compound': 39.31}
2022-09-28 05:43:45,397 [trainer.py] => CNN top1 curve: [85.42, 63.2, 51.35, 47.81, 50.92]
2022-09-28 05:43:45,397 [trainer.py] => CNN base curve: [85.42, 84.72, 82.64, 79.17, 74.31]
2022-09-28 05:43:45,397 [trainer.py] => CNN old curve: [85.42, 84.72, 59.74, 51.35, 49.73]
2022-09-28 05:43:45,397 [trainer.py] => CNN new curve: [0, 27.59, 21.54, 32.86, 57.35]
2022-09-28 05:43:45,397 [trainer.py] => CNN compound curve: [0, 27.59, 21.71, 27.48, 39.31]
2022-09-28 05:43:45,397 [trainer.py] => NME: {'total': 57.14, 'old': 54.92, 'new': 69.12, 'base': 72.22, 'compound': 49.66}
2022-09-28 05:43:45,397 [trainer.py] => NME top1 curve: [85.42, 73.59, 59.46, 58.2, 57.14]
2022-09-28 05:43:45,397 [trainer.py] => NME base curve: [85.42, 84.03, 77.08, 72.22, 72.22]
2022-09-28 05:43:45,397 [trainer.py] => NME old curve: [85.42, 84.03, 63.2, 56.76, 54.92]
2022-09-28 05:43:45,397 [trainer.py] => NME new curve: [0, 56.32, 46.15, 64.29, 69.12]
2022-09-28 05:43:45,397 [trainer.py] => NME compound curve: [0, 56.32, 42.76, 49.1, 49.66]
2022-09-28 05:43:45,629 [foster.py] => Learning on 19-22
2022-09-28 05:43:45,630 [foster.py] => All params: 22396607
2022-09-28 05:43:45,630 [foster.py] => Trainable params: 11210348
2022-09-28 05:43:45,651 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 05:43:48,759 [foster.py] => Task 5, Epoch 1/34 => Loss 6.661, Loss_clf 1.937, Loss_fe 2.474, Loss_kd 1.943, Train_accy 40.38, Test_accy 39.01
2022-09-28 05:43:50,876 [foster.py] => Task 5, Epoch 2/34 => Loss 5.174, Loss_clf 1.131, Loss_fe 1.791, Loss_kd 1.945, Train_accy 37.07
2022-09-28 05:43:52,989 [foster.py] => Task 5, Epoch 3/34 => Loss 4.944, Loss_clf 1.076, Loss_fe 1.626, Loss_kd 1.935, Train_accy 39.78
2022-09-28 05:43:55,108 [foster.py] => Task 5, Epoch 4/34 => Loss 4.850, Loss_clf 1.066, Loss_fe 1.521, Loss_kd 1.954, Train_accy 42.48
2022-09-28 05:43:57,200 [foster.py] => Task 5, Epoch 5/34 => Loss 4.622, Loss_clf 0.989, Loss_fe 1.395, Loss_kd 1.933, Train_accy 40.58
2022-09-28 05:44:00,320 [foster.py] => Task 5, Epoch 6/34 => Loss 4.506, Loss_clf 0.949, Loss_fe 1.317, Loss_kd 1.934, Train_accy 42.38, Test_accy 42.18
2022-09-28 05:44:02,432 [foster.py] => Task 5, Epoch 7/34 => Loss 4.475, Loss_clf 0.940, Loss_fe 1.289, Loss_kd 1.940, Train_accy 43.49
2022-09-28 05:44:04,553 [foster.py] => Task 5, Epoch 8/34 => Loss 4.394, Loss_clf 0.930, Loss_fe 1.213, Loss_kd 1.944, Train_accy 41.18
2022-09-28 05:44:06,658 [foster.py] => Task 5, Epoch 9/34 => Loss 4.373, Loss_clf 0.940, Loss_fe 1.190, Loss_kd 1.937, Train_accy 42.38
2022-09-28 05:44:08,727 [foster.py] => Task 5, Epoch 10/34 => Loss 4.307, Loss_clf 0.901, Loss_fe 1.159, Loss_kd 1.940, Train_accy 41.98
2022-09-28 05:44:11,845 [foster.py] => Task 5, Epoch 11/34 => Loss 4.248, Loss_clf 0.878, Loss_fe 1.121, Loss_kd 1.942, Train_accy 41.08, Test_accy 44.55
2022-09-28 05:44:13,966 [foster.py] => Task 5, Epoch 12/34 => Loss 4.234, Loss_clf 0.889, Loss_fe 1.094, Loss_kd 1.944, Train_accy 42.38
2022-09-28 05:44:16,080 [foster.py] => Task 5, Epoch 13/34 => Loss 4.237, Loss_clf 0.882, Loss_fe 1.108, Loss_kd 1.940, Train_accy 41.88
2022-09-28 05:44:18,158 [foster.py] => Task 5, Epoch 14/34 => Loss 4.190, Loss_clf 0.869, Loss_fe 1.079, Loss_kd 1.937, Train_accy 42.48
2022-09-28 05:44:20,266 [foster.py] => Task 5, Epoch 15/34 => Loss 4.162, Loss_clf 0.866, Loss_fe 1.042, Loss_kd 1.947, Train_accy 40.78
2022-09-28 05:44:23,323 [foster.py] => Task 5, Epoch 16/34 => Loss 4.077, Loss_clf 0.829, Loss_fe 0.995, Loss_kd 1.946, Train_accy 41.98, Test_accy 45.54
2022-09-28 05:44:25,409 [foster.py] => Task 5, Epoch 17/34 => Loss 4.064, Loss_clf 0.827, Loss_fe 0.981, Loss_kd 1.948, Train_accy 42.79
2022-09-28 05:44:27,553 [foster.py] => Task 5, Epoch 18/34 => Loss 4.094, Loss_clf 0.840, Loss_fe 0.991, Loss_kd 1.955, Train_accy 42.89
2022-09-28 05:44:29,624 [foster.py] => Task 5, Epoch 19/34 => Loss 4.031, Loss_clf 0.812, Loss_fe 0.970, Loss_kd 1.942, Train_accy 43.29
2022-09-28 05:44:31,722 [foster.py] => Task 5, Epoch 20/34 => Loss 4.043, Loss_clf 0.823, Loss_fe 0.960, Loss_kd 1.951, Train_accy 43.89
2022-09-28 05:44:34,804 [foster.py] => Task 5, Epoch 21/34 => Loss 4.006, Loss_clf 0.809, Loss_fe 0.946, Loss_kd 1.944, Train_accy 43.29, Test_accy 46.73
2022-09-28 05:44:36,867 [foster.py] => Task 5, Epoch 22/34 => Loss 4.009, Loss_clf 0.806, Loss_fe 0.942, Loss_kd 1.953, Train_accy 42.99
2022-09-28 05:44:39,008 [foster.py] => Task 5, Epoch 23/34 => Loss 4.003, Loss_clf 0.803, Loss_fe 0.948, Loss_kd 1.945, Train_accy 42.89
2022-09-28 05:44:41,121 [foster.py] => Task 5, Epoch 24/34 => Loss 4.001, Loss_clf 0.803, Loss_fe 0.942, Loss_kd 1.948, Train_accy 43.39
2022-09-28 05:44:43,237 [foster.py] => Task 5, Epoch 25/34 => Loss 3.952, Loss_clf 0.770, Loss_fe 0.922, Loss_kd 1.952, Train_accy 44.09
2022-09-28 05:44:46,375 [foster.py] => Task 5, Epoch 26/34 => Loss 3.919, Loss_clf 0.767, Loss_fe 0.896, Loss_kd 1.948, Train_accy 43.49, Test_accy 46.53
2022-09-28 05:44:48,482 [foster.py] => Task 5, Epoch 27/34 => Loss 3.969, Loss_clf 0.781, Loss_fe 0.931, Loss_kd 1.949, Train_accy 44.29
2022-09-28 05:44:50,563 [foster.py] => Task 5, Epoch 28/34 => Loss 3.970, Loss_clf 0.791, Loss_fe 0.924, Loss_kd 1.947, Train_accy 45.39
2022-09-28 05:44:52,688 [foster.py] => Task 5, Epoch 29/34 => Loss 3.969, Loss_clf 0.787, Loss_fe 0.930, Loss_kd 1.945, Train_accy 43.59
2022-09-28 05:44:54,837 [foster.py] => Task 5, Epoch 30/34 => Loss 3.927, Loss_clf 0.764, Loss_fe 0.908, Loss_kd 1.948, Train_accy 44.79
2022-09-28 05:44:57,952 [foster.py] => Task 5, Epoch 31/34 => Loss 3.891, Loss_clf 0.759, Loss_fe 0.882, Loss_kd 1.943, Train_accy 43.69, Test_accy 46.73
2022-09-28 05:45:00,019 [foster.py] => Task 5, Epoch 32/34 => Loss 3.878, Loss_clf 0.740, Loss_fe 0.879, Loss_kd 1.950, Train_accy 44.29
2022-09-28 05:45:02,123 [foster.py] => Task 5, Epoch 33/34 => Loss 3.981, Loss_clf 0.789, Loss_fe 0.930, Loss_kd 1.954, Train_accy 44.09
2022-09-28 05:45:04,212 [foster.py] => Task 5, Epoch 34/34 => Loss 4.000, Loss_clf 0.800, Loss_fe 0.936, Loss_kd 1.955, Train_accy 44.59
2022-09-28 05:45:04,212 [foster.py] => do not weight align teacher!
2022-09-28 05:45:04,213 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 05:45:07,626 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.457,  Train_accy 19.64, Test_accy 32.87
2022-09-28 05:45:09,961 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.441,  Train_accy 19.44
2022-09-28 05:45:12,318 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.443,  Train_accy 19.64
2022-09-28 05:45:14,715 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.424,  Train_accy 20.24
2022-09-28 05:45:17,062 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.413,  Train_accy 19.84
2022-09-28 05:45:20,264 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.411,  Train_accy 20.04, Test_accy 34.06
2022-09-28 05:45:22,639 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.418,  Train_accy 20.54
2022-09-28 05:45:24,953 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.412,  Train_accy 20.64
2022-09-28 05:45:27,316 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.400,  Train_accy 20.84
2022-09-28 05:45:29,670 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.399,  Train_accy 21.04
2022-09-28 05:45:32,935 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.398,  Train_accy 20.74, Test_accy 34.26
2022-09-28 05:45:35,275 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.406,  Train_accy 20.84
2022-09-28 05:45:37,615 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.383,  Train_accy 21.04
2022-09-28 05:45:39,980 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.399,  Train_accy 20.14
2022-09-28 05:45:42,382 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.399,  Train_accy 21.94
2022-09-28 05:45:45,639 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.396,  Train_accy 21.24, Test_accy 34.65
2022-09-28 05:45:48,009 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.396,  Train_accy 20.44
2022-09-28 05:45:50,363 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.382,  Train_accy 21.54
2022-09-28 05:45:52,770 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.385,  Train_accy 21.44
2022-09-28 05:45:55,119 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.386,  Train_accy 21.74
2022-09-28 05:45:58,462 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.400,  Train_accy 21.44, Test_accy 35.25
2022-09-28 05:46:00,800 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.396,  Train_accy 21.64
2022-09-28 05:46:03,161 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.385,  Train_accy 21.94
2022-09-28 05:46:05,532 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.384,  Train_accy 21.54
2022-09-28 05:46:07,903 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.392,  Train_accy 20.84
2022-09-28 05:46:11,176 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.392,  Train_accy 21.14, Test_accy 35.45
2022-09-28 05:46:11,176 [foster.py] => do not weight align student!
2022-09-28 05:46:12,021 [foster.py] => darknet eval: 
2022-09-28 05:46:12,021 [foster.py] => CNN top1 curve: 35.45
2022-09-28 05:46:12,021 [foster.py] => CNN top5 curve: 80.79
2022-09-28 05:46:12,021 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 05:46:22,672 [foster.py] => Exemplar size: 440
2022-09-28 05:46:22,672 [trainer.py] => CNN: {'total': 46.73, 'old': 50.69, 'new': 22.54, 'base': 73.61, 'compound': 36.01}
2022-09-28 05:46:22,672 [trainer.py] => CNN top1 curve: [85.42, 63.2, 51.35, 47.81, 50.92, 46.73]
2022-09-28 05:46:22,672 [trainer.py] => CNN base curve: [85.42, 84.72, 82.64, 79.17, 74.31, 73.61]
2022-09-28 05:46:22,672 [trainer.py] => CNN old curve: [85.42, 84.72, 59.74, 51.35, 49.73, 50.69]
2022-09-28 05:46:22,672 [trainer.py] => CNN new curve: [0, 27.59, 21.54, 32.86, 57.35, 22.54]
2022-09-28 05:46:22,672 [trainer.py] => CNN compound curve: [0, 27.59, 21.71, 27.48, 39.31, 36.01]
2022-09-28 05:46:22,672 [trainer.py] => NME: {'total': 52.87, 'old': 54.38, 'new': 43.66, 'base': 70.14, 'compound': 45.98}
2022-09-28 05:46:22,672 [trainer.py] => NME top1 curve: [85.42, 73.59, 59.46, 58.2, 57.14, 52.87]
2022-09-28 05:46:22,672 [trainer.py] => NME base curve: [85.42, 84.03, 77.08, 72.22, 72.22, 70.14]
2022-09-28 05:46:22,672 [trainer.py] => NME old curve: [85.42, 84.03, 63.2, 56.76, 54.92, 54.38]
2022-09-28 05:46:22,672 [trainer.py] => NME new curve: [0, 56.32, 46.15, 64.29, 69.12, 43.66]
2022-09-28 05:46:22,672 [trainer.py] => NME compound curve: [0, 56.32, 42.76, 49.1, 49.66, 45.98]
2022-09-28 05:46:22,674 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 05:46:22,674 [trainer.py] => prefix: cil
2022-09-28 05:46:22,674 [trainer.py] => dataset: CFEE
2022-09-28 05:46:22,674 [trainer.py] => memory_size: 2000
2022-09-28 05:46:22,674 [trainer.py] => memory_per_class: 20
2022-09-28 05:46:22,674 [trainer.py] => fixed_memory: True
2022-09-28 05:46:22,674 [trainer.py] => shuffle: True
2022-09-28 05:46:22,674 [trainer.py] => init_cls: 7
2022-09-28 05:46:22,674 [trainer.py] => increment: 3
2022-09-28 05:46:22,674 [trainer.py] => model_name: foster
2022-09-28 05:46:22,674 [trainer.py] => convnet_type: resnet18
2022-09-28 05:46:22,674 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 05:46:22,674 [trainer.py] => seed: 1993
2022-09-28 05:46:22,674 [trainer.py] => beta1: 0.96
2022-09-28 05:46:22,674 [trainer.py] => beta2: 0.97
2022-09-28 05:46:22,674 [trainer.py] => oofc: ft
2022-09-28 05:46:22,674 [trainer.py] => is_teacher_wa: False
2022-09-28 05:46:22,674 [trainer.py] => is_student_wa: False
2022-09-28 05:46:22,674 [trainer.py] => lambda_okd: 1
2022-09-28 05:46:22,674 [trainer.py] => wa_value: 1
2022-09-28 05:46:22,674 [trainer.py] => init_epochs: 40
2022-09-28 05:46:22,674 [trainer.py] => init_lr: 0.01
2022-09-28 05:46:22,674 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 05:46:22,674 [trainer.py] => boosting_epochs: 34
2022-09-28 05:46:22,674 [trainer.py] => compression_epochs: 26
2022-09-28 05:46:22,674 [trainer.py] => lr: 0.001
2022-09-28 05:46:22,674 [trainer.py] => batch_size: 32
2022-09-28 05:46:22,675 [trainer.py] => weight_decay: 0.0005
2022-09-28 05:46:22,675 [trainer.py] => num_workers: 8
2022-09-28 05:46:22,675 [trainer.py] => T: 2
2022-09-28 05:46:22,675 [trainer.py] => nb_runs: 3
2022-09-28 05:46:22,675 [trainer.py] => fold: 10
2022-09-28 05:46:22,675 [data.py] => ========== Fold:5 ==========
2022-09-28 05:46:22,680 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 12, 10, 19, 21, 17, 18, 8, 7, 9, 14, 15, 13, 11, 16]
2022-09-28 05:46:22,895 [foster.py] => Learning on 0-7
2022-09-28 05:46:22,895 [foster.py] => All params: 11183694
2022-09-28 05:46:22,896 [foster.py] => Trainable params: 11183694
2022-09-28 05:46:25,247 [foster.py] => Task 0, Epoch 1/40 => Loss 1.349, Train_accy 50.63
2022-09-28 05:46:28,282 [foster.py] => Task 0, Epoch 2/40 => Loss 0.552, Train_accy 80.81, Test_accy 79.88
2022-09-28 05:46:31,259 [foster.py] => Task 0, Epoch 3/40 => Loss 0.336, Train_accy 87.55, Test_accy 85.80
2022-09-28 05:46:34,252 [foster.py] => Task 0, Epoch 4/40 => Loss 0.285, Train_accy 90.40, Test_accy 85.80
2022-09-28 05:46:37,277 [foster.py] => Task 0, Epoch 5/40 => Loss 0.242, Train_accy 90.96, Test_accy 84.62
2022-09-28 05:46:39,652 [foster.py] => Task 0, Epoch 6/40 => Loss 0.189, Train_accy 93.25
2022-09-28 05:46:42,657 [foster.py] => Task 0, Epoch 7/40 => Loss 0.173, Train_accy 94.37, Test_accy 89.94
2022-09-28 05:46:45,621 [foster.py] => Task 0, Epoch 8/40 => Loss 0.134, Train_accy 95.55, Test_accy 86.39
2022-09-28 05:46:48,642 [foster.py] => Task 0, Epoch 9/40 => Loss 0.127, Train_accy 95.76, Test_accy 85.80
2022-09-28 05:46:51,689 [foster.py] => Task 0, Epoch 10/40 => Loss 0.088, Train_accy 97.43, Test_accy 89.35
2022-09-28 05:46:54,062 [foster.py] => Task 0, Epoch 11/40 => Loss 0.079, Train_accy 97.50
2022-09-28 05:46:57,069 [foster.py] => Task 0, Epoch 12/40 => Loss 0.075, Train_accy 97.57, Test_accy 89.94
2022-09-28 05:47:00,031 [foster.py] => Task 0, Epoch 13/40 => Loss 0.056, Train_accy 98.54, Test_accy 86.39
2022-09-28 05:47:03,059 [foster.py] => Task 0, Epoch 14/40 => Loss 0.051, Train_accy 99.03, Test_accy 88.17
2022-09-28 05:47:06,136 [foster.py] => Task 0, Epoch 15/40 => Loss 0.053, Train_accy 98.61, Test_accy 88.76
2022-09-28 05:47:08,481 [foster.py] => Task 0, Epoch 16/40 => Loss 0.041, Train_accy 98.96
2022-09-28 05:47:11,450 [foster.py] => Task 0, Epoch 17/40 => Loss 0.038, Train_accy 99.17, Test_accy 89.94
2022-09-28 05:47:14,409 [foster.py] => Task 0, Epoch 18/40 => Loss 0.034, Train_accy 99.24, Test_accy 89.94
2022-09-28 05:47:17,422 [foster.py] => Task 0, Epoch 19/40 => Loss 0.029, Train_accy 99.37, Test_accy 91.12
2022-09-28 05:47:20,418 [foster.py] => Task 0, Epoch 20/40 => Loss 0.022, Train_accy 99.86, Test_accy 89.35
2022-09-28 05:47:22,798 [foster.py] => Task 0, Epoch 21/40 => Loss 0.028, Train_accy 99.44
2022-09-28 05:47:25,753 [foster.py] => Task 0, Epoch 22/40 => Loss 0.029, Train_accy 99.37, Test_accy 89.35
2022-09-28 05:47:28,831 [foster.py] => Task 0, Epoch 23/40 => Loss 0.026, Train_accy 99.51, Test_accy 91.12
2022-09-28 05:47:31,836 [foster.py] => Task 0, Epoch 24/40 => Loss 0.024, Train_accy 99.51, Test_accy 89.94
2022-09-28 05:47:34,898 [foster.py] => Task 0, Epoch 25/40 => Loss 0.022, Train_accy 99.58, Test_accy 88.17
2022-09-28 05:47:37,271 [foster.py] => Task 0, Epoch 26/40 => Loss 0.017, Train_accy 99.65
2022-09-28 05:47:40,296 [foster.py] => Task 0, Epoch 27/40 => Loss 0.026, Train_accy 99.44, Test_accy 88.17
2022-09-28 05:47:43,270 [foster.py] => Task 0, Epoch 28/40 => Loss 0.019, Train_accy 99.65, Test_accy 89.94
2022-09-28 05:47:46,286 [foster.py] => Task 0, Epoch 29/40 => Loss 0.016, Train_accy 99.86, Test_accy 89.94
2022-09-28 05:47:49,257 [foster.py] => Task 0, Epoch 30/40 => Loss 0.015, Train_accy 99.86, Test_accy 90.53
2022-09-28 05:47:51,595 [foster.py] => Task 0, Epoch 31/40 => Loss 0.013, Train_accy 100.00
2022-09-28 05:47:54,576 [foster.py] => Task 0, Epoch 32/40 => Loss 0.016, Train_accy 99.79, Test_accy 89.94
2022-09-28 05:47:57,526 [foster.py] => Task 0, Epoch 33/40 => Loss 0.014, Train_accy 99.86, Test_accy 89.35
2022-09-28 05:48:00,506 [foster.py] => Task 0, Epoch 34/40 => Loss 0.012, Train_accy 99.79, Test_accy 89.94
2022-09-28 05:48:03,489 [foster.py] => Task 0, Epoch 35/40 => Loss 0.014, Train_accy 99.86, Test_accy 89.94
2022-09-28 05:48:05,846 [foster.py] => Task 0, Epoch 36/40 => Loss 0.015, Train_accy 99.86
2022-09-28 05:48:08,837 [foster.py] => Task 0, Epoch 37/40 => Loss 0.014, Train_accy 99.86, Test_accy 89.94
2022-09-28 05:48:11,847 [foster.py] => Task 0, Epoch 38/40 => Loss 0.013, Train_accy 99.93, Test_accy 89.35
2022-09-28 05:48:14,814 [foster.py] => Task 0, Epoch 39/40 => Loss 0.014, Train_accy 99.86, Test_accy 90.53
2022-09-28 05:48:17,837 [foster.py] => Task 0, Epoch 40/40 => Loss 0.016, Train_accy 99.93, Test_accy 89.35
2022-09-28 05:48:17,837 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 05:48:24,734 [foster.py] => Exemplar size: 140
2022-09-28 05:48:24,735 [trainer.py] => CNN: {'total': 89.35, 'old': 89.35, 'new': 0, 'base': 89.35, 'compound': 0}
2022-09-28 05:48:24,735 [trainer.py] => CNN top1 curve: [89.35]
2022-09-28 05:48:24,735 [trainer.py] => CNN base curve: [89.35]
2022-09-28 05:48:24,735 [trainer.py] => CNN old curve: [89.35]
2022-09-28 05:48:24,735 [trainer.py] => CNN new curve: [0]
2022-09-28 05:48:24,735 [trainer.py] => CNN compound curve: [0]
2022-09-28 05:48:24,735 [trainer.py] => NME: {'total': 89.94, 'old': 89.94, 'new': 0, 'base': 89.94, 'compound': 0}
2022-09-28 05:48:24,735 [trainer.py] => NME top1 curve: [89.94]
2022-09-28 05:48:24,735 [trainer.py] => NME base curve: [89.94]
2022-09-28 05:48:24,735 [trainer.py] => NME old curve: [89.94]
2022-09-28 05:48:24,735 [trainer.py] => NME new curve: [0]
2022-09-28 05:48:24,735 [trainer.py] => NME compound curve: [0]
2022-09-28 05:48:24,968 [foster.py] => Learning on 7-10
2022-09-28 05:48:24,969 [foster.py] => All params: 22371995
2022-09-28 05:48:24,969 [foster.py] => Trainable params: 11191892
2022-09-28 05:48:24,990 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 05:48:27,457 [foster.py] => Task 1, Epoch 1/34 => Loss 4.743, Loss_clf 2.353, Loss_fe 1.848, Loss_kd 0.380, Train_accy 34.00, Test_accy 59.11
2022-09-28 05:48:29,181 [foster.py] => Task 1, Epoch 2/34 => Loss 2.806, Loss_clf 0.933, Loss_fe 1.323, Loss_kd 0.385, Train_accy 58.27
2022-09-28 05:48:30,918 [foster.py] => Task 1, Epoch 3/34 => Loss 2.350, Loss_clf 0.688, Loss_fe 1.151, Loss_kd 0.358, Train_accy 40.53
2022-09-28 05:48:32,654 [foster.py] => Task 1, Epoch 4/34 => Loss 2.196, Loss_clf 0.645, Loss_fe 1.033, Loss_kd 0.363, Train_accy 38.80
2022-09-28 05:48:34,397 [foster.py] => Task 1, Epoch 5/34 => Loss 2.090, Loss_clf 0.613, Loss_fe 0.963, Loss_kd 0.360, Train_accy 43.47
2022-09-28 05:48:36,870 [foster.py] => Task 1, Epoch 6/34 => Loss 2.005, Loss_clf 0.603, Loss_fe 0.900, Loss_kd 0.352, Train_accy 37.73, Test_accy 66.40
2022-09-28 05:48:38,604 [foster.py] => Task 1, Epoch 7/34 => Loss 1.951, Loss_clf 0.592, Loss_fe 0.856, Loss_kd 0.352, Train_accy 43.33
2022-09-28 05:48:40,319 [foster.py] => Task 1, Epoch 8/34 => Loss 1.893, Loss_clf 0.558, Loss_fe 0.826, Loss_kd 0.356, Train_accy 42.27
2022-09-28 05:48:42,044 [foster.py] => Task 1, Epoch 9/34 => Loss 1.857, Loss_clf 0.571, Loss_fe 0.787, Loss_kd 0.349, Train_accy 38.93
2022-09-28 05:48:43,769 [foster.py] => Task 1, Epoch 10/34 => Loss 1.815, Loss_clf 0.544, Loss_fe 0.766, Loss_kd 0.354, Train_accy 43.20
2022-09-28 05:48:46,238 [foster.py] => Task 1, Epoch 11/34 => Loss 1.786, Loss_clf 0.539, Loss_fe 0.744, Loss_kd 0.352, Train_accy 41.20, Test_accy 68.83
2022-09-28 05:48:47,987 [foster.py] => Task 1, Epoch 12/34 => Loss 1.759, Loss_clf 0.526, Loss_fe 0.733, Loss_kd 0.350, Train_accy 42.27
2022-09-28 05:48:49,714 [foster.py] => Task 1, Epoch 13/34 => Loss 1.688, Loss_clf 0.499, Loss_fe 0.685, Loss_kd 0.353, Train_accy 42.80
2022-09-28 05:48:51,474 [foster.py] => Task 1, Epoch 14/34 => Loss 1.674, Loss_clf 0.487, Loss_fe 0.683, Loss_kd 0.353, Train_accy 43.33
2022-09-28 05:48:53,161 [foster.py] => Task 1, Epoch 15/34 => Loss 1.654, Loss_clf 0.502, Loss_fe 0.662, Loss_kd 0.343, Train_accy 42.80
2022-09-28 05:48:55,672 [foster.py] => Task 1, Epoch 16/34 => Loss 1.660, Loss_clf 0.490, Loss_fe 0.660, Loss_kd 0.357, Train_accy 45.73, Test_accy 69.23
2022-09-28 05:48:57,413 [foster.py] => Task 1, Epoch 17/34 => Loss 1.615, Loss_clf 0.469, Loss_fe 0.650, Loss_kd 0.347, Train_accy 43.07
2022-09-28 05:48:59,122 [foster.py] => Task 1, Epoch 18/34 => Loss 1.665, Loss_clf 0.502, Loss_fe 0.660, Loss_kd 0.352, Train_accy 43.60
2022-09-28 05:49:00,862 [foster.py] => Task 1, Epoch 19/34 => Loss 1.620, Loss_clf 0.479, Loss_fe 0.635, Loss_kd 0.355, Train_accy 44.67
2022-09-28 05:49:02,611 [foster.py] => Task 1, Epoch 20/34 => Loss 1.563, Loss_clf 0.451, Loss_fe 0.613, Loss_kd 0.349, Train_accy 46.00
2022-09-28 05:49:05,053 [foster.py] => Task 1, Epoch 21/34 => Loss 1.569, Loss_clf 0.465, Loss_fe 0.606, Loss_kd 0.349, Train_accy 45.20, Test_accy 69.64
2022-09-28 05:49:06,762 [foster.py] => Task 1, Epoch 22/34 => Loss 1.579, Loss_clf 0.472, Loss_fe 0.607, Loss_kd 0.350, Train_accy 45.47
2022-09-28 05:49:08,473 [foster.py] => Task 1, Epoch 23/34 => Loss 1.575, Loss_clf 0.460, Loss_fe 0.610, Loss_kd 0.353, Train_accy 47.60
2022-09-28 05:49:10,222 [foster.py] => Task 1, Epoch 24/34 => Loss 1.569, Loss_clf 0.462, Loss_fe 0.596, Loss_kd 0.358, Train_accy 45.33
2022-09-28 05:49:11,995 [foster.py] => Task 1, Epoch 25/34 => Loss 1.520, Loss_clf 0.443, Loss_fe 0.582, Loss_kd 0.347, Train_accy 45.20
2022-09-28 05:49:14,440 [foster.py] => Task 1, Epoch 26/34 => Loss 1.517, Loss_clf 0.432, Loss_fe 0.575, Loss_kd 0.357, Train_accy 46.80, Test_accy 69.64
2022-09-28 05:49:16,202 [foster.py] => Task 1, Epoch 27/34 => Loss 1.520, Loss_clf 0.441, Loss_fe 0.581, Loss_kd 0.349, Train_accy 46.80
2022-09-28 05:49:17,935 [foster.py] => Task 1, Epoch 28/34 => Loss 1.522, Loss_clf 0.441, Loss_fe 0.577, Loss_kd 0.353, Train_accy 46.13
2022-09-28 05:49:19,667 [foster.py] => Task 1, Epoch 29/34 => Loss 1.507, Loss_clf 0.425, Loss_fe 0.574, Loss_kd 0.355, Train_accy 45.47
2022-09-28 05:49:21,418 [foster.py] => Task 1, Epoch 30/34 => Loss 1.521, Loss_clf 0.428, Loss_fe 0.583, Loss_kd 0.357, Train_accy 46.93
2022-09-28 05:49:23,907 [foster.py] => Task 1, Epoch 31/34 => Loss 1.478, Loss_clf 0.417, Loss_fe 0.562, Loss_kd 0.349, Train_accy 44.93, Test_accy 69.64
2022-09-28 05:49:25,607 [foster.py] => Task 1, Epoch 32/34 => Loss 1.518, Loss_clf 0.435, Loss_fe 0.581, Loss_kd 0.352, Train_accy 47.60
2022-09-28 05:49:27,310 [foster.py] => Task 1, Epoch 33/34 => Loss 1.506, Loss_clf 0.422, Loss_fe 0.569, Loss_kd 0.361, Train_accy 47.47
2022-09-28 05:49:29,058 [foster.py] => Task 1, Epoch 34/34 => Loss 1.482, Loss_clf 0.416, Loss_fe 0.569, Loss_kd 0.347, Train_accy 46.67
2022-09-28 05:49:29,059 [foster.py] => do not weight align teacher!
2022-09-28 05:49:29,059 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 05:49:31,893 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.531,  Train_accy 17.47, Test_accy 58.70
2022-09-28 05:49:33,821 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.369,  Train_accy 18.53
2022-09-28 05:49:35,772 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.273,  Train_accy 18.53
2022-09-28 05:49:37,763 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.246,  Train_accy 19.07
2022-09-28 05:49:39,667 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.218,  Train_accy 19.73
2022-09-28 05:49:42,297 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.215,  Train_accy 21.07, Test_accy 61.13
2022-09-28 05:49:44,186 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.193,  Train_accy 20.67
2022-09-28 05:49:46,094 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.186,  Train_accy 21.47
2022-09-28 05:49:48,003 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.180,  Train_accy 21.87
2022-09-28 05:49:49,929 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.174,  Train_accy 23.33
2022-09-28 05:49:52,496 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.155,  Train_accy 22.53, Test_accy 61.54
2022-09-28 05:49:54,409 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.169,  Train_accy 23.07
2022-09-28 05:49:56,353 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.159,  Train_accy 23.07
2022-09-28 05:49:58,276 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.149,  Train_accy 21.60
2022-09-28 05:50:00,167 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.159,  Train_accy 22.53
2022-09-28 05:50:02,840 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.169,  Train_accy 22.93, Test_accy 62.35
2022-09-28 05:50:04,793 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.158,  Train_accy 22.80
2022-09-28 05:50:06,714 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.141,  Train_accy 22.53
2022-09-28 05:50:08,606 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.149,  Train_accy 24.53
2022-09-28 05:50:10,590 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.147,  Train_accy 23.33
2022-09-28 05:50:13,187 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.144,  Train_accy 23.07, Test_accy 61.94
2022-09-28 05:50:15,119 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.160,  Train_accy 23.33
2022-09-28 05:50:17,011 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.140,  Train_accy 23.07
2022-09-28 05:50:18,926 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.142,  Train_accy 23.07
2022-09-28 05:50:20,845 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.150,  Train_accy 23.60
2022-09-28 05:50:23,422 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.153,  Train_accy 23.47, Test_accy 61.94
2022-09-28 05:50:23,423 [foster.py] => do not weight align student!
2022-09-28 05:50:24,110 [foster.py] => darknet eval: 
2022-09-28 05:50:24,110 [foster.py] => CNN top1 curve: 61.94
2022-09-28 05:50:24,110 [foster.py] => CNN top5 curve: 99.19
2022-09-28 05:50:24,111 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 05:50:30,510 [foster.py] => Exemplar size: 200
2022-09-28 05:50:30,510 [trainer.py] => CNN: {'total': 69.64, 'old': 87.57, 'new': 30.77, 'base': 87.57, 'compound': 30.77}
2022-09-28 05:50:30,510 [trainer.py] => CNN top1 curve: [89.35, 69.64]
2022-09-28 05:50:30,510 [trainer.py] => CNN base curve: [89.35, 87.57]
2022-09-28 05:50:30,510 [trainer.py] => CNN old curve: [89.35, 87.57]
2022-09-28 05:50:30,510 [trainer.py] => CNN new curve: [0, 30.77]
2022-09-28 05:50:30,510 [trainer.py] => CNN compound curve: [0, 30.77]
2022-09-28 05:50:30,510 [trainer.py] => NME: {'total': 75.3, 'old': 82.25, 'new': 60.26, 'base': 82.25, 'compound': 60.26}
2022-09-28 05:50:30,510 [trainer.py] => NME top1 curve: [89.94, 75.3]
2022-09-28 05:50:30,510 [trainer.py] => NME base curve: [89.94, 82.25]
2022-09-28 05:50:30,510 [trainer.py] => NME old curve: [89.94, 82.25]
2022-09-28 05:50:30,510 [trainer.py] => NME new curve: [0, 60.26]
2022-09-28 05:50:30,510 [trainer.py] => NME compound curve: [0, 60.26]
2022-09-28 05:50:30,743 [foster.py] => Learning on 10-13
2022-09-28 05:50:30,744 [foster.py] => All params: 22378148
2022-09-28 05:50:30,744 [foster.py] => Trainable params: 11196506
2022-09-28 05:50:30,764 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 05:50:33,394 [foster.py] => Task 2, Epoch 1/34 => Loss 5.644, Loss_clf 2.297, Loss_fe 2.170, Loss_kd 0.905, Train_accy 37.58, Test_accy 50.81
2022-09-28 05:50:35,256 [foster.py] => Task 2, Epoch 2/34 => Loss 3.609, Loss_clf 1.002, Loss_fe 1.478, Loss_kd 0.868, Train_accy 47.27
2022-09-28 05:50:37,109 [foster.py] => Task 2, Epoch 3/34 => Loss 3.201, Loss_clf 0.788, Loss_fe 1.289, Loss_kd 0.865, Train_accy 41.33
2022-09-28 05:50:38,945 [foster.py] => Task 2, Epoch 4/34 => Loss 3.004, Loss_clf 0.718, Loss_fe 1.168, Loss_kd 0.860, Train_accy 41.21
2022-09-28 05:50:40,766 [foster.py] => Task 2, Epoch 5/34 => Loss 2.882, Loss_clf 0.691, Loss_fe 1.074, Loss_kd 0.860, Train_accy 43.52
2022-09-28 05:50:43,421 [foster.py] => Task 2, Epoch 6/34 => Loss 2.842, Loss_clf 0.682, Loss_fe 1.031, Loss_kd 0.869, Train_accy 39.39, Test_accy 56.31
2022-09-28 05:50:45,224 [foster.py] => Task 2, Epoch 7/34 => Loss 2.738, Loss_clf 0.658, Loss_fe 0.960, Loss_kd 0.862, Train_accy 42.55
2022-09-28 05:50:47,047 [foster.py] => Task 2, Epoch 8/34 => Loss 2.708, Loss_clf 0.663, Loss_fe 0.931, Loss_kd 0.858, Train_accy 41.94
2022-09-28 05:50:48,952 [foster.py] => Task 2, Epoch 9/34 => Loss 2.646, Loss_clf 0.641, Loss_fe 0.882, Loss_kd 0.864, Train_accy 39.64
2022-09-28 05:50:50,795 [foster.py] => Task 2, Epoch 10/34 => Loss 2.574, Loss_clf 0.608, Loss_fe 0.841, Loss_kd 0.865, Train_accy 40.85
2022-09-28 05:50:53,410 [foster.py] => Task 2, Epoch 11/34 => Loss 2.593, Loss_clf 0.635, Loss_fe 0.835, Loss_kd 0.863, Train_accy 44.36, Test_accy 55.34
2022-09-28 05:50:55,231 [foster.py] => Task 2, Epoch 12/34 => Loss 2.531, Loss_clf 0.610, Loss_fe 0.812, Loss_kd 0.854, Train_accy 41.45
2022-09-28 05:50:57,054 [foster.py] => Task 2, Epoch 13/34 => Loss 2.481, Loss_clf 0.580, Loss_fe 0.771, Loss_kd 0.869, Train_accy 42.67
2022-09-28 05:50:58,904 [foster.py] => Task 2, Epoch 14/34 => Loss 2.424, Loss_clf 0.571, Loss_fe 0.744, Loss_kd 0.853, Train_accy 42.91
2022-09-28 05:51:00,724 [foster.py] => Task 2, Epoch 15/34 => Loss 2.430, Loss_clf 0.562, Loss_fe 0.735, Loss_kd 0.871, Train_accy 44.97
2022-09-28 05:51:03,386 [foster.py] => Task 2, Epoch 16/34 => Loss 2.403, Loss_clf 0.561, Loss_fe 0.711, Loss_kd 0.869, Train_accy 42.67, Test_accy 55.02
2022-09-28 05:51:05,191 [foster.py] => Task 2, Epoch 17/34 => Loss 2.356, Loss_clf 0.541, Loss_fe 0.699, Loss_kd 0.859, Train_accy 42.79
2022-09-28 05:51:07,088 [foster.py] => Task 2, Epoch 18/34 => Loss 2.387, Loss_clf 0.557, Loss_fe 0.701, Loss_kd 0.868, Train_accy 43.64
2022-09-28 05:51:08,928 [foster.py] => Task 2, Epoch 19/34 => Loss 2.400, Loss_clf 0.569, Loss_fe 0.706, Loss_kd 0.865, Train_accy 43.15
2022-09-28 05:51:10,771 [foster.py] => Task 2, Epoch 20/34 => Loss 2.322, Loss_clf 0.526, Loss_fe 0.671, Loss_kd 0.865, Train_accy 44.48
2022-09-28 05:51:13,459 [foster.py] => Task 2, Epoch 21/34 => Loss 2.346, Loss_clf 0.542, Loss_fe 0.670, Loss_kd 0.872, Train_accy 44.48, Test_accy 54.69
2022-09-28 05:51:15,265 [foster.py] => Task 2, Epoch 22/34 => Loss 2.299, Loss_clf 0.525, Loss_fe 0.650, Loss_kd 0.865, Train_accy 44.36
2022-09-28 05:51:17,117 [foster.py] => Task 2, Epoch 23/34 => Loss 2.304, Loss_clf 0.518, Loss_fe 0.657, Loss_kd 0.868, Train_accy 45.33
2022-09-28 05:51:18,971 [foster.py] => Task 2, Epoch 24/34 => Loss 2.264, Loss_clf 0.508, Loss_fe 0.629, Loss_kd 0.867, Train_accy 43.88
2022-09-28 05:51:20,794 [foster.py] => Task 2, Epoch 25/34 => Loss 2.277, Loss_clf 0.509, Loss_fe 0.638, Loss_kd 0.869, Train_accy 44.97
2022-09-28 05:51:23,387 [foster.py] => Task 2, Epoch 26/34 => Loss 2.291, Loss_clf 0.508, Loss_fe 0.646, Loss_kd 0.875, Train_accy 45.82, Test_accy 55.34
2022-09-28 05:51:25,256 [foster.py] => Task 2, Epoch 27/34 => Loss 2.268, Loss_clf 0.506, Loss_fe 0.625, Loss_kd 0.875, Train_accy 46.91
2022-09-28 05:51:27,069 [foster.py] => Task 2, Epoch 28/34 => Loss 2.249, Loss_clf 0.496, Loss_fe 0.625, Loss_kd 0.868, Train_accy 47.27
2022-09-28 05:51:28,907 [foster.py] => Task 2, Epoch 29/34 => Loss 2.263, Loss_clf 0.506, Loss_fe 0.632, Loss_kd 0.865, Train_accy 46.42
2022-09-28 05:51:30,727 [foster.py] => Task 2, Epoch 30/34 => Loss 2.259, Loss_clf 0.501, Loss_fe 0.624, Loss_kd 0.872, Train_accy 45.58
2022-09-28 05:51:33,337 [foster.py] => Task 2, Epoch 31/34 => Loss 2.243, Loss_clf 0.492, Loss_fe 0.622, Loss_kd 0.869, Train_accy 45.33, Test_accy 54.37
2022-09-28 05:51:35,170 [foster.py] => Task 2, Epoch 32/34 => Loss 2.274, Loss_clf 0.512, Loss_fe 0.629, Loss_kd 0.872, Train_accy 45.21
2022-09-28 05:51:37,014 [foster.py] => Task 2, Epoch 33/34 => Loss 2.255, Loss_clf 0.509, Loss_fe 0.618, Loss_kd 0.868, Train_accy 44.85
2022-09-28 05:51:38,895 [foster.py] => Task 2, Epoch 34/34 => Loss 2.250, Loss_clf 0.499, Loss_fe 0.629, Loss_kd 0.864, Train_accy 45.45
2022-09-28 05:51:38,896 [foster.py] => do not weight align teacher!
2022-09-28 05:51:38,896 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 05:51:41,885 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.892,  Train_accy 16.36, Test_accy 46.93
2022-09-28 05:51:43,910 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.730,  Train_accy 16.97
2022-09-28 05:51:45,946 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.665,  Train_accy 17.33
2022-09-28 05:51:47,997 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.638,  Train_accy 17.21
2022-09-28 05:51:50,014 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.611,  Train_accy 17.45
2022-09-28 05:51:52,799 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.608,  Train_accy 18.06, Test_accy 50.16
2022-09-28 05:51:54,811 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.591,  Train_accy 18.06
2022-09-28 05:51:56,824 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.585,  Train_accy 18.06
2022-09-28 05:51:58,937 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.586,  Train_accy 17.82
2022-09-28 05:52:00,990 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.587,  Train_accy 18.18
2022-09-28 05:52:03,780 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.589,  Train_accy 19.03, Test_accy 49.51
2022-09-28 05:52:05,863 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.575,  Train_accy 18.55
2022-09-28 05:52:07,937 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.576,  Train_accy 18.42
2022-09-28 05:52:09,987 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.572,  Train_accy 18.91
2022-09-28 05:52:11,994 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.563,  Train_accy 18.55
2022-09-28 05:52:14,777 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.559,  Train_accy 19.15, Test_accy 49.51
2022-09-28 05:52:16,843 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.566,  Train_accy 19.03
2022-09-28 05:52:18,877 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.572,  Train_accy 18.91
2022-09-28 05:52:20,941 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.555,  Train_accy 19.64
2022-09-28 05:52:23,034 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.555,  Train_accy 18.91
2022-09-28 05:52:25,833 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.576,  Train_accy 19.03, Test_accy 49.84
2022-09-28 05:52:27,883 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.563,  Train_accy 19.03
2022-09-28 05:52:29,953 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.560,  Train_accy 18.91
2022-09-28 05:52:32,032 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.563,  Train_accy 18.42
2022-09-28 05:52:34,094 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.550,  Train_accy 18.42
2022-09-28 05:52:36,883 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.555,  Train_accy 18.91, Test_accy 49.51
2022-09-28 05:52:36,883 [foster.py] => do not weight align student!
2022-09-28 05:52:37,604 [foster.py] => darknet eval: 
2022-09-28 05:52:37,604 [foster.py] => CNN top1 curve: 49.51
2022-09-28 05:52:37,604 [foster.py] => CNN top5 curve: 95.47
2022-09-28 05:52:37,604 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 05:52:45,020 [foster.py] => Exemplar size: 260
2022-09-28 05:52:45,020 [trainer.py] => CNN: {'total': 54.37, 'old': 61.94, 'new': 24.19, 'base': 82.84, 'compound': 20.0}
2022-09-28 05:52:45,020 [trainer.py] => CNN top1 curve: [89.35, 69.64, 54.37]
2022-09-28 05:52:45,020 [trainer.py] => CNN base curve: [89.35, 87.57, 82.84]
2022-09-28 05:52:45,020 [trainer.py] => CNN old curve: [89.35, 87.57, 61.94]
2022-09-28 05:52:45,020 [trainer.py] => CNN new curve: [0, 30.77, 24.19]
2022-09-28 05:52:45,020 [trainer.py] => CNN compound curve: [0, 30.77, 20.0]
2022-09-28 05:52:45,020 [trainer.py] => NME: {'total': 61.81, 'old': 66.8, 'new': 41.94, 'base': 75.15, 'compound': 45.71}
2022-09-28 05:52:45,020 [trainer.py] => NME top1 curve: [89.94, 75.3, 61.81]
2022-09-28 05:52:45,020 [trainer.py] => NME base curve: [89.94, 82.25, 75.15]
2022-09-28 05:52:45,020 [trainer.py] => NME old curve: [89.94, 82.25, 66.8]
2022-09-28 05:52:45,020 [trainer.py] => NME new curve: [0, 60.26, 41.94]
2022-09-28 05:52:45,020 [trainer.py] => NME compound curve: [0, 60.26, 45.71]
2022-09-28 05:52:45,252 [foster.py] => Learning on 13-16
2022-09-28 05:52:45,252 [foster.py] => All params: 22384301
2022-09-28 05:52:45,252 [foster.py] => Trainable params: 11201120
2022-09-28 05:52:45,272 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 05:52:48,026 [foster.py] => Task 3, Epoch 1/34 => Loss 5.835, Loss_clf 1.784, Loss_fe 2.439, Loss_kd 1.310, Train_accy 43.74, Test_accy 50.26
2022-09-28 05:52:49,942 [foster.py] => Task 3, Epoch 2/34 => Loss 4.090, Loss_clf 0.873, Loss_fe 1.621, Loss_kd 1.296, Train_accy 45.33
2022-09-28 05:52:51,854 [foster.py] => Task 3, Epoch 3/34 => Loss 3.675, Loss_clf 0.742, Loss_fe 1.358, Loss_kd 1.280, Train_accy 49.66
2022-09-28 05:52:53,747 [foster.py] => Task 3, Epoch 4/34 => Loss 3.501, Loss_clf 0.706, Loss_fe 1.219, Loss_kd 1.281, Train_accy 45.10
2022-09-28 05:52:55,647 [foster.py] => Task 3, Epoch 5/34 => Loss 3.369, Loss_clf 0.683, Loss_fe 1.112, Loss_kd 1.280, Train_accy 48.18
2022-09-28 05:52:58,444 [foster.py] => Task 3, Epoch 6/34 => Loss 3.234, Loss_clf 0.629, Loss_fe 1.026, Loss_kd 1.284, Train_accy 49.77, Test_accy 51.59
2022-09-28 05:53:00,370 [foster.py] => Task 3, Epoch 7/34 => Loss 3.197, Loss_clf 0.631, Loss_fe 0.989, Loss_kd 1.282, Train_accy 49.89
2022-09-28 05:53:02,271 [foster.py] => Task 3, Epoch 8/34 => Loss 3.145, Loss_clf 0.627, Loss_fe 0.939, Loss_kd 1.283, Train_accy 47.95
2022-09-28 05:53:04,177 [foster.py] => Task 3, Epoch 9/34 => Loss 3.051, Loss_clf 0.591, Loss_fe 0.884, Loss_kd 1.280, Train_accy 51.25
2022-09-28 05:53:06,074 [foster.py] => Task 3, Epoch 10/34 => Loss 2.970, Loss_clf 0.563, Loss_fe 0.830, Loss_kd 1.281, Train_accy 49.66
2022-09-28 05:53:08,915 [foster.py] => Task 3, Epoch 11/34 => Loss 2.926, Loss_clf 0.560, Loss_fe 0.801, Loss_kd 1.272, Train_accy 51.94, Test_accy 54.76
2022-09-28 05:53:10,838 [foster.py] => Task 3, Epoch 12/34 => Loss 2.903, Loss_clf 0.546, Loss_fe 0.775, Loss_kd 1.286, Train_accy 52.62
2022-09-28 05:53:12,730 [foster.py] => Task 3, Epoch 13/34 => Loss 2.888, Loss_clf 0.559, Loss_fe 0.755, Loss_kd 1.279, Train_accy 53.64
2022-09-28 05:53:14,680 [foster.py] => Task 3, Epoch 14/34 => Loss 2.859, Loss_clf 0.552, Loss_fe 0.738, Loss_kd 1.275, Train_accy 50.57
2022-09-28 05:53:16,576 [foster.py] => Task 3, Epoch 15/34 => Loss 2.806, Loss_clf 0.512, Loss_fe 0.702, Loss_kd 1.293, Train_accy 53.30
2022-09-28 05:53:19,386 [foster.py] => Task 3, Epoch 16/34 => Loss 2.779, Loss_clf 0.525, Loss_fe 0.680, Loss_kd 1.279, Train_accy 52.73, Test_accy 56.61
2022-09-28 05:53:21,311 [foster.py] => Task 3, Epoch 17/34 => Loss 2.746, Loss_clf 0.499, Loss_fe 0.662, Loss_kd 1.288, Train_accy 55.81
2022-09-28 05:53:23,233 [foster.py] => Task 3, Epoch 18/34 => Loss 2.742, Loss_clf 0.497, Loss_fe 0.660, Loss_kd 1.288, Train_accy 55.47
2022-09-28 05:53:25,107 [foster.py] => Task 3, Epoch 19/34 => Loss 2.709, Loss_clf 0.495, Loss_fe 0.645, Loss_kd 1.275, Train_accy 51.03
2022-09-28 05:53:27,014 [foster.py] => Task 3, Epoch 20/34 => Loss 2.725, Loss_clf 0.498, Loss_fe 0.649, Loss_kd 1.282, Train_accy 54.21
2022-09-28 05:53:29,787 [foster.py] => Task 3, Epoch 21/34 => Loss 2.682, Loss_clf 0.478, Loss_fe 0.620, Loss_kd 1.287, Train_accy 55.35, Test_accy 55.82
2022-09-28 05:53:31,730 [foster.py] => Task 3, Epoch 22/34 => Loss 2.665, Loss_clf 0.472, Loss_fe 0.609, Loss_kd 1.287, Train_accy 54.21
2022-09-28 05:53:33,663 [foster.py] => Task 3, Epoch 23/34 => Loss 2.686, Loss_clf 0.484, Loss_fe 0.628, Loss_kd 1.278, Train_accy 55.81
2022-09-28 05:53:35,608 [foster.py] => Task 3, Epoch 24/34 => Loss 2.648, Loss_clf 0.459, Loss_fe 0.606, Loss_kd 1.285, Train_accy 56.04
2022-09-28 05:53:37,498 [foster.py] => Task 3, Epoch 25/34 => Loss 2.648, Loss_clf 0.467, Loss_fe 0.589, Loss_kd 1.293, Train_accy 55.92
2022-09-28 05:53:40,264 [foster.py] => Task 3, Epoch 26/34 => Loss 2.618, Loss_clf 0.453, Loss_fe 0.590, Loss_kd 1.280, Train_accy 56.04, Test_accy 56.88
2022-09-28 05:53:42,155 [foster.py] => Task 3, Epoch 27/34 => Loss 2.652, Loss_clf 0.468, Loss_fe 0.605, Loss_kd 1.283, Train_accy 55.81
2022-09-28 05:53:44,062 [foster.py] => Task 3, Epoch 28/34 => Loss 2.659, Loss_clf 0.475, Loss_fe 0.605, Loss_kd 1.283, Train_accy 55.47
2022-09-28 05:53:45,994 [foster.py] => Task 3, Epoch 29/34 => Loss 2.643, Loss_clf 0.470, Loss_fe 0.598, Loss_kd 1.280, Train_accy 55.13
2022-09-28 05:53:47,921 [foster.py] => Task 3, Epoch 30/34 => Loss 2.658, Loss_clf 0.467, Loss_fe 0.601, Loss_kd 1.292, Train_accy 56.15
2022-09-28 05:53:50,660 [foster.py] => Task 3, Epoch 31/34 => Loss 2.626, Loss_clf 0.466, Loss_fe 0.587, Loss_kd 1.278, Train_accy 55.35, Test_accy 57.14
2022-09-28 05:53:52,568 [foster.py] => Task 3, Epoch 32/34 => Loss 2.601, Loss_clf 0.449, Loss_fe 0.570, Loss_kd 1.286, Train_accy 55.92
2022-09-28 05:53:54,458 [foster.py] => Task 3, Epoch 33/34 => Loss 2.598, Loss_clf 0.451, Loss_fe 0.564, Loss_kd 1.286, Train_accy 58.54
2022-09-28 05:53:56,352 [foster.py] => Task 3, Epoch 34/34 => Loss 2.668, Loss_clf 0.473, Loss_fe 0.598, Loss_kd 1.297, Train_accy 57.40
2022-09-28 05:53:56,352 [foster.py] => do not weight align teacher!
2022-09-28 05:53:56,353 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 05:53:59,512 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.120,  Train_accy 16.97, Test_accy 39.95
2022-09-28 05:54:01,651 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.025,  Train_accy 17.54
2022-09-28 05:54:03,788 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 1.997,  Train_accy 17.31
2022-09-28 05:54:05,925 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 1.975,  Train_accy 17.54
2022-09-28 05:54:08,059 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.960,  Train_accy 17.43
2022-09-28 05:54:10,942 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.947,  Train_accy 17.65, Test_accy 41.53
2022-09-28 05:54:13,078 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.952,  Train_accy 17.77
2022-09-28 05:54:15,200 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.943,  Train_accy 18.22
2022-09-28 05:54:17,361 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.934,  Train_accy 19.02
2022-09-28 05:54:19,551 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.915,  Train_accy 17.65
2022-09-28 05:54:22,461 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.924,  Train_accy 18.56, Test_accy 42.33
2022-09-28 05:54:24,669 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.923,  Train_accy 20.05
2022-09-28 05:54:26,847 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.912,  Train_accy 19.25
2022-09-28 05:54:28,960 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.915,  Train_accy 19.25
2022-09-28 05:54:31,134 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.906,  Train_accy 20.16
2022-09-28 05:54:34,053 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.901,  Train_accy 19.82, Test_accy 43.39
2022-09-28 05:54:36,160 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.898,  Train_accy 20.39
2022-09-28 05:54:38,275 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.898,  Train_accy 20.96
2022-09-28 05:54:40,378 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.897,  Train_accy 20.50
2022-09-28 05:54:42,497 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.888,  Train_accy 20.84
2022-09-28 05:54:45,460 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.900,  Train_accy 19.93, Test_accy 42.86
2022-09-28 05:54:47,581 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.889,  Train_accy 20.62
2022-09-28 05:54:49,698 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.905,  Train_accy 20.05
2022-09-28 05:54:51,837 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.898,  Train_accy 20.05
2022-09-28 05:54:53,995 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.902,  Train_accy 21.30
2022-09-28 05:54:56,974 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.898,  Train_accy 20.50, Test_accy 43.92
2022-09-28 05:54:56,974 [foster.py] => do not weight align student!
2022-09-28 05:54:57,727 [foster.py] => darknet eval: 
2022-09-28 05:54:57,727 [foster.py] => CNN top1 curve: 43.92
2022-09-28 05:54:57,727 [foster.py] => CNN top5 curve: 91.27
2022-09-28 05:54:57,728 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 05:55:06,197 [foster.py] => Exemplar size: 320
2022-09-28 05:55:06,197 [trainer.py] => CNN: {'total': 56.88, 'old': 56.63, 'new': 57.97, 'base': 79.88, 'compound': 38.28}
2022-09-28 05:55:06,197 [trainer.py] => CNN top1 curve: [89.35, 69.64, 54.37, 56.88]
2022-09-28 05:55:06,197 [trainer.py] => CNN base curve: [89.35, 87.57, 82.84, 79.88]
2022-09-28 05:55:06,197 [trainer.py] => CNN old curve: [89.35, 87.57, 61.94, 56.63]
2022-09-28 05:55:06,197 [trainer.py] => CNN new curve: [0, 30.77, 24.19, 57.97]
2022-09-28 05:55:06,197 [trainer.py] => CNN compound curve: [0, 30.77, 20.0, 38.28]
2022-09-28 05:55:06,197 [trainer.py] => NME: {'total': 58.99, 'old': 56.31, 'new': 71.01, 'base': 71.01, 'compound': 49.28}
2022-09-28 05:55:06,197 [trainer.py] => NME top1 curve: [89.94, 75.3, 61.81, 58.99]
2022-09-28 05:55:06,197 [trainer.py] => NME base curve: [89.94, 82.25, 75.15, 71.01]
2022-09-28 05:55:06,197 [trainer.py] => NME old curve: [89.94, 82.25, 66.8, 56.31]
2022-09-28 05:55:06,197 [trainer.py] => NME new curve: [0, 60.26, 41.94, 71.01]
2022-09-28 05:55:06,198 [trainer.py] => NME compound curve: [0, 60.26, 45.71, 49.28]
2022-09-28 05:55:06,429 [foster.py] => Learning on 16-19
2022-09-28 05:55:06,429 [foster.py] => All params: 22390454
2022-09-28 05:55:06,430 [foster.py] => Trainable params: 11205734
2022-09-28 05:55:06,450 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 05:55:09,402 [foster.py] => Task 4, Epoch 1/34 => Loss 6.330, Loss_clf 1.817, Loss_fe 2.456, Loss_kd 1.732, Train_accy 44.61, Test_accy 38.41
2022-09-28 05:55:11,393 [foster.py] => Task 4, Epoch 2/34 => Loss 4.784, Loss_clf 0.981, Loss_fe 1.735, Loss_kd 1.741, Train_accy 48.20
2022-09-28 05:55:13,416 [foster.py] => Task 4, Epoch 3/34 => Loss 4.459, Loss_clf 0.874, Loss_fe 1.507, Loss_kd 1.750, Train_accy 54.65
2022-09-28 05:55:15,414 [foster.py] => Task 4, Epoch 4/34 => Loss 4.250, Loss_clf 0.825, Loss_fe 1.370, Loss_kd 1.730, Train_accy 52.96
2022-09-28 05:55:17,399 [foster.py] => Task 4, Epoch 5/34 => Loss 4.089, Loss_clf 0.772, Loss_fe 1.255, Loss_kd 1.737, Train_accy 54.65
2022-09-28 05:55:20,386 [foster.py] => Task 4, Epoch 6/34 => Loss 4.023, Loss_clf 0.759, Loss_fe 1.187, Loss_kd 1.749, Train_accy 56.55, Test_accy 50.23
2022-09-28 05:55:22,382 [foster.py] => Task 4, Epoch 7/34 => Loss 3.926, Loss_clf 0.745, Loss_fe 1.118, Loss_kd 1.737, Train_accy 54.33
2022-09-28 05:55:24,417 [foster.py] => Task 4, Epoch 8/34 => Loss 3.868, Loss_clf 0.738, Loss_fe 1.065, Loss_kd 1.738, Train_accy 56.66
2022-09-28 05:55:26,444 [foster.py] => Task 4, Epoch 9/34 => Loss 3.794, Loss_clf 0.713, Loss_fe 1.011, Loss_kd 1.743, Train_accy 56.45
2022-09-28 05:55:28,490 [foster.py] => Task 4, Epoch 10/34 => Loss 3.763, Loss_clf 0.701, Loss_fe 0.990, Loss_kd 1.744, Train_accy 57.19
2022-09-28 05:55:31,400 [foster.py] => Task 4, Epoch 11/34 => Loss 3.705, Loss_clf 0.689, Loss_fe 0.948, Loss_kd 1.742, Train_accy 57.72, Test_accy 50.68
2022-09-28 05:55:33,423 [foster.py] => Task 4, Epoch 12/34 => Loss 3.644, Loss_clf 0.665, Loss_fe 0.913, Loss_kd 1.739, Train_accy 58.25
2022-09-28 05:55:35,458 [foster.py] => Task 4, Epoch 13/34 => Loss 3.591, Loss_clf 0.648, Loss_fe 0.875, Loss_kd 1.742, Train_accy 58.03
2022-09-28 05:55:37,492 [foster.py] => Task 4, Epoch 14/34 => Loss 3.573, Loss_clf 0.637, Loss_fe 0.861, Loss_kd 1.747, Train_accy 59.51
2022-09-28 05:55:39,517 [foster.py] => Task 4, Epoch 15/34 => Loss 3.551, Loss_clf 0.635, Loss_fe 0.848, Loss_kd 1.742, Train_accy 57.51
2022-09-28 05:55:42,526 [foster.py] => Task 4, Epoch 16/34 => Loss 3.518, Loss_clf 0.633, Loss_fe 0.808, Loss_kd 1.749, Train_accy 58.99, Test_accy 51.82
2022-09-28 05:55:44,545 [foster.py] => Task 4, Epoch 17/34 => Loss 3.533, Loss_clf 0.637, Loss_fe 0.821, Loss_kd 1.748, Train_accy 58.77
2022-09-28 05:55:46,553 [foster.py] => Task 4, Epoch 18/34 => Loss 3.479, Loss_clf 0.615, Loss_fe 0.798, Loss_kd 1.740, Train_accy 60.04
2022-09-28 05:55:48,603 [foster.py] => Task 4, Epoch 19/34 => Loss 3.448, Loss_clf 0.602, Loss_fe 0.773, Loss_kd 1.746, Train_accy 60.15
2022-09-28 05:55:50,595 [foster.py] => Task 4, Epoch 20/34 => Loss 3.433, Loss_clf 0.604, Loss_fe 0.761, Loss_kd 1.741, Train_accy 58.56
2022-09-28 05:55:53,560 [foster.py] => Task 4, Epoch 21/34 => Loss 3.453, Loss_clf 0.608, Loss_fe 0.773, Loss_kd 1.744, Train_accy 57.82, Test_accy 52.27
2022-09-28 05:55:55,607 [foster.py] => Task 4, Epoch 22/34 => Loss 3.409, Loss_clf 0.596, Loss_fe 0.744, Loss_kd 1.743, Train_accy 60.89
2022-09-28 05:55:57,643 [foster.py] => Task 4, Epoch 23/34 => Loss 3.401, Loss_clf 0.590, Loss_fe 0.741, Loss_kd 1.743, Train_accy 61.73
2022-09-28 05:55:59,632 [foster.py] => Task 4, Epoch 24/34 => Loss 3.361, Loss_clf 0.573, Loss_fe 0.723, Loss_kd 1.739, Train_accy 60.89
2022-09-28 05:56:01,711 [foster.py] => Task 4, Epoch 25/34 => Loss 3.384, Loss_clf 0.585, Loss_fe 0.730, Loss_kd 1.742, Train_accy 61.95
2022-09-28 05:56:04,691 [foster.py] => Task 4, Epoch 26/34 => Loss 3.378, Loss_clf 0.574, Loss_fe 0.729, Loss_kd 1.747, Train_accy 58.56, Test_accy 53.86
2022-09-28 05:56:06,738 [foster.py] => Task 4, Epoch 27/34 => Loss 3.333, Loss_clf 0.564, Loss_fe 0.703, Loss_kd 1.740, Train_accy 61.63
2022-09-28 05:56:08,754 [foster.py] => Task 4, Epoch 28/34 => Loss 3.348, Loss_clf 0.572, Loss_fe 0.707, Loss_kd 1.743, Train_accy 62.79
2022-09-28 05:56:10,806 [foster.py] => Task 4, Epoch 29/34 => Loss 3.335, Loss_clf 0.567, Loss_fe 0.696, Loss_kd 1.745, Train_accy 62.05
2022-09-28 05:56:12,820 [foster.py] => Task 4, Epoch 30/34 => Loss 3.381, Loss_clf 0.580, Loss_fe 0.727, Loss_kd 1.746, Train_accy 61.31
2022-09-28 05:56:15,825 [foster.py] => Task 4, Epoch 31/34 => Loss 3.380, Loss_clf 0.575, Loss_fe 0.724, Loss_kd 1.753, Train_accy 61.21, Test_accy 52.95
2022-09-28 05:56:17,827 [foster.py] => Task 4, Epoch 32/34 => Loss 3.389, Loss_clf 0.579, Loss_fe 0.734, Loss_kd 1.748, Train_accy 60.36
2022-09-28 05:56:19,853 [foster.py] => Task 4, Epoch 33/34 => Loss 3.359, Loss_clf 0.572, Loss_fe 0.711, Loss_kd 1.747, Train_accy 62.16
2022-09-28 05:56:21,881 [foster.py] => Task 4, Epoch 34/34 => Loss 3.363, Loss_clf 0.571, Loss_fe 0.720, Loss_kd 1.745, Train_accy 59.41
2022-09-28 05:56:21,882 [foster.py] => do not weight align teacher!
2022-09-28 05:56:21,882 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 05:56:25,199 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.446,  Train_accy 15.12, Test_accy 36.14
2022-09-28 05:56:27,477 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.362,  Train_accy 15.43
2022-09-28 05:56:29,721 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.331,  Train_accy 17.65
2022-09-28 05:56:31,986 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.302,  Train_accy 18.29
2022-09-28 05:56:34,254 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.288,  Train_accy 18.18
2022-09-28 05:56:37,370 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.284,  Train_accy 18.71, Test_accy 40.68
2022-09-28 05:56:39,671 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.270,  Train_accy 18.50
2022-09-28 05:56:41,922 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.267,  Train_accy 19.34
2022-09-28 05:56:44,149 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.254,  Train_accy 18.18
2022-09-28 05:56:46,399 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.266,  Train_accy 19.03
2022-09-28 05:56:49,488 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.248,  Train_accy 18.82, Test_accy 41.82
2022-09-28 05:56:51,738 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.256,  Train_accy 20.19
2022-09-28 05:56:54,016 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.259,  Train_accy 19.34
2022-09-28 05:56:56,300 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.242,  Train_accy 19.98
2022-09-28 05:56:58,581 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.244,  Train_accy 21.14
2022-09-28 05:57:01,688 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.239,  Train_accy 20.72, Test_accy 43.64
2022-09-28 05:57:04,009 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.248,  Train_accy 20.72
2022-09-28 05:57:06,282 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.237,  Train_accy 19.87
2022-09-28 05:57:08,507 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.247,  Train_accy 20.61
2022-09-28 05:57:10,777 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.228,  Train_accy 20.08
2022-09-28 05:57:13,840 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.236,  Train_accy 20.82, Test_accy 43.18
2022-09-28 05:57:16,141 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.239,  Train_accy 21.56
2022-09-28 05:57:18,394 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.237,  Train_accy 21.67
2022-09-28 05:57:20,678 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.236,  Train_accy 21.25
2022-09-28 05:57:22,951 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.245,  Train_accy 20.08
2022-09-28 05:57:25,980 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.242,  Train_accy 20.40, Test_accy 42.50
2022-09-28 05:57:25,980 [foster.py] => do not weight align student!
2022-09-28 05:57:26,788 [foster.py] => darknet eval: 
2022-09-28 05:57:26,788 [foster.py] => CNN top1 curve: 42.5
2022-09-28 05:57:26,788 [foster.py] => CNN top5 curve: 85.45
2022-09-28 05:57:26,789 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 05:57:36,338 [foster.py] => Exemplar size: 380
2022-09-28 05:57:36,338 [trainer.py] => CNN: {'total': 52.27, 'old': 54.5, 'new': 38.71, 'base': 75.15, 'compound': 38.01}
2022-09-28 05:57:36,338 [trainer.py] => CNN top1 curve: [89.35, 69.64, 54.37, 56.88, 52.27]
2022-09-28 05:57:36,338 [trainer.py] => CNN base curve: [89.35, 87.57, 82.84, 79.88, 75.15]
2022-09-28 05:57:36,338 [trainer.py] => CNN old curve: [89.35, 87.57, 61.94, 56.63, 54.5]
2022-09-28 05:57:36,338 [trainer.py] => CNN new curve: [0, 30.77, 24.19, 57.97, 38.71]
2022-09-28 05:57:36,338 [trainer.py] => CNN compound curve: [0, 30.77, 20.0, 38.28, 38.01]
2022-09-28 05:57:36,338 [trainer.py] => NME: {'total': 56.59, 'old': 56.61, 'new': 56.45, 'base': 69.23, 'compound': 48.71}
2022-09-28 05:57:36,338 [trainer.py] => NME top1 curve: [89.94, 75.3, 61.81, 58.99, 56.59]
2022-09-28 05:57:36,338 [trainer.py] => NME base curve: [89.94, 82.25, 75.15, 71.01, 69.23]
2022-09-28 05:57:36,338 [trainer.py] => NME old curve: [89.94, 82.25, 66.8, 56.31, 56.61]
2022-09-28 05:57:36,338 [trainer.py] => NME new curve: [0, 60.26, 41.94, 71.01, 56.45]
2022-09-28 05:57:36,338 [trainer.py] => NME compound curve: [0, 60.26, 45.71, 49.28, 48.71]
2022-09-28 05:57:36,570 [foster.py] => Learning on 19-22
2022-09-28 05:57:36,571 [foster.py] => All params: 22396607
2022-09-28 05:57:36,571 [foster.py] => Trainable params: 11210348
2022-09-28 05:57:36,591 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 05:57:39,682 [foster.py] => Task 5, Epoch 1/34 => Loss 6.699, Loss_clf 1.926, Loss_fe 2.518, Loss_kd 1.947, Train_accy 38.75, Test_accy 40.59
2022-09-28 05:57:41,796 [foster.py] => Task 5, Epoch 2/34 => Loss 5.294, Loss_clf 1.139, Loss_fe 1.889, Loss_kd 1.957, Train_accy 38.35
2022-09-28 05:57:43,895 [foster.py] => Task 5, Epoch 3/34 => Loss 4.957, Loss_clf 1.056, Loss_fe 1.636, Loss_kd 1.956, Train_accy 41.73
2022-09-28 05:57:46,023 [foster.py] => Task 5, Epoch 4/34 => Loss 4.843, Loss_clf 1.027, Loss_fe 1.545, Loss_kd 1.961, Train_accy 42.93
2022-09-28 05:57:48,155 [foster.py] => Task 5, Epoch 5/34 => Loss 4.699, Loss_clf 0.994, Loss_fe 1.442, Loss_kd 1.954, Train_accy 43.23
2022-09-28 05:57:51,267 [foster.py] => Task 5, Epoch 6/34 => Loss 4.616, Loss_clf 0.980, Loss_fe 1.378, Loss_kd 1.950, Train_accy 43.13, Test_accy 45.94
2022-09-28 05:57:53,387 [foster.py] => Task 5, Epoch 7/34 => Loss 4.556, Loss_clf 0.965, Loss_fe 1.325, Loss_kd 1.957, Train_accy 43.92
2022-09-28 05:57:55,496 [foster.py] => Task 5, Epoch 8/34 => Loss 4.523, Loss_clf 0.962, Loss_fe 1.297, Loss_kd 1.954, Train_accy 45.42
2022-09-28 05:57:57,605 [foster.py] => Task 5, Epoch 9/34 => Loss 4.405, Loss_clf 0.926, Loss_fe 1.213, Loss_kd 1.957, Train_accy 46.22
2022-09-28 05:57:59,691 [foster.py] => Task 5, Epoch 10/34 => Loss 4.390, Loss_clf 0.920, Loss_fe 1.192, Loss_kd 1.967, Train_accy 43.33
2022-09-28 05:58:02,781 [foster.py] => Task 5, Epoch 11/34 => Loss 4.334, Loss_clf 0.908, Loss_fe 1.156, Loss_kd 1.961, Train_accy 44.62, Test_accy 46.73
2022-09-28 05:58:04,910 [foster.py] => Task 5, Epoch 12/34 => Loss 4.288, Loss_clf 0.892, Loss_fe 1.127, Loss_kd 1.960, Train_accy 44.12
2022-09-28 05:58:06,985 [foster.py] => Task 5, Epoch 13/34 => Loss 4.214, Loss_clf 0.865, Loss_fe 1.076, Loss_kd 1.963, Train_accy 45.02
2022-09-28 05:58:09,108 [foster.py] => Task 5, Epoch 14/34 => Loss 4.207, Loss_clf 0.864, Loss_fe 1.064, Loss_kd 1.968, Train_accy 44.02
2022-09-28 05:58:11,215 [foster.py] => Task 5, Epoch 15/34 => Loss 4.173, Loss_clf 0.853, Loss_fe 1.043, Loss_kd 1.966, Train_accy 44.02
2022-09-28 05:58:14,334 [foster.py] => Task 5, Epoch 16/34 => Loss 4.130, Loss_clf 0.843, Loss_fe 1.017, Loss_kd 1.960, Train_accy 46.12, Test_accy 47.52
2022-09-28 05:58:16,415 [foster.py] => Task 5, Epoch 17/34 => Loss 4.127, Loss_clf 0.842, Loss_fe 1.007, Loss_kd 1.967, Train_accy 46.31
2022-09-28 05:58:18,529 [foster.py] => Task 5, Epoch 18/34 => Loss 4.087, Loss_clf 0.819, Loss_fe 0.986, Loss_kd 1.970, Train_accy 44.42
2022-09-28 05:58:20,643 [foster.py] => Task 5, Epoch 19/34 => Loss 4.063, Loss_clf 0.821, Loss_fe 0.970, Loss_kd 1.961, Train_accy 46.12
2022-09-28 05:58:22,763 [foster.py] => Task 5, Epoch 20/34 => Loss 4.061, Loss_clf 0.814, Loss_fe 0.974, Loss_kd 1.962, Train_accy 47.31
2022-09-28 05:58:25,822 [foster.py] => Task 5, Epoch 21/34 => Loss 4.021, Loss_clf 0.791, Loss_fe 0.956, Loss_kd 1.964, Train_accy 46.61, Test_accy 48.51
2022-09-28 05:58:27,943 [foster.py] => Task 5, Epoch 22/34 => Loss 4.074, Loss_clf 0.806, Loss_fe 0.981, Loss_kd 1.975, Train_accy 45.52
2022-09-28 05:58:30,031 [foster.py] => Task 5, Epoch 23/34 => Loss 4.013, Loss_clf 0.798, Loss_fe 0.941, Loss_kd 1.964, Train_accy 45.42
2022-09-28 05:58:32,126 [foster.py] => Task 5, Epoch 24/34 => Loss 4.017, Loss_clf 0.798, Loss_fe 0.941, Loss_kd 1.968, Train_accy 44.02
2022-09-28 05:58:34,252 [foster.py] => Task 5, Epoch 25/34 => Loss 4.033, Loss_clf 0.803, Loss_fe 0.950, Loss_kd 1.969, Train_accy 46.41
2022-09-28 05:58:37,313 [foster.py] => Task 5, Epoch 26/34 => Loss 3.976, Loss_clf 0.781, Loss_fe 0.913, Loss_kd 1.971, Train_accy 46.41, Test_accy 48.32
2022-09-28 05:58:39,395 [foster.py] => Task 5, Epoch 27/34 => Loss 3.994, Loss_clf 0.789, Loss_fe 0.927, Loss_kd 1.968, Train_accy 47.51
2022-09-28 05:58:41,516 [foster.py] => Task 5, Epoch 28/34 => Loss 4.010, Loss_clf 0.798, Loss_fe 0.933, Loss_kd 1.969, Train_accy 46.61
2022-09-28 05:58:43,646 [foster.py] => Task 5, Epoch 29/34 => Loss 3.964, Loss_clf 0.773, Loss_fe 0.917, Loss_kd 1.964, Train_accy 47.91
2022-09-28 05:58:45,755 [foster.py] => Task 5, Epoch 30/34 => Loss 3.954, Loss_clf 0.763, Loss_fe 0.911, Loss_kd 1.969, Train_accy 48.11
2022-09-28 05:58:48,886 [foster.py] => Task 5, Epoch 31/34 => Loss 3.977, Loss_clf 0.780, Loss_fe 0.915, Loss_kd 1.970, Train_accy 46.61, Test_accy 48.32
2022-09-28 05:58:51,014 [foster.py] => Task 5, Epoch 32/34 => Loss 4.019, Loss_clf 0.802, Loss_fe 0.939, Loss_kd 1.968, Train_accy 46.81
2022-09-28 05:58:53,181 [foster.py] => Task 5, Epoch 33/34 => Loss 4.009, Loss_clf 0.798, Loss_fe 0.930, Loss_kd 1.970, Train_accy 47.51
2022-09-28 05:58:55,294 [foster.py] => Task 5, Epoch 34/34 => Loss 3.952, Loss_clf 0.761, Loss_fe 0.916, Loss_kd 1.965, Train_accy 48.31
2022-09-28 05:58:55,295 [foster.py] => do not weight align teacher!
2022-09-28 05:58:55,295 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 05:58:58,769 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.503,  Train_accy 18.33, Test_accy 37.23
2022-09-28 05:59:01,115 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.476,  Train_accy 19.02
2022-09-28 05:59:03,457 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.462,  Train_accy 19.42
2022-09-28 05:59:05,833 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.455,  Train_accy 19.22
2022-09-28 05:59:08,204 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.445,  Train_accy 19.62
2022-09-28 05:59:11,467 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.443,  Train_accy 20.42, Test_accy 38.22
2022-09-28 05:59:13,852 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.440,  Train_accy 19.32
2022-09-28 05:59:16,239 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.435,  Train_accy 20.72
2022-09-28 05:59:18,638 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.436,  Train_accy 19.62
2022-09-28 05:59:21,016 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.428,  Train_accy 20.92
2022-09-28 05:59:24,202 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.424,  Train_accy 20.42, Test_accy 39.21
2022-09-28 05:59:26,623 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.426,  Train_accy 20.02
2022-09-28 05:59:29,023 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.420,  Train_accy 20.62
2022-09-28 05:59:31,424 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.421,  Train_accy 21.22
2022-09-28 05:59:33,810 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.415,  Train_accy 21.51
2022-09-28 05:59:37,042 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.410,  Train_accy 21.02, Test_accy 39.01
2022-09-28 05:59:39,403 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.418,  Train_accy 21.31
2022-09-28 05:59:41,781 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.426,  Train_accy 20.42
2022-09-28 05:59:44,131 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.408,  Train_accy 20.52
2022-09-28 05:59:46,521 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.406,  Train_accy 20.82
2022-09-28 05:59:49,829 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.417,  Train_accy 20.82, Test_accy 39.41
2022-09-28 05:59:52,156 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.413,  Train_accy 21.22
2022-09-28 05:59:54,495 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.418,  Train_accy 21.02
2022-09-28 05:59:56,874 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.413,  Train_accy 19.92
2022-09-28 05:59:59,240 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.405,  Train_accy 20.92
2022-09-28 06:00:02,528 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.419,  Train_accy 20.42, Test_accy 39.41
2022-09-28 06:00:02,528 [foster.py] => do not weight align student!
2022-09-28 06:00:03,375 [foster.py] => darknet eval: 
2022-09-28 06:00:03,375 [foster.py] => CNN top1 curve: 39.41
2022-09-28 06:00:03,375 [foster.py] => CNN top5 curve: 81.98
2022-09-28 06:00:03,376 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 06:00:14,037 [foster.py] => Exemplar size: 440
2022-09-28 06:00:14,038 [trainer.py] => CNN: {'total': 48.12, 'old': 50.0, 'new': 35.38, 'base': 72.19, 'compound': 36.01}
2022-09-28 06:00:14,038 [trainer.py] => CNN top1 curve: [89.35, 69.64, 54.37, 56.88, 52.27, 48.12]
2022-09-28 06:00:14,038 [trainer.py] => CNN base curve: [89.35, 87.57, 82.84, 79.88, 75.15, 72.19]
2022-09-28 06:00:14,038 [trainer.py] => CNN old curve: [89.35, 87.57, 61.94, 56.63, 54.5, 50.0]
2022-09-28 06:00:14,038 [trainer.py] => CNN new curve: [0, 30.77, 24.19, 57.97, 38.71, 35.38]
2022-09-28 06:00:14,038 [trainer.py] => CNN compound curve: [0, 30.77, 20.0, 38.28, 38.01, 36.01]
2022-09-28 06:00:14,038 [trainer.py] => NME: {'total': 53.07, 'old': 53.64, 'new': 49.23, 'base': 66.86, 'compound': 46.13}
2022-09-28 06:00:14,038 [trainer.py] => NME top1 curve: [89.94, 75.3, 61.81, 58.99, 56.59, 53.07]
2022-09-28 06:00:14,038 [trainer.py] => NME base curve: [89.94, 82.25, 75.15, 71.01, 69.23, 66.86]
2022-09-28 06:00:14,038 [trainer.py] => NME old curve: [89.94, 82.25, 66.8, 56.31, 56.61, 53.64]
2022-09-28 06:00:14,038 [trainer.py] => NME new curve: [0, 60.26, 41.94, 71.01, 56.45, 49.23]
2022-09-28 06:00:14,038 [trainer.py] => NME compound curve: [0, 60.26, 45.71, 49.28, 48.71, 46.13]
2022-09-28 06:00:14,039 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 06:00:14,039 [trainer.py] => prefix: cil
2022-09-28 06:00:14,039 [trainer.py] => dataset: CFEE
2022-09-28 06:00:14,039 [trainer.py] => memory_size: 2000
2022-09-28 06:00:14,039 [trainer.py] => memory_per_class: 20
2022-09-28 06:00:14,039 [trainer.py] => fixed_memory: True
2022-09-28 06:00:14,039 [trainer.py] => shuffle: True
2022-09-28 06:00:14,039 [trainer.py] => init_cls: 7
2022-09-28 06:00:14,039 [trainer.py] => increment: 3
2022-09-28 06:00:14,039 [trainer.py] => model_name: foster
2022-09-28 06:00:14,040 [trainer.py] => convnet_type: resnet18
2022-09-28 06:00:14,040 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 06:00:14,040 [trainer.py] => seed: 1993
2022-09-28 06:00:14,040 [trainer.py] => beta1: 0.96
2022-09-28 06:00:14,040 [trainer.py] => beta2: 0.97
2022-09-28 06:00:14,040 [trainer.py] => oofc: ft
2022-09-28 06:00:14,040 [trainer.py] => is_teacher_wa: False
2022-09-28 06:00:14,040 [trainer.py] => is_student_wa: False
2022-09-28 06:00:14,040 [trainer.py] => lambda_okd: 1
2022-09-28 06:00:14,040 [trainer.py] => wa_value: 1
2022-09-28 06:00:14,040 [trainer.py] => init_epochs: 40
2022-09-28 06:00:14,040 [trainer.py] => init_lr: 0.01
2022-09-28 06:00:14,040 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 06:00:14,040 [trainer.py] => boosting_epochs: 34
2022-09-28 06:00:14,040 [trainer.py] => compression_epochs: 26
2022-09-28 06:00:14,040 [trainer.py] => lr: 0.001
2022-09-28 06:00:14,040 [trainer.py] => batch_size: 32
2022-09-28 06:00:14,040 [trainer.py] => weight_decay: 0.0005
2022-09-28 06:00:14,040 [trainer.py] => num_workers: 8
2022-09-28 06:00:14,040 [trainer.py] => T: 2
2022-09-28 06:00:14,040 [trainer.py] => nb_runs: 3
2022-09-28 06:00:14,040 [trainer.py] => fold: 10
2022-09-28 06:00:14,040 [data.py] => ========== Fold:6 ==========
2022-09-28 06:00:14,045 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 12, 10, 19, 21, 17, 18, 8, 7, 9, 14, 15, 13, 11, 16]
2022-09-28 06:00:14,262 [foster.py] => Learning on 0-7
2022-09-28 06:00:14,262 [foster.py] => All params: 11183694
2022-09-28 06:00:14,262 [foster.py] => Trainable params: 11183694
2022-09-28 06:00:16,619 [foster.py] => Task 0, Epoch 1/40 => Loss 1.310, Train_accy 52.84
2022-09-28 06:00:19,592 [foster.py] => Task 0, Epoch 2/40 => Loss 0.526, Train_accy 83.13, Test_accy 83.85
2022-09-28 06:00:22,643 [foster.py] => Task 0, Epoch 3/40 => Loss 0.365, Train_accy 87.07, Test_accy 85.09
2022-09-28 06:00:25,622 [foster.py] => Task 0, Epoch 4/40 => Loss 0.270, Train_accy 90.11, Test_accy 86.34
2022-09-28 06:00:28,575 [foster.py] => Task 0, Epoch 5/40 => Loss 0.221, Train_accy 92.05, Test_accy 84.47
2022-09-28 06:00:30,914 [foster.py] => Task 0, Epoch 6/40 => Loss 0.204, Train_accy 94.05
2022-09-28 06:00:33,897 [foster.py] => Task 0, Epoch 7/40 => Loss 0.170, Train_accy 94.40, Test_accy 88.82
2022-09-28 06:00:36,899 [foster.py] => Task 0, Epoch 8/40 => Loss 0.159, Train_accy 94.81, Test_accy 88.20
2022-09-28 06:00:39,874 [foster.py] => Task 0, Epoch 9/40 => Loss 0.132, Train_accy 95.99, Test_accy 83.85
2022-09-28 06:00:42,915 [foster.py] => Task 0, Epoch 10/40 => Loss 0.110, Train_accy 96.61, Test_accy 88.82
2022-09-28 06:00:45,313 [foster.py] => Task 0, Epoch 11/40 => Loss 0.103, Train_accy 96.06
2022-09-28 06:00:48,279 [foster.py] => Task 0, Epoch 12/40 => Loss 0.080, Train_accy 97.65, Test_accy 89.44
2022-09-28 06:00:51,235 [foster.py] => Task 0, Epoch 13/40 => Loss 0.081, Train_accy 97.16, Test_accy 87.58
2022-09-28 06:00:54,206 [foster.py] => Task 0, Epoch 14/40 => Loss 0.065, Train_accy 98.69, Test_accy 86.34
2022-09-28 06:00:57,184 [foster.py] => Task 0, Epoch 15/40 => Loss 0.075, Train_accy 98.48, Test_accy 87.58
2022-09-28 06:00:59,572 [foster.py] => Task 0, Epoch 16/40 => Loss 0.065, Train_accy 98.41
2022-09-28 06:01:02,550 [foster.py] => Task 0, Epoch 17/40 => Loss 0.061, Train_accy 98.41, Test_accy 89.44
2022-09-28 06:01:05,500 [foster.py] => Task 0, Epoch 18/40 => Loss 0.038, Train_accy 99.10, Test_accy 88.20
2022-09-28 06:01:08,458 [foster.py] => Task 0, Epoch 19/40 => Loss 0.032, Train_accy 99.38, Test_accy 85.71
2022-09-28 06:01:11,419 [foster.py] => Task 0, Epoch 20/40 => Loss 0.024, Train_accy 99.52, Test_accy 87.58
2022-09-28 06:01:13,832 [foster.py] => Task 0, Epoch 21/40 => Loss 0.027, Train_accy 99.31
2022-09-28 06:01:16,833 [foster.py] => Task 0, Epoch 22/40 => Loss 0.028, Train_accy 99.45, Test_accy 87.58
2022-09-28 06:01:19,820 [foster.py] => Task 0, Epoch 23/40 => Loss 0.025, Train_accy 99.59, Test_accy 88.20
2022-09-28 06:01:22,823 [foster.py] => Task 0, Epoch 24/40 => Loss 0.023, Train_accy 99.65, Test_accy 88.20
2022-09-28 06:01:25,815 [foster.py] => Task 0, Epoch 25/40 => Loss 0.045, Train_accy 99.24, Test_accy 86.96
2022-09-28 06:01:28,173 [foster.py] => Task 0, Epoch 26/40 => Loss 0.029, Train_accy 99.17
2022-09-28 06:01:31,165 [foster.py] => Task 0, Epoch 27/40 => Loss 0.029, Train_accy 99.59, Test_accy 88.82
2022-09-28 06:01:34,150 [foster.py] => Task 0, Epoch 28/40 => Loss 0.033, Train_accy 99.52, Test_accy 88.82
2022-09-28 06:01:37,116 [foster.py] => Task 0, Epoch 29/40 => Loss 0.022, Train_accy 99.52, Test_accy 87.58
2022-09-28 06:01:40,105 [foster.py] => Task 0, Epoch 30/40 => Loss 0.018, Train_accy 99.79, Test_accy 88.82
2022-09-28 06:01:42,486 [foster.py] => Task 0, Epoch 31/40 => Loss 0.012, Train_accy 100.00
2022-09-28 06:01:45,470 [foster.py] => Task 0, Epoch 32/40 => Loss 0.020, Train_accy 99.52, Test_accy 88.20
2022-09-28 06:01:48,466 [foster.py] => Task 0, Epoch 33/40 => Loss 0.015, Train_accy 99.79, Test_accy 88.82
2022-09-28 06:01:51,473 [foster.py] => Task 0, Epoch 34/40 => Loss 0.017, Train_accy 99.65, Test_accy 87.58
2022-09-28 06:01:54,462 [foster.py] => Task 0, Epoch 35/40 => Loss 0.012, Train_accy 99.86, Test_accy 90.06
2022-09-28 06:01:56,848 [foster.py] => Task 0, Epoch 36/40 => Loss 0.016, Train_accy 99.65
2022-09-28 06:01:59,850 [foster.py] => Task 0, Epoch 37/40 => Loss 0.017, Train_accy 99.65, Test_accy 88.82
2022-09-28 06:02:02,813 [foster.py] => Task 0, Epoch 38/40 => Loss 0.014, Train_accy 99.93, Test_accy 86.34
2022-09-28 06:02:05,825 [foster.py] => Task 0, Epoch 39/40 => Loss 0.016, Train_accy 99.72, Test_accy 90.06
2022-09-28 06:02:08,831 [foster.py] => Task 0, Epoch 40/40 => Loss 0.019, Train_accy 99.93, Test_accy 88.20
2022-09-28 06:02:08,831 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 06:02:15,691 [foster.py] => Exemplar size: 140
2022-09-28 06:02:15,691 [trainer.py] => CNN: {'total': 88.2, 'old': 88.2, 'new': 0, 'base': 88.2, 'compound': 0}
2022-09-28 06:02:15,691 [trainer.py] => CNN top1 curve: [88.2]
2022-09-28 06:02:15,691 [trainer.py] => CNN base curve: [88.2]
2022-09-28 06:02:15,691 [trainer.py] => CNN old curve: [88.2]
2022-09-28 06:02:15,691 [trainer.py] => CNN new curve: [0]
2022-09-28 06:02:15,691 [trainer.py] => CNN compound curve: [0]
2022-09-28 06:02:15,691 [trainer.py] => NME: {'total': 88.2, 'old': 88.2, 'new': 0, 'base': 88.2, 'compound': 0}
2022-09-28 06:02:15,692 [trainer.py] => NME top1 curve: [88.2]
2022-09-28 06:02:15,692 [trainer.py] => NME base curve: [88.2]
2022-09-28 06:02:15,692 [trainer.py] => NME old curve: [88.2]
2022-09-28 06:02:15,692 [trainer.py] => NME new curve: [0]
2022-09-28 06:02:15,692 [trainer.py] => NME compound curve: [0]
2022-09-28 06:02:15,926 [foster.py] => Learning on 7-10
2022-09-28 06:02:15,926 [foster.py] => All params: 22371995
2022-09-28 06:02:15,927 [foster.py] => Trainable params: 11191892
2022-09-28 06:02:15,947 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 06:02:18,428 [foster.py] => Task 1, Epoch 1/34 => Loss 4.909, Loss_clf 2.431, Loss_fe 1.934, Loss_kd 0.381, Train_accy 34.51, Test_accy 60.27
2022-09-28 06:02:20,167 [foster.py] => Task 1, Epoch 2/34 => Loss 2.843, Loss_clf 0.996, Loss_fe 1.290, Loss_kd 0.390, Train_accy 60.52
2022-09-28 06:02:21,931 [foster.py] => Task 1, Epoch 3/34 => Loss 2.340, Loss_clf 0.695, Loss_fe 1.124, Loss_kd 0.365, Train_accy 41.83
2022-09-28 06:02:23,724 [foster.py] => Task 1, Epoch 4/34 => Loss 2.168, Loss_clf 0.652, Loss_fe 1.019, Loss_kd 0.349, Train_accy 35.42
2022-09-28 06:02:25,483 [foster.py] => Task 1, Epoch 5/34 => Loss 2.076, Loss_clf 0.628, Loss_fe 0.944, Loss_kd 0.353, Train_accy 37.65
2022-09-28 06:02:28,004 [foster.py] => Task 1, Epoch 6/34 => Loss 1.974, Loss_clf 0.593, Loss_fe 0.874, Loss_kd 0.355, Train_accy 39.48, Test_accy 64.73
2022-09-28 06:02:29,756 [foster.py] => Task 1, Epoch 7/34 => Loss 1.907, Loss_clf 0.567, Loss_fe 0.839, Loss_kd 0.350, Train_accy 38.04
2022-09-28 06:02:31,465 [foster.py] => Task 1, Epoch 8/34 => Loss 1.917, Loss_clf 0.578, Loss_fe 0.832, Loss_kd 0.355, Train_accy 40.26
2022-09-28 06:02:33,209 [foster.py] => Task 1, Epoch 9/34 => Loss 1.845, Loss_clf 0.566, Loss_fe 0.786, Loss_kd 0.346, Train_accy 38.82
2022-09-28 06:02:34,951 [foster.py] => Task 1, Epoch 10/34 => Loss 1.784, Loss_clf 0.535, Loss_fe 0.754, Loss_kd 0.347, Train_accy 39.22
2022-09-28 06:02:37,403 [foster.py] => Task 1, Epoch 11/34 => Loss 1.824, Loss_clf 0.539, Loss_fe 0.775, Loss_kd 0.357, Train_accy 39.08, Test_accy 65.18
2022-09-28 06:02:39,126 [foster.py] => Task 1, Epoch 12/34 => Loss 1.719, Loss_clf 0.523, Loss_fe 0.704, Loss_kd 0.344, Train_accy 41.44
2022-09-28 06:02:40,902 [foster.py] => Task 1, Epoch 13/34 => Loss 1.705, Loss_clf 0.508, Loss_fe 0.698, Loss_kd 0.349, Train_accy 39.08
2022-09-28 06:02:42,634 [foster.py] => Task 1, Epoch 14/34 => Loss 1.702, Loss_clf 0.514, Loss_fe 0.684, Loss_kd 0.352, Train_accy 40.26
2022-09-28 06:02:44,415 [foster.py] => Task 1, Epoch 15/34 => Loss 1.655, Loss_clf 0.489, Loss_fe 0.668, Loss_kd 0.349, Train_accy 40.39
2022-09-28 06:02:46,840 [foster.py] => Task 1, Epoch 16/34 => Loss 1.617, Loss_clf 0.484, Loss_fe 0.645, Loss_kd 0.342, Train_accy 41.44, Test_accy 64.29
2022-09-28 06:02:48,584 [foster.py] => Task 1, Epoch 17/34 => Loss 1.608, Loss_clf 0.470, Loss_fe 0.641, Loss_kd 0.348, Train_accy 41.05
2022-09-28 06:02:50,339 [foster.py] => Task 1, Epoch 18/34 => Loss 1.631, Loss_clf 0.482, Loss_fe 0.651, Loss_kd 0.349, Train_accy 43.27
2022-09-28 06:02:52,086 [foster.py] => Task 1, Epoch 19/34 => Loss 1.587, Loss_clf 0.473, Loss_fe 0.622, Loss_kd 0.345, Train_accy 42.88
2022-09-28 06:02:53,833 [foster.py] => Task 1, Epoch 20/34 => Loss 1.557, Loss_clf 0.453, Loss_fe 0.613, Loss_kd 0.344, Train_accy 40.78
2022-09-28 06:02:56,370 [foster.py] => Task 1, Epoch 21/34 => Loss 1.560, Loss_clf 0.459, Loss_fe 0.609, Loss_kd 0.344, Train_accy 44.31, Test_accy 64.29
2022-09-28 06:02:58,146 [foster.py] => Task 1, Epoch 22/34 => Loss 1.533, Loss_clf 0.449, Loss_fe 0.589, Loss_kd 0.346, Train_accy 42.35
2022-09-28 06:02:59,895 [foster.py] => Task 1, Epoch 23/34 => Loss 1.561, Loss_clf 0.459, Loss_fe 0.609, Loss_kd 0.345, Train_accy 42.09
2022-09-28 06:03:01,645 [foster.py] => Task 1, Epoch 24/34 => Loss 1.602, Loss_clf 0.469, Loss_fe 0.625, Loss_kd 0.356, Train_accy 45.23
2022-09-28 06:03:03,371 [foster.py] => Task 1, Epoch 25/34 => Loss 1.527, Loss_clf 0.444, Loss_fe 0.590, Loss_kd 0.346, Train_accy 42.48
2022-09-28 06:03:05,855 [foster.py] => Task 1, Epoch 26/34 => Loss 1.533, Loss_clf 0.444, Loss_fe 0.590, Loss_kd 0.350, Train_accy 44.31, Test_accy 64.29
2022-09-28 06:03:07,577 [foster.py] => Task 1, Epoch 27/34 => Loss 1.556, Loss_clf 0.446, Loss_fe 0.598, Loss_kd 0.358, Train_accy 45.36
2022-09-28 06:03:09,371 [foster.py] => Task 1, Epoch 28/34 => Loss 1.545, Loss_clf 0.453, Loss_fe 0.599, Loss_kd 0.345, Train_accy 42.88
2022-09-28 06:03:11,135 [foster.py] => Task 1, Epoch 29/34 => Loss 1.527, Loss_clf 0.439, Loss_fe 0.588, Loss_kd 0.350, Train_accy 44.31
2022-09-28 06:03:12,895 [foster.py] => Task 1, Epoch 30/34 => Loss 1.522, Loss_clf 0.445, Loss_fe 0.584, Loss_kd 0.346, Train_accy 42.61
2022-09-28 06:03:15,494 [foster.py] => Task 1, Epoch 31/34 => Loss 1.542, Loss_clf 0.452, Loss_fe 0.593, Loss_kd 0.348, Train_accy 43.27, Test_accy 65.18
2022-09-28 06:03:17,291 [foster.py] => Task 1, Epoch 32/34 => Loss 1.510, Loss_clf 0.433, Loss_fe 0.584, Loss_kd 0.345, Train_accy 42.75
2022-09-28 06:03:19,027 [foster.py] => Task 1, Epoch 33/34 => Loss 1.494, Loss_clf 0.430, Loss_fe 0.564, Loss_kd 0.350, Train_accy 45.10
2022-09-28 06:03:20,851 [foster.py] => Task 1, Epoch 34/34 => Loss 1.540, Loss_clf 0.452, Loss_fe 0.595, Loss_kd 0.345, Train_accy 43.27
2022-09-28 06:03:20,852 [foster.py] => do not weight align teacher!
2022-09-28 06:03:20,852 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 06:03:23,674 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.511,  Train_accy 17.78, Test_accy 63.84
2022-09-28 06:03:25,635 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.373,  Train_accy 18.04
2022-09-28 06:03:27,604 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.278,  Train_accy 18.04
2022-09-28 06:03:29,585 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.236,  Train_accy 18.30
2022-09-28 06:03:31,518 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.195,  Train_accy 18.69
2022-09-28 06:03:34,131 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.181,  Train_accy 19.61, Test_accy 64.29
2022-09-28 06:03:36,079 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.190,  Train_accy 19.87
2022-09-28 06:03:38,042 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.184,  Train_accy 19.74
2022-09-28 06:03:40,003 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.169,  Train_accy 19.61
2022-09-28 06:03:42,000 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.149,  Train_accy 20.13
2022-09-28 06:03:44,573 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.164,  Train_accy 20.39, Test_accy 63.39
2022-09-28 06:03:46,521 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.144,  Train_accy 19.74
2022-09-28 06:03:48,446 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.158,  Train_accy 20.52
2022-09-28 06:03:50,379 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.138,  Train_accy 20.78
2022-09-28 06:03:52,330 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.148,  Train_accy 20.78
2022-09-28 06:03:54,916 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.136,  Train_accy 20.92, Test_accy 62.95
2022-09-28 06:03:56,921 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.146,  Train_accy 21.31
2022-09-28 06:03:58,914 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.147,  Train_accy 20.92
2022-09-28 06:04:00,816 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.143,  Train_accy 20.26
2022-09-28 06:04:02,771 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.136,  Train_accy 20.92
2022-09-28 06:04:05,396 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.145,  Train_accy 21.44, Test_accy 63.39
2022-09-28 06:04:07,354 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.148,  Train_accy 20.92
2022-09-28 06:04:09,291 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.135,  Train_accy 20.78
2022-09-28 06:04:11,227 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.141,  Train_accy 21.96
2022-09-28 06:04:13,192 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.142,  Train_accy 20.52
2022-09-28 06:04:15,775 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.145,  Train_accy 21.44, Test_accy 63.84
2022-09-28 06:04:15,775 [foster.py] => do not weight align student!
2022-09-28 06:04:16,441 [foster.py] => darknet eval: 
2022-09-28 06:04:16,441 [foster.py] => CNN top1 curve: 63.84
2022-09-28 06:04:16,441 [foster.py] => CNN top5 curve: 97.77
2022-09-28 06:04:16,441 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 06:04:22,746 [foster.py] => Exemplar size: 200
2022-09-28 06:04:22,746 [trainer.py] => CNN: {'total': 64.73, 'old': 82.61, 'new': 19.05, 'base': 82.61, 'compound': 19.05}
2022-09-28 06:04:22,746 [trainer.py] => CNN top1 curve: [88.2, 64.73]
2022-09-28 06:04:22,746 [trainer.py] => CNN base curve: [88.2, 82.61]
2022-09-28 06:04:22,746 [trainer.py] => CNN old curve: [88.2, 82.61]
2022-09-28 06:04:22,746 [trainer.py] => CNN new curve: [0, 19.05]
2022-09-28 06:04:22,746 [trainer.py] => CNN compound curve: [0, 19.05]
2022-09-28 06:04:22,746 [trainer.py] => NME: {'total': 75.45, 'old': 80.12, 'new': 63.49, 'base': 80.12, 'compound': 63.49}
2022-09-28 06:04:22,746 [trainer.py] => NME top1 curve: [88.2, 75.45]
2022-09-28 06:04:22,746 [trainer.py] => NME base curve: [88.2, 80.12]
2022-09-28 06:04:22,746 [trainer.py] => NME old curve: [88.2, 80.12]
2022-09-28 06:04:22,746 [trainer.py] => NME new curve: [0, 63.49]
2022-09-28 06:04:22,746 [trainer.py] => NME compound curve: [0, 63.49]
2022-09-28 06:04:22,980 [foster.py] => Learning on 10-13
2022-09-28 06:04:22,980 [foster.py] => All params: 22378148
2022-09-28 06:04:22,980 [foster.py] => Trainable params: 11196506
2022-09-28 06:04:23,001 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 06:04:25,635 [foster.py] => Task 2, Epoch 1/34 => Loss 5.226, Loss_clf 1.867, Loss_fe 2.183, Loss_kd 0.904, Train_accy 40.20, Test_accy 52.88
2022-09-28 06:04:27,421 [foster.py] => Task 2, Epoch 2/34 => Loss 3.615, Loss_clf 0.925, Loss_fe 1.538, Loss_kd 0.886, Train_accy 43.75
2022-09-28 06:04:29,242 [foster.py] => Task 2, Epoch 3/34 => Loss 3.280, Loss_clf 0.822, Loss_fe 1.324, Loss_kd 0.872, Train_accy 39.22
2022-09-28 06:04:31,077 [foster.py] => Task 2, Epoch 4/34 => Loss 3.063, Loss_clf 0.751, Loss_fe 1.179, Loss_kd 0.871, Train_accy 37.38
2022-09-28 06:04:32,907 [foster.py] => Task 2, Epoch 5/34 => Loss 2.961, Loss_clf 0.724, Loss_fe 1.102, Loss_kd 0.873, Train_accy 38.97
2022-09-28 06:04:35,520 [foster.py] => Task 2, Epoch 6/34 => Loss 2.854, Loss_clf 0.697, Loss_fe 1.032, Loss_kd 0.865, Train_accy 41.30, Test_accy 53.22
2022-09-28 06:04:37,358 [foster.py] => Task 2, Epoch 7/34 => Loss 2.762, Loss_clf 0.670, Loss_fe 0.967, Loss_kd 0.865, Train_accy 41.05
2022-09-28 06:04:39,148 [foster.py] => Task 2, Epoch 8/34 => Loss 2.710, Loss_clf 0.656, Loss_fe 0.917, Loss_kd 0.875, Train_accy 41.18
2022-09-28 06:04:40,937 [foster.py] => Task 2, Epoch 9/34 => Loss 2.642, Loss_clf 0.639, Loss_fe 0.882, Loss_kd 0.862, Train_accy 40.56
2022-09-28 06:04:42,746 [foster.py] => Task 2, Epoch 10/34 => Loss 2.607, Loss_clf 0.636, Loss_fe 0.839, Loss_kd 0.871, Train_accy 42.77
2022-09-28 06:04:45,383 [foster.py] => Task 2, Epoch 11/34 => Loss 2.550, Loss_clf 0.610, Loss_fe 0.808, Loss_kd 0.870, Train_accy 41.67, Test_accy 53.22
2022-09-28 06:04:47,176 [foster.py] => Task 2, Epoch 12/34 => Loss 2.536, Loss_clf 0.611, Loss_fe 0.786, Loss_kd 0.875, Train_accy 42.16
2022-09-28 06:04:48,963 [foster.py] => Task 2, Epoch 13/34 => Loss 2.475, Loss_clf 0.574, Loss_fe 0.762, Loss_kd 0.876, Train_accy 42.77
2022-09-28 06:04:50,808 [foster.py] => Task 2, Epoch 14/34 => Loss 2.431, Loss_clf 0.575, Loss_fe 0.727, Loss_kd 0.868, Train_accy 42.03
2022-09-28 06:04:52,611 [foster.py] => Task 2, Epoch 15/34 => Loss 2.438, Loss_clf 0.581, Loss_fe 0.726, Loss_kd 0.870, Train_accy 42.89
2022-09-28 06:04:55,226 [foster.py] => Task 2, Epoch 16/34 => Loss 2.437, Loss_clf 0.575, Loss_fe 0.725, Loss_kd 0.874, Train_accy 41.91, Test_accy 52.88
2022-09-28 06:04:57,055 [foster.py] => Task 2, Epoch 17/34 => Loss 2.398, Loss_clf 0.559, Loss_fe 0.700, Loss_kd 0.877, Train_accy 46.08
2022-09-28 06:04:58,882 [foster.py] => Task 2, Epoch 18/34 => Loss 2.387, Loss_clf 0.551, Loss_fe 0.691, Loss_kd 0.880, Train_accy 47.43
2022-09-28 06:05:00,719 [foster.py] => Task 2, Epoch 19/34 => Loss 2.355, Loss_clf 0.533, Loss_fe 0.682, Loss_kd 0.877, Train_accy 44.12
2022-09-28 06:05:02,535 [foster.py] => Task 2, Epoch 20/34 => Loss 2.305, Loss_clf 0.519, Loss_fe 0.648, Loss_kd 0.876, Train_accy 45.71
2022-09-28 06:05:05,150 [foster.py] => Task 2, Epoch 21/34 => Loss 2.305, Loss_clf 0.526, Loss_fe 0.647, Loss_kd 0.871, Train_accy 46.57, Test_accy 53.56
2022-09-28 06:05:06,982 [foster.py] => Task 2, Epoch 22/34 => Loss 2.317, Loss_clf 0.540, Loss_fe 0.650, Loss_kd 0.866, Train_accy 43.38
2022-09-28 06:05:08,819 [foster.py] => Task 2, Epoch 23/34 => Loss 2.297, Loss_clf 0.521, Loss_fe 0.636, Loss_kd 0.877, Train_accy 47.06
2022-09-28 06:05:10,677 [foster.py] => Task 2, Epoch 24/34 => Loss 2.290, Loss_clf 0.517, Loss_fe 0.631, Loss_kd 0.878, Train_accy 47.06
2022-09-28 06:05:12,488 [foster.py] => Task 2, Epoch 25/34 => Loss 2.284, Loss_clf 0.515, Loss_fe 0.630, Loss_kd 0.876, Train_accy 44.49
2022-09-28 06:05:15,116 [foster.py] => Task 2, Epoch 26/34 => Loss 2.233, Loss_clf 0.492, Loss_fe 0.607, Loss_kd 0.872, Train_accy 45.47, Test_accy 53.56
2022-09-28 06:05:16,969 [foster.py] => Task 2, Epoch 27/34 => Loss 2.289, Loss_clf 0.512, Loss_fe 0.634, Loss_kd 0.879, Train_accy 45.71
2022-09-28 06:05:18,798 [foster.py] => Task 2, Epoch 28/34 => Loss 2.284, Loss_clf 0.511, Loss_fe 0.636, Loss_kd 0.875, Train_accy 45.10
2022-09-28 06:05:20,598 [foster.py] => Task 2, Epoch 29/34 => Loss 2.273, Loss_clf 0.514, Loss_fe 0.616, Loss_kd 0.879, Train_accy 46.32
2022-09-28 06:05:22,416 [foster.py] => Task 2, Epoch 30/34 => Loss 2.269, Loss_clf 0.504, Loss_fe 0.623, Loss_kd 0.878, Train_accy 44.85
2022-09-28 06:05:25,032 [foster.py] => Task 2, Epoch 31/34 => Loss 2.251, Loss_clf 0.494, Loss_fe 0.616, Loss_kd 0.878, Train_accy 47.43, Test_accy 53.22
2022-09-28 06:05:26,857 [foster.py] => Task 2, Epoch 32/34 => Loss 2.241, Loss_clf 0.499, Loss_fe 0.605, Loss_kd 0.875, Train_accy 44.61
2022-09-28 06:05:28,661 [foster.py] => Task 2, Epoch 33/34 => Loss 2.278, Loss_clf 0.506, Loss_fe 0.627, Loss_kd 0.880, Train_accy 45.10
2022-09-28 06:05:30,443 [foster.py] => Task 2, Epoch 34/34 => Loss 2.248, Loss_clf 0.500, Loss_fe 0.613, Loss_kd 0.873, Train_accy 44.85
2022-09-28 06:05:30,443 [foster.py] => do not weight align teacher!
2022-09-28 06:05:30,444 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 06:05:33,434 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.865,  Train_accy 16.18, Test_accy 47.80
2022-09-28 06:05:35,486 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.734,  Train_accy 17.03
2022-09-28 06:05:37,562 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.682,  Train_accy 17.28
2022-09-28 06:05:39,652 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.658,  Train_accy 17.65
2022-09-28 06:05:41,714 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.629,  Train_accy 17.40
2022-09-28 06:05:44,405 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.624,  Train_accy 17.77, Test_accy 48.14
2022-09-28 06:05:46,457 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.610,  Train_accy 17.40
2022-09-28 06:05:48,471 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.601,  Train_accy 17.40
2022-09-28 06:05:50,500 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.599,  Train_accy 17.89
2022-09-28 06:05:52,544 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.611,  Train_accy 18.38
2022-09-28 06:05:55,261 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.604,  Train_accy 17.65, Test_accy 47.80
2022-09-28 06:05:57,319 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.593,  Train_accy 17.89
2022-09-28 06:05:59,359 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.604,  Train_accy 18.38
2022-09-28 06:06:01,383 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.591,  Train_accy 18.01
2022-09-28 06:06:03,417 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.586,  Train_accy 18.26
2022-09-28 06:06:06,180 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.590,  Train_accy 18.50, Test_accy 48.14
2022-09-28 06:06:08,197 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.585,  Train_accy 17.77
2022-09-28 06:06:10,199 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.585,  Train_accy 18.01
2022-09-28 06:06:12,247 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.583,  Train_accy 18.14
2022-09-28 06:06:14,296 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.567,  Train_accy 18.63
2022-09-28 06:06:17,014 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.580,  Train_accy 18.50, Test_accy 47.80
2022-09-28 06:06:19,015 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.593,  Train_accy 18.38
2022-09-28 06:06:21,064 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.576,  Train_accy 18.75
2022-09-28 06:06:23,079 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.581,  Train_accy 18.26
2022-09-28 06:06:25,089 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.575,  Train_accy 18.38
2022-09-28 06:06:27,803 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.585,  Train_accy 18.38, Test_accy 48.81
2022-09-28 06:06:27,804 [foster.py] => do not weight align student!
2022-09-28 06:06:28,512 [foster.py] => darknet eval: 
2022-09-28 06:06:28,512 [foster.py] => CNN top1 curve: 48.81
2022-09-28 06:06:28,513 [foster.py] => CNN top5 curve: 95.25
2022-09-28 06:06:28,513 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 06:06:35,879 [foster.py] => Exemplar size: 260
2022-09-28 06:06:35,879 [trainer.py] => CNN: {'total': 53.56, 'old': 60.27, 'new': 32.39, 'base': 79.5, 'compound': 22.39}
2022-09-28 06:06:35,879 [trainer.py] => CNN top1 curve: [88.2, 64.73, 53.56]
2022-09-28 06:06:35,879 [trainer.py] => CNN base curve: [88.2, 82.61, 79.5]
2022-09-28 06:06:35,880 [trainer.py] => CNN old curve: [88.2, 82.61, 60.27]
2022-09-28 06:06:35,880 [trainer.py] => CNN new curve: [0, 19.05, 32.39]
2022-09-28 06:06:35,880 [trainer.py] => CNN compound curve: [0, 19.05, 22.39]
2022-09-28 06:06:35,880 [trainer.py] => NME: {'total': 63.05, 'old': 66.07, 'new': 53.52, 'base': 74.53, 'compound': 49.25}
2022-09-28 06:06:35,880 [trainer.py] => NME top1 curve: [88.2, 75.45, 63.05]
2022-09-28 06:06:35,880 [trainer.py] => NME base curve: [88.2, 80.12, 74.53]
2022-09-28 06:06:35,880 [trainer.py] => NME old curve: [88.2, 80.12, 66.07]
2022-09-28 06:06:35,880 [trainer.py] => NME new curve: [0, 63.49, 53.52]
2022-09-28 06:06:35,880 [trainer.py] => NME compound curve: [0, 63.49, 49.25]
2022-09-28 06:06:36,112 [foster.py] => Learning on 13-16
2022-09-28 06:06:36,113 [foster.py] => All params: 22384301
2022-09-28 06:06:36,113 [foster.py] => Trainable params: 11201120
2022-09-28 06:06:36,133 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 06:06:38,889 [foster.py] => Task 3, Epoch 1/34 => Loss 5.688, Loss_clf 1.824, Loss_fe 2.218, Loss_kd 1.337, Train_accy 47.23, Test_accy 45.66
2022-09-28 06:06:40,842 [foster.py] => Task 3, Epoch 2/34 => Loss 4.023, Loss_clf 0.858, Loss_fe 1.536, Loss_kd 1.323, Train_accy 47.34
2022-09-28 06:06:42,777 [foster.py] => Task 3, Epoch 3/34 => Loss 3.631, Loss_clf 0.715, Loss_fe 1.300, Loss_kd 1.313, Train_accy 48.81
2022-09-28 06:06:44,717 [foster.py] => Task 3, Epoch 4/34 => Loss 3.437, Loss_clf 0.667, Loss_fe 1.162, Loss_kd 1.307, Train_accy 48.14
2022-09-28 06:06:46,638 [foster.py] => Task 3, Epoch 5/34 => Loss 3.351, Loss_clf 0.653, Loss_fe 1.076, Loss_kd 1.318, Train_accy 48.70
2022-09-28 06:06:49,423 [foster.py] => Task 3, Epoch 6/34 => Loss 3.309, Loss_clf 0.657, Loss_fe 1.039, Loss_kd 1.310, Train_accy 52.09, Test_accy 47.34
2022-09-28 06:06:51,351 [foster.py] => Task 3, Epoch 7/34 => Loss 3.156, Loss_clf 0.609, Loss_fe 0.939, Loss_kd 1.307, Train_accy 50.17
2022-09-28 06:06:53,260 [foster.py] => Task 3, Epoch 8/34 => Loss 3.109, Loss_clf 0.590, Loss_fe 0.896, Loss_kd 1.319, Train_accy 51.41
2022-09-28 06:06:55,197 [foster.py] => Task 3, Epoch 9/34 => Loss 3.041, Loss_clf 0.580, Loss_fe 0.853, Loss_kd 1.307, Train_accy 50.96
2022-09-28 06:06:57,130 [foster.py] => Task 3, Epoch 10/34 => Loss 2.987, Loss_clf 0.568, Loss_fe 0.809, Loss_kd 1.308, Train_accy 49.83
2022-09-28 06:06:59,867 [foster.py] => Task 3, Epoch 11/34 => Loss 2.979, Loss_clf 0.566, Loss_fe 0.793, Loss_kd 1.316, Train_accy 52.88, Test_accy 50.70
2022-09-28 06:07:01,771 [foster.py] => Task 3, Epoch 12/34 => Loss 2.903, Loss_clf 0.533, Loss_fe 0.748, Loss_kd 1.318, Train_accy 54.12
2022-09-28 06:07:03,659 [foster.py] => Task 3, Epoch 13/34 => Loss 2.898, Loss_clf 0.541, Loss_fe 0.737, Loss_kd 1.316, Train_accy 54.12
2022-09-28 06:07:05,583 [foster.py] => Task 3, Epoch 14/34 => Loss 2.882, Loss_clf 0.536, Loss_fe 0.717, Loss_kd 1.323, Train_accy 56.16
2022-09-28 06:07:07,495 [foster.py] => Task 3, Epoch 15/34 => Loss 2.829, Loss_clf 0.529, Loss_fe 0.691, Loss_kd 1.307, Train_accy 51.41
2022-09-28 06:07:10,260 [foster.py] => Task 3, Epoch 16/34 => Loss 2.812, Loss_clf 0.520, Loss_fe 0.679, Loss_kd 1.310, Train_accy 53.56, Test_accy 51.82
2022-09-28 06:07:12,213 [foster.py] => Task 3, Epoch 17/34 => Loss 2.836, Loss_clf 0.537, Loss_fe 0.681, Loss_kd 1.315, Train_accy 53.90
2022-09-28 06:07:14,145 [foster.py] => Task 3, Epoch 18/34 => Loss 2.794, Loss_clf 0.508, Loss_fe 0.658, Loss_kd 1.323, Train_accy 53.56
2022-09-28 06:07:16,083 [foster.py] => Task 3, Epoch 19/34 => Loss 2.757, Loss_clf 0.498, Loss_fe 0.634, Loss_kd 1.320, Train_accy 55.48
2022-09-28 06:07:18,045 [foster.py] => Task 3, Epoch 20/34 => Loss 2.754, Loss_clf 0.504, Loss_fe 0.628, Loss_kd 1.318, Train_accy 53.22
2022-09-28 06:07:20,871 [foster.py] => Task 3, Epoch 21/34 => Loss 2.725, Loss_clf 0.486, Loss_fe 0.621, Loss_kd 1.315, Train_accy 55.48, Test_accy 52.10
2022-09-28 06:07:22,866 [foster.py] => Task 3, Epoch 22/34 => Loss 2.733, Loss_clf 0.494, Loss_fe 0.619, Loss_kd 1.316, Train_accy 53.11
2022-09-28 06:07:24,798 [foster.py] => Task 3, Epoch 23/34 => Loss 2.742, Loss_clf 0.504, Loss_fe 0.617, Loss_kd 1.317, Train_accy 54.01
2022-09-28 06:07:26,701 [foster.py] => Task 3, Epoch 24/34 => Loss 2.725, Loss_clf 0.487, Loss_fe 0.611, Loss_kd 1.321, Train_accy 55.71
2022-09-28 06:07:28,639 [foster.py] => Task 3, Epoch 25/34 => Loss 2.702, Loss_clf 0.471, Loss_fe 0.604, Loss_kd 1.322, Train_accy 57.51
2022-09-28 06:07:31,366 [foster.py] => Task 3, Epoch 26/34 => Loss 2.693, Loss_clf 0.478, Loss_fe 0.594, Loss_kd 1.318, Train_accy 56.16, Test_accy 51.82
2022-09-28 06:07:33,296 [foster.py] => Task 3, Epoch 27/34 => Loss 2.674, Loss_clf 0.479, Loss_fe 0.577, Loss_kd 1.315, Train_accy 55.82
2022-09-28 06:07:35,288 [foster.py] => Task 3, Epoch 28/34 => Loss 2.714, Loss_clf 0.490, Loss_fe 0.608, Loss_kd 1.313, Train_accy 57.29
2022-09-28 06:07:37,182 [foster.py] => Task 3, Epoch 29/34 => Loss 2.689, Loss_clf 0.470, Loss_fe 0.590, Loss_kd 1.323, Train_accy 56.38
2022-09-28 06:07:39,118 [foster.py] => Task 3, Epoch 30/34 => Loss 2.663, Loss_clf 0.460, Loss_fe 0.577, Loss_kd 1.321, Train_accy 56.38
2022-09-28 06:07:41,911 [foster.py] => Task 3, Epoch 31/34 => Loss 2.681, Loss_clf 0.480, Loss_fe 0.596, Loss_kd 1.304, Train_accy 55.48, Test_accy 52.38
2022-09-28 06:07:43,866 [foster.py] => Task 3, Epoch 32/34 => Loss 2.694, Loss_clf 0.474, Loss_fe 0.601, Loss_kd 1.316, Train_accy 57.40
2022-09-28 06:07:45,886 [foster.py] => Task 3, Epoch 33/34 => Loss 2.677, Loss_clf 0.468, Loss_fe 0.586, Loss_kd 1.319, Train_accy 56.72
2022-09-28 06:07:47,779 [foster.py] => Task 3, Epoch 34/34 => Loss 2.687, Loss_clf 0.474, Loss_fe 0.588, Loss_kd 1.319, Train_accy 56.27
2022-09-28 06:07:47,780 [foster.py] => do not weight align teacher!
2022-09-28 06:07:47,780 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 06:07:50,904 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.106,  Train_accy 15.93, Test_accy 39.78
2022-09-28 06:07:53,083 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.040,  Train_accy 16.50
2022-09-28 06:07:55,257 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.001,  Train_accy 16.95
2022-09-28 06:07:57,385 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 1.973,  Train_accy 16.95
2022-09-28 06:07:59,584 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.974,  Train_accy 16.72
2022-09-28 06:08:02,553 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.964,  Train_accy 17.06, Test_accy 40.62
2022-09-28 06:08:04,674 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.951,  Train_accy 17.29
2022-09-28 06:08:06,818 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.965,  Train_accy 17.85
2022-09-28 06:08:08,972 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.950,  Train_accy 17.06
2022-09-28 06:08:11,099 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.940,  Train_accy 17.29
2022-09-28 06:08:14,004 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.932,  Train_accy 18.87, Test_accy 40.34
2022-09-28 06:08:16,140 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.934,  Train_accy 19.21
2022-09-28 06:08:18,269 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.939,  Train_accy 18.87
2022-09-28 06:08:20,441 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.922,  Train_accy 18.19
2022-09-28 06:08:22,619 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.916,  Train_accy 18.76
2022-09-28 06:08:25,579 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.927,  Train_accy 19.44, Test_accy 40.34
2022-09-28 06:08:27,754 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.927,  Train_accy 18.53
2022-09-28 06:08:29,883 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.918,  Train_accy 20.00
2022-09-28 06:08:32,048 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.935,  Train_accy 19.55
2022-09-28 06:08:34,208 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.917,  Train_accy 20.00
2022-09-28 06:08:37,065 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.922,  Train_accy 21.02, Test_accy 42.02
2022-09-28 06:08:39,264 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.924,  Train_accy 19.55
2022-09-28 06:08:41,469 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.918,  Train_accy 19.77
2022-09-28 06:08:43,593 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.923,  Train_accy 20.45
2022-09-28 06:08:45,765 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.917,  Train_accy 19.44
2022-09-28 06:08:48,678 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.922,  Train_accy 19.44, Test_accy 42.02
2022-09-28 06:08:48,678 [foster.py] => do not weight align student!
2022-09-28 06:08:49,435 [foster.py] => darknet eval: 
2022-09-28 06:08:49,435 [foster.py] => CNN top1 curve: 42.02
2022-09-28 06:08:49,435 [foster.py] => CNN top5 curve: 93.28
2022-09-28 06:08:49,435 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 06:08:57,924 [foster.py] => Exemplar size: 320
2022-09-28 06:08:57,924 [trainer.py] => CNN: {'total': 52.38, 'old': 54.92, 'new': 40.32, 'base': 76.4, 'compound': 32.65}
2022-09-28 06:08:57,924 [trainer.py] => CNN top1 curve: [88.2, 64.73, 53.56, 52.38]
2022-09-28 06:08:57,924 [trainer.py] => CNN base curve: [88.2, 82.61, 79.5, 76.4]
2022-09-28 06:08:57,924 [trainer.py] => CNN old curve: [88.2, 82.61, 60.27, 54.92]
2022-09-28 06:08:57,924 [trainer.py] => CNN new curve: [0, 19.05, 32.39, 40.32]
2022-09-28 06:08:57,924 [trainer.py] => CNN compound curve: [0, 19.05, 22.39, 32.65]
2022-09-28 06:08:57,924 [trainer.py] => NME: {'total': 59.94, 'old': 57.63, 'new': 70.97, 'base': 67.7, 'compound': 53.57}
2022-09-28 06:08:57,924 [trainer.py] => NME top1 curve: [88.2, 75.45, 63.05, 59.94]
2022-09-28 06:08:57,924 [trainer.py] => NME base curve: [88.2, 80.12, 74.53, 67.7]
2022-09-28 06:08:57,924 [trainer.py] => NME old curve: [88.2, 80.12, 66.07, 57.63]
2022-09-28 06:08:57,924 [trainer.py] => NME new curve: [0, 63.49, 53.52, 70.97]
2022-09-28 06:08:57,924 [trainer.py] => NME compound curve: [0, 63.49, 49.25, 53.57]
2022-09-28 06:08:58,156 [foster.py] => Learning on 16-19
2022-09-28 06:08:58,157 [foster.py] => All params: 22390454
2022-09-28 06:08:58,157 [foster.py] => Trainable params: 11205734
2022-09-28 06:08:58,177 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 06:09:01,084 [foster.py] => Task 4, Epoch 1/34 => Loss 6.375, Loss_clf 1.887, Loss_fe 2.448, Loss_kd 1.718, Train_accy 42.02, Test_accy 43.75
2022-09-28 06:09:03,094 [foster.py] => Task 4, Epoch 2/34 => Loss 4.877, Loss_clf 1.022, Loss_fe 1.792, Loss_kd 1.737, Train_accy 49.09
2022-09-28 06:09:05,067 [foster.py] => Task 4, Epoch 3/34 => Loss 4.522, Loss_clf 0.903, Loss_fe 1.573, Loss_kd 1.723, Train_accy 54.23
2022-09-28 06:09:07,060 [foster.py] => Task 4, Epoch 4/34 => Loss 4.340, Loss_clf 0.887, Loss_fe 1.401, Loss_kd 1.728, Train_accy 52.41
2022-09-28 06:09:09,088 [foster.py] => Task 4, Epoch 5/34 => Loss 4.190, Loss_clf 0.825, Loss_fe 1.315, Loss_kd 1.726, Train_accy 57.98
2022-09-28 06:09:12,032 [foster.py] => Task 4, Epoch 6/34 => Loss 4.070, Loss_clf 0.800, Loss_fe 1.221, Loss_kd 1.726, Train_accy 54.45, Test_accy 50.46
2022-09-28 06:09:14,034 [foster.py] => Task 4, Epoch 7/34 => Loss 3.962, Loss_clf 0.782, Loss_fe 1.135, Loss_kd 1.722, Train_accy 56.16
2022-09-28 06:09:16,006 [foster.py] => Task 4, Epoch 8/34 => Loss 3.906, Loss_clf 0.753, Loss_fe 1.099, Loss_kd 1.730, Train_accy 56.27
2022-09-28 06:09:18,049 [foster.py] => Task 4, Epoch 9/34 => Loss 3.883, Loss_clf 0.769, Loss_fe 1.066, Loss_kd 1.724, Train_accy 55.41
2022-09-28 06:09:20,031 [foster.py] => Task 4, Epoch 10/34 => Loss 3.808, Loss_clf 0.736, Loss_fe 1.024, Loss_kd 1.724, Train_accy 54.66
2022-09-28 06:09:23,023 [foster.py] => Task 4, Epoch 11/34 => Loss 3.737, Loss_clf 0.706, Loss_fe 0.965, Loss_kd 1.741, Train_accy 55.95, Test_accy 51.85
2022-09-28 06:09:25,028 [foster.py] => Task 4, Epoch 12/34 => Loss 3.634, Loss_clf 0.680, Loss_fe 0.910, Loss_kd 1.721, Train_accy 58.74
2022-09-28 06:09:27,056 [foster.py] => Task 4, Epoch 13/34 => Loss 3.718, Loss_clf 0.728, Loss_fe 0.933, Loss_kd 1.732, Train_accy 60.13
2022-09-28 06:09:29,071 [foster.py] => Task 4, Epoch 14/34 => Loss 3.621, Loss_clf 0.676, Loss_fe 0.884, Loss_kd 1.736, Train_accy 57.23
2022-09-28 06:09:31,085 [foster.py] => Task 4, Epoch 15/34 => Loss 3.597, Loss_clf 0.666, Loss_fe 0.876, Loss_kd 1.730, Train_accy 60.34
2022-09-28 06:09:34,046 [foster.py] => Task 4, Epoch 16/34 => Loss 3.595, Loss_clf 0.668, Loss_fe 0.861, Loss_kd 1.740, Train_accy 58.09, Test_accy 52.55
2022-09-28 06:09:36,021 [foster.py] => Task 4, Epoch 17/34 => Loss 3.508, Loss_clf 0.646, Loss_fe 0.811, Loss_kd 1.727, Train_accy 59.16
2022-09-28 06:09:38,023 [foster.py] => Task 4, Epoch 18/34 => Loss 3.495, Loss_clf 0.636, Loss_fe 0.795, Loss_kd 1.738, Train_accy 60.34
2022-09-28 06:09:40,006 [foster.py] => Task 4, Epoch 19/34 => Loss 3.493, Loss_clf 0.633, Loss_fe 0.790, Loss_kd 1.743, Train_accy 60.88
2022-09-28 06:09:41,985 [foster.py] => Task 4, Epoch 20/34 => Loss 3.484, Loss_clf 0.630, Loss_fe 0.809, Loss_kd 1.723, Train_accy 58.84
2022-09-28 06:09:44,877 [foster.py] => Task 4, Epoch 21/34 => Loss 3.448, Loss_clf 0.619, Loss_fe 0.779, Loss_kd 1.725, Train_accy 59.38, Test_accy 52.78
2022-09-28 06:09:46,881 [foster.py] => Task 4, Epoch 22/34 => Loss 3.438, Loss_clf 0.610, Loss_fe 0.768, Loss_kd 1.734, Train_accy 60.45
2022-09-28 06:09:48,871 [foster.py] => Task 4, Epoch 23/34 => Loss 3.442, Loss_clf 0.605, Loss_fe 0.768, Loss_kd 1.742, Train_accy 62.17
2022-09-28 06:09:50,837 [foster.py] => Task 4, Epoch 24/34 => Loss 3.415, Loss_clf 0.609, Loss_fe 0.758, Loss_kd 1.725, Train_accy 58.95
2022-09-28 06:09:52,854 [foster.py] => Task 4, Epoch 25/34 => Loss 3.384, Loss_clf 0.588, Loss_fe 0.733, Loss_kd 1.738, Train_accy 60.13
2022-09-28 06:09:55,790 [foster.py] => Task 4, Epoch 26/34 => Loss 3.450, Loss_clf 0.624, Loss_fe 0.764, Loss_kd 1.736, Train_accy 60.34, Test_accy 53.24
2022-09-28 06:09:57,769 [foster.py] => Task 4, Epoch 27/34 => Loss 3.407, Loss_clf 0.596, Loss_fe 0.741, Loss_kd 1.743, Train_accy 63.34
2022-09-28 06:09:59,762 [foster.py] => Task 4, Epoch 28/34 => Loss 3.406, Loss_clf 0.608, Loss_fe 0.742, Loss_kd 1.731, Train_accy 61.84
2022-09-28 06:10:01,791 [foster.py] => Task 4, Epoch 29/34 => Loss 3.339, Loss_clf 0.569, Loss_fe 0.717, Loss_kd 1.729, Train_accy 60.88
2022-09-28 06:10:03,780 [foster.py] => Task 4, Epoch 30/34 => Loss 3.352, Loss_clf 0.576, Loss_fe 0.701, Loss_kd 1.748, Train_accy 62.59
2022-09-28 06:10:06,702 [foster.py] => Task 4, Epoch 31/34 => Loss 3.347, Loss_clf 0.572, Loss_fe 0.708, Loss_kd 1.741, Train_accy 62.92, Test_accy 53.94
2022-09-28 06:10:08,716 [foster.py] => Task 4, Epoch 32/34 => Loss 3.406, Loss_clf 0.604, Loss_fe 0.738, Loss_kd 1.738, Train_accy 62.38
2022-09-28 06:10:10,699 [foster.py] => Task 4, Epoch 33/34 => Loss 3.357, Loss_clf 0.587, Loss_fe 0.718, Loss_kd 1.728, Train_accy 61.41
2022-09-28 06:10:12,737 [foster.py] => Task 4, Epoch 34/34 => Loss 3.335, Loss_clf 0.576, Loss_fe 0.705, Loss_kd 1.730, Train_accy 62.70
2022-09-28 06:10:12,738 [foster.py] => do not weight align teacher!
2022-09-28 06:10:12,738 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 06:10:16,014 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.430,  Train_accy 15.76, Test_accy 34.72
2022-09-28 06:10:18,270 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.358,  Train_accy 16.40
2022-09-28 06:10:20,507 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.318,  Train_accy 18.33
2022-09-28 06:10:22,766 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.288,  Train_accy 17.68
2022-09-28 06:10:24,988 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.279,  Train_accy 18.11
2022-09-28 06:10:28,082 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.277,  Train_accy 18.44, Test_accy 37.50
2022-09-28 06:10:30,346 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.264,  Train_accy 19.19
2022-09-28 06:10:32,600 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.257,  Train_accy 19.72
2022-09-28 06:10:34,864 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.259,  Train_accy 18.97
2022-09-28 06:10:37,130 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.253,  Train_accy 20.15
2022-09-28 06:10:40,193 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.255,  Train_accy 20.47, Test_accy 38.43
2022-09-28 06:10:42,527 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.250,  Train_accy 20.47
2022-09-28 06:10:44,767 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.244,  Train_accy 20.04
2022-09-28 06:10:47,098 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.252,  Train_accy 19.51
2022-09-28 06:10:49,335 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.254,  Train_accy 20.58
2022-09-28 06:10:52,398 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.233,  Train_accy 20.36, Test_accy 38.43
2022-09-28 06:10:54,647 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.244,  Train_accy 20.36
2022-09-28 06:10:56,942 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.235,  Train_accy 20.69
2022-09-28 06:10:59,183 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.243,  Train_accy 20.58
2022-09-28 06:11:01,447 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.240,  Train_accy 20.90
2022-09-28 06:11:04,501 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.231,  Train_accy 20.79, Test_accy 38.89
2022-09-28 06:11:06,761 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.244,  Train_accy 21.01
2022-09-28 06:11:09,000 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.242,  Train_accy 21.33
2022-09-28 06:11:11,240 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.240,  Train_accy 20.47
2022-09-28 06:11:13,516 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.225,  Train_accy 21.01
2022-09-28 06:11:16,556 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.246,  Train_accy 21.01, Test_accy 37.73
2022-09-28 06:11:16,556 [foster.py] => do not weight align student!
2022-09-28 06:11:17,352 [foster.py] => darknet eval: 
2022-09-28 06:11:17,353 [foster.py] => CNN top1 curve: 37.73
2022-09-28 06:11:17,353 [foster.py] => CNN top5 curve: 86.57
2022-09-28 06:11:17,353 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 06:11:27,009 [foster.py] => Exemplar size: 380
2022-09-28 06:11:27,009 [trainer.py] => CNN: {'total': 53.47, 'old': 52.1, 'new': 60.0, 'base': 72.05, 'compound': 42.44}
2022-09-28 06:11:27,009 [trainer.py] => CNN top1 curve: [88.2, 64.73, 53.56, 52.38, 53.47]
2022-09-28 06:11:27,009 [trainer.py] => CNN base curve: [88.2, 82.61, 79.5, 76.4, 72.05]
2022-09-28 06:11:27,009 [trainer.py] => CNN old curve: [88.2, 82.61, 60.27, 54.92, 52.1]
2022-09-28 06:11:27,009 [trainer.py] => CNN new curve: [0, 19.05, 32.39, 40.32, 60.0]
2022-09-28 06:11:27,009 [trainer.py] => CNN compound curve: [0, 19.05, 22.39, 32.65, 42.44]
2022-09-28 06:11:27,009 [trainer.py] => NME: {'total': 57.87, 'old': 55.74, 'new': 68.0, 'base': 67.7, 'compound': 52.03}
2022-09-28 06:11:27,009 [trainer.py] => NME top1 curve: [88.2, 75.45, 63.05, 59.94, 57.87]
2022-09-28 06:11:27,009 [trainer.py] => NME base curve: [88.2, 80.12, 74.53, 67.7, 67.7]
2022-09-28 06:11:27,009 [trainer.py] => NME old curve: [88.2, 80.12, 66.07, 57.63, 55.74]
2022-09-28 06:11:27,009 [trainer.py] => NME new curve: [0, 63.49, 53.52, 70.97, 68.0]
2022-09-28 06:11:27,009 [trainer.py] => NME compound curve: [0, 63.49, 49.25, 53.57, 52.03]
2022-09-28 06:11:27,240 [foster.py] => Learning on 19-22
2022-09-28 06:11:27,241 [foster.py] => All params: 22396607
2022-09-28 06:11:27,241 [foster.py] => Trainable params: 11210348
2022-09-28 06:11:27,261 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 06:11:30,300 [foster.py] => Task 5, Epoch 1/34 => Loss 6.756, Loss_clf 1.985, Loss_fe 2.505, Loss_kd 1.956, Train_accy 39.52, Test_accy 40.28
2022-09-28 06:11:32,428 [foster.py] => Task 5, Epoch 2/34 => Loss 5.319, Loss_clf 1.165, Loss_fe 1.894, Loss_kd 1.952, Train_accy 37.91
2022-09-28 06:11:34,531 [foster.py] => Task 5, Epoch 3/34 => Loss 5.037, Loss_clf 1.072, Loss_fe 1.714, Loss_kd 1.945, Train_accy 41.12
2022-09-28 06:11:36,617 [foster.py] => Task 5, Epoch 4/34 => Loss 4.893, Loss_clf 1.040, Loss_fe 1.591, Loss_kd 1.953, Train_accy 42.53
2022-09-28 06:11:38,685 [foster.py] => Task 5, Epoch 5/34 => Loss 4.784, Loss_clf 1.018, Loss_fe 1.488, Loss_kd 1.967, Train_accy 44.23
2022-09-28 06:11:41,828 [foster.py] => Task 5, Epoch 6/34 => Loss 4.648, Loss_clf 0.980, Loss_fe 1.396, Loss_kd 1.962, Train_accy 43.23, Test_accy 44.64
2022-09-28 06:11:43,963 [foster.py] => Task 5, Epoch 7/34 => Loss 4.608, Loss_clf 0.998, Loss_fe 1.343, Loss_kd 1.958, Train_accy 41.73
2022-09-28 06:11:46,083 [foster.py] => Task 5, Epoch 8/34 => Loss 4.483, Loss_clf 0.940, Loss_fe 1.276, Loss_kd 1.958, Train_accy 44.63
2022-09-28 06:11:48,159 [foster.py] => Task 5, Epoch 9/34 => Loss 4.365, Loss_clf 0.913, Loss_fe 1.186, Loss_kd 1.957, Train_accy 43.93
2022-09-28 06:11:50,248 [foster.py] => Task 5, Epoch 10/34 => Loss 4.359, Loss_clf 0.915, Loss_fe 1.169, Loss_kd 1.964, Train_accy 44.13
2022-09-28 06:11:53,347 [foster.py] => Task 5, Epoch 11/34 => Loss 4.291, Loss_clf 0.901, Loss_fe 1.123, Loss_kd 1.958, Train_accy 45.84, Test_accy 46.23
2022-09-28 06:11:55,466 [foster.py] => Task 5, Epoch 12/34 => Loss 4.230, Loss_clf 0.869, Loss_fe 1.088, Loss_kd 1.963, Train_accy 44.43
2022-09-28 06:11:57,587 [foster.py] => Task 5, Epoch 13/34 => Loss 4.229, Loss_clf 0.864, Loss_fe 1.084, Loss_kd 1.969, Train_accy 43.63
2022-09-28 06:11:59,686 [foster.py] => Task 5, Epoch 14/34 => Loss 4.204, Loss_clf 0.882, Loss_fe 1.057, Loss_kd 1.956, Train_accy 46.24
2022-09-28 06:12:01,794 [foster.py] => Task 5, Epoch 15/34 => Loss 4.158, Loss_clf 0.836, Loss_fe 1.032, Loss_kd 1.977, Train_accy 48.35
2022-09-28 06:12:04,917 [foster.py] => Task 5, Epoch 16/34 => Loss 4.115, Loss_clf 0.824, Loss_fe 1.007, Loss_kd 1.972, Train_accy 45.24, Test_accy 48.41
2022-09-28 06:12:07,029 [foster.py] => Task 5, Epoch 17/34 => Loss 4.068, Loss_clf 0.814, Loss_fe 0.977, Loss_kd 1.967, Train_accy 45.44
2022-09-28 06:12:09,182 [foster.py] => Task 5, Epoch 18/34 => Loss 4.116, Loss_clf 0.840, Loss_fe 1.000, Loss_kd 1.966, Train_accy 44.83
2022-09-28 06:12:11,302 [foster.py] => Task 5, Epoch 19/34 => Loss 4.094, Loss_clf 0.836, Loss_fe 0.977, Loss_kd 1.969, Train_accy 47.94
2022-09-28 06:12:13,496 [foster.py] => Task 5, Epoch 20/34 => Loss 4.053, Loss_clf 0.814, Loss_fe 0.970, Loss_kd 1.959, Train_accy 45.84
2022-09-28 06:12:16,540 [foster.py] => Task 5, Epoch 21/34 => Loss 4.011, Loss_clf 0.792, Loss_fe 0.948, Loss_kd 1.960, Train_accy 47.34, Test_accy 48.41
2022-09-28 06:12:18,650 [foster.py] => Task 5, Epoch 22/34 => Loss 4.044, Loss_clf 0.812, Loss_fe 0.949, Loss_kd 1.972, Train_accy 46.84
2022-09-28 06:12:20,763 [foster.py] => Task 5, Epoch 23/34 => Loss 4.057, Loss_clf 0.825, Loss_fe 0.962, Loss_kd 1.961, Train_accy 45.74
2022-09-28 06:12:22,958 [foster.py] => Task 5, Epoch 24/34 => Loss 3.985, Loss_clf 0.780, Loss_fe 0.922, Loss_kd 1.972, Train_accy 47.34
2022-09-28 06:12:25,063 [foster.py] => Task 5, Epoch 25/34 => Loss 3.995, Loss_clf 0.785, Loss_fe 0.918, Loss_kd 1.979, Train_accy 45.74
2022-09-28 06:12:28,108 [foster.py] => Task 5, Epoch 26/34 => Loss 4.014, Loss_clf 0.806, Loss_fe 0.935, Loss_kd 1.963, Train_accy 48.14, Test_accy 48.81
2022-09-28 06:12:30,163 [foster.py] => Task 5, Epoch 27/34 => Loss 3.941, Loss_clf 0.764, Loss_fe 0.900, Loss_kd 1.967, Train_accy 48.24
2022-09-28 06:12:32,278 [foster.py] => Task 5, Epoch 28/34 => Loss 4.008, Loss_clf 0.778, Loss_fe 0.958, Loss_kd 1.962, Train_accy 46.64
2022-09-28 06:12:34,375 [foster.py] => Task 5, Epoch 29/34 => Loss 4.044, Loss_clf 0.809, Loss_fe 0.946, Loss_kd 1.977, Train_accy 47.54
2022-09-28 06:12:36,490 [foster.py] => Task 5, Epoch 30/34 => Loss 3.975, Loss_clf 0.775, Loss_fe 0.915, Loss_kd 1.974, Train_accy 45.44
2022-09-28 06:12:39,580 [foster.py] => Task 5, Epoch 31/34 => Loss 3.967, Loss_clf 0.780, Loss_fe 0.905, Loss_kd 1.971, Train_accy 46.54, Test_accy 49.80
2022-09-28 06:12:41,653 [foster.py] => Task 5, Epoch 32/34 => Loss 3.969, Loss_clf 0.771, Loss_fe 0.921, Loss_kd 1.966, Train_accy 46.94
2022-09-28 06:12:43,745 [foster.py] => Task 5, Epoch 33/34 => Loss 4.048, Loss_clf 0.809, Loss_fe 0.944, Loss_kd 1.982, Train_accy 46.84
2022-09-28 06:12:45,845 [foster.py] => Task 5, Epoch 34/34 => Loss 3.959, Loss_clf 0.768, Loss_fe 0.900, Loss_kd 1.978, Train_accy 46.14
2022-09-28 06:12:45,845 [foster.py] => do not weight align teacher!
2022-09-28 06:12:45,846 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 06:12:49,244 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.470,  Train_accy 18.96, Test_accy 34.92
2022-09-28 06:12:51,600 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.458,  Train_accy 20.56
2022-09-28 06:12:53,930 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.454,  Train_accy 20.06
2022-09-28 06:12:56,299 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.440,  Train_accy 19.86
2022-09-28 06:12:58,713 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.451,  Train_accy 20.06
2022-09-28 06:13:01,931 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.435,  Train_accy 20.56, Test_accy 35.52
2022-09-28 06:13:04,306 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.435,  Train_accy 21.16
2022-09-28 06:13:06,690 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.429,  Train_accy 21.06
2022-09-28 06:13:09,038 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.424,  Train_accy 20.76
2022-09-28 06:13:11,404 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.413,  Train_accy 20.26
2022-09-28 06:13:14,609 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.424,  Train_accy 20.56, Test_accy 37.30
2022-09-28 06:13:16,966 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.410,  Train_accy 21.56
2022-09-28 06:13:19,337 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.417,  Train_accy 21.56
2022-09-28 06:13:21,703 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.409,  Train_accy 21.77
2022-09-28 06:13:24,092 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.419,  Train_accy 21.06
2022-09-28 06:13:27,292 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.412,  Train_accy 20.56, Test_accy 38.49
2022-09-28 06:13:29,659 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.407,  Train_accy 21.97
2022-09-28 06:13:32,034 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.414,  Train_accy 21.56
2022-09-28 06:13:34,375 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.410,  Train_accy 21.97
2022-09-28 06:13:36,719 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.414,  Train_accy 21.87
2022-09-28 06:13:39,920 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.404,  Train_accy 21.16, Test_accy 37.50
2022-09-28 06:13:42,279 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.425,  Train_accy 21.36
2022-09-28 06:13:44,615 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.409,  Train_accy 21.16
2022-09-28 06:13:46,994 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.406,  Train_accy 21.87
2022-09-28 06:13:49,385 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.423,  Train_accy 21.97
2022-09-28 06:13:52,619 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.418,  Train_accy 22.37, Test_accy 37.50
2022-09-28 06:13:52,619 [foster.py] => do not weight align student!
2022-09-28 06:13:53,501 [foster.py] => darknet eval: 
2022-09-28 06:13:53,501 [foster.py] => CNN top1 curve: 37.5
2022-09-28 06:13:53,501 [foster.py] => CNN top5 curve: 81.55
2022-09-28 06:13:53,502 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 06:14:04,184 [foster.py] => Exemplar size: 440
2022-09-28 06:14:04,185 [trainer.py] => CNN: {'total': 49.01, 'old': 51.39, 'new': 34.72, 'base': 70.81, 'compound': 38.78}
2022-09-28 06:14:04,185 [trainer.py] => CNN top1 curve: [88.2, 64.73, 53.56, 52.38, 53.47, 49.01]
2022-09-28 06:14:04,185 [trainer.py] => CNN base curve: [88.2, 82.61, 79.5, 76.4, 72.05, 70.81]
2022-09-28 06:14:04,185 [trainer.py] => CNN old curve: [88.2, 82.61, 60.27, 54.92, 52.1, 51.39]
2022-09-28 06:14:04,185 [trainer.py] => CNN new curve: [0, 19.05, 32.39, 40.32, 60.0, 34.72]
2022-09-28 06:14:04,185 [trainer.py] => CNN compound curve: [0, 19.05, 22.39, 32.65, 42.44, 38.78]
2022-09-28 06:14:04,185 [trainer.py] => NME: {'total': 53.97, 'old': 55.32, 'new': 45.83, 'base': 65.84, 'compound': 48.4}
2022-09-28 06:14:04,185 [trainer.py] => NME top1 curve: [88.2, 75.45, 63.05, 59.94, 57.87, 53.97]
2022-09-28 06:14:04,185 [trainer.py] => NME base curve: [88.2, 80.12, 74.53, 67.7, 67.7, 65.84]
2022-09-28 06:14:04,185 [trainer.py] => NME old curve: [88.2, 80.12, 66.07, 57.63, 55.74, 55.32]
2022-09-28 06:14:04,185 [trainer.py] => NME new curve: [0, 63.49, 53.52, 70.97, 68.0, 45.83]
2022-09-28 06:14:04,185 [trainer.py] => NME compound curve: [0, 63.49, 49.25, 53.57, 52.03, 48.4]
2022-09-28 06:14:04,186 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 06:14:04,186 [trainer.py] => prefix: cil
2022-09-28 06:14:04,186 [trainer.py] => dataset: CFEE
2022-09-28 06:14:04,186 [trainer.py] => memory_size: 2000
2022-09-28 06:14:04,186 [trainer.py] => memory_per_class: 20
2022-09-28 06:14:04,186 [trainer.py] => fixed_memory: True
2022-09-28 06:14:04,187 [trainer.py] => shuffle: True
2022-09-28 06:14:04,187 [trainer.py] => init_cls: 7
2022-09-28 06:14:04,187 [trainer.py] => increment: 3
2022-09-28 06:14:04,187 [trainer.py] => model_name: foster
2022-09-28 06:14:04,187 [trainer.py] => convnet_type: resnet18
2022-09-28 06:14:04,187 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 06:14:04,187 [trainer.py] => seed: 1993
2022-09-28 06:14:04,187 [trainer.py] => beta1: 0.96
2022-09-28 06:14:04,187 [trainer.py] => beta2: 0.97
2022-09-28 06:14:04,187 [trainer.py] => oofc: ft
2022-09-28 06:14:04,187 [trainer.py] => is_teacher_wa: False
2022-09-28 06:14:04,187 [trainer.py] => is_student_wa: False
2022-09-28 06:14:04,187 [trainer.py] => lambda_okd: 1
2022-09-28 06:14:04,187 [trainer.py] => wa_value: 1
2022-09-28 06:14:04,187 [trainer.py] => init_epochs: 40
2022-09-28 06:14:04,187 [trainer.py] => init_lr: 0.01
2022-09-28 06:14:04,187 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 06:14:04,187 [trainer.py] => boosting_epochs: 34
2022-09-28 06:14:04,187 [trainer.py] => compression_epochs: 26
2022-09-28 06:14:04,187 [trainer.py] => lr: 0.001
2022-09-28 06:14:04,187 [trainer.py] => batch_size: 32
2022-09-28 06:14:04,187 [trainer.py] => weight_decay: 0.0005
2022-09-28 06:14:04,187 [trainer.py] => num_workers: 8
2022-09-28 06:14:04,187 [trainer.py] => T: 2
2022-09-28 06:14:04,187 [trainer.py] => nb_runs: 3
2022-09-28 06:14:04,187 [trainer.py] => fold: 10
2022-09-28 06:14:04,188 [data.py] => ========== Fold:7 ==========
2022-09-28 06:14:04,193 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 12, 10, 19, 21, 17, 18, 8, 7, 9, 14, 15, 13, 11, 16]
2022-09-28 06:14:04,409 [foster.py] => Learning on 0-7
2022-09-28 06:14:04,410 [foster.py] => All params: 11183694
2022-09-28 06:14:04,410 [foster.py] => Trainable params: 11183694
2022-09-28 06:14:06,832 [foster.py] => Task 0, Epoch 1/40 => Loss 1.381, Train_accy 48.42
2022-09-28 06:14:09,840 [foster.py] => Task 0, Epoch 2/40 => Loss 0.530, Train_accy 82.65, Test_accy 85.23
2022-09-28 06:14:12,900 [foster.py] => Task 0, Epoch 3/40 => Loss 0.346, Train_accy 87.31, Test_accy 87.25
2022-09-28 06:14:15,909 [foster.py] => Task 0, Epoch 4/40 => Loss 0.287, Train_accy 88.82, Test_accy 84.56
2022-09-28 06:14:18,907 [foster.py] => Task 0, Epoch 5/40 => Loss 0.229, Train_accy 92.11, Test_accy 83.89
2022-09-28 06:14:21,345 [foster.py] => Task 0, Epoch 6/40 => Loss 0.172, Train_accy 94.24
2022-09-28 06:14:24,371 [foster.py] => Task 0, Epoch 7/40 => Loss 0.160, Train_accy 94.72, Test_accy 86.58
2022-09-28 06:14:27,371 [foster.py] => Task 0, Epoch 8/40 => Loss 0.138, Train_accy 94.99, Test_accy 88.59
2022-09-28 06:14:30,355 [foster.py] => Task 0, Epoch 9/40 => Loss 0.099, Train_accy 96.98, Test_accy 87.92
2022-09-28 06:14:33,352 [foster.py] => Task 0, Epoch 10/40 => Loss 0.101, Train_accy 96.84, Test_accy 87.25
2022-09-28 06:14:35,768 [foster.py] => Task 0, Epoch 11/40 => Loss 0.078, Train_accy 98.35
2022-09-28 06:14:38,739 [foster.py] => Task 0, Epoch 12/40 => Loss 0.072, Train_accy 97.87, Test_accy 87.25
2022-09-28 06:14:41,737 [foster.py] => Task 0, Epoch 13/40 => Loss 0.058, Train_accy 98.42, Test_accy 86.58
2022-09-28 06:14:44,704 [foster.py] => Task 0, Epoch 14/40 => Loss 0.063, Train_accy 98.01, Test_accy 84.56
2022-09-28 06:14:47,678 [foster.py] => Task 0, Epoch 15/40 => Loss 0.039, Train_accy 99.11, Test_accy 84.56
2022-09-28 06:14:50,041 [foster.py] => Task 0, Epoch 16/40 => Loss 0.040, Train_accy 98.83
2022-09-28 06:14:53,049 [foster.py] => Task 0, Epoch 17/40 => Loss 0.042, Train_accy 98.49, Test_accy 83.89
2022-09-28 06:14:56,047 [foster.py] => Task 0, Epoch 18/40 => Loss 0.038, Train_accy 99.18, Test_accy 87.25
2022-09-28 06:14:59,114 [foster.py] => Task 0, Epoch 19/40 => Loss 0.030, Train_accy 99.31, Test_accy 86.58
2022-09-28 06:15:02,132 [foster.py] => Task 0, Epoch 20/40 => Loss 0.031, Train_accy 99.18, Test_accy 87.25
2022-09-28 06:15:04,508 [foster.py] => Task 0, Epoch 21/40 => Loss 0.025, Train_accy 99.66
2022-09-28 06:15:07,486 [foster.py] => Task 0, Epoch 22/40 => Loss 0.017, Train_accy 99.79, Test_accy 85.91
2022-09-28 06:15:10,491 [foster.py] => Task 0, Epoch 23/40 => Loss 0.018, Train_accy 99.86, Test_accy 87.25
2022-09-28 06:15:13,484 [foster.py] => Task 0, Epoch 24/40 => Loss 0.024, Train_accy 99.38, Test_accy 85.23
2022-09-28 06:15:16,472 [foster.py] => Task 0, Epoch 25/40 => Loss 0.019, Train_accy 99.73, Test_accy 85.91
2022-09-28 06:15:18,829 [foster.py] => Task 0, Epoch 26/40 => Loss 0.017, Train_accy 99.79
2022-09-28 06:15:21,837 [foster.py] => Task 0, Epoch 27/40 => Loss 0.014, Train_accy 99.93, Test_accy 87.25
2022-09-28 06:15:24,813 [foster.py] => Task 0, Epoch 28/40 => Loss 0.018, Train_accy 99.86, Test_accy 86.58
2022-09-28 06:15:27,843 [foster.py] => Task 0, Epoch 29/40 => Loss 0.016, Train_accy 99.79, Test_accy 85.23
2022-09-28 06:15:30,852 [foster.py] => Task 0, Epoch 30/40 => Loss 0.016, Train_accy 99.73, Test_accy 87.25
2022-09-28 06:15:33,231 [foster.py] => Task 0, Epoch 31/40 => Loss 0.014, Train_accy 99.86
2022-09-28 06:15:36,217 [foster.py] => Task 0, Epoch 32/40 => Loss 0.016, Train_accy 99.73, Test_accy 87.92
2022-09-28 06:15:39,204 [foster.py] => Task 0, Epoch 33/40 => Loss 0.011, Train_accy 99.93, Test_accy 87.92
2022-09-28 06:15:42,210 [foster.py] => Task 0, Epoch 34/40 => Loss 0.013, Train_accy 99.86, Test_accy 86.58
2022-09-28 06:15:45,219 [foster.py] => Task 0, Epoch 35/40 => Loss 0.015, Train_accy 99.79, Test_accy 89.26
2022-09-28 06:15:47,591 [foster.py] => Task 0, Epoch 36/40 => Loss 0.011, Train_accy 99.86
2022-09-28 06:15:50,548 [foster.py] => Task 0, Epoch 37/40 => Loss 0.013, Train_accy 99.79, Test_accy 88.59
2022-09-28 06:15:53,550 [foster.py] => Task 0, Epoch 38/40 => Loss 0.012, Train_accy 99.86, Test_accy 88.59
2022-09-28 06:15:56,541 [foster.py] => Task 0, Epoch 39/40 => Loss 0.012, Train_accy 99.86, Test_accy 86.58
2022-09-28 06:15:59,527 [foster.py] => Task 0, Epoch 40/40 => Loss 0.009, Train_accy 100.00, Test_accy 86.58
2022-09-28 06:15:59,528 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 06:16:06,385 [foster.py] => Exemplar size: 140
2022-09-28 06:16:06,385 [trainer.py] => CNN: {'total': 86.58, 'old': 86.58, 'new': 0, 'base': 86.58, 'compound': 0}
2022-09-28 06:16:06,385 [trainer.py] => CNN top1 curve: [86.58]
2022-09-28 06:16:06,385 [trainer.py] => CNN base curve: [86.58]
2022-09-28 06:16:06,385 [trainer.py] => CNN old curve: [86.58]
2022-09-28 06:16:06,385 [trainer.py] => CNN new curve: [0]
2022-09-28 06:16:06,385 [trainer.py] => CNN compound curve: [0]
2022-09-28 06:16:06,385 [trainer.py] => NME: {'total': 89.26, 'old': 89.26, 'new': 0, 'base': 89.26, 'compound': 0}
2022-09-28 06:16:06,385 [trainer.py] => NME top1 curve: [89.26]
2022-09-28 06:16:06,385 [trainer.py] => NME base curve: [89.26]
2022-09-28 06:16:06,385 [trainer.py] => NME old curve: [89.26]
2022-09-28 06:16:06,385 [trainer.py] => NME new curve: [0]
2022-09-28 06:16:06,385 [trainer.py] => NME compound curve: [0]
2022-09-28 06:16:06,620 [foster.py] => Learning on 7-10
2022-09-28 06:16:06,620 [foster.py] => All params: 22371995
2022-09-28 06:16:06,620 [foster.py] => Trainable params: 11191892
2022-09-28 06:16:06,640 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 06:16:09,091 [foster.py] => Task 1, Epoch 1/34 => Loss 4.853, Loss_clf 2.583, Loss_fe 1.722, Loss_kd 0.384, Train_accy 31.72, Test_accy 61.21
2022-09-28 06:16:10,822 [foster.py] => Task 1, Epoch 2/34 => Loss 2.769, Loss_clf 0.949, Loss_fe 1.260, Loss_kd 0.392, Train_accy 62.39
2022-09-28 06:16:12,521 [foster.py] => Task 1, Epoch 3/34 => Loss 2.271, Loss_clf 0.670, Loss_fe 1.093, Loss_kd 0.356, Train_accy 42.33
2022-09-28 06:16:14,287 [foster.py] => Task 1, Epoch 4/34 => Loss 2.125, Loss_clf 0.630, Loss_fe 0.984, Loss_kd 0.357, Train_accy 41.81
2022-09-28 06:16:16,039 [foster.py] => Task 1, Epoch 5/34 => Loss 2.053, Loss_clf 0.620, Loss_fe 0.921, Loss_kd 0.359, Train_accy 46.53
2022-09-28 06:16:18,487 [foster.py] => Task 1, Epoch 6/34 => Loss 1.943, Loss_clf 0.576, Loss_fe 0.860, Loss_kd 0.355, Train_accy 40.24, Test_accy 65.89
2022-09-28 06:16:20,194 [foster.py] => Task 1, Epoch 7/34 => Loss 1.902, Loss_clf 0.575, Loss_fe 0.817, Loss_kd 0.357, Train_accy 42.73
2022-09-28 06:16:21,906 [foster.py] => Task 1, Epoch 8/34 => Loss 1.851, Loss_clf 0.560, Loss_fe 0.784, Loss_kd 0.355, Train_accy 39.45
2022-09-28 06:16:23,673 [foster.py] => Task 1, Epoch 9/34 => Loss 1.820, Loss_clf 0.551, Loss_fe 0.765, Loss_kd 0.353, Train_accy 39.97
2022-09-28 06:16:25,453 [foster.py] => Task 1, Epoch 10/34 => Loss 1.741, Loss_clf 0.528, Loss_fe 0.723, Loss_kd 0.344, Train_accy 41.02
2022-09-28 06:16:27,872 [foster.py] => Task 1, Epoch 11/34 => Loss 1.719, Loss_clf 0.519, Loss_fe 0.698, Loss_kd 0.352, Train_accy 43.38, Test_accy 65.42
2022-09-28 06:16:29,629 [foster.py] => Task 1, Epoch 12/34 => Loss 1.693, Loss_clf 0.502, Loss_fe 0.686, Loss_kd 0.354, Train_accy 42.46
2022-09-28 06:16:31,386 [foster.py] => Task 1, Epoch 13/34 => Loss 1.694, Loss_clf 0.518, Loss_fe 0.672, Loss_kd 0.353, Train_accy 42.33
2022-09-28 06:16:33,141 [foster.py] => Task 1, Epoch 14/34 => Loss 1.683, Loss_clf 0.510, Loss_fe 0.675, Loss_kd 0.349, Train_accy 41.68
2022-09-28 06:16:34,931 [foster.py] => Task 1, Epoch 15/34 => Loss 1.684, Loss_clf 0.508, Loss_fe 0.672, Loss_kd 0.353, Train_accy 42.73
2022-09-28 06:16:37,351 [foster.py] => Task 1, Epoch 16/34 => Loss 1.618, Loss_clf 0.482, Loss_fe 0.642, Loss_kd 0.346, Train_accy 43.25, Test_accy 66.36
2022-09-28 06:16:39,068 [foster.py] => Task 1, Epoch 17/34 => Loss 1.623, Loss_clf 0.488, Loss_fe 0.632, Loss_kd 0.352, Train_accy 43.77
2022-09-28 06:16:40,789 [foster.py] => Task 1, Epoch 18/34 => Loss 1.607, Loss_clf 0.480, Loss_fe 0.625, Loss_kd 0.351, Train_accy 43.77
2022-09-28 06:16:42,590 [foster.py] => Task 1, Epoch 19/34 => Loss 1.560, Loss_clf 0.459, Loss_fe 0.597, Loss_kd 0.352, Train_accy 43.91
2022-09-28 06:16:44,320 [foster.py] => Task 1, Epoch 20/34 => Loss 1.558, Loss_clf 0.452, Loss_fe 0.608, Loss_kd 0.349, Train_accy 43.12
2022-09-28 06:16:46,781 [foster.py] => Task 1, Epoch 21/34 => Loss 1.558, Loss_clf 0.459, Loss_fe 0.597, Loss_kd 0.351, Train_accy 43.51, Test_accy 65.89
2022-09-28 06:16:48,529 [foster.py] => Task 1, Epoch 22/34 => Loss 1.527, Loss_clf 0.443, Loss_fe 0.581, Loss_kd 0.352, Train_accy 45.48
2022-09-28 06:16:50,251 [foster.py] => Task 1, Epoch 23/34 => Loss 1.530, Loss_clf 0.441, Loss_fe 0.583, Loss_kd 0.354, Train_accy 45.74
2022-09-28 06:16:52,001 [foster.py] => Task 1, Epoch 24/34 => Loss 1.541, Loss_clf 0.453, Loss_fe 0.591, Loss_kd 0.348, Train_accy 44.69
2022-09-28 06:16:53,764 [foster.py] => Task 1, Epoch 25/34 => Loss 1.482, Loss_clf 0.425, Loss_fe 0.556, Loss_kd 0.352, Train_accy 46.66
2022-09-28 06:16:56,256 [foster.py] => Task 1, Epoch 26/34 => Loss 1.500, Loss_clf 0.433, Loss_fe 0.571, Loss_kd 0.348, Train_accy 44.69, Test_accy 65.89
2022-09-28 06:16:57,968 [foster.py] => Task 1, Epoch 27/34 => Loss 1.516, Loss_clf 0.439, Loss_fe 0.574, Loss_kd 0.352, Train_accy 45.35
2022-09-28 06:16:59,709 [foster.py] => Task 1, Epoch 28/34 => Loss 1.488, Loss_clf 0.426, Loss_fe 0.562, Loss_kd 0.349, Train_accy 46.40
2022-09-28 06:17:01,450 [foster.py] => Task 1, Epoch 29/34 => Loss 1.505, Loss_clf 0.427, Loss_fe 0.572, Loss_kd 0.354, Train_accy 46.00
2022-09-28 06:17:03,251 [foster.py] => Task 1, Epoch 30/34 => Loss 1.505, Loss_clf 0.436, Loss_fe 0.571, Loss_kd 0.349, Train_accy 44.30
2022-09-28 06:17:05,715 [foster.py] => Task 1, Epoch 31/34 => Loss 1.512, Loss_clf 0.436, Loss_fe 0.575, Loss_kd 0.351, Train_accy 44.30, Test_accy 65.89
2022-09-28 06:17:07,461 [foster.py] => Task 1, Epoch 32/34 => Loss 1.503, Loss_clf 0.430, Loss_fe 0.567, Loss_kd 0.354, Train_accy 45.87
2022-09-28 06:17:09,175 [foster.py] => Task 1, Epoch 33/34 => Loss 1.468, Loss_clf 0.419, Loss_fe 0.548, Loss_kd 0.350, Train_accy 44.69
2022-09-28 06:17:10,912 [foster.py] => Task 1, Epoch 34/34 => Loss 1.519, Loss_clf 0.433, Loss_fe 0.587, Loss_kd 0.350, Train_accy 45.74
2022-09-28 06:17:10,913 [foster.py] => do not weight align teacher!
2022-09-28 06:17:10,913 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 06:17:13,720 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.471,  Train_accy 17.56, Test_accy 59.81
2022-09-28 06:17:15,691 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.322,  Train_accy 17.96
2022-09-28 06:17:17,633 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.236,  Train_accy 18.48
2022-09-28 06:17:19,600 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.203,  Train_accy 19.40
2022-09-28 06:17:21,533 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.190,  Train_accy 19.00
2022-09-28 06:17:24,123 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.173,  Train_accy 20.18, Test_accy 60.28
2022-09-28 06:17:26,033 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.189,  Train_accy 20.45
2022-09-28 06:17:28,014 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.166,  Train_accy 21.10
2022-09-28 06:17:29,957 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.162,  Train_accy 21.63
2022-09-28 06:17:31,915 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.142,  Train_accy 20.97
2022-09-28 06:17:34,514 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.138,  Train_accy 21.36, Test_accy 59.35
2022-09-28 06:17:36,455 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.149,  Train_accy 21.89
2022-09-28 06:17:38,415 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.141,  Train_accy 22.02
2022-09-28 06:17:40,365 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.144,  Train_accy 20.84
2022-09-28 06:17:42,325 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.129,  Train_accy 21.49
2022-09-28 06:17:44,908 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.124,  Train_accy 22.67, Test_accy 59.35
2022-09-28 06:17:46,866 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.134,  Train_accy 22.54
2022-09-28 06:17:48,790 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.142,  Train_accy 22.15
2022-09-28 06:17:50,726 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.128,  Train_accy 22.28
2022-09-28 06:17:52,672 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.116,  Train_accy 21.89
2022-09-28 06:17:55,248 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.130,  Train_accy 22.80, Test_accy 59.35
2022-09-28 06:17:57,217 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.140,  Train_accy 23.59
2022-09-28 06:17:59,150 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.120,  Train_accy 22.28
2022-09-28 06:18:01,063 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.134,  Train_accy 22.54
2022-09-28 06:18:03,012 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.149,  Train_accy 21.23
2022-09-28 06:18:05,582 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.128,  Train_accy 23.46, Test_accy 60.28
2022-09-28 06:18:05,582 [foster.py] => do not weight align student!
2022-09-28 06:18:06,249 [foster.py] => darknet eval: 
2022-09-28 06:18:06,249 [foster.py] => CNN top1 curve: 60.28
2022-09-28 06:18:06,249 [foster.py] => CNN top5 curve: 98.13
2022-09-28 06:18:06,250 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 06:18:12,517 [foster.py] => Exemplar size: 200
2022-09-28 06:18:12,517 [trainer.py] => CNN: {'total': 65.89, 'old': 82.55, 'new': 27.69, 'base': 82.55, 'compound': 27.69}
2022-09-28 06:18:12,517 [trainer.py] => CNN top1 curve: [86.58, 65.89]
2022-09-28 06:18:12,517 [trainer.py] => CNN base curve: [86.58, 82.55]
2022-09-28 06:18:12,517 [trainer.py] => CNN old curve: [86.58, 82.55]
2022-09-28 06:18:12,517 [trainer.py] => CNN new curve: [0, 27.69]
2022-09-28 06:18:12,517 [trainer.py] => CNN compound curve: [0, 27.69]
2022-09-28 06:18:12,518 [trainer.py] => NME: {'total': 73.36, 'old': 82.55, 'new': 52.31, 'base': 82.55, 'compound': 52.31}
2022-09-28 06:18:12,518 [trainer.py] => NME top1 curve: [89.26, 73.36]
2022-09-28 06:18:12,518 [trainer.py] => NME base curve: [89.26, 82.55]
2022-09-28 06:18:12,518 [trainer.py] => NME old curve: [89.26, 82.55]
2022-09-28 06:18:12,518 [trainer.py] => NME new curve: [0, 52.31]
2022-09-28 06:18:12,518 [trainer.py] => NME compound curve: [0, 52.31]
2022-09-28 06:18:12,753 [foster.py] => Learning on 10-13
2022-09-28 06:18:12,753 [foster.py] => All params: 22378148
2022-09-28 06:18:12,753 [foster.py] => Trainable params: 11196506
2022-09-28 06:18:12,773 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 06:18:15,356 [foster.py] => Task 2, Epoch 1/34 => Loss 5.489, Loss_clf 2.207, Loss_fe 2.093, Loss_kd 0.915, Train_accy 36.32, Test_accy 52.86
2022-09-28 06:18:17,206 [foster.py] => Task 2, Epoch 2/34 => Loss 3.575, Loss_clf 0.979, Loss_fe 1.482, Loss_kd 0.857, Train_accy 44.03
2022-09-28 06:18:19,042 [foster.py] => Task 2, Epoch 3/34 => Loss 3.205, Loss_clf 0.798, Loss_fe 1.298, Loss_kd 0.853, Train_accy 40.17
2022-09-28 06:18:20,830 [foster.py] => Task 2, Epoch 4/34 => Loss 3.048, Loss_clf 0.740, Loss_fe 1.217, Loss_kd 0.840, Train_accy 38.93
2022-09-28 06:18:22,685 [foster.py] => Task 2, Epoch 5/34 => Loss 2.932, Loss_clf 0.701, Loss_fe 1.121, Loss_kd 0.853, Train_accy 38.18
2022-09-28 06:18:25,382 [foster.py] => Task 2, Epoch 6/34 => Loss 2.807, Loss_clf 0.685, Loss_fe 1.028, Loss_kd 0.841, Train_accy 37.06, Test_accy 50.84
2022-09-28 06:18:27,202 [foster.py] => Task 2, Epoch 7/34 => Loss 2.732, Loss_clf 0.660, Loss_fe 0.957, Loss_kd 0.857, Train_accy 40.30
2022-09-28 06:18:29,030 [foster.py] => Task 2, Epoch 8/34 => Loss 2.729, Loss_clf 0.667, Loss_fe 0.951, Loss_kd 0.854, Train_accy 42.54
2022-09-28 06:18:30,887 [foster.py] => Task 2, Epoch 9/34 => Loss 2.687, Loss_clf 0.676, Loss_fe 0.920, Loss_kd 0.839, Train_accy 39.68
2022-09-28 06:18:32,731 [foster.py] => Task 2, Epoch 10/34 => Loss 2.681, Loss_clf 0.650, Loss_fe 0.885, Loss_kd 0.881, Train_accy 39.68
2022-09-28 06:18:35,380 [foster.py] => Task 2, Epoch 11/34 => Loss 2.531, Loss_clf 0.584, Loss_fe 0.834, Loss_kd 0.857, Train_accy 41.29, Test_accy 51.18
2022-09-28 06:18:37,196 [foster.py] => Task 2, Epoch 12/34 => Loss 2.483, Loss_clf 0.581, Loss_fe 0.797, Loss_kd 0.850, Train_accy 41.29
2022-09-28 06:18:39,078 [foster.py] => Task 2, Epoch 13/34 => Loss 2.457, Loss_clf 0.573, Loss_fe 0.763, Loss_kd 0.862, Train_accy 42.29
2022-09-28 06:18:40,951 [foster.py] => Task 2, Epoch 14/34 => Loss 2.416, Loss_clf 0.563, Loss_fe 0.739, Loss_kd 0.856, Train_accy 43.03
2022-09-28 06:18:42,759 [foster.py] => Task 2, Epoch 15/34 => Loss 2.424, Loss_clf 0.560, Loss_fe 0.745, Loss_kd 0.861, Train_accy 38.43
2022-09-28 06:18:45,357 [foster.py] => Task 2, Epoch 16/34 => Loss 2.371, Loss_clf 0.554, Loss_fe 0.722, Loss_kd 0.843, Train_accy 40.42, Test_accy 50.51
2022-09-28 06:18:47,136 [foster.py] => Task 2, Epoch 17/34 => Loss 2.373, Loss_clf 0.553, Loss_fe 0.713, Loss_kd 0.852, Train_accy 43.28
2022-09-28 06:18:48,969 [foster.py] => Task 2, Epoch 18/34 => Loss 2.360, Loss_clf 0.560, Loss_fe 0.693, Loss_kd 0.852, Train_accy 43.16
2022-09-28 06:18:50,849 [foster.py] => Task 2, Epoch 19/34 => Loss 2.324, Loss_clf 0.524, Loss_fe 0.681, Loss_kd 0.861, Train_accy 40.80
2022-09-28 06:18:52,655 [foster.py] => Task 2, Epoch 20/34 => Loss 2.320, Loss_clf 0.532, Loss_fe 0.680, Loss_kd 0.853, Train_accy 41.04
2022-09-28 06:18:55,307 [foster.py] => Task 2, Epoch 21/34 => Loss 2.259, Loss_clf 0.503, Loss_fe 0.649, Loss_kd 0.851, Train_accy 46.27, Test_accy 51.85
2022-09-28 06:18:57,135 [foster.py] => Task 2, Epoch 22/34 => Loss 2.268, Loss_clf 0.496, Loss_fe 0.654, Loss_kd 0.861, Train_accy 45.52
2022-09-28 06:18:58,935 [foster.py] => Task 2, Epoch 23/34 => Loss 2.259, Loss_clf 0.504, Loss_fe 0.646, Loss_kd 0.853, Train_accy 48.13
2022-09-28 06:19:00,727 [foster.py] => Task 2, Epoch 24/34 => Loss 2.201, Loss_clf 0.481, Loss_fe 0.627, Loss_kd 0.841, Train_accy 46.39
2022-09-28 06:19:02,539 [foster.py] => Task 2, Epoch 25/34 => Loss 2.217, Loss_clf 0.478, Loss_fe 0.614, Loss_kd 0.866, Train_accy 45.77
2022-09-28 06:19:05,114 [foster.py] => Task 2, Epoch 26/34 => Loss 2.325, Loss_clf 0.540, Loss_fe 0.671, Loss_kd 0.857, Train_accy 44.15, Test_accy 51.52
2022-09-28 06:19:06,898 [foster.py] => Task 2, Epoch 27/34 => Loss 2.230, Loss_clf 0.500, Loss_fe 0.633, Loss_kd 0.844, Train_accy 41.79
2022-09-28 06:19:08,715 [foster.py] => Task 2, Epoch 28/34 => Loss 2.254, Loss_clf 0.511, Loss_fe 0.634, Loss_kd 0.853, Train_accy 44.15
2022-09-28 06:19:10,535 [foster.py] => Task 2, Epoch 29/34 => Loss 2.211, Loss_clf 0.477, Loss_fe 0.632, Loss_kd 0.848, Train_accy 44.65
2022-09-28 06:19:12,351 [foster.py] => Task 2, Epoch 30/34 => Loss 2.318, Loss_clf 0.542, Loss_fe 0.652, Loss_kd 0.864, Train_accy 45.02
2022-09-28 06:19:14,942 [foster.py] => Task 2, Epoch 31/34 => Loss 2.291, Loss_clf 0.513, Loss_fe 0.645, Loss_kd 0.871, Train_accy 46.14, Test_accy 51.52
2022-09-28 06:19:16,738 [foster.py] => Task 2, Epoch 32/34 => Loss 2.240, Loss_clf 0.487, Loss_fe 0.642, Loss_kd 0.855, Train_accy 45.52
2022-09-28 06:19:18,555 [foster.py] => Task 2, Epoch 33/34 => Loss 2.209, Loss_clf 0.473, Loss_fe 0.621, Loss_kd 0.857, Train_accy 45.40
2022-09-28 06:19:20,339 [foster.py] => Task 2, Epoch 34/34 => Loss 2.193, Loss_clf 0.466, Loss_fe 0.603, Loss_kd 0.864, Train_accy 44.90
2022-09-28 06:19:20,340 [foster.py] => do not weight align teacher!
2022-09-28 06:19:20,340 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 06:19:23,293 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.879,  Train_accy 17.29, Test_accy 42.76
2022-09-28 06:19:25,313 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.728,  Train_accy 17.54
2022-09-28 06:19:27,314 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.678,  Train_accy 17.91
2022-09-28 06:19:29,357 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.641,  Train_accy 17.66
2022-09-28 06:19:31,345 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.633,  Train_accy 17.79
2022-09-28 06:19:34,079 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.603,  Train_accy 18.28, Test_accy 42.42
2022-09-28 06:19:36,105 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.619,  Train_accy 17.91
2022-09-28 06:19:38,162 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.610,  Train_accy 17.79
2022-09-28 06:19:40,189 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.607,  Train_accy 18.03
2022-09-28 06:19:42,169 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.605,  Train_accy 18.78
2022-09-28 06:19:44,879 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.580,  Train_accy 18.28, Test_accy 44.11
2022-09-28 06:19:46,909 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.590,  Train_accy 19.03
2022-09-28 06:19:48,991 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.584,  Train_accy 19.65
2022-09-28 06:19:50,974 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.570,  Train_accy 19.28
2022-09-28 06:19:53,021 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.552,  Train_accy 19.65
2022-09-28 06:19:55,759 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.574,  Train_accy 19.03, Test_accy 43.77
2022-09-28 06:19:57,736 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.578,  Train_accy 19.53
2022-09-28 06:19:59,738 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.570,  Train_accy 19.40
2022-09-28 06:20:01,776 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.549,  Train_accy 19.40
2022-09-28 06:20:03,756 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.587,  Train_accy 18.78
2022-09-28 06:20:06,480 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.569,  Train_accy 19.03, Test_accy 44.11
2022-09-28 06:20:08,481 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.582,  Train_accy 18.41
2022-09-28 06:20:10,476 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.569,  Train_accy 20.02
2022-09-28 06:20:12,497 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.570,  Train_accy 18.91
2022-09-28 06:20:14,480 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.571,  Train_accy 19.15
2022-09-28 06:20:17,236 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.564,  Train_accy 18.66, Test_accy 43.10
2022-09-28 06:20:17,236 [foster.py] => do not weight align student!
2022-09-28 06:20:17,947 [foster.py] => darknet eval: 
2022-09-28 06:20:17,947 [foster.py] => CNN top1 curve: 43.1
2022-09-28 06:20:17,947 [foster.py] => CNN top5 curve: 97.31
2022-09-28 06:20:17,948 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 06:20:25,503 [foster.py] => Exemplar size: 260
2022-09-28 06:20:25,503 [trainer.py] => CNN: {'total': 51.85, 'old': 61.68, 'new': 26.51, 'base': 83.22, 'compound': 20.27}
2022-09-28 06:20:25,503 [trainer.py] => CNN top1 curve: [86.58, 65.89, 51.85]
2022-09-28 06:20:25,503 [trainer.py] => CNN base curve: [86.58, 82.55, 83.22]
2022-09-28 06:20:25,503 [trainer.py] => CNN old curve: [86.58, 82.55, 61.68]
2022-09-28 06:20:25,503 [trainer.py] => CNN new curve: [0, 27.69, 26.51]
2022-09-28 06:20:25,503 [trainer.py] => CNN compound curve: [0, 27.69, 20.27]
2022-09-28 06:20:25,503 [trainer.py] => NME: {'total': 62.29, 'old': 65.42, 'new': 54.22, 'base': 75.84, 'compound': 48.65}
2022-09-28 06:20:25,503 [trainer.py] => NME top1 curve: [89.26, 73.36, 62.29]
2022-09-28 06:20:25,503 [trainer.py] => NME base curve: [89.26, 82.55, 75.84]
2022-09-28 06:20:25,503 [trainer.py] => NME old curve: [89.26, 82.55, 65.42]
2022-09-28 06:20:25,503 [trainer.py] => NME new curve: [0, 52.31, 54.22]
2022-09-28 06:20:25,504 [trainer.py] => NME compound curve: [0, 52.31, 48.65]
2022-09-28 06:20:25,741 [foster.py] => Learning on 13-16
2022-09-28 06:20:25,742 [foster.py] => All params: 22384301
2022-09-28 06:20:25,742 [foster.py] => Trainable params: 11201120
2022-09-28 06:20:25,763 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 06:20:28,627 [foster.py] => Task 3, Epoch 1/34 => Loss 5.966, Loss_clf 2.219, Loss_fe 2.124, Loss_kd 1.318, Train_accy 40.47, Test_accy 43.14
2022-09-28 06:20:30,544 [foster.py] => Task 3, Epoch 2/34 => Loss 4.002, Loss_clf 0.880, Loss_fe 1.520, Loss_kd 1.302, Train_accy 48.93
2022-09-28 06:20:32,472 [foster.py] => Task 3, Epoch 3/34 => Loss 3.664, Loss_clf 0.766, Loss_fe 1.307, Loss_kd 1.292, Train_accy 47.24
2022-09-28 06:20:34,462 [foster.py] => Task 3, Epoch 4/34 => Loss 3.440, Loss_clf 0.695, Loss_fe 1.161, Loss_kd 1.287, Train_accy 44.53
2022-09-28 06:20:36,388 [foster.py] => Task 3, Epoch 5/34 => Loss 3.350, Loss_clf 0.678, Loss_fe 1.072, Loss_kd 1.299, Train_accy 46.45
2022-09-28 06:20:39,124 [foster.py] => Task 3, Epoch 6/34 => Loss 3.253, Loss_clf 0.662, Loss_fe 1.007, Loss_kd 1.287, Train_accy 49.15, Test_accy 47.34
2022-09-28 06:20:41,127 [foster.py] => Task 3, Epoch 7/34 => Loss 3.177, Loss_clf 0.644, Loss_fe 0.941, Loss_kd 1.294, Train_accy 49.27
2022-09-28 06:20:43,043 [foster.py] => Task 3, Epoch 8/34 => Loss 3.072, Loss_clf 0.591, Loss_fe 0.891, Loss_kd 1.292, Train_accy 49.72
2022-09-28 06:20:45,011 [foster.py] => Task 3, Epoch 9/34 => Loss 3.026, Loss_clf 0.586, Loss_fe 0.852, Loss_kd 1.290, Train_accy 47.46
2022-09-28 06:20:46,956 [foster.py] => Task 3, Epoch 10/34 => Loss 2.958, Loss_clf 0.562, Loss_fe 0.809, Loss_kd 1.289, Train_accy 52.31
2022-09-28 06:20:49,795 [foster.py] => Task 3, Epoch 11/34 => Loss 2.928, Loss_clf 0.560, Loss_fe 0.774, Loss_kd 1.295, Train_accy 49.72, Test_accy 47.62
2022-09-28 06:20:51,727 [foster.py] => Task 3, Epoch 12/34 => Loss 2.897, Loss_clf 0.564, Loss_fe 0.754, Loss_kd 1.283, Train_accy 50.17
2022-09-28 06:20:53,670 [foster.py] => Task 3, Epoch 13/34 => Loss 2.873, Loss_clf 0.553, Loss_fe 0.736, Loss_kd 1.287, Train_accy 52.99
2022-09-28 06:20:55,559 [foster.py] => Task 3, Epoch 14/34 => Loss 2.868, Loss_clf 0.550, Loss_fe 0.731, Loss_kd 1.290, Train_accy 50.51
2022-09-28 06:20:57,487 [foster.py] => Task 3, Epoch 15/34 => Loss 2.815, Loss_clf 0.534, Loss_fe 0.693, Loss_kd 1.291, Train_accy 51.18
2022-09-28 06:21:00,308 [foster.py] => Task 3, Epoch 16/34 => Loss 2.795, Loss_clf 0.518, Loss_fe 0.675, Loss_kd 1.302, Train_accy 51.07, Test_accy 48.46
2022-09-28 06:21:02,244 [foster.py] => Task 3, Epoch 17/34 => Loss 2.771, Loss_clf 0.518, Loss_fe 0.667, Loss_kd 1.289, Train_accy 54.45
2022-09-28 06:21:04,192 [foster.py] => Task 3, Epoch 18/34 => Loss 2.764, Loss_clf 0.508, Loss_fe 0.650, Loss_kd 1.305, Train_accy 50.96
2022-09-28 06:21:06,090 [foster.py] => Task 3, Epoch 19/34 => Loss 2.725, Loss_clf 0.495, Loss_fe 0.631, Loss_kd 1.299, Train_accy 55.13
2022-09-28 06:21:07,989 [foster.py] => Task 3, Epoch 20/34 => Loss 2.752, Loss_clf 0.520, Loss_fe 0.647, Loss_kd 1.288, Train_accy 51.41
2022-09-28 06:21:10,761 [foster.py] => Task 3, Epoch 21/34 => Loss 2.713, Loss_clf 0.495, Loss_fe 0.616, Loss_kd 1.302, Train_accy 51.75, Test_accy 48.74
2022-09-28 06:21:12,658 [foster.py] => Task 3, Epoch 22/34 => Loss 2.686, Loss_clf 0.475, Loss_fe 0.615, Loss_kd 1.297, Train_accy 54.00
2022-09-28 06:21:14,624 [foster.py] => Task 3, Epoch 23/34 => Loss 2.692, Loss_clf 0.485, Loss_fe 0.614, Loss_kd 1.295, Train_accy 54.90
2022-09-28 06:21:16,607 [foster.py] => Task 3, Epoch 24/34 => Loss 2.693, Loss_clf 0.488, Loss_fe 0.609, Loss_kd 1.296, Train_accy 54.45
2022-09-28 06:21:18,516 [foster.py] => Task 3, Epoch 25/34 => Loss 2.686, Loss_clf 0.489, Loss_fe 0.600, Loss_kd 1.299, Train_accy 55.02
2022-09-28 06:21:21,435 [foster.py] => Task 3, Epoch 26/34 => Loss 2.674, Loss_clf 0.477, Loss_fe 0.597, Loss_kd 1.300, Train_accy 55.24, Test_accy 48.46
2022-09-28 06:21:23,382 [foster.py] => Task 3, Epoch 27/34 => Loss 2.663, Loss_clf 0.470, Loss_fe 0.592, Loss_kd 1.301, Train_accy 54.57
2022-09-28 06:21:25,304 [foster.py] => Task 3, Epoch 28/34 => Loss 2.665, Loss_clf 0.480, Loss_fe 0.594, Loss_kd 1.293, Train_accy 54.57
2022-09-28 06:21:27,259 [foster.py] => Task 3, Epoch 29/34 => Loss 2.628, Loss_clf 0.467, Loss_fe 0.576, Loss_kd 1.288, Train_accy 54.11
2022-09-28 06:21:29,178 [foster.py] => Task 3, Epoch 30/34 => Loss 2.633, Loss_clf 0.465, Loss_fe 0.577, Loss_kd 1.293, Train_accy 54.11
2022-09-28 06:21:32,013 [foster.py] => Task 3, Epoch 31/34 => Loss 2.632, Loss_clf 0.457, Loss_fe 0.582, Loss_kd 1.295, Train_accy 54.57, Test_accy 48.46
2022-09-28 06:21:33,985 [foster.py] => Task 3, Epoch 32/34 => Loss 2.624, Loss_clf 0.453, Loss_fe 0.571, Loss_kd 1.300, Train_accy 54.68
2022-09-28 06:21:35,934 [foster.py] => Task 3, Epoch 33/34 => Loss 2.631, Loss_clf 0.462, Loss_fe 0.566, Loss_kd 1.302, Train_accy 54.90
2022-09-28 06:21:37,856 [foster.py] => Task 3, Epoch 34/34 => Loss 2.640, Loss_clf 0.461, Loss_fe 0.582, Loss_kd 1.298, Train_accy 55.92
2022-09-28 06:21:37,856 [foster.py] => do not weight align teacher!
2022-09-28 06:21:37,857 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 06:21:40,997 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.141,  Train_accy 16.46, Test_accy 36.41
2022-09-28 06:21:43,126 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.047,  Train_accy 16.80
2022-09-28 06:21:45,348 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.014,  Train_accy 17.81
2022-09-28 06:21:47,534 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 1.994,  Train_accy 17.93
2022-09-28 06:21:49,659 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.963,  Train_accy 17.81
2022-09-28 06:21:52,662 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.965,  Train_accy 17.59, Test_accy 36.69
2022-09-28 06:21:54,816 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.959,  Train_accy 18.15
2022-09-28 06:21:56,958 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.951,  Train_accy 17.25
2022-09-28 06:21:59,131 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.953,  Train_accy 18.04
2022-09-28 06:22:01,295 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.938,  Train_accy 18.04
2022-09-28 06:22:04,176 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.942,  Train_accy 18.83, Test_accy 36.41
2022-09-28 06:22:06,379 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.930,  Train_accy 18.15
2022-09-28 06:22:08,536 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.936,  Train_accy 18.38
2022-09-28 06:22:10,753 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.915,  Train_accy 19.28
2022-09-28 06:22:12,945 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.913,  Train_accy 18.71
2022-09-28 06:22:15,940 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.921,  Train_accy 18.94, Test_accy 37.25
2022-09-28 06:22:18,092 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.929,  Train_accy 19.39
2022-09-28 06:22:20,233 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.916,  Train_accy 19.05
2022-09-28 06:22:22,396 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.908,  Train_accy 20.41
2022-09-28 06:22:24,590 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.909,  Train_accy 19.73
2022-09-28 06:22:27,514 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.917,  Train_accy 20.29, Test_accy 37.25
2022-09-28 06:22:29,663 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.911,  Train_accy 18.04
2022-09-28 06:22:31,816 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.919,  Train_accy 18.38
2022-09-28 06:22:33,938 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.914,  Train_accy 20.52
2022-09-28 06:22:36,121 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.910,  Train_accy 19.39
2022-09-28 06:22:39,037 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.904,  Train_accy 19.28, Test_accy 37.25
2022-09-28 06:22:39,037 [foster.py] => do not weight align student!
2022-09-28 06:22:39,829 [foster.py] => darknet eval: 
2022-09-28 06:22:39,829 [foster.py] => CNN top1 curve: 37.25
2022-09-28 06:22:39,829 [foster.py] => CNN top5 curve: 94.4
2022-09-28 06:22:39,829 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 06:22:48,352 [foster.py] => Exemplar size: 320
2022-09-28 06:22:48,352 [trainer.py] => CNN: {'total': 48.74, 'old': 47.81, 'new': 53.33, 'base': 73.15, 'compound': 31.25}
2022-09-28 06:22:48,352 [trainer.py] => CNN top1 curve: [86.58, 65.89, 51.85, 48.74]
2022-09-28 06:22:48,352 [trainer.py] => CNN base curve: [86.58, 82.55, 83.22, 73.15]
2022-09-28 06:22:48,352 [trainer.py] => CNN old curve: [86.58, 82.55, 61.68, 47.81]
2022-09-28 06:22:48,352 [trainer.py] => CNN new curve: [0, 27.69, 26.51, 53.33]
2022-09-28 06:22:48,352 [trainer.py] => CNN compound curve: [0, 27.69, 20.27, 31.25]
2022-09-28 06:22:48,352 [trainer.py] => NME: {'total': 59.66, 'old': 58.59, 'new': 65.0, 'base': 72.48, 'compound': 50.48}
2022-09-28 06:22:48,352 [trainer.py] => NME top1 curve: [89.26, 73.36, 62.29, 59.66]
2022-09-28 06:22:48,352 [trainer.py] => NME base curve: [89.26, 82.55, 75.84, 72.48]
2022-09-28 06:22:48,352 [trainer.py] => NME old curve: [89.26, 82.55, 65.42, 58.59]
2022-09-28 06:22:48,352 [trainer.py] => NME new curve: [0, 52.31, 54.22, 65.0]
2022-09-28 06:22:48,352 [trainer.py] => NME compound curve: [0, 52.31, 48.65, 50.48]
2022-09-28 06:22:48,584 [foster.py] => Learning on 16-19
2022-09-28 06:22:48,585 [foster.py] => All params: 22390454
2022-09-28 06:22:48,585 [foster.py] => Trainable params: 11205734
2022-09-28 06:22:48,605 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 06:22:51,553 [foster.py] => Task 4, Epoch 1/34 => Loss 6.237, Loss_clf 1.703, Loss_fe 2.494, Loss_kd 1.718, Train_accy 41.41, Test_accy 41.12
2022-09-28 06:22:53,538 [foster.py] => Task 4, Epoch 2/34 => Loss 4.734, Loss_clf 0.939, Loss_fe 1.752, Loss_kd 1.720, Train_accy 47.17
2022-09-28 06:22:55,571 [foster.py] => Task 4, Epoch 3/34 => Loss 4.443, Loss_clf 0.864, Loss_fe 1.529, Loss_kd 1.726, Train_accy 52.51
2022-09-28 06:22:57,598 [foster.py] => Task 4, Epoch 4/34 => Loss 4.222, Loss_clf 0.811, Loss_fe 1.357, Loss_kd 1.730, Train_accy 54.11
2022-09-28 06:22:59,639 [foster.py] => Task 4, Epoch 5/34 => Loss 4.119, Loss_clf 0.787, Loss_fe 1.267, Loss_kd 1.739, Train_accy 53.79
2022-09-28 06:23:02,559 [foster.py] => Task 4, Epoch 6/34 => Loss 4.028, Loss_clf 0.769, Loss_fe 1.211, Loss_kd 1.724, Train_accy 55.39, Test_accy 48.36
2022-09-28 06:23:04,538 [foster.py] => Task 4, Epoch 7/34 => Loss 3.907, Loss_clf 0.732, Loss_fe 1.120, Loss_kd 1.730, Train_accy 54.96
2022-09-28 06:23:06,528 [foster.py] => Task 4, Epoch 8/34 => Loss 3.856, Loss_clf 0.722, Loss_fe 1.078, Loss_kd 1.731, Train_accy 54.86
2022-09-28 06:23:08,567 [foster.py] => Task 4, Epoch 9/34 => Loss 3.773, Loss_clf 0.710, Loss_fe 1.007, Loss_kd 1.731, Train_accy 55.82
2022-09-28 06:23:10,589 [foster.py] => Task 4, Epoch 10/34 => Loss 3.718, Loss_clf 0.691, Loss_fe 0.979, Loss_kd 1.725, Train_accy 56.78
2022-09-28 06:23:13,498 [foster.py] => Task 4, Epoch 11/34 => Loss 3.691, Loss_clf 0.688, Loss_fe 0.944, Loss_kd 1.734, Train_accy 57.74, Test_accy 49.77
2022-09-28 06:23:15,507 [foster.py] => Task 4, Epoch 12/34 => Loss 3.584, Loss_clf 0.640, Loss_fe 0.887, Loss_kd 1.732, Train_accy 56.88
2022-09-28 06:23:17,533 [foster.py] => Task 4, Epoch 13/34 => Loss 3.549, Loss_clf 0.634, Loss_fe 0.864, Loss_kd 1.728, Train_accy 58.48
2022-09-28 06:23:19,564 [foster.py] => Task 4, Epoch 14/34 => Loss 3.558, Loss_clf 0.654, Loss_fe 0.860, Loss_kd 1.721, Train_accy 59.45
2022-09-28 06:23:21,597 [foster.py] => Task 4, Epoch 15/34 => Loss 3.492, Loss_clf 0.618, Loss_fe 0.817, Loss_kd 1.733, Train_accy 58.91
2022-09-28 06:23:24,491 [foster.py] => Task 4, Epoch 16/34 => Loss 3.495, Loss_clf 0.624, Loss_fe 0.815, Loss_kd 1.732, Train_accy 60.30, Test_accy 48.83
2022-09-28 06:23:26,513 [foster.py] => Task 4, Epoch 17/34 => Loss 3.455, Loss_clf 0.607, Loss_fe 0.788, Loss_kd 1.734, Train_accy 59.87
2022-09-28 06:23:28,509 [foster.py] => Task 4, Epoch 18/34 => Loss 3.415, Loss_clf 0.583, Loss_fe 0.767, Loss_kd 1.739, Train_accy 61.26
2022-09-28 06:23:30,500 [foster.py] => Task 4, Epoch 19/34 => Loss 3.431, Loss_clf 0.600, Loss_fe 0.777, Loss_kd 1.729, Train_accy 59.77
2022-09-28 06:23:32,523 [foster.py] => Task 4, Epoch 20/34 => Loss 3.394, Loss_clf 0.585, Loss_fe 0.742, Loss_kd 1.740, Train_accy 61.69
2022-09-28 06:23:35,442 [foster.py] => Task 4, Epoch 21/34 => Loss 3.382, Loss_clf 0.584, Loss_fe 0.744, Loss_kd 1.730, Train_accy 59.66, Test_accy 50.70
2022-09-28 06:23:37,427 [foster.py] => Task 4, Epoch 22/34 => Loss 3.357, Loss_clf 0.570, Loss_fe 0.726, Loss_kd 1.735, Train_accy 62.97
2022-09-28 06:23:39,466 [foster.py] => Task 4, Epoch 23/34 => Loss 3.368, Loss_clf 0.581, Loss_fe 0.729, Loss_kd 1.733, Train_accy 58.70
2022-09-28 06:23:41,484 [foster.py] => Task 4, Epoch 24/34 => Loss 3.393, Loss_clf 0.596, Loss_fe 0.748, Loss_kd 1.726, Train_accy 61.05
2022-09-28 06:23:43,474 [foster.py] => Task 4, Epoch 25/34 => Loss 3.373, Loss_clf 0.572, Loss_fe 0.730, Loss_kd 1.744, Train_accy 60.62
2022-09-28 06:23:46,409 [foster.py] => Task 4, Epoch 26/34 => Loss 3.372, Loss_clf 0.581, Loss_fe 0.723, Loss_kd 1.741, Train_accy 61.90, Test_accy 49.77
2022-09-28 06:23:48,420 [foster.py] => Task 4, Epoch 27/34 => Loss 3.328, Loss_clf 0.571, Loss_fe 0.701, Loss_kd 1.731, Train_accy 60.30
2022-09-28 06:23:50,441 [foster.py] => Task 4, Epoch 28/34 => Loss 3.352, Loss_clf 0.566, Loss_fe 0.722, Loss_kd 1.739, Train_accy 61.37
2022-09-28 06:23:52,481 [foster.py] => Task 4, Epoch 29/34 => Loss 3.314, Loss_clf 0.547, Loss_fe 0.692, Loss_kd 1.748, Train_accy 61.79
2022-09-28 06:23:54,476 [foster.py] => Task 4, Epoch 30/34 => Loss 3.324, Loss_clf 0.555, Loss_fe 0.694, Loss_kd 1.748, Train_accy 60.51
2022-09-28 06:23:57,424 [foster.py] => Task 4, Epoch 31/34 => Loss 3.324, Loss_clf 0.564, Loss_fe 0.699, Loss_kd 1.735, Train_accy 64.25, Test_accy 50.00
2022-09-28 06:23:59,411 [foster.py] => Task 4, Epoch 32/34 => Loss 3.318, Loss_clf 0.559, Loss_fe 0.698, Loss_kd 1.735, Train_accy 60.62
2022-09-28 06:24:01,433 [foster.py] => Task 4, Epoch 33/34 => Loss 3.319, Loss_clf 0.562, Loss_fe 0.693, Loss_kd 1.738, Train_accy 60.73
2022-09-28 06:24:03,448 [foster.py] => Task 4, Epoch 34/34 => Loss 3.293, Loss_clf 0.543, Loss_fe 0.680, Loss_kd 1.743, Train_accy 62.11
2022-09-28 06:24:03,448 [foster.py] => do not weight align teacher!
2022-09-28 06:24:03,448 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 06:24:06,788 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.443,  Train_accy 16.01, Test_accy 32.01
2022-09-28 06:24:09,018 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.365,  Train_accy 16.86
2022-09-28 06:24:11,242 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.318,  Train_accy 17.29
2022-09-28 06:24:13,502 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.300,  Train_accy 17.61
2022-09-28 06:24:15,768 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.290,  Train_accy 17.93
2022-09-28 06:24:18,810 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.281,  Train_accy 17.82, Test_accy 35.28
2022-09-28 06:24:21,129 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.275,  Train_accy 18.46
2022-09-28 06:24:23,384 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.254,  Train_accy 18.36
2022-09-28 06:24:25,651 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.253,  Train_accy 18.46
2022-09-28 06:24:27,867 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.266,  Train_accy 19.21
2022-09-28 06:24:30,948 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.251,  Train_accy 20.49, Test_accy 36.45
2022-09-28 06:24:33,192 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.259,  Train_accy 20.38
2022-09-28 06:24:35,445 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.240,  Train_accy 19.96
2022-09-28 06:24:37,716 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.248,  Train_accy 20.06
2022-09-28 06:24:39,997 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.248,  Train_accy 20.38
2022-09-28 06:24:43,063 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.247,  Train_accy 19.32, Test_accy 38.32
2022-09-28 06:24:45,295 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.239,  Train_accy 20.38
2022-09-28 06:24:47,533 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.250,  Train_accy 19.96
2022-09-28 06:24:49,782 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.245,  Train_accy 19.53
2022-09-28 06:24:52,003 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.241,  Train_accy 20.06
2022-09-28 06:24:55,043 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.249,  Train_accy 22.31, Test_accy 38.08
2022-09-28 06:24:57,305 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.250,  Train_accy 21.99
2022-09-28 06:24:59,536 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.235,  Train_accy 20.28
2022-09-28 06:25:01,763 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.249,  Train_accy 20.49
2022-09-28 06:25:04,002 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.240,  Train_accy 20.70
2022-09-28 06:25:07,037 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.237,  Train_accy 20.60, Test_accy 38.79
2022-09-28 06:25:07,037 [foster.py] => do not weight align student!
2022-09-28 06:25:07,841 [foster.py] => darknet eval: 
2022-09-28 06:25:07,841 [foster.py] => CNN top1 curve: 38.79
2022-09-28 06:25:07,841 [foster.py] => CNN top5 curve: 89.95
2022-09-28 06:25:07,841 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 06:25:17,400 [foster.py] => Exemplar size: 380
2022-09-28 06:25:17,400 [trainer.py] => CNN: {'total': 50.23, 'old': 50.7, 'new': 47.89, 'base': 72.48, 'compound': 38.35}
2022-09-28 06:25:17,400 [trainer.py] => CNN top1 curve: [86.58, 65.89, 51.85, 48.74, 50.23]
2022-09-28 06:25:17,400 [trainer.py] => CNN base curve: [86.58, 82.55, 83.22, 73.15, 72.48]
2022-09-28 06:25:17,400 [trainer.py] => CNN old curve: [86.58, 82.55, 61.68, 47.81, 50.7]
2022-09-28 06:25:17,400 [trainer.py] => CNN new curve: [0, 27.69, 26.51, 53.33, 47.89]
2022-09-28 06:25:17,400 [trainer.py] => CNN compound curve: [0, 27.69, 20.27, 31.25, 38.35]
2022-09-28 06:25:17,400 [trainer.py] => NME: {'total': 57.71, 'old': 55.46, 'new': 69.01, 'base': 68.46, 'compound': 51.97}
2022-09-28 06:25:17,400 [trainer.py] => NME top1 curve: [89.26, 73.36, 62.29, 59.66, 57.71]
2022-09-28 06:25:17,400 [trainer.py] => NME base curve: [89.26, 82.55, 75.84, 72.48, 68.46]
2022-09-28 06:25:17,400 [trainer.py] => NME old curve: [89.26, 82.55, 65.42, 58.59, 55.46]
2022-09-28 06:25:17,400 [trainer.py] => NME new curve: [0, 52.31, 54.22, 65.0, 69.01]
2022-09-28 06:25:17,400 [trainer.py] => NME compound curve: [0, 52.31, 48.65, 50.48, 51.97]
2022-09-28 06:25:17,632 [foster.py] => Learning on 19-22
2022-09-28 06:25:17,633 [foster.py] => All params: 22396607
2022-09-28 06:25:17,633 [foster.py] => Trainable params: 11210348
2022-09-28 06:25:17,653 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 06:25:20,704 [foster.py] => Task 5, Epoch 1/34 => Loss 6.842, Loss_clf 1.982, Loss_fe 2.587, Loss_kd 1.963, Train_accy 36.86, Test_accy 39.48
2022-09-28 06:25:22,821 [foster.py] => Task 5, Epoch 2/34 => Loss 5.385, Loss_clf 1.170, Loss_fe 1.934, Loss_kd 1.970, Train_accy 38.37
2022-09-28 06:25:24,933 [foster.py] => Task 5, Epoch 3/34 => Loss 5.076, Loss_clf 1.085, Loss_fe 1.737, Loss_kd 1.946, Train_accy 40.58
2022-09-28 06:25:27,024 [foster.py] => Task 5, Epoch 4/34 => Loss 4.964, Loss_clf 1.039, Loss_fe 1.649, Loss_kd 1.966, Train_accy 43.30
2022-09-28 06:25:29,111 [foster.py] => Task 5, Epoch 5/34 => Loss 4.799, Loss_clf 0.993, Loss_fe 1.520, Loss_kd 1.975, Train_accy 40.99
2022-09-28 06:25:32,195 [foster.py] => Task 5, Epoch 6/34 => Loss 4.778, Loss_clf 1.041, Loss_fe 1.452, Loss_kd 1.974, Train_accy 41.39, Test_accy 44.84
2022-09-28 06:25:34,270 [foster.py] => Task 5, Epoch 7/34 => Loss 4.644, Loss_clf 1.002, Loss_fe 1.377, Loss_kd 1.956, Train_accy 43.91
2022-09-28 06:25:36,345 [foster.py] => Task 5, Epoch 8/34 => Loss 4.539, Loss_clf 0.968, Loss_fe 1.317, Loss_kd 1.947, Train_accy 44.31
2022-09-28 06:25:38,421 [foster.py] => Task 5, Epoch 9/34 => Loss 4.577, Loss_clf 0.988, Loss_fe 1.304, Loss_kd 1.974, Train_accy 48.04
2022-09-28 06:25:40,544 [foster.py] => Task 5, Epoch 10/34 => Loss 4.436, Loss_clf 0.919, Loss_fe 1.229, Loss_kd 1.976, Train_accy 42.60
2022-09-28 06:25:43,607 [foster.py] => Task 5, Epoch 11/34 => Loss 4.347, Loss_clf 0.918, Loss_fe 1.185, Loss_kd 1.938, Train_accy 44.91, Test_accy 45.83
2022-09-28 06:25:45,676 [foster.py] => Task 5, Epoch 12/34 => Loss 4.376, Loss_clf 0.913, Loss_fe 1.175, Loss_kd 1.976, Train_accy 44.81
2022-09-28 06:25:47,795 [foster.py] => Task 5, Epoch 13/34 => Loss 4.286, Loss_clf 0.882, Loss_fe 1.135, Loss_kd 1.960, Train_accy 45.32
2022-09-28 06:25:49,873 [foster.py] => Task 5, Epoch 14/34 => Loss 4.220, Loss_clf 0.853, Loss_fe 1.095, Loss_kd 1.961, Train_accy 45.12
2022-09-28 06:25:51,987 [foster.py] => Task 5, Epoch 15/34 => Loss 4.223, Loss_clf 0.811, Loss_fe 1.157, Loss_kd 1.947, Train_accy 48.34
2022-09-28 06:25:55,093 [foster.py] => Task 5, Epoch 16/34 => Loss 4.187, Loss_clf 0.826, Loss_fe 1.070, Loss_kd 1.978, Train_accy 45.32, Test_accy 46.43
2022-09-28 06:25:57,215 [foster.py] => Task 5, Epoch 17/34 => Loss 4.138, Loss_clf 0.813, Loss_fe 1.035, Loss_kd 1.977, Train_accy 45.72
2022-09-28 06:25:59,337 [foster.py] => Task 5, Epoch 18/34 => Loss 4.141, Loss_clf 0.852, Loss_fe 1.042, Loss_kd 1.940, Train_accy 44.21
2022-09-28 06:26:01,416 [foster.py] => Task 5, Epoch 19/34 => Loss 4.132, Loss_clf 0.819, Loss_fe 1.021, Loss_kd 1.980, Train_accy 49.85
2022-09-28 06:26:03,531 [foster.py] => Task 5, Epoch 20/34 => Loss 4.060, Loss_clf 0.786, Loss_fe 0.998, Loss_kd 1.966, Train_accy 46.83
2022-09-28 06:26:06,627 [foster.py] => Task 5, Epoch 21/34 => Loss 4.049, Loss_clf 0.771, Loss_fe 0.988, Loss_kd 1.978, Train_accy 46.22, Test_accy 46.63
2022-09-28 06:26:08,717 [foster.py] => Task 5, Epoch 22/34 => Loss 4.074, Loss_clf 0.778, Loss_fe 1.007, Loss_kd 1.976, Train_accy 44.71
2022-09-28 06:26:10,819 [foster.py] => Task 5, Epoch 23/34 => Loss 4.166, Loss_clf 0.859, Loss_fe 1.019, Loss_kd 1.976, Train_accy 45.42
2022-09-28 06:26:12,921 [foster.py] => Task 5, Epoch 24/34 => Loss 4.039, Loss_clf 0.782, Loss_fe 0.964, Loss_kd 1.981, Train_accy 45.32
2022-09-28 06:26:15,010 [foster.py] => Task 5, Epoch 25/34 => Loss 4.149, Loss_clf 0.829, Loss_fe 1.038, Loss_kd 1.971, Train_accy 46.93
2022-09-28 06:26:18,147 [foster.py] => Task 5, Epoch 26/34 => Loss 3.997, Loss_clf 0.748, Loss_fe 0.958, Loss_kd 1.979, Train_accy 45.72, Test_accy 46.83
2022-09-28 06:26:20,239 [foster.py] => Task 5, Epoch 27/34 => Loss 4.021, Loss_clf 0.774, Loss_fe 0.966, Loss_kd 1.970, Train_accy 45.82
2022-09-28 06:26:22,311 [foster.py] => Task 5, Epoch 28/34 => Loss 3.997, Loss_clf 0.760, Loss_fe 0.962, Loss_kd 1.965, Train_accy 48.54
2022-09-28 06:26:24,418 [foster.py] => Task 5, Epoch 29/34 => Loss 3.995, Loss_clf 0.752, Loss_fe 0.953, Loss_kd 1.977, Train_accy 48.44
2022-09-28 06:26:26,527 [foster.py] => Task 5, Epoch 30/34 => Loss 4.013, Loss_clf 0.760, Loss_fe 0.960, Loss_kd 1.980, Train_accy 48.44
2022-09-28 06:26:29,592 [foster.py] => Task 5, Epoch 31/34 => Loss 4.024, Loss_clf 0.750, Loss_fe 1.017, Loss_kd 1.949, Train_accy 46.53, Test_accy 47.42
2022-09-28 06:26:31,707 [foster.py] => Task 5, Epoch 32/34 => Loss 3.984, Loss_clf 0.747, Loss_fe 0.951, Loss_kd 1.975, Train_accy 48.14
2022-09-28 06:26:33,802 [foster.py] => Task 5, Epoch 33/34 => Loss 3.970, Loss_clf 0.752, Loss_fe 0.940, Loss_kd 1.967, Train_accy 48.14
2022-09-28 06:26:35,869 [foster.py] => Task 5, Epoch 34/34 => Loss 4.018, Loss_clf 0.798, Loss_fe 0.966, Loss_kd 1.947, Train_accy 46.22
2022-09-28 06:26:35,870 [foster.py] => do not weight align teacher!
2022-09-28 06:26:35,871 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 06:26:39,558 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.524,  Train_accy 18.73, Test_accy 32.94
2022-09-28 06:26:42,003 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.505,  Train_accy 19.13
2022-09-28 06:26:44,490 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.486,  Train_accy 18.93
2022-09-28 06:26:46,937 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.476,  Train_accy 19.44
2022-09-28 06:26:49,440 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.470,  Train_accy 19.84
2022-09-28 06:26:52,885 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.452,  Train_accy 19.94, Test_accy 36.51
2022-09-28 06:26:55,361 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.455,  Train_accy 20.64
2022-09-28 06:26:57,838 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.509,  Train_accy 19.13
2022-09-28 06:27:00,302 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.449,  Train_accy 20.34
2022-09-28 06:27:02,766 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.441,  Train_accy 20.34
2022-09-28 06:27:06,206 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.441,  Train_accy 20.54, Test_accy 37.30
2022-09-28 06:27:08,692 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.443,  Train_accy 21.05
2022-09-28 06:27:11,155 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.452,  Train_accy 20.64
2022-09-28 06:27:13,670 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.437,  Train_accy 19.23
2022-09-28 06:27:16,139 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.440,  Train_accy 20.14
2022-09-28 06:27:19,604 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.443,  Train_accy 20.75, Test_accy 37.10
2022-09-28 06:27:22,047 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.437,  Train_accy 21.75
2022-09-28 06:27:24,534 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.433,  Train_accy 20.95
2022-09-28 06:27:27,034 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.434,  Train_accy 20.75
2022-09-28 06:27:29,547 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.433,  Train_accy 20.85
2022-09-28 06:27:32,967 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.437,  Train_accy 20.95, Test_accy 38.29
2022-09-28 06:27:35,444 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.430,  Train_accy 20.75
2022-09-28 06:27:37,943 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.431,  Train_accy 21.15
2022-09-28 06:27:40,421 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.429,  Train_accy 20.04
2022-09-28 06:27:42,912 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.442,  Train_accy 21.25
2022-09-28 06:27:46,361 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.440,  Train_accy 21.15, Test_accy 38.49
2022-09-28 06:27:46,361 [foster.py] => do not weight align student!
2022-09-28 06:27:47,308 [foster.py] => darknet eval: 
2022-09-28 06:27:47,308 [foster.py] => CNN top1 curve: 38.49
2022-09-28 06:27:47,308 [foster.py] => CNN top5 curve: 81.75
2022-09-28 06:27:47,309 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 06:27:59,879 [foster.py] => Exemplar size: 440
2022-09-28 06:27:59,879 [trainer.py] => CNN: {'total': 47.42, 'old': 49.53, 'new': 35.53, 'base': 69.13, 'compound': 38.31}
2022-09-28 06:27:59,879 [trainer.py] => CNN top1 curve: [86.58, 65.89, 51.85, 48.74, 50.23, 47.42]
2022-09-28 06:27:59,879 [trainer.py] => CNN base curve: [86.58, 82.55, 83.22, 73.15, 72.48, 69.13]
2022-09-28 06:27:59,879 [trainer.py] => CNN old curve: [86.58, 82.55, 61.68, 47.81, 50.7, 49.53]
2022-09-28 06:27:59,880 [trainer.py] => CNN new curve: [0, 27.69, 26.51, 53.33, 47.89, 35.53]
2022-09-28 06:27:59,880 [trainer.py] => CNN compound curve: [0, 27.69, 20.27, 31.25, 38.35, 38.31]
2022-09-28 06:27:59,880 [trainer.py] => NME: {'total': 53.77, 'old': 53.97, 'new': 52.63, 'base': 65.77, 'compound': 48.73}
2022-09-28 06:27:59,880 [trainer.py] => NME top1 curve: [89.26, 73.36, 62.29, 59.66, 57.71, 53.77]
2022-09-28 06:27:59,880 [trainer.py] => NME base curve: [89.26, 82.55, 75.84, 72.48, 68.46, 65.77]
2022-09-28 06:27:59,880 [trainer.py] => NME old curve: [89.26, 82.55, 65.42, 58.59, 55.46, 53.97]
2022-09-28 06:27:59,880 [trainer.py] => NME new curve: [0, 52.31, 54.22, 65.0, 69.01, 52.63]
2022-09-28 06:27:59,880 [trainer.py] => NME compound curve: [0, 52.31, 48.65, 50.48, 51.97, 48.73]
2022-09-28 06:27:59,881 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 06:27:59,881 [trainer.py] => prefix: cil
2022-09-28 06:27:59,881 [trainer.py] => dataset: CFEE
2022-09-28 06:27:59,881 [trainer.py] => memory_size: 2000
2022-09-28 06:27:59,881 [trainer.py] => memory_per_class: 20
2022-09-28 06:27:59,881 [trainer.py] => fixed_memory: True
2022-09-28 06:27:59,881 [trainer.py] => shuffle: True
2022-09-28 06:27:59,881 [trainer.py] => init_cls: 7
2022-09-28 06:27:59,881 [trainer.py] => increment: 3
2022-09-28 06:27:59,881 [trainer.py] => model_name: foster
2022-09-28 06:27:59,881 [trainer.py] => convnet_type: resnet18
2022-09-28 06:27:59,881 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 06:27:59,881 [trainer.py] => seed: 1993
2022-09-28 06:27:59,881 [trainer.py] => beta1: 0.96
2022-09-28 06:27:59,881 [trainer.py] => beta2: 0.97
2022-09-28 06:27:59,882 [trainer.py] => oofc: ft
2022-09-28 06:27:59,882 [trainer.py] => is_teacher_wa: False
2022-09-28 06:27:59,882 [trainer.py] => is_student_wa: False
2022-09-28 06:27:59,882 [trainer.py] => lambda_okd: 1
2022-09-28 06:27:59,882 [trainer.py] => wa_value: 1
2022-09-28 06:27:59,882 [trainer.py] => init_epochs: 40
2022-09-28 06:27:59,882 [trainer.py] => init_lr: 0.01
2022-09-28 06:27:59,882 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 06:27:59,882 [trainer.py] => boosting_epochs: 34
2022-09-28 06:27:59,882 [trainer.py] => compression_epochs: 26
2022-09-28 06:27:59,882 [trainer.py] => lr: 0.001
2022-09-28 06:27:59,882 [trainer.py] => batch_size: 32
2022-09-28 06:27:59,882 [trainer.py] => weight_decay: 0.0005
2022-09-28 06:27:59,882 [trainer.py] => num_workers: 8
2022-09-28 06:27:59,882 [trainer.py] => T: 2
2022-09-28 06:27:59,882 [trainer.py] => nb_runs: 3
2022-09-28 06:27:59,882 [trainer.py] => fold: 10
2022-09-28 06:27:59,882 [data.py] => ========== Fold:8 ==========
2022-09-28 06:27:59,937 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 12, 10, 19, 21, 17, 18, 8, 7, 9, 14, 15, 13, 11, 16]
2022-09-28 06:28:00,152 [foster.py] => Learning on 0-7
2022-09-28 06:28:00,152 [foster.py] => All params: 11183694
2022-09-28 06:28:00,152 [foster.py] => Trainable params: 11183694
2022-09-28 06:28:02,537 [foster.py] => Task 0, Epoch 1/40 => Loss 1.307, Train_accy 53.42
2022-09-28 06:28:05,487 [foster.py] => Task 0, Epoch 2/40 => Loss 0.536, Train_accy 81.02, Test_accy 83.54
2022-09-28 06:28:08,483 [foster.py] => Task 0, Epoch 3/40 => Loss 0.352, Train_accy 88.06, Test_accy 86.71
2022-09-28 06:28:11,454 [foster.py] => Task 0, Epoch 4/40 => Loss 0.303, Train_accy 89.16, Test_accy 86.08
2022-09-28 06:28:14,468 [foster.py] => Task 0, Epoch 5/40 => Loss 0.239, Train_accy 91.30, Test_accy 87.34
2022-09-28 06:28:16,876 [foster.py] => Task 0, Epoch 6/40 => Loss 0.194, Train_accy 92.41
2022-09-28 06:28:19,936 [foster.py] => Task 0, Epoch 7/40 => Loss 0.175, Train_accy 94.48, Test_accy 85.44
2022-09-28 06:28:22,940 [foster.py] => Task 0, Epoch 8/40 => Loss 0.152, Train_accy 95.65, Test_accy 88.61
2022-09-28 06:28:25,900 [foster.py] => Task 0, Epoch 9/40 => Loss 0.121, Train_accy 96.41, Test_accy 87.97
2022-09-28 06:28:28,903 [foster.py] => Task 0, Epoch 10/40 => Loss 0.116, Train_accy 96.14, Test_accy 86.71
2022-09-28 06:28:31,276 [foster.py] => Task 0, Epoch 11/40 => Loss 0.080, Train_accy 97.93
2022-09-28 06:28:34,242 [foster.py] => Task 0, Epoch 12/40 => Loss 0.082, Train_accy 97.38, Test_accy 86.08
2022-09-28 06:28:37,241 [foster.py] => Task 0, Epoch 13/40 => Loss 0.072, Train_accy 98.07, Test_accy 86.08
2022-09-28 06:28:40,225 [foster.py] => Task 0, Epoch 14/40 => Loss 0.058, Train_accy 98.34, Test_accy 87.34
2022-09-28 06:28:43,224 [foster.py] => Task 0, Epoch 15/40 => Loss 0.073, Train_accy 97.86, Test_accy 87.97
2022-09-28 06:28:45,599 [foster.py] => Task 0, Epoch 16/40 => Loss 0.058, Train_accy 98.27
2022-09-28 06:28:48,585 [foster.py] => Task 0, Epoch 17/40 => Loss 0.053, Train_accy 98.27, Test_accy 89.24
2022-09-28 06:28:51,615 [foster.py] => Task 0, Epoch 18/40 => Loss 0.044, Train_accy 98.48, Test_accy 87.34
2022-09-28 06:28:54,621 [foster.py] => Task 0, Epoch 19/40 => Loss 0.036, Train_accy 98.90, Test_accy 86.71
2022-09-28 06:28:57,588 [foster.py] => Task 0, Epoch 20/40 => Loss 0.034, Train_accy 98.96, Test_accy 87.97
2022-09-28 06:28:59,988 [foster.py] => Task 0, Epoch 21/40 => Loss 0.025, Train_accy 99.72
2022-09-28 06:29:02,981 [foster.py] => Task 0, Epoch 22/40 => Loss 0.023, Train_accy 99.79, Test_accy 88.61
2022-09-28 06:29:05,985 [foster.py] => Task 0, Epoch 23/40 => Loss 0.024, Train_accy 99.59, Test_accy 88.61
2022-09-28 06:29:08,963 [foster.py] => Task 0, Epoch 24/40 => Loss 0.017, Train_accy 99.86, Test_accy 88.61
2022-09-28 06:29:11,971 [foster.py] => Task 0, Epoch 25/40 => Loss 0.023, Train_accy 99.52, Test_accy 87.34
2022-09-28 06:29:14,374 [foster.py] => Task 0, Epoch 26/40 => Loss 0.018, Train_accy 99.65
2022-09-28 06:29:17,372 [foster.py] => Task 0, Epoch 27/40 => Loss 0.018, Train_accy 99.72, Test_accy 87.97
2022-09-28 06:29:20,380 [foster.py] => Task 0, Epoch 28/40 => Loss 0.016, Train_accy 100.00, Test_accy 87.97
2022-09-28 06:29:23,344 [foster.py] => Task 0, Epoch 29/40 => Loss 0.021, Train_accy 99.38, Test_accy 88.61
2022-09-28 06:29:26,358 [foster.py] => Task 0, Epoch 30/40 => Loss 0.016, Train_accy 99.79, Test_accy 87.97
2022-09-28 06:29:28,785 [foster.py] => Task 0, Epoch 31/40 => Loss 0.017, Train_accy 99.79
2022-09-28 06:29:31,751 [foster.py] => Task 0, Epoch 32/40 => Loss 0.018, Train_accy 99.65, Test_accy 87.34
2022-09-28 06:29:34,729 [foster.py] => Task 0, Epoch 33/40 => Loss 0.011, Train_accy 99.93, Test_accy 88.61
2022-09-28 06:29:37,772 [foster.py] => Task 0, Epoch 34/40 => Loss 0.016, Train_accy 99.86, Test_accy 89.24
2022-09-28 06:29:40,741 [foster.py] => Task 0, Epoch 35/40 => Loss 0.014, Train_accy 99.86, Test_accy 87.97
2022-09-28 06:29:43,133 [foster.py] => Task 0, Epoch 36/40 => Loss 0.013, Train_accy 99.86
2022-09-28 06:29:46,147 [foster.py] => Task 0, Epoch 37/40 => Loss 0.013, Train_accy 99.86, Test_accy 88.61
2022-09-28 06:29:49,157 [foster.py] => Task 0, Epoch 38/40 => Loss 0.021, Train_accy 99.72, Test_accy 87.97
2022-09-28 06:29:52,158 [foster.py] => Task 0, Epoch 39/40 => Loss 0.015, Train_accy 99.86, Test_accy 88.61
2022-09-28 06:29:55,253 [foster.py] => Task 0, Epoch 40/40 => Loss 0.014, Train_accy 99.93, Test_accy 88.61
2022-09-28 06:29:55,253 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 06:30:02,158 [foster.py] => Exemplar size: 140
2022-09-28 06:30:02,158 [trainer.py] => CNN: {'total': 88.61, 'old': 88.61, 'new': 0, 'base': 88.61, 'compound': 0}
2022-09-28 06:30:02,158 [trainer.py] => CNN top1 curve: [88.61]
2022-09-28 06:30:02,158 [trainer.py] => CNN base curve: [88.61]
2022-09-28 06:30:02,159 [trainer.py] => CNN old curve: [88.61]
2022-09-28 06:30:02,159 [trainer.py] => CNN new curve: [0]
2022-09-28 06:30:02,159 [trainer.py] => CNN compound curve: [0]
2022-09-28 06:30:02,159 [trainer.py] => NME: {'total': 87.97, 'old': 87.97, 'new': 0, 'base': 87.97, 'compound': 0}
2022-09-28 06:30:02,159 [trainer.py] => NME top1 curve: [87.97]
2022-09-28 06:30:02,159 [trainer.py] => NME base curve: [87.97]
2022-09-28 06:30:02,159 [trainer.py] => NME old curve: [87.97]
2022-09-28 06:30:02,159 [trainer.py] => NME new curve: [0]
2022-09-28 06:30:02,159 [trainer.py] => NME compound curve: [0]
2022-09-28 06:30:02,391 [foster.py] => Learning on 7-10
2022-09-28 06:30:02,392 [foster.py] => All params: 22371995
2022-09-28 06:30:02,392 [foster.py] => Trainable params: 11191892
2022-09-28 06:30:02,412 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 06:30:04,899 [foster.py] => Task 1, Epoch 1/34 => Loss 5.064, Loss_clf 2.561, Loss_fe 1.955, Loss_kd 0.383, Train_accy 35.59, Test_accy 55.71
2022-09-28 06:30:06,710 [foster.py] => Task 1, Epoch 2/34 => Loss 2.881, Loss_clf 0.976, Loss_fe 1.332, Loss_kd 0.401, Train_accy 59.06
2022-09-28 06:30:08,469 [foster.py] => Task 1, Epoch 3/34 => Loss 2.341, Loss_clf 0.679, Loss_fe 1.143, Loss_kd 0.363, Train_accy 37.68
2022-09-28 06:30:10,201 [foster.py] => Task 1, Epoch 4/34 => Loss 2.177, Loss_clf 0.630, Loss_fe 1.051, Loss_kd 0.348, Train_accy 39.24
2022-09-28 06:30:11,955 [foster.py] => Task 1, Epoch 5/34 => Loss 2.086, Loss_clf 0.611, Loss_fe 0.975, Loss_kd 0.350, Train_accy 39.24
2022-09-28 06:30:14,441 [foster.py] => Task 1, Epoch 6/34 => Loss 2.019, Loss_clf 0.603, Loss_fe 0.915, Loss_kd 0.351, Train_accy 38.85, Test_accy 73.06
2022-09-28 06:30:16,181 [foster.py] => Task 1, Epoch 7/34 => Loss 1.946, Loss_clf 0.573, Loss_fe 0.873, Loss_kd 0.350, Train_accy 38.33
2022-09-28 06:30:17,922 [foster.py] => Task 1, Epoch 8/34 => Loss 1.923, Loss_clf 0.576, Loss_fe 0.843, Loss_kd 0.353, Train_accy 40.29
2022-09-28 06:30:19,694 [foster.py] => Task 1, Epoch 9/34 => Loss 1.846, Loss_clf 0.545, Loss_fe 0.798, Loss_kd 0.352, Train_accy 40.29
2022-09-28 06:30:21,469 [foster.py] => Task 1, Epoch 10/34 => Loss 1.809, Loss_clf 0.540, Loss_fe 0.779, Loss_kd 0.343, Train_accy 39.11
2022-09-28 06:30:23,956 [foster.py] => Task 1, Epoch 11/34 => Loss 1.807, Loss_clf 0.546, Loss_fe 0.764, Loss_kd 0.348, Train_accy 39.63, Test_accy 72.60
2022-09-28 06:30:25,714 [foster.py] => Task 1, Epoch 12/34 => Loss 1.791, Loss_clf 0.540, Loss_fe 0.747, Loss_kd 0.352, Train_accy 40.29
2022-09-28 06:30:27,450 [foster.py] => Task 1, Epoch 13/34 => Loss 1.752, Loss_clf 0.513, Loss_fe 0.732, Loss_kd 0.355, Train_accy 42.63
2022-09-28 06:30:29,183 [foster.py] => Task 1, Epoch 14/34 => Loss 1.690, Loss_clf 0.501, Loss_fe 0.698, Loss_kd 0.344, Train_accy 42.76
2022-09-28 06:30:30,920 [foster.py] => Task 1, Epoch 15/34 => Loss 1.695, Loss_clf 0.514, Loss_fe 0.690, Loss_kd 0.344, Train_accy 42.11
2022-09-28 06:30:33,400 [foster.py] => Task 1, Epoch 16/34 => Loss 1.704, Loss_clf 0.517, Loss_fe 0.689, Loss_kd 0.349, Train_accy 41.72, Test_accy 72.60
2022-09-28 06:30:35,115 [foster.py] => Task 1, Epoch 17/34 => Loss 1.653, Loss_clf 0.498, Loss_fe 0.660, Loss_kd 0.347, Train_accy 42.11
2022-09-28 06:30:36,846 [foster.py] => Task 1, Epoch 18/34 => Loss 1.620, Loss_clf 0.476, Loss_fe 0.643, Loss_kd 0.350, Train_accy 42.89
2022-09-28 06:30:38,558 [foster.py] => Task 1, Epoch 19/34 => Loss 1.631, Loss_clf 0.486, Loss_fe 0.645, Loss_kd 0.350, Train_accy 42.63
2022-09-28 06:30:40,270 [foster.py] => Task 1, Epoch 20/34 => Loss 1.646, Loss_clf 0.484, Loss_fe 0.658, Loss_kd 0.353, Train_accy 44.59
2022-09-28 06:30:42,733 [foster.py] => Task 1, Epoch 21/34 => Loss 1.573, Loss_clf 0.455, Loss_fe 0.621, Loss_kd 0.348, Train_accy 43.42, Test_accy 73.06
2022-09-28 06:30:44,481 [foster.py] => Task 1, Epoch 22/34 => Loss 1.649, Loss_clf 0.489, Loss_fe 0.656, Loss_kd 0.353, Train_accy 43.55
2022-09-28 06:30:46,257 [foster.py] => Task 1, Epoch 23/34 => Loss 1.566, Loss_clf 0.465, Loss_fe 0.609, Loss_kd 0.344, Train_accy 43.94
2022-09-28 06:30:47,962 [foster.py] => Task 1, Epoch 24/34 => Loss 1.556, Loss_clf 0.448, Loss_fe 0.613, Loss_kd 0.346, Train_accy 44.33
2022-09-28 06:30:49,696 [foster.py] => Task 1, Epoch 25/34 => Loss 1.547, Loss_clf 0.443, Loss_fe 0.606, Loss_kd 0.348, Train_accy 43.16
2022-09-28 06:30:52,142 [foster.py] => Task 1, Epoch 26/34 => Loss 1.571, Loss_clf 0.459, Loss_fe 0.613, Loss_kd 0.348, Train_accy 43.68, Test_accy 72.60
2022-09-28 06:30:53,893 [foster.py] => Task 1, Epoch 27/34 => Loss 1.571, Loss_clf 0.460, Loss_fe 0.609, Loss_kd 0.352, Train_accy 44.72
2022-09-28 06:30:55,639 [foster.py] => Task 1, Epoch 28/34 => Loss 1.560, Loss_clf 0.442, Loss_fe 0.611, Loss_kd 0.354, Train_accy 43.16
2022-09-28 06:30:57,441 [foster.py] => Task 1, Epoch 29/34 => Loss 1.598, Loss_clf 0.472, Loss_fe 0.627, Loss_kd 0.350, Train_accy 42.63
2022-09-28 06:30:59,181 [foster.py] => Task 1, Epoch 30/34 => Loss 1.551, Loss_clf 0.442, Loss_fe 0.610, Loss_kd 0.349, Train_accy 43.81
2022-09-28 06:31:01,618 [foster.py] => Task 1, Epoch 31/34 => Loss 1.537, Loss_clf 0.450, Loss_fe 0.598, Loss_kd 0.342, Train_accy 43.81, Test_accy 72.60
2022-09-28 06:31:03,368 [foster.py] => Task 1, Epoch 32/34 => Loss 1.545, Loss_clf 0.442, Loss_fe 0.610, Loss_kd 0.345, Train_accy 42.50
2022-09-28 06:31:05,148 [foster.py] => Task 1, Epoch 33/34 => Loss 1.587, Loss_clf 0.461, Loss_fe 0.615, Loss_kd 0.358, Train_accy 44.33
2022-09-28 06:31:06,906 [foster.py] => Task 1, Epoch 34/34 => Loss 1.537, Loss_clf 0.444, Loss_fe 0.602, Loss_kd 0.344, Train_accy 42.89
2022-09-28 06:31:06,907 [foster.py] => do not weight align teacher!
2022-09-28 06:31:06,907 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 06:31:09,764 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.475,  Train_accy 17.73, Test_accy 60.73
2022-09-28 06:31:11,695 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.340,  Train_accy 17.86
2022-09-28 06:31:13,636 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.273,  Train_accy 18.12
2022-09-28 06:31:15,597 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.220,  Train_accy 18.77
2022-09-28 06:31:17,570 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.204,  Train_accy 19.04
2022-09-28 06:31:20,152 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.210,  Train_accy 19.04, Test_accy 65.30
2022-09-28 06:31:22,113 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.177,  Train_accy 19.69
2022-09-28 06:31:24,088 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.176,  Train_accy 20.21
2022-09-28 06:31:25,994 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.166,  Train_accy 20.21
2022-09-28 06:31:28,023 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.168,  Train_accy 20.86
2022-09-28 06:31:30,656 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.161,  Train_accy 21.25, Test_accy 65.30
2022-09-28 06:31:32,610 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.158,  Train_accy 20.21
2022-09-28 06:31:34,518 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.147,  Train_accy 20.34
2022-09-28 06:31:36,449 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.143,  Train_accy 20.73
2022-09-28 06:31:38,384 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.134,  Train_accy 20.60
2022-09-28 06:31:41,044 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.142,  Train_accy 22.16, Test_accy 66.21
2022-09-28 06:31:42,967 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.149,  Train_accy 21.51
2022-09-28 06:31:44,972 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.142,  Train_accy 21.38
2022-09-28 06:31:46,883 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.142,  Train_accy 21.77
2022-09-28 06:31:48,874 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.137,  Train_accy 21.38
2022-09-28 06:31:51,468 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.143,  Train_accy 21.77, Test_accy 66.67
2022-09-28 06:31:53,400 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.144,  Train_accy 22.56
2022-09-28 06:31:55,393 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.135,  Train_accy 21.77
2022-09-28 06:31:57,318 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.148,  Train_accy 22.03
2022-09-28 06:31:59,261 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.134,  Train_accy 20.99
2022-09-28 06:32:01,895 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.141,  Train_accy 21.64, Test_accy 67.58
2022-09-28 06:32:01,896 [foster.py] => do not weight align student!
2022-09-28 06:32:02,586 [foster.py] => darknet eval: 
2022-09-28 06:32:02,586 [foster.py] => CNN top1 curve: 67.58
2022-09-28 06:32:02,587 [foster.py] => CNN top5 curve: 98.63
2022-09-28 06:32:02,587 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 06:32:08,928 [foster.py] => Exemplar size: 200
2022-09-28 06:32:08,928 [trainer.py] => CNN: {'total': 72.6, 'old': 86.08, 'new': 37.7, 'base': 86.08, 'compound': 37.7}
2022-09-28 06:32:08,928 [trainer.py] => CNN top1 curve: [88.61, 72.6]
2022-09-28 06:32:08,928 [trainer.py] => CNN base curve: [88.61, 86.08]
2022-09-28 06:32:08,928 [trainer.py] => CNN old curve: [88.61, 86.08]
2022-09-28 06:32:08,928 [trainer.py] => CNN new curve: [0, 37.7]
2022-09-28 06:32:08,928 [trainer.py] => CNN compound curve: [0, 37.7]
2022-09-28 06:32:08,928 [trainer.py] => NME: {'total': 73.52, 'old': 80.38, 'new': 55.74, 'base': 80.38, 'compound': 55.74}
2022-09-28 06:32:08,928 [trainer.py] => NME top1 curve: [87.97, 73.52]
2022-09-28 06:32:08,928 [trainer.py] => NME base curve: [87.97, 80.38]
2022-09-28 06:32:08,928 [trainer.py] => NME old curve: [87.97, 80.38]
2022-09-28 06:32:08,928 [trainer.py] => NME new curve: [0, 55.74]
2022-09-28 06:32:08,928 [trainer.py] => NME compound curve: [0, 55.74]
2022-09-28 06:32:09,160 [foster.py] => Learning on 10-13
2022-09-28 06:32:09,160 [foster.py] => All params: 22378148
2022-09-28 06:32:09,160 [foster.py] => Trainable params: 11196506
2022-09-28 06:32:09,180 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 06:32:11,761 [foster.py] => Task 2, Epoch 1/34 => Loss 5.280, Loss_clf 2.001, Loss_fe 2.133, Loss_kd 0.882, Train_accy 39.58, Test_accy 50.34
2022-09-28 06:32:13,605 [foster.py] => Task 2, Epoch 2/34 => Loss 3.638, Loss_clf 0.995, Loss_fe 1.521, Loss_kd 0.863, Train_accy 44.61
2022-09-28 06:32:15,449 [foster.py] => Task 2, Epoch 3/34 => Loss 3.215, Loss_clf 0.806, Loss_fe 1.317, Loss_kd 0.840, Train_accy 37.62
2022-09-28 06:32:17,256 [foster.py] => Task 2, Epoch 4/34 => Loss 3.050, Loss_clf 0.758, Loss_fe 1.203, Loss_kd 0.837, Train_accy 37.50
2022-09-28 06:32:19,099 [foster.py] => Task 2, Epoch 5/34 => Loss 2.927, Loss_clf 0.718, Loss_fe 1.111, Loss_kd 0.844, Train_accy 37.62
2022-09-28 06:32:21,680 [foster.py] => Task 2, Epoch 6/34 => Loss 2.823, Loss_clf 0.683, Loss_fe 1.048, Loss_kd 0.840, Train_accy 38.11, Test_accy 55.52
2022-09-28 06:32:23,528 [foster.py] => Task 2, Epoch 7/34 => Loss 2.781, Loss_clf 0.692, Loss_fe 1.000, Loss_kd 0.837, Train_accy 39.95
2022-09-28 06:32:25,358 [foster.py] => Task 2, Epoch 8/34 => Loss 2.689, Loss_clf 0.652, Loss_fe 0.944, Loss_kd 0.841, Train_accy 39.71
2022-09-28 06:32:27,185 [foster.py] => Task 2, Epoch 9/34 => Loss 2.608, Loss_clf 0.626, Loss_fe 0.891, Loss_kd 0.839, Train_accy 40.07
2022-09-28 06:32:28,974 [foster.py] => Task 2, Epoch 10/34 => Loss 2.565, Loss_clf 0.617, Loss_fe 0.856, Loss_kd 0.840, Train_accy 41.05
2022-09-28 06:32:31,598 [foster.py] => Task 2, Epoch 11/34 => Loss 2.554, Loss_clf 0.613, Loss_fe 0.843, Loss_kd 0.845, Train_accy 41.05, Test_accy 57.24
2022-09-28 06:32:33,453 [foster.py] => Task 2, Epoch 12/34 => Loss 2.498, Loss_clf 0.607, Loss_fe 0.802, Loss_kd 0.837, Train_accy 38.97
2022-09-28 06:32:35,322 [foster.py] => Task 2, Epoch 13/34 => Loss 2.458, Loss_clf 0.588, Loss_fe 0.772, Loss_kd 0.845, Train_accy 41.18
2022-09-28 06:32:37,143 [foster.py] => Task 2, Epoch 14/34 => Loss 2.437, Loss_clf 0.579, Loss_fe 0.771, Loss_kd 0.836, Train_accy 41.91
2022-09-28 06:32:38,969 [foster.py] => Task 2, Epoch 15/34 => Loss 2.418, Loss_clf 0.581, Loss_fe 0.741, Loss_kd 0.843, Train_accy 42.03
2022-09-28 06:32:41,560 [foster.py] => Task 2, Epoch 16/34 => Loss 2.375, Loss_clf 0.563, Loss_fe 0.720, Loss_kd 0.840, Train_accy 41.42, Test_accy 57.59
2022-09-28 06:32:43,389 [foster.py] => Task 2, Epoch 17/34 => Loss 2.316, Loss_clf 0.529, Loss_fe 0.697, Loss_kd 0.839, Train_accy 43.75
2022-09-28 06:32:45,191 [foster.py] => Task 2, Epoch 18/34 => Loss 2.320, Loss_clf 0.535, Loss_fe 0.689, Loss_kd 0.844, Train_accy 40.32
2022-09-28 06:32:47,029 [foster.py] => Task 2, Epoch 19/34 => Loss 2.300, Loss_clf 0.531, Loss_fe 0.672, Loss_kd 0.844, Train_accy 41.91
2022-09-28 06:32:48,823 [foster.py] => Task 2, Epoch 20/34 => Loss 2.290, Loss_clf 0.524, Loss_fe 0.675, Loss_kd 0.839, Train_accy 42.65
2022-09-28 06:32:51,435 [foster.py] => Task 2, Epoch 21/34 => Loss 2.269, Loss_clf 0.514, Loss_fe 0.663, Loss_kd 0.840, Train_accy 41.18, Test_accy 57.59
2022-09-28 06:32:53,296 [foster.py] => Task 2, Epoch 22/34 => Loss 2.275, Loss_clf 0.521, Loss_fe 0.653, Loss_kd 0.847, Train_accy 42.52
2022-09-28 06:32:55,091 [foster.py] => Task 2, Epoch 23/34 => Loss 2.268, Loss_clf 0.517, Loss_fe 0.661, Loss_kd 0.839, Train_accy 41.05
2022-09-28 06:32:56,905 [foster.py] => Task 2, Epoch 24/34 => Loss 2.226, Loss_clf 0.509, Loss_fe 0.633, Loss_kd 0.833, Train_accy 43.75
2022-09-28 06:32:58,704 [foster.py] => Task 2, Epoch 25/34 => Loss 2.238, Loss_clf 0.501, Loss_fe 0.638, Loss_kd 0.846, Train_accy 43.50
2022-09-28 06:33:01,355 [foster.py] => Task 2, Epoch 26/34 => Loss 2.225, Loss_clf 0.492, Loss_fe 0.625, Loss_kd 0.852, Train_accy 41.30, Test_accy 57.93
2022-09-28 06:33:03,181 [foster.py] => Task 2, Epoch 27/34 => Loss 2.225, Loss_clf 0.500, Loss_fe 0.626, Loss_kd 0.845, Train_accy 43.50
2022-09-28 06:33:05,027 [foster.py] => Task 2, Epoch 28/34 => Loss 2.205, Loss_clf 0.488, Loss_fe 0.624, Loss_kd 0.841, Train_accy 43.38
2022-09-28 06:33:06,850 [foster.py] => Task 2, Epoch 29/34 => Loss 2.204, Loss_clf 0.481, Loss_fe 0.626, Loss_kd 0.844, Train_accy 43.75
2022-09-28 06:33:08,637 [foster.py] => Task 2, Epoch 30/34 => Loss 2.222, Loss_clf 0.502, Loss_fe 0.625, Loss_kd 0.842, Train_accy 44.12
2022-09-28 06:33:11,241 [foster.py] => Task 2, Epoch 31/34 => Loss 2.215, Loss_clf 0.498, Loss_fe 0.624, Loss_kd 0.841, Train_accy 41.42, Test_accy 57.93
2022-09-28 06:33:13,109 [foster.py] => Task 2, Epoch 32/34 => Loss 2.207, Loss_clf 0.495, Loss_fe 0.618, Loss_kd 0.841, Train_accy 42.52
2022-09-28 06:33:14,907 [foster.py] => Task 2, Epoch 33/34 => Loss 2.195, Loss_clf 0.476, Loss_fe 0.627, Loss_kd 0.840, Train_accy 42.89
2022-09-28 06:33:16,711 [foster.py] => Task 2, Epoch 34/34 => Loss 2.219, Loss_clf 0.497, Loss_fe 0.621, Loss_kd 0.847, Train_accy 44.61
2022-09-28 06:33:16,712 [foster.py] => do not weight align teacher!
2022-09-28 06:33:16,712 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 06:33:19,713 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.816,  Train_accy 16.79, Test_accy 49.31
2022-09-28 06:33:21,778 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.673,  Train_accy 16.91
2022-09-28 06:33:23,857 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.648,  Train_accy 17.03
2022-09-28 06:33:25,862 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.612,  Train_accy 17.52
2022-09-28 06:33:27,949 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.585,  Train_accy 17.65
2022-09-28 06:33:30,676 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.593,  Train_accy 17.77, Test_accy 51.03
2022-09-28 06:33:32,708 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.598,  Train_accy 17.89
2022-09-28 06:33:34,767 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.576,  Train_accy 17.52
2022-09-28 06:33:36,796 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.561,  Train_accy 18.38
2022-09-28 06:33:38,829 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.575,  Train_accy 18.75
2022-09-28 06:33:41,570 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.568,  Train_accy 18.38, Test_accy 52.07
2022-09-28 06:33:43,612 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.564,  Train_accy 19.00
2022-09-28 06:33:45,621 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.563,  Train_accy 18.01
2022-09-28 06:33:47,654 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.563,  Train_accy 18.26
2022-09-28 06:33:49,668 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.562,  Train_accy 18.87
2022-09-28 06:33:52,429 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.546,  Train_accy 18.63, Test_accy 52.76
2022-09-28 06:33:54,466 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.544,  Train_accy 18.38
2022-09-28 06:33:56,570 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.546,  Train_accy 18.87
2022-09-28 06:33:58,569 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.549,  Train_accy 18.87
2022-09-28 06:34:00,620 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.553,  Train_accy 19.00
2022-09-28 06:34:03,378 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.564,  Train_accy 19.49, Test_accy 52.07
2022-09-28 06:34:05,398 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.532,  Train_accy 19.12
2022-09-28 06:34:07,415 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.538,  Train_accy 19.00
2022-09-28 06:34:09,541 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.544,  Train_accy 18.75
2022-09-28 06:34:11,576 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.547,  Train_accy 18.87
2022-09-28 06:34:14,283 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.556,  Train_accy 18.50, Test_accy 52.07
2022-09-28 06:34:14,284 [foster.py] => do not weight align student!
2022-09-28 06:34:14,992 [foster.py] => darknet eval: 
2022-09-28 06:34:14,992 [foster.py] => CNN top1 curve: 52.07
2022-09-28 06:34:14,992 [foster.py] => CNN top5 curve: 96.55
2022-09-28 06:34:14,992 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 06:34:22,372 [foster.py] => Exemplar size: 260
2022-09-28 06:34:22,372 [trainer.py] => CNN: {'total': 57.59, 'old': 68.49, 'new': 23.94, 'base': 83.54, 'compound': 26.52}
2022-09-28 06:34:22,372 [trainer.py] => CNN top1 curve: [88.61, 72.6, 57.59]
2022-09-28 06:34:22,372 [trainer.py] => CNN base curve: [88.61, 86.08, 83.54]
2022-09-28 06:34:22,372 [trainer.py] => CNN old curve: [88.61, 86.08, 68.49]
2022-09-28 06:34:22,372 [trainer.py] => CNN new curve: [0, 37.7, 23.94]
2022-09-28 06:34:22,372 [trainer.py] => CNN compound curve: [0, 37.7, 26.52]
2022-09-28 06:34:22,372 [trainer.py] => NME: {'total': 64.83, 'old': 68.49, 'new': 53.52, 'base': 75.32, 'compound': 52.27}
2022-09-28 06:34:22,372 [trainer.py] => NME top1 curve: [87.97, 73.52, 64.83]
2022-09-28 06:34:22,372 [trainer.py] => NME base curve: [87.97, 80.38, 75.32]
2022-09-28 06:34:22,372 [trainer.py] => NME old curve: [87.97, 80.38, 68.49]
2022-09-28 06:34:22,372 [trainer.py] => NME new curve: [0, 55.74, 53.52]
2022-09-28 06:34:22,372 [trainer.py] => NME compound curve: [0, 55.74, 52.27]
2022-09-28 06:34:22,606 [foster.py] => Learning on 13-16
2022-09-28 06:34:22,606 [foster.py] => All params: 22384301
2022-09-28 06:34:22,606 [foster.py] => Trainable params: 11201120
2022-09-28 06:34:22,627 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 06:34:25,535 [foster.py] => Task 3, Epoch 1/34 => Loss 6.302, Loss_clf 2.215, Loss_fe 2.454, Loss_kd 1.327, Train_accy 43.36, Test_accy 45.18
2022-09-28 06:34:27,465 [foster.py] => Task 3, Epoch 2/34 => Loss 4.083, Loss_clf 0.904, Loss_fe 1.580, Loss_kd 1.299, Train_accy 46.57
2022-09-28 06:34:29,443 [foster.py] => Task 3, Epoch 3/34 => Loss 3.714, Loss_clf 0.742, Loss_fe 1.370, Loss_kd 1.303, Train_accy 45.77
2022-09-28 06:34:31,351 [foster.py] => Task 3, Epoch 4/34 => Loss 3.519, Loss_clf 0.705, Loss_fe 1.219, Loss_kd 1.296, Train_accy 47.14
2022-09-28 06:34:33,288 [foster.py] => Task 3, Epoch 5/34 => Loss 3.447, Loss_clf 0.707, Loss_fe 1.145, Loss_kd 1.296, Train_accy 46.34
2022-09-28 06:34:36,077 [foster.py] => Task 3, Epoch 6/34 => Loss 3.295, Loss_clf 0.648, Loss_fe 1.048, Loss_kd 1.299, Train_accy 48.97, Test_accy 53.72
2022-09-28 06:34:38,021 [foster.py] => Task 3, Epoch 7/34 => Loss 3.173, Loss_clf 0.609, Loss_fe 0.974, Loss_kd 1.291, Train_accy 47.03
2022-09-28 06:34:39,949 [foster.py] => Task 3, Epoch 8/34 => Loss 3.111, Loss_clf 0.597, Loss_fe 0.928, Loss_kd 1.289, Train_accy 48.40
2022-09-28 06:34:41,856 [foster.py] => Task 3, Epoch 9/34 => Loss 3.074, Loss_clf 0.586, Loss_fe 0.884, Loss_kd 1.303, Train_accy 47.60
2022-09-28 06:34:43,748 [foster.py] => Task 3, Epoch 10/34 => Loss 3.002, Loss_clf 0.580, Loss_fe 0.838, Loss_kd 1.287, Train_accy 46.45
2022-09-28 06:34:46,560 [foster.py] => Task 3, Epoch 11/34 => Loss 2.995, Loss_clf 0.577, Loss_fe 0.820, Loss_kd 1.299, Train_accy 51.37, Test_accy 53.72
2022-09-28 06:34:48,488 [foster.py] => Task 3, Epoch 12/34 => Loss 2.949, Loss_clf 0.563, Loss_fe 0.796, Loss_kd 1.293, Train_accy 50.00
2022-09-28 06:34:50,391 [foster.py] => Task 3, Epoch 13/34 => Loss 2.894, Loss_clf 0.550, Loss_fe 0.747, Loss_kd 1.297, Train_accy 50.34
2022-09-28 06:34:52,323 [foster.py] => Task 3, Epoch 14/34 => Loss 2.877, Loss_clf 0.535, Loss_fe 0.737, Loss_kd 1.304, Train_accy 50.69
2022-09-28 06:34:54,232 [foster.py] => Task 3, Epoch 15/34 => Loss 2.860, Loss_clf 0.543, Loss_fe 0.720, Loss_kd 1.298, Train_accy 51.95
2022-09-28 06:34:56,962 [foster.py] => Task 3, Epoch 16/34 => Loss 2.848, Loss_clf 0.531, Loss_fe 0.708, Loss_kd 1.307, Train_accy 50.57, Test_accy 53.72
2022-09-28 06:34:58,904 [foster.py] => Task 3, Epoch 17/34 => Loss 2.797, Loss_clf 0.516, Loss_fe 0.682, Loss_kd 1.299, Train_accy 51.49
2022-09-28 06:35:00,843 [foster.py] => Task 3, Epoch 18/34 => Loss 2.782, Loss_clf 0.510, Loss_fe 0.675, Loss_kd 1.297, Train_accy 53.66
2022-09-28 06:35:02,753 [foster.py] => Task 3, Epoch 19/34 => Loss 2.750, Loss_clf 0.494, Loss_fe 0.657, Loss_kd 1.299, Train_accy 54.46
2022-09-28 06:35:04,627 [foster.py] => Task 3, Epoch 20/34 => Loss 2.763, Loss_clf 0.508, Loss_fe 0.655, Loss_kd 1.301, Train_accy 54.00
2022-09-28 06:35:07,408 [foster.py] => Task 3, Epoch 21/34 => Loss 2.727, Loss_clf 0.498, Loss_fe 0.644, Loss_kd 1.287, Train_accy 50.57, Test_accy 54.82
2022-09-28 06:35:09,345 [foster.py] => Task 3, Epoch 22/34 => Loss 2.732, Loss_clf 0.493, Loss_fe 0.645, Loss_kd 1.295, Train_accy 54.23
2022-09-28 06:35:11,250 [foster.py] => Task 3, Epoch 23/34 => Loss 2.687, Loss_clf 0.471, Loss_fe 0.621, Loss_kd 1.296, Train_accy 54.92
2022-09-28 06:35:13,166 [foster.py] => Task 3, Epoch 24/34 => Loss 2.682, Loss_clf 0.479, Loss_fe 0.600, Loss_kd 1.302, Train_accy 52.75
2022-09-28 06:35:15,067 [foster.py] => Task 3, Epoch 25/34 => Loss 2.689, Loss_clf 0.483, Loss_fe 0.620, Loss_kd 1.288, Train_accy 54.12
2022-09-28 06:35:17,856 [foster.py] => Task 3, Epoch 26/34 => Loss 2.703, Loss_clf 0.481, Loss_fe 0.621, Loss_kd 1.300, Train_accy 52.63, Test_accy 55.10
2022-09-28 06:35:19,782 [foster.py] => Task 3, Epoch 27/34 => Loss 2.668, Loss_clf 0.466, Loss_fe 0.597, Loss_kd 1.304, Train_accy 55.38
2022-09-28 06:35:21,684 [foster.py] => Task 3, Epoch 28/34 => Loss 2.642, Loss_clf 0.449, Loss_fe 0.584, Loss_kd 1.307, Train_accy 54.58
2022-09-28 06:35:23,585 [foster.py] => Task 3, Epoch 29/34 => Loss 2.686, Loss_clf 0.472, Loss_fe 0.606, Loss_kd 1.306, Train_accy 54.23
2022-09-28 06:35:25,476 [foster.py] => Task 3, Epoch 30/34 => Loss 2.689, Loss_clf 0.479, Loss_fe 0.610, Loss_kd 1.300, Train_accy 53.43
2022-09-28 06:35:28,226 [foster.py] => Task 3, Epoch 31/34 => Loss 2.678, Loss_clf 0.473, Loss_fe 0.604, Loss_kd 1.302, Train_accy 54.46, Test_accy 54.55
2022-09-28 06:35:30,123 [foster.py] => Task 3, Epoch 32/34 => Loss 2.689, Loss_clf 0.488, Loss_fe 0.615, Loss_kd 1.289, Train_accy 51.60
2022-09-28 06:35:32,015 [foster.py] => Task 3, Epoch 33/34 => Loss 2.674, Loss_clf 0.475, Loss_fe 0.604, Loss_kd 1.296, Train_accy 53.32
2022-09-28 06:35:33,913 [foster.py] => Task 3, Epoch 34/34 => Loss 2.682, Loss_clf 0.461, Loss_fe 0.604, Loss_kd 1.313, Train_accy 53.09
2022-09-28 06:35:33,914 [foster.py] => do not weight align teacher!
2022-09-28 06:35:33,914 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 06:35:37,014 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.133,  Train_accy 16.82, Test_accy 41.05
2022-09-28 06:35:39,204 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.035,  Train_accy 17.05
2022-09-28 06:35:41,366 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 1.994,  Train_accy 16.82
2022-09-28 06:35:43,571 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 1.990,  Train_accy 17.51
2022-09-28 06:35:45,760 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.984,  Train_accy 16.93
2022-09-28 06:35:48,680 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.974,  Train_accy 17.28, Test_accy 41.60
2022-09-28 06:35:50,833 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.955,  Train_accy 17.39
2022-09-28 06:35:52,952 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.965,  Train_accy 17.39
2022-09-28 06:35:55,048 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.964,  Train_accy 17.62
2022-09-28 06:35:57,183 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.962,  Train_accy 17.73
2022-09-28 06:36:00,071 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.949,  Train_accy 18.65, Test_accy 42.42
2022-09-28 06:36:02,242 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.940,  Train_accy 18.42
2022-09-28 06:36:04,358 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.926,  Train_accy 18.54
2022-09-28 06:36:06,491 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.935,  Train_accy 18.31
2022-09-28 06:36:08,671 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.932,  Train_accy 18.31
2022-09-28 06:36:11,527 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.925,  Train_accy 18.76, Test_accy 42.70
2022-09-28 06:36:13,724 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.939,  Train_accy 18.19
2022-09-28 06:36:15,918 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.924,  Train_accy 18.42
2022-09-28 06:36:18,133 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.915,  Train_accy 18.42
2022-09-28 06:36:20,315 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.921,  Train_accy 18.19
2022-09-28 06:36:23,196 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.924,  Train_accy 18.08, Test_accy 42.42
2022-09-28 06:36:25,315 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.926,  Train_accy 17.51
2022-09-28 06:36:27,431 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.928,  Train_accy 17.73
2022-09-28 06:36:29,573 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.937,  Train_accy 18.54
2022-09-28 06:36:31,682 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.929,  Train_accy 18.99
2022-09-28 06:36:34,557 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.919,  Train_accy 19.11, Test_accy 42.98
2022-09-28 06:36:34,558 [foster.py] => do not weight align student!
2022-09-28 06:36:35,306 [foster.py] => darknet eval: 
2022-09-28 06:36:35,307 [foster.py] => CNN top1 curve: 42.98
2022-09-28 06:36:35,307 [foster.py] => CNN top5 curve: 88.43
2022-09-28 06:36:35,307 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 06:36:43,868 [foster.py] => Exemplar size: 320
2022-09-28 06:36:43,868 [trainer.py] => CNN: {'total': 54.55, 'old': 56.21, 'new': 47.95, 'base': 77.22, 'compound': 37.07}
2022-09-28 06:36:43,868 [trainer.py] => CNN top1 curve: [88.61, 72.6, 57.59, 54.55]
2022-09-28 06:36:43,868 [trainer.py] => CNN base curve: [88.61, 86.08, 83.54, 77.22]
2022-09-28 06:36:43,868 [trainer.py] => CNN old curve: [88.61, 86.08, 68.49, 56.21]
2022-09-28 06:36:43,868 [trainer.py] => CNN new curve: [0, 37.7, 23.94, 47.95]
2022-09-28 06:36:43,868 [trainer.py] => CNN compound curve: [0, 37.7, 26.52, 37.07]
2022-09-28 06:36:43,868 [trainer.py] => NME: {'total': 61.98, 'old': 60.0, 'new': 69.86, 'base': 66.46, 'compound': 58.54}
2022-09-28 06:36:43,868 [trainer.py] => NME top1 curve: [87.97, 73.52, 64.83, 61.98]
2022-09-28 06:36:43,868 [trainer.py] => NME base curve: [87.97, 80.38, 75.32, 66.46]
2022-09-28 06:36:43,868 [trainer.py] => NME old curve: [87.97, 80.38, 68.49, 60.0]
2022-09-28 06:36:43,868 [trainer.py] => NME new curve: [0, 55.74, 53.52, 69.86]
2022-09-28 06:36:43,868 [trainer.py] => NME compound curve: [0, 55.74, 52.27, 58.54]
2022-09-28 06:36:44,101 [foster.py] => Learning on 16-19
2022-09-28 06:36:44,101 [foster.py] => All params: 22390454
2022-09-28 06:36:44,102 [foster.py] => Trainable params: 11205734
2022-09-28 06:36:44,122 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 06:36:47,013 [foster.py] => Task 4, Epoch 1/34 => Loss 6.351, Loss_clf 1.864, Loss_fe 2.497, Loss_kd 1.676, Train_accy 37.88, Test_accy 42.60
2022-09-28 06:36:48,997 [foster.py] => Task 4, Epoch 2/34 => Loss 4.717, Loss_clf 0.982, Loss_fe 1.738, Loss_kd 1.681, Train_accy 41.20
2022-09-28 06:36:50,966 [foster.py] => Task 4, Epoch 3/34 => Loss 4.412, Loss_clf 0.897, Loss_fe 1.507, Loss_kd 1.691, Train_accy 47.75
2022-09-28 06:36:52,983 [foster.py] => Task 4, Epoch 4/34 => Loss 4.275, Loss_clf 0.861, Loss_fe 1.399, Loss_kd 1.696, Train_accy 48.28
2022-09-28 06:36:54,975 [foster.py] => Task 4, Epoch 5/34 => Loss 4.080, Loss_clf 0.786, Loss_fe 1.266, Loss_kd 1.707, Train_accy 49.68
2022-09-28 06:36:57,936 [foster.py] => Task 4, Epoch 6/34 => Loss 4.072, Loss_clf 0.810, Loss_fe 1.235, Loss_kd 1.707, Train_accy 51.07, Test_accy 49.66
2022-09-28 06:36:59,903 [foster.py] => Task 4, Epoch 7/34 => Loss 3.894, Loss_clf 0.756, Loss_fe 1.112, Loss_kd 1.706, Train_accy 49.57
2022-09-28 06:37:01,931 [foster.py] => Task 4, Epoch 8/34 => Loss 3.805, Loss_clf 0.726, Loss_fe 1.063, Loss_kd 1.698, Train_accy 51.72
2022-09-28 06:37:03,947 [foster.py] => Task 4, Epoch 9/34 => Loss 3.782, Loss_clf 0.726, Loss_fe 1.049, Loss_kd 1.691, Train_accy 50.43
2022-09-28 06:37:05,961 [foster.py] => Task 4, Epoch 10/34 => Loss 3.702, Loss_clf 0.687, Loss_fe 0.992, Loss_kd 1.703, Train_accy 52.79
2022-09-28 06:37:08,911 [foster.py] => Task 4, Epoch 11/34 => Loss 3.666, Loss_clf 0.695, Loss_fe 0.959, Loss_kd 1.694, Train_accy 54.83, Test_accy 53.30
2022-09-28 06:37:10,936 [foster.py] => Task 4, Epoch 12/34 => Loss 3.624, Loss_clf 0.668, Loss_fe 0.918, Loss_kd 1.716, Train_accy 54.18
2022-09-28 06:37:12,934 [foster.py] => Task 4, Epoch 13/34 => Loss 3.608, Loss_clf 0.683, Loss_fe 0.913, Loss_kd 1.694, Train_accy 53.22
2022-09-28 06:37:14,940 [foster.py] => Task 4, Epoch 14/34 => Loss 3.503, Loss_clf 0.634, Loss_fe 0.849, Loss_kd 1.701, Train_accy 55.36
2022-09-28 06:37:16,951 [foster.py] => Task 4, Epoch 15/34 => Loss 3.456, Loss_clf 0.602, Loss_fe 0.833, Loss_kd 1.702, Train_accy 55.79
2022-09-28 06:37:19,938 [foster.py] => Task 4, Epoch 16/34 => Loss 3.464, Loss_clf 0.627, Loss_fe 0.823, Loss_kd 1.696, Train_accy 54.40, Test_accy 55.13
2022-09-28 06:37:21,969 [foster.py] => Task 4, Epoch 17/34 => Loss 3.407, Loss_clf 0.607, Loss_fe 0.785, Loss_kd 1.697, Train_accy 56.01
2022-09-28 06:37:23,953 [foster.py] => Task 4, Epoch 18/34 => Loss 3.450, Loss_clf 0.612, Loss_fe 0.832, Loss_kd 1.690, Train_accy 55.90
2022-09-28 06:37:25,974 [foster.py] => Task 4, Epoch 19/34 => Loss 3.362, Loss_clf 0.591, Loss_fe 0.758, Loss_kd 1.695, Train_accy 58.69
2022-09-28 06:37:28,029 [foster.py] => Task 4, Epoch 20/34 => Loss 3.347, Loss_clf 0.576, Loss_fe 0.743, Loss_kd 1.709, Train_accy 56.55
2022-09-28 06:37:30,938 [foster.py] => Task 4, Epoch 21/34 => Loss 3.393, Loss_clf 0.605, Loss_fe 0.768, Loss_kd 1.701, Train_accy 57.08, Test_accy 57.18
2022-09-28 06:37:32,918 [foster.py] => Task 4, Epoch 22/34 => Loss 3.347, Loss_clf 0.574, Loss_fe 0.747, Loss_kd 1.707, Train_accy 58.58
2022-09-28 06:37:34,914 [foster.py] => Task 4, Epoch 23/34 => Loss 3.356, Loss_clf 0.583, Loss_fe 0.748, Loss_kd 1.705, Train_accy 57.19
2022-09-28 06:37:36,907 [foster.py] => Task 4, Epoch 24/34 => Loss 3.320, Loss_clf 0.565, Loss_fe 0.733, Loss_kd 1.703, Train_accy 56.65
2022-09-28 06:37:38,901 [foster.py] => Task 4, Epoch 25/34 => Loss 3.322, Loss_clf 0.562, Loss_fe 0.730, Loss_kd 1.709, Train_accy 57.94
2022-09-28 06:37:41,830 [foster.py] => Task 4, Epoch 26/34 => Loss 3.353, Loss_clf 0.580, Loss_fe 0.751, Loss_kd 1.703, Train_accy 58.05, Test_accy 55.58
2022-09-28 06:37:43,883 [foster.py] => Task 4, Epoch 27/34 => Loss 3.254, Loss_clf 0.547, Loss_fe 0.688, Loss_kd 1.700, Train_accy 58.58
2022-09-28 06:37:45,911 [foster.py] => Task 4, Epoch 28/34 => Loss 3.312, Loss_clf 0.567, Loss_fe 0.716, Loss_kd 1.709, Train_accy 56.97
2022-09-28 06:37:47,893 [foster.py] => Task 4, Epoch 29/34 => Loss 3.347, Loss_clf 0.580, Loss_fe 0.727, Loss_kd 1.718, Train_accy 58.37
2022-09-28 06:37:49,910 [foster.py] => Task 4, Epoch 30/34 => Loss 3.339, Loss_clf 0.575, Loss_fe 0.737, Loss_kd 1.706, Train_accy 57.08
2022-09-28 06:37:52,834 [foster.py] => Task 4, Epoch 31/34 => Loss 3.410, Loss_clf 0.614, Loss_fe 0.763, Loss_kd 1.712, Train_accy 58.26, Test_accy 57.18
2022-09-28 06:37:54,910 [foster.py] => Task 4, Epoch 32/34 => Loss 3.291, Loss_clf 0.557, Loss_fe 0.707, Loss_kd 1.707, Train_accy 57.73
2022-09-28 06:37:56,922 [foster.py] => Task 4, Epoch 33/34 => Loss 3.297, Loss_clf 0.557, Loss_fe 0.697, Loss_kd 1.720, Train_accy 56.97
2022-09-28 06:37:58,906 [foster.py] => Task 4, Epoch 34/34 => Loss 3.294, Loss_clf 0.551, Loss_fe 0.718, Loss_kd 1.706, Train_accy 58.37
2022-09-28 06:37:58,906 [foster.py] => do not weight align teacher!
2022-09-28 06:37:58,907 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 06:38:02,155 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.405,  Train_accy 16.31, Test_accy 34.17
2022-09-28 06:38:04,421 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.310,  Train_accy 17.17
2022-09-28 06:38:06,635 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.294,  Train_accy 17.06
2022-09-28 06:38:08,841 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.272,  Train_accy 17.70
2022-09-28 06:38:11,082 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.270,  Train_accy 17.92
2022-09-28 06:38:14,166 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.248,  Train_accy 17.92, Test_accy 38.04
2022-09-28 06:38:16,405 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.247,  Train_accy 18.24
2022-09-28 06:38:18,678 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.240,  Train_accy 18.45
2022-09-28 06:38:20,914 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.245,  Train_accy 19.31
2022-09-28 06:38:23,177 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.233,  Train_accy 20.06
2022-09-28 06:38:26,213 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.229,  Train_accy 19.74, Test_accy 39.18
2022-09-28 06:38:28,460 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.225,  Train_accy 19.42
2022-09-28 06:38:30,717 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.221,  Train_accy 20.92
2022-09-28 06:38:33,024 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.218,  Train_accy 21.57
2022-09-28 06:38:35,274 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.216,  Train_accy 19.96
2022-09-28 06:38:38,332 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.204,  Train_accy 21.46, Test_accy 39.86
2022-09-28 06:38:40,566 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.230,  Train_accy 21.24
2022-09-28 06:38:42,827 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.217,  Train_accy 21.35
2022-09-28 06:38:45,077 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.233,  Train_accy 21.57
2022-09-28 06:38:47,356 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.218,  Train_accy 23.07
2022-09-28 06:38:50,510 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.209,  Train_accy 21.89, Test_accy 40.09
2022-09-28 06:38:52,716 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.219,  Train_accy 22.10
2022-09-28 06:38:54,980 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.214,  Train_accy 22.10
2022-09-28 06:38:57,213 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.218,  Train_accy 22.21
2022-09-28 06:38:59,491 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.220,  Train_accy 22.42
2022-09-28 06:39:02,546 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.223,  Train_accy 22.32, Test_accy 39.86
2022-09-28 06:39:02,546 [foster.py] => do not weight align student!
2022-09-28 06:39:03,408 [foster.py] => darknet eval: 
2022-09-28 06:39:03,408 [foster.py] => CNN top1 curve: 39.86
2022-09-28 06:39:03,408 [foster.py] => CNN top5 curve: 85.42
2022-09-28 06:39:03,408 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 06:39:13,115 [foster.py] => Exemplar size: 380
2022-09-28 06:39:13,115 [trainer.py] => CNN: {'total': 55.81, 'old': 55.65, 'new': 56.58, 'base': 72.15, 'compound': 46.62}
2022-09-28 06:39:13,115 [trainer.py] => CNN top1 curve: [88.61, 72.6, 57.59, 54.55, 55.81]
2022-09-28 06:39:13,115 [trainer.py] => CNN base curve: [88.61, 86.08, 83.54, 77.22, 72.15]
2022-09-28 06:39:13,115 [trainer.py] => CNN old curve: [88.61, 86.08, 68.49, 56.21, 55.65]
2022-09-28 06:39:13,115 [trainer.py] => CNN new curve: [0, 37.7, 23.94, 47.95, 56.58]
2022-09-28 06:39:13,115 [trainer.py] => CNN compound curve: [0, 37.7, 26.52, 37.07, 46.62]
2022-09-28 06:39:13,115 [trainer.py] => NME: {'total': 58.77, 'old': 56.75, 'new': 68.42, 'base': 62.66, 'compound': 56.58}
2022-09-28 06:39:13,115 [trainer.py] => NME top1 curve: [87.97, 73.52, 64.83, 61.98, 58.77]
2022-09-28 06:39:13,115 [trainer.py] => NME base curve: [87.97, 80.38, 75.32, 66.46, 62.66]
2022-09-28 06:39:13,115 [trainer.py] => NME old curve: [87.97, 80.38, 68.49, 60.0, 56.75]
2022-09-28 06:39:13,115 [trainer.py] => NME new curve: [0, 55.74, 53.52, 69.86, 68.42]
2022-09-28 06:39:13,115 [trainer.py] => NME compound curve: [0, 55.74, 52.27, 58.54, 56.58]
2022-09-28 06:39:13,349 [foster.py] => Learning on 19-22
2022-09-28 06:39:13,349 [foster.py] => All params: 22396607
2022-09-28 06:39:13,349 [foster.py] => Trainable params: 11210348
2022-09-28 06:39:13,370 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 06:39:16,452 [foster.py] => Task 5, Epoch 1/34 => Loss 6.678, Loss_clf 1.860, Loss_fe 2.553, Loss_kd 1.955, Train_accy 39.34, Test_accy 37.70
2022-09-28 06:39:18,654 [foster.py] => Task 5, Epoch 2/34 => Loss 5.344, Loss_clf 1.177, Loss_fe 1.894, Loss_kd 1.963, Train_accy 34.06
2022-09-28 06:39:20,779 [foster.py] => Task 5, Epoch 3/34 => Loss 5.031, Loss_clf 1.074, Loss_fe 1.682, Loss_kd 1.964, Train_accy 39.34
2022-09-28 06:39:22,865 [foster.py] => Task 5, Epoch 4/34 => Loss 4.839, Loss_clf 1.020, Loss_fe 1.547, Loss_kd 1.962, Train_accy 39.74
2022-09-28 06:39:24,997 [foster.py] => Task 5, Epoch 5/34 => Loss 4.721, Loss_clf 0.998, Loss_fe 1.449, Loss_kd 1.964, Train_accy 41.43
2022-09-28 06:39:28,097 [foster.py] => Task 5, Epoch 6/34 => Loss 4.623, Loss_clf 0.974, Loss_fe 1.372, Loss_kd 1.966, Train_accy 39.74, Test_accy 44.25
2022-09-28 06:39:30,223 [foster.py] => Task 5, Epoch 7/34 => Loss 4.551, Loss_clf 0.958, Loss_fe 1.310, Loss_kd 1.971, Train_accy 43.63
2022-09-28 06:39:32,344 [foster.py] => Task 5, Epoch 8/34 => Loss 4.453, Loss_clf 0.924, Loss_fe 1.250, Loss_kd 1.968, Train_accy 40.64
2022-09-28 06:39:34,410 [foster.py] => Task 5, Epoch 9/34 => Loss 4.408, Loss_clf 0.910, Loss_fe 1.210, Loss_kd 1.975, Train_accy 43.13
2022-09-28 06:39:36,504 [foster.py] => Task 5, Epoch 10/34 => Loss 4.350, Loss_clf 0.899, Loss_fe 1.167, Loss_kd 1.972, Train_accy 41.04
2022-09-28 06:39:39,544 [foster.py] => Task 5, Epoch 11/34 => Loss 4.268, Loss_clf 0.874, Loss_fe 1.114, Loss_kd 1.969, Train_accy 43.23, Test_accy 43.45
2022-09-28 06:39:41,660 [foster.py] => Task 5, Epoch 12/34 => Loss 4.301, Loss_clf 0.890, Loss_fe 1.120, Loss_kd 1.979, Train_accy 44.62
2022-09-28 06:39:43,769 [foster.py] => Task 5, Epoch 13/34 => Loss 4.232, Loss_clf 0.865, Loss_fe 1.083, Loss_kd 1.973, Train_accy 41.93
2022-09-28 06:39:45,878 [foster.py] => Task 5, Epoch 14/34 => Loss 4.180, Loss_clf 0.855, Loss_fe 1.042, Loss_kd 1.971, Train_accy 41.14
2022-09-28 06:39:47,949 [foster.py] => Task 5, Epoch 15/34 => Loss 4.175, Loss_clf 0.850, Loss_fe 1.043, Loss_kd 1.971, Train_accy 44.12
2022-09-28 06:39:51,018 [foster.py] => Task 5, Epoch 16/34 => Loss 4.118, Loss_clf 0.820, Loss_fe 1.011, Loss_kd 1.975, Train_accy 44.12, Test_accy 44.44
2022-09-28 06:39:53,133 [foster.py] => Task 5, Epoch 17/34 => Loss 4.154, Loss_clf 0.834, Loss_fe 1.034, Loss_kd 1.974, Train_accy 44.02
2022-09-28 06:39:55,244 [foster.py] => Task 5, Epoch 18/34 => Loss 4.093, Loss_clf 0.806, Loss_fe 0.991, Loss_kd 1.983, Train_accy 43.73
2022-09-28 06:39:57,321 [foster.py] => Task 5, Epoch 19/34 => Loss 4.102, Loss_clf 0.815, Loss_fe 1.000, Loss_kd 1.976, Train_accy 43.53
2022-09-28 06:39:59,434 [foster.py] => Task 5, Epoch 20/34 => Loss 4.074, Loss_clf 0.812, Loss_fe 0.974, Loss_kd 1.976, Train_accy 47.21
2022-09-28 06:40:02,465 [foster.py] => Task 5, Epoch 21/34 => Loss 4.050, Loss_clf 0.801, Loss_fe 0.963, Loss_kd 1.974, Train_accy 45.42, Test_accy 44.64
2022-09-28 06:40:04,618 [foster.py] => Task 5, Epoch 22/34 => Loss 4.060, Loss_clf 0.813, Loss_fe 0.959, Loss_kd 1.977, Train_accy 46.22
2022-09-28 06:40:06,691 [foster.py] => Task 5, Epoch 23/34 => Loss 4.032, Loss_clf 0.788, Loss_fe 0.958, Loss_kd 1.974, Train_accy 42.23
2022-09-28 06:40:08,766 [foster.py] => Task 5, Epoch 24/34 => Loss 3.966, Loss_clf 0.770, Loss_fe 0.915, Loss_kd 1.970, Train_accy 46.12
2022-09-28 06:40:10,866 [foster.py] => Task 5, Epoch 25/34 => Loss 3.988, Loss_clf 0.781, Loss_fe 0.917, Loss_kd 1.978, Train_accy 45.12
2022-09-28 06:40:13,982 [foster.py] => Task 5, Epoch 26/34 => Loss 3.978, Loss_clf 0.776, Loss_fe 0.922, Loss_kd 1.969, Train_accy 45.52, Test_accy 44.84
2022-09-28 06:40:16,064 [foster.py] => Task 5, Epoch 27/34 => Loss 4.000, Loss_clf 0.782, Loss_fe 0.928, Loss_kd 1.978, Train_accy 45.62
2022-09-28 06:40:18,189 [foster.py] => Task 5, Epoch 28/34 => Loss 3.978, Loss_clf 0.774, Loss_fe 0.911, Loss_kd 1.980, Train_accy 45.42
2022-09-28 06:40:20,311 [foster.py] => Task 5, Epoch 29/34 => Loss 3.965, Loss_clf 0.774, Loss_fe 0.903, Loss_kd 1.976, Train_accy 46.51
2022-09-28 06:40:22,448 [foster.py] => Task 5, Epoch 30/34 => Loss 4.005, Loss_clf 0.788, Loss_fe 0.924, Loss_kd 1.981, Train_accy 46.51
2022-09-28 06:40:25,551 [foster.py] => Task 5, Epoch 31/34 => Loss 3.988, Loss_clf 0.778, Loss_fe 0.920, Loss_kd 1.977, Train_accy 46.22, Test_accy 45.24
2022-09-28 06:40:27,681 [foster.py] => Task 5, Epoch 32/34 => Loss 3.960, Loss_clf 0.773, Loss_fe 0.911, Loss_kd 1.965, Train_accy 45.82
2022-09-28 06:40:29,745 [foster.py] => Task 5, Epoch 33/34 => Loss 3.936, Loss_clf 0.751, Loss_fe 0.900, Loss_kd 1.973, Train_accy 46.71
2022-09-28 06:40:31,890 [foster.py] => Task 5, Epoch 34/34 => Loss 3.954, Loss_clf 0.773, Loss_fe 0.902, Loss_kd 1.969, Train_accy 45.42
2022-09-28 06:40:31,891 [foster.py] => do not weight align teacher!
2022-09-28 06:40:31,891 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 06:40:35,307 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.498,  Train_accy 18.33, Test_accy 34.52
2022-09-28 06:40:37,699 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.468,  Train_accy 19.02
2022-09-28 06:40:40,101 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.453,  Train_accy 18.33
2022-09-28 06:40:42,432 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.452,  Train_accy 18.73
2022-09-28 06:40:44,823 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.437,  Train_accy 19.22
2022-09-28 06:40:48,010 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.437,  Train_accy 18.73, Test_accy 37.70
2022-09-28 06:40:50,402 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.425,  Train_accy 19.92
2022-09-28 06:40:52,769 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.438,  Train_accy 21.02
2022-09-28 06:40:55,095 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.433,  Train_accy 20.72
2022-09-28 06:40:57,434 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.421,  Train_accy 19.52
2022-09-28 06:41:00,607 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.423,  Train_accy 20.12, Test_accy 39.09
2022-09-28 06:41:02,946 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.427,  Train_accy 20.22
2022-09-28 06:41:05,303 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.425,  Train_accy 19.42
2022-09-28 06:41:07,637 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.413,  Train_accy 20.32
2022-09-28 06:41:10,006 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.416,  Train_accy 19.52
2022-09-28 06:41:13,257 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.419,  Train_accy 20.22, Test_accy 40.28
2022-09-28 06:41:15,617 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.418,  Train_accy 20.52
2022-09-28 06:41:17,988 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.410,  Train_accy 19.82
2022-09-28 06:41:20,328 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.423,  Train_accy 20.72
2022-09-28 06:41:22,677 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.421,  Train_accy 21.02
2022-09-28 06:41:25,901 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.417,  Train_accy 19.92, Test_accy 40.67
2022-09-28 06:41:28,311 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.420,  Train_accy 21.71
2022-09-28 06:41:30,636 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.419,  Train_accy 19.82
2022-09-28 06:41:32,975 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.422,  Train_accy 19.72
2022-09-28 06:41:35,368 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.421,  Train_accy 20.32
2022-09-28 06:41:38,540 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.409,  Train_accy 20.12, Test_accy 40.08
2022-09-28 06:41:38,541 [foster.py] => do not weight align student!
2022-09-28 06:41:39,383 [foster.py] => darknet eval: 
2022-09-28 06:41:39,383 [foster.py] => CNN top1 curve: 40.08
2022-09-28 06:41:39,383 [foster.py] => CNN top5 curve: 82.14
2022-09-28 06:41:39,383 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 06:41:50,064 [foster.py] => Exemplar size: 440
2022-09-28 06:41:50,064 [trainer.py] => CNN: {'total': 44.84, 'old': 48.06, 'new': 23.08, 'base': 67.09, 'compound': 34.68}
2022-09-28 06:41:50,064 [trainer.py] => CNN top1 curve: [88.61, 72.6, 57.59, 54.55, 55.81, 44.84]
2022-09-28 06:41:50,064 [trainer.py] => CNN base curve: [88.61, 86.08, 83.54, 77.22, 72.15, 67.09]
2022-09-28 06:41:50,064 [trainer.py] => CNN old curve: [88.61, 86.08, 68.49, 56.21, 55.65, 48.06]
2022-09-28 06:41:50,064 [trainer.py] => CNN new curve: [0, 37.7, 23.94, 47.95, 56.58, 23.08]
2022-09-28 06:41:50,064 [trainer.py] => CNN compound curve: [0, 37.7, 26.52, 37.07, 46.62, 34.68]
2022-09-28 06:41:50,064 [trainer.py] => NME: {'total': 53.17, 'old': 55.35, 'new': 38.46, 'base': 63.29, 'compound': 48.55}
2022-09-28 06:41:50,064 [trainer.py] => NME top1 curve: [87.97, 73.52, 64.83, 61.98, 58.77, 53.17]
2022-09-28 06:41:50,064 [trainer.py] => NME base curve: [87.97, 80.38, 75.32, 66.46, 62.66, 63.29]
2022-09-28 06:41:50,064 [trainer.py] => NME old curve: [87.97, 80.38, 68.49, 60.0, 56.75, 55.35]
2022-09-28 06:41:50,064 [trainer.py] => NME new curve: [0, 55.74, 53.52, 69.86, 68.42, 38.46]
2022-09-28 06:41:50,064 [trainer.py] => NME compound curve: [0, 55.74, 52.27, 58.54, 56.58, 48.55]
2022-09-28 06:41:50,066 [trainer.py] => config: ./exps/CFEE/foster.json
2022-09-28 06:41:50,066 [trainer.py] => prefix: cil
2022-09-28 06:41:50,066 [trainer.py] => dataset: CFEE
2022-09-28 06:41:50,066 [trainer.py] => memory_size: 2000
2022-09-28 06:41:50,066 [trainer.py] => memory_per_class: 20
2022-09-28 06:41:50,066 [trainer.py] => fixed_memory: True
2022-09-28 06:41:50,066 [trainer.py] => shuffle: True
2022-09-28 06:41:50,066 [trainer.py] => init_cls: 7
2022-09-28 06:41:50,066 [trainer.py] => increment: 3
2022-09-28 06:41:50,066 [trainer.py] => model_name: foster
2022-09-28 06:41:50,066 [trainer.py] => convnet_type: resnet18
2022-09-28 06:41:50,066 [trainer.py] => device: [device(type='cuda', index=1)]
2022-09-28 06:41:50,066 [trainer.py] => seed: 1993
2022-09-28 06:41:50,066 [trainer.py] => beta1: 0.96
2022-09-28 06:41:50,066 [trainer.py] => beta2: 0.97
2022-09-28 06:41:50,066 [trainer.py] => oofc: ft
2022-09-28 06:41:50,066 [trainer.py] => is_teacher_wa: False
2022-09-28 06:41:50,066 [trainer.py] => is_student_wa: False
2022-09-28 06:41:50,066 [trainer.py] => lambda_okd: 1
2022-09-28 06:41:50,066 [trainer.py] => wa_value: 1
2022-09-28 06:41:50,066 [trainer.py] => init_epochs: 40
2022-09-28 06:41:50,066 [trainer.py] => init_lr: 0.01
2022-09-28 06:41:50,066 [trainer.py] => init_weight_decay: 0.0005
2022-09-28 06:41:50,066 [trainer.py] => boosting_epochs: 34
2022-09-28 06:41:50,067 [trainer.py] => compression_epochs: 26
2022-09-28 06:41:50,067 [trainer.py] => lr: 0.001
2022-09-28 06:41:50,067 [trainer.py] => batch_size: 32
2022-09-28 06:41:50,067 [trainer.py] => weight_decay: 0.0005
2022-09-28 06:41:50,067 [trainer.py] => num_workers: 8
2022-09-28 06:41:50,067 [trainer.py] => T: 2
2022-09-28 06:41:50,067 [trainer.py] => nb_runs: 3
2022-09-28 06:41:50,067 [trainer.py] => fold: 10
2022-09-28 06:41:50,067 [data.py] => ========== Fold:9 ==========
2022-09-28 06:41:50,072 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 20, 12, 10, 19, 21, 17, 18, 8, 7, 9, 14, 15, 13, 11, 16]
2022-09-28 06:41:50,289 [foster.py] => Learning on 0-7
2022-09-28 06:41:50,289 [foster.py] => All params: 11183694
2022-09-28 06:41:50,289 [foster.py] => Trainable params: 11183694
2022-09-28 06:41:52,653 [foster.py] => Task 0, Epoch 1/40 => Loss 1.353, Train_accy 51.98
2022-09-28 06:41:55,696 [foster.py] => Task 0, Epoch 2/40 => Loss 0.569, Train_accy 81.29, Test_accy 77.44
2022-09-28 06:41:58,712 [foster.py] => Task 0, Epoch 3/40 => Loss 0.369, Train_accy 87.94, Test_accy 81.10
2022-09-28 06:42:01,714 [foster.py] => Task 0, Epoch 4/40 => Loss 0.295, Train_accy 89.33, Test_accy 83.54
2022-09-28 06:42:04,682 [foster.py] => Task 0, Epoch 5/40 => Loss 0.215, Train_accy 92.10, Test_accy 82.32
2022-09-28 06:42:07,080 [foster.py] => Task 0, Epoch 6/40 => Loss 0.186, Train_accy 93.69
2022-09-28 06:42:10,121 [foster.py] => Task 0, Epoch 7/40 => Loss 0.148, Train_accy 95.36, Test_accy 84.76
2022-09-28 06:42:13,125 [foster.py] => Task 0, Epoch 8/40 => Loss 0.141, Train_accy 95.43, Test_accy 84.15
2022-09-28 06:42:16,117 [foster.py] => Task 0, Epoch 9/40 => Loss 0.158, Train_accy 95.01, Test_accy 85.37
2022-09-28 06:42:19,137 [foster.py] => Task 0, Epoch 10/40 => Loss 0.131, Train_accy 95.56, Test_accy 82.32
2022-09-28 06:42:21,531 [foster.py] => Task 0, Epoch 11/40 => Loss 0.123, Train_accy 96.74
2022-09-28 06:42:24,536 [foster.py] => Task 0, Epoch 12/40 => Loss 0.128, Train_accy 95.84, Test_accy 82.32
2022-09-28 06:42:27,553 [foster.py] => Task 0, Epoch 13/40 => Loss 0.074, Train_accy 97.51, Test_accy 84.15
2022-09-28 06:42:30,521 [foster.py] => Task 0, Epoch 14/40 => Loss 0.055, Train_accy 98.54, Test_accy 82.93
2022-09-28 06:42:33,518 [foster.py] => Task 0, Epoch 15/40 => Loss 0.046, Train_accy 99.03, Test_accy 84.15
2022-09-28 06:42:35,903 [foster.py] => Task 0, Epoch 16/40 => Loss 0.091, Train_accy 98.48
2022-09-28 06:42:38,885 [foster.py] => Task 0, Epoch 17/40 => Loss 0.062, Train_accy 98.75, Test_accy 85.37
2022-09-28 06:42:41,871 [foster.py] => Task 0, Epoch 18/40 => Loss 0.058, Train_accy 98.82, Test_accy 83.54
2022-09-28 06:42:44,867 [foster.py] => Task 0, Epoch 19/40 => Loss 0.043, Train_accy 99.10, Test_accy 85.98
2022-09-28 06:42:47,895 [foster.py] => Task 0, Epoch 20/40 => Loss 0.041, Train_accy 99.38, Test_accy 84.76
2022-09-28 06:42:50,366 [foster.py] => Task 0, Epoch 21/40 => Loss 0.058, Train_accy 98.68
2022-09-28 06:42:53,420 [foster.py] => Task 0, Epoch 22/40 => Loss 0.057, Train_accy 98.82, Test_accy 84.15
2022-09-28 06:42:56,429 [foster.py] => Task 0, Epoch 23/40 => Loss 0.040, Train_accy 99.31, Test_accy 82.32
2022-09-28 06:42:59,396 [foster.py] => Task 0, Epoch 24/40 => Loss 0.032, Train_accy 99.58, Test_accy 83.54
2022-09-28 06:43:02,406 [foster.py] => Task 0, Epoch 25/40 => Loss 0.028, Train_accy 99.45, Test_accy 82.93
2022-09-28 06:43:04,775 [foster.py] => Task 0, Epoch 26/40 => Loss 0.051, Train_accy 99.38
2022-09-28 06:43:07,783 [foster.py] => Task 0, Epoch 27/40 => Loss 0.046, Train_accy 99.31, Test_accy 85.37
2022-09-28 06:43:10,757 [foster.py] => Task 0, Epoch 28/40 => Loss 0.031, Train_accy 99.17, Test_accy 81.10
2022-09-28 06:43:13,803 [foster.py] => Task 0, Epoch 29/40 => Loss 0.021, Train_accy 99.65, Test_accy 82.32
2022-09-28 06:43:16,793 [foster.py] => Task 0, Epoch 30/40 => Loss 0.024, Train_accy 99.51, Test_accy 81.71
2022-09-28 06:43:19,170 [foster.py] => Task 0, Epoch 31/40 => Loss 0.021, Train_accy 99.65
2022-09-28 06:43:22,185 [foster.py] => Task 0, Epoch 32/40 => Loss 0.025, Train_accy 99.79, Test_accy 82.93
2022-09-28 06:43:25,227 [foster.py] => Task 0, Epoch 33/40 => Loss 0.017, Train_accy 99.79, Test_accy 81.71
2022-09-28 06:43:28,206 [foster.py] => Task 0, Epoch 34/40 => Loss 0.046, Train_accy 99.51, Test_accy 81.71
2022-09-28 06:43:31,260 [foster.py] => Task 0, Epoch 35/40 => Loss 0.017, Train_accy 99.79, Test_accy 82.32
2022-09-28 06:43:33,670 [foster.py] => Task 0, Epoch 36/40 => Loss 0.016, Train_accy 99.93
2022-09-28 06:43:36,685 [foster.py] => Task 0, Epoch 37/40 => Loss 0.015, Train_accy 99.93, Test_accy 82.93
2022-09-28 06:43:39,731 [foster.py] => Task 0, Epoch 38/40 => Loss 0.021, Train_accy 99.65, Test_accy 81.71
2022-09-28 06:43:42,723 [foster.py] => Task 0, Epoch 39/40 => Loss 0.018, Train_accy 99.93, Test_accy 81.71
2022-09-28 06:43:45,685 [foster.py] => Task 0, Epoch 40/40 => Loss 0.021, Train_accy 99.45, Test_accy 82.32
2022-09-28 06:43:45,685 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 06:43:52,556 [foster.py] => Exemplar size: 140
2022-09-28 06:43:52,556 [trainer.py] => CNN: {'total': 82.32, 'old': 82.32, 'new': 0, 'base': 82.32, 'compound': 0}
2022-09-28 06:43:52,556 [trainer.py] => CNN top1 curve: [82.32]
2022-09-28 06:43:52,556 [trainer.py] => CNN base curve: [82.32]
2022-09-28 06:43:52,556 [trainer.py] => CNN old curve: [82.32]
2022-09-28 06:43:52,556 [trainer.py] => CNN new curve: [0]
2022-09-28 06:43:52,556 [trainer.py] => CNN compound curve: [0]
2022-09-28 06:43:52,556 [trainer.py] => NME: {'total': 81.71, 'old': 81.71, 'new': 0, 'base': 81.71, 'compound': 0}
2022-09-28 06:43:52,556 [trainer.py] => NME top1 curve: [81.71]
2022-09-28 06:43:52,556 [trainer.py] => NME base curve: [81.71]
2022-09-28 06:43:52,556 [trainer.py] => NME old curve: [81.71]
2022-09-28 06:43:52,556 [trainer.py] => NME new curve: [0]
2022-09-28 06:43:52,556 [trainer.py] => NME compound curve: [0]
2022-09-28 06:43:52,789 [foster.py] => Learning on 7-10
2022-09-28 06:43:52,790 [foster.py] => All params: 22371995
2022-09-28 06:43:52,790 [foster.py] => Trainable params: 11191892
2022-09-28 06:43:52,810 [foster.py] => per cls weights : [1.15287162 1.15287162 1.15287162 1.15287162 1.15287162 1.15287162
 1.15287162 0.64329956 0.64329956 0.64329956]
2022-09-28 06:43:55,300 [foster.py] => Task 1, Epoch 1/34 => Loss 4.840, Loss_clf 2.480, Loss_fe 1.844, Loss_kd 0.361, Train_accy 34.46, Test_accy 59.73
2022-09-28 06:43:57,035 [foster.py] => Task 1, Epoch 2/34 => Loss 2.829, Loss_clf 0.950, Loss_fe 1.322, Loss_kd 0.390, Train_accy 61.36
2022-09-28 06:43:58,781 [foster.py] => Task 1, Epoch 3/34 => Loss 2.337, Loss_clf 0.691, Loss_fe 1.139, Loss_kd 0.355, Train_accy 42.17
2022-09-28 06:44:00,581 [foster.py] => Task 1, Epoch 4/34 => Loss 2.153, Loss_clf 0.634, Loss_fe 1.023, Loss_kd 0.348, Train_accy 40.47
2022-09-28 06:44:02,349 [foster.py] => Task 1, Epoch 5/34 => Loss 2.045, Loss_clf 0.618, Loss_fe 0.943, Loss_kd 0.339, Train_accy 38.25
2022-09-28 06:44:04,788 [foster.py] => Task 1, Epoch 6/34 => Loss 1.966, Loss_clf 0.589, Loss_fe 0.892, Loss_kd 0.339, Train_accy 41.12, Test_accy 65.04
2022-09-28 06:44:06,525 [foster.py] => Task 1, Epoch 7/34 => Loss 1.948, Loss_clf 0.609, Loss_fe 0.850, Loss_kd 0.342, Train_accy 40.86
2022-09-28 06:44:08,287 [foster.py] => Task 1, Epoch 8/34 => Loss 1.898, Loss_clf 0.592, Loss_fe 0.823, Loss_kd 0.338, Train_accy 39.16
2022-09-28 06:44:10,050 [foster.py] => Task 1, Epoch 9/34 => Loss 1.812, Loss_clf 0.550, Loss_fe 0.777, Loss_kd 0.340, Train_accy 42.04
2022-09-28 06:44:11,777 [foster.py] => Task 1, Epoch 10/34 => Loss 1.789, Loss_clf 0.547, Loss_fe 0.760, Loss_kd 0.337, Train_accy 40.47
2022-09-28 06:44:14,237 [foster.py] => Task 1, Epoch 11/34 => Loss 1.779, Loss_clf 0.541, Loss_fe 0.754, Loss_kd 0.339, Train_accy 41.25, Test_accy 65.49
2022-09-28 06:44:16,007 [foster.py] => Task 1, Epoch 12/34 => Loss 1.759, Loss_clf 0.547, Loss_fe 0.731, Loss_kd 0.337, Train_accy 41.91
2022-09-28 06:44:17,750 [foster.py] => Task 1, Epoch 13/34 => Loss 1.698, Loss_clf 0.524, Loss_fe 0.693, Loss_kd 0.336, Train_accy 41.51
2022-09-28 06:44:19,493 [foster.py] => Task 1, Epoch 14/34 => Loss 1.702, Loss_clf 0.524, Loss_fe 0.693, Loss_kd 0.340, Train_accy 42.30
2022-09-28 06:44:21,246 [foster.py] => Task 1, Epoch 15/34 => Loss 1.657, Loss_clf 0.513, Loss_fe 0.669, Loss_kd 0.333, Train_accy 43.86
2022-09-28 06:44:23,726 [foster.py] => Task 1, Epoch 16/34 => Loss 1.681, Loss_clf 0.516, Loss_fe 0.678, Loss_kd 0.341, Train_accy 43.60, Test_accy 65.93
2022-09-28 06:44:25,453 [foster.py] => Task 1, Epoch 17/34 => Loss 1.699, Loss_clf 0.519, Loss_fe 0.685, Loss_kd 0.347, Train_accy 43.73
2022-09-28 06:44:27,164 [foster.py] => Task 1, Epoch 18/34 => Loss 1.610, Loss_clf 0.487, Loss_fe 0.644, Loss_kd 0.336, Train_accy 43.73
2022-09-28 06:44:28,907 [foster.py] => Task 1, Epoch 19/34 => Loss 1.621, Loss_clf 0.492, Loss_fe 0.639, Loss_kd 0.343, Train_accy 44.52
2022-09-28 06:44:30,673 [foster.py] => Task 1, Epoch 20/34 => Loss 1.635, Loss_clf 0.509, Loss_fe 0.643, Loss_kd 0.338, Train_accy 43.73
2022-09-28 06:44:33,134 [foster.py] => Task 1, Epoch 21/34 => Loss 1.586, Loss_clf 0.488, Loss_fe 0.619, Loss_kd 0.335, Train_accy 44.13, Test_accy 66.37
2022-09-28 06:44:34,861 [foster.py] => Task 1, Epoch 22/34 => Loss 1.558, Loss_clf 0.471, Loss_fe 0.623, Loss_kd 0.325, Train_accy 43.08
2022-09-28 06:44:36,638 [foster.py] => Task 1, Epoch 23/34 => Loss 1.590, Loss_clf 0.477, Loss_fe 0.622, Loss_kd 0.344, Train_accy 43.99
2022-09-28 06:44:38,390 [foster.py] => Task 1, Epoch 24/34 => Loss 1.593, Loss_clf 0.483, Loss_fe 0.629, Loss_kd 0.337, Train_accy 42.95
2022-09-28 06:44:40,108 [foster.py] => Task 1, Epoch 25/34 => Loss 1.553, Loss_clf 0.468, Loss_fe 0.601, Loss_kd 0.338, Train_accy 43.99
2022-09-28 06:44:42,651 [foster.py] => Task 1, Epoch 26/34 => Loss 1.551, Loss_clf 0.466, Loss_fe 0.604, Loss_kd 0.337, Train_accy 44.52, Test_accy 66.37
2022-09-28 06:44:44,367 [foster.py] => Task 1, Epoch 27/34 => Loss 1.544, Loss_clf 0.463, Loss_fe 0.593, Loss_kd 0.342, Train_accy 45.95
2022-09-28 06:44:46,097 [foster.py] => Task 1, Epoch 28/34 => Loss 1.565, Loss_clf 0.472, Loss_fe 0.609, Loss_kd 0.339, Train_accy 44.78
2022-09-28 06:44:47,857 [foster.py] => Task 1, Epoch 29/34 => Loss 1.558, Loss_clf 0.467, Loss_fe 0.601, Loss_kd 0.343, Train_accy 45.04
2022-09-28 06:44:49,572 [foster.py] => Task 1, Epoch 30/34 => Loss 1.529, Loss_clf 0.456, Loss_fe 0.591, Loss_kd 0.337, Train_accy 44.91
2022-09-28 06:44:52,026 [foster.py] => Task 1, Epoch 31/34 => Loss 1.520, Loss_clf 0.448, Loss_fe 0.589, Loss_kd 0.338, Train_accy 44.26, Test_accy 66.37
2022-09-28 06:44:53,786 [foster.py] => Task 1, Epoch 32/34 => Loss 1.528, Loss_clf 0.449, Loss_fe 0.593, Loss_kd 0.340, Train_accy 44.91
2022-09-28 06:44:55,526 [foster.py] => Task 1, Epoch 33/34 => Loss 1.521, Loss_clf 0.454, Loss_fe 0.592, Loss_kd 0.333, Train_accy 44.65
2022-09-28 06:44:57,251 [foster.py] => Task 1, Epoch 34/34 => Loss 1.545, Loss_clf 0.457, Loss_fe 0.598, Loss_kd 0.343, Train_accy 45.69
2022-09-28 06:44:57,252 [foster.py] => do not weight align teacher!
2022-09-28 06:44:57,252 [foster.py] => per cls weights : [1.19494058 1.19494058 1.19494058 1.19494058 1.19494058 1.19494058
 1.19494058 0.54513865 0.54513865 0.54513865]
2022-09-28 06:45:00,133 [foster.py] => SNet: Task 1, Epoch 1/26 => Loss 1.467,  Train_accy 17.75, Test_accy 58.41
2022-09-28 06:45:02,067 [foster.py] => SNet: Task 1, Epoch 2/26 => Loss 1.334,  Train_accy 17.89
2022-09-28 06:45:03,995 [foster.py] => SNet: Task 1, Epoch 3/26 => Loss 1.241,  Train_accy 18.67
2022-09-28 06:45:05,932 [foster.py] => SNet: Task 1, Epoch 4/26 => Loss 1.218,  Train_accy 19.71
2022-09-28 06:45:07,842 [foster.py] => SNet: Task 1, Epoch 5/26 => Loss 1.204,  Train_accy 20.63
2022-09-28 06:45:10,434 [foster.py] => SNet: Task 1, Epoch 6/26 => Loss 1.175,  Train_accy 21.02, Test_accy 60.62
2022-09-28 06:45:12,405 [foster.py] => SNet: Task 1, Epoch 7/26 => Loss 1.173,  Train_accy 21.02
2022-09-28 06:45:14,349 [foster.py] => SNet: Task 1, Epoch 8/26 => Loss 1.189,  Train_accy 22.06
2022-09-28 06:45:16,266 [foster.py] => SNet: Task 1, Epoch 9/26 => Loss 1.160,  Train_accy 22.72
2022-09-28 06:45:18,215 [foster.py] => SNet: Task 1, Epoch 10/26 => Loss 1.168,  Train_accy 22.19
2022-09-28 06:45:20,910 [foster.py] => SNet: Task 1, Epoch 11/26 => Loss 1.162,  Train_accy 22.72, Test_accy 59.73
2022-09-28 06:45:22,874 [foster.py] => SNet: Task 1, Epoch 12/26 => Loss 1.154,  Train_accy 23.11
2022-09-28 06:45:24,800 [foster.py] => SNet: Task 1, Epoch 13/26 => Loss 1.146,  Train_accy 22.72
2022-09-28 06:45:26,728 [foster.py] => SNet: Task 1, Epoch 14/26 => Loss 1.153,  Train_accy 23.63
2022-09-28 06:45:28,670 [foster.py] => SNet: Task 1, Epoch 15/26 => Loss 1.139,  Train_accy 23.24
2022-09-28 06:45:31,239 [foster.py] => SNet: Task 1, Epoch 16/26 => Loss 1.154,  Train_accy 23.50, Test_accy 59.73
2022-09-28 06:45:33,169 [foster.py] => SNet: Task 1, Epoch 17/26 => Loss 1.147,  Train_accy 23.89
2022-09-28 06:45:35,111 [foster.py] => SNet: Task 1, Epoch 18/26 => Loss 1.153,  Train_accy 24.41
2022-09-28 06:45:37,059 [foster.py] => SNet: Task 1, Epoch 19/26 => Loss 1.145,  Train_accy 24.02
2022-09-28 06:45:39,049 [foster.py] => SNet: Task 1, Epoch 20/26 => Loss 1.155,  Train_accy 22.58
2022-09-28 06:45:41,683 [foster.py] => SNet: Task 1, Epoch 21/26 => Loss 1.158,  Train_accy 23.63, Test_accy 59.73
2022-09-28 06:45:43,585 [foster.py] => SNet: Task 1, Epoch 22/26 => Loss 1.139,  Train_accy 22.85
2022-09-28 06:45:45,538 [foster.py] => SNet: Task 1, Epoch 23/26 => Loss 1.134,  Train_accy 23.50
2022-09-28 06:45:47,480 [foster.py] => SNet: Task 1, Epoch 24/26 => Loss 1.132,  Train_accy 22.72
2022-09-28 06:45:49,415 [foster.py] => SNet: Task 1, Epoch 25/26 => Loss 1.146,  Train_accy 22.19
2022-09-28 06:45:52,080 [foster.py] => SNet: Task 1, Epoch 26/26 => Loss 1.139,  Train_accy 22.58, Test_accy 59.73
2022-09-28 06:45:52,081 [foster.py] => do not weight align student!
2022-09-28 06:45:52,760 [foster.py] => darknet eval: 
2022-09-28 06:45:52,760 [foster.py] => CNN top1 curve: 59.73
2022-09-28 06:45:52,760 [foster.py] => CNN top5 curve: 96.9
2022-09-28 06:45:52,761 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 06:45:59,125 [foster.py] => Exemplar size: 200
2022-09-28 06:45:59,125 [trainer.py] => CNN: {'total': 66.37, 'old': 79.27, 'new': 32.26, 'base': 79.27, 'compound': 32.26}
2022-09-28 06:45:59,125 [trainer.py] => CNN top1 curve: [82.32, 66.37]
2022-09-28 06:45:59,125 [trainer.py] => CNN base curve: [82.32, 79.27]
2022-09-28 06:45:59,125 [trainer.py] => CNN old curve: [82.32, 79.27]
2022-09-28 06:45:59,125 [trainer.py] => CNN new curve: [0, 32.26]
2022-09-28 06:45:59,125 [trainer.py] => CNN compound curve: [0, 32.26]
2022-09-28 06:45:59,125 [trainer.py] => NME: {'total': 74.78, 'old': 81.71, 'new': 56.45, 'base': 81.71, 'compound': 56.45}
2022-09-28 06:45:59,125 [trainer.py] => NME top1 curve: [81.71, 74.78]
2022-09-28 06:45:59,125 [trainer.py] => NME base curve: [81.71, 81.71]
2022-09-28 06:45:59,125 [trainer.py] => NME old curve: [81.71, 81.71]
2022-09-28 06:45:59,125 [trainer.py] => NME new curve: [0, 56.45]
2022-09-28 06:45:59,125 [trainer.py] => NME compound curve: [0, 56.45]
2022-09-28 06:45:59,358 [foster.py] => Learning on 10-13
2022-09-28 06:45:59,358 [foster.py] => All params: 22378148
2022-09-28 06:45:59,358 [foster.py] => Trainable params: 11196506
2022-09-28 06:45:59,378 [foster.py] => per cls weights : [1.11358644 1.11358644 1.11358644 1.11358644 1.11358644 1.11358644
 1.11358644 1.11358644 1.11358644 1.11358644 0.62137852 0.62137852
 0.62137852]
2022-09-28 06:46:02,011 [foster.py] => Task 2, Epoch 1/34 => Loss 5.720, Loss_clf 2.393, Loss_fe 2.123, Loss_kd 0.926, Train_accy 38.38, Test_accy 48.08
2022-09-28 06:46:03,820 [foster.py] => Task 2, Epoch 2/34 => Loss 3.670, Loss_clf 0.987, Loss_fe 1.510, Loss_kd 0.902, Train_accy 50.12
2022-09-28 06:46:05,614 [foster.py] => Task 2, Epoch 3/34 => Loss 3.264, Loss_clf 0.772, Loss_fe 1.330, Loss_kd 0.894, Train_accy 44.07
2022-09-28 06:46:07,413 [foster.py] => Task 2, Epoch 4/34 => Loss 3.094, Loss_clf 0.730, Loss_fe 1.200, Loss_kd 0.895, Train_accy 42.13
2022-09-28 06:46:09,248 [foster.py] => Task 2, Epoch 5/34 => Loss 3.020, Loss_clf 0.722, Loss_fe 1.137, Loss_kd 0.893, Train_accy 45.28
2022-09-28 06:46:11,919 [foster.py] => Task 2, Epoch 6/34 => Loss 2.895, Loss_clf 0.687, Loss_fe 1.041, Loss_kd 0.898, Train_accy 40.92, Test_accy 56.45
2022-09-28 06:46:13,761 [foster.py] => Task 2, Epoch 7/34 => Loss 2.833, Loss_clf 0.677, Loss_fe 0.990, Loss_kd 0.897, Train_accy 43.83
2022-09-28 06:46:15,566 [foster.py] => Task 2, Epoch 8/34 => Loss 2.754, Loss_clf 0.642, Loss_fe 0.947, Loss_kd 0.896, Train_accy 44.43
2022-09-28 06:46:17,407 [foster.py] => Task 2, Epoch 9/34 => Loss 2.754, Loss_clf 0.667, Loss_fe 0.922, Loss_kd 0.896, Train_accy 41.77
2022-09-28 06:46:19,232 [foster.py] => Task 2, Epoch 10/34 => Loss 2.660, Loss_clf 0.626, Loss_fe 0.867, Loss_kd 0.897, Train_accy 43.95
2022-09-28 06:46:21,826 [foster.py] => Task 2, Epoch 11/34 => Loss 2.617, Loss_clf 0.619, Loss_fe 0.836, Loss_kd 0.893, Train_accy 46.25, Test_accy 55.75
2022-09-28 06:46:23,665 [foster.py] => Task 2, Epoch 12/34 => Loss 2.570, Loss_clf 0.607, Loss_fe 0.799, Loss_kd 0.896, Train_accy 44.79
2022-09-28 06:46:25,460 [foster.py] => Task 2, Epoch 13/34 => Loss 2.540, Loss_clf 0.596, Loss_fe 0.787, Loss_kd 0.891, Train_accy 43.95
2022-09-28 06:46:27,302 [foster.py] => Task 2, Epoch 14/34 => Loss 2.560, Loss_clf 0.600, Loss_fe 0.800, Loss_kd 0.892, Train_accy 47.46
2022-09-28 06:46:29,103 [foster.py] => Task 2, Epoch 15/34 => Loss 2.490, Loss_clf 0.578, Loss_fe 0.740, Loss_kd 0.901, Train_accy 45.16
2022-09-28 06:46:31,714 [foster.py] => Task 2, Epoch 16/34 => Loss 2.462, Loss_clf 0.574, Loss_fe 0.734, Loss_kd 0.887, Train_accy 47.94, Test_accy 56.45
2022-09-28 06:46:33,532 [foster.py] => Task 2, Epoch 17/34 => Loss 2.424, Loss_clf 0.548, Loss_fe 0.705, Loss_kd 0.901, Train_accy 45.88
2022-09-28 06:46:35,364 [foster.py] => Task 2, Epoch 18/34 => Loss 2.452, Loss_clf 0.567, Loss_fe 0.712, Loss_kd 0.902, Train_accy 46.37
2022-09-28 06:46:37,189 [foster.py] => Task 2, Epoch 19/34 => Loss 2.428, Loss_clf 0.559, Loss_fe 0.709, Loss_kd 0.893, Train_accy 47.70
2022-09-28 06:46:39,028 [foster.py] => Task 2, Epoch 20/34 => Loss 2.380, Loss_clf 0.545, Loss_fe 0.677, Loss_kd 0.890, Train_accy 46.61
2022-09-28 06:46:41,661 [foster.py] => Task 2, Epoch 21/34 => Loss 2.428, Loss_clf 0.555, Loss_fe 0.694, Loss_kd 0.907, Train_accy 47.22, Test_accy 56.79
2022-09-28 06:46:43,463 [foster.py] => Task 2, Epoch 22/34 => Loss 2.380, Loss_clf 0.548, Loss_fe 0.670, Loss_kd 0.894, Train_accy 46.85
2022-09-28 06:46:45,272 [foster.py] => Task 2, Epoch 23/34 => Loss 2.364, Loss_clf 0.539, Loss_fe 0.666, Loss_kd 0.891, Train_accy 45.88
2022-09-28 06:46:47,128 [foster.py] => Task 2, Epoch 24/34 => Loss 2.341, Loss_clf 0.527, Loss_fe 0.660, Loss_kd 0.887, Train_accy 45.76
2022-09-28 06:46:48,939 [foster.py] => Task 2, Epoch 25/34 => Loss 2.363, Loss_clf 0.529, Loss_fe 0.659, Loss_kd 0.904, Train_accy 46.25
2022-09-28 06:46:51,577 [foster.py] => Task 2, Epoch 26/34 => Loss 2.347, Loss_clf 0.526, Loss_fe 0.653, Loss_kd 0.898, Train_accy 46.97, Test_accy 57.49
2022-09-28 06:46:53,415 [foster.py] => Task 2, Epoch 27/34 => Loss 2.323, Loss_clf 0.517, Loss_fe 0.641, Loss_kd 0.896, Train_accy 47.70
2022-09-28 06:46:55,256 [foster.py] => Task 2, Epoch 28/34 => Loss 2.338, Loss_clf 0.519, Loss_fe 0.649, Loss_kd 0.900, Train_accy 47.34
2022-09-28 06:46:57,096 [foster.py] => Task 2, Epoch 29/34 => Loss 2.332, Loss_clf 0.528, Loss_fe 0.645, Loss_kd 0.892, Train_accy 45.76
2022-09-28 06:46:58,927 [foster.py] => Task 2, Epoch 30/34 => Loss 2.356, Loss_clf 0.536, Loss_fe 0.647, Loss_kd 0.903, Train_accy 47.70
2022-09-28 06:47:01,555 [foster.py] => Task 2, Epoch 31/34 => Loss 2.331, Loss_clf 0.523, Loss_fe 0.639, Loss_kd 0.899, Train_accy 48.67, Test_accy 57.84
2022-09-28 06:47:03,367 [foster.py] => Task 2, Epoch 32/34 => Loss 2.353, Loss_clf 0.533, Loss_fe 0.651, Loss_kd 0.899, Train_accy 47.34
2022-09-28 06:47:05,232 [foster.py] => Task 2, Epoch 33/34 => Loss 2.324, Loss_clf 0.511, Loss_fe 0.637, Loss_kd 0.905, Train_accy 48.55
2022-09-28 06:47:07,041 [foster.py] => Task 2, Epoch 34/34 => Loss 2.335, Loss_clf 0.514, Loss_fe 0.653, Loss_kd 0.898, Train_accy 47.22
2022-09-28 06:47:07,041 [foster.py] => do not weight align teacher!
2022-09-28 06:47:07,042 [foster.py] => per cls weights : [1.14349881 1.14349881 1.14349881 1.14349881 1.14349881 1.14349881
 1.14349881 1.14349881 1.14349881 1.14349881 0.52167063 0.52167063
 0.52167063]
2022-09-28 06:47:10,062 [foster.py] => SNet: Task 2, Epoch 1/26 => Loss 1.915,  Train_accy 16.71, Test_accy 45.30
2022-09-28 06:47:12,091 [foster.py] => SNet: Task 2, Epoch 2/26 => Loss 1.789,  Train_accy 16.83
2022-09-28 06:47:14,138 [foster.py] => SNet: Task 2, Epoch 3/26 => Loss 1.709,  Train_accy 17.43
2022-09-28 06:47:16,199 [foster.py] => SNet: Task 2, Epoch 4/26 => Loss 1.685,  Train_accy 17.80
2022-09-28 06:47:18,227 [foster.py] => SNet: Task 2, Epoch 5/26 => Loss 1.660,  Train_accy 17.80
2022-09-28 06:47:21,039 [foster.py] => SNet: Task 2, Epoch 6/26 => Loss 1.648,  Train_accy 17.43, Test_accy 47.39
2022-09-28 06:47:23,139 [foster.py] => SNet: Task 2, Epoch 7/26 => Loss 1.647,  Train_accy 18.04
2022-09-28 06:47:25,193 [foster.py] => SNet: Task 2, Epoch 8/26 => Loss 1.643,  Train_accy 18.04
2022-09-28 06:47:27,265 [foster.py] => SNet: Task 2, Epoch 9/26 => Loss 1.639,  Train_accy 18.04
2022-09-28 06:47:29,339 [foster.py] => SNet: Task 2, Epoch 10/26 => Loss 1.627,  Train_accy 18.28
2022-09-28 06:47:32,076 [foster.py] => SNet: Task 2, Epoch 11/26 => Loss 1.620,  Train_accy 18.89, Test_accy 49.13
2022-09-28 06:47:34,115 [foster.py] => SNet: Task 2, Epoch 12/26 => Loss 1.622,  Train_accy 17.80
2022-09-28 06:47:36,134 [foster.py] => SNet: Task 2, Epoch 13/26 => Loss 1.618,  Train_accy 18.28
2022-09-28 06:47:38,143 [foster.py] => SNet: Task 2, Epoch 14/26 => Loss 1.612,  Train_accy 18.77
2022-09-28 06:47:40,193 [foster.py] => SNet: Task 2, Epoch 15/26 => Loss 1.611,  Train_accy 18.52
2022-09-28 06:47:42,997 [foster.py] => SNet: Task 2, Epoch 16/26 => Loss 1.605,  Train_accy 18.28, Test_accy 50.87
2022-09-28 06:47:45,078 [foster.py] => SNet: Task 2, Epoch 17/26 => Loss 1.600,  Train_accy 19.25
2022-09-28 06:47:47,117 [foster.py] => SNet: Task 2, Epoch 18/26 => Loss 1.609,  Train_accy 18.89
2022-09-28 06:47:49,144 [foster.py] => SNet: Task 2, Epoch 19/26 => Loss 1.604,  Train_accy 18.89
2022-09-28 06:47:51,221 [foster.py] => SNet: Task 2, Epoch 20/26 => Loss 1.612,  Train_accy 18.52
2022-09-28 06:47:53,988 [foster.py] => SNet: Task 2, Epoch 21/26 => Loss 1.615,  Train_accy 18.89, Test_accy 50.87
2022-09-28 06:47:56,085 [foster.py] => SNet: Task 2, Epoch 22/26 => Loss 1.618,  Train_accy 19.61
2022-09-28 06:47:58,106 [foster.py] => SNet: Task 2, Epoch 23/26 => Loss 1.599,  Train_accy 19.25
2022-09-28 06:48:00,159 [foster.py] => SNet: Task 2, Epoch 24/26 => Loss 1.598,  Train_accy 19.25
2022-09-28 06:48:02,197 [foster.py] => SNet: Task 2, Epoch 25/26 => Loss 1.604,  Train_accy 19.37
2022-09-28 06:48:04,928 [foster.py] => SNet: Task 2, Epoch 26/26 => Loss 1.603,  Train_accy 18.40, Test_accy 51.57
2022-09-28 06:48:04,929 [foster.py] => do not weight align student!
2022-09-28 06:48:05,623 [foster.py] => darknet eval: 
2022-09-28 06:48:05,623 [foster.py] => CNN top1 curve: 51.57
2022-09-28 06:48:05,623 [foster.py] => CNN top5 curve: 94.08
2022-09-28 06:48:05,623 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 06:48:13,038 [foster.py] => Exemplar size: 260
2022-09-28 06:48:13,039 [trainer.py] => CNN: {'total': 57.14, 'old': 62.83, 'new': 36.07, 'base': 76.83, 'compound': 30.89}
2022-09-28 06:48:13,039 [trainer.py] => CNN top1 curve: [82.32, 66.37, 57.14]
2022-09-28 06:48:13,039 [trainer.py] => CNN base curve: [82.32, 79.27, 76.83]
2022-09-28 06:48:13,039 [trainer.py] => CNN old curve: [82.32, 79.27, 62.83]
2022-09-28 06:48:13,039 [trainer.py] => CNN new curve: [0, 32.26, 36.07]
2022-09-28 06:48:13,039 [trainer.py] => CNN compound curve: [0, 32.26, 30.89]
2022-09-28 06:48:13,039 [trainer.py] => NME: {'total': 65.16, 'old': 68.14, 'new': 54.1, 'base': 75.0, 'compound': 52.03}
2022-09-28 06:48:13,039 [trainer.py] => NME top1 curve: [81.71, 74.78, 65.16]
2022-09-28 06:48:13,039 [trainer.py] => NME base curve: [81.71, 81.71, 75.0]
2022-09-28 06:48:13,039 [trainer.py] => NME old curve: [81.71, 81.71, 68.14]
2022-09-28 06:48:13,039 [trainer.py] => NME new curve: [0, 56.45, 54.1]
2022-09-28 06:48:13,039 [trainer.py] => NME compound curve: [0, 56.45, 52.03]
2022-09-28 06:48:13,270 [foster.py] => Learning on 13-16
2022-09-28 06:48:13,270 [foster.py] => All params: 22384301
2022-09-28 06:48:13,271 [foster.py] => Trainable params: 11201120
2022-09-28 06:48:13,291 [foster.py] => per cls weights : [1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445 1.09036445
 1.09036445 0.60842071 0.60842071 0.60842071]
2022-09-28 06:48:16,057 [foster.py] => Task 3, Epoch 1/34 => Loss 5.975, Loss_clf 2.034, Loss_fe 2.286, Loss_kd 1.345, Train_accy 44.47, Test_accy 50.40
2022-09-28 06:48:17,919 [foster.py] => Task 3, Epoch 2/34 => Loss 4.109, Loss_clf 0.895, Loss_fe 1.588, Loss_kd 1.322, Train_accy 48.43
2022-09-28 06:48:19,767 [foster.py] => Task 3, Epoch 3/34 => Loss 3.679, Loss_clf 0.733, Loss_fe 1.343, Loss_kd 1.303, Train_accy 45.52
2022-09-28 06:48:21,622 [foster.py] => Task 3, Epoch 4/34 => Loss 3.495, Loss_clf 0.689, Loss_fe 1.208, Loss_kd 1.298, Train_accy 45.52
2022-09-28 06:48:23,515 [foster.py] => Task 3, Epoch 5/34 => Loss 3.396, Loss_clf 0.667, Loss_fe 1.125, Loss_kd 1.303, Train_accy 46.33
2022-09-28 06:48:26,300 [foster.py] => Task 3, Epoch 6/34 => Loss 3.277, Loss_clf 0.632, Loss_fe 1.031, Loss_kd 1.311, Train_accy 48.20, Test_accy 50.40
2022-09-28 06:48:28,216 [foster.py] => Task 3, Epoch 7/34 => Loss 3.185, Loss_clf 0.614, Loss_fe 0.973, Loss_kd 1.298, Train_accy 48.78
2022-09-28 06:48:30,125 [foster.py] => Task 3, Epoch 8/34 => Loss 3.154, Loss_clf 0.620, Loss_fe 0.922, Loss_kd 1.309, Train_accy 51.92
2022-09-28 06:48:32,002 [foster.py] => Task 3, Epoch 9/34 => Loss 3.096, Loss_clf 0.598, Loss_fe 0.893, Loss_kd 1.304, Train_accy 48.78
2022-09-28 06:48:33,909 [foster.py] => Task 3, Epoch 10/34 => Loss 3.043, Loss_clf 0.579, Loss_fe 0.847, Loss_kd 1.313, Train_accy 47.85
2022-09-28 06:48:36,659 [foster.py] => Task 3, Epoch 11/34 => Loss 2.978, Loss_clf 0.564, Loss_fe 0.806, Loss_kd 1.307, Train_accy 54.13, Test_accy 52.00
2022-09-28 06:48:38,570 [foster.py] => Task 3, Epoch 12/34 => Loss 2.933, Loss_clf 0.549, Loss_fe 0.780, Loss_kd 1.303, Train_accy 52.39
2022-09-28 06:48:40,430 [foster.py] => Task 3, Epoch 13/34 => Loss 2.935, Loss_clf 0.557, Loss_fe 0.765, Loss_kd 1.310, Train_accy 50.52
2022-09-28 06:48:42,326 [foster.py] => Task 3, Epoch 14/34 => Loss 2.894, Loss_clf 0.547, Loss_fe 0.731, Loss_kd 1.313, Train_accy 52.15
2022-09-28 06:48:44,284 [foster.py] => Task 3, Epoch 15/34 => Loss 2.878, Loss_clf 0.534, Loss_fe 0.729, Loss_kd 1.313, Train_accy 51.46
2022-09-28 06:48:47,012 [foster.py] => Task 3, Epoch 16/34 => Loss 2.808, Loss_clf 0.507, Loss_fe 0.692, Loss_kd 1.307, Train_accy 53.32, Test_accy 53.07
2022-09-28 06:48:48,901 [foster.py] => Task 3, Epoch 17/34 => Loss 2.820, Loss_clf 0.514, Loss_fe 0.691, Loss_kd 1.312, Train_accy 54.48
2022-09-28 06:48:50,776 [foster.py] => Task 3, Epoch 18/34 => Loss 2.794, Loss_clf 0.503, Loss_fe 0.675, Loss_kd 1.313, Train_accy 54.13
2022-09-28 06:48:52,657 [foster.py] => Task 3, Epoch 19/34 => Loss 2.806, Loss_clf 0.514, Loss_fe 0.670, Loss_kd 1.317, Train_accy 54.13
2022-09-28 06:48:54,505 [foster.py] => Task 3, Epoch 20/34 => Loss 2.790, Loss_clf 0.512, Loss_fe 0.656, Loss_kd 1.318, Train_accy 53.67
2022-09-28 06:48:57,304 [foster.py] => Task 3, Epoch 21/34 => Loss 2.735, Loss_clf 0.488, Loss_fe 0.637, Loss_kd 1.309, Train_accy 55.41, Test_accy 53.33
2022-09-28 06:48:59,178 [foster.py] => Task 3, Epoch 22/34 => Loss 2.709, Loss_clf 0.481, Loss_fe 0.621, Loss_kd 1.305, Train_accy 54.25
2022-09-28 06:49:01,062 [foster.py] => Task 3, Epoch 23/34 => Loss 2.712, Loss_clf 0.477, Loss_fe 0.622, Loss_kd 1.310, Train_accy 55.88
2022-09-28 06:49:02,990 [foster.py] => Task 3, Epoch 24/34 => Loss 2.727, Loss_clf 0.480, Loss_fe 0.622, Loss_kd 1.320, Train_accy 55.53
2022-09-28 06:49:04,902 [foster.py] => Task 3, Epoch 25/34 => Loss 2.737, Loss_clf 0.495, Loss_fe 0.636, Loss_kd 1.304, Train_accy 53.90
2022-09-28 06:49:07,751 [foster.py] => Task 3, Epoch 26/34 => Loss 2.724, Loss_clf 0.498, Loss_fe 0.621, Loss_kd 1.304, Train_accy 55.76, Test_accy 54.40
2022-09-28 06:49:09,628 [foster.py] => Task 3, Epoch 27/34 => Loss 2.712, Loss_clf 0.480, Loss_fe 0.607, Loss_kd 1.320, Train_accy 56.58
2022-09-28 06:49:11,532 [foster.py] => Task 3, Epoch 28/34 => Loss 2.701, Loss_clf 0.475, Loss_fe 0.613, Loss_kd 1.310, Train_accy 55.88
2022-09-28 06:49:13,392 [foster.py] => Task 3, Epoch 29/34 => Loss 2.697, Loss_clf 0.468, Loss_fe 0.609, Loss_kd 1.317, Train_accy 56.11
2022-09-28 06:49:15,279 [foster.py] => Task 3, Epoch 30/34 => Loss 2.679, Loss_clf 0.473, Loss_fe 0.594, Loss_kd 1.310, Train_accy 55.53
2022-09-28 06:49:18,012 [foster.py] => Task 3, Epoch 31/34 => Loss 2.653, Loss_clf 0.454, Loss_fe 0.596, Loss_kd 1.302, Train_accy 55.30, Test_accy 53.87
2022-09-28 06:49:19,925 [foster.py] => Task 3, Epoch 32/34 => Loss 2.671, Loss_clf 0.464, Loss_fe 0.600, Loss_kd 1.305, Train_accy 55.18
2022-09-28 06:49:21,826 [foster.py] => Task 3, Epoch 33/34 => Loss 2.686, Loss_clf 0.479, Loss_fe 0.602, Loss_kd 1.304, Train_accy 54.13
2022-09-28 06:49:23,779 [foster.py] => Task 3, Epoch 34/34 => Loss 2.687, Loss_clf 0.470, Loss_fe 0.606, Loss_kd 1.309, Train_accy 54.13
2022-09-28 06:49:23,779 [foster.py] => do not weight align teacher!
2022-09-28 06:49:23,780 [foster.py] => per cls weights : [1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793 1.11353793
 1.11353793 0.5080023  0.5080023  0.5080023 ]
2022-09-28 06:49:26,864 [foster.py] => SNet: Task 3, Epoch 1/26 => Loss 2.121,  Train_accy 16.76, Test_accy 38.40
2022-09-28 06:49:29,049 [foster.py] => SNet: Task 3, Epoch 2/26 => Loss 2.053,  Train_accy 17.46
2022-09-28 06:49:31,217 [foster.py] => SNet: Task 3, Epoch 3/26 => Loss 2.002,  Train_accy 17.58
2022-09-28 06:49:33,379 [foster.py] => SNet: Task 3, Epoch 4/26 => Loss 1.992,  Train_accy 17.58
2022-09-28 06:49:35,484 [foster.py] => SNet: Task 3, Epoch 5/26 => Loss 1.970,  Train_accy 17.93
2022-09-28 06:49:38,421 [foster.py] => SNet: Task 3, Epoch 6/26 => Loss 1.963,  Train_accy 18.16, Test_accy 39.73
2022-09-28 06:49:40,572 [foster.py] => SNet: Task 3, Epoch 7/26 => Loss 1.942,  Train_accy 18.86
2022-09-28 06:49:42,657 [foster.py] => SNet: Task 3, Epoch 8/26 => Loss 1.958,  Train_accy 18.39
2022-09-28 06:49:44,725 [foster.py] => SNet: Task 3, Epoch 9/26 => Loss 1.945,  Train_accy 18.51
2022-09-28 06:49:46,870 [foster.py] => SNet: Task 3, Epoch 10/26 => Loss 1.929,  Train_accy 19.09
2022-09-28 06:49:49,723 [foster.py] => SNet: Task 3, Epoch 11/26 => Loss 1.922,  Train_accy 19.44, Test_accy 40.80
2022-09-28 06:49:51,793 [foster.py] => SNet: Task 3, Epoch 12/26 => Loss 1.933,  Train_accy 19.79
2022-09-28 06:49:53,909 [foster.py] => SNet: Task 3, Epoch 13/26 => Loss 1.927,  Train_accy 19.67
2022-09-28 06:49:56,037 [foster.py] => SNet: Task 3, Epoch 14/26 => Loss 1.924,  Train_accy 20.95
2022-09-28 06:49:58,157 [foster.py] => SNet: Task 3, Epoch 15/26 => Loss 1.925,  Train_accy 20.02
2022-09-28 06:50:01,010 [foster.py] => SNet: Task 3, Epoch 16/26 => Loss 1.923,  Train_accy 20.26, Test_accy 41.07
2022-09-28 06:50:03,094 [foster.py] => SNet: Task 3, Epoch 17/26 => Loss 1.916,  Train_accy 20.49
2022-09-28 06:50:05,202 [foster.py] => SNet: Task 3, Epoch 18/26 => Loss 1.915,  Train_accy 22.35
2022-09-28 06:50:07,295 [foster.py] => SNet: Task 3, Epoch 19/26 => Loss 1.913,  Train_accy 20.84
2022-09-28 06:50:09,433 [foster.py] => SNet: Task 3, Epoch 20/26 => Loss 1.912,  Train_accy 21.42
2022-09-28 06:50:12,296 [foster.py] => SNet: Task 3, Epoch 21/26 => Loss 1.912,  Train_accy 21.77, Test_accy 40.27
2022-09-28 06:50:14,416 [foster.py] => SNet: Task 3, Epoch 22/26 => Loss 1.906,  Train_accy 21.89
2022-09-28 06:50:16,584 [foster.py] => SNet: Task 3, Epoch 23/26 => Loss 1.921,  Train_accy 21.65
2022-09-28 06:50:18,678 [foster.py] => SNet: Task 3, Epoch 24/26 => Loss 1.908,  Train_accy 20.95
2022-09-28 06:50:20,809 [foster.py] => SNet: Task 3, Epoch 25/26 => Loss 1.918,  Train_accy 22.47
2022-09-28 06:50:23,745 [foster.py] => SNet: Task 3, Epoch 26/26 => Loss 1.921,  Train_accy 21.89, Test_accy 41.33
2022-09-28 06:50:23,745 [foster.py] => do not weight align student!
2022-09-28 06:50:24,508 [foster.py] => darknet eval: 
2022-09-28 06:50:24,508 [foster.py] => CNN top1 curve: 41.33
2022-09-28 06:50:24,508 [foster.py] => CNN top5 curve: 90.67
2022-09-28 06:50:24,509 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 06:50:33,014 [foster.py] => Exemplar size: 320
2022-09-28 06:50:33,014 [trainer.py] => CNN: {'total': 54.13, 'old': 54.01, 'new': 54.55, 'base': 74.39, 'compound': 38.39}
2022-09-28 06:50:33,014 [trainer.py] => CNN top1 curve: [82.32, 66.37, 57.14, 54.13]
2022-09-28 06:50:33,014 [trainer.py] => CNN base curve: [82.32, 79.27, 76.83, 74.39]
2022-09-28 06:50:33,015 [trainer.py] => CNN old curve: [82.32, 79.27, 62.83, 54.01]
2022-09-28 06:50:33,015 [trainer.py] => CNN new curve: [0, 32.26, 36.07, 54.55]
2022-09-28 06:50:33,015 [trainer.py] => CNN compound curve: [0, 32.26, 30.89, 38.39]
2022-09-28 06:50:33,015 [trainer.py] => NME: {'total': 62.13, 'old': 58.54, 'new': 73.86, 'base': 70.73, 'compound': 55.45}
2022-09-28 06:50:33,015 [trainer.py] => NME top1 curve: [81.71, 74.78, 65.16, 62.13]
2022-09-28 06:50:33,015 [trainer.py] => NME base curve: [81.71, 81.71, 75.0, 70.73]
2022-09-28 06:50:33,015 [trainer.py] => NME old curve: [81.71, 81.71, 68.14, 58.54]
2022-09-28 06:50:33,015 [trainer.py] => NME new curve: [0, 56.45, 54.1, 73.86]
2022-09-28 06:50:33,015 [trainer.py] => NME compound curve: [0, 56.45, 52.03, 55.45]
2022-09-28 06:50:33,245 [foster.py] => Learning on 16-19
2022-09-28 06:50:33,246 [foster.py] => All params: 22390454
2022-09-28 06:50:33,246 [foster.py] => Trainable params: 11205734
2022-09-28 06:50:33,266 [foster.py] => per cls weights : [1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591 1.07502591
 1.07502591 1.07502591 1.07502591 1.07502591 0.59986184 0.59986184
 0.59986184]
2022-09-28 06:50:36,207 [foster.py] => Task 4, Epoch 1/34 => Loss 6.342, Loss_clf 1.899, Loss_fe 2.390, Loss_kd 1.729, Train_accy 42.04, Test_accy 41.50
2022-09-28 06:50:38,196 [foster.py] => Task 4, Epoch 2/34 => Loss 4.783, Loss_clf 1.014, Loss_fe 1.710, Loss_kd 1.733, Train_accy 47.77
2022-09-28 06:50:40,235 [foster.py] => Task 4, Epoch 3/34 => Loss 4.435, Loss_clf 0.880, Loss_fe 1.489, Loss_kd 1.740, Train_accy 54.56
2022-09-28 06:50:42,243 [foster.py] => Task 4, Epoch 4/34 => Loss 4.270, Loss_clf 0.847, Loss_fe 1.353, Loss_kd 1.743, Train_accy 52.55
2022-09-28 06:50:44,264 [foster.py] => Task 4, Epoch 5/34 => Loss 4.139, Loss_clf 0.813, Loss_fe 1.264, Loss_kd 1.736, Train_accy 56.69
2022-09-28 06:50:47,235 [foster.py] => Task 4, Epoch 6/34 => Loss 4.014, Loss_clf 0.775, Loss_fe 1.170, Loss_kd 1.743, Train_accy 56.37, Test_accy 50.34
2022-09-28 06:50:49,275 [foster.py] => Task 4, Epoch 7/34 => Loss 3.935, Loss_clf 0.757, Loss_fe 1.120, Loss_kd 1.733, Train_accy 56.16
2022-09-28 06:50:51,269 [foster.py] => Task 4, Epoch 8/34 => Loss 3.876, Loss_clf 0.744, Loss_fe 1.069, Loss_kd 1.738, Train_accy 59.24
2022-09-28 06:50:53,314 [foster.py] => Task 4, Epoch 9/34 => Loss 3.817, Loss_clf 0.728, Loss_fe 1.015, Loss_kd 1.747, Train_accy 58.17
2022-09-28 06:50:55,330 [foster.py] => Task 4, Epoch 10/34 => Loss 3.737, Loss_clf 0.700, Loss_fe 0.963, Loss_kd 1.747, Train_accy 58.49
2022-09-28 06:50:58,391 [foster.py] => Task 4, Epoch 11/34 => Loss 3.673, Loss_clf 0.677, Loss_fe 0.929, Loss_kd 1.740, Train_accy 59.02, Test_accy 51.47
2022-09-28 06:51:00,409 [foster.py] => Task 4, Epoch 12/34 => Loss 3.606, Loss_clf 0.650, Loss_fe 0.886, Loss_kd 1.742, Train_accy 60.83
2022-09-28 06:51:02,413 [foster.py] => Task 4, Epoch 13/34 => Loss 3.592, Loss_clf 0.654, Loss_fe 0.869, Loss_kd 1.742, Train_accy 57.86
2022-09-28 06:51:04,491 [foster.py] => Task 4, Epoch 14/34 => Loss 3.537, Loss_clf 0.635, Loss_fe 0.832, Loss_kd 1.743, Train_accy 61.68
2022-09-28 06:51:06,484 [foster.py] => Task 4, Epoch 15/34 => Loss 3.536, Loss_clf 0.638, Loss_fe 0.824, Loss_kd 1.747, Train_accy 60.19
2022-09-28 06:51:09,416 [foster.py] => Task 4, Epoch 16/34 => Loss 3.519, Loss_clf 0.635, Loss_fe 0.806, Loss_kd 1.750, Train_accy 59.13, Test_accy 52.38
2022-09-28 06:51:11,442 [foster.py] => Task 4, Epoch 17/34 => Loss 3.494, Loss_clf 0.629, Loss_fe 0.790, Loss_kd 1.747, Train_accy 60.08
2022-09-28 06:51:13,450 [foster.py] => Task 4, Epoch 18/34 => Loss 3.498, Loss_clf 0.626, Loss_fe 0.799, Loss_kd 1.745, Train_accy 61.15
2022-09-28 06:51:15,464 [foster.py] => Task 4, Epoch 19/34 => Loss 3.461, Loss_clf 0.626, Loss_fe 0.766, Loss_kd 1.742, Train_accy 61.36
2022-09-28 06:51:17,493 [foster.py] => Task 4, Epoch 20/34 => Loss 3.432, Loss_clf 0.605, Loss_fe 0.742, Loss_kd 1.756, Train_accy 64.12
2022-09-28 06:51:20,438 [foster.py] => Task 4, Epoch 21/34 => Loss 3.415, Loss_clf 0.598, Loss_fe 0.739, Loss_kd 1.750, Train_accy 62.95, Test_accy 53.06
2022-09-28 06:51:22,433 [foster.py] => Task 4, Epoch 22/34 => Loss 3.392, Loss_clf 0.585, Loss_fe 0.729, Loss_kd 1.750, Train_accy 62.85
2022-09-28 06:51:24,470 [foster.py] => Task 4, Epoch 23/34 => Loss 3.429, Loss_clf 0.605, Loss_fe 0.752, Loss_kd 1.744, Train_accy 61.25
2022-09-28 06:51:26,547 [foster.py] => Task 4, Epoch 24/34 => Loss 3.377, Loss_clf 0.585, Loss_fe 0.722, Loss_kd 1.743, Train_accy 62.21
2022-09-28 06:51:28,614 [foster.py] => Task 4, Epoch 25/34 => Loss 3.386, Loss_clf 0.586, Loss_fe 0.716, Loss_kd 1.756, Train_accy 64.23
2022-09-28 06:51:31,554 [foster.py] => Task 4, Epoch 26/34 => Loss 3.390, Loss_clf 0.587, Loss_fe 0.729, Loss_kd 1.747, Train_accy 62.10, Test_accy 53.06
2022-09-28 06:51:33,542 [foster.py] => Task 4, Epoch 27/34 => Loss 3.370, Loss_clf 0.590, Loss_fe 0.705, Loss_kd 1.747, Train_accy 61.25
2022-09-28 06:51:35,533 [foster.py] => Task 4, Epoch 28/34 => Loss 3.363, Loss_clf 0.578, Loss_fe 0.704, Loss_kd 1.752, Train_accy 59.55
2022-09-28 06:51:37,525 [foster.py] => Task 4, Epoch 29/34 => Loss 3.383, Loss_clf 0.589, Loss_fe 0.720, Loss_kd 1.747, Train_accy 63.06
2022-09-28 06:51:39,539 [foster.py] => Task 4, Epoch 30/34 => Loss 3.356, Loss_clf 0.572, Loss_fe 0.703, Loss_kd 1.751, Train_accy 63.27
2022-09-28 06:51:42,490 [foster.py] => Task 4, Epoch 31/34 => Loss 3.355, Loss_clf 0.576, Loss_fe 0.708, Loss_kd 1.744, Train_accy 62.74, Test_accy 53.29
2022-09-28 06:51:44,592 [foster.py] => Task 4, Epoch 32/34 => Loss 3.349, Loss_clf 0.572, Loss_fe 0.701, Loss_kd 1.748, Train_accy 62.85
2022-09-28 06:51:46,587 [foster.py] => Task 4, Epoch 33/34 => Loss 3.324, Loss_clf 0.559, Loss_fe 0.679, Loss_kd 1.757, Train_accy 62.53
2022-09-28 06:51:48,622 [foster.py] => Task 4, Epoch 34/34 => Loss 3.338, Loss_clf 0.567, Loss_fe 0.690, Loss_kd 1.752, Train_accy 62.31
2022-09-28 06:51:48,623 [foster.py] => do not weight align teacher!
2022-09-28 06:51:48,623 [foster.py] => per cls weights : [1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705 1.09392705
 1.09392705 1.09392705 1.09392705 1.09392705 0.49905571 0.49905571
 0.49905571]
2022-09-28 06:51:51,976 [foster.py] => SNet: Task 4, Epoch 1/26 => Loss 2.455,  Train_accy 16.35, Test_accy 32.88
2022-09-28 06:51:54,290 [foster.py] => SNet: Task 4, Epoch 2/26 => Loss 2.393,  Train_accy 16.88
2022-09-28 06:51:56,516 [foster.py] => SNet: Task 4, Epoch 3/26 => Loss 2.341,  Train_accy 17.20
2022-09-28 06:51:58,790 [foster.py] => SNet: Task 4, Epoch 4/26 => Loss 2.324,  Train_accy 18.37
2022-09-28 06:52:01,079 [foster.py] => SNet: Task 4, Epoch 5/26 => Loss 2.311,  Train_accy 18.15
2022-09-28 06:52:04,118 [foster.py] => SNet: Task 4, Epoch 6/26 => Loss 2.302,  Train_accy 17.94, Test_accy 36.05
2022-09-28 06:52:06,359 [foster.py] => SNet: Task 4, Epoch 7/26 => Loss 2.292,  Train_accy 17.83
2022-09-28 06:52:08,659 [foster.py] => SNet: Task 4, Epoch 8/26 => Loss 2.296,  Train_accy 19.00
2022-09-28 06:52:10,887 [foster.py] => SNet: Task 4, Epoch 9/26 => Loss 2.279,  Train_accy 19.53
2022-09-28 06:52:13,162 [foster.py] => SNet: Task 4, Epoch 10/26 => Loss 2.290,  Train_accy 19.21
2022-09-28 06:52:16,196 [foster.py] => SNet: Task 4, Epoch 11/26 => Loss 2.278,  Train_accy 20.28, Test_accy 37.87
2022-09-28 06:52:18,441 [foster.py] => SNet: Task 4, Epoch 12/26 => Loss 2.261,  Train_accy 19.00
2022-09-28 06:52:20,761 [foster.py] => SNet: Task 4, Epoch 13/26 => Loss 2.271,  Train_accy 19.85
2022-09-28 06:52:23,008 [foster.py] => SNet: Task 4, Epoch 14/26 => Loss 2.268,  Train_accy 19.64
2022-09-28 06:52:25,283 [foster.py] => SNet: Task 4, Epoch 15/26 => Loss 2.268,  Train_accy 20.17
2022-09-28 06:52:28,397 [foster.py] => SNet: Task 4, Epoch 16/26 => Loss 2.259,  Train_accy 20.49, Test_accy 39.68
2022-09-28 06:52:30,638 [foster.py] => SNet: Task 4, Epoch 17/26 => Loss 2.267,  Train_accy 20.91
2022-09-28 06:52:32,928 [foster.py] => SNet: Task 4, Epoch 18/26 => Loss 2.268,  Train_accy 20.81
2022-09-28 06:52:35,148 [foster.py] => SNet: Task 4, Epoch 19/26 => Loss 2.253,  Train_accy 21.87
2022-09-28 06:52:37,420 [foster.py] => SNet: Task 4, Epoch 20/26 => Loss 2.264,  Train_accy 21.23
2022-09-28 06:52:40,541 [foster.py] => SNet: Task 4, Epoch 21/26 => Loss 2.259,  Train_accy 20.81, Test_accy 39.91
2022-09-28 06:52:42,819 [foster.py] => SNet: Task 4, Epoch 22/26 => Loss 2.248,  Train_accy 20.59
2022-09-28 06:52:45,054 [foster.py] => SNet: Task 4, Epoch 23/26 => Loss 2.256,  Train_accy 20.70
2022-09-28 06:52:47,297 [foster.py] => SNet: Task 4, Epoch 24/26 => Loss 2.265,  Train_accy 22.72
2022-09-28 06:52:49,553 [foster.py] => SNet: Task 4, Epoch 25/26 => Loss 2.279,  Train_accy 19.64
2022-09-28 06:52:52,631 [foster.py] => SNet: Task 4, Epoch 26/26 => Loss 2.250,  Train_accy 20.70, Test_accy 38.78
2022-09-28 06:52:52,632 [foster.py] => do not weight align student!
2022-09-28 06:52:53,432 [foster.py] => darknet eval: 
2022-09-28 06:52:53,433 [foster.py] => CNN top1 curve: 38.78
2022-09-28 06:52:53,433 [foster.py] => CNN top5 curve: 89.57
2022-09-28 06:52:53,433 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 06:53:03,068 [foster.py] => Exemplar size: 380
2022-09-28 06:53:03,068 [trainer.py] => CNN: {'total': 53.29, 'old': 53.07, 'new': 54.55, 'base': 70.12, 'compound': 43.32}
2022-09-28 06:53:03,068 [trainer.py] => CNN top1 curve: [82.32, 66.37, 57.14, 54.13, 53.29]
2022-09-28 06:53:03,068 [trainer.py] => CNN base curve: [82.32, 79.27, 76.83, 74.39, 70.12]
2022-09-28 06:53:03,068 [trainer.py] => CNN old curve: [82.32, 79.27, 62.83, 54.01, 53.07]
2022-09-28 06:53:03,068 [trainer.py] => CNN new curve: [0, 32.26, 36.07, 54.55, 54.55]
2022-09-28 06:53:03,068 [trainer.py] => CNN compound curve: [0, 32.26, 30.89, 38.39, 43.32]
2022-09-28 06:53:03,068 [trainer.py] => NME: {'total': 59.41, 'old': 58.4, 'new': 65.15, 'base': 67.68, 'compound': 54.51}
2022-09-28 06:53:03,068 [trainer.py] => NME top1 curve: [81.71, 74.78, 65.16, 62.13, 59.41]
2022-09-28 06:53:03,068 [trainer.py] => NME base curve: [81.71, 81.71, 75.0, 70.73, 67.68]
2022-09-28 06:53:03,068 [trainer.py] => NME old curve: [81.71, 81.71, 68.14, 58.54, 58.4]
2022-09-28 06:53:03,068 [trainer.py] => NME new curve: [0, 56.45, 54.1, 73.86, 65.15]
2022-09-28 06:53:03,068 [trainer.py] => NME compound curve: [0, 56.45, 52.03, 55.45, 54.51]
2022-09-28 06:53:03,298 [foster.py] => Learning on 19-22
2022-09-28 06:53:03,299 [foster.py] => All params: 22396607
2022-09-28 06:53:03,299 [foster.py] => Trainable params: 11210348
2022-09-28 06:53:03,319 [foster.py] => per cls weights : [1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891 1.06413891
 1.06413891 0.59378692 0.59378692 0.59378692]
2022-09-28 06:53:06,422 [foster.py] => Task 5, Epoch 1/34 => Loss 6.626, Loss_clf 1.824, Loss_fe 2.498, Loss_kd 1.989, Train_accy 39.26, Test_accy 40.08
2022-09-28 06:53:08,518 [foster.py] => Task 5, Epoch 2/34 => Loss 5.293, Loss_clf 1.143, Loss_fe 1.844, Loss_kd 1.992, Train_accy 40.06
2022-09-28 06:53:10,646 [foster.py] => Task 5, Epoch 3/34 => Loss 5.069, Loss_clf 1.089, Loss_fe 1.679, Loss_kd 1.987, Train_accy 45.13
2022-09-28 06:53:12,743 [foster.py] => Task 5, Epoch 4/34 => Loss 4.897, Loss_clf 1.042, Loss_fe 1.549, Loss_kd 1.991, Train_accy 45.23
2022-09-28 06:53:14,864 [foster.py] => Task 5, Epoch 5/34 => Loss 4.771, Loss_clf 1.019, Loss_fe 1.455, Loss_kd 1.984, Train_accy 43.24
2022-09-28 06:53:17,957 [foster.py] => Task 5, Epoch 6/34 => Loss 4.697, Loss_clf 1.006, Loss_fe 1.393, Loss_kd 1.985, Train_accy 45.33, Test_accy 45.83
2022-09-28 06:53:20,090 [foster.py] => Task 5, Epoch 7/34 => Loss 4.609, Loss_clf 0.979, Loss_fe 1.325, Loss_kd 1.991, Train_accy 46.92
2022-09-28 06:53:22,235 [foster.py] => Task 5, Epoch 8/34 => Loss 4.507, Loss_clf 0.946, Loss_fe 1.255, Loss_kd 1.992, Train_accy 45.83
2022-09-28 06:53:24,330 [foster.py] => Task 5, Epoch 9/34 => Loss 4.468, Loss_clf 0.947, Loss_fe 1.213, Loss_kd 1.993, Train_accy 47.02
2022-09-28 06:53:26,432 [foster.py] => Task 5, Epoch 10/34 => Loss 4.403, Loss_clf 0.922, Loss_fe 1.179, Loss_kd 1.989, Train_accy 45.43
2022-09-28 06:53:29,537 [foster.py] => Task 5, Epoch 11/34 => Loss 4.365, Loss_clf 0.914, Loss_fe 1.147, Loss_kd 1.989, Train_accy 45.03, Test_accy 46.83
2022-09-28 06:53:31,650 [foster.py] => Task 5, Epoch 12/34 => Loss 4.310, Loss_clf 0.888, Loss_fe 1.109, Loss_kd 1.998, Train_accy 45.92
2022-09-28 06:53:33,738 [foster.py] => Task 5, Epoch 13/34 => Loss 4.334, Loss_clf 0.907, Loss_fe 1.107, Loss_kd 2.003, Train_accy 47.71
2022-09-28 06:53:35,852 [foster.py] => Task 5, Epoch 14/34 => Loss 4.268, Loss_clf 0.883, Loss_fe 1.072, Loss_kd 1.998, Train_accy 46.92
2022-09-28 06:53:37,972 [foster.py] => Task 5, Epoch 15/34 => Loss 4.224, Loss_clf 0.857, Loss_fe 1.053, Loss_kd 1.999, Train_accy 49.11
2022-09-28 06:53:41,142 [foster.py] => Task 5, Epoch 16/34 => Loss 4.223, Loss_clf 0.868, Loss_fe 1.047, Loss_kd 1.993, Train_accy 47.32, Test_accy 47.62
2022-09-28 06:53:43,227 [foster.py] => Task 5, Epoch 17/34 => Loss 4.221, Loss_clf 0.863, Loss_fe 1.039, Loss_kd 2.003, Train_accy 46.42
2022-09-28 06:53:45,373 [foster.py] => Task 5, Epoch 18/34 => Loss 4.134, Loss_clf 0.835, Loss_fe 0.989, Loss_kd 1.995, Train_accy 47.81
2022-09-28 06:53:47,481 [foster.py] => Task 5, Epoch 19/34 => Loss 4.118, Loss_clf 0.825, Loss_fe 0.978, Loss_kd 1.999, Train_accy 47.32
2022-09-28 06:53:49,579 [foster.py] => Task 5, Epoch 20/34 => Loss 4.135, Loss_clf 0.832, Loss_fe 0.986, Loss_kd 2.001, Train_accy 48.61
2022-09-28 06:53:52,699 [foster.py] => Task 5, Epoch 21/34 => Loss 4.114, Loss_clf 0.821, Loss_fe 0.975, Loss_kd 2.001, Train_accy 46.52, Test_accy 48.41
2022-09-28 06:53:54,813 [foster.py] => Task 5, Epoch 22/34 => Loss 4.119, Loss_clf 0.832, Loss_fe 0.973, Loss_kd 1.998, Train_accy 49.11
2022-09-28 06:53:56,961 [foster.py] => Task 5, Epoch 23/34 => Loss 4.087, Loss_clf 0.820, Loss_fe 0.950, Loss_kd 2.001, Train_accy 47.81
2022-09-28 06:53:59,041 [foster.py] => Task 5, Epoch 24/34 => Loss 4.077, Loss_clf 0.814, Loss_fe 0.953, Loss_kd 1.995, Train_accy 48.31
2022-09-28 06:54:01,167 [foster.py] => Task 5, Epoch 25/34 => Loss 4.054, Loss_clf 0.807, Loss_fe 0.945, Loss_kd 1.988, Train_accy 48.01
2022-09-28 06:54:04,301 [foster.py] => Task 5, Epoch 26/34 => Loss 4.082, Loss_clf 0.814, Loss_fe 0.945, Loss_kd 2.007, Train_accy 49.20, Test_accy 47.42
2022-09-28 06:54:06,417 [foster.py] => Task 5, Epoch 27/34 => Loss 4.055, Loss_clf 0.810, Loss_fe 0.933, Loss_kd 1.997, Train_accy 49.40
2022-09-28 06:54:08,554 [foster.py] => Task 5, Epoch 28/34 => Loss 4.041, Loss_clf 0.789, Loss_fe 0.943, Loss_kd 1.994, Train_accy 49.90
2022-09-28 06:54:10,719 [foster.py] => Task 5, Epoch 29/34 => Loss 4.047, Loss_clf 0.805, Loss_fe 0.933, Loss_kd 1.995, Train_accy 48.21
2022-09-28 06:54:12,866 [foster.py] => Task 5, Epoch 30/34 => Loss 4.043, Loss_clf 0.798, Loss_fe 0.927, Loss_kd 2.002, Train_accy 49.50
2022-09-28 06:54:15,990 [foster.py] => Task 5, Epoch 31/34 => Loss 4.025, Loss_clf 0.789, Loss_fe 0.924, Loss_kd 1.997, Train_accy 49.30, Test_accy 48.21
2022-09-28 06:54:18,063 [foster.py] => Task 5, Epoch 32/34 => Loss 4.024, Loss_clf 0.796, Loss_fe 0.918, Loss_kd 1.995, Train_accy 47.61
2022-09-28 06:54:20,167 [foster.py] => Task 5, Epoch 33/34 => Loss 4.015, Loss_clf 0.783, Loss_fe 0.916, Loss_kd 2.000, Train_accy 48.91
2022-09-28 06:54:22,277 [foster.py] => Task 5, Epoch 34/34 => Loss 4.035, Loss_clf 0.794, Loss_fe 0.929, Loss_kd 1.996, Train_accy 48.61
2022-09-28 06:54:22,278 [foster.py] => do not weight align teacher!
2022-09-28 06:54:22,278 [foster.py] => per cls weights : [1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297 1.08009297
 1.08009297 0.49274452 0.49274452 0.49274452]
2022-09-28 06:54:25,726 [foster.py] => SNet: Task 5, Epoch 1/26 => Loss 2.523,  Train_accy 18.09, Test_accy 35.32
2022-09-28 06:54:28,101 [foster.py] => SNet: Task 5, Epoch 2/26 => Loss 2.496,  Train_accy 18.99
2022-09-28 06:54:30,509 [foster.py] => SNet: Task 5, Epoch 3/26 => Loss 2.487,  Train_accy 18.79
2022-09-28 06:54:32,933 [foster.py] => SNet: Task 5, Epoch 4/26 => Loss 2.486,  Train_accy 19.68
2022-09-28 06:54:35,303 [foster.py] => SNet: Task 5, Epoch 5/26 => Loss 2.478,  Train_accy 18.89
2022-09-28 06:54:38,527 [foster.py] => SNet: Task 5, Epoch 6/26 => Loss 2.465,  Train_accy 19.98, Test_accy 36.31
2022-09-28 06:54:40,927 [foster.py] => SNet: Task 5, Epoch 7/26 => Loss 2.461,  Train_accy 19.68
2022-09-28 06:54:43,317 [foster.py] => SNet: Task 5, Epoch 8/26 => Loss 2.454,  Train_accy 19.88
2022-09-28 06:54:45,715 [foster.py] => SNet: Task 5, Epoch 9/26 => Loss 2.455,  Train_accy 20.97
2022-09-28 06:54:48,060 [foster.py] => SNet: Task 5, Epoch 10/26 => Loss 2.453,  Train_accy 20.97
2022-09-28 06:54:51,283 [foster.py] => SNet: Task 5, Epoch 11/26 => Loss 2.447,  Train_accy 20.58, Test_accy 37.30
2022-09-28 06:54:53,648 [foster.py] => SNet: Task 5, Epoch 12/26 => Loss 2.449,  Train_accy 20.97
2022-09-28 06:54:55,997 [foster.py] => SNet: Task 5, Epoch 13/26 => Loss 2.449,  Train_accy 20.87
2022-09-28 06:54:58,430 [foster.py] => SNet: Task 5, Epoch 14/26 => Loss 2.450,  Train_accy 19.98
2022-09-28 06:55:00,820 [foster.py] => SNet: Task 5, Epoch 15/26 => Loss 2.447,  Train_accy 20.97
2022-09-28 06:55:04,071 [foster.py] => SNet: Task 5, Epoch 16/26 => Loss 2.441,  Train_accy 21.27, Test_accy 37.90
2022-09-28 06:55:06,419 [foster.py] => SNet: Task 5, Epoch 17/26 => Loss 2.440,  Train_accy 21.07
2022-09-28 06:55:08,830 [foster.py] => SNet: Task 5, Epoch 18/26 => Loss 2.437,  Train_accy 21.27
2022-09-28 06:55:11,199 [foster.py] => SNet: Task 5, Epoch 19/26 => Loss 2.445,  Train_accy 20.48
2022-09-28 06:55:13,533 [foster.py] => SNet: Task 5, Epoch 20/26 => Loss 2.441,  Train_accy 21.27
2022-09-28 06:55:16,798 [foster.py] => SNet: Task 5, Epoch 21/26 => Loss 2.443,  Train_accy 20.97, Test_accy 38.69
2022-09-28 06:55:19,147 [foster.py] => SNet: Task 5, Epoch 22/26 => Loss 2.445,  Train_accy 21.07
2022-09-28 06:55:21,512 [foster.py] => SNet: Task 5, Epoch 23/26 => Loss 2.437,  Train_accy 21.47
2022-09-28 06:55:23,914 [foster.py] => SNet: Task 5, Epoch 24/26 => Loss 2.440,  Train_accy 21.87
2022-09-28 06:55:26,324 [foster.py] => SNet: Task 5, Epoch 25/26 => Loss 2.432,  Train_accy 21.07
2022-09-28 06:55:29,518 [foster.py] => SNet: Task 5, Epoch 26/26 => Loss 2.439,  Train_accy 19.88, Test_accy 36.90
2022-09-28 06:55:29,518 [foster.py] => do not weight align student!
2022-09-28 06:55:30,373 [foster.py] => darknet eval: 
2022-09-28 06:55:30,373 [foster.py] => CNN top1 curve: 36.9
2022-09-28 06:55:30,373 [foster.py] => CNN top5 curve: 82.14
2022-09-28 06:55:30,374 [base.py] => Constructing exemplars for new classes...(20 per classes)
2022-09-28 06:55:41,053 [foster.py] => Exemplar size: 440
2022-09-28 06:55:41,053 [trainer.py] => CNN: {'total': 48.21, 'old': 51.93, 'new': 22.22, 'base': 67.68, 'compound': 38.82}
2022-09-28 06:55:41,053 [trainer.py] => CNN top1 curve: [82.32, 66.37, 57.14, 54.13, 53.29, 48.21]
2022-09-28 06:55:41,053 [trainer.py] => CNN base curve: [82.32, 79.27, 76.83, 74.39, 70.12, 67.68]
2022-09-28 06:55:41,053 [trainer.py] => CNN old curve: [82.32, 79.27, 62.83, 54.01, 53.07, 51.93]
2022-09-28 06:55:41,053 [trainer.py] => CNN new curve: [0, 32.26, 36.07, 54.55, 54.55, 22.22]
2022-09-28 06:55:41,053 [trainer.py] => CNN compound curve: [0, 32.26, 30.89, 38.39, 43.32, 38.82]
2022-09-28 06:55:41,053 [trainer.py] => NME: {'total': 54.76, 'old': 57.37, 'new': 36.51, 'base': 67.68, 'compound': 48.53}
2022-09-28 06:55:41,053 [trainer.py] => NME top1 curve: [81.71, 74.78, 65.16, 62.13, 59.41, 54.76]
2022-09-28 06:55:41,053 [trainer.py] => NME base curve: [81.71, 81.71, 75.0, 70.73, 67.68, 67.68]
2022-09-28 06:55:41,053 [trainer.py] => NME old curve: [81.71, 81.71, 68.14, 58.54, 58.4, 57.37]
2022-09-28 06:55:41,053 [trainer.py] => NME new curve: [0, 56.45, 54.1, 73.86, 65.15, 36.51]
2022-09-28 06:55:41,053 [trainer.py] => NME compound curve: [0, 56.45, 52.03, 55.45, 54.51, 48.53]
2022-09-28 06:55:41,055 [trainer.py] => top1: CNN:[87.29166667 72.028      60.29833333 53.791      51.333      47.95166667]+-[0.30764084 3.7050982  4.43618713 2.50687215 1.19915498 0.16892273]
2022-09-28 06:55:41,055 [trainer.py] => top1: NME:[87.655      77.87066667 68.008      61.17533333 57.373      53.86433333]+-[0.23239621 3.41128728 4.26885098 1.72956841 1.00322912 0.66263934]
2022-09-28 06:55:41,055 [trainer.py] => Last: top1: CNN:62.12+-1.60
2022-09-28 06:55:41,055 [trainer.py] => Last: top1: NME:67.66+-1.40
2022-09-28 06:55:41,056 [trainer.py] => base: CNN:[87.29166667 84.72833333 80.75933333 76.96333333 73.4        70.024     ]+-[0.30764084 0.6489917  1.02542165 0.68770843 1.25421396 1.19510111]
2022-09-28 06:55:41,056 [trainer.py] => base: NME:[87.655      82.22866667 74.81433333 70.264      68.14733333 67.055     ]+-[0.23239621 1.10349938 1.27122653 0.96633638 0.81422861 0.9934576 ]
2022-09-28 06:55:41,056 [trainer.py] => Last: base: CNN:78.86+-0.75
2022-09-28 06:55:41,056 [trainer.py] => Last: base: NME:75.03+-0.66
2022-09-28 06:55:41,056 [trainer.py] => old: CNN:[87.29166667 84.72833333 68.78133333 58.41233333 53.23433333 50.228     ]+-[0.30764084 0.6489917  4.56555147 4.8294492  1.188091   0.25880623]
2022-09-28 06:55:41,057 [trainer.py] => old: NME:[87.655      82.22866667 70.23966667 62.77333333 57.413      54.741     ]+-[0.23239621 1.10349938 3.37026857 4.1843061  0.92380229 0.26139625]
2022-09-28 06:55:41,057 [trainer.py] => Last: old: CNN:67.11+-1.84
2022-09-28 06:55:41,057 [trainer.py] => Last: old: NME:69.18+-1.54
2022-09-28 06:55:41,057 [trainer.py] => new: CNN:[ 0.         42.437      32.13433333 33.921      41.18266667 33.41      ]+-[ 0.         10.81602404  5.0169574   9.03374883 11.84617875  2.54750348]
2022-09-28 06:55:41,057 [trainer.py] => new: NME:[ 0.         67.76333333 60.50733333 54.26466667 57.207      48.38166667]+-[ 0.          8.88202118  7.55876676 12.09619558  9.05584964  3.70189738]
2022-09-28 06:55:41,057 [trainer.py] => Last: new: CNN:36.62+-0.92
2022-09-28 06:55:41,058 [trainer.py] => Last: new: NME:57.62+-0.22
2022-09-28 06:55:41,058 [trainer.py] => compound: CNN:[ 0.         42.437      36.49266667 35.79233333 38.474      37.68733333]+-[ 0.         10.81602404  9.44329788  3.91899046  2.63764529  0.4757915 ]
2022-09-28 06:55:41,058 [trainer.py] => compound: NME:[ 0.         67.76333333 60.145      54.12366667 51.09333333 47.75466667]+-[0.         8.88202118 9.05636763 2.4305325  2.01888721 0.51698958]
2022-09-28 06:55:41,058 [trainer.py] => Last: compound: CNN:38.18+-4.09
2022-09-28 06:55:41,058 [trainer.py] => Last: compound: NME:56.18+-3.61